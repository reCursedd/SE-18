{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429539894", "html_url": "https://github.com/tensorflow/tensorflow/issues/13342#issuecomment-429539894", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13342", "id": 429539894, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTUzOTg5NA==", "user": {"login": "u10116032", "id": 20497002, "node_id": "MDQ6VXNlcjIwNDk3MDAy", "avatar_url": "https://avatars3.githubusercontent.com/u/20497002?v=4", "gravatar_id": "", "url": "https://api.github.com/users/u10116032", "html_url": "https://github.com/u10116032", "followers_url": "https://api.github.com/users/u10116032/followers", "following_url": "https://api.github.com/users/u10116032/following{/other_user}", "gists_url": "https://api.github.com/users/u10116032/gists{/gist_id}", "starred_url": "https://api.github.com/users/u10116032/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/u10116032/subscriptions", "organizations_url": "https://api.github.com/users/u10116032/orgs", "repos_url": "https://api.github.com/users/u10116032/repos", "events_url": "https://api.github.com/users/u10116032/events{/privacy}", "received_events_url": "https://api.github.com/users/u10116032/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-13T12:58:08Z", "updated_at": "2018-10-13T12:59:06Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11674304\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gauss-clb\">@gauss-clb</a> First of all, thanks for your sharing.</p>\n<p>According to your comment \"Don't put checkpoint file in logdir, so that the saver can't restore and init_fn will work.\" So in my concept, slim will still run init_op and init_fn when saver cannot restore successfully, which means all global variables are initialized then.</p>\n<p>However, in my case, I found that the additional variables (not included in checkpoint) are still not initialized in NON CHIEF worker, but the chief worker can train well (I think it means that all variables are initialized successfully).<br>\nAny ideas? Thanks!</p>", "body_text": "@gauss-clb First of all, thanks for your sharing.\nAccording to your comment \"Don't put checkpoint file in logdir, so that the saver can't restore and init_fn will work.\" So in my concept, slim will still run init_op and init_fn when saver cannot restore successfully, which means all global variables are initialized then.\nHowever, in my case, I found that the additional variables (not included in checkpoint) are still not initialized in NON CHIEF worker, but the chief worker can train well (I think it means that all variables are initialized successfully).\nAny ideas? Thanks!", "body": "@gauss-clb First of all, thanks for your sharing. \r\n\r\nAccording to your comment \"Don't put checkpoint file in logdir, so that the saver can't restore and init_fn will work.\" So in my concept, slim will still run init_op and init_fn when saver cannot restore successfully, which means all global variables are initialized then.\r\n\r\nHowever, in my case, I found that the additional variables (not included in checkpoint) are still not initialized in NON CHIEF worker, but the chief worker can train well (I think it means that all variables are initialized successfully).\r\nAny ideas? Thanks!"}