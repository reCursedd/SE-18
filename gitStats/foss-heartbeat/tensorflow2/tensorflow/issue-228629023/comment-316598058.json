{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316598058", "html_url": "https://github.com/tensorflow/tensorflow/pull/9909#issuecomment-316598058", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9909", "id": 316598058, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjU5ODA1OA==", "user": {"login": "KristianHolsheimer", "id": 8200332, "node_id": "MDQ6VXNlcjgyMDAzMzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8200332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KristianHolsheimer", "html_url": "https://github.com/KristianHolsheimer", "followers_url": "https://api.github.com/users/KristianHolsheimer/followers", "following_url": "https://api.github.com/users/KristianHolsheimer/following{/other_user}", "gists_url": "https://api.github.com/users/KristianHolsheimer/gists{/gist_id}", "starred_url": "https://api.github.com/users/KristianHolsheimer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KristianHolsheimer/subscriptions", "organizations_url": "https://api.github.com/users/KristianHolsheimer/orgs", "repos_url": "https://api.github.com/users/KristianHolsheimer/repos", "events_url": "https://api.github.com/users/KristianHolsheimer/events{/privacy}", "received_events_url": "https://api.github.com/users/KristianHolsheimer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-20T05:07:55Z", "updated_at": "2017-07-20T05:07:55Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> The docstring isn't the thing that's wrong here. The reason is that it's used by e.g. <code>LSTMCell</code>, which requires the behavior mentioned in the docsting, <em>not</em> the implementation that you suggest. If we keep the implementation like this, we are diverting from the standard LSTM architecture in two ways:</p>\n<ol>\n<li>We use <code>len(args)</code> more weights</li>\n<li>We allow for mixing between input and hidden state at each time step</li>\n</ol>\n<p>I suspect that the real reason we're doing this concatenation thing is (time) optimization. So, if we're willing to have a non-standard definition of LSTM in tensorflow, we could decide to leave it like this, but <em>we need to be honest and make this choice consciously</em>, not as an unintended by-product of a low-level optimization trick.</p>\n<p>For the record, my choice would be to use the definition of LSTM that is used by the rest of the community (as per this pull request).</p>", "body_text": "@ebrevdo The docstring isn't the thing that's wrong here. The reason is that it's used by e.g. LSTMCell, which requires the behavior mentioned in the docsting, not the implementation that you suggest. If we keep the implementation like this, we are diverting from the standard LSTM architecture in two ways:\n\nWe use len(args) more weights\nWe allow for mixing between input and hidden state at each time step\n\nI suspect that the real reason we're doing this concatenation thing is (time) optimization. So, if we're willing to have a non-standard definition of LSTM in tensorflow, we could decide to leave it like this, but we need to be honest and make this choice consciously, not as an unintended by-product of a low-level optimization trick.\nFor the record, my choice would be to use the definition of LSTM that is used by the rest of the community (as per this pull request).", "body": "@ebrevdo The docstring isn't the thing that's wrong here. The reason is that it's used by e.g. `LSTMCell`, which requires the behavior mentioned in the docsting, *not* the implementation that you suggest. If we keep the implementation like this, we are diverting from the standard LSTM architecture in two ways:\r\n\r\n1. We use `len(args)` more weights\r\n2. We allow for mixing between input and hidden state at each time step\r\n\r\nI suspect that the real reason we're doing this concatenation thing is (time) optimization. So, if we're willing to have a non-standard definition of LSTM in tensorflow, we could decide to leave it like this, but *we need to be honest and make this choice consciously*, not as an unintended by-product of a low-level optimization trick.\r\n\r\nFor the record, my choice would be to use the definition of LSTM that is used by the rest of the community (as per this pull request).\r\n\r\n"}