{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17765", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17765/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17765/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17765/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17765", "id": 305890853, "node_id": "MDU6SXNzdWUzMDU4OTA4NTM=", "number": 17765, "title": "how to set sample weight  for binary classfication", "user": {"login": "klyan", "id": 7780254, "node_id": "MDQ6VXNlcjc3ODAyNTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7780254?v=4", "gravatar_id": "", "url": "https://api.github.com/users/klyan", "html_url": "https://github.com/klyan", "followers_url": "https://api.github.com/users/klyan/followers", "following_url": "https://api.github.com/users/klyan/following{/other_user}", "gists_url": "https://api.github.com/users/klyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/klyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/klyan/subscriptions", "organizations_url": "https://api.github.com/users/klyan/orgs", "repos_url": "https://api.github.com/users/klyan/repos", "events_url": "https://api.github.com/users/klyan/events{/privacy}", "received_events_url": "https://api.github.com/users/klyan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-03-16T11:17:47Z", "updated_at": "2018-03-16T19:40:42Z", "closed_at": "2018-03-16T19:40:42Z", "author_association": "NONE", "body_html": "<p>I Know <code>tf.losses.sparse_softmax_cross_entropy</code> could set weights for different samples, But I don not know how to use it in my_custom_model</p>\n<p>for example, in the ctr predicition, I want set 10 weights for the order samples, and the weight of click samples and the unclick sample is still 1.</p>\n<p>Here is my unweighted code</p>\n<p>`</p>\n<p>def my_custom_model(features, labels, mode, params):</p>\n<pre><code>net = tf.feature_column.input_layer(features, params['feature_columns'])\n\nfor units in params['hidden_units']:\n    net = tf.layers.dense(net, units=units, activation=params[\"activation\"])  \n\nlogits = tf.layers.dense(net, params['n_classes'], activation=None)\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\n        'probabilities': tf.nn.softmax(logits),\n        'logits': logits,\n   }\n   return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\nmetrics = {'auc': tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])}\n\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n\nassert mode == tf.estimator.ModeKeys.TRAIN\noptimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n</code></pre>\n<p><code></code><br>\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=False)<br>\nclassifier.train(input_fn=train_input_fn)`</p>\n<p>Here <code>data_train_click</code> is a Series, which the click samples are 1 and the unclicked samples are 0.</p>\n<p>And in the weight Series <code>data_train_weight</code> , the order samples are 10 and the others are 1.</p>\n<p>However, I don't known how to use <code>data_train_weight</code> in my model.</p>", "body_text": "I Know tf.losses.sparse_softmax_cross_entropy could set weights for different samples, But I don not know how to use it in my_custom_model\nfor example, in the ctr predicition, I want set 10 weights for the order samples, and the weight of click samples and the unclick sample is still 1.\nHere is my unweighted code\n`\ndef my_custom_model(features, labels, mode, params):\nnet = tf.feature_column.input_layer(features, params['feature_columns'])\n\nfor units in params['hidden_units']:\n    net = tf.layers.dense(net, units=units, activation=params[\"activation\"])  \n\nlogits = tf.layers.dense(net, params['n_classes'], activation=None)\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\n        'probabilities': tf.nn.softmax(logits),\n        'logits': logits,\n   }\n   return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\nmetrics = {'auc': tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])}\n\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n\nassert mode == tf.estimator.ModeKeys.TRAIN\noptimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\n\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=False)\nclassifier.train(input_fn=train_input_fn)`\nHere data_train_click is a Series, which the click samples are 1 and the unclicked samples are 0.\nAnd in the weight Series data_train_weight , the order samples are 10 and the others are 1.\nHowever, I don't known how to use data_train_weight in my model.", "body": "I Know `tf.losses.sparse_softmax_cross_entropy` could set weights for different samples, But I don not know how to use it in my_custom_model\r\n\r\nfor example, in the ctr predicition, I want set 10 weights for the order samples, and the weight of click samples and the unclick sample is still 1.\r\n\r\nHere is my unweighted code\r\n\r\n`\r\n\r\ndef my_custom_model(features, labels, mode, params):\r\n\r\n    net = tf.feature_column.input_layer(features, params['feature_columns'])\r\n\r\n    for units in params['hidden_units']:\r\n        net = tf.layers.dense(net, units=units, activation=params[\"activation\"])  \r\n\r\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            'probabilities': tf.nn.softmax(logits),\r\n            'logits': logits,\r\n       }\r\n       return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n\r\n    metrics = {'auc': tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])}\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n    assert mode == tf.estimator.ModeKeys.TRAIN\r\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\r\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n`\r\n`\r\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=False)\r\nclassifier.train(input_fn=train_input_fn)`\r\n\r\nHere `data_train_click` is a Series, which the click samples are 1 and the unclicked samples are 0. \r\n\r\nAnd in the weight Series `data_train_weight` , the order samples are 10 and the others are 1.\r\n\r\nHowever, I don't known how to use `data_train_weight` in my model.\r\n"}