{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348849210", "html_url": "https://github.com/tensorflow/tensorflow/issues/15034#issuecomment-348849210", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15034", "id": 348849210, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODg0OTIxMA==", "user": {"login": "khanrc", "id": 3657248, "node_id": "MDQ6VXNlcjM2NTcyNDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/3657248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/khanrc", "html_url": "https://github.com/khanrc", "followers_url": "https://api.github.com/users/khanrc/followers", "following_url": "https://api.github.com/users/khanrc/following{/other_user}", "gists_url": "https://api.github.com/users/khanrc/gists{/gist_id}", "starred_url": "https://api.github.com/users/khanrc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/khanrc/subscriptions", "organizations_url": "https://api.github.com/users/khanrc/orgs", "repos_url": "https://api.github.com/users/khanrc/repos", "events_url": "https://api.github.com/users/khanrc/events{/privacy}", "received_events_url": "https://api.github.com/users/khanrc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-04T03:04:48Z", "updated_at": "2017-12-04T03:04:48Z", "author_association": "NONE", "body_html": "<p>I tried:</p>\n<pre><code>python tensorflow/python/tools/optimize_for_inference.py \\\n--input ./ckpt/frozen_model.pb \\\n--output ./ckpt/optimized_model.pb \\\n--frozen_graph true \\\n--input_names Placeholder \\\n--output_names policy_head/softmax,value_head/value/Tanh\n</code></pre>\n<p>and</p>\n<pre><code>tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph='./ckpt/frozen_model.pb' \\\n--out_graph='./ckpt/transformed_model.pb' \\\n--inputs='Placeholder' \\\n--outputs='policy_head/softmax,value_head/value/Tanh' \\\n--transforms='\nfold_constants(ignore_errors=true)\nfold_batch_norms\nfold_old_batch_norms\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\n'\n</code></pre>\n<p>In both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error.</p>", "body_text": "I tried:\npython tensorflow/python/tools/optimize_for_inference.py \\\n--input ./ckpt/frozen_model.pb \\\n--output ./ckpt/optimized_model.pb \\\n--frozen_graph true \\\n--input_names Placeholder \\\n--output_names policy_head/softmax,value_head/value/Tanh\n\nand\ntensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph='./ckpt/frozen_model.pb' \\\n--out_graph='./ckpt/transformed_model.pb' \\\n--inputs='Placeholder' \\\n--outputs='policy_head/softmax,value_head/value/Tanh' \\\n--transforms='\nfold_constants(ignore_errors=true)\nfold_batch_norms\nfold_old_batch_norms\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\n'\n\nIn both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error.", "body": "I tried:\r\n\r\n```\r\npython tensorflow/python/tools/optimize_for_inference.py \\\r\n--input ./ckpt/frozen_model.pb \\\r\n--output ./ckpt/optimized_model.pb \\\r\n--frozen_graph true \\\r\n--input_names Placeholder \\\r\n--output_names policy_head/softmax,value_head/value/Tanh\r\n```\r\n\r\nand\r\n\r\n```\r\ntensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph='./ckpt/frozen_model.pb' \\\r\n--out_graph='./ckpt/transformed_model.pb' \\\r\n--inputs='Placeholder' \\\r\n--outputs='policy_head/softmax,value_head/value/Tanh' \\\r\n--transforms='\r\nfold_constants(ignore_errors=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\n'\r\n```\r\n\r\nIn both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error."}