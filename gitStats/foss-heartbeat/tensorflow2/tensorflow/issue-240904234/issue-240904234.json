{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11320", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11320/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11320/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11320/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11320", "id": 240904234, "node_id": "MDU6SXNzdWUyNDA5MDQyMzQ=", "number": 11320, "title": "BeamSearchDecoder Bug on beam_width", "user": {"login": "superrrrrr1995", "id": 17977180, "node_id": "MDQ6VXNlcjE3OTc3MTgw", "avatar_url": "https://avatars3.githubusercontent.com/u/17977180?v=4", "gravatar_id": "", "url": "https://api.github.com/users/superrrrrr1995", "html_url": "https://github.com/superrrrrr1995", "followers_url": "https://api.github.com/users/superrrrrr1995/followers", "following_url": "https://api.github.com/users/superrrrrr1995/following{/other_user}", "gists_url": "https://api.github.com/users/superrrrrr1995/gists{/gist_id}", "starred_url": "https://api.github.com/users/superrrrrr1995/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/superrrrrr1995/subscriptions", "organizations_url": "https://api.github.com/users/superrrrrr1995/orgs", "repos_url": "https://api.github.com/users/superrrrrr1995/repos", "events_url": "https://api.github.com/users/superrrrrr1995/events{/privacy}", "received_events_url": "https://api.github.com/users/superrrrrr1995/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-06T09:56:00Z", "updated_at": "2017-07-06T17:21:15Z", "closed_at": "2017-07-06T17:21:15Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04</li>\n<li>TensorFlow installed from (source or binary): Pip Binary</li>\n<li>TensorFlow version (use command below): 1.2.1</li>\n<li>Python version: 3.4</li>\n</ul>\n<h3>My coustom code</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>():\n<span class=\"pl-s\"><span class=\"pl-pds\">'''</span></span>\n<span class=\"pl-s\">A seq2seq model</span>\n<span class=\"pl-s\">placeholder: </span>\n<span class=\"pl-s\">    encoder_input, a int32 tensor shaped [None, max_encoder_len]</span>\n<span class=\"pl-s\">    encoder_length, a int32 tensor shaped [None]</span>\n<span class=\"pl-s\">    decoder_input, a int32 tensor shaped [None, max_decoder_len]</span>\n<span class=\"pl-s\">cell:</span>\n<span class=\"pl-s\">    LSTMCell. cell.output_size = 128</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">'''</span></span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> some irrespective code</span>\n\n    <span class=\"pl-en\">@</span><span class=\"pl-c1\">property</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_prediction</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">with</span> <span class=\"pl-c1\">self</span>._graph.as_default():\n            <span class=\"pl-c1\">GO_SYMBOL</span> <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">500</span>]\n            <span class=\"pl-c1\">END_SYMBOL</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">501</span>\n\n            initial_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.encoder[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>final_state<span class=\"pl-pds\">'</span></span>]\n\n            decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BeamSearchDecoder(\n                <span class=\"pl-v\">cell</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.cell,\n                <span class=\"pl-v\">embedding</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">tokens</span>:tf.nn.embedding_lookup(<span class=\"pl-c1\">self</span>._decoder_embedding, tokens),\n                <span class=\"pl-v\">start_tokens</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">GO_SYMBOL</span>,\n                <span class=\"pl-v\">end_token</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">END_SYMBOL</span>,\n                <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>initial_state,\n                <span class=\"pl-v\">beam_width</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._beam_size, <span class=\"pl-c\"><span class=\"pl-c\">#</span> self._beam_size = 1 is ok </span>\n                                            <span class=\"pl-c\"><span class=\"pl-c\">#</span> but self._beam_size = 2 runs wrong</span>\n                <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._output_projection_layer\n            )\n\n            outputs, _, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n                <span class=\"pl-v\">decoder</span><span class=\"pl-k\">=</span>decoder,\n                <span class=\"pl-v\">maximum_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._max_decoder_len\n            )\n\n            <span class=\"pl-k\">return</span> outputs.predicted_ids[:, :, <span class=\"pl-c1\">0</span>]\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> some irrespective code</span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">predict</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">word_list</span>):\n        <span class=\"pl-s\"><span class=\"pl-pds\">'''</span></span>\n<span class=\"pl-s\">        Args:</span>\n<span class=\"pl-s\">            word_list: [word0, word1...]. 1-dimentional array</span>\n<span class=\"pl-s\">        return:</span>\n<span class=\"pl-s\">            outputs: [o0, o1...]. 1-dimentional array</span>\n<span class=\"pl-s\">                     where oi is word_index</span>\n<span class=\"pl-s\">        <span class=\"pl-pds\">'''</span></span>\n        length <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(word_list)\n        word_index_list <span class=\"pl-k\">=</span> preprocess.words_to_indices(word_list) <span class=\"pl-c\"><span class=\"pl-c\">#</span> turn words to numbers</span>\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(word_index_list) <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">self</span>._max_encoder_len:\n            word_index_list.extend([<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">self</span>._max_encoder_len <span class=\"pl-k\">-</span> <span class=\"pl-c1\">len</span>(word_index_list)))\n\n        feed_dict <span class=\"pl-k\">=</span> {\n            <span class=\"pl-c1\">self</span>.input_length[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_input<span class=\"pl-pds\">'</span></span>]: [word_index_list],\n            <span class=\"pl-c1\">self</span>.input_length[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_length<span class=\"pl-pds\">'</span></span>]: [length]\n        }\n\n        (\n            output\n        ) <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._session.run([\n            <span class=\"pl-c1\">self</span>._prediction\n        ],\n            <span class=\"pl-v\">feed_dict</span> <span class=\"pl-k\">=</span> feed_dict\n        )\n\n        <span class=\"pl-k\">return</span> output</pre></div>\n<h3>Error Desciption</h3>\n<p>It is ok to build tfGraph. But I get into trouble when calling Model.predict().<br>\nIf the beam_width is set as 1, the program can normally run. And it raise the following error when the beam_width is set as 2.</p>\n<pre><code>  File \"/home/runke/lxtest/algorithm/algorithm/estimation/get_earnings.py\", line 347, in _prediction\n    output_layer=self._output_projection_layer\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 193, in __init__\n    initial_state, self._cell.state_size)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in &lt;listcomp&gt;\n    structure[0], [func(*x) for x in entries])\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 374, in _maybe_split_batch_beams\n    return self._split_batch_beams(t, s)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 339, in _split_batch_beams\n    ([self._batch_size, self._beam_width], t_shape[1:]), 0))\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\n    name=name)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 128 values, but the requested shape has 256\n         [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](encoder/rnn/while/Exit_2, concat)]]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\nTensorFlow installed from (source or binary): Pip Binary\nTensorFlow version (use command below): 1.2.1\nPython version: 3.4\n\nMy coustom code\nclass Model():\n'''\nA seq2seq model\nplaceholder: \n    encoder_input, a int32 tensor shaped [None, max_encoder_len]\n    encoder_length, a int32 tensor shaped [None]\n    decoder_input, a int32 tensor shaped [None, max_decoder_len]\ncell:\n    LSTMCell. cell.output_size = 128\n'''\n\n    # some irrespective code\n\n    @property\n    def _prediction(self):\n        with self._graph.as_default():\n            GO_SYMBOL = [500]\n            END_SYMBOL = 501\n\n            initial_state = self.encoder['final_state']\n\n            decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n                cell=self.cell,\n                embedding=lambda tokens:tf.nn.embedding_lookup(self._decoder_embedding, tokens),\n                start_tokens=GO_SYMBOL,\n                end_token=END_SYMBOL,\n                initial_state=initial_state,\n                beam_width=self._beam_size, # self._beam_size = 1 is ok \n                                            # but self._beam_size = 2 runs wrong\n                output_layer=self._output_projection_layer\n            )\n\n            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n                decoder=decoder,\n                maximum_iterations=self._max_decoder_len\n            )\n\n            return outputs.predicted_ids[:, :, 0]\n\n    # some irrespective code\n\n    def predict(self, word_list):\n        '''\n        Args:\n            word_list: [word0, word1...]. 1-dimentional array\n        return:\n            outputs: [o0, o1...]. 1-dimentional array\n                     where oi is word_index\n        '''\n        length = len(word_list)\n        word_index_list = preprocess.words_to_indices(word_list) # turn words to numbers\n        if len(word_index_list) < self._max_encoder_len:\n            word_index_list.extend([0] * (self._max_encoder_len - len(word_index_list)))\n\n        feed_dict = {\n            self.input_length['encoder_input']: [word_index_list],\n            self.input_length['encoder_length']: [length]\n        }\n\n        (\n            output\n        ) = self._session.run([\n            self._prediction\n        ],\n            feed_dict = feed_dict\n        )\n\n        return output\nError Desciption\nIt is ok to build tfGraph. But I get into trouble when calling Model.predict().\nIf the beam_width is set as 1, the program can normally run. And it raise the following error when the beam_width is set as 2.\n  File \"/home/runke/lxtest/algorithm/algorithm/estimation/get_earnings.py\", line 347, in _prediction\n    output_layer=self._output_projection_layer\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 193, in __init__\n    initial_state, self._cell.state_size)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 374, in _maybe_split_batch_beams\n    return self._split_batch_beams(t, s)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 339, in _split_batch_beams\n    ([self._batch_size, self._beam_width], t_shape[1:]), 0))\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\n    name=name)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 128 values, but the requested shape has 256\n         [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](encoder/rnn/while/Exit_2, concat)]]", "body": "### System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\r\n- TensorFlow installed from (source or binary): Pip Binary\r\n- TensorFlow version (use command below): 1.2.1\r\n- Python version: 3.4\r\n### My coustom code\r\n```python\r\nclass Model():\r\n'''\r\nA seq2seq model\r\nplaceholder: \r\n    encoder_input, a int32 tensor shaped [None, max_encoder_len]\r\n    encoder_length, a int32 tensor shaped [None]\r\n    decoder_input, a int32 tensor shaped [None, max_decoder_len]\r\ncell:\r\n    LSTMCell. cell.output_size = 128\r\n'''\r\n\r\n    # some irrespective code\r\n\r\n    @property\r\n    def _prediction(self):\r\n        with self._graph.as_default():\r\n            GO_SYMBOL = [500]\r\n            END_SYMBOL = 501\r\n\r\n            initial_state = self.encoder['final_state']\r\n\r\n            decoder = tf.contrib.seq2seq.BeamSearchDecoder(\r\n                cell=self.cell,\r\n                embedding=lambda tokens:tf.nn.embedding_lookup(self._decoder_embedding, tokens),\r\n                start_tokens=GO_SYMBOL,\r\n                end_token=END_SYMBOL,\r\n                initial_state=initial_state,\r\n                beam_width=self._beam_size, # self._beam_size = 1 is ok \r\n                                            # but self._beam_size = 2 runs wrong\r\n                output_layer=self._output_projection_layer\r\n            )\r\n\r\n            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\r\n                decoder=decoder,\r\n                maximum_iterations=self._max_decoder_len\r\n            )\r\n\r\n            return outputs.predicted_ids[:, :, 0]\r\n\r\n    # some irrespective code\r\n\r\n    def predict(self, word_list):\r\n        '''\r\n        Args:\r\n            word_list: [word0, word1...]. 1-dimentional array\r\n        return:\r\n            outputs: [o0, o1...]. 1-dimentional array\r\n                     where oi is word_index\r\n        '''\r\n        length = len(word_list)\r\n        word_index_list = preprocess.words_to_indices(word_list) # turn words to numbers\r\n        if len(word_index_list) < self._max_encoder_len:\r\n            word_index_list.extend([0] * (self._max_encoder_len - len(word_index_list)))\r\n\r\n        feed_dict = {\r\n            self.input_length['encoder_input']: [word_index_list],\r\n            self.input_length['encoder_length']: [length]\r\n        }\r\n\r\n        (\r\n            output\r\n        ) = self._session.run([\r\n            self._prediction\r\n        ],\r\n            feed_dict = feed_dict\r\n        )\r\n\r\n        return output\r\n```\r\n### Error Desciption\r\nIt is ok to build tfGraph. But I get into trouble when calling Model.predict().\r\nIf the beam_width is set as 1, the program can normally run. And it raise the following error when the beam_width is set as 2.\r\n```\r\n  File \"/home/runke/lxtest/algorithm/algorithm/estimation/get_earnings.py\", line 347, in _prediction\r\n    output_layer=self._output_projection_layer\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 193, in __init__\r\n    initial_state, self._cell.state_size)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in map_structure\r\n    structure[0], [func(*x) for x in entries])\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in <listcomp>\r\n    structure[0], [func(*x) for x in entries])\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 374, in _maybe_split_batch_beams\r\n    return self._split_batch_beams(t, s)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 339, in _split_batch_beams\r\n    ([self._batch_size, self._beam_width], t_shape[1:]), 0))\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\r\n    name=name)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 128 values, but the requested shape has 256\r\n         [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](encoder/rnn/while/Exit_2, concat)]]\r\n```"}