{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312410942", "html_url": "https://github.com/tensorflow/tensorflow/issues/11199#issuecomment-312410942", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11199", "id": 312410942, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjQxMDk0Mg==", "user": {"login": "printdhruv", "id": 17731159, "node_id": "MDQ6VXNlcjE3NzMxMTU5", "avatar_url": "https://avatars0.githubusercontent.com/u/17731159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/printdhruv", "html_url": "https://github.com/printdhruv", "followers_url": "https://api.github.com/users/printdhruv/followers", "following_url": "https://api.github.com/users/printdhruv/following{/other_user}", "gists_url": "https://api.github.com/users/printdhruv/gists{/gist_id}", "starred_url": "https://api.github.com/users/printdhruv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/printdhruv/subscriptions", "organizations_url": "https://api.github.com/users/printdhruv/orgs", "repos_url": "https://api.github.com/users/printdhruv/repos", "events_url": "https://api.github.com/users/printdhruv/events{/privacy}", "received_events_url": "https://api.github.com/users/printdhruv/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-01T05:03:16Z", "updated_at": "2017-07-01T05:03:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi,</p>\n<ol>\n<li>\n<p>It won't compile as you have <code>tensor-flow API 1.1.0</code> which doesn't have <code>tf.contrib.seq2seq.prepare_attention()</code> and the link which you are referring is for <code>API 1.0</code>.</p>\n</li>\n<li>\n<p>For your existing version <code>1.1.0</code> the <code> tf.contrib.seq2seq.DynamicAttentionWrapper</code> will work. Refer link <a href=\"https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper\" rel=\"nofollow\">https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper</a></p>\n</li>\n<li>\n<p>If you want to use your existing code than you have to upgrade your version of tensor flow by executing i.e. <code>pip3 install --upgrade tensorflow</code></p>\n</li>\n<li>\n<p>Please refer suggestions and guidelines listed here <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md\">link</a> before raising an issue.</p>\n</li>\n</ol>", "body_text": "Hi,\n\n\nIt won't compile as you have tensor-flow API 1.1.0 which doesn't have tf.contrib.seq2seq.prepare_attention() and the link which you are referring is for API 1.0.\n\n\nFor your existing version 1.1.0 the  tf.contrib.seq2seq.DynamicAttentionWrapper will work. Refer link https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper\n\n\nIf you want to use your existing code than you have to upgrade your version of tensor flow by executing i.e. pip3 install --upgrade tensorflow\n\n\nPlease refer suggestions and guidelines listed here link before raising an issue.", "body": "Hi,\r\n\r\n1. It won't compile as you have `tensor-flow API 1.1.0` which doesn't have `tf.contrib.seq2seq.prepare_attention()` and the link which you are referring is for `API 1.0`.\r\n\r\n2. For your existing version `1.1.0` the ` tf.contrib.seq2seq.DynamicAttentionWrapper` will work. Refer link [https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/seq2seq/DynamicAttentionWrapper)\r\n\r\n3. If you want to use your existing code than you have to upgrade your version of tensor flow by executing i.e. `pip3 install --upgrade tensorflow`\r\n \r\n4. Please refer suggestions and guidelines listed here [link](https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md) before raising an issue."}