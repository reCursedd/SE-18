{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23295", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23295/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23295/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23295/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23295", "id": 374338540, "node_id": "MDU6SXNzdWUzNzQzMzg1NDA=", "number": 23295, "title": "[Keras tensorflow] float16 doesn't work with conv2d ?", "user": {"login": "NitroBAY", "id": 9869317, "node_id": "MDQ6VXNlcjk4NjkzMTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/9869317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NitroBAY", "html_url": "https://github.com/NitroBAY", "followers_url": "https://api.github.com/users/NitroBAY/followers", "following_url": "https://api.github.com/users/NitroBAY/following{/other_user}", "gists_url": "https://api.github.com/users/NitroBAY/gists{/gist_id}", "starred_url": "https://api.github.com/users/NitroBAY/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NitroBAY/subscriptions", "organizations_url": "https://api.github.com/users/NitroBAY/orgs", "repos_url": "https://api.github.com/users/NitroBAY/repos", "events_url": "https://api.github.com/users/NitroBAY/events{/privacy}", "received_events_url": "https://api.github.com/users/NitroBAY/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097546578, "node_id": "MDU6TGFiZWwxMDk3NTQ2NTc4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:keras", "name": "comp:keras", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-10-26T11:16:19Z", "updated_at": "2018-11-20T07:51:20Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello,<br>\nI have a rtx card to use RT cores (dedicated for NN, uses half-precision to my understanding) I'd like using float16 so I :</p>\n<pre><code>from tensorflow.keras import backend\nos.environ['KERAS_FLOATX'] = 'float16'\nos.environ['TF_FP16_CONV_USE_FP32_COMPUTE'] = '0'\nbackend.set_floatx('float16')\n</code></pre>\n<p>but this triggers error :<br>\nmodel = Sequential([<br>\nConv2D(32, kernel_size=(5, 5), input_shape=(32, 32, 3), strides=(1, 1))<br>\n])<br>\nmodel.compile(optimizer=Adam(), loss='mse')</p>\n<p>Traceback (most recent call last):<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 510, in _apply_op_helper<br>\npreferred_dtype=default_dtype)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1107, in internal_convert_to_tensor<br>\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 944, in _TensorTensorConversionFunction<br>\n(dtype.name, t.dtype.name, str(t)))<br>\nValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(\"conv2d_sample_weights:0\", shape=(?,), dtype=float32)'</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"float16.py\", line 17, in <br>\ninit()<br>\nFile \"float16.py\", line 15, in init<br>\nmodel.compile(optimizer=Adam(), loss='mse')<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 442, in compile<br>\noutput_loss = weighted_loss(y_true, y_pred, sample_weight, mask)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\", line 453, in weighted<br>\nscore_array *= weights<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 847, in binary_op_wrapper<br>\nreturn func(x, y, name=name)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1091, in _mul_dispatch<br>\nreturn gen_math_ops.mul(x, y, name=name)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4758, in mul<br>\n\"Mul\", x=x, y=y, name=name)<br>\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 546, in _apply_op_helper<br>\ninferred_from[input_arg.type_attr]))<br>\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.</p>\n<p>I'm not a professional I'm a newbie to NN so excuse me if my question is not relevant.</p>", "body_text": "Hello,\nI have a rtx card to use RT cores (dedicated for NN, uses half-precision to my understanding) I'd like using float16 so I :\nfrom tensorflow.keras import backend\nos.environ['KERAS_FLOATX'] = 'float16'\nos.environ['TF_FP16_CONV_USE_FP32_COMPUTE'] = '0'\nbackend.set_floatx('float16')\n\nbut this triggers error :\nmodel = Sequential([\nConv2D(32, kernel_size=(5, 5), input_shape=(32, 32, 3), strides=(1, 1))\n])\nmodel.compile(optimizer=Adam(), loss='mse')\nTraceback (most recent call last):\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 510, in _apply_op_helper\npreferred_dtype=default_dtype)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1107, in internal_convert_to_tensor\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 944, in _TensorTensorConversionFunction\n(dtype.name, t.dtype.name, str(t)))\nValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(\"conv2d_sample_weights:0\", shape=(?,), dtype=float32)'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"float16.py\", line 17, in \ninit()\nFile \"float16.py\", line 15, in init\nmodel.compile(optimizer=Adam(), loss='mse')\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 442, in compile\noutput_loss = weighted_loss(y_true, y_pred, sample_weight, mask)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\", line 453, in weighted\nscore_array *= weights\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 847, in binary_op_wrapper\nreturn func(x, y, name=name)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1091, in _mul_dispatch\nreturn gen_math_ops.mul(x, y, name=name)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4758, in mul\n\"Mul\", x=x, y=y, name=name)\nFile \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 546, in _apply_op_helper\ninferred_from[input_arg.type_attr]))\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\nI'm not a professional I'm a newbie to NN so excuse me if my question is not relevant.", "body": "Hello,\r\nI have a rtx card to use RT cores (dedicated for NN, uses half-precision to my understanding) I'd like using float16 so I : \r\n\r\n    from tensorflow.keras import backend\r\n    os.environ['KERAS_FLOATX'] = 'float16'\r\n    os.environ['TF_FP16_CONV_USE_FP32_COMPUTE'] = '0'\r\n    backend.set_floatx('float16')\r\n\r\nbut this triggers error : \r\n   model = Sequential([\r\n        Conv2D(32, kernel_size=(5, 5), input_shape=(32, 32, 3), strides=(1, 1))\r\n    ])\r\n    model.compile(optimizer=Adam(), loss='mse')\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1107, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 944, in _TensorTensorConversionFunction\r\n    (dtype.name, t.dtype.name, str(t)))\r\nValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(\"conv2d_sample_weights:0\", shape=(?,), dtype=float32)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"float16.py\", line 17, in <module>\r\n    init()\r\n  File \"float16.py\", line 15, in init\r\n    model.compile(optimizer=Adam(), loss='mse')\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 442, in compile\r\n    output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\", line 453, in weighted\r\n    score_array *= weights\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 847, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1091, in _mul_dispatch\r\n    return gen_math_ops.mul(x, y, name=name)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4758, in mul\r\n    \"Mul\", x=x, y=y, name=name)\r\n  File \"C:\\Users\\xd111\\Miniconda3\\envs\\evo\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 546, in _apply_op_helper\r\n    inferred_from[input_arg.type_attr]))\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n\r\nI'm not a professional I'm a newbie to NN so excuse me if my question is not relevant.\r\n\r\n"}