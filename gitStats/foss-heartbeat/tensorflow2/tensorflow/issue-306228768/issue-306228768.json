{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17804", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17804/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17804/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17804/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17804", "id": 306228768, "node_id": "MDU6SXNzdWUzMDYyMjg3Njg=", "number": 17804, "title": "How to read `feature_lists` from tfrecord.", "user": {"login": "TechBK", "id": 8995895, "node_id": "MDQ6VXNlcjg5OTU4OTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8995895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TechBK", "html_url": "https://github.com/TechBK", "followers_url": "https://api.github.com/users/TechBK/followers", "following_url": "https://api.github.com/users/TechBK/following{/other_user}", "gists_url": "https://api.github.com/users/TechBK/gists{/gist_id}", "starred_url": "https://api.github.com/users/TechBK/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TechBK/subscriptions", "organizations_url": "https://api.github.com/users/TechBK/orgs", "repos_url": "https://api.github.com/users/TechBK/repos", "events_url": "https://api.github.com/users/TechBK/events{/privacy}", "received_events_url": "https://api.github.com/users/TechBK/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-03-18T10:29:24Z", "updated_at": "2018-04-02T23:22:15Z", "closed_at": "2018-04-02T23:22:15Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: 17.10</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc2-20-g0787eee 1.3.0</li>\n<li><strong>Python version</strong>: 3.6.2</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I save idex of chars to tfrecords, but i cant know how to read it.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">make_example</span>(<span class=\"pl-smi\">words</span>, <span class=\"pl-smi\">chars</span>, <span class=\"pl-smi\">labels</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> print(chars)</span>\n    ex <span class=\"pl-k\">=</span> tf.train.SequenceExample()\n    ex.context.feature[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>len<span class=\"pl-pds\">\"</span></span>].int64_list.value.append(<span class=\"pl-c1\">len</span>(words))\n\n    <span class=\"pl-k\">for</span> w, char_of_a_word, l <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(words, chars, labels):\n        ex.feature_lists.feature_list[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>words<span class=\"pl-pds\">\"</span></span>].feature.add().int64_list.value.append(w)\n        ex.feature_lists.feature_list[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>label<span class=\"pl-pds\">\"</span></span>].feature.add().int64_list.value.append(l)\n\n        chars_feature <span class=\"pl-k\">=</span> ex.feature_lists.feature_list[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars<span class=\"pl-pds\">\"</span></span>].feature.add()\n        <span class=\"pl-k\">for</span> c <span class=\"pl-k\">in</span> char_of_a_word:\n            chars_feature.int64_list.value.append(c)\n\n    <span class=\"pl-k\">return</span> ex</pre></div>\n<p><code>words</code> is a list of indexing, example: <code>[1, 2, 3]</code><br>\n<code>chars</code> is list of character indexing, example: <code>[[1,2,3], [2], [2,3,4]]</code></p>\n<p>Parsing function:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">_parse_function</span>(<span class=\"pl-smi\">example_proto</span>):\n    context_features <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>len<span class=\"pl-pds\">\"</span></span>: tf.FixedLenFeature((), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64),\n    }\n    sequence_features <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>words<span class=\"pl-pds\">\"</span></span>: tf.FixedLenSequenceFeature((), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars<span class=\"pl-pds\">\"</span></span>: tf.FixedLenSequenceFeature((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">35</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>label<span class=\"pl-pds\">\"</span></span>: tf.FixedLenSequenceFeature((), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64),\n    }\n\n    context_parsed, sequence_parsed <span class=\"pl-k\">=</span> tf.parse_single_sequence_example(\n        <span class=\"pl-v\">serialized</span><span class=\"pl-k\">=</span>example_proto,\n        <span class=\"pl-v\">context_features</span><span class=\"pl-k\">=</span>context_features,\n        <span class=\"pl-v\">sequence_features</span><span class=\"pl-k\">=</span>sequence_features\n    )\n\n    len_ <span class=\"pl-k\">=</span> tf.cast(context_parsed[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>len<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\n    word <span class=\"pl-k\">=</span> tf.cast(sequence_parsed[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>words<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\n    chars <span class=\"pl-k\">=</span> tf.cast(sequence_parsed[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>chars<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>word.shape<span class=\"pl-pds\">\"</span></span>, word.shape)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars.shape<span class=\"pl-pds\">\"</span></span>, chars.shape)\n    label <span class=\"pl-k\">=</span> tf.cast(sequence_parsed[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>label<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\n\n    <span class=\"pl-k\">return</span> {<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>words<span class=\"pl-pds\">\"</span></span>: word, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars<span class=\"pl-pds\">\"</span></span>: chars, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>len<span class=\"pl-pds\">\"</span></span>: len_}, label</pre></div>\n<p>Input function:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">inputs</span>(<span class=\"pl-smi\">file_names</span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">num_epochs</span>):\n    dataset <span class=\"pl-k\">=</span> tf.contrib.data.TFRecordDataset(file_names)\n    dataset <span class=\"pl-k\">=</span> dataset.map(_parse_function)\n    dataset <span class=\"pl-k\">=</span> dataset.padded_batch(<span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size,\n                                   <span class=\"pl-v\">padded_shapes</span><span class=\"pl-k\">=</span>({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>word<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-c1\">None</span>], <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-c1\">None</span>], <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>len<span class=\"pl-pds\">\"</span></span>: []}, [<span class=\"pl-c1\">None</span>]),\n                                   <span class=\"pl-v\">padding_values</span><span class=\"pl-k\">=</span>(\n                                       {<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>word<span class=\"pl-pds\">\"</span></span>: word_lookup.idx_of_pad,\n                                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>chars<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-c1\">0</span>,\n                                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>len<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-c1\">0</span>}, <span class=\"pl-c1\">0</span>))\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> dataset = dataset.filter(lambda f, l: tf.equal(tf.shape(l)[0], batch_size))</span>\n    dataset <span class=\"pl-k\">=</span> dataset.repeat(num_epochs)\n    iterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\n    features, label <span class=\"pl-k\">=</span> iterator.get_next()\n    <span class=\"pl-k\">return</span> features, label</pre></div>\n<p>Error log:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\n    pydev_imports.execfile(file, globals, locals)  # execute the script\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 62, in &lt;module&gt;\n    _result = inputs_test(['/home/binhnq/hitelli/WordSegmentation/data/test-ws.tfrecords', ])\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 55, in inputs_test\n    \"features\": features}, n=1)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\n    return func(*args, **kwargs)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 644, in run_n\n    restore_checkpoint_path=restore_checkpoint_path)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\n    return func(*args, **kwargs)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 702, in run_feeds\n    return list(run_feeds_iter(*args, **kwargs))\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 692, in run_feeds_iter\n    yield session.run(output_dict, f)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: chars, Index: 1.  Number of int64 values != expected.  values size: 2 but output shape: [1]\n\t [[Node: ParseSingleSequenceExample/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=3, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[1], [], []], feature_list_dense_types=[DT_INT64, DT_INT64, DT_INT64], feature_list_sparse_types=[]](arg0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_1, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_2, ParseSingleSequenceExample/Const, ParseSingleSequenceExample/ParseSingleSequenceExample/debug_name)]]\n</code></pre>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 17.10\nTensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: 3.6.2\n\nDescribe the problem\nI save idex of chars to tfrecords, but i cant know how to read it.\nSource code / logs\ndef make_example(words, chars, labels):\n    # print(chars)\n    ex = tf.train.SequenceExample()\n    ex.context.feature[\"len\"].int64_list.value.append(len(words))\n\n    for w, char_of_a_word, l in zip(words, chars, labels):\n        ex.feature_lists.feature_list[\"words\"].feature.add().int64_list.value.append(w)\n        ex.feature_lists.feature_list[\"label\"].feature.add().int64_list.value.append(l)\n\n        chars_feature = ex.feature_lists.feature_list[\"chars\"].feature.add()\n        for c in char_of_a_word:\n            chars_feature.int64_list.value.append(c)\n\n    return ex\nwords is a list of indexing, example: [1, 2, 3]\nchars is list of character indexing, example: [[1,2,3], [2], [2,3,4]]\nParsing function:\ndef _parse_function(example_proto):\n    context_features = {\n        \"len\": tf.FixedLenFeature((), dtype=tf.int64),\n    }\n    sequence_features = {\n        \"words\": tf.FixedLenSequenceFeature((), dtype=tf.int64),\n        \"chars\": tf.FixedLenSequenceFeature((1,35), dtype=tf.int64),\n        \"label\": tf.FixedLenSequenceFeature((), dtype=tf.int64),\n    }\n\n    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n        serialized=example_proto,\n        context_features=context_features,\n        sequence_features=sequence_features\n    )\n\n    len_ = tf.cast(context_parsed['len'], dtype=tf.int32)\n    word = tf.cast(sequence_parsed['words'], dtype=tf.int32)\n    chars = tf.cast(sequence_parsed['chars'], dtype=tf.int32)\n    print(\"word.shape\", word.shape)\n    print(\"chars.shape\", chars.shape)\n    label = tf.cast(sequence_parsed['label'], dtype=tf.int32)\n\n    return {\"words\": word, \"chars\": chars, \"len\": len_}, label\nInput function:\ndef inputs(file_names, batch_size, num_epochs):\n    dataset = tf.contrib.data.TFRecordDataset(file_names)\n    dataset = dataset.map(_parse_function)\n    dataset = dataset.padded_batch(batch_size=batch_size,\n                                   padded_shapes=({\"word\": [None], \"chars\": [None], \"len\": []}, [None]),\n                                   padding_values=(\n                                       {\"word\": word_lookup.idx_of_pad,\n                                        \"chars\": 0,\n                                        \"len\": 0}, 0))\n    # dataset = dataset.filter(lambda f, l: tf.equal(tf.shape(l)[0], batch_size))\n    dataset = dataset.repeat(num_epochs)\n    iterator = dataset.make_one_shot_iterator()\n    features, label = iterator.get_next()\n    return features, label\nError log:\nTraceback (most recent call last):\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\n    pydev_imports.execfile(file, globals, locals)  # execute the script\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 62, in <module>\n    _result = inputs_test(['/home/binhnq/hitelli/WordSegmentation/data/test-ws.tfrecords', ])\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 55, in inputs_test\n    \"features\": features}, n=1)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\n    return func(*args, **kwargs)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 644, in run_n\n    restore_checkpoint_path=restore_checkpoint_path)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\n    return func(*args, **kwargs)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 702, in run_feeds\n    return list(run_feeds_iter(*args, **kwargs))\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 692, in run_feeds_iter\n    yield session.run(output_dict, f)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: chars, Index: 1.  Number of int64 values != expected.  values size: 2 but output shape: [1]\n\t [[Node: ParseSingleSequenceExample/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=3, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[1], [], []], feature_list_dense_types=[DT_INT64, DT_INT64, DT_INT64], feature_list_sparse_types=[]](arg0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_1, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_2, ParseSingleSequenceExample/Const, ParseSingleSequenceExample/ParseSingleSequenceExample/debug_name)]]", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.10\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.6.2\r\n### Describe the problem\r\nI save idex of chars to tfrecords, but i cant know how to read it.\r\n\r\n### Source code / logs\r\n```python\r\ndef make_example(words, chars, labels):\r\n    # print(chars)\r\n    ex = tf.train.SequenceExample()\r\n    ex.context.feature[\"len\"].int64_list.value.append(len(words))\r\n\r\n    for w, char_of_a_word, l in zip(words, chars, labels):\r\n        ex.feature_lists.feature_list[\"words\"].feature.add().int64_list.value.append(w)\r\n        ex.feature_lists.feature_list[\"label\"].feature.add().int64_list.value.append(l)\r\n\r\n        chars_feature = ex.feature_lists.feature_list[\"chars\"].feature.add()\r\n        for c in char_of_a_word:\r\n            chars_feature.int64_list.value.append(c)\r\n\r\n    return ex\r\n```\r\n`words` is a list of indexing, example: `[1, 2, 3]`\r\n`chars` is list of character indexing, example: `[[1,2,3], [2], [2,3,4]]`\r\n\r\nParsing function:\r\n```python\r\ndef _parse_function(example_proto):\r\n    context_features = {\r\n        \"len\": tf.FixedLenFeature((), dtype=tf.int64),\r\n    }\r\n    sequence_features = {\r\n        \"words\": tf.FixedLenSequenceFeature((), dtype=tf.int64),\r\n        \"chars\": tf.FixedLenSequenceFeature((1,35), dtype=tf.int64),\r\n        \"label\": tf.FixedLenSequenceFeature((), dtype=tf.int64),\r\n    }\r\n\r\n    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\r\n        serialized=example_proto,\r\n        context_features=context_features,\r\n        sequence_features=sequence_features\r\n    )\r\n\r\n    len_ = tf.cast(context_parsed['len'], dtype=tf.int32)\r\n    word = tf.cast(sequence_parsed['words'], dtype=tf.int32)\r\n    chars = tf.cast(sequence_parsed['chars'], dtype=tf.int32)\r\n    print(\"word.shape\", word.shape)\r\n    print(\"chars.shape\", chars.shape)\r\n    label = tf.cast(sequence_parsed['label'], dtype=tf.int32)\r\n\r\n    return {\"words\": word, \"chars\": chars, \"len\": len_}, label\r\n```\r\n\r\nInput function:\r\n```python\r\ndef inputs(file_names, batch_size, num_epochs):\r\n    dataset = tf.contrib.data.TFRecordDataset(file_names)\r\n    dataset = dataset.map(_parse_function)\r\n    dataset = dataset.padded_batch(batch_size=batch_size,\r\n                                   padded_shapes=({\"word\": [None], \"chars\": [None], \"len\": []}, [None]),\r\n                                   padding_values=(\r\n                                       {\"word\": word_lookup.idx_of_pad,\r\n                                        \"chars\": 0,\r\n                                        \"len\": 0}, 0))\r\n    # dataset = dataset.filter(lambda f, l: tf.equal(tf.shape(l)[0], batch_size))\r\n    dataset = dataset.repeat(num_epochs)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    features, label = iterator.get_next()\r\n    return features, label\r\n```\r\n\r\nError log:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 62, in <module>\r\n    _result = inputs_test(['/home/binhnq/hitelli/WordSegmentation/data/test-ws.tfrecords', ])\r\n  File \"/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py\", line 55, in inputs_test\r\n    \"features\": features}, n=1)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 644, in run_n\r\n    restore_checkpoint_path=restore_checkpoint_path)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 128, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 702, in run_feeds\r\n    return list(run_feeds_iter(*args, **kwargs))\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 692, in run_feeds_iter\r\n    yield session.run(output_dict, f)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: chars, Index: 1.  Number of int64 values != expected.  values size: 2 but output shape: [1]\r\n\t [[Node: ParseSingleSequenceExample/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=3, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[1], [], []], feature_list_dense_types=[DT_INT64, DT_INT64, DT_INT64], feature_list_sparse_types=[]](arg0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_1, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_2, ParseSingleSequenceExample/Const, ParseSingleSequenceExample/ParseSingleSequenceExample/debug_name)]]\r\n```"}