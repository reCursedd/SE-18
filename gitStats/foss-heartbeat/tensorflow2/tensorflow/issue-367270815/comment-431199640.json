{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/431199640", "html_url": "https://github.com/tensorflow/tensorflow/issues/22769#issuecomment-431199640", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22769", "id": 431199640, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTE5OTY0MA==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-18T23:43:36Z", "updated_at": "2018-10-18T23:43:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21358816\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lenassero\">@lenassero</a> My understanding is that <code>alignment_history</code> is integrated into seq2seq model with attention,<br>\n<code>tf.contrib.seq2seq.BahdanauAttention</code> to be specific in this case. Therefore it would impact the output of <code>tf.contrib.seq2seq.AttentionWrapper</code> which is supposed to be the alignments for each step.</p>", "body_text": "@lenassero My understanding is that alignment_history is integrated into seq2seq model with attention,\ntf.contrib.seq2seq.BahdanauAttention to be specific in this case. Therefore it would impact the output of tf.contrib.seq2seq.AttentionWrapper which is supposed to be the alignments for each step.", "body": "@lenassero My understanding is that `alignment_history` is integrated into seq2seq model with attention, \r\n`tf.contrib.seq2seq.BahdanauAttention` to be specific in this case. Therefore it would impact the output of `tf.contrib.seq2seq.AttentionWrapper` which is supposed to be the alignments for each step."}