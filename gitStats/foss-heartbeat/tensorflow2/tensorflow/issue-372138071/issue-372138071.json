{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23113", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23113/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23113/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23113/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23113", "id": 372138071, "node_id": "MDU6SXNzdWUzNzIxMzgwNzE=", "number": 23113, "title": "testing tflite quantized model on an input image", "user": {"login": "sumeetssaurav", "id": 13672595, "node_id": "MDQ6VXNlcjEzNjcyNTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/13672595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sumeetssaurav", "html_url": "https://github.com/sumeetssaurav", "followers_url": "https://api.github.com/users/sumeetssaurav/followers", "following_url": "https://api.github.com/users/sumeetssaurav/following{/other_user}", "gists_url": "https://api.github.com/users/sumeetssaurav/gists{/gist_id}", "starred_url": "https://api.github.com/users/sumeetssaurav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sumeetssaurav/subscriptions", "organizations_url": "https://api.github.com/users/sumeetssaurav/orgs", "repos_url": "https://api.github.com/users/sumeetssaurav/repos", "events_url": "https://api.github.com/users/sumeetssaurav/events{/privacy}", "received_events_url": "https://api.github.com/users/sumeetssaurav/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-19T22:39:08Z", "updated_at": "2018-11-02T20:19:35Z", "closed_at": "2018-11-02T20:19:35Z", "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No</li>\n<li>TensorFlow installed from (source or binary): Binary</li>\n<li>TensorFlow version (use command below): tf_nightly</li>\n<li>Python version:  3.5.2</li>\n<li>Bazel version (if compiling from source): NA</li>\n<li>GCC/Compiler version (if compiling from source):  5.4.0</li>\n<li>CUDA/cuDNN version: 9.0/7.1</li>\n<li>GPU model and memory: GeFORCE 1080 Ti and 12 GB</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p><strong>Describe the current behavior</strong></p>\n<p><strong>Describe the expected behavior</strong></p>\n<p><strong>Code to reproduce the issue</strong><br>\nNA</p>\n<p><strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>\n<p>`import numpy as np<br>\nimport tensorflow as tf<br>\nimport pathlib<br>\nimport cv2<br>\nfrom keras.preprocessing import image<br>\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions<br>\nimg_path = 'elephant.jpg'<br>\nimg = image.load_img(img_path, target_size=(299, 299))</p>\n<p>x = image.img_to_array(img)<br>\ninput_data = np.expand_dims(x, axis=0)</p>\n<p>#print(input_data.type)<br>\n#x = preprocess_input(x)</p>\n<p>archive_path = tf.keras.utils.get_file(\"resnet_v2_101.tgz\", \"<a href=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz\" rel=\"nofollow\">https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz</a>\", extract=True)<br>\narchive_path = pathlib.Path(archive_path)<br>\narchive_dir = str(archive_path.parent)<br>\nprint(archive_dir)</p>\n<p>graph_def_file = pathlib.Path(archive_path).parent/\"resnet_v2_101_299_frozen.pb\"<br>\ninput_arrays = [\"input\"]<br>\noutput_arrays = [\"output\"]</p>\n<p>converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(<br>\nstr(graph_def_file), input_arrays, output_arrays, input_shapes={\"input\":[1,299,299,3]})</p>\n<p>converter.post_training_quantize = False<br>\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101.tflite\"<br>\nresnet_tflite_file.write_bytes(converter.convert())</p>\n<p>converter.post_training_quantize = True<br>\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101_quantized.tflite\"<br>\nresnet_tflite_file.write_bytes(converter.convert())</p>\n<p>#!ls -lh {archive_dir}/*.tflite</p>\n<h1>Load TFLite model and allocate tensors.</h1>\n<p>interpreter = tf.contrib.lite.Interpreter(model_path=\"/home/sumeet/.keras/datasets/resnet_v2_101_quantized.tflite\")<br>\ninterpreter.allocate_tensors()</p>\n<h1>Get input and output tensors.</h1>\n<p>input_index= interpreter.get_input_details()<br>\nprint(input_index)<br>\n#output_details = interpreter.get_output_details()<br>\noutput_index = interpreter.get_output_details()<br>\nprint(output_index)</p>\n<h1>Test model on random input data.</h1>\n<p>input_shape = input_index[0]['shape']<br>\n#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)<br>\n#input_data = np.array(X(input_shape), dtype=np.float32)<br>\ninterpreter.set_tensor(input_index[0]['index'],input_data)</p>\n<p>interpreter.invoke()<br>\npredictions = interpreter.get_tensor(output_index[0]['index'])<br>\npredictions[0]['name']<br>\nprint(predictions[0,0])<br>\n#print('Predicted:', decode_predictions(predictions, top=3)[0])`</p>\n<p>How to make predictions on a custom input image like the code given below<br>\nfrom keras.applications.resnet50 import ResNet50<br>\nfrom keras.preprocessing import image<br>\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions<br>\nimport numpy as np</p>\n<p>model = ResNet50(weights='imagenet')</p>\n<p>img_path = 'elephant.jpg'<br>\nimg = image.load_img(img_path, target_size=(224, 224))<br>\nx = image.img_to_array(img)<br>\nx = np.expand_dims(x, axis=0)<br>\nx = preprocess_input(x)</p>\n<p>preds = model.predict(x)<br>\nprint(preds.shape)</p>\n<h1>decode the results into a list of tuples (class, description, probability)</h1>\n<h1>(one such list for each sample in the batch)</h1>\n<p>print('Predicted:', decode_predictions(preds, top=3)[0])</p>\n<h1>Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)</h1>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): tf_nightly\nPython version:  3.5.2\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source):  5.4.0\nCUDA/cuDNN version: 9.0/7.1\nGPU model and memory: GeFORCE 1080 Ti and 12 GB\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the current behavior\nDescribe the expected behavior\nCode to reproduce the issue\nNA\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\n`import numpy as np\nimport tensorflow as tf\nimport pathlib\nimport cv2\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(299, 299))\nx = image.img_to_array(img)\ninput_data = np.expand_dims(x, axis=0)\n#print(input_data.type)\n#x = preprocess_input(x)\narchive_path = tf.keras.utils.get_file(\"resnet_v2_101.tgz\", \"https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz\", extract=True)\narchive_path = pathlib.Path(archive_path)\narchive_dir = str(archive_path.parent)\nprint(archive_dir)\ngraph_def_file = pathlib.Path(archive_path).parent/\"resnet_v2_101_299_frozen.pb\"\ninput_arrays = [\"input\"]\noutput_arrays = [\"output\"]\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\nstr(graph_def_file), input_arrays, output_arrays, input_shapes={\"input\":[1,299,299,3]})\nconverter.post_training_quantize = False\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101.tflite\"\nresnet_tflite_file.write_bytes(converter.convert())\nconverter.post_training_quantize = True\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101_quantized.tflite\"\nresnet_tflite_file.write_bytes(converter.convert())\n#!ls -lh {archive_dir}/*.tflite\nLoad TFLite model and allocate tensors.\ninterpreter = tf.contrib.lite.Interpreter(model_path=\"/home/sumeet/.keras/datasets/resnet_v2_101_quantized.tflite\")\ninterpreter.allocate_tensors()\nGet input and output tensors.\ninput_index= interpreter.get_input_details()\nprint(input_index)\n#output_details = interpreter.get_output_details()\noutput_index = interpreter.get_output_details()\nprint(output_index)\nTest model on random input data.\ninput_shape = input_index[0]['shape']\n#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n#input_data = np.array(X(input_shape), dtype=np.float32)\ninterpreter.set_tensor(input_index[0]['index'],input_data)\ninterpreter.invoke()\npredictions = interpreter.get_tensor(output_index[0]['index'])\npredictions[0]['name']\nprint(predictions[0,0])\n#print('Predicted:', decode_predictions(predictions, top=3)[0])`\nHow to make predictions on a custom input image like the code given below\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\nmodel = ResNet50(weights='imagenet')\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\nprint(preds.shape)\ndecode the results into a list of tuples (class, description, probability)\n(one such list for each sample in the batch)\nprint('Predicted:', decode_predictions(preds, top=3)[0])\nPredicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): tf_nightly\r\n- Python version:  3.5.2\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source):  5.4.0\r\n- CUDA/cuDNN version: 9.0/7.1\r\n- GPU model and memory: GeFORCE 1080 Ti and 12 GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\n NA\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n`import numpy as np\r\nimport tensorflow as tf\r\nimport pathlib\r\nimport cv2\r\nfrom keras.preprocessing import image\r\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\r\nimg_path = 'elephant.jpg'\r\nimg = image.load_img(img_path, target_size=(299, 299))\r\n\r\nx = image.img_to_array(img)\r\ninput_data = np.expand_dims(x, axis=0)\r\n\r\n#print(input_data.type)\r\n#x = preprocess_input(x)\r\n\r\narchive_path = tf.keras.utils.get_file(\"resnet_v2_101.tgz\", \"https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz\", extract=True)\r\narchive_path = pathlib.Path(archive_path)\r\narchive_dir = str(archive_path.parent)\r\nprint(archive_dir)\r\n\r\n\r\ngraph_def_file = pathlib.Path(archive_path).parent/\"resnet_v2_101_299_frozen.pb\"\r\ninput_arrays = [\"input\"] \r\noutput_arrays = [\"output\"]\r\n\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\r\n  str(graph_def_file), input_arrays, output_arrays, input_shapes={\"input\":[1,299,299,3]})\r\n\r\nconverter.post_training_quantize = False\r\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101.tflite\"\r\nresnet_tflite_file.write_bytes(converter.convert())\r\n\r\n\r\nconverter.post_training_quantize = True\r\nresnet_tflite_file = graph_def_file.parent/\"resnet_v2_101_quantized.tflite\"\r\nresnet_tflite_file.write_bytes(converter.convert())\r\n\r\n\r\n#!ls -lh {archive_dir}/*.tflite\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.contrib.lite.Interpreter(model_path=\"/home/sumeet/.keras/datasets/resnet_v2_101_quantized.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_index= interpreter.get_input_details()\r\nprint(input_index)\r\n#output_details = interpreter.get_output_details()\r\noutput_index = interpreter.get_output_details()\r\nprint(output_index)\r\n\r\n# Test model on random input data.\r\ninput_shape = input_index[0]['shape']\r\n#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n#input_data = np.array(X(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_index[0]['index'],input_data)\r\n\r\ninterpreter.invoke()\r\npredictions = interpreter.get_tensor(output_index[0]['index'])\r\npredictions[0]['name']\r\nprint(predictions[0,0])\r\n#print('Predicted:', decode_predictions(predictions, top=3)[0])`\r\n\r\n\r\n\r\nHow to make predictions on a custom input image like the code given below\r\nfrom keras.applications.resnet50 import ResNet50\r\nfrom keras.preprocessing import image\r\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\r\nimport numpy as np\r\n\r\nmodel = ResNet50(weights='imagenet')\r\n\r\nimg_path = 'elephant.jpg'\r\nimg = image.load_img(img_path, target_size=(224, 224))\r\nx = image.img_to_array(img)\r\nx = np.expand_dims(x, axis=0)\r\nx = preprocess_input(x)\r\n\r\npreds = model.predict(x)\r\nprint(preds.shape)\r\n# decode the results into a list of tuples (class, description, probability)\r\n# (one such list for each sample in the batch)\r\nprint('Predicted:', decode_predictions(preds, top=3)[0])\r\n# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)\r\n"}