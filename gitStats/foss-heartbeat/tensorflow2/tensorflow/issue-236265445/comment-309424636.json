{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309424636", "html_url": "https://github.com/tensorflow/tensorflow/issues/10739#issuecomment-309424636", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10739", "id": 309424636, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTQyNDYzNg==", "user": {"login": "rajnamitha", "id": 13020727, "node_id": "MDQ6VXNlcjEzMDIwNzI3", "avatar_url": "https://avatars1.githubusercontent.com/u/13020727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajnamitha", "html_url": "https://github.com/rajnamitha", "followers_url": "https://api.github.com/users/rajnamitha/followers", "following_url": "https://api.github.com/users/rajnamitha/following{/other_user}", "gists_url": "https://api.github.com/users/rajnamitha/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajnamitha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajnamitha/subscriptions", "organizations_url": "https://api.github.com/users/rajnamitha/orgs", "repos_url": "https://api.github.com/users/rajnamitha/repos", "events_url": "https://api.github.com/users/rajnamitha/events{/privacy}", "received_events_url": "https://api.github.com/users/rajnamitha/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-19T12:26:42Z", "updated_at": "2017-06-19T12:29:40Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=161459\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/petewarden\">@petewarden</a> The error was common across other inception models that I tried (i.e. Inception V3 and Inception V4) even for those models I got similar error as above:</p>\n<pre><code>File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 312, in import_graph_def\nop_def=op_def)\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2528, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1203, in init\nself._traceback = self._graph._extract_stack() # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): requested_output_max must be &gt;= requested_output_min, but got nan and 0\n[[Node: InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:1, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:2, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range:1)]]\n\n</code></pre>\n<p>However, I tried the solution you gave. i.e.  using:<br>\nquantize_nodes(fallback_min=-10, fallback_max=10)</p>\n<p>graph that is generated, the inference runs without error but the results is totally inaccurate results (0% accuracy). The results are very similar that I get when I remove \"quantize_nodes\" from \"transforms\".</p>\n<p>This behavior is same also for inceptionV3 and inceptionV4 as that for inception_resnet_v2.</p>", "body_text": "@petewarden The error was common across other inception models that I tried (i.e. Inception V3 and Inception V4) even for those models I got similar error as above:\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 312, in import_graph_def\nop_def=op_def)\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2528, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1203, in init\nself._traceback = self._graph._extract_stack() # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): requested_output_max must be >= requested_output_min, but got nan and 0\n[[Node: InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:1, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:2, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range:1)]]\n\n\nHowever, I tried the solution you gave. i.e.  using:\nquantize_nodes(fallback_min=-10, fallback_max=10)\ngraph that is generated, the inference runs without error but the results is totally inaccurate results (0% accuracy). The results are very similar that I get when I remove \"quantize_nodes\" from \"transforms\".\nThis behavior is same also for inceptionV3 and inceptionV4 as that for inception_resnet_v2.", "body": "@petewarden The error was common across other inception models that I tried (i.e. Inception V3 and Inception V4) even for those models I got similar error as above: \r\n\r\n\r\n```\r\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 312, in import_graph_def\r\nop_def=op_def)\r\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2528, in create_op\r\noriginal_op=self._default_original_op, op_def=op_def)\r\nFile \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1203, in init\r\nself._traceback = self._graph._extract_stack() # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): requested_output_max must be >= requested_output_min, but got nan and 0\r\n[[Node: InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:1, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit:2, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range, InceptionResnetV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/batchnorm/mul_1/eightbit/requant_range:1)]]\r\n\r\n```\r\nHowever, I tried the solution you gave. i.e.  using: \r\nquantize_nodes(fallback_min=-10, fallback_max=10)\r\n\r\ngraph that is generated, the inference runs without error but the results is totally inaccurate results (0% accuracy). The results are very similar that I get when I remove \"quantize_nodes\" from \"transforms\".\r\n\r\nThis behavior is same also for inceptionV3 and inceptionV4 as that for inception_resnet_v2.\r\n"}