{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17017", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17017/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17017/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17017/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17017", "id": 297230834, "node_id": "MDU6SXNzdWUyOTcyMzA4MzQ=", "number": 17017, "title": "Integration of \"Tensor Comprehensions\"?", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-14T20:15:59Z", "updated_at": "2018-03-27T17:11:32Z", "closed_at": "2018-02-23T08:30:11Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Not relevant</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Not relevant</li>\n<li><strong>TensorFlow version (use command below)</strong>: Not relevant</li>\n<li><strong>Python version</strong>: Not relevant</li>\n<li><strong>Bazel version (if compiling from source)</strong>: Not relevant</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Not relevant</li>\n<li><strong>CUDA/cuDNN version</strong>: Not relevant</li>\n<li><strong>GPU model and memory</strong>: Not relevant</li>\n<li><strong>Exact command to reproduce</strong>: Not relevant</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>FAIR just released an initial version of their <a href=\"https://research.fb.com/announcing-tensor-comprehensions/\" rel=\"nofollow\">Tensor Comprehension Framework</a> which I think is a really clever concept. The Tensor comprehension library allows to define functions with a syntax similar to einstein-notation and then compiles these functions into fast GPU code via evolutionary search. Is this something you would consider including into the core or would you rather favor an integration as a separate framework?</p>\n<p>Cheers,<br>\nPhil</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Not relevant\nTensorFlow installed from (source or binary): Not relevant\nTensorFlow version (use command below): Not relevant\nPython version: Not relevant\nBazel version (if compiling from source): Not relevant\nGCC/Compiler version (if compiling from source): Not relevant\nCUDA/cuDNN version: Not relevant\nGPU model and memory: Not relevant\nExact command to reproduce: Not relevant\n\nDescribe the problem\nFAIR just released an initial version of their Tensor Comprehension Framework which I think is a really clever concept. The Tensor comprehension library allows to define functions with a syntax similar to einstein-notation and then compiles these functions into fast GPU code via evolutionary search. Is this something you would consider including into the core or would you rather favor an integration as a separate framework?\nCheers,\nPhil", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Not relevant\r\n- **TensorFlow installed from (source or binary)**: Not relevant\r\n- **TensorFlow version (use command below)**: Not relevant\r\n- **Python version**: Not relevant\r\n- **Bazel version (if compiling from source)**: Not relevant\r\n- **GCC/Compiler version (if compiling from source)**: Not relevant\r\n- **CUDA/cuDNN version**: Not relevant\r\n- **GPU model and memory**: Not relevant\r\n- **Exact command to reproduce**: Not relevant\r\n\r\n### Describe the problem\r\nFAIR just released an initial version of their [Tensor Comprehension Framework](https://research.fb.com/announcing-tensor-comprehensions/) which I think is a really clever concept. The Tensor comprehension library allows to define functions with a syntax similar to einstein-notation and then compiles these functions into fast GPU code via evolutionary search. Is this something you would consider including into the core or would you rather favor an integration as a separate framework?\r\n\r\nCheers,\r\nPhil\r\n"}