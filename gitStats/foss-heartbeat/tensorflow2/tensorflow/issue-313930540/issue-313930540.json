{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18477", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18477/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18477/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18477/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18477", "id": 313930540, "node_id": "MDU6SXNzdWUzMTM5MzA1NDA=", "number": 18477, "title": "tf.gather's gradient fails on GPU in eager mode", "user": {"login": "ethereon", "id": 337985, "node_id": "MDQ6VXNlcjMzNzk4NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/337985?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethereon", "html_url": "https://github.com/ethereon", "followers_url": "https://api.github.com/users/ethereon/followers", "following_url": "https://api.github.com/users/ethereon/following{/other_user}", "gists_url": "https://api.github.com/users/ethereon/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethereon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethereon/subscriptions", "organizations_url": "https://api.github.com/users/ethereon/orgs", "repos_url": "https://api.github.com/users/ethereon/repos", "events_url": "https://api.github.com/users/ethereon/events{/privacy}", "received_events_url": "https://api.github.com/users/ethereon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-13T00:26:16Z", "updated_at": "2018-04-14T01:44:58Z", "closed_at": "2018-04-13T23:54:59Z", "author_association": "NONE", "body_html": "<p>Tested with TensorFlow v1.7.0 on Ubuntu 16.06.</p>\n<p>Consider the following contrived example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n\ntfe.enable_eager_execution()\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-k\">with</span> tfe.GradientTape() <span class=\"pl-k\">as</span> tape:\n        params <span class=\"pl-k\">=</span> tfe.Variable(tf.zeros((<span class=\"pl-c1\">1024</span>,)))\n        indices <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>))\n        output <span class=\"pl-k\">=</span> tf.reduce_sum(tf.gather(params, indices))\n    <span class=\"pl-c1\">print</span>(tape.gradient(output, [params]))</pre></div>\n<p>When executed, it fails with:</p>\n<pre><code>Tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Cast] name: ToInt32\n</code></pre>\n<p>This does not occur on the CPU.</p>\n<p>The issue can be fixed by removing the <code>to_int32</code> call and just changing the <code>out_types</code> to <code>int32</code> here in <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.7.0/tensorflow/python/ops/array_grad.py#L398-L399\">array_grad.py</a> as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>params_shape <span class=\"pl-k\">=</span> array_ops.shape(params, <span class=\"pl-v\">out_type</span><span class=\"pl-k\">=</span>ops.dtypes.int32) <span class=\"pl-c\"><span class=\"pl-c\">#</span> int64 -&gt; int32</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> params_shape = math_ops.to_int32(params_shape) [remove this line]</span></pre></div>", "body_text": "Tested with TensorFlow v1.7.0 on Ubuntu 16.06.\nConsider the following contrived example:\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nwith tf.device('/gpu:0'):\n    with tfe.GradientTape() as tape:\n        params = tfe.Variable(tf.zeros((1024,)))\n        indices = tf.constant(range(5))\n        output = tf.reduce_sum(tf.gather(params, indices))\n    print(tape.gradient(output, [params]))\nWhen executed, it fails with:\nTensorflow.python.framework.errors_impl.InvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Cast] name: ToInt32\n\nThis does not occur on the CPU.\nThe issue can be fixed by removing the to_int32 call and just changing the out_types to int32 here in array_grad.py as follows:\nparams_shape = array_ops.shape(params, out_type=ops.dtypes.int32) # int64 -> int32\n# params_shape = math_ops.to_int32(params_shape) [remove this line]", "body": "Tested with TensorFlow v1.7.0 on Ubuntu 16.06.\r\n\r\nConsider the following contrived example:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\nwith tf.device('/gpu:0'):\r\n    with tfe.GradientTape() as tape:\r\n        params = tfe.Variable(tf.zeros((1024,)))\r\n        indices = tf.constant(range(5))\r\n        output = tf.reduce_sum(tf.gather(params, indices))\r\n    print(tape.gradient(output, [params]))\r\n```\r\n\r\nWhen executed, it fails with:\r\n\r\n```\r\nTensorflow.python.framework.errors_impl.InvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Cast] name: ToInt32\r\n```\r\n\r\nThis does not occur on the CPU.\r\n\r\nThe issue can be fixed by removing the `to_int32` call and just changing the `out_types` to `int32` here in [array_grad.py](https://github.com/tensorflow/tensorflow/blob/v1.7.0/tensorflow/python/ops/array_grad.py#L398-L399) as follows:\r\n```python\r\nparams_shape = array_ops.shape(params, out_type=ops.dtypes.int32) # int64 -> int32\r\n# params_shape = math_ops.to_int32(params_shape) [remove this line]\r\n```"}