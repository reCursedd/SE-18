{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23182", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23182/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23182/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23182/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23182", "id": 372825024, "node_id": "MDU6SXNzdWUzNzI4MjUwMjQ=", "number": 23182, "title": "Different results got using different batch sizes (cannot fully fit into GPU memory therefore evaluating different batch each time)", "user": {"login": "ZisIsNotZis", "id": 6444018, "node_id": "MDQ6VXNlcjY0NDQwMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6444018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZisIsNotZis", "html_url": "https://github.com/ZisIsNotZis", "followers_url": "https://api.github.com/users/ZisIsNotZis/followers", "following_url": "https://api.github.com/users/ZisIsNotZis/following{/other_user}", "gists_url": "https://api.github.com/users/ZisIsNotZis/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZisIsNotZis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZisIsNotZis/subscriptions", "organizations_url": "https://api.github.com/users/ZisIsNotZis/orgs", "repos_url": "https://api.github.com/users/ZisIsNotZis/repos", "events_url": "https://api.github.com/users/ZisIsNotZis/events{/privacy}", "received_events_url": "https://api.github.com/users/ZisIsNotZis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097547538, "node_id": "MDU6TGFiZWwxMDk3NTQ3NTM4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:gpu", "name": "comp:gpu", "color": "0052cc", "default": false}, {"id": 1105108936, "node_id": "MDU6TGFiZWwxMTA1MTA4OTM2", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:model", "name": "comp:model", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-10-23T06:16:47Z", "updated_at": "2018-11-21T17:03:48Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code: <strong>Yes</strong></li>\n<li>OS Platform and Distribution: <strong>Linux Ubuntu 18.04.1</strong></li>\n<li>Mobile device: N/A</li>\n<li>TensorFlow installed from: <strong>binary, tensorflow-gpu from anaconda</strong></li>\n<li>TensorFlow version: <strong>b'unknown', 1.11.0</strong></li>\n<li>Python version: <strong>3.6.6</strong></li>\n<li>Bazel version: N/A</li>\n<li>GCC/Compiler version: N/A</li>\n<li>CUDA/cuDNN version: <strong>10.0, Driver Version: 410.66</strong></li>\n<li>GPU model and memory: <strong>TITAN Xp, 12195MiB</strong></li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI'm trying to batch evaluate MLP (with same structure but different parameter) on GPU. Since the whole batch is too big to fit into GPU memory, I have to create smaller batches from the whole batch. Since the size of whole batch is not divisible by the size of little batch, the last little batch will be smaller than usual. It turns out the results in the last small batch is way smaller than previous batches.</p>\n<p><strong>Describe the expected behavior</strong><br>\nThe result should be the same since batch size should not affect the result itself.</p>\n<p><strong>Exact command to reproduce</strong><br>\nPut any of the following examples in a <code>jupyter</code> cell, and run it<br>\nPut any of the following examples in <code>xxx.py</code>, and run <code>python xxx.py</code> should also be fine</p>\n<p><strong>Code to reproduce the issue</strong><br>\nA small example:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nwith tf.Session():\n    x = tf.Variable(np.random.rand(43, 60000).astype('f2'))\n    w = tf.Variable(np.ones((58624, 43), 'f2'))\n    b = tf.Variable(np.ones((58624, 1), 'f2'))\n    v1 = w @ x + b\n    w = tf.Variable(np.ones((5376, 43), 'f2'))\n    b = tf.Variable(np.ones((5376, 1), 'f2'))\n    v2 = w @ x + b\n    tf.global_variables_initializer().run()\n    print(v1.eval(), v2.eval()) # they should have the same value while they dont\n</code></pre>\n<p>The actual example:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nwith tf.Session():\n    x = tf.Variable(np.ones((43, 60000), 'f2'))\n    y = tf.Variable(np.ones((8, 60000), 'f2'))\n    w = tf.Variable(np.ones((916* 64, 43), 'f2'))\n    b = tf.Variable(np.ones((916* 64, 1), 'f2'))\n    v = tf.Variable(np.ones((916, 8, 64), 'f2'))\n    c = tf.Variable(np.ones((916, 8, 1), 'f2'))\n    r = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(916,64,60000))+c,'float32'),axis=(1,2))# prevent overflow\n    w = tf.Variable(np.ones((84* 64, 43), 'f2'))\n    b = tf.Variable(np.ones((84* 64, 1), 'f2'))\n    v = tf.Variable(np.ones((84, 8, 64), 'f2'))\n    c = tf.Variable(np.ones((84, 8, 1), 'f2'))\n    R = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(84,64,60000))+c,'float32'),axis=(1,2)) # prevent overflow\n    tf.global_variables_initializer().run()\n    print(r.eval()[::100], R.eval()[::10]) # summary, they should have the same value while they dont\n</code></pre>\n<p><strong>Other info / logs</strong><br>\nI created a stack overflow question (<a href=\"https://stackoverflow.com/questions/52921884/tensorflow-result-inconsistent-across-batch-size\" rel=\"nofollow\">https://stackoverflow.com/questions/52921884/tensorflow-result-inconsistent-across-batch-size</a>) but since no body solved the problem, I submitted an issue here. It seems that this problem does not occur with small batches, it sometimes is not stably reproducible</p>", "body_text": "System information\n\nHave I written custom code: Yes\nOS Platform and Distribution: Linux Ubuntu 18.04.1\nMobile device: N/A\nTensorFlow installed from: binary, tensorflow-gpu from anaconda\nTensorFlow version: b'unknown', 1.11.0\nPython version: 3.6.6\nBazel version: N/A\nGCC/Compiler version: N/A\nCUDA/cuDNN version: 10.0, Driver Version: 410.66\nGPU model and memory: TITAN Xp, 12195MiB\n\nDescribe the current behavior\nI'm trying to batch evaluate MLP (with same structure but different parameter) on GPU. Since the whole batch is too big to fit into GPU memory, I have to create smaller batches from the whole batch. Since the size of whole batch is not divisible by the size of little batch, the last little batch will be smaller than usual. It turns out the results in the last small batch is way smaller than previous batches.\nDescribe the expected behavior\nThe result should be the same since batch size should not affect the result itself.\nExact command to reproduce\nPut any of the following examples in a jupyter cell, and run it\nPut any of the following examples in xxx.py, and run python xxx.py should also be fine\nCode to reproduce the issue\nA small example:\nimport tensorflow as tf\nimport numpy as np\nwith tf.Session():\n    x = tf.Variable(np.random.rand(43, 60000).astype('f2'))\n    w = tf.Variable(np.ones((58624, 43), 'f2'))\n    b = tf.Variable(np.ones((58624, 1), 'f2'))\n    v1 = w @ x + b\n    w = tf.Variable(np.ones((5376, 43), 'f2'))\n    b = tf.Variable(np.ones((5376, 1), 'f2'))\n    v2 = w @ x + b\n    tf.global_variables_initializer().run()\n    print(v1.eval(), v2.eval()) # they should have the same value while they dont\n\nThe actual example:\nimport tensorflow as tf\nimport numpy as np\nwith tf.Session():\n    x = tf.Variable(np.ones((43, 60000), 'f2'))\n    y = tf.Variable(np.ones((8, 60000), 'f2'))\n    w = tf.Variable(np.ones((916* 64, 43), 'f2'))\n    b = tf.Variable(np.ones((916* 64, 1), 'f2'))\n    v = tf.Variable(np.ones((916, 8, 64), 'f2'))\n    c = tf.Variable(np.ones((916, 8, 1), 'f2'))\n    r = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(916,64,60000))+c,'float32'),axis=(1,2))# prevent overflow\n    w = tf.Variable(np.ones((84* 64, 43), 'f2'))\n    b = tf.Variable(np.ones((84* 64, 1), 'f2'))\n    v = tf.Variable(np.ones((84, 8, 64), 'f2'))\n    c = tf.Variable(np.ones((84, 8, 1), 'f2'))\n    R = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(84,64,60000))+c,'float32'),axis=(1,2)) # prevent overflow\n    tf.global_variables_initializer().run()\n    print(r.eval()[::100], R.eval()[::10]) # summary, they should have the same value while they dont\n\nOther info / logs\nI created a stack overflow question (https://stackoverflow.com/questions/52921884/tensorflow-result-inconsistent-across-batch-size) but since no body solved the problem, I submitted an issue here. It seems that this problem does not occur with small batches, it sometimes is not stably reproducible", "body": "**System information**\r\n- Have I written custom code: **Yes**\r\n- OS Platform and Distribution: **Linux Ubuntu 18.04.1** \r\n- Mobile device: N/A\r\n- TensorFlow installed from: **binary, tensorflow-gpu from anaconda**\r\n- TensorFlow version: **b'unknown', 1.11.0**\r\n- Python version: **3.6.6**\r\n- Bazel version: N/A\r\n- GCC/Compiler version: N/A\r\n- CUDA/cuDNN version: **10.0, Driver Version: 410.66**\r\n- GPU model and memory: **TITAN Xp, 12195MiB**\r\n\r\n**Describe the current behavior**\r\nI'm trying to batch evaluate MLP (with same structure but different parameter) on GPU. Since the whole batch is too big to fit into GPU memory, I have to create smaller batches from the whole batch. Since the size of whole batch is not divisible by the size of little batch, the last little batch will be smaller than usual. It turns out the results in the last small batch is way smaller than previous batches.\r\n\r\n**Describe the expected behavior**\r\nThe result should be the same since batch size should not affect the result itself.\r\n\r\n**Exact command to reproduce**\r\nPut any of the following examples in a `jupyter` cell, and run it\r\nPut any of the following examples in `xxx.py`, and run `python xxx.py` should also be fine\r\n\r\n**Code to reproduce the issue**\r\nA small example:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    with tf.Session():\r\n        x = tf.Variable(np.random.rand(43, 60000).astype('f2'))\r\n        w = tf.Variable(np.ones((58624, 43), 'f2'))\r\n        b = tf.Variable(np.ones((58624, 1), 'f2'))\r\n        v1 = w @ x + b\r\n        w = tf.Variable(np.ones((5376, 43), 'f2'))\r\n        b = tf.Variable(np.ones((5376, 1), 'f2'))\r\n        v2 = w @ x + b\r\n        tf.global_variables_initializer().run()\r\n        print(v1.eval(), v2.eval()) # they should have the same value while they dont\r\n\r\nThe actual example:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    with tf.Session():\r\n        x = tf.Variable(np.ones((43, 60000), 'f2'))\r\n        y = tf.Variable(np.ones((8, 60000), 'f2'))\r\n        w = tf.Variable(np.ones((916* 64, 43), 'f2'))\r\n        b = tf.Variable(np.ones((916* 64, 1), 'f2'))\r\n        v = tf.Variable(np.ones((916, 8, 64), 'f2'))\r\n        c = tf.Variable(np.ones((916, 8, 1), 'f2'))\r\n        r = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(916,64,60000))+c,'float32'),axis=(1,2))# prevent overflow\r\n        w = tf.Variable(np.ones((84* 64, 43), 'f2'))\r\n        b = tf.Variable(np.ones((84* 64, 1), 'f2'))\r\n        v = tf.Variable(np.ones((84, 8, 64), 'f2'))\r\n        c = tf.Variable(np.ones((84, 8, 1), 'f2'))\r\n        R = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(84,64,60000))+c,'float32'),axis=(1,2)) # prevent overflow\r\n        tf.global_variables_initializer().run()\r\n        print(r.eval()[::100], R.eval()[::10]) # summary, they should have the same value while they dont\r\n\r\n**Other info / logs**\r\nI created a stack overflow question (https://stackoverflow.com/questions/52921884/tensorflow-result-inconsistent-across-batch-size) but since no body solved the problem, I submitted an issue here. It seems that this problem does not occur with small batches, it sometimes is not stably reproducible "}