{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23553", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23553/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23553/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23553/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23553", "id": 377835034, "node_id": "MDU6SXNzdWUzNzc4MzUwMzQ=", "number": 23553, "title": "Relationships between Grappler, GraphOptimizer and GraphOptimizationPass", "user": {"login": "wangsiyu", "id": 5387343, "node_id": "MDQ6VXNlcjUzODczNDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5387343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wangsiyu", "html_url": "https://github.com/wangsiyu", "followers_url": "https://api.github.com/users/wangsiyu/followers", "following_url": "https://api.github.com/users/wangsiyu/following{/other_user}", "gists_url": "https://api.github.com/users/wangsiyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wangsiyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wangsiyu/subscriptions", "organizations_url": "https://api.github.com/users/wangsiyu/orgs", "repos_url": "https://api.github.com/users/wangsiyu/repos", "events_url": "https://api.github.com/users/wangsiyu/events{/privacy}", "received_events_url": "https://api.github.com/users/wangsiyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097545273, "node_id": "MDU6TGFiZWwxMDk3NTQ1Mjcz", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:grappler", "name": "comp:grappler", "color": "0052cc", "default": false}, {"id": 1093464312, "node_id": "MDU6TGFiZWwxMDkzNDY0MzEy", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:others", "name": "type:others", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-11-06T12:57:39Z", "updated_at": "2018-11-23T18:37:44Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>There are so many graph optimization tools in TensorFlow Runtime such as <code>Grappler</code>, <code>GraphOptimizer</code> and <code>GraphOptimizationPass</code>. This makes me confused.  Is there any plan to unify these interfaces\uff1fCurrently, it seems that these optimizers could not replace with each other.</p>\n<p><code>Grappler</code> is very light weight because it does graph optimization on <code>GraphDef</code> .The limitation is that  these <code>optimizers</code> can only run after <code>Placer.run()</code>.  However,  some optimizers in <code>Grappler</code> will rewrite placement information. Therefore,  this will possibly cause some placement errors without the protection of <code>Placer</code>(Is it reasonable to  run <code>Placer</code> after running grappler?). Another, the <code>FeedBack</code> function is not being used in framework.</p>\n<p><code>GraphOptimizationPass</code> does optimization on <code>Graph</code> object. The advantage is that these optimizers can be specified with execution stage(PRE_PLACEMENT, POST_PLACEMENT......) .This is necessary. I think the execution stage of graph optimizers should be treated differently. Some optimizers should be done before placement and the other may be suitable for post partitioning and etc.</p>\n<p>As for <code>GraphOptimizer</code>, I heard that it will not be updated in the future.</p>\n<p>It will be nice to unify them and bring their strength together.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16824702\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/caisq\">@caisq</a></p>", "body_text": "There are so many graph optimization tools in TensorFlow Runtime such as Grappler, GraphOptimizer and GraphOptimizationPass. This makes me confused.  Is there any plan to unify these interfaces\uff1fCurrently, it seems that these optimizers could not replace with each other.\nGrappler is very light weight because it does graph optimization on GraphDef .The limitation is that  these optimizers can only run after Placer.run().  However,  some optimizers in Grappler will rewrite placement information. Therefore,  this will possibly cause some placement errors without the protection of Placer(Is it reasonable to  run Placer after running grappler?). Another, the FeedBack function is not being used in framework.\nGraphOptimizationPass does optimization on Graph object. The advantage is that these optimizers can be specified with execution stage(PRE_PLACEMENT, POST_PLACEMENT......) .This is necessary. I think the execution stage of graph optimizers should be treated differently. Some optimizers should be done before placement and the other may be suitable for post partitioning and etc.\nAs for GraphOptimizer, I heard that it will not be updated in the future.\nIt will be nice to unify them and bring their strength together.  @caisq", "body": "There are so many graph optimization tools in TensorFlow Runtime such as `Grappler`, `GraphOptimizer` and `GraphOptimizationPass`. This makes me confused.  Is there any plan to unify these interfaces\uff1fCurrently, it seems that these optimizers could not replace with each other.\r\n\r\n`Grappler` is very light weight because it does graph optimization on `GraphDef` .The limitation is that  these `optimizers` can only run after `Placer.run()`.  However,  some optimizers in `Grappler` will rewrite placement information. Therefore,  this will possibly cause some placement errors without the protection of `Placer`(Is it reasonable to  run `Placer` after running grappler?). Another, the `FeedBack` function is not being used in framework.\r\n\r\n`GraphOptimizationPass` does optimization on `Graph` object. The advantage is that these optimizers can be specified with execution stage(PRE_PLACEMENT, POST_PLACEMENT......) .This is necessary. I think the execution stage of graph optimizers should be treated differently. Some optimizers should be done before placement and the other may be suitable for post partitioning and etc. \r\n\r\nAs for `GraphOptimizer`, I heard that it will not be updated in the future. \r\n\r\nIt will be nice to unify them and bring their strength together.  @caisq "}