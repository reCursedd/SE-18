{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7702", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7702/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7702/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7702/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7702", "id": 208907463, "node_id": "MDU6SXNzdWUyMDg5MDc0NjM=", "number": 7702, "title": "dynamic_rnn_decoder returns shape [?, batch_size, cell.output_size]", "user": {"login": "jbingel", "id": 10550688, "node_id": "MDQ6VXNlcjEwNTUwNjg4", "avatar_url": "https://avatars2.githubusercontent.com/u/10550688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbingel", "html_url": "https://github.com/jbingel", "followers_url": "https://api.github.com/users/jbingel/followers", "following_url": "https://api.github.com/users/jbingel/following{/other_user}", "gists_url": "https://api.github.com/users/jbingel/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbingel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbingel/subscriptions", "organizations_url": "https://api.github.com/users/jbingel/orgs", "repos_url": "https://api.github.com/users/jbingel/repos", "events_url": "https://api.github.com/users/jbingel/events{/privacy}", "received_events_url": "https://api.github.com/users/jbingel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-02-20T15:12:53Z", "updated_at": "2018-09-09T16:37:53Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>According to <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder\" rel=\"nofollow\">the docs</a>,  the dynamic_rnn_decoder returns a tuple contaning <code>outputs</code>, which is a Tensor of shape <code>[max_time, batch_size, cell.output_size]</code>(provided <code>time_major==True</code>).</p>\n<p>In my case, however, the first dimension of that Tensor is returned as underspecified (Dimension <code>?</code>), and in fact depending on the provided batch when running the RNN.</p>\n<p>If this is the intended behaviour, it should probably be highlighted in the documentation that <code>max_time</code> is variable.</p>\n<p>Reproduce with:</p>\n<pre lang=\"import\" data-meta=\"tensorflow as tf\"><code>import numpy as np\n\n# toy data, timesteps between 1 and 10\ntimesteps = np.random.randint(1, 11, [10])\nX=np.random.randint(0, 20, [10,10,1])\n\nbatch_size = 2\nmax_ts = 10\ninputs = tf.placeholder(tf.float32, \n                        (max_ts, batch_size, 1), name=\"X_in\")\n\ncell_fw = tf.contrib.rnn.LSTMCell(50)\ncell_bw = tf.contrib.rnn.LSTMCell(50)\ncell_dec = tf.contrib.rnn.LSTMCell(50)\n\nseq_lens = tf.placeholder(tf.int32, batch_size, name=\"seq_lens\")\n\nenc_outputs, states = tf.nn.bidirectional_dynamic_rnn(\n    cell_fw, cell_bw, inputs, time_major=True, sequence_length=seq_lens, dtype=tf.float32)\n\ndecoder_inp = tf.concat(enc_outputs, axis=2) \n\nattention_states = tf.zeros([batch_size, 1, cell_dec.output_size],\n                                    name=\"attention_states\")\n\natt_keys, att_vals, att_score_fn, att_construct_fn = \\\n            tf.contrib.seq2seq.prepare_attention(attention_states,\n                                                 attention_option=\"luong\",\n                                                 num_units=50)\n\ndynamic_fn_train = tf.contrib.seq2seq.attention_decoder_fn_train(\n            states[0], att_keys, att_vals, att_score_fn, att_construct_fn)\n\noutputs, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n            cell_dec, dynamic_fn_train, decoder_inp, time_major=True,\n            sequence_length=seq_lens)\n\nwith tf.Session() as sess:\n    feed_dict = {inputs: X[:,:2,:], seq_lens: ts[:2]}\n    sess.run(tf.global_variables_initializer())\n    out = sess.run(outputs, feed_dict=feed_dict)\n    print(out.shape[0])\n</code></pre>\n<p>The very last print statement will show that the first output dimension is not max_ts, but the max timestep of the batch (&lt;= 10)</p>", "body_text": "According to the docs,  the dynamic_rnn_decoder returns a tuple contaning outputs, which is a Tensor of shape [max_time, batch_size, cell.output_size](provided time_major==True).\nIn my case, however, the first dimension of that Tensor is returned as underspecified (Dimension ?), and in fact depending on the provided batch when running the RNN.\nIf this is the intended behaviour, it should probably be highlighted in the documentation that max_time is variable.\nReproduce with:\nimport numpy as np\n\n# toy data, timesteps between 1 and 10\ntimesteps = np.random.randint(1, 11, [10])\nX=np.random.randint(0, 20, [10,10,1])\n\nbatch_size = 2\nmax_ts = 10\ninputs = tf.placeholder(tf.float32, \n                        (max_ts, batch_size, 1), name=\"X_in\")\n\ncell_fw = tf.contrib.rnn.LSTMCell(50)\ncell_bw = tf.contrib.rnn.LSTMCell(50)\ncell_dec = tf.contrib.rnn.LSTMCell(50)\n\nseq_lens = tf.placeholder(tf.int32, batch_size, name=\"seq_lens\")\n\nenc_outputs, states = tf.nn.bidirectional_dynamic_rnn(\n    cell_fw, cell_bw, inputs, time_major=True, sequence_length=seq_lens, dtype=tf.float32)\n\ndecoder_inp = tf.concat(enc_outputs, axis=2) \n\nattention_states = tf.zeros([batch_size, 1, cell_dec.output_size],\n                                    name=\"attention_states\")\n\natt_keys, att_vals, att_score_fn, att_construct_fn = \\\n            tf.contrib.seq2seq.prepare_attention(attention_states,\n                                                 attention_option=\"luong\",\n                                                 num_units=50)\n\ndynamic_fn_train = tf.contrib.seq2seq.attention_decoder_fn_train(\n            states[0], att_keys, att_vals, att_score_fn, att_construct_fn)\n\noutputs, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n            cell_dec, dynamic_fn_train, decoder_inp, time_major=True,\n            sequence_length=seq_lens)\n\nwith tf.Session() as sess:\n    feed_dict = {inputs: X[:,:2,:], seq_lens: ts[:2]}\n    sess.run(tf.global_variables_initializer())\n    out = sess.run(outputs, feed_dict=feed_dict)\n    print(out.shape[0])\n\nThe very last print statement will show that the first output dimension is not max_ts, but the max timestep of the batch (<= 10)", "body": "According to [the docs](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder),  the dynamic_rnn_decoder returns a tuple contaning `outputs`, which is a Tensor of shape `[max_time, batch_size, cell.output_size]`(provided `time_major==True`).\r\n\r\nIn my case, however, the first dimension of that Tensor is returned as underspecified (Dimension `?`), and in fact depending on the provided batch when running the RNN. \r\n\r\nIf this is the intended behaviour, it should probably be highlighted in the documentation that `max_time` is variable.\r\n\r\nReproduce with:\r\n\r\n```import tensorflow as tf\r\nimport numpy as np\r\n\r\n# toy data, timesteps between 1 and 10\r\ntimesteps = np.random.randint(1, 11, [10])\r\nX=np.random.randint(0, 20, [10,10,1])\r\n\r\nbatch_size = 2\r\nmax_ts = 10\r\ninputs = tf.placeholder(tf.float32, \r\n                        (max_ts, batch_size, 1), name=\"X_in\")\r\n\r\ncell_fw = tf.contrib.rnn.LSTMCell(50)\r\ncell_bw = tf.contrib.rnn.LSTMCell(50)\r\ncell_dec = tf.contrib.rnn.LSTMCell(50)\r\n\r\nseq_lens = tf.placeholder(tf.int32, batch_size, name=\"seq_lens\")\r\n\r\nenc_outputs, states = tf.nn.bidirectional_dynamic_rnn(\r\n    cell_fw, cell_bw, inputs, time_major=True, sequence_length=seq_lens, dtype=tf.float32)\r\n\r\ndecoder_inp = tf.concat(enc_outputs, axis=2) \r\n\r\nattention_states = tf.zeros([batch_size, 1, cell_dec.output_size],\r\n                                    name=\"attention_states\")\r\n\r\natt_keys, att_vals, att_score_fn, att_construct_fn = \\\r\n            tf.contrib.seq2seq.prepare_attention(attention_states,\r\n                                                 attention_option=\"luong\",\r\n                                                 num_units=50)\r\n\r\ndynamic_fn_train = tf.contrib.seq2seq.attention_decoder_fn_train(\r\n            states[0], att_keys, att_vals, att_score_fn, att_construct_fn)\r\n\r\noutputs, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\r\n            cell_dec, dynamic_fn_train, decoder_inp, time_major=True,\r\n            sequence_length=seq_lens)\r\n\r\nwith tf.Session() as sess:\r\n    feed_dict = {inputs: X[:,:2,:], seq_lens: ts[:2]}\r\n    sess.run(tf.global_variables_initializer())\r\n    out = sess.run(outputs, feed_dict=feed_dict)\r\n    print(out.shape[0])\r\n```\r\n\r\nThe very last print statement will show that the first output dimension is not max_ts, but the max timestep of the batch (<= 10)"}