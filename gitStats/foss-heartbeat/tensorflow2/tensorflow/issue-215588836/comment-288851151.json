{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288851151", "html_url": "https://github.com/tensorflow/tensorflow/issues/8569#issuecomment-288851151", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8569", "id": 288851151, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODg1MTE1MQ==", "user": {"login": "panyx0718", "id": 2887803, "node_id": "MDQ6VXNlcjI4ODc4MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2887803?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panyx0718", "html_url": "https://github.com/panyx0718", "followers_url": "https://api.github.com/users/panyx0718/followers", "following_url": "https://api.github.com/users/panyx0718/following{/other_user}", "gists_url": "https://api.github.com/users/panyx0718/gists{/gist_id}", "starred_url": "https://api.github.com/users/panyx0718/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panyx0718/subscriptions", "organizations_url": "https://api.github.com/users/panyx0718/orgs", "repos_url": "https://api.github.com/users/panyx0718/repos", "events_url": "https://api.github.com/users/panyx0718/events{/privacy}", "received_events_url": "https://api.github.com/users/panyx0718/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-23T20:33:06Z", "updated_at": "2017-03-23T20:33:33Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11547801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prb12\">@prb12</a> Thanks for the explanation.</p>\n<p>So looks like tfprof is tracking the MatMulOp::Compute(). It is actually the GPU kernel schedule time.<br>\nWhile the needed ones are the actually GPU execution time, which is in gpu:0/stream.</p>\n<p>Another place I found is in the compute_cost in cost_graph, which can be propagated to Python via the:<br>\nconfig = tf.ConfigProto(<br>\ngraph_options=tf.GraphOptions(build_cost_model=1))</p>", "body_text": "@prb12 Thanks for the explanation.\nSo looks like tfprof is tracking the MatMulOp::Compute(). It is actually the GPU kernel schedule time.\nWhile the needed ones are the actually GPU execution time, which is in gpu:0/stream.\nAnother place I found is in the compute_cost in cost_graph, which can be propagated to Python via the:\nconfig = tf.ConfigProto(\ngraph_options=tf.GraphOptions(build_cost_model=1))", "body": "@prb12 Thanks for the explanation.\r\n\r\nSo looks like tfprof is tracking the MatMulOp::Compute(). It is actually the GPU kernel schedule time.\r\nWhile the needed ones are the actually GPU execution time, which is in gpu:0/stream.\r\n\r\nAnother place I found is in the compute_cost in cost_graph, which can be propagated to Python via the:\r\n    config = tf.ConfigProto(\r\n        graph_options=tf.GraphOptions(build_cost_model=1))\r\n\r\n\r\n"}