{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429399021", "html_url": "https://github.com/tensorflow/tensorflow/issues/22854#issuecomment-429399021", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22854", "id": 429399021, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTM5OTAyMQ==", "user": {"login": "samikama", "id": 10539540, "node_id": "MDQ6VXNlcjEwNTM5NTQw", "avatar_url": "https://avatars0.githubusercontent.com/u/10539540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samikama", "html_url": "https://github.com/samikama", "followers_url": "https://api.github.com/users/samikama/followers", "following_url": "https://api.github.com/users/samikama/following{/other_user}", "gists_url": "https://api.github.com/users/samikama/gists{/gist_id}", "starred_url": "https://api.github.com/users/samikama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samikama/subscriptions", "organizations_url": "https://api.github.com/users/samikama/orgs", "repos_url": "https://api.github.com/users/samikama/repos", "events_url": "https://api.github.com/users/samikama/events{/privacy}", "received_events_url": "https://api.github.com/users/samikama/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T17:22:12Z", "updated_at": "2018-10-12T17:22:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4759327\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dhingratul\">@dhingratul</a>, are you running calib_to_infer_graph in the same process? if you exit the process between calibration and baking of the calibration? Also you need to pass graph that returned to you from trt.create_inference_graph() in the first step to calib_graph_to_infer_graph() in the third step not the graph from tf.train.write_graph(). You <em>need</em> to import it as graph to be able to run.</p>\n<ol>\n<li>create inference graph</li>\n<li>run it with calibration data</li>\n<li>pass the graph_def returned in 1 to calib_graph_to_infer_graph(). you can discard the graph you run in step 2, it is only used for collecting calibration data.</li>\n</ol>", "body_text": "@dhingratul, are you running calib_to_infer_graph in the same process? if you exit the process between calibration and baking of the calibration? Also you need to pass graph that returned to you from trt.create_inference_graph() in the first step to calib_graph_to_infer_graph() in the third step not the graph from tf.train.write_graph(). You need to import it as graph to be able to run.\n\ncreate inference graph\nrun it with calibration data\npass the graph_def returned in 1 to calib_graph_to_infer_graph(). you can discard the graph you run in step 2, it is only used for collecting calibration data.", "body": "@dhingratul, are you running calib_to_infer_graph in the same process? if you exit the process between calibration and baking of the calibration? Also you need to pass graph that returned to you from trt.create_inference_graph() in the first step to calib_graph_to_infer_graph() in the third step not the graph from tf.train.write_graph(). You *need* to import it as graph to be able to run. \r\n1. create inference graph\r\n2. run it with calibration data \r\n3. pass the graph_def returned in 1 to calib_graph_to_infer_graph(). you can discard the graph you run in step 2, it is only used for collecting calibration data."}