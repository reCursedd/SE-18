{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19144", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19144/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19144/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19144/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19144", "id": 321167362, "node_id": "MDU6SXNzdWUzMjExNjczNjI=", "number": 19144, "title": "TF 1.8 benchmark distributed run failed", "user": {"login": "boriskovalev", "id": 31654570, "node_id": "MDQ6VXNlcjMxNjU0NTcw", "avatar_url": "https://avatars1.githubusercontent.com/u/31654570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boriskovalev", "html_url": "https://github.com/boriskovalev", "followers_url": "https://api.github.com/users/boriskovalev/followers", "following_url": "https://api.github.com/users/boriskovalev/following{/other_user}", "gists_url": "https://api.github.com/users/boriskovalev/gists{/gist_id}", "starred_url": "https://api.github.com/users/boriskovalev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boriskovalev/subscriptions", "organizations_url": "https://api.github.com/users/boriskovalev/orgs", "repos_url": "https://api.github.com/users/boriskovalev/repos", "events_url": "https://api.github.com/users/boriskovalev/events{/privacy}", "received_events_url": "https://api.github.com/users/boriskovalev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-08T12:33:27Z", "updated_at": "2018-05-11T22:09:13Z", "closed_at": "2018-05-11T22:09:12Z", "author_association": "NONE", "body_html": "<p>System information</p>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nLinux Ubuntu 16.04<br>\nTensorFlow installed from source with verbs support<br>\nTensorFlow version:<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\n('v1.8.0-1-g8753e2e', '1.8.0')<br>\nPython version: 2.7<br>\nBazel version: 0.9 ,0.10<br>\nGCC/Compiler version: 5.4<br>\nCUDA/cuDNN version: 9.1 ,7.0<br>\nGPU model and memory: P100, 16GB<br>\nExact command to reproduce:</li>\n</ul>\n<p>On first node:<br>\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &amp;</p>\n<p>python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True</p>\n<p>On second node:<br>\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &amp;</p>\n<h1>python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True<br>\nProblem<br>\nI'm running benchmark ( master branch) on two hosts with error:<br>\n2018-05-08 14:55:30.598759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:<br>\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285<br>\npciBusID: 0000:04:00.0<br>\ntotalMemory: 15.90GiB freeMemory: 15.61GiB<br>\n2018-05-08 14:55:30.979461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:<br>\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285<br>\npciBusID: 0000:06:00.0<br>\ntotalMemory: 15.90GiB freeMemory: 15.61GiB<br>\n2018-05-08 14:55:31.325185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:<br>\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285<br>\npciBusID: 0000:07:00.0<br>\ntotalMemory: 15.90GiB freeMemory: 15.61GiB<br>\n2018-05-08 14:55:31.676291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties:<br>\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285<br>\npciBusID: 0000:08:00.0<br>\ntotalMemory: 15.90GiB freeMemory: 15.61GiB<br>\n2018-05-08 14:55:31.685309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3<br>\n2018-05-08 14:55:32.760916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:<br>\n2018-05-08 14:55:32.760978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3<br>\n2018-05-08 14:55:32.760986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y<br>\n2018-05-08 14:55:32.760991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y<br>\n2018-05-08 14:55:32.760997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y<br>\n2018-05-08 14:55:32.761002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N<br>\n2018-05-08 14:55:32.762303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 15133 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)<br>\n2018-05-08 14:55:33.097816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 15133 MB memory) -&gt; physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)<br>\n2018-05-08 14:55:33.431088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:2 with 15133 MB memory) -&gt; physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:07:00.0, compute capability: 6.0)<br>\n2018-05-08 14:55:33.735570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:3 with 15133 MB memory) -&gt; physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)<br>\n2018-05-08 14:55:34.010006: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; 11.11.11.47:10001, 1 -&gt; 11.11.11.48:10002}<br>\n2018-05-08 14:55:34.010056: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:20001, 1 -&gt; 11.11.11.48:20002}<br>\n2018-05-08 14:55:34.016202: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:332] Started server with target: grpc://localhost:20001<br>\nTensorFlow:  1.8<br>\nModel:       inception3<br>\nDataset:     imagenet (synthetic)<br>\nMode:        training<br>\nSingleSess:  False<br>\nBatch size:  128 global<br>\n64 per device<br>\nNum batches: 100<br>\nNum epochs:  0.01<br>\nDevices:     ['/job:worker/task:0/gpu:0']<br>\nData format: NCHW<br>\nLayout optimizer: False<br>\nOptimizer:   sgd<br>\nVariables:   distributed_replicated<br>\nSync:        True</h1>\n<p>Generating model<br>\nW0508 14:55:41.537986 139727489328896 tf_logging.py:126] From /root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1525: <strong>init</strong> (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.<br>\nInstructions for updating:<br>\nPlease switch to tf.train.MonitoredTrainingSession<br>\n2018-05-08 14:55:53.359721: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1<br>\n2018-05-08 14:56:00.360362: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error<br>\nI0508 14:56:00.440299 139727489328896 tf_logging.py:116] Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors_impl.UnavailableError'&gt;, OS Error<br>\nTraceback (most recent call last):<br>\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 60, in <br>\napp.run(main)  # Raises error on invalid flags, unlike tf.app.run()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 274, in run<br>\n_run_main(main, argv)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 238, in _run_main<br>\nsys.exit(main(argv))<br>\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 56, in main<br>\nbench.run()<br>\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1306, in run<br>\nreturn self._benchmark_cnn()<br>\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1535, in _benchmark_cnn<br>\nstart_standard_services=start_standard_services) as sess:<br>\nFile \"/usr/lib/python2.7/contextlib.py\", line 17, in <strong>enter</strong><br>\nreturn self.gen.next()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session<br>\nself.stop(close_summary_writer=close_summary_writer)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop<br>\nignore_live_threads=ignore_live_threads)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join<br>\nsix.reraise(*self._exc_info_to_raise)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 989, in managed_session<br>\nstart_standard_services=start_standard_services)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 726, in prepare_or_wait_for_session<br>\ninit_feed_dict=self._init_feed_dict, init_fn=self._init_fn)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 285, in prepare_session<br>\nsess.run(init_op, feed_dict=init_feed_dict)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run<br>\nrun_metadata)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.UnavailableError: OS Error</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nLinux Ubuntu 16.04\nTensorFlow installed from source with verbs support\nTensorFlow version:\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n('v1.8.0-1-g8753e2e', '1.8.0')\nPython version: 2.7\nBazel version: 0.9 ,0.10\nGCC/Compiler version: 5.4\nCUDA/cuDNN version: 9.1 ,7.0\nGPU model and memory: P100, 16GB\nExact command to reproduce:\n\nOn first node:\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &\npython ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True\nOn second node:\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &\npython ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True\nProblem\nI'm running benchmark ( master branch) on two hosts with error:\n2018-05-08 14:55:30.598759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:04:00.0\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\n2018-05-08 14:55:30.979461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:06:00.0\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\n2018-05-08 14:55:31.325185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:07:00.0\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\n2018-05-08 14:55:31.676291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties:\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:08:00.0\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\n2018-05-08 14:55:31.685309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\n2018-05-08 14:55:32.760916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-08 14:55:32.760978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3\n2018-05-08 14:55:32.760986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y\n2018-05-08 14:55:32.760991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y\n2018-05-08 14:55:32.760997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y\n2018-05-08 14:55:32.761002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N\n2018-05-08 14:55:32.762303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 15133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)\n2018-05-08 14:55:33.097816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 15133 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)\n2018-05-08 14:55:33.431088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:2 with 15133 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:07:00.0, compute capability: 6.0)\n2018-05-08 14:55:33.735570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:3 with 15133 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)\n2018-05-08 14:55:34.010006: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> 11.11.11.47:10001, 1 -> 11.11.11.48:10002}\n2018-05-08 14:55:34.010056: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20001, 1 -> 11.11.11.48:20002}\n2018-05-08 14:55:34.016202: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:332] Started server with target: grpc://localhost:20001\nTensorFlow:  1.8\nModel:       inception3\nDataset:     imagenet (synthetic)\nMode:        training\nSingleSess:  False\nBatch size:  128 global\n64 per device\nNum batches: 100\nNum epochs:  0.01\nDevices:     ['/job:worker/task:0/gpu:0']\nData format: NCHW\nLayout optimizer: False\nOptimizer:   sgd\nVariables:   distributed_replicated\nSync:        True\nGenerating model\nW0508 14:55:41.537986 139727489328896 tf_logging.py:126] From /root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1525: init (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease switch to tf.train.MonitoredTrainingSession\n2018-05-08 14:55:53.359721: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n2018-05-08 14:56:00.360362: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error\nI0508 14:56:00.440299 139727489328896 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnavailableError'>, OS Error\nTraceback (most recent call last):\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 60, in \napp.run(main)  # Raises error on invalid flags, unlike tf.app.run()\nFile \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 274, in run\n_run_main(main, argv)\nFile \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 238, in _run_main\nsys.exit(main(argv))\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 56, in main\nbench.run()\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1306, in run\nreturn self._benchmark_cnn()\nFile \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1535, in _benchmark_cnn\nstart_standard_services=start_standard_services) as sess:\nFile \"/usr/lib/python2.7/contextlib.py\", line 17, in enter\nreturn self.gen.next()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session\nself.stop(close_summary_writer=close_summary_writer)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop\nignore_live_threads=ignore_live_threads)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\nsix.reraise(*self._exc_info_to_raise)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 989, in managed_session\nstart_standard_services=start_standard_services)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 726, in prepare_or_wait_for_session\ninit_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 285, in prepare_session\nsess.run(init_op, feed_dict=init_feed_dict)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\nrun_metadata)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.UnavailableError: OS Error", "body": "System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nLinux Ubuntu 16.04\r\nTensorFlow installed from source with verbs support\r\nTensorFlow version:\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.8.0-1-g8753e2e', '1.8.0')\r\nPython version: 2.7 \r\nBazel version: 0.9 ,0.10\r\nGCC/Compiler version: 5.4\r\nCUDA/cuDNN version: 9.1 ,7.0\r\nGPU model and memory: P100, 16GB\r\nExact command to reproduce:\r\n\r\nOn first node:\r\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &\r\n\r\npython ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True\r\n\r\n\r\nOn second node:\r\nCUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &\r\n\r\npython ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True\r\nProblem\r\nI'm running benchmark ( master branch) on two hosts with error:\r\n2018-05-08 14:55:30.598759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\r\n2018-05-08 14:55:30.979461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:06:00.0\r\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\r\n2018-05-08 14:55:31.325185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:07:00.0\r\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\r\n2018-05-08 14:55:31.676291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:08:00.0\r\ntotalMemory: 15.90GiB freeMemory: 15.61GiB\r\n2018-05-08 14:55:31.685309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\r\n2018-05-08 14:55:32.760916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-08 14:55:32.760978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3 \r\n2018-05-08 14:55:32.760986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y \r\n2018-05-08 14:55:32.760991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y \r\n2018-05-08 14:55:32.760997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y \r\n2018-05-08 14:55:32.761002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N \r\n2018-05-08 14:55:32.762303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 15133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)\r\n2018-05-08 14:55:33.097816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 15133 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)\r\n2018-05-08 14:55:33.431088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:2 with 15133 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:07:00.0, compute capability: 6.0)\r\n2018-05-08 14:55:33.735570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:3 with 15133 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)\r\n2018-05-08 14:55:34.010006: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> 11.11.11.47:10001, 1 -> 11.11.11.48:10002}\r\n2018-05-08 14:55:34.010056: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20001, 1 -> 11.11.11.48:20002}\r\n2018-05-08 14:55:34.016202: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:332] Started server with target: grpc://localhost:20001\r\nTensorFlow:  1.8\r\nModel:       inception3\r\nDataset:     imagenet (synthetic)\r\nMode:        training\r\nSingleSess:  False\r\nBatch size:  128 global\r\n             64 per device\r\nNum batches: 100\r\nNum epochs:  0.01\r\nDevices:     ['/job:worker/task:0/gpu:0']\r\nData format: NCHW\r\nLayout optimizer: False\r\nOptimizer:   sgd\r\nVariables:   distributed_replicated\r\nSync:        True\r\n==========\r\nGenerating model\r\nW0508 14:55:41.537986 139727489328896 tf_logging.py:126] From /root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1525: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.MonitoredTrainingSession\r\n2018-05-08 14:55:53.359721: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\r\n2018-05-08 14:56:00.360362: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error\r\nI0508 14:56:00.440299 139727489328896 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnavailableError'>, OS Error\r\nTraceback (most recent call last):\r\n  File \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 60, in <module>\r\n    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 274, in run\r\n    _run_main(main, argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 238, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 56, in main\r\n    bench.run()\r\n  File \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1306, in run\r\n    return self._benchmark_cnn()\r\n  File \"/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1535, in _benchmark_cnn\r\n    start_standard_services=start_standard_services) as sess:\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 989, in managed_session\r\n    start_standard_services=start_standard_services)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 726, in prepare_or_wait_for_session\r\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 285, in prepare_session\r\n    sess.run(init_op, feed_dict=init_feed_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnavailableError: OS Error\r\n\r\n"}