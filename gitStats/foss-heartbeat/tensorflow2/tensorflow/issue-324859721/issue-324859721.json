{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19431", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19431/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19431/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19431/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19431", "id": 324859721, "node_id": "MDU6SXNzdWUzMjQ4NTk3MjE=", "number": 19431, "title": "TFLite toco failed to conver quantized model ( mobilenet_v1_1.0_224 ) to tflite format", "user": {"login": "cefengxu", "id": 11307973, "node_id": "MDQ6VXNlcjExMzA3OTcz", "avatar_url": "https://avatars2.githubusercontent.com/u/11307973?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cefengxu", "html_url": "https://github.com/cefengxu", "followers_url": "https://api.github.com/users/cefengxu/followers", "following_url": "https://api.github.com/users/cefengxu/following{/other_user}", "gists_url": "https://api.github.com/users/cefengxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/cefengxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cefengxu/subscriptions", "organizations_url": "https://api.github.com/users/cefengxu/orgs", "repos_url": "https://api.github.com/users/cefengxu/repos", "events_url": "https://api.github.com/users/cefengxu/events{/privacy}", "received_events_url": "https://api.github.com/users/cefengxu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-05-21T10:06:55Z", "updated_at": "2018-11-11T02:39:28Z", "closed_at": "2018-06-12T17:07:47Z", "author_association": "NONE", "body_html": "<h3>Describe the Problem</h3>\n<p>Firstly, I download the mobilenet_v1_1.0_224 model from ( <a href=\"http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz\" rel=\"nofollow\">http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz</a> ) ;</p>\n<p>Then, i used Command  belown to get a quantized model ( mobilenet_v1_1.0_224_frozen_quantized_graph.pb  ) successfully.</p>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph=/tmp /mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen.pb \\\n--inputs=\"input\" \\\n--outputs=\"MobilenetV1/Predictions/Reshape_1\" \\\n--out_graph=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\n--transforms='add_default_attributes strip_unused_nodes(type=float, shape=\"1,224,224,3\") \nremove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) \nfold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes \nstrip_unused_nodes sort_by_execution_order'\n</code></pre>\n<p>However , when I used TFLite toco Command to convert .pb to .lite format but ERROR was output</p>\n<h4>TFLite toco Build Command:</h4>\n<pre><code>bazel run --config=opt \\\n  //tensorflow/contrib/lite/toco:toco -- \\\n  --input_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\n  --output_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.lite \\\n  --input_format=TENSORFLOW_GRAPHDEF \\\n  --output_format=TFLITE \\\n  --input_shapes=1,224,224,3 \\\n  --mean_values=128 \\\n  --std_values=128 \\\n  --input_arrays=\"input\" \\\n  --output_arrays=\"MobilenetV1/Predictions/Reshape_1\" \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --default_ranges_min=0 \\\n  --default_ranges_max=6 \n\n</code></pre>\n<h4>ERROR OUTPUT:</h4>\n<pre><code>2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op-&gt;inputs[1]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[2]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\n</code></pre>\n<h4>ERROR LOG:</h4>\n<pre><code>: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedConv2D\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: RequantizationRange\n\u2026\u2026\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n2018-05-21 17:32:50.581333: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 352 operators, 853 arrays (0 quantized)\n2018-05-21 17:32:50.601042: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 352 operators, 853 arrays (0 quantized)\n2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op-&gt;inputs[1]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[2]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\n\n</code></pre>", "body_text": "Describe the Problem\nFirstly, I download the mobilenet_v1_1.0_224 model from ( http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz ) ;\nThen, i used Command  belown to get a quantized model ( mobilenet_v1_1.0_224_frozen_quantized_graph.pb  ) successfully.\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph=/tmp /mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen.pb \\\n--inputs=\"input\" \\\n--outputs=\"MobilenetV1/Predictions/Reshape_1\" \\\n--out_graph=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\n--transforms='add_default_attributes strip_unused_nodes(type=float, shape=\"1,224,224,3\") \nremove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) \nfold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes \nstrip_unused_nodes sort_by_execution_order'\n\nHowever , when I used TFLite toco Command to convert .pb to .lite format but ERROR was output\nTFLite toco Build Command:\nbazel run --config=opt \\\n  //tensorflow/contrib/lite/toco:toco -- \\\n  --input_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\n  --output_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.lite \\\n  --input_format=TENSORFLOW_GRAPHDEF \\\n  --output_format=TFLITE \\\n  --input_shapes=1,224,224,3 \\\n  --mean_values=128 \\\n  --std_values=128 \\\n  --input_arrays=\"input\" \\\n  --output_arrays=\"MobilenetV1/Predictions/Reshape_1\" \\\n  --inference_type=QUANTIZED_UINT8 \\\n  --default_ranges_min=0 \\\n  --default_ranges_max=6 \n\n\nERROR OUTPUT:\n2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\n\nERROR LOG:\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedConv2D\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: RequantizationRange\n\u2026\u2026\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\n2018-05-21 17:32:50.581333: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 352 operators, 853 arrays (0 quantized)\n2018-05-21 17:32:50.601042: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 352 operators, 853 arrays (0 quantized)\n2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.", "body": "### Describe the Problem\r\n\r\nFirstly, I download the mobilenet_v1_1.0_224 model from ( http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz ) ;\r\n\r\nThen, i used Command  belown to get a quantized model ( mobilenet_v1_1.0_224_frozen_quantized_graph.pb  ) successfully.\r\n\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=/tmp /mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen.pb \\\r\n--inputs=\"input\" \\\r\n--outputs=\"MobilenetV1/Predictions/Reshape_1\" \\\r\n--out_graph=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\r\n--transforms='add_default_attributes strip_unused_nodes(type=float, shape=\"1,224,224,3\") \r\nremove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) \r\nfold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes \r\nstrip_unused_nodes sort_by_execution_order'\r\n```\r\nHowever , when I used TFLite toco Command to convert .pb to .lite format but ERROR was output\r\n\r\n#### TFLite toco Build Command:\r\n\r\n```\r\nbazel run --config=opt \\\r\n  //tensorflow/contrib/lite/toco:toco -- \\\r\n  --input_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \\\r\n  --output_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.lite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --input_shapes=1,224,224,3 \\\r\n  --mean_values=128 \\\r\n  --std_values=128 \\\r\n  --input_arrays=\"input\" \\\r\n  --output_arrays=\"MobilenetV1/Predictions/Reshape_1\" \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6 \r\n\r\n```\r\n#### ERROR OUTPUT:\r\n```\r\n2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\n```\r\n\r\n#### ERROR LOG:\r\n\r\n```\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedConv2D\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: RequantizationRange\r\n\u2026\u2026\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape\r\n: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize\r\n2018-05-21 17:32:50.581333: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 352 operators, 853 arrays (0 quantized)\r\n2018-05-21 17:32:50.601042: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 352 operators, 853 arrays (0 quantized)\r\n2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\n\r\n```\r\n\r\n"}