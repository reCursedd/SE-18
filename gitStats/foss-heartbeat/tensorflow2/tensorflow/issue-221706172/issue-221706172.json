{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9205", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9205/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9205/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9205/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9205", "id": 221706172, "node_id": "MDU6SXNzdWUyMjE3MDYxNzI=", "number": 9205, "title": "Results are corrupted when running multiple sessions on one GPU ", "user": {"login": "dongwang218", "id": 169071, "node_id": "MDQ6VXNlcjE2OTA3MQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/169071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dongwang218", "html_url": "https://github.com/dongwang218", "followers_url": "https://api.github.com/users/dongwang218/followers", "following_url": "https://api.github.com/users/dongwang218/following{/other_user}", "gists_url": "https://api.github.com/users/dongwang218/gists{/gist_id}", "starred_url": "https://api.github.com/users/dongwang218/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dongwang218/subscriptions", "organizations_url": "https://api.github.com/users/dongwang218/orgs", "repos_url": "https://api.github.com/users/dongwang218/repos", "events_url": "https://api.github.com/users/dongwang218/events{/privacy}", "received_events_url": "https://api.github.com/users/dongwang218/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-04-13T23:16:32Z", "updated_at": "2018-06-25T18:19:11Z", "closed_at": "2017-06-02T20:39:05Z", "author_association": "NONE", "body_html": "<p>Tensorflow generates corrupted results when running two sessions concurrently on gpu. Each session has a separate graph.</p>\n<p>Code (thx to @bnoodle):</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom threading import Thread, Event\n\nsize = 10240\ndef myfunc(sess, name):\n  values = set()\n  count = 0\n  while True:\n    count += 1\n    v = sess.run(name + \"/matmul4:0\", feed_dict={name + \"/input:0\": np.ones((1,1))})\n    v = float(np.squeeze(v))\n    old = len(values)\n    values.add(v)\n    if len(values) != old:\n      print(values, name, count)\n\ndef create_graph(sess, name):\n  with sess.graph.as_default():\n    with tf.variable_scope(name):\n      input = tf.placeholder(tf.float32, shape=[1,1], name = \"input\")\n      tf.set_random_seed(1)\n\n      matrix1 = tf.Variable(tf.truncated_normal([1, size]), name = 'matrix1')\n      matrix2 = tf.Variable(tf.truncated_normal([size, size]), name = 'matrix2')\n      matrix4 = tf.Variable(tf.truncated_normal([size, 1]), name = 'matrix4')\n\n      matmul1 = tf.matmul(input, matrix1, name = 'matmul1')\n      matmul2 = tf.matmul(matmul1, matrix2, name = 'matmul2')\n      matmul4 = tf.matmul(matmul2, matrix4, name = \"matmul4\")\n      sess.run(tf.global_variables_initializer())\n\nsess1 = tf.Session()\nwith tf.device(\"/gpu:0\"):\n  create_graph(sess1, \"s1\")\n\nsess2 = tf.Session()\nwith tf.device(\"/gpu:0\"):\n  create_graph(sess2, \"s2\")\n\nt1 = Thread(target=myfunc, args=(sess1, 's1'))\nt1.start()\n\nt2 = Thread(target=myfunc, args=(sess2, 's2'))\nt2.start()\n</code></pre>\n<p>sess1 should output -17430.388671875, sess2 should output -968.17529296875. But the output sets are nondeterministically growing:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n((set([set([-968.17529296875]), 's2', 1-17430.388671875]))\n, 's1', 1)\n(set([-968.17529296875, -903.794921875]), 's2', 2)\n(set([-17430.388671875, -17302.84375]), 's1', 2)\n(set([-968.17529296875, -903.794921875, 2173.232177734375]), 's2', 511)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625]), 's2', 1723)\n(set([-17430.388671875, -17302.84375, -211.60272216796875]), 's1', 1961)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625, -30.6038818359375]), 's2', 2180)\n(set([-17430.388671875, -17302.84375, -1592.9022216796875, -211.60272216796875]), 's1', 2722)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, -287.991455078125, -30.6038818359375, 841.5855712890625]), 's2', 3337)\n...\n</code></pre>\n<p>Tensorflow serving has a similar corrupted results issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"210129732\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/serving/issues/335\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/serving/issues/335/hovercard\" href=\"https://github.com/tensorflow/serving/issues/335\">tensorflow/serving#335</a>, but this seems to be a tensorflow gpu memory problem. With <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> memory_util.py, it seems when sess1 and sess2 interleaving in memory allocation/deallocation and gpu memory address (the second to last column in the log) is reused, results will be corrupted. The shortest trace I found is</p>\n<pre><code>(set([-968.17529296875]), 's2', 1)\n('**************', 's2', 2)\n(set([-17430.388671875]), 's1', 1)\n('**************', 's1', 2)\n(set([-968.17529296875, -875.1435546875]), 's2', 2)\n       11                     s2/matmul1(44-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       23                     s1/matmul1(46-gpu_bfc)       40960       81920 gpu_bfc 30103375360 MemoryLogTensorAllocation\n       26                     s2/matmul2(47-gpu_bfc)       40960      122880 gpu_bfc 30103416320 MemoryLogTensorAllocation\n       28                     s2/matmul1(44-gpu_bfc)      -40960       81920 gpu_bfc -1 MemoryLogTensorDeallocation\n       31                     s2/matmul2(47-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       35                     s1/matmul2(49-gpu_bfc)       40960       81920 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       37                     s1/matmul1(46-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       40                     s1/matmul2(49-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n       61                     s2/matmul1(52-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       66                     s2/matmul2(53-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\n       71                     s2/matmul1(52-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       80                     s2/matmul2(53-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n       81                     s1/matmul1(56-gpu_bfc)       40960       40960 gpu_bfc 30103334912 MemoryLogTensorAllocation\n       85                     s1/matmul2(57-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\n       87                     s1/matmul1(56-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       90                     s1/matmul2(57-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n</code></pre>\n<h3>System Information</h3>\n<ul>\n<li><em>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?</em>: Yes</li>\n<li><em>OS Platform and Distribution (i.e. Linux Ubuntu 16.0)</em>: Ubuntu 14.04</li>\n<li><em>TensorFlow installed from (source or binary)?</em>: binary</li>\n<li><em>TensorFlow version</em> (use command below): 1.0.1</li>\n<li><em>Bazel version (if compiling from source)</em>:</li>\n<li><em>CUDA/cuDNN version</em>: cuda 8.0/cudnn5.1.5</li>\n<li><em>GPU Model and Memory</em>: GRID K520, 4GB</li>\n<li><em>Exact command to reproduce</em>: python multi_session.py</li>\n</ul>", "body_text": "Tensorflow generates corrupted results when running two sessions concurrently on gpu. Each session has a separate graph.\nCode (thx to @bnoodle):\nimport tensorflow as tf\nimport numpy as np\nfrom threading import Thread, Event\n\nsize = 10240\ndef myfunc(sess, name):\n  values = set()\n  count = 0\n  while True:\n    count += 1\n    v = sess.run(name + \"/matmul4:0\", feed_dict={name + \"/input:0\": np.ones((1,1))})\n    v = float(np.squeeze(v))\n    old = len(values)\n    values.add(v)\n    if len(values) != old:\n      print(values, name, count)\n\ndef create_graph(sess, name):\n  with sess.graph.as_default():\n    with tf.variable_scope(name):\n      input = tf.placeholder(tf.float32, shape=[1,1], name = \"input\")\n      tf.set_random_seed(1)\n\n      matrix1 = tf.Variable(tf.truncated_normal([1, size]), name = 'matrix1')\n      matrix2 = tf.Variable(tf.truncated_normal([size, size]), name = 'matrix2')\n      matrix4 = tf.Variable(tf.truncated_normal([size, 1]), name = 'matrix4')\n\n      matmul1 = tf.matmul(input, matrix1, name = 'matmul1')\n      matmul2 = tf.matmul(matmul1, matrix2, name = 'matmul2')\n      matmul4 = tf.matmul(matmul2, matrix4, name = \"matmul4\")\n      sess.run(tf.global_variables_initializer())\n\nsess1 = tf.Session()\nwith tf.device(\"/gpu:0\"):\n  create_graph(sess1, \"s1\")\n\nsess2 = tf.Session()\nwith tf.device(\"/gpu:0\"):\n  create_graph(sess2, \"s2\")\n\nt1 = Thread(target=myfunc, args=(sess1, 's1'))\nt1.start()\n\nt2 = Thread(target=myfunc, args=(sess2, 's2'))\nt2.start()\n\nsess1 should output -17430.388671875, sess2 should output -968.17529296875. But the output sets are nondeterministically growing:\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n((set([set([-968.17529296875]), 's2', 1-17430.388671875]))\n, 's1', 1)\n(set([-968.17529296875, -903.794921875]), 's2', 2)\n(set([-17430.388671875, -17302.84375]), 's1', 2)\n(set([-968.17529296875, -903.794921875, 2173.232177734375]), 's2', 511)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625]), 's2', 1723)\n(set([-17430.388671875, -17302.84375, -211.60272216796875]), 's1', 1961)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625, -30.6038818359375]), 's2', 2180)\n(set([-17430.388671875, -17302.84375, -1592.9022216796875, -211.60272216796875]), 's1', 2722)\n(set([-968.17529296875, -903.794921875, 2173.232177734375, -287.991455078125, -30.6038818359375, 841.5855712890625]), 's2', 3337)\n...\n\nTensorflow serving has a similar corrupted results issue tensorflow/serving#335, but this seems to be a tensorflow gpu memory problem. With @yaroslavvb memory_util.py, it seems when sess1 and sess2 interleaving in memory allocation/deallocation and gpu memory address (the second to last column in the log) is reused, results will be corrupted. The shortest trace I found is\n(set([-968.17529296875]), 's2', 1)\n('**************', 's2', 2)\n(set([-17430.388671875]), 's1', 1)\n('**************', 's1', 2)\n(set([-968.17529296875, -875.1435546875]), 's2', 2)\n       11                     s2/matmul1(44-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       23                     s1/matmul1(46-gpu_bfc)       40960       81920 gpu_bfc 30103375360 MemoryLogTensorAllocation\n       26                     s2/matmul2(47-gpu_bfc)       40960      122880 gpu_bfc 30103416320 MemoryLogTensorAllocation\n       28                     s2/matmul1(44-gpu_bfc)      -40960       81920 gpu_bfc -1 MemoryLogTensorDeallocation\n       31                     s2/matmul2(47-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       35                     s1/matmul2(49-gpu_bfc)       40960       81920 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       37                     s1/matmul1(46-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       40                     s1/matmul2(49-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n       61                     s2/matmul1(52-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\n       66                     s2/matmul2(53-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\n       71                     s2/matmul1(52-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       80                     s2/matmul2(53-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n       81                     s1/matmul1(56-gpu_bfc)       40960       40960 gpu_bfc 30103334912 MemoryLogTensorAllocation\n       85                     s1/matmul2(57-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\n       87                     s1/matmul1(56-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\n       90                     s1/matmul2(57-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\n\nSystem Information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: Yes\nOS Platform and Distribution (i.e. Linux Ubuntu 16.0): Ubuntu 14.04\nTensorFlow installed from (source or binary)?: binary\nTensorFlow version (use command below): 1.0.1\nBazel version (if compiling from source):\nCUDA/cuDNN version: cuda 8.0/cudnn5.1.5\nGPU Model and Memory: GRID K520, 4GB\nExact command to reproduce: python multi_session.py", "body": "Tensorflow generates corrupted results when running two sessions concurrently on gpu. Each session has a separate graph.\r\n\r\nCode (thx to @bnoodle):\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom threading import Thread, Event\r\n\r\nsize = 10240\r\ndef myfunc(sess, name):\r\n  values = set()\r\n  count = 0\r\n  while True:\r\n    count += 1\r\n    v = sess.run(name + \"/matmul4:0\", feed_dict={name + \"/input:0\": np.ones((1,1))})\r\n    v = float(np.squeeze(v))\r\n    old = len(values)\r\n    values.add(v)\r\n    if len(values) != old:\r\n      print(values, name, count)\r\n\r\ndef create_graph(sess, name):\r\n  with sess.graph.as_default():\r\n    with tf.variable_scope(name):\r\n      input = tf.placeholder(tf.float32, shape=[1,1], name = \"input\")\r\n      tf.set_random_seed(1)\r\n\r\n      matrix1 = tf.Variable(tf.truncated_normal([1, size]), name = 'matrix1')\r\n      matrix2 = tf.Variable(tf.truncated_normal([size, size]), name = 'matrix2')\r\n      matrix4 = tf.Variable(tf.truncated_normal([size, 1]), name = 'matrix4')\r\n\r\n      matmul1 = tf.matmul(input, matrix1, name = 'matmul1')\r\n      matmul2 = tf.matmul(matmul1, matrix2, name = 'matmul2')\r\n      matmul4 = tf.matmul(matmul2, matrix4, name = \"matmul4\")\r\n      sess.run(tf.global_variables_initializer())\r\n\r\nsess1 = tf.Session()\r\nwith tf.device(\"/gpu:0\"):\r\n  create_graph(sess1, \"s1\")\r\n\r\nsess2 = tf.Session()\r\nwith tf.device(\"/gpu:0\"):\r\n  create_graph(sess2, \"s2\")\r\n\r\nt1 = Thread(target=myfunc, args=(sess1, 's1'))\r\nt1.start()\r\n\r\nt2 = Thread(target=myfunc, args=(sess2, 's2'))\r\nt2.start()\r\n```\r\nsess1 should output -17430.388671875, sess2 should output -968.17529296875. But the output sets are nondeterministically growing:\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\r\nname: GRID K520\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\r\npciBusID 0000:00:03.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.91GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\n((set([set([-968.17529296875]), 's2', 1-17430.388671875]))\r\n, 's1', 1)\r\n(set([-968.17529296875, -903.794921875]), 's2', 2)\r\n(set([-17430.388671875, -17302.84375]), 's1', 2)\r\n(set([-968.17529296875, -903.794921875, 2173.232177734375]), 's2', 511)\r\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625]), 's2', 1723)\r\n(set([-17430.388671875, -17302.84375, -211.60272216796875]), 's1', 1961)\r\n(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625, -30.6038818359375]), 's2', 2180)\r\n(set([-17430.388671875, -17302.84375, -1592.9022216796875, -211.60272216796875]), 's1', 2722)\r\n(set([-968.17529296875, -903.794921875, 2173.232177734375, -287.991455078125, -30.6038818359375, 841.5855712890625]), 's2', 3337)\r\n...\r\n```\r\n\r\nTensorflow serving has a similar corrupted results issue https://github.com/tensorflow/serving/issues/335, but this seems to be a tensorflow gpu memory problem. With @yaroslavvb memory_util.py, it seems when sess1 and sess2 interleaving in memory allocation/deallocation and gpu memory address (the second to last column in the log) is reused, results will be corrupted. The shortest trace I found is\r\n```\r\n(set([-968.17529296875]), 's2', 1)\r\n('**************', 's2', 2)\r\n(set([-17430.388671875]), 's1', 1)\r\n('**************', 's1', 2)\r\n(set([-968.17529296875, -875.1435546875]), 's2', 2)\r\n       11                     s2/matmul1(44-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\r\n       23                     s1/matmul1(46-gpu_bfc)       40960       81920 gpu_bfc 30103375360 MemoryLogTensorAllocation\r\n       26                     s2/matmul2(47-gpu_bfc)       40960      122880 gpu_bfc 30103416320 MemoryLogTensorAllocation\r\n       28                     s2/matmul1(44-gpu_bfc)      -40960       81920 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       31                     s2/matmul2(47-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       35                     s1/matmul2(49-gpu_bfc)       40960       81920 gpu_bfc 30103334400 MemoryLogTensorAllocation\r\n       37                     s1/matmul1(46-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       40                     s1/matmul2(49-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       61                     s2/matmul1(52-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation\r\n       66                     s2/matmul2(53-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\r\n       71                     s2/matmul1(52-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       80                     s2/matmul2(53-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       81                     s1/matmul1(56-gpu_bfc)       40960       40960 gpu_bfc 30103334912 MemoryLogTensorAllocation\r\n       85                     s1/matmul2(57-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation\r\n       87                     s1/matmul1(56-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation\r\n       90                     s1/matmul2(57-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation\r\n```\r\n\r\n### System Information\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes\r\n- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: Ubuntu 14.04\r\n- *TensorFlow installed from (source or binary)?*: binary\r\n- *TensorFlow version* (use command below): 1.0.1\r\n- *Bazel version (if compiling from source)*:\r\n- *CUDA/cuDNN version*: cuda 8.0/cudnn5.1.5\r\n- *GPU Model and Memory*: GRID K520, 4GB\r\n- *Exact command to reproduce*: python multi_session.py\r\n\r\n"}