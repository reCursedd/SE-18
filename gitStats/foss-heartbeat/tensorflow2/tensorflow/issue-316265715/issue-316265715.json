{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18733", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18733/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18733/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18733/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18733", "id": 316265715, "node_id": "MDU6SXNzdWUzMTYyNjU3MTU=", "number": 18733, "title": "How can we handle resource exhaust error coming while allocating a tensor of a particular size.", "user": {"login": "alok2490", "id": 33896904, "node_id": "MDQ6VXNlcjMzODk2OTA0", "avatar_url": "https://avatars2.githubusercontent.com/u/33896904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alok2490", "html_url": "https://github.com/alok2490", "followers_url": "https://api.github.com/users/alok2490/followers", "following_url": "https://api.github.com/users/alok2490/following{/other_user}", "gists_url": "https://api.github.com/users/alok2490/gists{/gist_id}", "starred_url": "https://api.github.com/users/alok2490/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alok2490/subscriptions", "organizations_url": "https://api.github.com/users/alok2490/orgs", "repos_url": "https://api.github.com/users/alok2490/repos", "events_url": "https://api.github.com/users/alok2490/events{/privacy}", "received_events_url": "https://api.github.com/users/alok2490/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-20T13:22:26Z", "updated_at": "2018-04-24T23:31:12Z", "closed_at": "2018-04-24T23:31:12Z", "author_association": "NONE", "body_html": "<p>I am currently using single GPU : GEFORCE GTX1080 8GB and I am unable to handle an error coming while I am trying to train a network. Error is :</p>\n<p>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[131072,2048]<br>\n[[Node: training/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/beta_1/read, training/Adam/Variable/read)]]<br>\n[[Node: loss/mul/_179 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_697_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]</p>\n<p>However, I understand that I have limited memory in GPU which has to be utilized. I currently just wanting to know if there is any workaround of this by which I can train the network without reducing the dimensions of the network.</p>\n<p>Model :</p>\n<pre><code>model = Sequential()\nmodel.add(TimeDistributed(Flatten(), input_shape = (24,8,8,2048)))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(512, return_sequences=True, dropout=0.5))\nmodel.add(LSTM(512, return_sequences=False, dropout=0.5))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\n</code></pre>\n<p>Input to this network is actually image embedding I am getting from InceptionV3 without top.</p>\n<p>Any help in this regard is appreciated.</p>\n<p>Thanks in advance.</p>", "body_text": "I am currently using single GPU : GEFORCE GTX1080 8GB and I am unable to handle an error coming while I am trying to train a network. Error is :\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[131072,2048]\n[[Node: training/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/beta_1/read, training/Adam/Variable/read)]]\n[[Node: loss/mul/_179 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_697_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nHowever, I understand that I have limited memory in GPU which has to be utilized. I currently just wanting to know if there is any workaround of this by which I can train the network without reducing the dimensions of the network.\nModel :\nmodel = Sequential()\nmodel.add(TimeDistributed(Flatten(), input_shape = (24,8,8,2048)))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(512, return_sequences=True, dropout=0.5))\nmodel.add(LSTM(512, return_sequences=False, dropout=0.5))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\n\nInput to this network is actually image embedding I am getting from InceptionV3 without top.\nAny help in this regard is appreciated.\nThanks in advance.", "body": "I am currently using single GPU : GEFORCE GTX1080 8GB and I am unable to handle an error coming while I am trying to train a network. Error is :\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[131072,2048]\r\n[[Node: training/Adam/mul_3 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/beta_1/read, training/Adam/Variable/read)]]\r\n[[Node: loss/mul/_179 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_697_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\r\n\r\nHowever, I understand that I have limited memory in GPU which has to be utilized. I currently just wanting to know if there is any workaround of this by which I can train the network without reducing the dimensions of the network.\r\n\r\nModel :\r\n\r\n    model = Sequential()\r\n    model.add(TimeDistributed(Flatten(), input_shape = (24,8,8,2048)))\r\n    model.add(Dropout(0.5))\r\n    model.add(LSTM(512, return_sequences=True, dropout=0.5))\r\n    model.add(LSTM(512, return_sequences=False, dropout=0.5))\r\n    model.add(Dense(512, activation='relu'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(256, activation='relu'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(5, activation='softmax'))\r\nInput to this network is actually image embedding I am getting from InceptionV3 without top.\r\n\r\nAny help in this regard is appreciated.\r\n\r\nThanks in advance."}