{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/383288459", "html_url": "https://github.com/tensorflow/tensorflow/issues/18733#issuecomment-383288459", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18733", "id": 383288459, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzI4ODQ1OQ==", "user": {"login": "Baschdl", "id": 3034832, "node_id": "MDQ6VXNlcjMwMzQ4MzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3034832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Baschdl", "html_url": "https://github.com/Baschdl", "followers_url": "https://api.github.com/users/Baschdl/followers", "following_url": "https://api.github.com/users/Baschdl/following{/other_user}", "gists_url": "https://api.github.com/users/Baschdl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Baschdl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Baschdl/subscriptions", "organizations_url": "https://api.github.com/users/Baschdl/orgs", "repos_url": "https://api.github.com/users/Baschdl/repos", "events_url": "https://api.github.com/users/Baschdl/events{/privacy}", "received_events_url": "https://api.github.com/users/Baschdl/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-21T11:38:44Z", "updated_at": "2018-04-21T11:38:44Z", "author_association": "NONE", "body_html": "<p>It's a huge tensor you try to allocate. If we assume that you use a data type which needs 32bit for each value, your complete tensor needs 131072<em>2048</em>32bit/1024/1024/1024=8GB of memory on your GPU. Can you reduce some dimension like the embedding size or the time steps?</p>", "body_text": "It's a huge tensor you try to allocate. If we assume that you use a data type which needs 32bit for each value, your complete tensor needs 131072204832bit/1024/1024/1024=8GB of memory on your GPU. Can you reduce some dimension like the embedding size or the time steps?", "body": "It's a huge tensor you try to allocate. If we assume that you use a data type which needs 32bit for each value, your complete tensor needs 131072*2048*32bit/1024/1024/1024=8GB of memory on your GPU. Can you reduce some dimension like the embedding size or the time steps?"}