{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18676", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18676/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18676/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18676/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18676", "id": 315647621, "node_id": "MDU6SXNzdWUzMTU2NDc2MjE=", "number": 18676, "title": "Bug: CPU/Eigen fp16 matmul kernel fails on AVX512 systems", "user": {"login": "jbobba", "id": 21375855, "node_id": "MDQ6VXNlcjIxMzc1ODU1", "avatar_url": "https://avatars1.githubusercontent.com/u/21375855?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbobba", "html_url": "https://github.com/jbobba", "followers_url": "https://api.github.com/users/jbobba/followers", "following_url": "https://api.github.com/users/jbobba/following{/other_user}", "gists_url": "https://api.github.com/users/jbobba/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbobba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbobba/subscriptions", "organizations_url": "https://api.github.com/users/jbobba/orgs", "repos_url": "https://api.github.com/users/jbobba/repos", "events_url": "https://api.github.com/users/jbobba/events{/privacy}", "received_events_url": "https://api.github.com/users/jbobba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-04-18T21:24:05Z", "updated_at": "2018-08-30T22:56:09Z", "closed_at": "2018-08-30T22:56:09Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNo</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n('v1.8.0-rc0-561-g075fbb59d7', '1.8.0-rc0')</li>\n<li><strong>Python version</strong>:<br>\nPython 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nNA</li>\n<li><strong>GPU model and memory</strong>:<br>\nNA</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nbazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>bazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test<br>\nOn machines with AVX512, batch_matmul_op_test fails. Most likely culprit is Eigen's fp16 matmul running on CPU.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<h2>======================================================================<br>\nFAIL: testBatchMatmulOp_float16_False_True_True (<strong>main</strong>.BatchMatmulOpTest)</h2>\n<p>AssertionError:<br>\nNot equal to tolerance rtol=0.0976562, atol=0.0976562<br>\nMismatched value: a is different from b.<br>\n(mismatch 25.8125%)<br>\nx: array([[[ 7532.,  8860.,  6856., ...,  6372.,  8070.,  8264.],<br>\n[10400.,  9840.,  7188., ...,  8360.,  7640.,  9010.],<br>\n[ 8172.,  6590.,  3046., ...,  7400.,  6224.,  7656.],...<br>\ny: array([[[ 7824.,  8156.,  6804., ...,  6372.,  8064.,  8264.],<br>\n[10140., 11500.,  8380., ...,  8360.,  7644.,  9010.],<br>\n[ 8080.,  7964.,  5756., ...,  7404.,  6224.,  7656.],...</p>\n<hr>\n<p>Ran 4 tests in 0.681s</p>\n<p>FAILED (failures=1)<br>\nnot close where =  (array([0, 0, 0, ..., 9, 9, 9]), array([ 0,  0,  0, ..., 63, 63, 63]), array([ 4,  8, 10, ..., 10, 12, 13]))<br>\nnot close lhs =  [ 6570.  7150.  7024. ...  8530.  7310. 10290.]<br>\nnot close rhs =  [ 5820.  5290.  9060. ... 10680.  6480.  9280.]<br>\nnot close dif =  [ 748. 1864. 2032. ... 2152.  832. 1008.]<br>\nnot close tol =  [ 568.5  516.5  884.5 ... 1043.   633.   906. ]<br>\ndtype = float16, shape = (10, 64, 30)</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNo\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\n('v1.8.0-rc0-561-g075fbb59d7', '1.8.0-rc0')\nPython version:\nPython 2.7.12\nBazel version (if compiling from source):\nBuild label: 0.11.0\nGCC/Compiler version (if compiling from source):\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nCUDA/cuDNN version:\nNA\nGPU model and memory:\nNA\nExact command to reproduce:\nbazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nbazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test\nOn machines with AVX512, batch_matmul_op_test fails. Most likely culprit is Eigen's fp16 matmul running on CPU.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n======================================================================\nFAIL: testBatchMatmulOp_float16_False_True_True (main.BatchMatmulOpTest)\nAssertionError:\nNot equal to tolerance rtol=0.0976562, atol=0.0976562\nMismatched value: a is different from b.\n(mismatch 25.8125%)\nx: array([[[ 7532.,  8860.,  6856., ...,  6372.,  8070.,  8264.],\n[10400.,  9840.,  7188., ...,  8360.,  7640.,  9010.],\n[ 8172.,  6590.,  3046., ...,  7400.,  6224.,  7656.],...\ny: array([[[ 7824.,  8156.,  6804., ...,  6372.,  8064.,  8264.],\n[10140., 11500.,  8380., ...,  8360.,  7644.,  9010.],\n[ 8080.,  7964.,  5756., ...,  7404.,  6224.,  7656.],...\n\nRan 4 tests in 0.681s\nFAILED (failures=1)\nnot close where =  (array([0, 0, 0, ..., 9, 9, 9]), array([ 0,  0,  0, ..., 63, 63, 63]), array([ 4,  8, 10, ..., 10, 12, 13]))\nnot close lhs =  [ 6570.  7150.  7024. ...  8530.  7310. 10290.]\nnot close rhs =  [ 5820.  5290.  9060. ... 10680.  6480.  9280.]\nnot close dif =  [ 748. 1864. 2032. ... 2152.  832. 1008.]\nnot close tol =  [ 568.5  516.5  884.5 ... 1043.   633.   906. ]\ndtype = float16, shape = (10, 64, 30)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n('v1.8.0-rc0-561-g075fbb59d7', '1.8.0-rc0')\r\n- **Python version**: \r\nPython 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:\r\nNA\r\n- **GPU model and memory**:\r\nNA\r\n- **Exact command to reproduce**:\r\nbazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nbazel test --config=opt  -s //tensorflow/python/kernel_tests:batch_matmul_op_test\r\nOn machines with AVX512, batch_matmul_op_test fails. Most likely culprit is Eigen's fp16 matmul running on CPU.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n======================================================================\r\nFAIL: testBatchMatmulOp_float16_False_True_True (__main__.BatchMatmulOpTest)\r\n----------------------------------------------------------------------\r\n\r\nAssertionError: \r\nNot equal to tolerance rtol=0.0976562, atol=0.0976562\r\nMismatched value: a is different from b.\r\n(mismatch 25.8125%)\r\n x: array([[[ 7532.,  8860.,  6856., ...,  6372.,  8070.,  8264.],\r\n        [10400.,  9840.,  7188., ...,  8360.,  7640.,  9010.],\r\n        [ 8172.,  6590.,  3046., ...,  7400.,  6224.,  7656.],...\r\n y: array([[[ 7824.,  8156.,  6804., ...,  6372.,  8064.,  8264.],\r\n        [10140., 11500.,  8380., ...,  8360.,  7644.,  9010.],\r\n        [ 8080.,  7964.,  5756., ...,  7404.,  6224.,  7656.],...\r\n\r\n----------------------------------------------------------------------\r\nRan 4 tests in 0.681s\r\n\r\nFAILED (failures=1)\r\nnot close where =  (array([0, 0, 0, ..., 9, 9, 9]), array([ 0,  0,  0, ..., 63, 63, 63]), array([ 4,  8, 10, ..., 10, 12, 13]))\r\nnot close lhs =  [ 6570.  7150.  7024. ...  8530.  7310. 10290.]\r\nnot close rhs =  [ 5820.  5290.  9060. ... 10680.  6480.  9280.]\r\nnot close dif =  [ 748. 1864. 2032. ... 2152.  832. 1008.]\r\nnot close tol =  [ 568.5  516.5  884.5 ... 1043.   633.   906. ]\r\ndtype = float16, shape = (10, 64, 30)\r\n"}