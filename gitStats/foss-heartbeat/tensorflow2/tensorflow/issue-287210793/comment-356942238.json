{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/356942238", "html_url": "https://github.com/tensorflow/tensorflow/issues/15980#issuecomment-356942238", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15980", "id": 356942238, "node_id": "MDEyOklzc3VlQ29tbWVudDM1Njk0MjIzOA==", "user": {"login": "nikita68", "id": 15629332, "node_id": "MDQ6VXNlcjE1NjI5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15629332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikita68", "html_url": "https://github.com/nikita68", "followers_url": "https://api.github.com/users/nikita68/followers", "following_url": "https://api.github.com/users/nikita68/following{/other_user}", "gists_url": "https://api.github.com/users/nikita68/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikita68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikita68/subscriptions", "organizations_url": "https://api.github.com/users/nikita68/orgs", "repos_url": "https://api.github.com/users/nikita68/repos", "events_url": "https://api.github.com/users/nikita68/events{/privacy}", "received_events_url": "https://api.github.com/users/nikita68/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-11T14:01:34Z", "updated_at": "2018-01-11T14:01:34Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> I completely forgot about that parameter! Unfortunately, the error still persists. I'm trying to make a really small example showing where the code fails, but in the meantime here is a minimum version of the code above (the error is in the run_full_transducer.body function):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.rnn <span class=\"pl-k\">import</span> LSTMCell, LSTMStateTuple\n<span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>: Time major</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Constants</span>\ninput_dimensions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\nvocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\ninput_embedding_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\nencoder_hidden_units <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\ninput_block_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Model -------------------------------</span>\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-c1\">object</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">self</span>.encoder_inputs, <span class=\"pl-c1\">self</span>.encoder_inputs_length, <span class=\"pl-c1\">self</span>.encoder_hidden_state, \\\n        <span class=\"pl-c1\">self</span>.encoder_outputs, <span class=\"pl-c1\">self</span>.encoder_hidden_state_new <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.build_encoder_model()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">build_encoder_model</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        encoder_inputs <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(input_block_size, batch_size, input_dimensions)),\n                                     <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        encoder_inputs_length <span class=\"pl-k\">=</span> tf.Variable([tf.shape(encoder_inputs)[<span class=\"pl-c1\">0</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32,\n                                            <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs_length<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        encoder_hidden_state <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, encoder_hidden_units)), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                           <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_hidden_state<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save the state as one tensor</span>\n\n        encoder_inputs_embedded <span class=\"pl-k\">=</span> encoder_inputs\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build model</span>\n        encoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build previous state</span>\n        encoder_hidden_c, encoder_hidden_h <span class=\"pl-k\">=</span> tf.split(encoder_hidden_state, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n        encoder_hidden_c <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_c, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n        encoder_hidden_h <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_h, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n        encoder_hidden_state_t <span class=\"pl-k\">=</span> LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_outputs: [max_time, batch_size, num_units]</span>\n        encoder_outputs, encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n            encoder_cell, encoder_inputs_embedded,\n            <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n            <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>encoder_hidden_state_t)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.</span>\n        encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n        encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_state_new, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n\n        <span class=\"pl-k\">return</span> encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\n\n\nmodel <span class=\"pl-k\">=</span> Model()\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Training --------------------------</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run_full_transducer</span>():\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Inputs</span>\n    max_blocks <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>max_blocks<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> How often to run the encoder</span>\n    inputs_full_raw <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, batch_size, input_dimensions), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                     <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>inputs_full_raw<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Turn inputs into tensor which is easily readable</span>\n    inputs_full <span class=\"pl-k\">=</span> tf.reshape(inputs_full_raw, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[max_blocks, input_block_size, batch_size, input_dimensions])\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Hidden states</span>\n    encoder_hidden_init <span class=\"pl-k\">=</span> tf.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, encoder_hidden_units))\n\n    init_state <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">0</span>, encoder_hidden_init)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">cond</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">encoder_hidden</span>):\n        <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">&lt;</span> max_blocks\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">encoder_hidden</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Process encoder</span>\n        model.encoder_inputs <span class=\"pl-k\">=</span> model.encoder_inputs.assign(inputs_full[current_block])\n        model.encoder_inputs_length <span class=\"pl-k\">=</span> model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[<span class=\"pl-c1\">0</span>]])\n        model.encoder_hidden_state <span class=\"pl-k\">=</span> model.encoder_hidden_state.assign(encoder_hidden)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: Error is SOMETIMES gone when using tf.Print. If you comment out the next 2 lines the return val is 0.</span>\n        current_block <span class=\"pl-k\">=</span> tf.Print(current_block, [model.encoder_inputs], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Enc in: <span class=\"pl-pds\">'</span></span>)\n        current_block <span class=\"pl-k\">=</span> tf.Print(current_block, [model.encoder_outputs], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Enc out: <span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, model.encoder_hidden_state_new\n\n    _, final_enc_state <span class=\"pl-k\">=</span> tf.while_loop(cond, body, init_state, <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    <span class=\"pl-k\">return</span> max_blocks, inputs_full_raw, model.encoder_outputs, final_enc_state\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---------------------- Management -----------------------------</span>\n\ninit <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(init)\n\n    inp_max_blocks, inp_inputs_full_raw, enc_out, fin_enc_state <span class=\"pl-k\">=</span> run_full_transducer()\n\n    out, _ <span class=\"pl-k\">=</span> sess.run([enc_out, fin_enc_state], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{\n        inp_max_blocks: <span class=\"pl-c1\">3</span>,  <span class=\"pl-c\"><span class=\"pl-c\">#</span> How often to run the encoder</span>\n        inp_inputs_full_raw: np.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span> <span class=\"pl-k\">*</span> input_block_size, <span class=\"pl-c1\">1</span>, input_dimensions))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Full inputs</span>\n    })\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Encoder outputs: <span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">str</span>(out)</pre></div>", "body_text": "@ebrevdo I completely forgot about that parameter! Unfortunately, the error still persists. I'm trying to make a really small example showing where the code fails, but in the meantime here is a minimum version of the code above (the error is in the run_full_transducer.body function):\nimport tensorflow as tf\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\nfrom tensorflow.python.layers import core as layers_core\nimport numpy as np\n\n# NOTE: Time major\n\n# Constants\ninput_dimensions = 1\nvocab_size = 3\ninput_embedding_size = 20\nencoder_hidden_units = 64\nbatch_size = 1\ninput_block_size = 2\n\n# ----------------- Model -------------------------------\n\nclass Model(object):\n    def __init__(self):\n        self.encoder_inputs, self.encoder_inputs_length, self.encoder_hidden_state, \\\n        self.encoder_outputs, self.encoder_hidden_state_new = self.build_encoder_model()\n\n    def build_encoder_model(self):\n        encoder_inputs = tf.Variable(tf.zeros(shape=(input_block_size, batch_size, input_dimensions)),\n                                     dtype=tf.float32, name='encoder_inputs', trainable=False)\n        encoder_inputs_length = tf.Variable([tf.shape(encoder_inputs)[0]], dtype=tf.int32,\n                                            name='encoder_inputs_length', trainable=False)\n        encoder_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, encoder_hidden_units)), dtype=tf.float32,\n                                           name='encoder_hidden_state')  # Save the state as one tensor\n\n        encoder_inputs_embedded = encoder_inputs\n\n        # Build model\n        encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n        # Build previous state\n        encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\n        encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, encoder_hidden_units])\n        encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, encoder_hidden_units])\n        encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n        #   encoder_outputs: [max_time, batch_size, num_units]\n        encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\n            encoder_cell, encoder_inputs_embedded,\n            sequence_length=encoder_inputs_length, time_major=True,\n            dtype=tf.float32, initial_state=encoder_hidden_state_t)\n\n        # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\n        encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\n        encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new, shape=[2, -1, encoder_hidden_units])\n\n        return encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\n\n\nmodel = Model()\n\n\n# ----------------- Training --------------------------\n\ndef run_full_transducer():\n    # Inputs\n    max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # How often to run the encoder\n    inputs_full_raw = tf.placeholder(shape=(None, batch_size, input_dimensions), dtype=tf.float32,\n                                     name='inputs_full_raw')\n\n    # Turn inputs into tensor which is easily readable\n    inputs_full = tf.reshape(inputs_full_raw, shape=[max_blocks, input_block_size, batch_size, input_dimensions])\n\n    # Hidden states\n    encoder_hidden_init = tf.ones(shape=(2, 1, encoder_hidden_units))\n\n    init_state = (0, encoder_hidden_init)\n\n    def cond(current_block, encoder_hidden):\n        return current_block < max_blocks\n\n    def body(current_block, encoder_hidden):\n        # Process encoder\n        model.encoder_inputs = model.encoder_inputs.assign(inputs_full[current_block])\n        model.encoder_inputs_length = model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[0]])\n        model.encoder_hidden_state = model.encoder_hidden_state.assign(encoder_hidden)\n\n        # TODO: Error is SOMETIMES gone when using tf.Print. If you comment out the next 2 lines the return val is 0.\n        current_block = tf.Print(current_block, [model.encoder_inputs], message='Enc in: ')\n        current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')\n        return current_block + 1, model.encoder_hidden_state_new\n\n    _, final_enc_state = tf.while_loop(cond, body, init_state, parallel_iterations=1)\n\n    return max_blocks, inputs_full_raw, model.encoder_outputs, final_enc_state\n\n\n# ---------------------- Management -----------------------------\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    inp_max_blocks, inp_inputs_full_raw, enc_out, fin_enc_state = run_full_transducer()\n\n    out, _ = sess.run([enc_out, fin_enc_state], feed_dict={\n        inp_max_blocks: 3,  # How often to run the encoder\n        inp_inputs_full_raw: np.ones(shape=(3 * input_block_size, 1, input_dimensions))  # Full inputs\n    })\n    print 'Encoder outputs: ' + str(out)", "body": "@ebrevdo I completely forgot about that parameter! Unfortunately, the error still persists. I'm trying to make a really small example showing where the code fails, but in the meantime here is a minimum version of the code above (the error is in the run_full_transducer.body function):\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\r\nfrom tensorflow.python.layers import core as layers_core\r\nimport numpy as np\r\n\r\n# NOTE: Time major\r\n\r\n# Constants\r\ninput_dimensions = 1\r\nvocab_size = 3\r\ninput_embedding_size = 20\r\nencoder_hidden_units = 64\r\nbatch_size = 1\r\ninput_block_size = 2\r\n\r\n# ----------------- Model -------------------------------\r\n\r\nclass Model(object):\r\n    def __init__(self):\r\n        self.encoder_inputs, self.encoder_inputs_length, self.encoder_hidden_state, \\\r\n        self.encoder_outputs, self.encoder_hidden_state_new = self.build_encoder_model()\r\n\r\n    def build_encoder_model(self):\r\n        encoder_inputs = tf.Variable(tf.zeros(shape=(input_block_size, batch_size, input_dimensions)),\r\n                                     dtype=tf.float32, name='encoder_inputs', trainable=False)\r\n        encoder_inputs_length = tf.Variable([tf.shape(encoder_inputs)[0]], dtype=tf.int32,\r\n                                            name='encoder_inputs_length', trainable=False)\r\n        encoder_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, encoder_hidden_units)), dtype=tf.float32,\r\n                                           name='encoder_hidden_state')  # Save the state as one tensor\r\n\r\n        encoder_inputs_embedded = encoder_inputs\r\n\r\n        # Build model\r\n        encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\r\n\r\n        # Build previous state\r\n        encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\r\n        encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, encoder_hidden_units])\r\n        encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, encoder_hidden_units])\r\n        encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\r\n\r\n        #   encoder_outputs: [max_time, batch_size, num_units]\r\n        encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\r\n            encoder_cell, encoder_inputs_embedded,\r\n            sequence_length=encoder_inputs_length, time_major=True,\r\n            dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n\r\n        # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\r\n        encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\r\n        encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new, shape=[2, -1, encoder_hidden_units])\r\n\r\n        return encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\r\n\r\n\r\nmodel = Model()\r\n\r\n\r\n# ----------------- Training --------------------------\r\n\r\ndef run_full_transducer():\r\n    # Inputs\r\n    max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # How often to run the encoder\r\n    inputs_full_raw = tf.placeholder(shape=(None, batch_size, input_dimensions), dtype=tf.float32,\r\n                                     name='inputs_full_raw')\r\n\r\n    # Turn inputs into tensor which is easily readable\r\n    inputs_full = tf.reshape(inputs_full_raw, shape=[max_blocks, input_block_size, batch_size, input_dimensions])\r\n\r\n    # Hidden states\r\n    encoder_hidden_init = tf.ones(shape=(2, 1, encoder_hidden_units))\r\n\r\n    init_state = (0, encoder_hidden_init)\r\n\r\n    def cond(current_block, encoder_hidden):\r\n        return current_block < max_blocks\r\n\r\n    def body(current_block, encoder_hidden):\r\n        # Process encoder\r\n        model.encoder_inputs = model.encoder_inputs.assign(inputs_full[current_block])\r\n        model.encoder_inputs_length = model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[0]])\r\n        model.encoder_hidden_state = model.encoder_hidden_state.assign(encoder_hidden)\r\n\r\n        # TODO: Error is SOMETIMES gone when using tf.Print. If you comment out the next 2 lines the return val is 0.\r\n        current_block = tf.Print(current_block, [model.encoder_inputs], message='Enc in: ')\r\n        current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')\r\n        return current_block + 1, model.encoder_hidden_state_new\r\n\r\n    _, final_enc_state = tf.while_loop(cond, body, init_state, parallel_iterations=1)\r\n\r\n    return max_blocks, inputs_full_raw, model.encoder_outputs, final_enc_state\r\n\r\n\r\n# ---------------------- Management -----------------------------\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n\r\n    inp_max_blocks, inp_inputs_full_raw, enc_out, fin_enc_state = run_full_transducer()\r\n\r\n    out, _ = sess.run([enc_out, fin_enc_state], feed_dict={\r\n        inp_max_blocks: 3,  # How often to run the encoder\r\n        inp_inputs_full_raw: np.ones(shape=(3 * input_block_size, 1, input_dimensions))  # Full inputs\r\n    })\r\n    print 'Encoder outputs: ' + str(out)\r\n```"}