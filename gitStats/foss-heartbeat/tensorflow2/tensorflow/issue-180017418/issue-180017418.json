{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4653", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4653/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4653/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4653/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4653", "id": 180017418, "node_id": "MDU6SXNzdWUxODAwMTc0MTg=", "number": 4653, "title": "sysmalloc in session.run(tf.initialize_all_variables()) - cuda 8.0 + cudnn 5/5.1 + tensorflow 0.9/0.10", "user": {"login": "cyrilP-qs", "id": 18574755, "node_id": "MDQ6VXNlcjE4NTc0NzU1", "avatar_url": "https://avatars0.githubusercontent.com/u/18574755?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyrilP-qs", "html_url": "https://github.com/cyrilP-qs", "followers_url": "https://api.github.com/users/cyrilP-qs/followers", "following_url": "https://api.github.com/users/cyrilP-qs/following{/other_user}", "gists_url": "https://api.github.com/users/cyrilP-qs/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyrilP-qs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyrilP-qs/subscriptions", "organizations_url": "https://api.github.com/users/cyrilP-qs/orgs", "repos_url": "https://api.github.com/users/cyrilP-qs/repos", "events_url": "https://api.github.com/users/cyrilP-qs/events{/privacy}", "received_events_url": "https://api.github.com/users/cyrilP-qs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-09-29T10:59:53Z", "updated_at": "2016-09-29T15:39:01Z", "closed_at": "2016-09-29T15:39:01Z", "author_association": "NONE", "body_html": "<p>Hi all<br>\nI recently bought a new Titan X Pascal, and needed to upgrade cuda from 7 to 8.<br>\nAfter updating cuda 7 + cudnn 4 + tensorflow 0.9 -&gt; cuda 8 + cudnn 5 + tensorflow 0.10, my code which used to work fine now crashes with a segfault :</p>\n<ul>\n<li>with my GPUs on :</li>\n</ul>\n<pre><code>/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:03:00.0\nTotal memory: 11.90GiB\nFree memory: 11.76GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x30882d0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\npython2.7: malloc.c:2372: sysmalloc: Assertion `(old_top == (((mbinptr) (((char *) &amp;((av)-&gt;bins[((1) - 1) * 2])) - __builtin_offsetof (struct malloc_chunk, fd)))) &amp;&amp; old_size == 0) || ((unsigned long) (old_size) &gt;= (unsigned long)((((__builtin_offsetof (struct malloc_chunk, fd_nextsize))+((2 *(sizeof(size_t))) - 1)) &amp; ~((2 *(sizeof(size_t))) - 1))) &amp;&amp; ((old_top)-&gt;size &amp; 0x1) &amp;&amp; ((unsigned long) old_end &amp; pagemask) == 0)' failed.\n\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\n</code></pre>\n<ul>\n<li>if I restrict to 1 detected device with <code>os.environ['CUDA_VISIBLE_DEVICES'] = '1'</code>, it still crashes (with any of my 2 gpus) but with a different signal code:</li>\n</ul>\n<pre><code>/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n</code></pre>\n<ul>\n<li>If finally I restrict to CPU only, it works fine.</li>\n</ul>\n<p>I verified, both host and docker have the same driver version (367.48 ), cuda is installed correctly (on my host AND in my docker), nvdia-smi correctly finds the 2 GPUs, deviceQuery runs fine (also on the host and inside the docker), cudnn libraries are there, and moreover caffe works just fine on the gpus, which would indicate that my install is indeed correct.</p>\n<p>The problem persists with cudnn 5.1, and on both version of cudnn if i rollback to tensorflow 0.9</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nDocker ubuntu 14.04</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<pre><code>-rw-r--r-- 1 root root   558720 Sep 29 09:18 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       38 Sep 29 10:01 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; /usr/local/cuda/lib64/libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Sep 29 09:18 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 1000       13 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5\nlrwxrwxrwx 1 1000 1000       17 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.0.5\n-rwxr-xr-x 1 1000 1000 78065952 Apr 22 19:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n</code></pre>\n<p>But the problem remains with cudnn 5.1</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:<br>\n<code>http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl</code></li>\n</ol>\n<p>(but the problem reproduces with tensorflow 0.9)</p>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Complicated at this point, but I'm not sure its relevant...</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>Tried with cudnn-5 and cudnn 5.1, and tensorflow 0.9 / 0.10</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "Hi all\nI recently bought a new Titan X Pascal, and needed to upgrade cuda from 7 to 8.\nAfter updating cuda 7 + cudnn 4 + tensorflow 0.9 -> cuda 8 + cudnn 5 + tensorflow 0.10, my code which used to work fine now crashes with a segfault :\n\nwith my GPUs on :\n\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:03:00.0\nTotal memory: 11.90GiB\nFree memory: 11.76GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x30882d0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\npython2.7: malloc.c:2372: sysmalloc: Assertion `(old_top == (((mbinptr) (((char *) &((av)->bins[((1) - 1) * 2])) - __builtin_offsetof (struct malloc_chunk, fd)))) && old_size == 0) || ((unsigned long) (old_size) >= (unsigned long)((((__builtin_offsetof (struct malloc_chunk, fd_nextsize))+((2 *(sizeof(size_t))) - 1)) & ~((2 *(sizeof(size_t))) - 1))) && ((old_top)->size & 0x1) && ((unsigned long) old_end & pagemask) == 0)' failed.\n\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\n\n\nif I restrict to 1 detected device with os.environ['CUDA_VISIBLE_DEVICES'] = '1', it still crashes (with any of my 2 gpus) but with a different signal code:\n\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n\n\nIf finally I restrict to CPU only, it works fine.\n\nI verified, both host and docker have the same driver version (367.48 ), cuda is installed correctly (on my host AND in my docker), nvdia-smi correctly finds the 2 GPUs, deviceQuery runs fine (also on the host and inside the docker), cudnn libraries are there, and moreover caffe works just fine on the gpus, which would indicate that my install is indeed correct.\nThe problem persists with cudnn 5.1, and on both version of cudnn if i rollback to tensorflow 0.9\nEnvironment info\nOperating System:\nDocker ubuntu 14.04\nInstalled version of CUDA and cuDNN:\n-rw-r--r-- 1 root root   558720 Sep 29 09:18 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       38 Sep 29 10:01 /usr/local/cuda/lib64/libcudart.so.7.5 -> /usr/local/cuda/lib64/libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Sep 29 09:18 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 1000       13 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 1000 1000       17 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\n-rwxr-xr-x 1 1000 1000 78065952 Apr 22 19:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n\nBut the problem remains with cudnn 5.1\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nhttp://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl\n\n(but the problem reproduces with tensorflow 0.9)\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nComplicated at this point, but I'm not sure its relevant...\nWhat other attempted solutions have you tried?\nTried with cudnn-5 and cudnn 5.1, and tensorflow 0.9 / 0.10\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "Hi all\nI recently bought a new Titan X Pascal, and needed to upgrade cuda from 7 to 8.\nAfter updating cuda 7 + cudnn 4 + tensorflow 0.9 -> cuda 8 + cudnn 5 + tensorflow 0.10, my code which used to work fine now crashes with a segfault : \n- with my GPUs on : \n\n```\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:03:00.0\nTotal memory: 11.90GiB\nFree memory: 11.76GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x30882d0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\npython2.7: malloc.c:2372: sysmalloc: Assertion `(old_top == (((mbinptr) (((char *) &((av)->bins[((1) - 1) * 2])) - __builtin_offsetof (struct malloc_chunk, fd)))) && old_size == 0) || ((unsigned long) (old_size) >= (unsigned long)((((__builtin_offsetof (struct malloc_chunk, fd_nextsize))+((2 *(sizeof(size_t))) - 1)) & ~((2 *(sizeof(size_t))) - 1))) && ((old_top)->size & 0x1) && ((unsigned long) old_end & pagemask) == 0)' failed.\n\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\n```\n- if I restrict to 1 detected device with `os.environ['CUDA_VISIBLE_DEVICES'] = '1'`, it still crashes (with any of my 2 gpus) but with a different signal code: \n\n```\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n```\n- If finally I restrict to CPU only, it works fine.\n\nI verified, both host and docker have the same driver version (367.48 ), cuda is installed correctly (on my host AND in my docker), nvdia-smi correctly finds the 2 GPUs, deviceQuery runs fine (also on the host and inside the docker), cudnn libraries are there, and moreover caffe works just fine on the gpus, which would indicate that my install is indeed correct.\n\nThe problem persists with cudnn 5.1, and on both version of cudnn if i rollback to tensorflow 0.9\n### Environment info\n\nOperating System:\nDocker ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n\n```\n-rw-r--r-- 1 root root   558720 Sep 29 09:18 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       38 Sep 29 10:01 /usr/local/cuda/lib64/libcudart.so.7.5 -> /usr/local/cuda/lib64/libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Sep 29 09:18 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 1000       13 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 1000 1000       17 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\n-rwxr-xr-x 1 1000 1000 78065952 Apr 22 19:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n```\n\nBut the problem remains with cudnn 5.1\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n   `http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl`\n\n(but the problem reproduces with tensorflow 0.9)\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nComplicated at this point, but I'm not sure its relevant...\n### What other attempted solutions have you tried?\n\nTried with cudnn-5 and cudnn 5.1, and tensorflow 0.9 / 0.10\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n"}