{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10288", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10288/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10288/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10288/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10288", "id": 232283325, "node_id": "MDU6SXNzdWUyMzIyODMzMjU=", "number": 10288, "title": "[XLA][Feature] - Pass config flags for LLVM runtime.", "user": {"login": "annanay25", "id": 10982987, "node_id": "MDQ6VXNlcjEwOTgyOTg3", "avatar_url": "https://avatars2.githubusercontent.com/u/10982987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/annanay25", "html_url": "https://github.com/annanay25", "followers_url": "https://api.github.com/users/annanay25/followers", "following_url": "https://api.github.com/users/annanay25/following{/other_user}", "gists_url": "https://api.github.com/users/annanay25/gists{/gist_id}", "starred_url": "https://api.github.com/users/annanay25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/annanay25/subscriptions", "organizations_url": "https://api.github.com/users/annanay25/orgs", "repos_url": "https://api.github.com/users/annanay25/repos", "events_url": "https://api.github.com/users/annanay25/events{/privacy}", "received_events_url": "https://api.github.com/users/annanay25/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-05-30T15:02:25Z", "updated_at": "2017-06-09T05:10:45Z", "closed_at": "2017-06-09T05:10:45Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>:  ('v1.0.0-1783-g4c3bb1a', '1.0.0')</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>: -</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>: -</li>\n</ul>\n<h3>Problem description</h3>\n<p>As part of my Google Summer of Code project, I am trying to build TensorFlow with Polly-enabled LLVM. To do this, I have written my own BUILD file which runs TensorFlow with a custom repository of LLVM that has Polly checked out as well. I have managed to get a clean build and am now looking to incorporate Polly's passes in the Optimization pipeline of XLA.</p>\n<p>In XLA, the llvm module passes are registered <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/cpu/compiler_functor.cc#L214\">here</a>.</p>\n<p>Polly register's its passes in LLVM through the following steps</p>\n<ol>\n<li></li>\n</ol>\n<pre><code>static llvm::RegisterStandardPasses RegisterPollyOptimizerEarly(\n    llvm::PassManagerBuilder::EP_ModuleOptimizerEarly,\n    registerPollyEarlyAsPossiblePasses);\n</code></pre>\n<p>Corresponding file - <code>&lt;polly-src&gt;/lib/Support/RegisterPasses.cpp</code>.</p>\n<ol start=\"2\">\n<li></li>\n</ol>\n<pre><code>polly::initializePollyPasses(Registry); \n</code></pre>\n<p>Corresponding file - <code>&lt;polly-src&gt;/lib/Polly.cpp</code></p>\n<p>I have built the object files for both these files. But I want to check if Polly is actually being invoked in the pipeline, and so my question is -</p>\n<ul>\n<li>Are these steps enough to use Polly in the bazel build of TensorFlow?</li>\n<li>How can I pass configuration flags to LLVM in TensorFlow to check for Polly usage?</li>\n</ul>\n<p>As a reference, please find my BUILD file <a href=\"https://gitlab.com/annanay25/tensorflow/blob/master/third_party/llvm/llvm.BUILD\" rel=\"nofollow\">here</a>.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5807746\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/phawkins\">@phawkins</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1130906\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/eliben\">@eliben</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below):  ('v1.0.0-1783-g4c3bb1a', '1.0.0')\nBazel version (if compiling from source):  0.4.5\nCUDA/cuDNN version: -\nGPU model and memory: -\nExact command to reproduce: -\n\nProblem description\nAs part of my Google Summer of Code project, I am trying to build TensorFlow with Polly-enabled LLVM. To do this, I have written my own BUILD file which runs TensorFlow with a custom repository of LLVM that has Polly checked out as well. I have managed to get a clean build and am now looking to incorporate Polly's passes in the Optimization pipeline of XLA.\nIn XLA, the llvm module passes are registered here.\nPolly register's its passes in LLVM through the following steps\n\n\n\nstatic llvm::RegisterStandardPasses RegisterPollyOptimizerEarly(\n    llvm::PassManagerBuilder::EP_ModuleOptimizerEarly,\n    registerPollyEarlyAsPossiblePasses);\n\nCorresponding file - <polly-src>/lib/Support/RegisterPasses.cpp.\n\n\n\npolly::initializePollyPasses(Registry); \n\nCorresponding file - <polly-src>/lib/Polly.cpp\nI have built the object files for both these files. But I want to check if Polly is actually being invoked in the pipeline, and so my question is -\n\nAre these steps enough to use Polly in the bazel build of TensorFlow?\nHow can I pass configuration flags to LLVM in TensorFlow to check for Polly usage?\n\nAs a reference, please find my BUILD file here.\ncc @phawkins @eliben", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**:  ('v1.0.0-1783-g4c3bb1a', '1.0.0')\r\n- **Bazel version (if compiling from source)**:  0.4.5\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -\r\n\r\n### Problem description\r\nAs part of my Google Summer of Code project, I am trying to build TensorFlow with Polly-enabled LLVM. To do this, I have written my own BUILD file which runs TensorFlow with a custom repository of LLVM that has Polly checked out as well. I have managed to get a clean build and am now looking to incorporate Polly's passes in the Optimization pipeline of XLA. \r\n\r\nIn XLA, the llvm module passes are registered [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/cpu/compiler_functor.cc#L214).\r\n\r\nPolly register's its passes in LLVM through the following steps  \r\n\r\n1)\r\n```\r\nstatic llvm::RegisterStandardPasses RegisterPollyOptimizerEarly(\r\n    llvm::PassManagerBuilder::EP_ModuleOptimizerEarly,\r\n    registerPollyEarlyAsPossiblePasses);\r\n```\r\nCorresponding file - ```<polly-src>/lib/Support/RegisterPasses.cpp```.  \r\n\r\n2)\r\n\r\n```\r\npolly::initializePollyPasses(Registry); \r\n```\r\n\r\nCorresponding file - ```<polly-src>/lib/Polly.cpp```\r\n\r\nI have built the object files for both these files. But I want to check if Polly is actually being invoked in the pipeline, and so my question is -\r\n- Are these steps enough to use Polly in the bazel build of TensorFlow?\r\n- How can I pass configuration flags to LLVM in TensorFlow to check for Polly usage?\r\n\r\nAs a reference, please find my BUILD file [here](https://gitlab.com/annanay25/tensorflow/blob/master/third_party/llvm/llvm.BUILD).\r\n\r\ncc @phawkins @eliben"}