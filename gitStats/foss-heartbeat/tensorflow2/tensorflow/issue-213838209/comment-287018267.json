{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/287018267", "html_url": "https://github.com/tensorflow/tensorflow/pull/8363#issuecomment-287018267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8363", "id": 287018267, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NzAxODI2Nw==", "user": {"login": "jyegerlehner", "id": 2138320, "node_id": "MDQ6VXNlcjIxMzgzMjA=", "avatar_url": "https://avatars2.githubusercontent.com/u/2138320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jyegerlehner", "html_url": "https://github.com/jyegerlehner", "followers_url": "https://api.github.com/users/jyegerlehner/followers", "following_url": "https://api.github.com/users/jyegerlehner/following{/other_user}", "gists_url": "https://api.github.com/users/jyegerlehner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jyegerlehner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jyegerlehner/subscriptions", "organizations_url": "https://api.github.com/users/jyegerlehner/orgs", "repos_url": "https://api.github.com/users/jyegerlehner/repos", "events_url": "https://api.github.com/users/jyegerlehner/events{/privacy}", "received_events_url": "https://api.github.com/users/jyegerlehner/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-16T10:36:08Z", "updated_at": "2017-03-16T10:36:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>There is another reason I think this kind of filtering is superior. The moving-average window filter currently implemented averages over a window centered on the current point, and so in general the \"kernel radius\" stretches forward to include future data, making it non-causal. In the common use case where you've got a training loss curve, you make a hyper-param or other change, and restart training, and then you want to compare how training progresses relative to the previous iteration. The previous iteration's loss curve you are comparing to stretches out into the future, which is reflected in its curve. However for the currently-executing training, the future loss values don't exist yet so you can't directly compare the latest smoothed curve values of the currently-executing training loss to that of the previous iterations.</p>\n<p>That problem doesn't apply with this kind of smoothing. In the case of this PR, the smoothed curves are always causal, so you can compare previous iterations' curves to the current iteration's curve at every point, right up to the most recent data. Sure, it has some lag, but the lag is the same for all the curves.</p>\n<p>Hope that makes sense.</p>", "body_text": "There is another reason I think this kind of filtering is superior. The moving-average window filter currently implemented averages over a window centered on the current point, and so in general the \"kernel radius\" stretches forward to include future data, making it non-causal. In the common use case where you've got a training loss curve, you make a hyper-param or other change, and restart training, and then you want to compare how training progresses relative to the previous iteration. The previous iteration's loss curve you are comparing to stretches out into the future, which is reflected in its curve. However for the currently-executing training, the future loss values don't exist yet so you can't directly compare the latest smoothed curve values of the currently-executing training loss to that of the previous iterations.\nThat problem doesn't apply with this kind of smoothing. In the case of this PR, the smoothed curves are always causal, so you can compare previous iterations' curves to the current iteration's curve at every point, right up to the most recent data. Sure, it has some lag, but the lag is the same for all the curves.\nHope that makes sense.", "body": "There is another reason I think this kind of filtering is superior. The moving-average window filter currently implemented averages over a window centered on the current point, and so in general the \"kernel radius\" stretches forward to include future data, making it non-causal. In the common use case where you've got a training loss curve, you make a hyper-param or other change, and restart training, and then you want to compare how training progresses relative to the previous iteration. The previous iteration's loss curve you are comparing to stretches out into the future, which is reflected in its curve. However for the currently-executing training, the future loss values don't exist yet so you can't directly compare the latest smoothed curve values of the currently-executing training loss to that of the previous iterations. \r\n\r\nThat problem doesn't apply with this kind of smoothing. In the case of this PR, the smoothed curves are always causal, so you can compare previous iterations' curves to the current iteration's curve at every point, right up to the most recent data. Sure, it has some lag, but the lag is the same for all the curves.\r\n\r\nHope that makes sense."}