{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245800695", "html_url": "https://github.com/tensorflow/tensorflow/issues/4164#issuecomment-245800695", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4164", "id": 245800695, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTgwMDY5NQ==", "user": {"login": "heroleap", "id": 12758834, "node_id": "MDQ6VXNlcjEyNzU4ODM0", "avatar_url": "https://avatars0.githubusercontent.com/u/12758834?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heroleap", "html_url": "https://github.com/heroleap", "followers_url": "https://api.github.com/users/heroleap/followers", "following_url": "https://api.github.com/users/heroleap/following{/other_user}", "gists_url": "https://api.github.com/users/heroleap/gists{/gist_id}", "starred_url": "https://api.github.com/users/heroleap/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heroleap/subscriptions", "organizations_url": "https://api.github.com/users/heroleap/orgs", "repos_url": "https://api.github.com/users/heroleap/repos", "events_url": "https://api.github.com/users/heroleap/events{/privacy}", "received_events_url": "https://api.github.com/users/heroleap/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-09T02:25:22Z", "updated_at": "2016-09-09T02:25:22Z", "author_association": "NONE", "body_html": "<p>I am AlvinChen13's colleague and I am going to give more details on the structure. We uses CustomNet CNN to do image classification such as gender detection. We execute our CNN model under the following two cases.</p>\n<p>(1) Single Server Case - We mimic the google cifar muti-GPU model to modify our CNN to be able to execute on two GPUs (both GPUs are K40 as mentioned by AlvinChen13 installed on a single server)<br>\nThe training performance is ~210 examples/sec if we train the CNN on both GPUs and 150 examples/sec if we train CNN only on a single GPU (GPU0 in our case).</p>\n<p>(2) Distributed Case: We mimic the google Inception model to modify our CNN to be able to execute on one server with one PS and one worker (worker uses only one GPU for training).<br>\nThe performance is almost halved (~60 examples/sec).<br>\nThen, we further extend our case, in which we use one PS and two workers. PS and one worker is placed on one server and the other worker is placed on another server. Two servers are connected by Gigabyte network switch. During training, we disabled almost all other network traffic within the network.<br>\nThe performance is getting worse again, where worker0 and worker1 are both trained at ~20 examples/sec. (We use sync training method)</p>\n<p>The number surprised us. From our experiment, the performance keeps getting worse if we add more servers. In our case, single server with multiple GPU trains at hundreds examples/sec. One worker trains at 60 examples/sec (worse than single server case). Two workers train at 40 examples/sec combined (20 examples/sec * 2 workers) which is even worse than single worker. Do you have any idea on how it happens?</p>", "body_text": "I am AlvinChen13's colleague and I am going to give more details on the structure. We uses CustomNet CNN to do image classification such as gender detection. We execute our CNN model under the following two cases.\n(1) Single Server Case - We mimic the google cifar muti-GPU model to modify our CNN to be able to execute on two GPUs (both GPUs are K40 as mentioned by AlvinChen13 installed on a single server)\nThe training performance is ~210 examples/sec if we train the CNN on both GPUs and 150 examples/sec if we train CNN only on a single GPU (GPU0 in our case).\n(2) Distributed Case: We mimic the google Inception model to modify our CNN to be able to execute on one server with one PS and one worker (worker uses only one GPU for training).\nThe performance is almost halved (~60 examples/sec).\nThen, we further extend our case, in which we use one PS and two workers. PS and one worker is placed on one server and the other worker is placed on another server. Two servers are connected by Gigabyte network switch. During training, we disabled almost all other network traffic within the network.\nThe performance is getting worse again, where worker0 and worker1 are both trained at ~20 examples/sec. (We use sync training method)\nThe number surprised us. From our experiment, the performance keeps getting worse if we add more servers. In our case, single server with multiple GPU trains at hundreds examples/sec. One worker trains at 60 examples/sec (worse than single server case). Two workers train at 40 examples/sec combined (20 examples/sec * 2 workers) which is even worse than single worker. Do you have any idea on how it happens?", "body": "I am AlvinChen13's colleague and I am going to give more details on the structure. We uses CustomNet CNN to do image classification such as gender detection. We execute our CNN model under the following two cases.\n\n(1) Single Server Case - We mimic the google cifar muti-GPU model to modify our CNN to be able to execute on two GPUs (both GPUs are K40 as mentioned by AlvinChen13 installed on a single server)\nThe training performance is ~210 examples/sec if we train the CNN on both GPUs and 150 examples/sec if we train CNN only on a single GPU (GPU0 in our case).\n\n(2) Distributed Case: We mimic the google Inception model to modify our CNN to be able to execute on one server with one PS and one worker (worker uses only one GPU for training).\nThe performance is almost halved (~60 examples/sec).\nThen, we further extend our case, in which we use one PS and two workers. PS and one worker is placed on one server and the other worker is placed on another server. Two servers are connected by Gigabyte network switch. During training, we disabled almost all other network traffic within the network. \nThe performance is getting worse again, where worker0 and worker1 are both trained at ~20 examples/sec. (We use sync training method)\n\nThe number surprised us. From our experiment, the performance keeps getting worse if we add more servers. In our case, single server with multiple GPU trains at hundreds examples/sec. One worker trains at 60 examples/sec (worse than single server case). Two workers train at 40 examples/sec combined (20 examples/sec \\* 2 workers) which is even worse than single worker. Do you have any idea on how it happens?\n"}