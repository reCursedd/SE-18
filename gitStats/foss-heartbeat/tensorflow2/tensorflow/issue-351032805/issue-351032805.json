{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21643", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21643/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21643/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21643/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21643", "id": 351032805, "node_id": "MDU6SXNzdWUzNTEwMzI4MDU=", "number": 21643, "title": "Tensorflow Lite Custom op have no effect even source code *.cc has modified", "user": {"login": "pcub", "id": 7065417, "node_id": "MDQ6VXNlcjcwNjU0MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/7065417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcub", "html_url": "https://github.com/pcub", "followers_url": "https://api.github.com/users/pcub/followers", "following_url": "https://api.github.com/users/pcub/following{/other_user}", "gists_url": "https://api.github.com/users/pcub/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcub/subscriptions", "organizations_url": "https://api.github.com/users/pcub/orgs", "repos_url": "https://api.github.com/users/pcub/repos", "events_url": "https://api.github.com/users/pcub/events{/privacy}", "received_events_url": "https://api.github.com/users/pcub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, {"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-08-16T02:28:44Z", "updated_at": "2018-09-06T01:21:31Z", "closed_at": "2018-09-04T08:34:23Z", "author_association": "NONE", "body_html": "<p>System information<br>\n== cat /etc/issue ===============================================<br>\nLinux master 4.15.0-29-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115944861\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/31\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/31/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/31\">#31</a>~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions. There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux master 4.15.0-29-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115944861\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/31\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/31/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/31\">#31</a>~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy 1.14.5<br>\nprotobuf 3.6.0<br>\ntensorflow 1.8.0<br>\ntensorflow-tensorboard 0.4.0</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.8.0<br>\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072<br>\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072<br>\nSanity check: array([1], dtype=int32)<br>\n/usr/local/lib/python2.7/dist-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.<br>\nfrom ._conv import register_converters as _register_converters</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda/lib64/:/usr/local/cuda/lib64/:/usr/local/cuda-9.0/lib64:<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nMon Jul 30 11:49:23 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 396.45 Driver Version: 396.45 |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |<br>\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |<br>\n|===============================+======================+======================|<br>\n| 0 Quadro P600 Off | 00000000:03:00.0 On | N/A |<br>\n| 34% 43C P8 N/A / N/A | 574MiB / 1997MiB | 1% Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes: GPU Memory |<br>\n| GPU PID Type Process name Usage |<br>\n|=============================================================================|<br>\n| 0 1152 G /usr/lib/xorg/Xorg 237MiB |<br>\n| 0 2213 G compiz 79MiB |<br>\n| 0 2589 G ...-token=224D99F526E00AE3A3C0EF4D5E6D103A 113MiB |<br>\n| 0 5305 G ...-token=53BA9EE005E85645FEB6537828E37D64 141MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs ===================================================<br>\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart_static.a<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart.so.9.2.148</p>\n<h3>Describe the problem</h3>\n<p>I converted caffe ssd model to tensorflow/tensorfow lite. There are small differences in caffe and tensorflow detection layer (i.e., decode box and coordinates difference).<br>\nTensorflow lite does not support all ops of tensorflow.<br>\nDetection layer in tensorflow lite is implemented in detect_postprocess.cc as custom op.<br>\nI changed detect_postprocess.cc to apply caffes' decode box and other functions. Then, I compiled tf with \"bazel build -c opt --jobs=8 //tensorflow/tools/pip_package:build_pip_package\" and also tried with \"bazel build -c opt \"//tensorflow/contrib/lite/kernels:builtin_ops\",<br>\nHowever, problem is when I load detect.tflite on android and/or PC (with tensorfow lite python api &lt;&lt;tf.VERSION = 1.8.0 does not work,tf version:: 1.10.0 workd&gt;&gt;), the detection results return the same result as what detect_postprocess.cc supposed to work even I changed functionality of detect_postprocess.cc.</p>\n<p>In other words, tensorflow lite always refers very first version of detect_postprocess.cc</p>\n<p>What is the problem?</p>", "body_text": "System information\n== cat /etc/issue ===============================================\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions. There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy 1.14.5\nprotobuf 3.6.0\ntensorflow 1.8.0\ntensorflow-tensorboard 0.4.0\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.8.0\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\nSanity check: array([1], dtype=int32)\n/usr/local/lib/python2.7/dist-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\nfrom ._conv import register_converters as _register_converters\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda/lib64/:/usr/local/cuda/lib64/:/usr/local/cuda-9.0/lib64:\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nMon Jul 30 11:49:23 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 396.45 Driver Version: 396.45 |\n|-------------------------------+----------------------+----------------------+\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\n|===============================+======================+======================|\n| 0 Quadro P600 Off | 00000000:03:00.0 On | N/A |\n| 34% 43C P8 N/A / N/A | 574MiB / 1997MiB | 1% Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes: GPU Memory |\n| GPU PID Type Process name Usage |\n|=============================================================================|\n| 0 1152 G /usr/lib/xorg/Xorg 237MiB |\n| 0 2213 G compiz 79MiB |\n| 0 2589 G ...-token=224D99F526E00AE3A3C0EF4D5E6D103A 113MiB |\n| 0 5305 G ...-token=53BA9EE005E85645FEB6537828E37D64 141MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs ===================================================\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart.so.9.2.148\nDescribe the problem\nI converted caffe ssd model to tensorflow/tensorfow lite. There are small differences in caffe and tensorflow detection layer (i.e., decode box and coordinates difference).\nTensorflow lite does not support all ops of tensorflow.\nDetection layer in tensorflow lite is implemented in detect_postprocess.cc as custom op.\nI changed detect_postprocess.cc to apply caffes' decode box and other functions. Then, I compiled tf with \"bazel build -c opt --jobs=8 //tensorflow/tools/pip_package:build_pip_package\" and also tried with \"bazel build -c opt \"//tensorflow/contrib/lite/kernels:builtin_ops\",\nHowever, problem is when I load detect.tflite on android and/or PC (with tensorfow lite python api <<tf.VERSION = 1.8.0 does not work,tf version:: 1.10.0 workd>>), the detection results return the same result as what detect_postprocess.cc supposed to work even I changed functionality of detect_postprocess.cc.\nIn other words, tensorflow lite always refers very first version of detect_postprocess.cc\nWhat is the problem?", "body": "System information\r\n== cat /etc/issue ===============================================\r\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions. There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n== uname -a =====================================================\r\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy 1.14.5\r\nprotobuf 3.6.0\r\ntensorflow 1.8.0\r\ntensorflow-tensorboard 0.4.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/dist-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\r\nfrom ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/lib64/:/usr/local/cuda/lib64/:/usr/local/cuda-9.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nMon Jul 30 11:49:23 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.45 Driver Version: 396.45 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r\n|===============================+======================+======================|\r\n| 0 Quadro P600 Off | 00000000:03:00.0 On | N/A |\r\n| 34% 43C P8 N/A / N/A | 574MiB / 1997MiB | 1% Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes: GPU Memory |\r\n| GPU PID Type Process name Usage |\r\n|=============================================================================|\r\n| 0 1152 G /usr/lib/xorg/Xorg 237MiB |\r\n| 0 2213 G compiz 79MiB |\r\n| 0 2589 G ...-token=224D99F526E00AE3A3C0EF4D5E6D103A 113MiB |\r\n| 0 5305 G ...-token=53BA9EE005E85645FEB6537828E37D64 141MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs ===================================================\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart.so.9.2.148\r\n\r\n\r\n### Describe the problem\r\nI converted caffe ssd model to tensorflow/tensorfow lite. There are small differences in caffe and tensorflow detection layer (i.e., decode box and coordinates difference). \r\nTensorflow lite does not support all ops of tensorflow.\r\nDetection layer in tensorflow lite is implemented in detect_postprocess.cc as custom op.\r\nI changed detect_postprocess.cc to apply caffes' decode box and other functions. Then, I compiled tf with \"bazel build -c opt --jobs=8 //tensorflow/tools/pip_package:build_pip_package\" and also tried with \"bazel build -c opt \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\nHowever, problem is when I load detect.tflite on android and/or PC (with tensorfow lite python api <<tf.VERSION = 1.8.0 does not work,tf version:: 1.10.0 workd>>), the detection results return the same result as what detect_postprocess.cc supposed to work even I changed functionality of detect_postprocess.cc.\r\n\r\nIn other words, tensorflow lite always refers very first version of detect_postprocess.cc\r\n\r\nWhat is the problem?\r\n\r\n"}