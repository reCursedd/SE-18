{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/250798911", "html_url": "https://github.com/tensorflow/tensorflow/issues/4685#issuecomment-250798911", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4685", "id": 250798911, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MDc5ODkxMQ==", "user": {"login": "huttunensami", "id": 16336473, "node_id": "MDQ6VXNlcjE2MzM2NDcz", "avatar_url": "https://avatars2.githubusercontent.com/u/16336473?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huttunensami", "html_url": "https://github.com/huttunensami", "followers_url": "https://api.github.com/users/huttunensami/followers", "following_url": "https://api.github.com/users/huttunensami/following{/other_user}", "gists_url": "https://api.github.com/users/huttunensami/gists{/gist_id}", "starred_url": "https://api.github.com/users/huttunensami/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huttunensami/subscriptions", "organizations_url": "https://api.github.com/users/huttunensami/orgs", "repos_url": "https://api.github.com/users/huttunensami/repos", "events_url": "https://api.github.com/users/huttunensami/events{/privacy}", "received_events_url": "https://api.github.com/users/huttunensami/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-30T17:06:40Z", "updated_at": "2016-09-30T17:06:40Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I have a same kind of issue when trying to download and preprocess the MSCOCO dataset used in im2txt model  (<a href=\"https://github.com/tensorflow/models/tree/master/im2txt\">https://github.com/tensorflow/models/tree/master/im2txt</a>). It seems that the script <code>bazel-bin/im2txt/download_and_preprocess_mscoco \"${MSCOCO_DIR}\"</code> is able to process up to 1024 images but after that all the threads fail:</p>\n<pre><code>Exception in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/threading.py\", line 811, in __bootstrap_inner\n  File \"/usr/lib64/python2.7/threading.py\", line 764, in run\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 278, in _process_image_files\n    sequence_example = _to_sequence_example(image, decoder, vocab)\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 214, in _to_sequence_example\n    encoded_image = f.read()\n  File \"&lt;PYTHONDIR&gt;/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 99, in read\n  File \"&lt;PYTHONDIR&gt;/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 72, in _preread_check\n  File \"/usr/lib64/python2.7/contextlib.py\", line 24, in __exit__\n  File \"&lt;PYTHONDIR&gt;/lib/python2.7/site-packages/tensorflow/python/framework/errors.py\", line 463, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nResourceExhaustedError: &lt;DATA_DIR&gt;/models/im2txt/im2txt/data/mscoco/raw-data/train2014/COCO_train2014_000000069569.jpg\n</code></pre>\n<p>Apparently the script does not close the file handles it uses properly which leads to this kind of unfortunate situation.</p>\n<p>Operating System: CentOS Linux release 7.2.1511 (Core)<br>\nCUDA 7.5<br>\ncuDNN 5.0<br>\nTensorFlow master branch</p>", "body_text": "Hi,\nI have a same kind of issue when trying to download and preprocess the MSCOCO dataset used in im2txt model  (https://github.com/tensorflow/models/tree/master/im2txt). It seems that the script bazel-bin/im2txt/download_and_preprocess_mscoco \"${MSCOCO_DIR}\" is able to process up to 1024 images but after that all the threads fail:\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/threading.py\", line 811, in __bootstrap_inner\n  File \"/usr/lib64/python2.7/threading.py\", line 764, in run\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 278, in _process_image_files\n    sequence_example = _to_sequence_example(image, decoder, vocab)\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 214, in _to_sequence_example\n    encoded_image = f.read()\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 99, in read\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 72, in _preread_check\n  File \"/usr/lib64/python2.7/contextlib.py\", line 24, in __exit__\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/framework/errors.py\", line 463, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nResourceExhaustedError: <DATA_DIR>/models/im2txt/im2txt/data/mscoco/raw-data/train2014/COCO_train2014_000000069569.jpg\n\nApparently the script does not close the file handles it uses properly which leads to this kind of unfortunate situation.\nOperating System: CentOS Linux release 7.2.1511 (Core)\nCUDA 7.5\ncuDNN 5.0\nTensorFlow master branch", "body": "Hi,\n\nI have a same kind of issue when trying to download and preprocess the MSCOCO dataset used in im2txt model  (https://github.com/tensorflow/models/tree/master/im2txt). It seems that the script `bazel-bin/im2txt/download_and_preprocess_mscoco \"${MSCOCO_DIR}\"` is able to process up to 1024 images but after that all the threads fail:\n\n```\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/threading.py\", line 811, in __bootstrap_inner\n  File \"/usr/lib64/python2.7/threading.py\", line 764, in run\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 278, in _process_image_files\n    sequence_example = _to_sequence_example(image, decoder, vocab)\n  File \"bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py\", line 214, in _to_sequence_example\n    encoded_image = f.read()\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 99, in read\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 72, in _preread_check\n  File \"/usr/lib64/python2.7/contextlib.py\", line 24, in __exit__\n  File \"<PYTHONDIR>/lib/python2.7/site-packages/tensorflow/python/framework/errors.py\", line 463, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\nResourceExhaustedError: <DATA_DIR>/models/im2txt/im2txt/data/mscoco/raw-data/train2014/COCO_train2014_000000069569.jpg\n```\n\nApparently the script does not close the file handles it uses properly which leads to this kind of unfortunate situation.\n\nOperating System: CentOS Linux release 7.2.1511 (Core)\nCUDA 7.5\ncuDNN 5.0\nTensorFlow master branch\n"}