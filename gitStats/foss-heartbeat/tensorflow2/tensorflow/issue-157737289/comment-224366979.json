{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224366979", "html_url": "https://github.com/tensorflow/tensorflow/issues/2594#issuecomment-224366979", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2594", "id": 224366979, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDM2Njk3OQ==", "user": {"login": "markpwoodward", "id": 6820773, "node_id": "MDQ6VXNlcjY4MjA3NzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6820773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markpwoodward", "html_url": "https://github.com/markpwoodward", "followers_url": "https://api.github.com/users/markpwoodward/followers", "following_url": "https://api.github.com/users/markpwoodward/following{/other_user}", "gists_url": "https://api.github.com/users/markpwoodward/gists{/gist_id}", "starred_url": "https://api.github.com/users/markpwoodward/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markpwoodward/subscriptions", "organizations_url": "https://api.github.com/users/markpwoodward/orgs", "repos_url": "https://api.github.com/users/markpwoodward/repos", "events_url": "https://api.github.com/users/markpwoodward/events{/privacy}", "received_events_url": "https://api.github.com/users/markpwoodward/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-07T18:14:09Z", "updated_at": "2016-06-07T18:14:09Z", "author_association": "NONE", "body_html": "<p>Thank you. This makes sense. I do understand the distinction between hard placement and soft placement.</p>\n<p>Seeing that something in dynamic_rnn did not have a GPU implementation (requiring soft placement) made me hope that, if only there were a GPU implementation for that operation, then I would get a huge speedup. :) Of course, those operations might not have any impact on performance.</p>\n<p>I should probably just look at the graph for dynamic_rnn and see what was placed on the CPU, rather than forcing dynamic_rnn onto the GPU and then posting a github issue when it complains. My apologies. Feel free to close this.</p>", "body_text": "Thank you. This makes sense. I do understand the distinction between hard placement and soft placement.\nSeeing that something in dynamic_rnn did not have a GPU implementation (requiring soft placement) made me hope that, if only there were a GPU implementation for that operation, then I would get a huge speedup. :) Of course, those operations might not have any impact on performance.\nI should probably just look at the graph for dynamic_rnn and see what was placed on the CPU, rather than forcing dynamic_rnn onto the GPU and then posting a github issue when it complains. My apologies. Feel free to close this.", "body": "Thank you. This makes sense. I do understand the distinction between hard placement and soft placement.\n\nSeeing that something in dynamic_rnn did not have a GPU implementation (requiring soft placement) made me hope that, if only there were a GPU implementation for that operation, then I would get a huge speedup. :) Of course, those operations might not have any impact on performance.\n\nI should probably just look at the graph for dynamic_rnn and see what was placed on the CPU, rather than forcing dynamic_rnn onto the GPU and then posting a github issue when it complains. My apologies. Feel free to close this.\n"}