{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16868", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16868/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16868/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16868/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16868", "id": 295531447, "node_id": "MDU6SXNzdWUyOTU1MzE0NDc=", "number": 16868, "title": "Backpropagation/weight update issue with custom layer", "user": {"login": "roya0045", "id": 12854129, "node_id": "MDQ6VXNlcjEyODU0MTI5", "avatar_url": "https://avatars1.githubusercontent.com/u/12854129?v=4", "gravatar_id": "", "url": "https://api.github.com/users/roya0045", "html_url": "https://github.com/roya0045", "followers_url": "https://api.github.com/users/roya0045/followers", "following_url": "https://api.github.com/users/roya0045/following{/other_user}", "gists_url": "https://api.github.com/users/roya0045/gists{/gist_id}", "starred_url": "https://api.github.com/users/roya0045/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/roya0045/subscriptions", "organizations_url": "https://api.github.com/users/roya0045/orgs", "repos_url": "https://api.github.com/users/roya0045/repos", "events_url": "https://api.github.com/users/roya0045/events{/privacy}", "received_events_url": "https://api.github.com/users/roya0045/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-08T14:27:12Z", "updated_at": "2018-02-09T00:33:26Z", "closed_at": "2018-02-09T00:33:25Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Win 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: From pip (binary)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5</li>\n<li><strong>Python version</strong>:  3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:---</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:----</li>\n<li><strong>CUDA/cuDNN version</strong>:None</li>\n<li><strong>GPU model and memory</strong>:None</li>\n<li><strong>Exact command to reproduce</strong>:See source code</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am attempting to implement a custom layer. The layer uses the Image to Patch function and simple tensorflow operator. The layer is implemented in keras to simplify the model building and training but the backend is in tensorflow.</p>\n<p>I am using a simple cnn as a benchmark, whenever I implement my custom layer ( even only as the first layer to 'encode' the data) backpropagation seems to break as no weights get updated in the entirety of the model.</p>\n<p>From my understanding the all the operations used (mult, div, add, minus) are differentiable and things such as reshape, transpose and extract_image_patches should not prevent backpropagation and weight updates.</p>\n<p>I tried using the basic layer building method and inheriting from the convolution class (_Conv) and both cases prevent the weight update for the whole model, but such a thing shouldn't be the case.</p>\n<h3>Source code / logs</h3>\n<p>Prototype layer: <a href=\"https://github.com/roya0045/cvar2/blob/master/tfvar.py\">https://github.com/roya0045/cvar2/blob/master/tfvar.py</a><br>\nModel builder: <a href=\"https://github.com/roya0045/cvar2/blob/master/test2.py\">https://github.com/roya0045/cvar2/blob/master/test2.py</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win 10\nTensorFlow installed from (source or binary): From pip (binary)\nTensorFlow version (use command below): 1.5\nPython version:  3.5\nBazel version (if compiling from source):---\nGCC/Compiler version (if compiling from source):----\nCUDA/cuDNN version:None\nGPU model and memory:None\nExact command to reproduce:See source code\n\nDescribe the problem\nI am attempting to implement a custom layer. The layer uses the Image to Patch function and simple tensorflow operator. The layer is implemented in keras to simplify the model building and training but the backend is in tensorflow.\nI am using a simple cnn as a benchmark, whenever I implement my custom layer ( even only as the first layer to 'encode' the data) backpropagation seems to break as no weights get updated in the entirety of the model.\nFrom my understanding the all the operations used (mult, div, add, minus) are differentiable and things such as reshape, transpose and extract_image_patches should not prevent backpropagation and weight updates.\nI tried using the basic layer building method and inheriting from the convolution class (_Conv) and both cases prevent the weight update for the whole model, but such a thing shouldn't be the case.\nSource code / logs\nPrototype layer: https://github.com/roya0045/cvar2/blob/master/tfvar.py\nModel builder: https://github.com/roya0045/cvar2/blob/master/test2.py", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win 10\r\n- **TensorFlow installed from (source or binary)**: From pip (binary)\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**:---\r\n- **GCC/Compiler version (if compiling from source)**:----\r\n- **CUDA/cuDNN version**:None\r\n- **GPU model and memory**:None\r\n- **Exact command to reproduce**:See source code\r\n\r\n### Describe the problem\r\nI am attempting to implement a custom layer. The layer uses the Image to Patch function and simple tensorflow operator. The layer is implemented in keras to simplify the model building and training but the backend is in tensorflow.\r\n\r\nI am using a simple cnn as a benchmark, whenever I implement my custom layer ( even only as the first layer to 'encode' the data) backpropagation seems to break as no weights get updated in the entirety of the model.\r\n\r\nFrom my understanding the all the operations used (mult, div, add, minus) are differentiable and things such as reshape, transpose and extract_image_patches should not prevent backpropagation and weight updates.\r\n\r\nI tried using the basic layer building method and inheriting from the convolution class (_Conv) and both cases prevent the weight update for the whole model, but such a thing shouldn't be the case.\r\n\r\n### Source code / logs\r\n\r\nPrototype layer: https://github.com/roya0045/cvar2/blob/master/tfvar.py\r\nModel builder: https://github.com/roya0045/cvar2/blob/master/test2.py"}