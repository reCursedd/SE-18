{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2776", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2776/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2776/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2776/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2776", "id": 159561977, "node_id": "MDU6SXNzdWUxNTk1NjE5Nzc=", "number": 2776, "title": "TensorFlow : Machine Translation example Segmentation fault (Core dumped)", "user": {"login": "suraj1990", "id": 5551707, "node_id": "MDQ6VXNlcjU1NTE3MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5551707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suraj1990", "html_url": "https://github.com/suraj1990", "followers_url": "https://api.github.com/users/suraj1990/followers", "following_url": "https://api.github.com/users/suraj1990/following{/other_user}", "gists_url": "https://api.github.com/users/suraj1990/gists{/gist_id}", "starred_url": "https://api.github.com/users/suraj1990/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suraj1990/subscriptions", "organizations_url": "https://api.github.com/users/suraj1990/orgs", "repos_url": "https://api.github.com/users/suraj1990/repos", "events_url": "https://api.github.com/users/suraj1990/events{/privacy}", "received_events_url": "https://api.github.com/users/suraj1990/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-06-10T05:33:43Z", "updated_at": "2016-11-22T21:10:07Z", "closed_at": "2016-06-16T05:23:09Z", "author_association": "NONE", "body_html": "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5551707/15954993/e761dda4-2efa-11e6-8d70-a36a8ad02239.png\"><img src=\"https://cloud.githubusercontent.com/assets/5551707/15954993/e761dda4-2efa-11e6-8d70-a36a8ad02239.png\" alt=\"cuda\" style=\"max-width:100%;\"></a><br>\nGitHub issues are for bugs / installation problems / feature requests.<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>Environment info</h3>\n<p>Operating System: AWS X2-large GPU instance. Ubuntu</p>\n<p>Installed version of CUDA 7.5 and cuDNN: 7.5.18<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>. - 0.8.0</li>\n</ol>\n<p>If installed from sources, provide the commit hash:</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Running the translate.py script from tensorflow/modles/rnn/translate path</li>\n<li>It downloads the files, unzip's the files</li>\n<li>prepares the data - &gt; creates the vocabulary for English and French data -&gt; tockenizes the data -&gt; train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size)</li>\n<li>In train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) there is a crash bacause of out of memory.</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>Tried to give smaller batch size. varied from 32,64 ...512</li>\n</ol>\n<h3>log</h3>\n<p>segmentation fault(core dumped)<br>\nI tried to run gdb and when I back traced I found this<br>\nPyObject_Malloc (nbytes=&lt;optimized out) at ../objects/obmalloc.c 934</p>\n<p>How can I run Machine Translation example on a smaller dataset.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>", "body_text": "GitHub issues are for bugs / installation problems / feature requests.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nEnvironment info\nOperating System: AWS X2-large GPU instance. Ubuntu\nInstalled version of CUDA 7.5 and cuDNN: 7.5.18\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\". - 0.8.0\n\nIf installed from sources, provide the commit hash:\nSteps to reproduce\n\nRunning the translate.py script from tensorflow/modles/rnn/translate path\nIt downloads the files, unzip's the files\nprepares the data - > creates the vocabulary for English and French data -> tockenizes the data -> train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size)\nIn train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) there is a crash bacause of out of memory.\n\nWhat have you tried?\n\nTried to give smaller batch size. varied from 32,64 ...512\n\nlog\nsegmentation fault(core dumped)\nI tried to run gdb and when I back traced I found this\nPyObject_Malloc (nbytes=<optimized out) at ../objects/obmalloc.c 934\nHow can I run Machine Translation example on a smaller dataset.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).", "body": "![cuda](https://cloud.githubusercontent.com/assets/5551707/15954993/e761dda4-2efa-11e6-8d70-a36a8ad02239.png)\nGitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: AWS X2-large GPU instance. Ubuntu\n\nInstalled version of CUDA 7.5 and cuDNN: 7.5.18\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. - 0.8.0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. Running the translate.py script from tensorflow/modles/rnn/translate path\n2. It downloads the files, unzip's the files\n3. prepares the data - > creates the vocabulary for English and French data -> tockenizes the data -> train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) \n4. In train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) there is a crash bacause of out of memory.\n### What have you tried?\n1. Tried to give smaller batch size. varied from 32,64 ...512\n### log\n\nsegmentation fault(core dumped)\nI tried to run gdb and when I back traced I found this\nPyObject_Malloc (nbytes=<optimized out) at ../objects/obmalloc.c 934\n\nHow can I run Machine Translation example on a smaller dataset.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n"}