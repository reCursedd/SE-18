{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/155824615", "html_url": "https://github.com/tensorflow/tensorflow/issues/139#issuecomment-155824615", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/139", "id": 155824615, "node_id": "MDEyOklzc3VlQ29tbWVudDE1NTgyNDYxNQ==", "user": {"login": "rinuboney", "id": 1678100, "node_id": "MDQ6VXNlcjE2NzgxMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1678100?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rinuboney", "html_url": "https://github.com/rinuboney", "followers_url": "https://api.github.com/users/rinuboney/followers", "following_url": "https://api.github.com/users/rinuboney/following{/other_user}", "gists_url": "https://api.github.com/users/rinuboney/gists{/gist_id}", "starred_url": "https://api.github.com/users/rinuboney/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rinuboney/subscriptions", "organizations_url": "https://api.github.com/users/rinuboney/orgs", "repos_url": "https://api.github.com/users/rinuboney/repos", "events_url": "https://api.github.com/users/rinuboney/events{/privacy}", "received_events_url": "https://api.github.com/users/rinuboney/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-11T15:55:22Z", "updated_at": "2015-11-11T16:04:46Z", "author_association": "NONE", "body_html": "<p>I'm using this custom function right now:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">moments</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">axes</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n  <span class=\"pl-k\">with</span> tf.op_scope([x, axes], name, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>moments<span class=\"pl-pds\">\"</span></span>):\n    x <span class=\"pl-k\">=</span> tf.convert_to_tensor(x, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>)\n    divisor <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span>)\n    <span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(x.get_shape())):\n      <span class=\"pl-k\">if</span> d <span class=\"pl-k\">in</span> axes:\n        divisor <span class=\"pl-k\">*=</span> tf.to_float(tf.shape(x)[d])\n    divisor <span class=\"pl-k\">=</span> tf.inv(divisor, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>divisor<span class=\"pl-pds\">\"</span></span>)\n    axes <span class=\"pl-k\">=</span> tf.constant(axes, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>axes<span class=\"pl-pds\">\"</span></span>)\n    mean <span class=\"pl-k\">=</span> tf.mul(tf.reduce_sum(x, axes), divisor, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>mean<span class=\"pl-pds\">\"</span></span>)\n    var <span class=\"pl-k\">=</span> tf.mul(tf.reduce_sum(tf.square(x <span class=\"pl-k\">-</span> mean), axes),\n                       divisor, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>variance<span class=\"pl-pds\">\"</span></span>)\n    <span class=\"pl-k\">return</span> mean, var</pre></div>\n<p>I guess it is not trivial to access the function tf.shape within the <code>nn.moments</code> implementation</p>", "body_text": "I'm using this custom function right now:\ndef moments(x, axes, name=None):\n  with tf.op_scope([x, axes], name, \"moments\"):\n    x = tf.convert_to_tensor(x, name=\"x\")\n    divisor = tf.constant(1.0)\n    for d in xrange(len(x.get_shape())):\n      if d in axes:\n        divisor *= tf.to_float(tf.shape(x)[d])\n    divisor = tf.inv(divisor, name=\"divisor\")\n    axes = tf.constant(axes, name=\"axes\")\n    mean = tf.mul(tf.reduce_sum(x, axes), divisor, name=\"mean\")\n    var = tf.mul(tf.reduce_sum(tf.square(x - mean), axes),\n                       divisor, name=\"variance\")\n    return mean, var\nI guess it is not trivial to access the function tf.shape within the nn.moments implementation", "body": "I'm using this custom function right now:\n\n``` python\ndef moments(x, axes, name=None):\n  with tf.op_scope([x, axes], name, \"moments\"):\n    x = tf.convert_to_tensor(x, name=\"x\")\n    divisor = tf.constant(1.0)\n    for d in xrange(len(x.get_shape())):\n      if d in axes:\n        divisor *= tf.to_float(tf.shape(x)[d])\n    divisor = tf.inv(divisor, name=\"divisor\")\n    axes = tf.constant(axes, name=\"axes\")\n    mean = tf.mul(tf.reduce_sum(x, axes), divisor, name=\"mean\")\n    var = tf.mul(tf.reduce_sum(tf.square(x - mean), axes),\n                       divisor, name=\"variance\")\n    return mean, var\n```\n\nI guess it is not trivial to access the function tf.shape within the `nn.moments` implementation\n"}