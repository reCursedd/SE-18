{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/255788505", "html_url": "https://github.com/tensorflow/tensorflow/issues/4668#issuecomment-255788505", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4668", "id": 255788505, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NTc4ODUwNQ==", "user": {"login": "Fenugreek", "id": 3323801, "node_id": "MDQ6VXNlcjMzMjM4MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3323801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Fenugreek", "html_url": "https://github.com/Fenugreek", "followers_url": "https://api.github.com/users/Fenugreek/followers", "following_url": "https://api.github.com/users/Fenugreek/following{/other_user}", "gists_url": "https://api.github.com/users/Fenugreek/gists{/gist_id}", "starred_url": "https://api.github.com/users/Fenugreek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Fenugreek/subscriptions", "organizations_url": "https://api.github.com/users/Fenugreek/orgs", "repos_url": "https://api.github.com/users/Fenugreek/repos", "events_url": "https://api.github.com/users/Fenugreek/events{/privacy}", "received_events_url": "https://api.github.com/users/Fenugreek/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-24T16:16:45Z", "updated_at": "2016-10-24T16:16:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes. Here's code that worked for me. It requires three variables that need to be implemented, placed in &lt; &gt;, that I'll say more about below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">atrous_conv2d_transpose</span>(<span class=\"pl-smi\">value</span>, <span class=\"pl-smi\">filters</span>, <span class=\"pl-smi\">rate</span>, <span class=\"pl-smi\">padding</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    value <span class=\"pl-k\">=</span> array_ops.space_to_batch(<span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>value,\n                                     <span class=\"pl-v\">paddings</span><span class=\"pl-k\">=</span><span class=\"pl-k\">&lt;</span>batch_to_space_crop<span class=\"pl-k\">&gt;</span>,\n                                     <span class=\"pl-v\">block_size</span><span class=\"pl-k\">=</span>rate)\n\n    value <span class=\"pl-k\">=</span> tf.nn.conv2d_transpose(value, filters,\n                                   <span class=\"pl-k\">&lt;</span>output_shape<span class=\"pl-k\">&gt;</span>, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>],\n                                   <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n\n    value <span class=\"pl-k\">=</span> array_ops.batch_to_space(<span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>value,\n                                     <span class=\"pl-v\">crops</span><span class=\"pl-k\">=</span><span class=\"pl-k\">&lt;</span>space_to_batch_pad<span class=\"pl-k\">&gt;</span>,\n                                     <span class=\"pl-v\">block_size</span><span class=\"pl-k\">=</span>rate)\n    <span class=\"pl-k\">return</span> value</pre></div>\n<p>You'll notice that the steps above are the steps in <code>nn_ops.atrous_conv2d()</code> in reverse. In that code, the variables <code>batch_to_space_crop</code> and <code>space_to_batch_pad</code> are constructed. We can use the same construction (I did, and it worked). The other variable in the code excerpt above that needs implementation, <code>output_shape</code>, however, needs some new calculation. I hard-coded it to work in my specific case, and so have no code to offer for the general case.</p>\n<p>Also: I see in the code for <code>nn_ops.conv2d_transpose()</code> a call to <code>gen_nn_ops.conv2d_backprop_input(...)</code>. Not sure if it's better to implement/use something like that rather than above approach.</p>\n<p>Thanks.</p>", "body_text": "Yes. Here's code that worked for me. It requires three variables that need to be implemented, placed in < >, that I'll say more about below:\ndef atrous_conv2d_transpose(value, filters, rate, padding, name=None):\n    value = array_ops.space_to_batch(input=value,\n                                     paddings=<batch_to_space_crop>,\n                                     block_size=rate)\n\n    value = tf.nn.conv2d_transpose(value, filters,\n                                   <output_shape>, [1, 1, 1, 1],\n                                   padding='VALID', name=name)\n\n    value = array_ops.batch_to_space(input=value,\n                                     crops=<space_to_batch_pad>,\n                                     block_size=rate)\n    return value\nYou'll notice that the steps above are the steps in nn_ops.atrous_conv2d() in reverse. In that code, the variables batch_to_space_crop and space_to_batch_pad are constructed. We can use the same construction (I did, and it worked). The other variable in the code excerpt above that needs implementation, output_shape, however, needs some new calculation. I hard-coded it to work in my specific case, and so have no code to offer for the general case.\nAlso: I see in the code for nn_ops.conv2d_transpose() a call to gen_nn_ops.conv2d_backprop_input(...). Not sure if it's better to implement/use something like that rather than above approach.\nThanks.", "body": "Yes. Here's code that worked for me. It requires three variables that need to be implemented, placed in < >, that I'll say more about below:\n\n``` python\ndef atrous_conv2d_transpose(value, filters, rate, padding, name=None):\n    value = array_ops.space_to_batch(input=value,\n                                     paddings=<batch_to_space_crop>,\n                                     block_size=rate)\n\n    value = tf.nn.conv2d_transpose(value, filters,\n                                   <output_shape>, [1, 1, 1, 1],\n                                   padding='VALID', name=name)\n\n    value = array_ops.batch_to_space(input=value,\n                                     crops=<space_to_batch_pad>,\n                                     block_size=rate)\n    return value\n```\n\nYou'll notice that the steps above are the steps in `nn_ops.atrous_conv2d()` in reverse. In that code, the variables `batch_to_space_crop` and `space_to_batch_pad` are constructed. We can use the same construction (I did, and it worked). The other variable in the code excerpt above that needs implementation, `output_shape`, however, needs some new calculation. I hard-coded it to work in my specific case, and so have no code to offer for the general case.\n\nAlso: I see in the code for `nn_ops.conv2d_transpose()` a call to `gen_nn_ops.conv2d_backprop_input(...)`. Not sure if it's better to implement/use something like that rather than above approach.\n\nThanks.\n"}