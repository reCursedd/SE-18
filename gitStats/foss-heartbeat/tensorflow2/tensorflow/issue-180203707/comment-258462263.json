{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/258462263", "html_url": "https://github.com/tensorflow/tensorflow/issues/4668#issuecomment-258462263", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4668", "id": 258462263, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODQ2MjI2Mw==", "user": {"login": "Fenugreek", "id": 3323801, "node_id": "MDQ6VXNlcjMzMjM4MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3323801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Fenugreek", "html_url": "https://github.com/Fenugreek", "followers_url": "https://api.github.com/users/Fenugreek/followers", "following_url": "https://api.github.com/users/Fenugreek/following{/other_user}", "gists_url": "https://api.github.com/users/Fenugreek/gists{/gist_id}", "starred_url": "https://api.github.com/users/Fenugreek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Fenugreek/subscriptions", "organizations_url": "https://api.github.com/users/Fenugreek/orgs", "repos_url": "https://api.github.com/users/Fenugreek/repos", "events_url": "https://api.github.com/users/Fenugreek/events{/privacy}", "received_events_url": "https://api.github.com/users/Fenugreek/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-04T15:27:17Z", "updated_at": "2016-11-04T15:27:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6232317\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gpapan\">@gpapan</a> I didn't realize that, though I'd read that guide (to convolution arithmetic) you linked to before -- I looked at it again just now. Yes, if you set <code>tf.transpose(filters, perm=[1, 0])</code> as the kernel you can achieve the transpose.</p>\n<p>The one complication I see is for the most common case when the original convolution has <code>padding=\"SAME\"</code> (rather than <code>padding=\"VALID\"</code>), after the transpose you'll have values which contain some zero-padding. This zero-padding is easily stripped using array slicing, which I think has recently been implemented (including gradients), but at least I am not so confident of just writing it into my code without testing to check that I used the right indices for the slices.</p>\n<p>So maybe worth implementing anyway. I don't know if this approach (just calling atrous_conv2d with transposed filters, stripping any resulting zero-padding) is different from and/or faster than what <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4702353\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/guotong1988\">@guotong1988</a> did in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"186240624\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5300\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/5300/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/5300\">#5300</a>. Thanks.</p>", "body_text": "@gpapan I didn't realize that, though I'd read that guide (to convolution arithmetic) you linked to before -- I looked at it again just now. Yes, if you set tf.transpose(filters, perm=[1, 0]) as the kernel you can achieve the transpose.\nThe one complication I see is for the most common case when the original convolution has padding=\"SAME\" (rather than padding=\"VALID\"), after the transpose you'll have values which contain some zero-padding. This zero-padding is easily stripped using array slicing, which I think has recently been implemented (including gradients), but at least I am not so confident of just writing it into my code without testing to check that I used the right indices for the slices.\nSo maybe worth implementing anyway. I don't know if this approach (just calling atrous_conv2d with transposed filters, stripping any resulting zero-padding) is different from and/or faster than what @guotong1988 did in #5300. Thanks.", "body": "@gpapan I didn't realize that, though I'd read that guide (to convolution arithmetic) you linked to before -- I looked at it again just now. Yes, if you set `tf.transpose(filters, perm=[1, 0])` as the kernel you can achieve the transpose.\n\nThe one complication I see is for the most common case when the original convolution has `padding=\"SAME\"` (rather than `padding=\"VALID\"`), after the transpose you'll have values which contain some zero-padding. This zero-padding is easily stripped using array slicing, which I think has recently been implemented (including gradients), but at least I am not so confident of just writing it into my code without testing to check that I used the right indices for the slices.\n\nSo maybe worth implementing anyway. I don't know if this approach (just calling atrous_conv2d with transposed filters, stripping any resulting zero-padding) is different from and/or faster than what @guotong1988 did in #5300. Thanks.\n"}