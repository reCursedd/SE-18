{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21500", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21500/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21500/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21500/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21500", "id": 348931476, "node_id": "MDU6SXNzdWUzNDg5MzE0NzY=", "number": 21500, "title": "Memory error with tensorflow GPU", "user": {"login": "pathakrohit08", "id": 17154292, "node_id": "MDQ6VXNlcjE3MTU0Mjky", "avatar_url": "https://avatars2.githubusercontent.com/u/17154292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pathakrohit08", "html_url": "https://github.com/pathakrohit08", "followers_url": "https://api.github.com/users/pathakrohit08/followers", "following_url": "https://api.github.com/users/pathakrohit08/following{/other_user}", "gists_url": "https://api.github.com/users/pathakrohit08/gists{/gist_id}", "starred_url": "https://api.github.com/users/pathakrohit08/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pathakrohit08/subscriptions", "organizations_url": "https://api.github.com/users/pathakrohit08/orgs", "repos_url": "https://api.github.com/users/pathakrohit08/repos", "events_url": "https://api.github.com/users/pathakrohit08/events{/privacy}", "received_events_url": "https://api.github.com/users/pathakrohit08/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-08-08T23:53:19Z", "updated_at": "2018-08-23T05:17:10Z", "closed_at": "2018-08-23T05:17:10Z", "author_association": "NONE", "body_html": "<p>I have NVIDIA GPU Titan V installed on my remote machine and I am trying to do simple multi class lassification using CNN</p>\n<p><code>train_file = './data/csv_data.csv.zip'</code><br>\n<code>x_raw, y_raw, df, labels = data_helper.load_data_and_labels(train_file)</code></p>\n<p>here my csv_data zip file is 65MB .</p>\n<p><code>max_document_length = max([len(x.split(' ')) for x in x_raw])</code><br>\n<code>logging.info('The maximum length of all sentences: {}'.format(max_document_length))</code><br>\n<code>vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)</code><br>\n<code>x = np.array(list(vocab_processor.fit_transform(x_raw)))</code><br>\n<code>y = np.array(y_raw)</code></p>\n<p>I am getting memory error at<br>\n<code>vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)</code></p>\n<p>I think it is trying to load all the data in memory which is obviously a bad practice. How can I optimize this code to load it in the memory efficiently.</p>\n<p>Can anyone please point me to a detailed example or tutorial?</p>\n<p>Thanks</p>", "body_text": "I have NVIDIA GPU Titan V installed on my remote machine and I am trying to do simple multi class lassification using CNN\ntrain_file = './data/csv_data.csv.zip'\nx_raw, y_raw, df, labels = data_helper.load_data_and_labels(train_file)\nhere my csv_data zip file is 65MB .\nmax_document_length = max([len(x.split(' ')) for x in x_raw])\nlogging.info('The maximum length of all sentences: {}'.format(max_document_length))\nvocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\nx = np.array(list(vocab_processor.fit_transform(x_raw)))\ny = np.array(y_raw)\nI am getting memory error at\nvocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\nI think it is trying to load all the data in memory which is obviously a bad practice. How can I optimize this code to load it in the memory efficiently.\nCan anyone please point me to a detailed example or tutorial?\nThanks", "body": "I have NVIDIA GPU Titan V installed on my remote machine and I am trying to do simple multi class lassification using CNN\r\n\r\n\r\n`train_file = './data/csv_data.csv.zip'`\r\n `x_raw, y_raw, df, labels = data_helper.load_data_and_labels(train_file)`\r\n\r\n\r\nhere my csv_data zip file is 65MB .\r\n\r\n`max_document_length = max([len(x.split(' ')) for x in x_raw])`\r\n`logging.info('The maximum length of all sentences: {}'.format(max_document_length))`\r\n`vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)`\r\n`x = np.array(list(vocab_processor.fit_transform(x_raw)))`\r\n`y = np.array(y_raw)`\r\n\r\n\r\nI am getting memory error at \r\n`vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)`\r\n\r\nI think it is trying to load all the data in memory which is obviously a bad practice. How can I optimize this code to load it in the memory efficiently.\r\n\r\nCan anyone please point me to a detailed example or tutorial? \r\n\r\nThanks"}