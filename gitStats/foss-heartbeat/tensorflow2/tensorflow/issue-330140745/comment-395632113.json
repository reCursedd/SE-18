{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/395632113", "html_url": "https://github.com/tensorflow/tensorflow/pull/19828#issuecomment-395632113", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19828", "id": 395632113, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTYzMjExMw==", "user": {"login": "nestle1993", "id": 18111038, "node_id": "MDQ6VXNlcjE4MTExMDM4", "avatar_url": "https://avatars2.githubusercontent.com/u/18111038?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nestle1993", "html_url": "https://github.com/nestle1993", "followers_url": "https://api.github.com/users/nestle1993/followers", "following_url": "https://api.github.com/users/nestle1993/following{/other_user}", "gists_url": "https://api.github.com/users/nestle1993/gists{/gist_id}", "starred_url": "https://api.github.com/users/nestle1993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nestle1993/subscriptions", "organizations_url": "https://api.github.com/users/nestle1993/orgs", "repos_url": "https://api.github.com/users/nestle1993/repos", "events_url": "https://api.github.com/users/nestle1993/events{/privacy}", "received_events_url": "https://api.github.com/users/nestle1993/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-08T03:06:00Z", "updated_at": "2018-06-08T03:06:55Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a>  Thanks for your advice!</p>\n<p>Indeed, I got inf cost when I tested this function on my language model, which has about 80,000 classes in total, with <code>label_smoothing=0.2</code>, and I finally found that it was due to the <code>remove_accidental_hits</code> switch. When this switch is set <code>True</code>, the <code>true_logit</code> of some sampled classes will be set <code>-inf</code> in function <code>_compute_sampled_logits</code> if they are accidentally the target, which causes <code>sampled_loss</code> to be <code>inf</code> since <code>label</code> is not zero because of label smoothing.<br>\nThere are two possible solutions: 1) Considering that the total classes number is relative large, we can get approximate result even we turn off <code>remove_accidental_hits</code>. 2) Make sure that target will not be sampled.</p>\n<p>BTW, I got similar result on my language model with <code>label_smoothing=0.2</code> after I turned off <code>remove_accidental_hits</code>.</p>", "body_text": "@drpngx  Thanks for your advice!\nIndeed, I got inf cost when I tested this function on my language model, which has about 80,000 classes in total, with label_smoothing=0.2, and I finally found that it was due to the remove_accidental_hits switch. When this switch is set True, the true_logit of some sampled classes will be set -inf in function _compute_sampled_logits if they are accidentally the target, which causes sampled_loss to be inf since label is not zero because of label smoothing.\nThere are two possible solutions: 1) Considering that the total classes number is relative large, we can get approximate result even we turn off remove_accidental_hits. 2) Make sure that target will not be sampled.\nBTW, I got similar result on my language model with label_smoothing=0.2 after I turned off remove_accidental_hits.", "body": "@drpngx  Thanks for your advice!\r\n\r\nIndeed, I got inf cost when I tested this function on my language model, which has about 80,000 classes in total, with `label_smoothing=0.2`, and I finally found that it was due to the `remove_accidental_hits` switch. When this switch is set `True`, the `true_logit` of some sampled classes will be set `-inf` in function `_compute_sampled_logits` if they are accidentally the target, which causes `sampled_loss` to be `inf` since `label` is not zero because of label smoothing.\r\nThere are two possible solutions: 1) Considering that the total classes number is relative large, we can get approximate result even we turn off `remove_accidental_hits`. 2) Make sure that target will not be sampled.\r\n\r\nBTW, I got similar result on my language model with `label_smoothing=0.2` after I turned off `remove_accidental_hits`."}