{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260606873", "html_url": "https://github.com/tensorflow/tensorflow/issues/3527#issuecomment-260606873", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3527", "id": 260606873, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDYwNjg3Mw==", "user": {"login": "Nayana-ibm", "id": 20816038, "node_id": "MDQ6VXNlcjIwODE2MDM4", "avatar_url": "https://avatars0.githubusercontent.com/u/20816038?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nayana-ibm", "html_url": "https://github.com/Nayana-ibm", "followers_url": "https://api.github.com/users/Nayana-ibm/followers", "following_url": "https://api.github.com/users/Nayana-ibm/following{/other_user}", "gists_url": "https://api.github.com/users/Nayana-ibm/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nayana-ibm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nayana-ibm/subscriptions", "organizations_url": "https://api.github.com/users/Nayana-ibm/orgs", "repos_url": "https://api.github.com/users/Nayana-ibm/repos", "events_url": "https://api.github.com/users/Nayana-ibm/events{/privacy}", "received_events_url": "https://api.github.com/users/Nayana-ibm/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-15T10:36:34Z", "updated_at": "2016-11-15T10:36:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a><br>\nWe are currently debugging  <code>//tensorflow/python:string_to_hash_bucket_op_test</code> on s390x as well as x86 architecture.<br>\nWe could see that the mismatch of values is happening in <code>def create_op()</code>from <code>ops.py</code> .<br>\nWe could observe that the  op.outputs is populated after  <code>_add_op(self, op)</code> is being called:</p>\n<pre><code>ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n                    control_inputs=control_inputs, input_types=input_types,\n                    original_op=self._default_original_op, op_def=op_def)\n    if compute_shapes:\n      set_shapes_for_outputs(ret)\n-------------&gt; **here,  ret.outputs[0].eval() gives NotFoundError**\n    self._add_op(ret)\n-------------&gt; **here,  p ret.outputs[0].eval() gives array([3, 5, 7]) ( expected output is array[4,2,8])**\n\n    self._record_op_seen_by_control_dependencies(ret)\n</code></pre>\n<p>We tried debugging function _<code>add_op()</code> , however couldn't find where the <code>op.outputs</code> is getting populated.<br>\nAlso, we could see<code>self.lock</code> being used in this function. Is some other thread populating these values?</p>", "body_text": "@aselle @girving\nWe are currently debugging  //tensorflow/python:string_to_hash_bucket_op_test on s390x as well as x86 architecture.\nWe could see that the mismatch of values is happening in def create_op()from ops.py .\nWe could observe that the  op.outputs is populated after  _add_op(self, op) is being called:\nret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n                    control_inputs=control_inputs, input_types=input_types,\n                    original_op=self._default_original_op, op_def=op_def)\n    if compute_shapes:\n      set_shapes_for_outputs(ret)\n-------------> **here,  ret.outputs[0].eval() gives NotFoundError**\n    self._add_op(ret)\n-------------> **here,  p ret.outputs[0].eval() gives array([3, 5, 7]) ( expected output is array[4,2,8])**\n\n    self._record_op_seen_by_control_dependencies(ret)\n\nWe tried debugging function _add_op() , however couldn't find where the op.outputs is getting populated.\nAlso, we could seeself.lock being used in this function. Is some other thread populating these values?", "body": "@aselle @girving  \nWe are currently debugging  `//tensorflow/python:string_to_hash_bucket_op_test` on s390x as well as x86 architecture.\nWe could see that the mismatch of values is happening in `def create_op()`from `ops.py` .\nWe could observe that the  op.outputs is populated after  `_add_op(self, op)` is being called:\n\n```\nret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n                    control_inputs=control_inputs, input_types=input_types,\n                    original_op=self._default_original_op, op_def=op_def)\n    if compute_shapes:\n      set_shapes_for_outputs(ret)\n-------------> **here,  ret.outputs[0].eval() gives NotFoundError**\n    self._add_op(ret)\n-------------> **here,  p ret.outputs[0].eval() gives array([3, 5, 7]) ( expected output is array[4,2,8])**\n\n    self._record_op_seen_by_control_dependencies(ret)\n```\n\nWe tried debugging function _`add_op()` , however couldn't find where the `op.outputs` is getting populated.\nAlso, we could see`self.lock` being used in this function. Is some other thread populating these values?\n"}