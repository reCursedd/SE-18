{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263442628", "html_url": "https://github.com/tensorflow/tensorflow/issues/5876#issuecomment-263442628", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5876", "id": 263442628, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzQ0MjYyOA==", "user": {"login": "goodfeli", "id": 387866, "node_id": "MDQ6VXNlcjM4Nzg2Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/387866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goodfeli", "html_url": "https://github.com/goodfeli", "followers_url": "https://api.github.com/users/goodfeli/followers", "following_url": "https://api.github.com/users/goodfeli/following{/other_user}", "gists_url": "https://api.github.com/users/goodfeli/gists{/gist_id}", "starred_url": "https://api.github.com/users/goodfeli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goodfeli/subscriptions", "organizations_url": "https://api.github.com/users/goodfeli/orgs", "repos_url": "https://api.github.com/users/goodfeli/repos", "events_url": "https://api.github.com/users/goodfeli/events{/privacy}", "received_events_url": "https://api.github.com/users/goodfeli/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-29T00:49:06Z", "updated_at": "2016-11-29T00:49:06Z", "author_association": "NONE", "body_html": "<p>I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=966348\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tillahoffmann\">@tillahoffmann</a> that this sounds like the gradient of <code>sparse_softmax_cross_entropy_with_logits</code> does not implement the gradient correctly.</p>\n<p>If this is indeed caused by an op failing to <em>implement</em> the gradient, it seems like tf.gradients ought to raise a NotImplementedError or issue some other error message, rather than silently returning numerically incorrect values.</p>\n<p>Vincent Dumoulin and Alex Kurakin have both told me they have had trouble with ops silently returning zero as their second derivative in the past.</p>", "body_text": "I agree with @tillahoffmann that this sounds like the gradient of sparse_softmax_cross_entropy_with_logits does not implement the gradient correctly.\nIf this is indeed caused by an op failing to implement the gradient, it seems like tf.gradients ought to raise a NotImplementedError or issue some other error message, rather than silently returning numerically incorrect values.\nVincent Dumoulin and Alex Kurakin have both told me they have had trouble with ops silently returning zero as their second derivative in the past.", "body": "I agree with @tillahoffmann that this sounds like the gradient of `sparse_softmax_cross_entropy_with_logits` does not implement the gradient correctly.\r\n\r\nIf this is indeed caused by an op failing to *implement* the gradient, it seems like tf.gradients ought to raise a NotImplementedError or issue some other error message, rather than silently returning numerically incorrect values.\r\n\r\nVincent Dumoulin and Alex Kurakin have both told me they have had trouble with ops silently returning zero as their second derivative in the past."}