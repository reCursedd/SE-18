{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15626", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15626/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15626/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15626/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15626", "id": 284452301, "node_id": "MDU6SXNzdWUyODQ0NTIzMDE=", "number": 15626, "title": "TensorFlowInferenceInterface's feed method - a performance bottleneck", "user": {"login": "theyonibomber", "id": 711216, "node_id": "MDQ6VXNlcjcxMTIxNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/711216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/theyonibomber", "html_url": "https://github.com/theyonibomber", "followers_url": "https://api.github.com/users/theyonibomber/followers", "following_url": "https://api.github.com/users/theyonibomber/following{/other_user}", "gists_url": "https://api.github.com/users/theyonibomber/gists{/gist_id}", "starred_url": "https://api.github.com/users/theyonibomber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/theyonibomber/subscriptions", "organizations_url": "https://api.github.com/users/theyonibomber/orgs", "repos_url": "https://api.github.com/users/theyonibomber/repos", "events_url": "https://api.github.com/users/theyonibomber/events{/privacy}", "received_events_url": "https://api.github.com/users/theyonibomber/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-12-25T14:44:51Z", "updated_at": "2018-11-14T19:14:24Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Compiled on macos 10.13.2, Observed on Android</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/ab0fcaceda001825654424bf18e8a8e0f8d39df2/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/ab0fcaceda001825654424bf18e8a8e0f8d39df2\"><tt>ab0fcac</tt></a> on master - between release of 1.4.0 and 1.4.1 (compared to 1.0.1)</li>\n<li><strong>Python version</strong>: N/A (java android code)</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.7.0-homebrew</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Apple LLVM version 9.0.0 (clang-900.0.39.2)</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: Observed on a Huawei Nexus 6P</li>\n<li><strong>Exact command to reproduce</strong>: N/A (java android code)</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Following the move to Java API in commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/1a9769dc79fdd27c347633df210ff64f48de8d07/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/1a9769dc79fdd27c347633df210ff64f48de8d07\"><tt>1a9769d</tt></a>, it seems that it is very ineffective to feed nodes.<br>\nI am feeding my model an input array of about 1100 floats, and when I sample CPU usage using CPU Profiler on Android Studio (Instrumented) it seems that the feed method takes ~x4 time than running the inference. If I leave everything the same but I use android libs compiled in tensorflow 1.0.1 CPU time of feed method (used to be fillNodeFloat) becomes negligible.<br>\nIt seems that putting a float array into the Tensor's FloatBuffer is a very costly operation.</p>\n<h3>Source code / logs</h3>\n<p><strong>TF 1.4.0:</strong><br>\nRelevant inference code:</p>\n<pre><code>tensorflow.feed(INPUT_NODE_NAME, input, shape);\ntensorflow.run(OUTPUT_NAMES);\ntensorflow.fetch(OUTPUT_NAMES[0], output);\n</code></pre>\n<p>Screenshot of CPU Profiler's call chart: <a href=\"https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0</a><br>\nScreenshot of CPU Profiler's top-down breakdown of the 2 methods: <a href=\"https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0</a></p>\n<p><strong>TF 1.0.1:</strong><br>\nRelevant inference code:</p>\n<pre><code>tensorflow.fillNodeFloat(INPUT_NODE_NAME, shape, input);\ntensorflow.runInference(OUTPUT_NAMES);\ntensorflow.readNodeFloat(OUTPUT_NAMES[0], output);\n</code></pre>\n<p>Screenshot of CPU Profiler's call chart: <a href=\"https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0</a><br>\nScreenshot of CPU Profiler's bottom-up breakdown of the 2 methods: <a href=\"https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Compiled on macos 10.13.2, Observed on Android\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): commit ab0fcac on master - between release of 1.4.0 and 1.4.1 (compared to 1.0.1)\nPython version: N/A (java android code)\nBazel version (if compiling from source): 0.7.0-homebrew\nGCC/Compiler version (if compiling from source): Apple LLVM version 9.0.0 (clang-900.0.39.2)\nCUDA/cuDNN version: N/A\nGPU model and memory: Observed on a Huawei Nexus 6P\nExact command to reproduce: N/A (java android code)\n\nDescribe the problem\nFollowing the move to Java API in commit 1a9769d, it seems that it is very ineffective to feed nodes.\nI am feeding my model an input array of about 1100 floats, and when I sample CPU usage using CPU Profiler on Android Studio (Instrumented) it seems that the feed method takes ~x4 time than running the inference. If I leave everything the same but I use android libs compiled in tensorflow 1.0.1 CPU time of feed method (used to be fillNodeFloat) becomes negligible.\nIt seems that putting a float array into the Tensor's FloatBuffer is a very costly operation.\nSource code / logs\nTF 1.4.0:\nRelevant inference code:\ntensorflow.feed(INPUT_NODE_NAME, input, shape);\ntensorflow.run(OUTPUT_NAMES);\ntensorflow.fetch(OUTPUT_NAMES[0], output);\n\nScreenshot of CPU Profiler's call chart: https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0\nScreenshot of CPU Profiler's top-down breakdown of the 2 methods: https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0\nTF 1.0.1:\nRelevant inference code:\ntensorflow.fillNodeFloat(INPUT_NODE_NAME, shape, input);\ntensorflow.runInference(OUTPUT_NAMES);\ntensorflow.readNodeFloat(OUTPUT_NAMES[0], output);\n\nScreenshot of CPU Profiler's call chart: https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0\nScreenshot of CPU Profiler's bottom-up breakdown of the 2 methods: https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Compiled on macos 10.13.2, Observed on Android \r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: commit ab0fcaceda on master - between release of 1.4.0 and 1.4.1 (compared to 1.0.1)\r\n- **Python version**: N/A (java android code)\r\n- **Bazel version (if compiling from source)**: 0.7.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: Observed on a Huawei Nexus 6P\r\n- **Exact command to reproduce**: N/A (java android code)\r\n\r\n### Describe the problem\r\nFollowing the move to Java API in commit 1a9769dc79fdd27c347633df210ff64f48de8d07, it seems that it is very ineffective to feed nodes.\r\nI am feeding my model an input array of about 1100 floats, and when I sample CPU usage using CPU Profiler on Android Studio (Instrumented) it seems that the feed method takes ~x4 time than running the inference. If I leave everything the same but I use android libs compiled in tensorflow 1.0.1 CPU time of feed method (used to be fillNodeFloat) becomes negligible.\r\nIt seems that putting a float array into the Tensor's FloatBuffer is a very costly operation.\r\n\r\n### Source code / logs\r\n**TF 1.4.0:**\r\nRelevant inference code:\r\n```\r\ntensorflow.feed(INPUT_NODE_NAME, input, shape);\r\ntensorflow.run(OUTPUT_NAMES);\r\ntensorflow.fetch(OUTPUT_NAMES[0], output);\r\n```\r\n\r\nScreenshot of CPU Profiler's call chart: https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0\r\nScreenshot of CPU Profiler's top-down breakdown of the 2 methods: https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0\r\n\r\n**TF 1.0.1:**\r\nRelevant inference code:\r\n```\r\ntensorflow.fillNodeFloat(INPUT_NODE_NAME, shape, input);\r\ntensorflow.runInference(OUTPUT_NAMES);\r\ntensorflow.readNodeFloat(OUTPUT_NAMES[0], output);\r\n```\r\n\r\nScreenshot of CPU Profiler's call chart: https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0\r\nScreenshot of CPU Profiler's bottom-up breakdown of the 2 methods: https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0"}