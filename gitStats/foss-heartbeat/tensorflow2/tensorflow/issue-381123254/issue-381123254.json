{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23770", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23770/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23770/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23770/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23770", "id": 381123254, "node_id": "MDU6SXNzdWUzODExMjMyNTQ=", "number": 23770, "title": "The distribute strategy is not compatible with tf.contrib.slim.batch_norm() and tf.contrib.layers.batch_norm()", "user": {"login": "mzhaoshuai", "id": 22476764, "node_id": "MDQ6VXNlcjIyNDc2NzY0", "avatar_url": "https://avatars1.githubusercontent.com/u/22476764?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mzhaoshuai", "html_url": "https://github.com/mzhaoshuai", "followers_url": "https://api.github.com/users/mzhaoshuai/followers", "following_url": "https://api.github.com/users/mzhaoshuai/following{/other_user}", "gists_url": "https://api.github.com/users/mzhaoshuai/gists{/gist_id}", "starred_url": "https://api.github.com/users/mzhaoshuai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mzhaoshuai/subscriptions", "organizations_url": "https://api.github.com/users/mzhaoshuai/orgs", "repos_url": "https://api.github.com/users/mzhaoshuai/repos", "events_url": "https://api.github.com/users/mzhaoshuai/events{/privacy}", "received_events_url": "https://api.github.com/users/mzhaoshuai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "josh11b", "id": 15258583, "node_id": "MDQ6VXNlcjE1MjU4NTgz", "avatar_url": "https://avatars0.githubusercontent.com/u/15258583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josh11b", "html_url": "https://github.com/josh11b", "followers_url": "https://api.github.com/users/josh11b/followers", "following_url": "https://api.github.com/users/josh11b/following{/other_user}", "gists_url": "https://api.github.com/users/josh11b/gists{/gist_id}", "starred_url": "https://api.github.com/users/josh11b/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josh11b/subscriptions", "organizations_url": "https://api.github.com/users/josh11b/orgs", "repos_url": "https://api.github.com/users/josh11b/repos", "events_url": "https://api.github.com/users/josh11b/events{/privacy}", "received_events_url": "https://api.github.com/users/josh11b/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-11-15T11:41:53Z", "updated_at": "2018-11-21T06:47:14Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): <strong><em>no</em></strong></li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): <em><strong>Ubuntu 16.04.5 LTS</strong></em></li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:<strong><em>no</em></strong></li>\n<li>TensorFlow installed from (source or binary):<strong><em>binary</em></strong></li>\n<li>TensorFlow version (use command below):<strong><em>1.12.0</em></strong></li>\n<li>Python version: <strong><em>Python 3.5.2</em></strong></li>\n<li>Bazel version (if compiling from source): <em><strong>None</strong></em></li>\n<li>GCC/Compiler version (if compiling from source):  <strong><em>5.4.0</em></strong></li>\n<li>CUDA/cuDNN version: <strong><em>cuda-9.0.176/cudnn-7.2.1</em></strong></li>\n<li>GPU model and memory: <strong><em>2 same GTX Titan X (Pascal), 12GB</em></strong></li>\n</ul>\n<p>I just use the offical docker image of the tensorflow, the tag is <code>1.12.0-devel-gpu-py3</code></p>\n<p><strong>Problem</strong></p>\n<p>The code is shown below</p>\n<pre><code>#coding=utf-8\n\nimport tensorflow as tf\nimport numpy as np\nimport argparse\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--num_gpus', type=int, default=2,\n\t\t\t\t\t\thelp='The number of the GPUs.')\nFLAGS, unparsed = parser.parse_known_args()\n\n\ndef input_fn():\n    return (\n        tf.data.Dataset.from_tensor_slices([0])\n        .map(lambda _: tf.random_uniform([1], 0, np.pi * 2))\n        .map(lambda x: (x, tf.sin(x)))\n        .repeat()\n        .batch(10)\n    )\n\ndef model_fn(features, labels, mode):\n    net = tf.layers.dense(features, units=20)\n    net = tf.nn.tanh(net)\n    \n    #net = tf.contrib.layers.batch_norm(net)\n    net = tf.contrib.slim.batch_norm(net)\n    #net = tf.keras.layers.BatchNormalization()(net)\n    #net = tf.layers.batch_normalization(inputs=net)\n\n    net = tf.layers.dense(net, units=20)\n    net = tf.nn.tanh(net)\n    output = tf.layers.dense(net, units=1)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(tf.pow(output - labels, 2))\n        loss = tf.identity(loss, name='loss')\n        train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\n\nsession_config = tf.ConfigProto(allow_soft_placement=True,\n                                    gpu_options=tf.GPUOptions(allow_growth=True, \n                                                force_gpu_compatible=True))\ndistribution = tf.contrib.distribute.MirroredStrategy(num_gpus=FLAGS.num_gpus)\nconfig = tf.estimator.RunConfig(keep_checkpoint_max=0, \n\t\t\t\t\t\t\t\ttrain_distribute=distribution)\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\ntf.logging.set_verbosity(tf.logging.INFO)\ntensors_to_log = {'loss':'loss'}\nlogging_hook = tf.train.LoggingTensorHook(\n        \t\t\ttensors=tensors_to_log, every_n_iter=100)\ntrain_hooks=[logging_hook]\nprint('tensorflow version: %s' % tf.__version__)\nestimator.train(input_fn=input_fn, steps=1000, hooks=train_hooks)\n</code></pre>\n<p>When use <code>tf.contrib.layers.batch_norm</code>  and <code>tf.contrib.slim.batch_norm</code> will raise error</p>\n<pre><code> name: GeForce GTX TITAN X, pci bus id: 0000:18:00.0, compute capability: 5.2)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"estimator_multi_gpu.py\", line 27, in model_fn\n    net = tf.contrib.slim.batch_norm(net)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\n    scope=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\n    is_training, _delay_updates, moving_vars_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\n    return static_cond(pred_value, fn1, fn2)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\n    return fn1()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\n    with ops.colocate_with(variable):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\n</code></pre>\n<p>But if I use <code>tf.keras.layers.BatchNormalization()(net)</code> or   <code>tf.layers.batch_normalization(inputs=net)</code>,<br>\nit is totally OK.</p>\n<p>I see the source code of the <code>tf.layers.batch_normalization</code> and find it is inherited form <code>keras.layers.BatchNormalization</code></p>\n<pre><code>from tensorflow.python.keras import layers as keras_layers\nfrom tensorflow.python.layers import base\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.util.tf_export import tf_export\n\n@tf_export('layers.BatchNormalization')\nclass BatchNormalization(keras_layers.BatchNormalization, base.Layer):\n</code></pre>\n<p>And I also find some similar issues<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"337830693\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20509\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/20509/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/20509\">#20509</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"341831336\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20874\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/20874/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/20874\">#20874</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"355493584\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/21968\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/21968/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/21968\">#21968</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"361980374\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22399\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/22399/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/22399\">#22399</a></p>\n<p><em><strong>There are many pretrained models in the model zoo of <code>slim</code>, the bn layer are all not compatible with the distribute stratege. It is not convinient for us to use them in other tasks with <code>tf.estimator</code>.</strong></em></p>\n<p><strong>Other info / logs</strong><br>\nThere are also two samll problems in the docker images....</p>\n<p><strong><em>ONE:</em></strong></p>\n<pre><code>__new__() got an unexpected keyword argument 'serialized_options'\n</code></pre>\n<p>I solvd it by</p>\n<pre><code>RUN pip3 install --upgrade pip\n</code></pre>\n<p>when build the image.</p>\n<p>The <code>pip install -U protobuf </code> did not work.</p>\n<p><strong><em>TWO:</em></strong></p>\n<pre><code>\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpggc6_3sr/model.ckpt.\nINFO:tensorflow:model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/GFPVUUB6DIRSEA556PJ7UZSB2U:/var/lib/docker/overlay2/l/Z7PKFCBJ2NCRWLDUMR7HOGXHY5:/var/lib/docker/overlay2/l/XJZAHQOGE7RXOAHTAKELNSYBZ5:/var/lib/docker/overlay2/l/ESG4TTNOTM5ZINQ5O4JCYNFODB:/var/lib/docker/overlay2/l/6ZQZQCRBLVJTIVAKYNIA2VNCNX:/var/lib/docker/overlay2/l/ZIWP422R2WQJXJQWA6BWTKSVP2:/var/lib/docker/overlay2/l/EZJIAHDCQ5P5GASJZR3GCECEE6:/var/lib/docker/overlay2/l/OA2WSFXRNJQI36B7ZILMTVTD5V:/var/lib/docker/overlay2/l/XITXCQNT5YIY7'\nUnexpected end of /proc/mounts line `YSSGYLTAEXMQX:/var/lib/docker/overlay2/l/EHORMZU5A6H3H6NAL34XTIYBEA:/var/lib/docker/overlay2/l/E34DRW27EHWOG6HEQCYM2LKYJX:/var/lib/docker/overlay2/l/Y4SABJDSTVMRHZ2SC6QYSK4NP6:/var/lib/docker/overlay2/l/BWHO3NPMOZYCZ33PIH4XXQH3Z6:/var/lib/docker/overlay2/l/YLLBXOSS6TVCINXJNKTZX7J6PQ:/var/lib/docker/overlay2/l/QQ2FBR7QT4NFNYR4UZUXOBD2K3:/var/lib/docker/overlay2/l/SSP6MK4IQCUV2N5DSY5BO4EZO7:/var/lib/docker/overlay2/l/XUONJPPZG5ANA2ELQECHOIY7KU:/var/lib/docker/overlay2/l/ZOCEMSU7RIV6OH6QZNTKKIGACB:/var/lib/do'\n</code></pre>\n<p>It seems that this is harmless.<br>\n<a href=\"https://stackoverflow.com/questions/46138549/docker-openmpi-and-unexpected-end-of-proc-mounts-line\" rel=\"nofollow\">https://stackoverflow.com/questions/46138549/docker-openmpi-and-unexpected-end-of-proc-mounts-line</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5 LTS\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.12.0\nPython version: Python 3.5.2\nBazel version (if compiling from source): None\nGCC/Compiler version (if compiling from source):  5.4.0\nCUDA/cuDNN version: cuda-9.0.176/cudnn-7.2.1\nGPU model and memory: 2 same GTX Titan X (Pascal), 12GB\n\nI just use the offical docker image of the tensorflow, the tag is 1.12.0-devel-gpu-py3\nProblem\nThe code is shown below\n#coding=utf-8\n\nimport tensorflow as tf\nimport numpy as np\nimport argparse\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--num_gpus', type=int, default=2,\n\t\t\t\t\t\thelp='The number of the GPUs.')\nFLAGS, unparsed = parser.parse_known_args()\n\n\ndef input_fn():\n    return (\n        tf.data.Dataset.from_tensor_slices([0])\n        .map(lambda _: tf.random_uniform([1], 0, np.pi * 2))\n        .map(lambda x: (x, tf.sin(x)))\n        .repeat()\n        .batch(10)\n    )\n\ndef model_fn(features, labels, mode):\n    net = tf.layers.dense(features, units=20)\n    net = tf.nn.tanh(net)\n    \n    #net = tf.contrib.layers.batch_norm(net)\n    net = tf.contrib.slim.batch_norm(net)\n    #net = tf.keras.layers.BatchNormalization()(net)\n    #net = tf.layers.batch_normalization(inputs=net)\n\n    net = tf.layers.dense(net, units=20)\n    net = tf.nn.tanh(net)\n    output = tf.layers.dense(net, units=1)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(tf.pow(output - labels, 2))\n        loss = tf.identity(loss, name='loss')\n        train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\n\nsession_config = tf.ConfigProto(allow_soft_placement=True,\n                                    gpu_options=tf.GPUOptions(allow_growth=True, \n                                                force_gpu_compatible=True))\ndistribution = tf.contrib.distribute.MirroredStrategy(num_gpus=FLAGS.num_gpus)\nconfig = tf.estimator.RunConfig(keep_checkpoint_max=0, \n\t\t\t\t\t\t\t\ttrain_distribute=distribution)\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\ntf.logging.set_verbosity(tf.logging.INFO)\ntensors_to_log = {'loss':'loss'}\nlogging_hook = tf.train.LoggingTensorHook(\n        \t\t\ttensors=tensors_to_log, every_n_iter=100)\ntrain_hooks=[logging_hook]\nprint('tensorflow version: %s' % tf.__version__)\nestimator.train(input_fn=input_fn, steps=1000, hooks=train_hooks)\n\nWhen use tf.contrib.layers.batch_norm  and tf.contrib.slim.batch_norm will raise error\n name: GeForce GTX TITAN X, pci bus id: 0000:18:00.0, compute capability: 5.2)\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"estimator_multi_gpu.py\", line 27, in model_fn\n    net = tf.contrib.slim.batch_norm(net)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\n    scope=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\n    is_training, _delay_updates, moving_vars_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\n    return static_cond(pred_value, fn1, fn2)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\n    return fn1()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\n    with ops.colocate_with(variable):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\n    with self.colocate_with(op, ignore_existing):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\n    value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\n    assert not as_ref\nAssertionError\n\nBut if I use tf.keras.layers.BatchNormalization()(net) or   tf.layers.batch_normalization(inputs=net),\nit is totally OK.\nI see the source code of the tf.layers.batch_normalization and find it is inherited form keras.layers.BatchNormalization\nfrom tensorflow.python.keras import layers as keras_layers\nfrom tensorflow.python.layers import base\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.util.tf_export import tf_export\n\n@tf_export('layers.BatchNormalization')\nclass BatchNormalization(keras_layers.BatchNormalization, base.Layer):\n\nAnd I also find some similar issues\n#20509\n#20874\n#21968\n#22399\nThere are many pretrained models in the model zoo of slim, the bn layer are all not compatible with the distribute stratege. It is not convinient for us to use them in other tasks with tf.estimator.\nOther info / logs\nThere are also two samll problems in the docker images....\nONE:\n__new__() got an unexpected keyword argument 'serialized_options'\n\nI solvd it by\nRUN pip3 install --upgrade pip\n\nwhen build the image.\nThe pip install -U protobuf  did not work.\nTWO:\n\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpggc6_3sr/model.ckpt.\nINFO:tensorflow:model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/GFPVUUB6DIRSEA556PJ7UZSB2U:/var/lib/docker/overlay2/l/Z7PKFCBJ2NCRWLDUMR7HOGXHY5:/var/lib/docker/overlay2/l/XJZAHQOGE7RXOAHTAKELNSYBZ5:/var/lib/docker/overlay2/l/ESG4TTNOTM5ZINQ5O4JCYNFODB:/var/lib/docker/overlay2/l/6ZQZQCRBLVJTIVAKYNIA2VNCNX:/var/lib/docker/overlay2/l/ZIWP422R2WQJXJQWA6BWTKSVP2:/var/lib/docker/overlay2/l/EZJIAHDCQ5P5GASJZR3GCECEE6:/var/lib/docker/overlay2/l/OA2WSFXRNJQI36B7ZILMTVTD5V:/var/lib/docker/overlay2/l/XITXCQNT5YIY7'\nUnexpected end of /proc/mounts line `YSSGYLTAEXMQX:/var/lib/docker/overlay2/l/EHORMZU5A6H3H6NAL34XTIYBEA:/var/lib/docker/overlay2/l/E34DRW27EHWOG6HEQCYM2LKYJX:/var/lib/docker/overlay2/l/Y4SABJDSTVMRHZ2SC6QYSK4NP6:/var/lib/docker/overlay2/l/BWHO3NPMOZYCZ33PIH4XXQH3Z6:/var/lib/docker/overlay2/l/YLLBXOSS6TVCINXJNKTZX7J6PQ:/var/lib/docker/overlay2/l/QQ2FBR7QT4NFNYR4UZUXOBD2K3:/var/lib/docker/overlay2/l/SSP6MK4IQCUV2N5DSY5BO4EZO7:/var/lib/docker/overlay2/l/XUONJPPZG5ANA2ELQECHOIY7KU:/var/lib/docker/overlay2/l/ZOCEMSU7RIV6OH6QZNTKKIGACB:/var/lib/do'\n\nIt seems that this is harmless.\nhttps://stackoverflow.com/questions/46138549/docker-openmpi-and-unexpected-end-of-proc-mounts-line", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **_no_**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): _**Ubuntu 16.04.5 LTS**_\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:**_no_**\r\n- TensorFlow installed from (source or binary):**_binary_**\r\n- TensorFlow version (use command below):**_1.12.0_**\r\n- Python version: **_Python 3.5.2_**\r\n- Bazel version (if compiling from source): _**None**_\r\n- GCC/Compiler version (if compiling from source):  **_5.4.0_**\r\n- CUDA/cuDNN version: **_cuda-9.0.176/cudnn-7.2.1_**\r\n- GPU model and memory: **_2 same GTX Titan X (Pascal), 12GB_** \r\n\r\nI just use the offical docker image of the tensorflow, the tag is `1.12.0-devel-gpu-py3`\r\n\r\n**Problem**\r\n\r\nThe code is shown below\r\n```\r\n#coding=utf-8\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport argparse\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--num_gpus', type=int, default=2,\r\n\t\t\t\t\t\thelp='The number of the GPUs.')\r\nFLAGS, unparsed = parser.parse_known_args()\r\n\r\n\r\ndef input_fn():\r\n    return (\r\n        tf.data.Dataset.from_tensor_slices([0])\r\n        .map(lambda _: tf.random_uniform([1], 0, np.pi * 2))\r\n        .map(lambda x: (x, tf.sin(x)))\r\n        .repeat()\r\n        .batch(10)\r\n    )\r\n\r\ndef model_fn(features, labels, mode):\r\n    net = tf.layers.dense(features, units=20)\r\n    net = tf.nn.tanh(net)\r\n    \r\n    #net = tf.contrib.layers.batch_norm(net)\r\n    net = tf.contrib.slim.batch_norm(net)\r\n    #net = tf.keras.layers.BatchNormalization()(net)\r\n    #net = tf.layers.batch_normalization(inputs=net)\r\n\r\n    net = tf.layers.dense(net, units=20)\r\n    net = tf.nn.tanh(net)\r\n    output = tf.layers.dense(net, units=1)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        loss = tf.reduce_mean(tf.pow(output - labels, 2))\r\n        loss = tf.identity(loss, name='loss')\r\n        train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n\r\nsession_config = tf.ConfigProto(allow_soft_placement=True,\r\n                                    gpu_options=tf.GPUOptions(allow_growth=True, \r\n                                                force_gpu_compatible=True))\r\ndistribution = tf.contrib.distribute.MirroredStrategy(num_gpus=FLAGS.num_gpus)\r\nconfig = tf.estimator.RunConfig(keep_checkpoint_max=0, \r\n\t\t\t\t\t\t\t\ttrain_distribute=distribution)\r\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\ntensors_to_log = {'loss':'loss'}\r\nlogging_hook = tf.train.LoggingTensorHook(\r\n        \t\t\ttensors=tensors_to_log, every_n_iter=100)\r\ntrain_hooks=[logging_hook]\r\nprint('tensorflow version: %s' % tf.__version__)\r\nestimator.train(input_fn=input_fn, steps=1000, hooks=train_hooks)\r\n```\r\n\r\nWhen use `tf.contrib.layers.batch_norm`  and `tf.contrib.slim.batch_norm` will raise error\r\n```\r\n name: GeForce GTX TITAN X, pci bus id: 0000:18:00.0, compute capability: 5.2)\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Error reported to Coordinator:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"estimator_multi_gpu.py\", line 27, in model_fn\r\n    net = tf.contrib.slim.batch_norm(net)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 596, in batch_norm\r\n    scope=scope)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 416, in _fused_batch_norm\r\n    is_training, _delay_updates, moving_vars_fn)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 214, in smart_cond\r\n    return static_cond(pred_value, fn1, fn2)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/utils.py\", line 192, in static_cond\r\n    return fn1()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 410, in _delay_updates\r\n    moving_mean, mean, decay, zero_debias=zero_debias_moving_mean)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/moving_averages.py\", line 84, in assign_moving_average\r\n    with ops.colocate_with(variable):\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4094, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 4146, in colocate_with\r\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1307, in internal_convert_to_tensor_or_indexed_slices\r\n    value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 439, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\n```\r\n\r\nBut if I use `tf.keras.layers.BatchNormalization()(net)` or   `tf.layers.batch_normalization(inputs=net)`,\r\nit is totally OK.\r\n\r\nI see the source code of the `tf.layers.batch_normalization` and find it is inherited form `keras.layers.BatchNormalization`\r\n```\r\nfrom tensorflow.python.keras import layers as keras_layers\r\nfrom tensorflow.python.layers import base\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.util.tf_export import tf_export\r\n\r\n@tf_export('layers.BatchNormalization')\r\nclass BatchNormalization(keras_layers.BatchNormalization, base.Layer):\r\n```\r\nAnd I also find some similar issues\r\nhttps://github.com/tensorflow/tensorflow/issues/20509\r\nhttps://github.com/tensorflow/tensorflow/issues/20874\r\nhttps://github.com/tensorflow/tensorflow/issues/21968\r\nhttps://github.com/tensorflow/tensorflow/issues/22399\r\n\r\n_**There are many pretrained models in the model zoo of `slim`, the bn layer are all not compatible with the distribute stratege. It is not convinient for us to use them in other tasks with `tf.estimator`.**_\r\n\r\n\r\n**Other info / logs**\r\nThere are also two samll problems in the docker images....\r\n\r\n**_ONE:_**\r\n```\r\n__new__() got an unexpected keyword argument 'serialized_options'\r\n```\r\nI solvd it by \r\n```\r\nRUN pip3 install --upgrade pip\r\n```\r\nwhen build the image.\r\n\r\nThe `pip install -U protobuf ` did not work.\r\n\r\n**_TWO:_**\r\n```\r\n\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpggc6_3sr/model.ckpt.\r\nINFO:tensorflow:model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\r\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/GFPVUUB6DIRSEA556PJ7UZSB2U:/var/lib/docker/overlay2/l/Z7PKFCBJ2NCRWLDUMR7HOGXHY5:/var/lib/docker/overlay2/l/XJZAHQOGE7RXOAHTAKELNSYBZ5:/var/lib/docker/overlay2/l/ESG4TTNOTM5ZINQ5O4JCYNFODB:/var/lib/docker/overlay2/l/6ZQZQCRBLVJTIVAKYNIA2VNCNX:/var/lib/docker/overlay2/l/ZIWP422R2WQJXJQWA6BWTKSVP2:/var/lib/docker/overlay2/l/EZJIAHDCQ5P5GASJZR3GCECEE6:/var/lib/docker/overlay2/l/OA2WSFXRNJQI36B7ZILMTVTD5V:/var/lib/docker/overlay2/l/XITXCQNT5YIY7'\r\nUnexpected end of /proc/mounts line `YSSGYLTAEXMQX:/var/lib/docker/overlay2/l/EHORMZU5A6H3H6NAL34XTIYBEA:/var/lib/docker/overlay2/l/E34DRW27EHWOG6HEQCYM2LKYJX:/var/lib/docker/overlay2/l/Y4SABJDSTVMRHZ2SC6QYSK4NP6:/var/lib/docker/overlay2/l/BWHO3NPMOZYCZ33PIH4XXQH3Z6:/var/lib/docker/overlay2/l/YLLBXOSS6TVCINXJNKTZX7J6PQ:/var/lib/docker/overlay2/l/QQ2FBR7QT4NFNYR4UZUXOBD2K3:/var/lib/docker/overlay2/l/SSP6MK4IQCUV2N5DSY5BO4EZO7:/var/lib/docker/overlay2/l/XUONJPPZG5ANA2ELQECHOIY7KU:/var/lib/docker/overlay2/l/ZOCEMSU7RIV6OH6QZNTKKIGACB:/var/lib/do'\r\n```\r\nIt seems that this is harmless.\r\nhttps://stackoverflow.com/questions/46138549/docker-openmpi-and-unexpected-end-of-proc-mounts-line"}