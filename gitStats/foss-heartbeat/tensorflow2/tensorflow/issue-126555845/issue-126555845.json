{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/766", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/766/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/766/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/766/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/766", "id": 126555845, "node_id": "MDU6SXNzdWUxMjY1NTU4NDU=", "number": 766, "title": "Running TensorFlow on GTX 480 (Compute capability 2.0)", "user": {"login": "daothanhtuan", "id": 6870097, "node_id": "MDQ6VXNlcjY4NzAwOTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6870097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daothanhtuan", "html_url": "https://github.com/daothanhtuan", "followers_url": "https://api.github.com/users/daothanhtuan/followers", "following_url": "https://api.github.com/users/daothanhtuan/following{/other_user}", "gists_url": "https://api.github.com/users/daothanhtuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/daothanhtuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daothanhtuan/subscriptions", "organizations_url": "https://api.github.com/users/daothanhtuan/orgs", "repos_url": "https://api.github.com/users/daothanhtuan/repos", "events_url": "https://api.github.com/users/daothanhtuan/events{/privacy}", "received_events_url": "https://api.github.com/users/daothanhtuan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-01-14T01:29:26Z", "updated_at": "2016-01-14T01:35:04Z", "closed_at": "2016-01-14T01:35:04Z", "author_association": "NONE", "body_html": "<p>I'm trying to make tensorflow run on an older GPU (GTX 480). So I removed the compute checking condition in gpu_device.cc like this:</p>\n<div class=\"highlight highlight-source-c\"><pre>       <span class=\"pl-c\"><span class=\"pl-c\">//</span> Only GPUs with no less than the minimum supported compute capability is</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> accepted.</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>if (device_capability &lt; min_supported_capability) {</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>  LOG(INFO) &lt;&lt; \"Ignoring gpu device \"</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>            &lt;&lt; \"(\" &lt;&lt; GetShortDeviceDescription(i, desc) &lt;&lt; \") \"</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>            &lt;&lt; \"with Cuda compute capability \" &lt;&lt; device_capability</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>            &lt;&lt; \". The minimum required Cuda capability is \"</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>            &lt;&lt; min_supported_capability &lt;&lt; \".\";</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>  continue;</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>}</span></pre></div>\n<p>And run the cifar10_train.py<br>\nI got the errors as following:</p>\n<div class=\"highlight highlight-source-c\"><pre>I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:<span class=\"pl-c1\">67</span>] Creating bin of max chunk size <span class=\"pl-c1\">2</span>.00GiB\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:<span class=\"pl-c1\">245</span>] PoolAllocator: After <span class=\"pl-c1\">2424</span> get requests, put_count=<span class=\"pl-c1\">2259</span> evicted_count=<span class=\"pl-c1\">1000</span> eviction_rate=<span class=\"pl-c1\">0.442674</span> and unsatisfied allocation rate=<span class=\"pl-c1\">0.521865</span>\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:<span class=\"pl-c1\">257</span>] Raising pool_size_limit_ from <span class=\"pl-c1\">100</span> to <span class=\"pl-c1\">110</span>\nW tensorflow/core/common_runtime/executor.cc:<span class=\"pl-c1\">1075</span>] <span class=\"pl-c1\">0x206ad80</span> Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=<span class=\"pl-c1\">true</span>, _device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/cpu:0<span class=\"pl-pds\">\"</span></span>](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\nW tensorflow/core/common_runtime/executor.cc:<span class=\"pl-c1\">1075</span>] <span class=\"pl-c1\">0x35962a0</span> Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=<span class=\"pl-c1\">true</span>, _device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/cpu:0<span class=\"pl-pds\">\"</span></span>](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\n     [[Node: SparseToDense/_203 = _Recv[client_terminated=<span class=\"pl-c1\">false</span>, recv_device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/gpu:0<span class=\"pl-pds\">\"</span></span>, send_device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/cpu:0<span class=\"pl-pds\">\"</span></span>, send_device_incarnation=<span class=\"pl-c1\">1</span>, tensor_name=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>edge_474_SparseToDense<span class=\"pl-pds\">\"</span></span>, tensor_type=DT_FLOAT, _device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/gpu:0<span class=\"pl-pds\">\"</span></span>]()]]\n</pre></div>\n<p>I'm guessing if tensorflow is trying to allocate more memory than supported?</p>", "body_text": "I'm trying to make tensorflow run on an older GPU (GTX 480). So I removed the compute checking condition in gpu_device.cc like this:\n       // Only GPUs with no less than the minimum supported compute capability is\n      // accepted.\n      //if (device_capability < min_supported_capability) {\n      //  LOG(INFO) << \"Ignoring gpu device \"\n      //            << \"(\" << GetShortDeviceDescription(i, desc) << \") \"\n      //            << \"with Cuda compute capability \" << device_capability\n      //            << \". The minimum required Cuda capability is \"\n      //            << min_supported_capability << \".\";\n      //  continue;\n      //}\nAnd run the cifar10_train.py\nI got the errors as following:\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2424 get requests, put_count=2259 evicted_count=1000 eviction_rate=0.442674 and unsatisfied allocation rate=0.521865\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nW tensorflow/core/common_runtime/executor.cc:1075] 0x206ad80 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\nW tensorflow/core/common_runtime/executor.cc:1075] 0x35962a0 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\n     [[Node: SparseToDense/_203 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_474_SparseToDense\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nI'm guessing if tensorflow is trying to allocate more memory than supported?", "body": "I'm trying to make tensorflow run on an older GPU (GTX 480). So I removed the compute checking condition in gpu_device.cc like this:\n\n``` C\n       // Only GPUs with no less than the minimum supported compute capability is\n      // accepted.\n      //if (device_capability < min_supported_capability) {\n      //  LOG(INFO) << \"Ignoring gpu device \"\n      //            << \"(\" << GetShortDeviceDescription(i, desc) << \") \"\n      //            << \"with Cuda compute capability \" << device_capability\n      //            << \". The minimum required Cuda capability is \"\n      //            << min_supported_capability << \".\";\n      //  continue;\n      //}\n```\n\nAnd run the cifar10_train.py\nI got the errors as following: \n\n``` C\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2424 get requests, put_count=2259 evicted_count=1000 eviction_rate=0.442674 and unsatisfied allocation rate=0.521865\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\nW tensorflow/core/common_runtime/executor.cc:1075] 0x206ad80 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\nW tensorflow/core/common_runtime/executor.cc:1075] 0x35962a0 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.\n     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]\n     [[Node: SparseToDense/_203 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_474_SparseToDense\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\n```\n\nI'm guessing if tensorflow is trying to allocate more memory than supported?\n"}