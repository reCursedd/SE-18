{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17284", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17284/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17284/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17284/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17284", "id": 300398689, "node_id": "MDU6SXNzdWUzMDAzOTg2ODk=", "number": 17284, "title": "tensor-valued seeds in tf.data API can result in nondeterministic results", "user": {"login": "rightaditya", "id": 1624945, "node_id": "MDQ6VXNlcjE2MjQ5NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1624945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rightaditya", "html_url": "https://github.com/rightaditya", "followers_url": "https://api.github.com/users/rightaditya/followers", "following_url": "https://api.github.com/users/rightaditya/following{/other_user}", "gists_url": "https://api.github.com/users/rightaditya/gists{/gist_id}", "starred_url": "https://api.github.com/users/rightaditya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rightaditya/subscriptions", "organizations_url": "https://api.github.com/users/rightaditya/orgs", "repos_url": "https://api.github.com/users/rightaditya/repos", "events_url": "https://api.github.com/users/rightaditya/events{/privacy}", "received_events_url": "https://api.github.com/users/rightaditya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-02-26T21:15:35Z", "updated_at": "2018-03-02T20:05:14Z", "closed_at": "2018-03-02T20:05:14Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 17.10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.5.0-11-g4588350f20 1.5.0</li>\n<li><strong>Python version</strong>: 3.6.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 7.2.0</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: See code below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <code>tf.data</code> API allows/requires seeds to be provided that are <code>tf.tensor</code>s. This is an issue when the graph-level seed has been set to 0, and the provided op-level seed tensor takes on a value of 0. As noted in the comments in the code for <code>tf.get_seed</code>, a <code>(0, 0)</code> seed is problematic because the C++ ops assume this means nondeterminism. Of course, when a user is specifying these seeds, they're expecting deterministic behaviour. Unfortunately, <code>tf.get_seed</code> only checks for this issue for the case where the seeds are ints, not tensors. See the code below for an example.</p>\n<p>I would have been happy to submit a PR for this, but I have no idea where the fix should be for this bug. As I'm not especially familiar with the code base, it's not apparent whether it's even possible to have the code for <code>tf.get_seed</code> to check the value of a tensor seed. If not, I'm guessing the <code>tf.data</code> API would need to provide the checks.</p>\n<h3>Source code / logs</h3>\n<p>The following code reproduces the bug for me:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ntf.set_random_seed(<span class=\"pl-c1\">0</span>)\nseed_tensor <span class=\"pl-k\">=</span> tf.placeholder(tf.int64, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>data_seed<span class=\"pl-pds\">'</span></span>)\ndata <span class=\"pl-k\">=</span> tf.data.Dataset.range(<span class=\"pl-c1\">10</span>).shuffle(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span>seed_tensor)\niterator <span class=\"pl-k\">=</span> tf.data.Iterator.from_structure(tf.int64, tf.TensorShape([]))\n\ninit <span class=\"pl-k\">=</span> iterator.make_initializer(data)\nvalue <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>First run: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">end</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess1:\n    sess1.run(init, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{seed_tensor: <span class=\"pl-c1\">0</span>})\n    values <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        <span class=\"pl-k\">try</span>:\n            values.append(<span class=\"pl-c1\">str</span>(sess1.run(value)))\n        <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n            <span class=\"pl-k\">break</span>\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>, <span class=\"pl-pds\">'</span></span>.join(values))\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Second run: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">end</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess2:\n    sess2.run(init, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{seed_tensor: <span class=\"pl-c1\">0</span>})\n    values <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        <span class=\"pl-k\">try</span>:\n            values.append(<span class=\"pl-c1\">str</span>(sess2.run(value)))\n        <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n            <span class=\"pl-k\">break</span>\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>, <span class=\"pl-pds\">'</span></span>.join(values))</pre></div>\n<p>The result I get is:</p>\n<pre><code>First run: 8, 4, 6, 9, 1, 0, 5, 7, 3, 2\nSecond run: 1, 6, 3, 0, 7, 5, 2, 9, 8, 4\n</code></pre>\n<p>I would expect the first and second runs to produce the exact same sequence, though the particular sequence might differ from environment to environment.</p>\n<p>If I change the <code>feed_dict</code> to provide a value of <code>0</code> for <code>seed_tensor</code> for both runs, I get the expected result:</p>\n<pre><code>First run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\nSecond run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\n</code></pre>\n<p>If I change the <code>shuffle()</code> call to take a value of 0 directly (i.e., `...shuffle(10, seed=0)), I get the expected result as well:</p>\n<pre><code>First run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\nSecond run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\n</code></pre>\n<p>For the record, I encountered this issue because I'm using an <code>Iterator</code> via <code>Iterator.from_structure</code>, and when I use that iterator on a <code>Dataset.shuffle()</code> I get the same order for each epoch. To get around this, I provided the epoch number as a seed to <code>Dataset.shuffle()</code>, with the first epoch being epoch 0. In my case I can avoid this bug by just starting the epoch count at 1, but it took me a while to track down, and there may be other cases where the API is used in a similar way that would be problematic for those expecting deterministic results.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): v1.5.0-11-g4588350f20 1.5.0\nPython version: 3.6.3\nBazel version (if compiling from source): 0.11.0\nGCC/Compiler version (if compiling from source): 7.2.0\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: See code below\n\nDescribe the problem\nThe tf.data API allows/requires seeds to be provided that are tf.tensors. This is an issue when the graph-level seed has been set to 0, and the provided op-level seed tensor takes on a value of 0. As noted in the comments in the code for tf.get_seed, a (0, 0) seed is problematic because the C++ ops assume this means nondeterminism. Of course, when a user is specifying these seeds, they're expecting deterministic behaviour. Unfortunately, tf.get_seed only checks for this issue for the case where the seeds are ints, not tensors. See the code below for an example.\nI would have been happy to submit a PR for this, but I have no idea where the fix should be for this bug. As I'm not especially familiar with the code base, it's not apparent whether it's even possible to have the code for tf.get_seed to check the value of a tensor seed. If not, I'm guessing the tf.data API would need to provide the checks.\nSource code / logs\nThe following code reproduces the bug for me:\nimport tensorflow as tf\n\ntf.set_random_seed(0)\nseed_tensor = tf.placeholder(tf.int64, shape=[], name='data_seed')\ndata = tf.data.Dataset.range(10).shuffle(10, seed=seed_tensor)\niterator = tf.data.Iterator.from_structure(tf.int64, tf.TensorShape([]))\n\ninit = iterator.make_initializer(data)\nvalue = iterator.get_next()\n\nprint('First run: ', end='')\nwith tf.Session() as sess1:\n    sess1.run(init, feed_dict={seed_tensor: 0})\n    values = []\n    while True:\n        try:\n            values.append(str(sess1.run(value)))\n        except tf.errors.OutOfRangeError:\n            break\n\n    print(', '.join(values))\n\nprint('Second run: ', end='')\nwith tf.Session() as sess2:\n    sess2.run(init, feed_dict={seed_tensor: 0})\n    values = []\n    while True:\n        try:\n            values.append(str(sess2.run(value)))\n        except tf.errors.OutOfRangeError:\n            break\n\n    print(', '.join(values))\nThe result I get is:\nFirst run: 8, 4, 6, 9, 1, 0, 5, 7, 3, 2\nSecond run: 1, 6, 3, 0, 7, 5, 2, 9, 8, 4\n\nI would expect the first and second runs to produce the exact same sequence, though the particular sequence might differ from environment to environment.\nIf I change the feed_dict to provide a value of 0 for seed_tensor for both runs, I get the expected result:\nFirst run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\nSecond run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\n\nIf I change the shuffle() call to take a value of 0 directly (i.e., `...shuffle(10, seed=0)), I get the expected result as well:\nFirst run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\nSecond run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\n\nFor the record, I encountered this issue because I'm using an Iterator via Iterator.from_structure, and when I use that iterator on a Dataset.shuffle() I get the same order for each epoch. To get around this, I provided the epoch number as a seed to Dataset.shuffle(), with the first epoch being epoch 0. In my case I can avoid this bug by just starting the epoch count at 1, but it took me a while to track down, and there may be other cases where the API is used in a similar way that would be problematic for those expecting deterministic results.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.5.0-11-g4588350f20 1.5.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See code below\r\n\r\n### Describe the problem\r\nThe `tf.data` API allows/requires seeds to be provided that are `tf.tensor`s. This is an issue when the graph-level seed has been set to 0, and the provided op-level seed tensor takes on a value of 0. As noted in the comments in the code for `tf.get_seed`, a `(0, 0)` seed is problematic because the C++ ops assume this means nondeterminism. Of course, when a user is specifying these seeds, they're expecting deterministic behaviour. Unfortunately, `tf.get_seed` only checks for this issue for the case where the seeds are ints, not tensors. See the code below for an example.\r\n\r\nI would have been happy to submit a PR for this, but I have no idea where the fix should be for this bug. As I'm not especially familiar with the code base, it's not apparent whether it's even possible to have the code for `tf.get_seed` to check the value of a tensor seed. If not, I'm guessing the `tf.data` API would need to provide the checks.\r\n\r\n### Source code / logs\r\nThe following code reproduces the bug for me:\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.set_random_seed(0)\r\nseed_tensor = tf.placeholder(tf.int64, shape=[], name='data_seed')\r\ndata = tf.data.Dataset.range(10).shuffle(10, seed=seed_tensor)\r\niterator = tf.data.Iterator.from_structure(tf.int64, tf.TensorShape([]))\r\n\r\ninit = iterator.make_initializer(data)\r\nvalue = iterator.get_next()\r\n\r\nprint('First run: ', end='')\r\nwith tf.Session() as sess1:\r\n    sess1.run(init, feed_dict={seed_tensor: 0})\r\n    values = []\r\n    while True:\r\n        try:\r\n            values.append(str(sess1.run(value)))\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\n\r\n    print(', '.join(values))\r\n\r\nprint('Second run: ', end='')\r\nwith tf.Session() as sess2:\r\n    sess2.run(init, feed_dict={seed_tensor: 0})\r\n    values = []\r\n    while True:\r\n        try:\r\n            values.append(str(sess2.run(value)))\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\n\r\n    print(', '.join(values))\r\n```\r\n\r\nThe result I get is:\r\n```\r\nFirst run: 8, 4, 6, 9, 1, 0, 5, 7, 3, 2\r\nSecond run: 1, 6, 3, 0, 7, 5, 2, 9, 8, 4\r\n```\r\n\r\nI would expect the first and second runs to produce the exact same sequence, though the particular sequence might differ from environment to environment.\r\n\r\nIf I change the `feed_dict` to provide a value of `0` for `seed_tensor` for both runs, I get the expected result:\r\n\r\n```\r\nFirst run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\r\nSecond run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\r\n```\r\n\r\nIf I change the `shuffle()` call to take a value of 0 directly (i.e., `...shuffle(10, seed=0)), I get the expected result as well:\r\n\r\n```\r\nFirst run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\r\nSecond run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\r\n```\r\nFor the record, I encountered this issue because I'm using an `Iterator` via `Iterator.from_structure`, and when I use that iterator on a `Dataset.shuffle()` I get the same order for each epoch. To get around this, I provided the epoch number as a seed to `Dataset.shuffle()`, with the first epoch being epoch 0. In my case I can avoid this bug by just starting the epoch count at 1, but it took me a while to track down, and there may be other cases where the API is used in a similar way that would be problematic for those expecting deterministic results."}