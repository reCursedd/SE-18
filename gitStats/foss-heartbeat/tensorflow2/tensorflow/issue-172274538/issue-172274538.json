{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3941", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3941/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3941/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3941/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3941", "id": 172274538, "node_id": "MDU6SXNzdWUxNzIyNzQ1Mzg=", "number": 3941, "title": "cifar10_train can't use all CPUs", "user": {"login": "perhapszzy", "id": 7953637, "node_id": "MDQ6VXNlcjc5NTM2Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7953637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/perhapszzy", "html_url": "https://github.com/perhapszzy", "followers_url": "https://api.github.com/users/perhapszzy/followers", "following_url": "https://api.github.com/users/perhapszzy/following{/other_user}", "gists_url": "https://api.github.com/users/perhapszzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/perhapszzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/perhapszzy/subscriptions", "organizations_url": "https://api.github.com/users/perhapszzy/orgs", "repos_url": "https://api.github.com/users/perhapszzy/repos", "events_url": "https://api.github.com/users/perhapszzy/events{/privacy}", "received_events_url": "https://api.github.com/users/perhapszzy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-08-20T14:53:40Z", "updated_at": "2016-08-22T21:29:12Z", "closed_at": "2016-08-22T21:29:12Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Linux 14.04</p>\n<p>Installed version of CUDA and cuDNN:  No</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n</ol>\n<p><a href=\"https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl</a></p>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>0.10.0rc</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>clone the tensorflow main repo</li>\n<li>run <code>python cifar10_train.py</code><br>\nThis will only occupy ~6 CPUs on a machine with 8 CPUs (<code>top</code> command shows the CPU usage is ~600%)</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>set  <code>intra_op_parallelism_threads</code> and  <code>inter_op_parallelism_threads</code> in the <code>ConfigProto</code> when creating the session.  This doesn't help at all.</li>\n<li>use multi-thread training like:</li>\n</ol>\n<pre><code>class Cifar10(object):\n  def __init__(self, sess):\n    print(\"In construction\")\n    self.global_step = tf.Variable(0, trainable=False)\n    self.images, self.labels = cifar10.distorted_inputs()\n    self.logits = cifar10.inference(self.images)\n    self.loss = cifar10.loss(self.logits, self.labels)\n    self.train_op = cifar10.train(self.loss, self.global_step)\n\n    self.sess = sess\n    init = tf.initialize_all_variables()\n    self.sess.run(init)\n    self.start = time.time()\n    tf.train.start_queue_runners(sess=self.sess)\n    print(\"Construction Done\")\n    self.saver = tf.train.Saver()\n\n  def train(self):\n    for step in xrange(FLAGS.max_steps):\n      self.sess.run(self.train_op)\n\n  def run(self, sess):\n    workers = []\n    for _ in xrange(4):\n      t = threading.Thread(target=self.train)\n      t.start()\n      workers.append(t)\n\n    for t in workers:\n      t.join()\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  with tf.Graph().as_default(): \n    with tf.Session() as sess:\n      model = Cifar10(sess)\n      for _ in xrange(10000):\n        gs = sess.run(model.global_step)\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        model.saver.save(sess, checkpoint_path, global_step=gs)\n        model.run(sess)\n\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>The complete code:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/428362/cifar10_multi_thread.txt\">cifar10_multi_thread.txt</a></p>\n<p>This did help. The CPU usage became 800% and the training process did go faster.</p>\n<p>I assume that the data feeding process should not be the bottleneck because in the multi-thread training the input queue is not adjusted. Then how does TensorFlow parallelize the training process? Is there any parameter I should try to increase the CPU usage with the original code?</p>\n<p>I also observed that if I train the multi-threads version in a distributed setting (I'm running 3 workers async, each runs a multi-threads training process), the precision on testing data looks like:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/7953637/17831863/d1d4b4d8-6727-11e6-8501-441796b8a70e.png\"><img src=\"https://cloud.githubusercontent.com/assets/7953637/17831863/d1d4b4d8-6727-11e6-8501-441796b8a70e.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>But if I use the original version, the performance looks like:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/7953637/17831884/a478c1c2-6728-11e6-988b-59f51e9284a1.png\"><img src=\"https://cloud.githubusercontent.com/assets/7953637/17831884/a478c1c2-6728-11e6-988b-59f51e9284a1.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>I guess that might be caused by the async updates, is there any suggestion to avoid this?</p>\n<p>Thanks</p>", "body_text": "Environment info\nOperating System: Linux 14.04\nInstalled version of CUDA and cuDNN:  No\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n0.10.0rc\nSteps to reproduce\n\nclone the tensorflow main repo\nrun python cifar10_train.py\nThis will only occupy ~6 CPUs on a machine with 8 CPUs (top command shows the CPU usage is ~600%)\n\nWhat have you tried?\n\nset  intra_op_parallelism_threads and  inter_op_parallelism_threads in the ConfigProto when creating the session.  This doesn't help at all.\nuse multi-thread training like:\n\nclass Cifar10(object):\n  def __init__(self, sess):\n    print(\"In construction\")\n    self.global_step = tf.Variable(0, trainable=False)\n    self.images, self.labels = cifar10.distorted_inputs()\n    self.logits = cifar10.inference(self.images)\n    self.loss = cifar10.loss(self.logits, self.labels)\n    self.train_op = cifar10.train(self.loss, self.global_step)\n\n    self.sess = sess\n    init = tf.initialize_all_variables()\n    self.sess.run(init)\n    self.start = time.time()\n    tf.train.start_queue_runners(sess=self.sess)\n    print(\"Construction Done\")\n    self.saver = tf.train.Saver()\n\n  def train(self):\n    for step in xrange(FLAGS.max_steps):\n      self.sess.run(self.train_op)\n\n  def run(self, sess):\n    workers = []\n    for _ in xrange(4):\n      t = threading.Thread(target=self.train)\n      t.start()\n      workers.append(t)\n\n    for t in workers:\n      t.join()\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  with tf.Graph().as_default(): \n    with tf.Session() as sess:\n      model = Cifar10(sess)\n      for _ in xrange(10000):\n        gs = sess.run(model.global_step)\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        model.saver.save(sess, checkpoint_path, global_step=gs)\n        model.run(sess)\n\nif __name__ == '__main__':\n  tf.app.run()\n\nThe complete code:\ncifar10_multi_thread.txt\nThis did help. The CPU usage became 800% and the training process did go faster.\nI assume that the data feeding process should not be the bottleneck because in the multi-thread training the input queue is not adjusted. Then how does TensorFlow parallelize the training process? Is there any parameter I should try to increase the CPU usage with the original code?\nI also observed that if I train the multi-threads version in a distributed setting (I'm running 3 workers async, each runs a multi-threads training process), the precision on testing data looks like:\n\nBut if I use the original version, the performance looks like:\n\nI guess that might be caused by the async updates, is there any suggestion to avoid this?\nThanks", "body": "### Environment info\n\nOperating System: Linux 14.04\n\nInstalled version of CUDA and cuDNN:  No\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n0.10.0rc\n### Steps to reproduce\n1. clone the tensorflow main repo\n2. run `python cifar10_train.py`\n   This will only occupy ~6 CPUs on a machine with 8 CPUs (`top` command shows the CPU usage is ~600%)\n### What have you tried?\n1. set  `intra_op_parallelism_threads` and  `inter_op_parallelism_threads` in the `ConfigProto` when creating the session.  This doesn't help at all.\n2. use multi-thread training like:\n\n```\nclass Cifar10(object):\n  def __init__(self, sess):\n    print(\"In construction\")\n    self.global_step = tf.Variable(0, trainable=False)\n    self.images, self.labels = cifar10.distorted_inputs()\n    self.logits = cifar10.inference(self.images)\n    self.loss = cifar10.loss(self.logits, self.labels)\n    self.train_op = cifar10.train(self.loss, self.global_step)\n\n    self.sess = sess\n    init = tf.initialize_all_variables()\n    self.sess.run(init)\n    self.start = time.time()\n    tf.train.start_queue_runners(sess=self.sess)\n    print(\"Construction Done\")\n    self.saver = tf.train.Saver()\n\n  def train(self):\n    for step in xrange(FLAGS.max_steps):\n      self.sess.run(self.train_op)\n\n  def run(self, sess):\n    workers = []\n    for _ in xrange(4):\n      t = threading.Thread(target=self.train)\n      t.start()\n      workers.append(t)\n\n    for t in workers:\n      t.join()\n\ndef main(argv=None):  # pylint: disable=unused-argument\n  cifar10.maybe_download_and_extract()\n  with tf.Graph().as_default(): \n    with tf.Session() as sess:\n      model = Cifar10(sess)\n      for _ in xrange(10000):\n        gs = sess.run(model.global_step)\n        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n        model.saver.save(sess, checkpoint_path, global_step=gs)\n        model.run(sess)\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nThe complete code:\n[cifar10_multi_thread.txt](https://github.com/tensorflow/tensorflow/files/428362/cifar10_multi_thread.txt)\n\nThis did help. The CPU usage became 800% and the training process did go faster.\n\nI assume that the data feeding process should not be the bottleneck because in the multi-thread training the input queue is not adjusted. Then how does TensorFlow parallelize the training process? Is there any parameter I should try to increase the CPU usage with the original code?\n\nI also observed that if I train the multi-threads version in a distributed setting (I'm running 3 workers async, each runs a multi-threads training process), the precision on testing data looks like:\n![image](https://cloud.githubusercontent.com/assets/7953637/17831863/d1d4b4d8-6727-11e6-8501-441796b8a70e.png)\n\nBut if I use the original version, the performance looks like:\n![image](https://cloud.githubusercontent.com/assets/7953637/17831884/a478c1c2-6728-11e6-988b-59f51e9284a1.png)\n\nI guess that might be caused by the async updates, is there any suggestion to avoid this?\n\nThanks\n"}