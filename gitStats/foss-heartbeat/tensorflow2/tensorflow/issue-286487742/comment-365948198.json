{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/365948198", "html_url": "https://github.com/tensorflow/tensorflow/issues/15911#issuecomment-365948198", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15911", "id": 365948198, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTk0ODE5OA==", "user": {"login": "marcj", "id": 450980, "node_id": "MDQ6VXNlcjQ1MDk4MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/450980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marcj", "html_url": "https://github.com/marcj", "followers_url": "https://api.github.com/users/marcj/followers", "following_url": "https://api.github.com/users/marcj/following{/other_user}", "gists_url": "https://api.github.com/users/marcj/gists{/gist_id}", "starred_url": "https://api.github.com/users/marcj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marcj/subscriptions", "organizations_url": "https://api.github.com/users/marcj/orgs", "repos_url": "https://api.github.com/users/marcj/repos", "events_url": "https://api.github.com/users/marcj/events{/privacy}", "received_events_url": "https://api.github.com/users/marcj/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-15T14:45:40Z", "updated_at": "2018-02-15T14:45:40Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>It would be helpful if you could do a bit of debugging yourself. CUDADriver::CreateContext is responsible for creating the driver context TF uses. Is it being called and successfully getting down to the cuCtxSetCurrent call?</p>\n</blockquote>\n<p>I don't know C++ well enough to do any debugging here.<br>\nI expect however, that a Cuda context is application bound, that means it shouldn't matter if some program (in my case Python script) should create a Cuda context and another program (in Tensorflow's case a Python C++ module), right?</p>\n<blockquote>\n<p>Alternatively, it's possible if you just moved the \"import tensorflow\" bit up, the initialization would happen before you touch libcudart, and everything would work. I'm not sure.</p>\n</blockquote>\n<p>When I move <code>import tensorflow as tf</code> to line 2, I get exact same error.</p>", "body_text": "It would be helpful if you could do a bit of debugging yourself. CUDADriver::CreateContext is responsible for creating the driver context TF uses. Is it being called and successfully getting down to the cuCtxSetCurrent call?\n\nI don't know C++ well enough to do any debugging here.\nI expect however, that a Cuda context is application bound, that means it shouldn't matter if some program (in my case Python script) should create a Cuda context and another program (in Tensorflow's case a Python C++ module), right?\n\nAlternatively, it's possible if you just moved the \"import tensorflow\" bit up, the initialization would happen before you touch libcudart, and everything would work. I'm not sure.\n\nWhen I move import tensorflow as tf to line 2, I get exact same error.", "body": "> It would be helpful if you could do a bit of debugging yourself. CUDADriver::CreateContext is responsible for creating the driver context TF uses. Is it being called and successfully getting down to the cuCtxSetCurrent call?\r\n\r\nI don't know C++ well enough to do any debugging here.\r\nI expect however, that a Cuda context is application bound, that means it shouldn't matter if some program (in my case Python script) should create a Cuda context and another program (in Tensorflow's case a Python C++ module), right?\r\n\r\n\r\n> Alternatively, it's possible if you just moved the \"import tensorflow\" bit up, the initialization would happen before you touch libcudart, and everything would work. I'm not sure.\r\n\r\nWhen I move `import tensorflow as tf` to line 2, I get exact same error."}