{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412926249", "html_url": "https://github.com/tensorflow/tensorflow/issues/20524#issuecomment-412926249", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20524", "id": 412926249, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjkyNjI0OQ==", "user": {"login": "ccolby", "id": 15960281, "node_id": "MDQ6VXNlcjE1OTYwMjgx", "avatar_url": "https://avatars1.githubusercontent.com/u/15960281?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ccolby", "html_url": "https://github.com/ccolby", "followers_url": "https://api.github.com/users/ccolby/followers", "following_url": "https://api.github.com/users/ccolby/following{/other_user}", "gists_url": "https://api.github.com/users/ccolby/gists{/gist_id}", "starred_url": "https://api.github.com/users/ccolby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ccolby/subscriptions", "organizations_url": "https://api.github.com/users/ccolby/orgs", "repos_url": "https://api.github.com/users/ccolby/repos", "events_url": "https://api.github.com/users/ccolby/events{/privacy}", "received_events_url": "https://api.github.com/users/ccolby/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-14T16:07:23Z", "updated_at": "2018-08-14T16:07:23Z", "author_association": "NONE", "body_html": "<p>To add a little more to this explanation, it would have been possible (but difficult) to fix the tf.while_loop bug with a more localized change that would have affected only tf.while_loop. But we considered the change to disallow integer gradients to be more principled. So in addition to fixing the tf.while_loop bug, this makes TensorFlow's treatment of gradients more consistent.</p>\n<p>First of all, before this change, integer gradients were inconsistently implemented. For example, before this change:</p>\n<pre><code>k = tf.constant(3)\ngrad_1, = tf.gradients(k * k, k)\ngrad_2, = tf.gradients(tf.square(k), k)\n\ngrad_1 is a tf.int32 Tensor that evaluates to 6.\nThe tf.gradients call for grad_2 raises an exception: [TypeError: Expected int32 passed to parameter 'y' of op 'Mul', got 2.0 of type 'float' instead.]\n</code></pre>\n<p>But secondly, and more importantly, it is not clear in general how integer gradients should work. In the example above, what should <code>grad_1</code> be? If f(k)=k*k is interpreted as a real-valued function then the gradient at k=3 is 6. But f(k) is an integer-valued function, so perhaps it is more correct for the gradient to be f(4)-f(3) = 7. Or should it be f(3)-f(2) = 5? Or should it be the average of the last two options? Ultimately, it is not clear if there is a sensible way to support gradients of integer-valued functions. This is why we made this change.</p>\n<p>Probably we should have explained this further in the release notes.</p>", "body_text": "To add a little more to this explanation, it would have been possible (but difficult) to fix the tf.while_loop bug with a more localized change that would have affected only tf.while_loop. But we considered the change to disallow integer gradients to be more principled. So in addition to fixing the tf.while_loop bug, this makes TensorFlow's treatment of gradients more consistent.\nFirst of all, before this change, integer gradients were inconsistently implemented. For example, before this change:\nk = tf.constant(3)\ngrad_1, = tf.gradients(k * k, k)\ngrad_2, = tf.gradients(tf.square(k), k)\n\ngrad_1 is a tf.int32 Tensor that evaluates to 6.\nThe tf.gradients call for grad_2 raises an exception: [TypeError: Expected int32 passed to parameter 'y' of op 'Mul', got 2.0 of type 'float' instead.]\n\nBut secondly, and more importantly, it is not clear in general how integer gradients should work. In the example above, what should grad_1 be? If f(k)=k*k is interpreted as a real-valued function then the gradient at k=3 is 6. But f(k) is an integer-valued function, so perhaps it is more correct for the gradient to be f(4)-f(3) = 7. Or should it be f(3)-f(2) = 5? Or should it be the average of the last two options? Ultimately, it is not clear if there is a sensible way to support gradients of integer-valued functions. This is why we made this change.\nProbably we should have explained this further in the release notes.", "body": "To add a little more to this explanation, it would have been possible (but difficult) to fix the tf.while_loop bug with a more localized change that would have affected only tf.while_loop. But we considered the change to disallow integer gradients to be more principled. So in addition to fixing the tf.while_loop bug, this makes TensorFlow's treatment of gradients more consistent.\r\n\r\nFirst of all, before this change, integer gradients were inconsistently implemented. For example, before this change:\r\n```\r\nk = tf.constant(3)\r\ngrad_1, = tf.gradients(k * k, k)\r\ngrad_2, = tf.gradients(tf.square(k), k)\r\n\r\ngrad_1 is a tf.int32 Tensor that evaluates to 6.\r\nThe tf.gradients call for grad_2 raises an exception: [TypeError: Expected int32 passed to parameter 'y' of op 'Mul', got 2.0 of type 'float' instead.]\r\n```\r\n\r\nBut secondly, and more importantly, it is not clear in general how integer gradients should work. In the example above, what should `grad_1` be? If f(k)=k*k is interpreted as a real-valued function then the gradient at k=3 is 6. But f(k) is an integer-valued function, so perhaps it is more correct for the gradient to be f(4)-f(3) = 7. Or should it be f(3)-f(2) = 5? Or should it be the average of the last two options? Ultimately, it is not clear if there is a sensible way to support gradients of integer-valued functions. This is why we made this change.\r\n\r\nProbably we should have explained this further in the release notes."}