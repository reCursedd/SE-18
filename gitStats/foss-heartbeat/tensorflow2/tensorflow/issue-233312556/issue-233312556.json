{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10408", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10408/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10408/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10408/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10408", "id": 233312556, "node_id": "MDU6SXNzdWUyMzMzMTI1NTY=", "number": 10408, "title": "Memory leak ", "user": {"login": "Caselles", "id": 19774802, "node_id": "MDQ6VXNlcjE5Nzc0ODAy", "avatar_url": "https://avatars3.githubusercontent.com/u/19774802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Caselles", "html_url": "https://github.com/Caselles", "followers_url": "https://api.github.com/users/Caselles/followers", "following_url": "https://api.github.com/users/Caselles/following{/other_user}", "gists_url": "https://api.github.com/users/Caselles/gists{/gist_id}", "starred_url": "https://api.github.com/users/Caselles/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Caselles/subscriptions", "organizations_url": "https://api.github.com/users/Caselles/orgs", "repos_url": "https://api.github.com/users/Caselles/repos", "events_url": "https://api.github.com/users/Caselles/events{/privacy}", "received_events_url": "https://api.github.com/users/Caselles/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 25, "created_at": "2017-06-02T21:55:39Z", "updated_at": "2018-11-14T19:13:05Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I have a memory leak with TensorFlow. I refered to <a href=\"https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session\" rel=\"nofollow\">https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session</a> to address my issue, and I followed the advices of the answer, that seemed to have solved the problem. However it does not work here.</p>\n<p>In order to recreate the memory leak, I have created a simple example. First, I use this function (that I got here : <a href=\"https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python\" rel=\"nofollow\">https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python</a>) to check the memory use of the python process :</p>\n<pre><code>def memory():\n    import os\n    import psutil\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n    print('memory use:', memoryUse)\n</code></pre>\n<p>Then, everytime I call the <code>build_model</code> function, the use of memory increases.</p>\n<p>Here is the <code>build_model</code> function that has a memory leak :</p>\n<pre><code>def build_model():\n\n    '''Model'''\n\n    tf.reset_default_graph()\n\n\n    with tf.Graph().as_default(), tf.Session() as sess:\n        tf.contrib.keras.backend.set_session(sess)\n\n        labels = tf.placeholder(tf.float32, shape=(None, 1))\n        input = tf.placeholder(tf.float32, shape=(None, 1))\n\n        x = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense1')(input)\n        x1 = tf.contrib.keras.layers.Dropout(0.5)(x)\n        x2 = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense2')(x1)\n        y = tf.contrib.keras.layers.Dense(1, activation='sigmoid', name='dense3')(x2)\n\n\n        loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(labels, y))\n\n        train_step = tf.train.AdamOptimizer(0.004).minimize(loss)\n\n        #Initialize all variables\n        init_op = tf.global_variables_initializer()\n        sess.run(init_op)\n\n        sess.close()\n\n    tf.reset_default_graph()\n\n    return \n</code></pre>\n<p>I would have thought that using the block <code>with tf.Graph().as_default(), tf.Session() as sess:</code> and then <strong>closing the session</strong> and <strong>calling <code>tf.reset_default_graph</code></strong> would clear all the memory used by TensorFlow. Apparently it does not.</p>\n<p>The memory leak can be recreated as following :</p>\n<pre><code>memory()\nbuild_model()\nmemory()\nbuild_model()\nmemory()\n</code></pre>\n<p>The output of this is (for my computer) :</p>\n<pre><code>memory use: 0.1794891357421875\nmemory use: 0.184417724609375\nmemory use: 0.18923568725585938\n</code></pre>\n<p>Clearly we can see that all the memory used by TensorFlow is not freed afterwards. Why?</p>\n<p>I hope I made myself clear.</p>", "body_text": "I have a memory leak with TensorFlow. I refered to https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session to address my issue, and I followed the advices of the answer, that seemed to have solved the problem. However it does not work here.\nIn order to recreate the memory leak, I have created a simple example. First, I use this function (that I got here : https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python) to check the memory use of the python process :\ndef memory():\n    import os\n    import psutil\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n    print('memory use:', memoryUse)\n\nThen, everytime I call the build_model function, the use of memory increases.\nHere is the build_model function that has a memory leak :\ndef build_model():\n\n    '''Model'''\n\n    tf.reset_default_graph()\n\n\n    with tf.Graph().as_default(), tf.Session() as sess:\n        tf.contrib.keras.backend.set_session(sess)\n\n        labels = tf.placeholder(tf.float32, shape=(None, 1))\n        input = tf.placeholder(tf.float32, shape=(None, 1))\n\n        x = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense1')(input)\n        x1 = tf.contrib.keras.layers.Dropout(0.5)(x)\n        x2 = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense2')(x1)\n        y = tf.contrib.keras.layers.Dense(1, activation='sigmoid', name='dense3')(x2)\n\n\n        loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(labels, y))\n\n        train_step = tf.train.AdamOptimizer(0.004).minimize(loss)\n\n        #Initialize all variables\n        init_op = tf.global_variables_initializer()\n        sess.run(init_op)\n\n        sess.close()\n\n    tf.reset_default_graph()\n\n    return \n\nI would have thought that using the block with tf.Graph().as_default(), tf.Session() as sess: and then closing the session and calling tf.reset_default_graph would clear all the memory used by TensorFlow. Apparently it does not.\nThe memory leak can be recreated as following :\nmemory()\nbuild_model()\nmemory()\nbuild_model()\nmemory()\n\nThe output of this is (for my computer) :\nmemory use: 0.1794891357421875\nmemory use: 0.184417724609375\nmemory use: 0.18923568725585938\n\nClearly we can see that all the memory used by TensorFlow is not freed afterwards. Why?\nI hope I made myself clear.", "body": "I have a memory leak with TensorFlow. I refered to https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session to address my issue, and I followed the advices of the answer, that seemed to have solved the problem. However it does not work here. \r\n\r\nIn order to recreate the memory leak, I have created a simple example. First, I use this function (that I got here : https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python) to check the memory use of the python process : \r\n\r\n    def memory():\r\n        import os\r\n        import psutil\r\n        pid = os.getpid()\r\n        py = psutil.Process(pid)\r\n        memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\r\n        print('memory use:', memoryUse)\r\n\r\nThen, everytime I call the `build_model` function, the use of memory increases.\r\n\r\nHere is the `build_model` function that has a memory leak : \r\n \r\n    def build_model():\r\n\r\n        '''Model'''\r\n\r\n        tf.reset_default_graph()\r\n\r\n\r\n        with tf.Graph().as_default(), tf.Session() as sess:\r\n            tf.contrib.keras.backend.set_session(sess)\r\n\r\n            labels = tf.placeholder(tf.float32, shape=(None, 1))\r\n            input = tf.placeholder(tf.float32, shape=(None, 1))\r\n\r\n            x = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense1')(input)\r\n            x1 = tf.contrib.keras.layers.Dropout(0.5)(x)\r\n            x2 = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense2')(x1)\r\n            y = tf.contrib.keras.layers.Dense(1, activation='sigmoid', name='dense3')(x2)\r\n\r\n\r\n            loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(labels, y))\r\n\r\n            train_step = tf.train.AdamOptimizer(0.004).minimize(loss)\r\n\r\n            #Initialize all variables\r\n            init_op = tf.global_variables_initializer()\r\n            sess.run(init_op)\r\n\r\n            sess.close()\r\n\r\n        tf.reset_default_graph()\r\n\r\n        return \r\n\r\n I would have thought that using the block ` with tf.Graph().as_default(), tf.Session() as sess: ` and then **closing the session** and **calling `tf.reset_default_graph`** would clear all the memory used by TensorFlow. Apparently it does not.\r\n\r\nThe memory leak can be recreated as following : \r\n\r\n    memory()\r\n    build_model()\r\n    memory()\r\n    build_model()\r\n    memory()\r\n\r\nThe output of this is (for my computer) :\r\n\r\n    memory use: 0.1794891357421875\r\n    memory use: 0.184417724609375\r\n    memory use: 0.18923568725585938\r\n\r\nClearly we can see that all the memory used by TensorFlow is not freed afterwards. Why?\r\n\r\nI hope I made myself clear."}