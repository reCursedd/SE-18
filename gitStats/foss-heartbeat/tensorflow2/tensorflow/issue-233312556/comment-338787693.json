{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/338787693", "html_url": "https://github.com/tensorflow/tensorflow/issues/10408#issuecomment-338787693", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10408", "id": 338787693, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODc4NzY5Mw==", "user": {"login": "myyan92", "id": 14825120, "node_id": "MDQ6VXNlcjE0ODI1MTIw", "avatar_url": "https://avatars0.githubusercontent.com/u/14825120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myyan92", "html_url": "https://github.com/myyan92", "followers_url": "https://api.github.com/users/myyan92/followers", "following_url": "https://api.github.com/users/myyan92/following{/other_user}", "gists_url": "https://api.github.com/users/myyan92/gists{/gist_id}", "starred_url": "https://api.github.com/users/myyan92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myyan92/subscriptions", "organizations_url": "https://api.github.com/users/myyan92/orgs", "repos_url": "https://api.github.com/users/myyan92/repos", "events_url": "https://api.github.com/users/myyan92/events{/privacy}", "received_events_url": "https://api.github.com/users/myyan92/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-23T20:33:02Z", "updated_at": "2017-10-23T20:33:02Z", "author_association": "NONE", "body_html": "<p>I have a very similar issue causing memory leak, but I'm only using tensorflow without keras. Here's the minimal code:</p>\n<p>import tensorflow as tf<br>\nimport numpy as np<br>\nfor i in range(30):<br>\ntf.Session().<strong>enter</strong>()<br>\ntf.constant(np.random.random((800,500,500,1)))<br>\ntf.get_default_session().close()<br>\ntf.reset_default_graph()</p>\n<p>When executing the loop the memory used keeps going up. How can I actually delete the old large constants and free the memory?<br>\nI'm using tensorflow 1.2 with python 3.4 on ubuntu 14.04</p>", "body_text": "I have a very similar issue causing memory leak, but I'm only using tensorflow without keras. Here's the minimal code:\nimport tensorflow as tf\nimport numpy as np\nfor i in range(30):\ntf.Session().enter()\ntf.constant(np.random.random((800,500,500,1)))\ntf.get_default_session().close()\ntf.reset_default_graph()\nWhen executing the loop the memory used keeps going up. How can I actually delete the old large constants and free the memory?\nI'm using tensorflow 1.2 with python 3.4 on ubuntu 14.04", "body": "I have a very similar issue causing memory leak, but I'm only using tensorflow without keras. Here's the minimal code:\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfor i in range(30):\r\n    tf.Session().__enter__()\r\n    tf.constant(np.random.random((800,500,500,1)))\r\n    tf.get_default_session().close()\r\n    tf.reset_default_graph()\r\n\r\n\r\nWhen executing the loop the memory used keeps going up. How can I actually delete the old large constants and free the memory?\r\nI'm using tensorflow 1.2 with python 3.4 on ubuntu 14.04"}