{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260118987", "html_url": "https://github.com/tensorflow/tensorflow/issues/5562#issuecomment-260118987", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5562", "id": 260118987, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDExODk4Nw==", "user": {"login": "AshishBora", "id": 4586769, "node_id": "MDQ6VXNlcjQ1ODY3Njk=", "avatar_url": "https://avatars0.githubusercontent.com/u/4586769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AshishBora", "html_url": "https://github.com/AshishBora", "followers_url": "https://api.github.com/users/AshishBora/followers", "following_url": "https://api.github.com/users/AshishBora/following{/other_user}", "gists_url": "https://api.github.com/users/AshishBora/gists{/gist_id}", "starred_url": "https://api.github.com/users/AshishBora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AshishBora/subscriptions", "organizations_url": "https://api.github.com/users/AshishBora/orgs", "repos_url": "https://api.github.com/users/AshishBora/repos", "events_url": "https://api.github.com/users/AshishBora/events{/privacy}", "received_events_url": "https://api.github.com/users/AshishBora/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-12T12:19:25Z", "updated_at": "2016-11-15T05:32:45Z", "author_association": "NONE", "body_html": "<p>The toy example in the previous post may be bad because it tries to compute gradient at 0 but the square root is not defined below zero. What I am actually trying to do is closer to this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ntensor1, tensor2 <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span>), tf.constant(<span class=\"pl-c1\">1.0</span>)\ntensor3, tensor4 <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">2.0</span>), tf.constant(<span class=\"pl-c1\">2.0</span>)\ntensor_list <span class=\"pl-k\">=</span> [tensor1 <span class=\"pl-k\">-</span> tensor2, tensor3 <span class=\"pl-k\">-</span> tensor4]\nloss <span class=\"pl-k\">=</span> tf.square(tf.global_norm(tensor_list))\n\ngrad <span class=\"pl-k\">=</span> tf.gradients(loss, tensor1)[<span class=\"pl-c1\">0</span>]\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span> grad.eval()</pre></div>", "body_text": "The toy example in the previous post may be bad because it tries to compute gradient at 0 but the square root is not defined below zero. What I am actually trying to do is closer to this:\nimport tensorflow as tf\n\ntensor1, tensor2 = tf.constant(1.0), tf.constant(1.0)\ntensor3, tensor4 = tf.constant(2.0), tf.constant(2.0)\ntensor_list = [tensor1 - tensor2, tensor3 - tensor4]\nloss = tf.square(tf.global_norm(tensor_list))\n\ngrad = tf.gradients(loss, tensor1)[0]\nwith tf.Session() as sess:\n    print grad.eval()", "body": "The toy example in the previous post may be bad because it tries to compute gradient at 0 but the square root is not defined below zero. What I am actually trying to do is closer to this:\n\n``` python\nimport tensorflow as tf\n\ntensor1, tensor2 = tf.constant(1.0), tf.constant(1.0)\ntensor3, tensor4 = tf.constant(2.0), tf.constant(2.0)\ntensor_list = [tensor1 - tensor2, tensor3 - tensor4]\nloss = tf.square(tf.global_norm(tensor_list))\n\ngrad = tf.gradients(loss, tensor1)[0]\nwith tf.Session() as sess:\n    print grad.eval()\n```\n"}