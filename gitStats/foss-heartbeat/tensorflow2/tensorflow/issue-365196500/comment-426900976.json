{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426900976", "html_url": "https://github.com/tensorflow/tensorflow/issues/22630#issuecomment-426900976", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22630", "id": 426900976, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjkwMDk3Ng==", "user": {"login": "Elites2017", "id": 35799396, "node_id": "MDQ6VXNlcjM1Nzk5Mzk2", "avatar_url": "https://avatars2.githubusercontent.com/u/35799396?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Elites2017", "html_url": "https://github.com/Elites2017", "followers_url": "https://api.github.com/users/Elites2017/followers", "following_url": "https://api.github.com/users/Elites2017/following{/other_user}", "gists_url": "https://api.github.com/users/Elites2017/gists{/gist_id}", "starred_url": "https://api.github.com/users/Elites2017/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Elites2017/subscriptions", "organizations_url": "https://api.github.com/users/Elites2017/orgs", "repos_url": "https://api.github.com/users/Elites2017/repos", "events_url": "https://api.github.com/users/Elites2017/events{/privacy}", "received_events_url": "https://api.github.com/users/Elites2017/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-04T06:32:44Z", "updated_at": "2018-10-04T06:32:44Z", "author_association": "NONE", "body_html": "<p>I gave the following model a try <a href=\"download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz\"></a><br>\nit stiils give me the warning of unsupported types.</p>\n<p>My model details :Found 1 possible inputs: (name=normalized_input_image_tensor, type=float(1), shape=[1,300,300,3])<br>\nNo variables spotted.<br>\nFound 1 possible outputs: (name=TFLite_Detection_PostProcess, op=TFLite_Detection_PostProcess)<br>\nFound 5595395 (5.59M) const parameters, 0 (0) variable parameters, and 0 control_edges<br>\nOp types used: 451 Const, 389 Identity, 105 Mul, 94 FakeQuantWithMinMaxVars, 70 Add, 35 Sub, 35 Relu6, 35 Rsqrt, 34 Conv2D, 25 Reshape, 13 DepthwiseConv2dNative, 12 BiasAdd, 2 ConcatV2, 1 TFLite_Detection_PostProcess, 1 Squeeze, 1 Sigmoid, 1 RealDiv, 1 Placeholder<br>\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:<br>\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=converting/tflite_graph.pb --show_flops --input_layer=normalized_input_image_tensor --input_layer_type=float --input_layer_shape=1,300,300,3 --output_layer=TFLite_Detection_PostProcess</p>\n<p>But it still gives me the error <strong>W tensorflow/contrib/lite/toco/tflite/operator.cc:879] Ignoring unsupported attribute type with key '_output_types'</strong> when trying to converting the exported graph (.pb file) to .tflite file although it's converted to .tflite file</p>\n<p>Exact command:<br>\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- <br>\n--input_file=/home/david/tensorflow/converting/tflite_graph.pb <br>\n--output_file=/home/david/tensorflow/converting/detect.tflite <br>\n--input_shapes=1,300,300,3 <br>\n--input_arrays=normalized_input_image_tensor <br>\n--output_arrays=TFLite_Detection_PostProcess <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--mean_values=128 <br>\n--std_values=128 <br>\n--change_concat_input_ranges=false <br>\n--allow_custom_ops <br>\n--default_ranges_min=0 <br>\n--default_ranges_max=6</p>", "body_text": "I gave the following model a try \nit stiils give me the warning of unsupported types.\nMy model details :Found 1 possible inputs: (name=normalized_input_image_tensor, type=float(1), shape=[1,300,300,3])\nNo variables spotted.\nFound 1 possible outputs: (name=TFLite_Detection_PostProcess, op=TFLite_Detection_PostProcess)\nFound 5595395 (5.59M) const parameters, 0 (0) variable parameters, and 0 control_edges\nOp types used: 451 Const, 389 Identity, 105 Mul, 94 FakeQuantWithMinMaxVars, 70 Add, 35 Sub, 35 Relu6, 35 Rsqrt, 34 Conv2D, 25 Reshape, 13 DepthwiseConv2dNative, 12 BiasAdd, 2 ConcatV2, 1 TFLite_Detection_PostProcess, 1 Squeeze, 1 Sigmoid, 1 RealDiv, 1 Placeholder\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=converting/tflite_graph.pb --show_flops --input_layer=normalized_input_image_tensor --input_layer_type=float --input_layer_shape=1,300,300,3 --output_layer=TFLite_Detection_PostProcess\nBut it still gives me the error W tensorflow/contrib/lite/toco/tflite/operator.cc:879] Ignoring unsupported attribute type with key '_output_types' when trying to converting the exported graph (.pb file) to .tflite file although it's converted to .tflite file\nExact command:\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \n--input_file=/home/david/tensorflow/converting/tflite_graph.pb \n--output_file=/home/david/tensorflow/converting/detect.tflite \n--input_shapes=1,300,300,3 \n--input_arrays=normalized_input_image_tensor \n--output_arrays=TFLite_Detection_PostProcess \n--inference_type=QUANTIZED_UINT8 \n--mean_values=128 \n--std_values=128 \n--change_concat_input_ranges=false \n--allow_custom_ops \n--default_ranges_min=0 \n--default_ranges_max=6", "body": "I gave the following model a try [](download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz)\r\n it stiils give me the warning of unsupported types.\r\n\r\nMy model details :Found 1 possible inputs: (name=normalized_input_image_tensor, type=float(1), shape=[1,300,300,3]) \r\nNo variables spotted.\r\nFound 1 possible outputs: (name=TFLite_Detection_PostProcess, op=TFLite_Detection_PostProcess) \r\nFound 5595395 (5.59M) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 451 Const, 389 Identity, 105 Mul, 94 FakeQuantWithMinMaxVars, 70 Add, 35 Sub, 35 Relu6, 35 Rsqrt, 34 Conv2D, 25 Reshape, 13 DepthwiseConv2dNative, 12 BiasAdd, 2 ConcatV2, 1 TFLite_Detection_PostProcess, 1 Squeeze, 1 Sigmoid, 1 RealDiv, 1 Placeholder\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=converting/tflite_graph.pb --show_flops --input_layer=normalized_input_image_tensor --input_layer_type=float --input_layer_shape=1,300,300,3 --output_layer=TFLite_Detection_PostProcess\r\n\r\nBut it still gives me the error **W tensorflow/contrib/lite/toco/tflite/operator.cc:879] Ignoring unsupported attribute type with key '_output_types'** when trying to converting the exported graph (.pb file) to .tflite file although it's converted to .tflite file\r\n\r\nExact command:\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=/home/david/tensorflow/converting/tflite_graph.pb \\\r\n--output_file=/home/david/tensorflow/converting/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays=TFLite_Detection_PostProcess \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_values=128 \\\r\n--change_concat_input_ranges=false \\\r\n--allow_custom_ops \\\r\n--default_ranges_min=0 \\\r\n--default_ranges_max=6 "}