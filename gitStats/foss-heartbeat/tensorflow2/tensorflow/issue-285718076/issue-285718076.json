{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15818", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15818/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15818/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15818/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15818", "id": 285718076, "node_id": "MDU6SXNzdWUyODU3MTgwNzY=", "number": 15818, "title": "Tensorflow Object Detection using Tensorflow Mobile", "user": {"login": "sekhar989", "id": 19548050, "node_id": "MDQ6VXNlcjE5NTQ4MDUw", "avatar_url": "https://avatars0.githubusercontent.com/u/19548050?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sekhar989", "html_url": "https://github.com/sekhar989", "followers_url": "https://api.github.com/users/sekhar989/followers", "following_url": "https://api.github.com/users/sekhar989/following{/other_user}", "gists_url": "https://api.github.com/users/sekhar989/gists{/gist_id}", "starred_url": "https://api.github.com/users/sekhar989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sekhar989/subscriptions", "organizations_url": "https://api.github.com/users/sekhar989/orgs", "repos_url": "https://api.github.com/users/sekhar989/repos", "events_url": "https://api.github.com/users/sekhar989/events{/privacy}", "received_events_url": "https://api.github.com/users/sekhar989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "derekjchow", "id": 1195088, "node_id": "MDQ6VXNlcjExOTUwODg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1195088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/derekjchow", "html_url": "https://github.com/derekjchow", "followers_url": "https://api.github.com/users/derekjchow/followers", "following_url": "https://api.github.com/users/derekjchow/following{/other_user}", "gists_url": "https://api.github.com/users/derekjchow/gists{/gist_id}", "starred_url": "https://api.github.com/users/derekjchow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/derekjchow/subscriptions", "organizations_url": "https://api.github.com/users/derekjchow/orgs", "repos_url": "https://api.github.com/users/derekjchow/repos", "events_url": "https://api.github.com/users/derekjchow/events{/privacy}", "received_events_url": "https://api.github.com/users/derekjchow/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "derekjchow", "id": 1195088, "node_id": "MDQ6VXNlcjExOTUwODg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1195088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/derekjchow", "html_url": "https://github.com/derekjchow", "followers_url": "https://api.github.com/users/derekjchow/followers", "following_url": "https://api.github.com/users/derekjchow/following{/other_user}", "gists_url": "https://api.github.com/users/derekjchow/gists{/gist_id}", "starred_url": "https://api.github.com/users/derekjchow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/derekjchow/subscriptions", "organizations_url": "https://api.github.com/users/derekjchow/orgs", "repos_url": "https://api.github.com/users/derekjchow/repos", "events_url": "https://api.github.com/users/derekjchow/events{/privacy}", "received_events_url": "https://api.github.com/users/derekjchow/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-01-03T15:24:15Z", "updated_at": "2018-11-14T19:14:28Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I am trying to use a custom model in the\u00a0<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\">TF-Detect Android Demo</a>.</p>\n<p><strong>model: ssd_mobilenet_v1_coco</strong></p>\n<p>The model is trained on 8 classes. After exporting the model I've optimised it using\u00a0Tensorflow-Mobile.</p>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n    --in_graph=frozen_inference_graph.pb \\\n    --out_graph=optimized_inf_graph.pb \\\n    --inputs='image_tensor' \\\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\n</code></pre>\n<p>The optimised graph is giving proper output in my local system, but when it's integrated in the application there is no output shown in the screen. But when I'm using the unoptimised graph (<code>frozen_inference_graph.pb</code>) in the application, it's working fine. I'm getting outputs.What am I doing wrong here?</p>\n<p>Have I written custom code: No<br>\nOS Platform and Distribution: Mac OS Sierra<br>\nTensorFlow installed from: Virtualenv installation<br>\nTensorFlow version: 1.4<br>\nBazel version: Build label: 0.7.0-homebrew<br>\nCUDA/cuDNN version: NA<br>\nGPU model and memory: NA<br>\nExact command to reproduce:</p>\n<ol>\n<li>Trained a <code>ssd_mobilenet_v1_coco</code> model using google cloud ml for 8 classes</li>\n<li>Exported the frozen graph from checkpoints using the below command set:</li>\n</ol>\n<pre><code>python export_inference_graph.py --input_type image_tensor \\\n     --pipeline_config_path training/ssd_inception_v2_coco.config \\\n     --trained_checkpoint_prefix training/model.ckpt-200000 \\\n     --output_directory frozen_graph/\n</code></pre>\n<p><code>export_inference_graph.py</code> is the python script provided in here <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py\">https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py</a>. Tested the <code>frozen_inference_graph.py</code> in my local system, it's working fine.</p>\n<ol start=\"3\">\n<li>Used the below command to convert the <code>frozen_inference_graph.py</code> to optimized graph:</li>\n</ol>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n    --in_graph=&lt;path to frozen_inference_graph.pb&gt; \\\n    --out_graph=&lt;path where optimized_inf_graph.pb will be stored&gt; \\\n    --inputs='image_tensor' \\\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\n</code></pre>\n<p>Tested the <code>optimized_inf_graph.pb</code> graph in my local system. It's working fine.</p>\n<ol start=\"4\">\n<li>\n<p>Copied the <code>optimized_inf_graph.pb</code> in <code>tensorflow/tensorflow/examples/android/assets/</code> folder. Also, copied <code>my_labels.txt</code> file in the assets folder.</p>\n</li>\n<li>\n<p>Replaced <code>ssd_mobilenet_v1_android_export.pb</code> with <code>optimized_inf_graph.pb</code> in DetectorActivity.java <a href=\"https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L65\">file</a></p>\n</li>\n</ol>\n<p>Replaced <code>coco_labels_list.txt</code> with <code>my_labels.txt</code> in DetectorActivity.java <a href=\"https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L67\">file</a></p>\n<p>Tf Detect:</p>\n<pre><code>private static final String TF_OD_API_MODEL_FILE =\n      \"file:///android_asset/optimized_inf_graph.pb\";\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/coco_labels_list.txt\";\n</code></pre>\n<p>My Version:</p>\n<pre><code>private static final String TF_OD_API_MODEL_FILE =\n      \"file:///android_asset/ssd_mobilenet_v1_android_export.pb\";\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/my_labels.txt\";\n</code></pre>\n<ol start=\"6\">\n<li>Installed on my phone: LG G4</li>\n</ol>", "body_text": "I am trying to use a custom model in the\u00a0TF-Detect Android Demo.\nmodel: ssd_mobilenet_v1_coco\nThe model is trained on 8 classes. After exporting the model I've optimised it using\u00a0Tensorflow-Mobile.\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n    --in_graph=frozen_inference_graph.pb \\\n    --out_graph=optimized_inf_graph.pb \\\n    --inputs='image_tensor' \\\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\n\nThe optimised graph is giving proper output in my local system, but when it's integrated in the application there is no output shown in the screen. But when I'm using the unoptimised graph (frozen_inference_graph.pb) in the application, it's working fine. I'm getting outputs.What am I doing wrong here?\nHave I written custom code: No\nOS Platform and Distribution: Mac OS Sierra\nTensorFlow installed from: Virtualenv installation\nTensorFlow version: 1.4\nBazel version: Build label: 0.7.0-homebrew\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce:\n\nTrained a ssd_mobilenet_v1_coco model using google cloud ml for 8 classes\nExported the frozen graph from checkpoints using the below command set:\n\npython export_inference_graph.py --input_type image_tensor \\\n     --pipeline_config_path training/ssd_inception_v2_coco.config \\\n     --trained_checkpoint_prefix training/model.ckpt-200000 \\\n     --output_directory frozen_graph/\n\nexport_inference_graph.py is the python script provided in here https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py. Tested the frozen_inference_graph.py in my local system, it's working fine.\n\nUsed the below command to convert the frozen_inference_graph.py to optimized graph:\n\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n    --in_graph=<path to frozen_inference_graph.pb> \\\n    --out_graph=<path where optimized_inf_graph.pb will be stored> \\\n    --inputs='image_tensor' \\\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\n\nTested the optimized_inf_graph.pb graph in my local system. It's working fine.\n\n\nCopied the optimized_inf_graph.pb in tensorflow/tensorflow/examples/android/assets/ folder. Also, copied my_labels.txt file in the assets folder.\n\n\nReplaced ssd_mobilenet_v1_android_export.pb with optimized_inf_graph.pb in DetectorActivity.java file\n\n\nReplaced coco_labels_list.txt with my_labels.txt in DetectorActivity.java file\nTf Detect:\nprivate static final String TF_OD_API_MODEL_FILE =\n      \"file:///android_asset/optimized_inf_graph.pb\";\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/coco_labels_list.txt\";\n\nMy Version:\nprivate static final String TF_OD_API_MODEL_FILE =\n      \"file:///android_asset/ssd_mobilenet_v1_android_export.pb\";\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/my_labels.txt\";\n\n\nInstalled on my phone: LG G4", "body": "I am trying to use a custom model in the\u00a0[TF-Detect Android Demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android).\r\n\r\n**model: ssd_mobilenet_v1_coco**\r\n\r\nThe model is trained on 8 classes. After exporting the model I've optimised it using\u00a0Tensorflow-Mobile.\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n    --in_graph=frozen_inference_graph.pb \\\r\n    --out_graph=optimized_inf_graph.pb \\\r\n    --inputs='image_tensor' \\\r\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\r\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\r\n```\r\nThe optimised graph is giving proper output in my local system, but when it's integrated in the application there is no output shown in the screen. But when I'm using the unoptimised graph (`frozen_inference_graph.pb`) in the application, it's working fine. I'm getting outputs.What am I doing wrong here?\r\n\r\n\r\nHave I written custom code: No\r\nOS Platform and Distribution: Mac OS Sierra\r\nTensorFlow installed from: Virtualenv installation\r\nTensorFlow version: 1.4\r\nBazel version: Build label: 0.7.0-homebrew\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce:\r\n\r\n1. Trained a `ssd_mobilenet_v1_coco` model using google cloud ml for 8 classes\r\n2. Exported the frozen graph from checkpoints using the below command set:\r\n\r\n```\r\npython export_inference_graph.py --input_type image_tensor \\\r\n     --pipeline_config_path training/ssd_inception_v2_coco.config \\\r\n     --trained_checkpoint_prefix training/model.ckpt-200000 \\\r\n     --output_directory frozen_graph/\r\n```\r\n\r\n`export_inference_graph.py` is the python script provided in here https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py. Tested the `frozen_inference_graph.py` in my local system, it's working fine.\r\n\r\n3. Used the below command to convert the `frozen_inference_graph.py` to optimized graph:\r\n\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n    --in_graph=<path to frozen_inference_graph.pb> \\\r\n    --out_graph=<path where optimized_inf_graph.pb will be stored> \\\r\n    --inputs='image_tensor' \\\r\n    --outputs='detection_boxes detection_scores detection_classes num_detections' \\\r\n    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'\r\n```\r\nTested the `optimized_inf_graph.pb` graph in my local system. It's working fine.\r\n\r\n4. Copied the `optimized_inf_graph.pb` in `tensorflow/tensorflow/examples/android/assets/` folder. Also, copied `my_labels.txt` file in the assets folder.\r\n\r\n5. Replaced `ssd_mobilenet_v1_android_export.pb` with `optimized_inf_graph.pb` in DetectorActivity.java [file](https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L65)\r\n\r\nReplaced `coco_labels_list.txt` with `my_labels.txt` in DetectorActivity.java [file](https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L67)\r\n\r\nTf Detect:\r\n```\r\nprivate static final String TF_OD_API_MODEL_FILE =\r\n      \"file:///android_asset/optimized_inf_graph.pb\";\r\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/coco_labels_list.txt\";\r\n```\r\n\r\nMy Version:\r\n```\r\nprivate static final String TF_OD_API_MODEL_FILE =\r\n      \"file:///android_asset/ssd_mobilenet_v1_android_export.pb\";\r\n  private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/my_labels.txt\";\r\n```\r\n\r\n6. Installed on my phone: LG G4"}