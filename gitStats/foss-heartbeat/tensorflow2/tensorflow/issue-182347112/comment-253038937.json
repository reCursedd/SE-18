{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253038937", "html_url": "https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-253038937", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4897", "id": 253038937, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MzAzODkzNw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-11T20:40:33Z", "updated_at": "2016-10-11T20:41:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>example_costs</code> in my example is a Python list of costs you want to differentiate with respect to, and you can change this list during runtime. For efficiency, you may want small number of per-example-cost gradient graphs and reuse them during runtime.</p>\n<p>Generally though, \"retrieve raw gradient\" request is ill-specified -- there's no place in TensorFlow where \"per-example gradients\" are added together since there's no notion of \"example\" when differentiating. IE, you can encode your examples as rows of data matrix, or as columns, or in some other way, and that would give you the same gradient, but different sets of \"per-example gradients\". The AD system of TensorFlow gives you freedom to choose example encoding and does not need to know about your choice, which I think is what's needed from a general computation framework.</p>\n<p>That said, it would be useful to see implementations of methods like Ian's or others that give ways of computing per-example gradients efficiently</p>", "body_text": "example_costs in my example is a Python list of costs you want to differentiate with respect to, and you can change this list during runtime. For efficiency, you may want small number of per-example-cost gradient graphs and reuse them during runtime.\nGenerally though, \"retrieve raw gradient\" request is ill-specified -- there's no place in TensorFlow where \"per-example gradients\" are added together since there's no notion of \"example\" when differentiating. IE, you can encode your examples as rows of data matrix, or as columns, or in some other way, and that would give you the same gradient, but different sets of \"per-example gradients\". The AD system of TensorFlow gives you freedom to choose example encoding and does not need to know about your choice, which I think is what's needed from a general computation framework.\nThat said, it would be useful to see implementations of methods like Ian's or others that give ways of computing per-example gradients efficiently", "body": "`example_costs` in my example is a Python list of costs you want to differentiate with respect to, and you can change this list during runtime. For efficiency, you may want small number of per-example-cost gradient graphs and reuse them during runtime.\n\nGenerally though, \"retrieve raw gradient\" request is ill-specified -- there's no place in TensorFlow where \"per-example gradients\" are added together since there's no notion of \"example\" when differentiating. IE, you can encode your examples as rows of data matrix, or as columns, or in some other way, and that would give you the same gradient, but different sets of \"per-example gradients\". The AD system of TensorFlow gives you freedom to choose example encoding and does not need to know about your choice, which I think is what's needed from a general computation framework.\n\nThat said, it would be useful to see implementations of methods like Ian's or others that give ways of computing per-example gradients efficiently\n"}