{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257531935", "html_url": "https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-257531935", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4897", "id": 257531935, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzUzMTkzNQ==", "user": {"login": "jpiabrantes", "id": 2369107, "node_id": "MDQ6VXNlcjIzNjkxMDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2369107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpiabrantes", "html_url": "https://github.com/jpiabrantes", "followers_url": "https://api.github.com/users/jpiabrantes/followers", "following_url": "https://api.github.com/users/jpiabrantes/following{/other_user}", "gists_url": "https://api.github.com/users/jpiabrantes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpiabrantes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpiabrantes/subscriptions", "organizations_url": "https://api.github.com/users/jpiabrantes/orgs", "repos_url": "https://api.github.com/users/jpiabrantes/repos", "events_url": "https://api.github.com/users/jpiabrantes/events{/privacy}", "received_events_url": "https://api.github.com/users/jpiabrantes/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-01T10:18:07Z", "updated_at": "2016-11-01T10:18:07Z", "author_association": "NONE", "body_html": "<p>When I ask tensorflow for the gradient of a function that returns a scalar for every example, tf just gives me one gradient instead of a gradient per example. My \"loss\" function is not a sum or average so I can't understand this behaviour. Simple example:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">3</span>] , <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>)\nW1 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>W1<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>],\n           <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.contrib.layers.xavier_initializer())\noutput <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(x,W1))\ngrads <span class=\"pl-k\">=</span> tf.gradients(output,[W1])\nsess <span class=\"pl-k\">=</span> tf.InteractiveSession()\ninit <span class=\"pl-k\">=</span> tf.initialize_all_variables()\nsess.run(init)\n<span class=\"pl-c1\">print</span> sess.run(grads,<span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x:np.random.rand(<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">3</span>)})\n<span class=\"pl-k\">&gt;&gt;</span>[array([[ <span class=\"pl-c1\">0.83393538</span>],\n       [ <span class=\"pl-c1\">0.16146532</span>],\n       [ <span class=\"pl-c1\">0.43589821</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)]</pre></div>", "body_text": "When I ask tensorflow for the gradient of a function that returns a scalar for every example, tf just gives me one gradient instead of a gradient per example. My \"loss\" function is not a sum or average so I can't understand this behaviour. Simple example:\nx = tf.placeholder(tf.float32, [None,3] , name=\"input\")\nW1 = tf.get_variable(\"W1\", shape=[3, 1],\n           initializer=tf.contrib.layers.xavier_initializer())\noutput = tf.nn.relu(tf.matmul(x,W1))\ngrads = tf.gradients(output,[W1])\nsess = tf.InteractiveSession()\ninit = tf.initialize_all_variables()\nsess.run(init)\nprint sess.run(grads,feed_dict={x:np.random.rand(10,3)})\n>>[array([[ 0.83393538],\n       [ 0.16146532],\n       [ 0.43589821]], dtype=float32)]", "body": "When I ask tensorflow for the gradient of a function that returns a scalar for every example, tf just gives me one gradient instead of a gradient per example. My \"loss\" function is not a sum or average so I can't understand this behaviour. Simple example:\n\n``` python\nx = tf.placeholder(tf.float32, [None,3] , name=\"input\")\nW1 = tf.get_variable(\"W1\", shape=[3, 1],\n           initializer=tf.contrib.layers.xavier_initializer())\noutput = tf.nn.relu(tf.matmul(x,W1))\ngrads = tf.gradients(output,[W1])\nsess = tf.InteractiveSession()\ninit = tf.initialize_all_variables()\nsess.run(init)\nprint sess.run(grads,feed_dict={x:np.random.rand(10,3)})\n>>[array([[ 0.83393538],\n       [ 0.16146532],\n       [ 0.43589821]], dtype=float32)]\n```\n"}