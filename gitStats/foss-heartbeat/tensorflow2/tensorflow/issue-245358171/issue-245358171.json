{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11744", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11744/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11744/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11744/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11744", "id": 245358171, "node_id": "MDU6SXNzdWUyNDUzNTgxNzE=", "number": 11744, "title": "can't understand tf.contrib.training.bucket_by_sequence_length", "user": {"login": "yanghoonkim", "id": 9985986, "node_id": "MDQ6VXNlcjk5ODU5ODY=", "avatar_url": "https://avatars2.githubusercontent.com/u/9985986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanghoonkim", "html_url": "https://github.com/yanghoonkim", "followers_url": "https://api.github.com/users/yanghoonkim/followers", "following_url": "https://api.github.com/users/yanghoonkim/following{/other_user}", "gists_url": "https://api.github.com/users/yanghoonkim/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanghoonkim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanghoonkim/subscriptions", "organizations_url": "https://api.github.com/users/yanghoonkim/orgs", "repos_url": "https://api.github.com/users/yanghoonkim/repos", "events_url": "https://api.github.com/users/yanghoonkim/events{/privacy}", "received_events_url": "https://api.github.com/users/yanghoonkim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-07-25T10:35:23Z", "updated_at": "2017-07-25T21:39:03Z", "closed_at": "2017-07-25T20:31:13Z", "author_association": "NONE", "body_html": "<pre><code>seqLen = 10\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3,5,4,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,3])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,2])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,5])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,4])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,1])))\n\nsequences, output = tf.contrib.training.bucket_by_sequence_length(input_length=seqLen, tensors= inputs, batch_size=[4,2], \n                                                                  bucket_boundaries =[4], allow_smaller_final_batch=True,\n                                              dynamic_pad=True, capacity=32)\n\ninit_op = tf.global_variables_initializer()\n\nsess = tf.Session()\n\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\ntry:\n    while not coord.should_stop():\n        s, o= sess.run([sequences, output])\n        print s\n        print '****'\n        print o\n        print '----'\n        coord.request_stop()\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\nfinally:\n    coord.request_stop()\n\ncoord.join(threads)\nsess.close()\n</code></pre>\n<p>It seems that the documentation of those bucketing function is quite not clear<br>\nI can't figure out why the result the this code is</p>\n<pre><code>[10 10]\n****\n[array([[2, 3, 3, 3, 3, 3, 5, 4, 3],\n       [2, 3, 3, 3, 3, 3, 5, 4, 3]]), array([[2, 3, 4],\n       [2, 3, 4]]), array([[3, 4, 3],\n       [3, 4, 3]]), array([[3, 4, 2],\n       [3, 4, 2]]), array([[3, 4, 5],\n       [3, 4, 5]]), array([[3, 4, 4],\n       [3, 4, 4]]), array([[3, 4, 1],\n       [3, 4, 1]])]\n----\n</code></pre>\n<p>what I intended was :  batch size 4 for those input length are smaller than 4,  batch size 2 for those input length is bigger or the same as 4(because the bucket_boundaries = [4])</p>\n<p>There was a similar post before <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"189281953\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5609\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5609/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5609\">#5609</a> but I still think that there lacks a  proper example for it.</p>\n<p>which point do i misunderstand about?</p>", "body_text": "seqLen = 10\ninputs = []\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3,5,4,3])))\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,3])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,2])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,5])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,4])))\ninputs.append(tf.convert_to_tensor(np.array([3,4,1])))\n\nsequences, output = tf.contrib.training.bucket_by_sequence_length(input_length=seqLen, tensors= inputs, batch_size=[4,2], \n                                                                  bucket_boundaries =[4], allow_smaller_final_batch=True,\n                                              dynamic_pad=True, capacity=32)\n\ninit_op = tf.global_variables_initializer()\n\nsess = tf.Session()\n\nsess.run(init_op)\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\ntry:\n    while not coord.should_stop():\n        s, o= sess.run([sequences, output])\n        print s\n        print '****'\n        print o\n        print '----'\n        coord.request_stop()\n\nexcept tf.errors.OutOfRangeError:\n    print('Done training -- epoch limit reached')\nfinally:\n    coord.request_stop()\n\ncoord.join(threads)\nsess.close()\n\nIt seems that the documentation of those bucketing function is quite not clear\nI can't figure out why the result the this code is\n[10 10]\n****\n[array([[2, 3, 3, 3, 3, 3, 5, 4, 3],\n       [2, 3, 3, 3, 3, 3, 5, 4, 3]]), array([[2, 3, 4],\n       [2, 3, 4]]), array([[3, 4, 3],\n       [3, 4, 3]]), array([[3, 4, 2],\n       [3, 4, 2]]), array([[3, 4, 5],\n       [3, 4, 5]]), array([[3, 4, 4],\n       [3, 4, 4]]), array([[3, 4, 1],\n       [3, 4, 1]])]\n----\n\nwhat I intended was :  batch size 4 for those input length are smaller than 4,  batch size 2 for those input length is bigger or the same as 4(because the bucket_boundaries = [4])\nThere was a similar post before #5609 but I still think that there lacks a  proper example for it.\nwhich point do i misunderstand about?", "body": "```\r\nseqLen = 10\r\ninputs = []\r\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3,5,4,3])))\r\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,3])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,2])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,5])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,4])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,1])))\r\n\r\nsequences, output = tf.contrib.training.bucket_by_sequence_length(input_length=seqLen, tensors= inputs, batch_size=[4,2], \r\n                                                                  bucket_boundaries =[4], allow_smaller_final_batch=True,\r\n                                              dynamic_pad=True, capacity=32)\r\n\r\ninit_op = tf.global_variables_initializer()\r\n\r\nsess = tf.Session()\r\n\r\nsess.run(init_op)\r\n\r\ncoord = tf.train.Coordinator()\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\ntry:\r\n    while not coord.should_stop():\r\n        s, o= sess.run([sequences, output])\r\n        print s\r\n        print '****'\r\n        print o\r\n        print '----'\r\n        coord.request_stop()\r\n\r\nexcept tf.errors.OutOfRangeError:\r\n    print('Done training -- epoch limit reached')\r\nfinally:\r\n    coord.request_stop()\r\n\r\ncoord.join(threads)\r\nsess.close()\r\n```\r\nIt seems that the documentation of those bucketing function is quite not clear\r\nI can't figure out why the result the this code is \r\n```\r\n[10 10]\r\n****\r\n[array([[2, 3, 3, 3, 3, 3, 5, 4, 3],\r\n       [2, 3, 3, 3, 3, 3, 5, 4, 3]]), array([[2, 3, 4],\r\n       [2, 3, 4]]), array([[3, 4, 3],\r\n       [3, 4, 3]]), array([[3, 4, 2],\r\n       [3, 4, 2]]), array([[3, 4, 5],\r\n       [3, 4, 5]]), array([[3, 4, 4],\r\n       [3, 4, 4]]), array([[3, 4, 1],\r\n       [3, 4, 1]])]\r\n----\r\n```\r\n\r\nwhat I intended was :  batch size 4 for those input length are smaller than 4,  batch size 2 for those input length is bigger or the same as 4(because the bucket_boundaries = [4])\r\n\r\nThere was a similar post before #5609 but I still think that there lacks a  proper example for it.\r\n\r\nwhich point do i misunderstand about?"}