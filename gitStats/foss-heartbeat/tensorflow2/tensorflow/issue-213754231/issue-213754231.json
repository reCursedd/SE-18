{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8352", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8352/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8352/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8352/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8352", "id": 213754231, "node_id": "MDU6SXNzdWUyMTM3NTQyMzE=", "number": 8352, "title": "GPU memory problem when using tensorflow 1.0.0 on TITAN X (Pascal) ", "user": {"login": "stephenjia", "id": 9429707, "node_id": "MDQ6VXNlcjk0Mjk3MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/9429707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stephenjia", "html_url": "https://github.com/stephenjia", "followers_url": "https://api.github.com/users/stephenjia/followers", "following_url": "https://api.github.com/users/stephenjia/following{/other_user}", "gists_url": "https://api.github.com/users/stephenjia/gists{/gist_id}", "starred_url": "https://api.github.com/users/stephenjia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stephenjia/subscriptions", "organizations_url": "https://api.github.com/users/stephenjia/orgs", "repos_url": "https://api.github.com/users/stephenjia/repos", "events_url": "https://api.github.com/users/stephenjia/events{/privacy}", "received_events_url": "https://api.github.com/users/stephenjia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-03-13T12:37:30Z", "updated_at": "2017-07-02T04:53:29Z", "closed_at": "2017-03-13T18:30:29Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Fedora 25<br>\ncuda 8.0 and cuDNN 5.1<br>\nTITAN X (Pascal) and Driver Version: 375.26</p>\n<p>I installed tensorflow 1.0.0 using pip install under anaconda<br>\n<a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl</a></p>\n<p>I have a problem when using tensorflow on TITAN X (Pascal) . I am able to ran my code on other type of GPUs. I also tried running theano and matconvnet on the same GPU but there is no problem.</p>\n<p>I tried several ways to check it.</p>\n<ol>\n<li>if I directly run sess = tf.Session(), it gets stuck there.</li>\n</ol>\n<p>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:<br>\nname: TITAN X (Pascal)<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 11.90GiB<br>\nFree memory: 10.97GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)<br>\nKilled</p>\n<ol start=\"2\">\n<li>I also tried to set allow_growth=True and it is able to run tf.Session.<br>\ngpu_options= tf.GPUOptions(allow_growth=True)<br>\ntf_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, gpu_options=gpu_options)<br>\nsess = tf.Session(config=tf_config)</li>\n</ol>\n<p>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:<br>\nname: TITAN X (Pascal)<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 11.90GiB<br>\nFree memory: 10.97GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)<br>\nDevice mapping:<br>\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0<br>\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:<br>\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0</p>\n<p>I check the GPU memory being used, it is 151MB.</p>\n<ol start=\"3\">\n<li>I also tried to allocate different amount of GPU memory in the following way and it crashed.<br>\ntf_config = tf.ConfigProto()<br>\ntf_config.gpu_options.per_process_gpu_memory_fraction = 0.1<br>\nsess = tf.Session(config=tf_config)</li>\n</ol>\n<p>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:<br>\nname: TITAN X (Pascal)<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 11.90GiB<br>\nFree memory: 10.97GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)<br>\nterminate called after throwing an instance of 'std::system_error'<br>\nwhat():  Resource temporarily unavailable<br>\nAborted (core dumped)</p>\n<p>Can anyone help me on this? Thanks a lot.</p>", "body_text": "Environment info\nOperating System: Fedora 25\ncuda 8.0 and cuDNN 5.1\nTITAN X (Pascal) and Driver Version: 375.26\nI installed tensorflow 1.0.0 using pip install under anaconda\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\nI have a problem when using tensorflow on TITAN X (Pascal) . I am able to ran my code on other type of GPUs. I also tried running theano and matconvnet on the same GPU but there is no problem.\nI tried several ways to check it.\n\nif I directly run sess = tf.Session(), it gets stuck there.\n\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 10.97GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\nKilled\n\nI also tried to set allow_growth=True and it is able to run tf.Session.\ngpu_options= tf.GPUOptions(allow_growth=True)\ntf_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, gpu_options=gpu_options)\nsess = tf.Session(config=tf_config)\n\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 10.97GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\nI check the GPU memory being used, it is 151MB.\n\nI also tried to allocate different amount of GPU memory in the following way and it crashed.\ntf_config = tf.ConfigProto()\ntf_config.gpu_options.per_process_gpu_memory_fraction = 0.1\nsess = tf.Session(config=tf_config)\n\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 10.97GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\nterminate called after throwing an instance of 'std::system_error'\nwhat():  Resource temporarily unavailable\nAborted (core dumped)\nCan anyone help me on this? Thanks a lot.", "body": "### Environment info\r\nOperating System: Fedora 25\r\ncuda 8.0 and cuDNN 5.1\r\nTITAN X (Pascal) and Driver Version: 375.26\r\n\r\nI installed tensorflow 1.0.0 using pip install under anaconda\r\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\r\n\r\nI have a problem when using tensorflow on TITAN X (Pascal) . I am able to ran my code on other type of GPUs. I also tried running theano and matconvnet on the same GPU but there is no problem.\r\n\r\nI tried several ways to check it.\r\n1. if I directly run sess = tf.Session(), it gets stuck there.\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nKilled\r\n\r\n2. I also tried to set allow_growth=True and it is able to run tf.Session.\r\ngpu_options= tf.GPUOptions(allow_growth=True)\r\ntf_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, gpu_options=gpu_options)\r\nsess = tf.Session(config=tf_config)\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\r\n\r\nI check the GPU memory being used, it is 151MB.\r\n\r\n3. I also tried to allocate different amount of GPU memory in the following way and it crashed.\r\ntf_config = tf.ConfigProto()\r\ntf_config.gpu_options.per_process_gpu_memory_fraction = 0.1\r\nsess = tf.Session(config=tf_config)\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Resource temporarily unavailable\r\nAborted (core dumped)\r\n\r\nCan anyone help me on this? Thanks a lot."}