{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284146645", "html_url": "https://github.com/tensorflow/tensorflow/issues/3845#issuecomment-284146645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3845", "id": 284146645, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDE0NjY0NQ==", "user": {"login": "sunsided", "id": 495335, "node_id": "MDQ6VXNlcjQ5NTMzNQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/495335?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunsided", "html_url": "https://github.com/sunsided", "followers_url": "https://api.github.com/users/sunsided/followers", "following_url": "https://api.github.com/users/sunsided/following{/other_user}", "gists_url": "https://api.github.com/users/sunsided/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunsided/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunsided/subscriptions", "organizations_url": "https://api.github.com/users/sunsided/orgs", "repos_url": "https://api.github.com/users/sunsided/repos", "events_url": "https://api.github.com/users/sunsided/events{/privacy}", "received_events_url": "https://api.github.com/users/sunsided/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-04T11:48:55Z", "updated_at": "2017-03-04T11:50:51Z", "author_association": "NONE", "body_html": "<p>The same happens when building TensorFlow 1.0 on Tegra (Nvidia Jetson TX1) and cuda 8.0.34 (so for me, it's sort of related to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128321728\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/851\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/851/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/851\">#851</a>). Patching away the <code>#error</code> as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14196089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/npanpaliya\">@npanpaliya</a> described (I had to do this trick once with Caffe) did not help for me; in fact, some of the cuda sources do <em>seem</em> to get compiled. I tried both the 1.0 tag as well as master for a while now and nothing seems to work.</p>\n<p>Here's the system info:</p>\n<pre><code>Linux tegra-ubuntu 3.10.96-tegra #1 SMP PREEMPT Wed Nov 9 19:42:57 PST 2016 aarch64 aarch64 aarch64 GNU/Linux\n\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.2 LTS\nRelease:        16.04\nCodename:       xenial\n</code></pre>\n<p>I started the build using</p>\n<pre><code>bazel build --verbose_failures --local_resources 2048,.5,1.0 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<p>At one point it was complaining abount <code>cwise_op_gpu_select.cu.pic.o</code>, during the last try it apparently chose to fail at <code>softmax_op_gpu.cu.pic.o</code>:</p>\n<pre><code>INFO: From Compiling tensorflow/core/common_runtime/gpu/gpu_tracer.cc:\ntensorflow/core/common_runtime/gpu/gpu_tracer.cc:82:13: warning: 'const char* {anonymous}::getActivityOverheadKindString(CUpti_ActivityOverheadKind)' defined but not used [-Wunused-function]\n const char *getActivityOverheadKindString(CUpti_ActivityOverheadKind kind) {\n             ^\nINFO: From Compiling tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc: In function 'const char* tensorflow::GrpcWorkerMethodName(tensorflow::GrpcWorkerMethod)':\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:50:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nINFO: From Compiling tensorflow/core/debug/debug_io_utils.cc:\ntensorflow/core/debug/debug_io_utils.cc:306:15: warning: 'tensorflow::Status tensorflow::CloseDebugURL(const string&amp;)' defined but not used [-Wunused-function]\n static Status CloseDebugURL(const string&amp; debug_url) { return Status::OK(); }\n               ^\nINFO: From Compiling tensorflow/core/kernels/softmax_op_gpu.cu.cc:\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h(275): internal error: assertion failed at: \"/dvs/p4/build/sw/rel/gpu_drv/r361/r361_00/drivers/compiler/edg/EDG_4.10/src/folding.c\", line 9819\n\n\n1 catastrophic error detected in the compilation of \"/tmp/tmpxft_00003c5c_00000000-9_softmax_op_gpu.cu.compute_52.cpp1.ii\".\nCompilation aborted.\nAborted\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: output 'tensorflow/core/kernels/_objs/softmax_op_gpu/tensorflow/core/kernels/softmax_op_gpu.cu.pic.o' was not created.\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: not all outputs were created or valid.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 6367.284s, Critical Path: 5141.64s\n</code></pre>", "body_text": "The same happens when building TensorFlow 1.0 on Tegra (Nvidia Jetson TX1) and cuda 8.0.34 (so for me, it's sort of related to #851). Patching away the #error as @npanpaliya described (I had to do this trick once with Caffe) did not help for me; in fact, some of the cuda sources do seem to get compiled. I tried both the 1.0 tag as well as master for a while now and nothing seems to work.\nHere's the system info:\nLinux tegra-ubuntu 3.10.96-tegra #1 SMP PREEMPT Wed Nov 9 19:42:57 PST 2016 aarch64 aarch64 aarch64 GNU/Linux\n\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.2 LTS\nRelease:        16.04\nCodename:       xenial\n\nI started the build using\nbazel build --verbose_failures --local_resources 2048,.5,1.0 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nAt one point it was complaining abount cwise_op_gpu_select.cu.pic.o, during the last try it apparently chose to fail at softmax_op_gpu.cu.pic.o:\nINFO: From Compiling tensorflow/core/common_runtime/gpu/gpu_tracer.cc:\ntensorflow/core/common_runtime/gpu/gpu_tracer.cc:82:13: warning: 'const char* {anonymous}::getActivityOverheadKindString(CUpti_ActivityOverheadKind)' defined but not used [-Wunused-function]\n const char *getActivityOverheadKindString(CUpti_ActivityOverheadKind kind) {\n             ^\nINFO: From Compiling tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc: In function 'const char* tensorflow::GrpcWorkerMethodName(tensorflow::GrpcWorkerMethod)':\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:50:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\nINFO: From Compiling tensorflow/core/debug/debug_io_utils.cc:\ntensorflow/core/debug/debug_io_utils.cc:306:15: warning: 'tensorflow::Status tensorflow::CloseDebugURL(const string&)' defined but not used [-Wunused-function]\n static Status CloseDebugURL(const string& debug_url) { return Status::OK(); }\n               ^\nINFO: From Compiling tensorflow/core/kernels/softmax_op_gpu.cu.cc:\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h(275): internal error: assertion failed at: \"/dvs/p4/build/sw/rel/gpu_drv/r361/r361_00/drivers/compiler/edg/EDG_4.10/src/folding.c\", line 9819\n\n\n1 catastrophic error detected in the compilation of \"/tmp/tmpxft_00003c5c_00000000-9_softmax_op_gpu.cu.compute_52.cpp1.ii\".\nCompilation aborted.\nAborted\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: output 'tensorflow/core/kernels/_objs/softmax_op_gpu/tensorflow/core/kernels/softmax_op_gpu.cu.pic.o' was not created.\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: not all outputs were created or valid.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 6367.284s, Critical Path: 5141.64s", "body": "The same happens when building TensorFlow 1.0 on Tegra (Nvidia Jetson TX1) and cuda 8.0.34 (so for me, it's sort of related to #851). Patching away the `#error` as @npanpaliya described (I had to do this trick once with Caffe) did not help for me; in fact, some of the cuda sources do _seem_ to get compiled. I tried both the 1.0 tag as well as master for a while now and nothing seems to work.\r\n\r\nHere's the system info:\r\n\r\n```\r\nLinux tegra-ubuntu 3.10.96-tegra #1 SMP PREEMPT Wed Nov 9 19:42:57 PST 2016 aarch64 aarch64 aarch64 GNU/Linux\r\n\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 16.04.2 LTS\r\nRelease:        16.04\r\nCodename:       xenial\r\n```\r\n\r\nI started the build using\r\n\r\n```\r\nbazel build --verbose_failures --local_resources 2048,.5,1.0 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nAt one point it was complaining abount `cwise_op_gpu_select.cu.pic.o`, during the last try it apparently chose to fail at `softmax_op_gpu.cu.pic.o`:\r\n```\r\nINFO: From Compiling tensorflow/core/common_runtime/gpu/gpu_tracer.cc:\r\ntensorflow/core/common_runtime/gpu/gpu_tracer.cc:82:13: warning: 'const char* {anonymous}::getActivityOverheadKindString(CUpti_ActivityOverheadKind)' defined but not used [-Wunused-function]\r\n const char *getActivityOverheadKindString(CUpti_ActivityOverheadKind kind) {\r\n             ^\r\nINFO: From Compiling tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:\r\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc: In function 'const char* tensorflow::GrpcWorkerMethodName(tensorflow::GrpcWorkerMethod)':\r\ntensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:50:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\nINFO: From Compiling tensorflow/core/debug/debug_io_utils.cc:\r\ntensorflow/core/debug/debug_io_utils.cc:306:15: warning: 'tensorflow::Status tensorflow::CloseDebugURL(const string&)' defined but not used [-Wunused-function]\r\n static Status CloseDebugURL(const string& debug_url) { return Status::OK(); }\r\n               ^\r\nINFO: From Compiling tensorflow/core/kernels/softmax_op_gpu.cu.cc:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h(275): internal error: assertion failed at: \"/dvs/p4/build/sw/rel/gpu_drv/r361/r361_00/drivers/compiler/edg/EDG_4.10/src/folding.c\", line 9819\r\n\r\n\r\n1 catastrophic error detected in the compilation of \"/tmp/tmpxft_00003c5c_00000000-9_softmax_op_gpu.cu.compute_52.cpp1.ii\".\r\nCompilation aborted.\r\nAborted\r\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: output 'tensorflow/core/kernels/_objs/softmax_op_gpu/tensorflow/core/kernels/softmax_op_gpu.cu.pic.o' was not created.\r\nERROR: /mnt/tensorflow/tensorflow/core/kernels/BUILD:2531:1: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6367.284s, Critical Path: 5141.64s\r\n```"}