{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391852262", "html_url": "https://github.com/tensorflow/tensorflow/issues/19361#issuecomment-391852262", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19361", "id": 391852262, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTg1MjI2Mg==", "user": {"login": "mattjj", "id": 1458824, "node_id": "MDQ6VXNlcjE0NTg4MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1458824?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattjj", "html_url": "https://github.com/mattjj", "followers_url": "https://api.github.com/users/mattjj/followers", "following_url": "https://api.github.com/users/mattjj/following{/other_user}", "gists_url": "https://api.github.com/users/mattjj/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattjj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattjj/subscriptions", "organizations_url": "https://api.github.com/users/mattjj/orgs", "repos_url": "https://api.github.com/users/mattjj/repos", "events_url": "https://api.github.com/users/mattjj/events{/privacy}", "received_events_url": "https://api.github.com/users/mattjj/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-24T20:40:39Z", "updated_at": "2018-05-24T20:41:22Z", "author_association": "NONE", "body_html": "<p>Here are two ways to get forward-mode autodiff in TensorFlow:</p>\n<ol>\n<li>You can use <a href=\"https://github.com/renmengye/tensorflow-forward-ad\">the tensorflow-forward-ad package</a>,</li>\n<li>You can use <a href=\"https://github.com/renmengye/tensorflow-forward-ad/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/renmengye/tensorflow-forward-ad/issues/2/hovercard\">this trick for building a graph that implements efficient forward-mode autodiff by calling <code>tf.gradients</code> twice</a>.</li>\n</ol>\n<p>The latter is simpler and doesn't require any new dependencies, but there might be some corner cases it doesn't handle (as discussed in that thread). There's a wrapper that deals with a few of those corner-cases in the <a href=\"https://github.com/tensorflow/kfac/blob/master/kfac/python/ops/utils.py\">K-FAC utils.py module</a> (look for <code>fwd_gradients</code>), though it's essentially the same code. As far as I know, there's no official version of this trick included TensorFlow, though I know several researchers who've used it.</p>\n<p>For more detail on how that trick works, see <a href=\"https://j-towns.github.io/2017/06/12/A-new-trick.html\" rel=\"nofollow\">this blog post</a> by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15261883\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/j-towns\">@j-towns</a> (a recent Brain intern!).</p>", "body_text": "Here are two ways to get forward-mode autodiff in TensorFlow:\n\nYou can use the tensorflow-forward-ad package,\nYou can use this trick for building a graph that implements efficient forward-mode autodiff by calling tf.gradients twice.\n\nThe latter is simpler and doesn't require any new dependencies, but there might be some corner cases it doesn't handle (as discussed in that thread). There's a wrapper that deals with a few of those corner-cases in the K-FAC utils.py module (look for fwd_gradients), though it's essentially the same code. As far as I know, there's no official version of this trick included TensorFlow, though I know several researchers who've used it.\nFor more detail on how that trick works, see this blog post by @j-towns (a recent Brain intern!).", "body": "Here are two ways to get forward-mode autodiff in TensorFlow:\r\n\r\n1. You can use [the tensorflow-forward-ad package](https://github.com/renmengye/tensorflow-forward-ad),\r\n2. You can use [this trick for building a graph that implements efficient forward-mode autodiff by calling `tf.gradients` twice](https://github.com/renmengye/tensorflow-forward-ad/issues/2).\r\n\r\nThe latter is simpler and doesn't require any new dependencies, but there might be some corner cases it doesn't handle (as discussed in that thread). There's a wrapper that deals with a few of those corner-cases in the [K-FAC utils.py module](https://github.com/tensorflow/kfac/blob/master/kfac/python/ops/utils.py) (look for `fwd_gradients`), though it's essentially the same code. As far as I know, there's no official version of this trick included TensorFlow, though I know several researchers who've used it.\r\n\r\nFor more detail on how that trick works, see [this blog post](https://j-towns.github.io/2017/06/12/A-new-trick.html) by @j-towns (a recent Brain intern!)."}