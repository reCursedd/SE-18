{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23743", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23743/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23743/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23743/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23743", "id": 380742354, "node_id": "MDU6SXNzdWUzODA3NDIzNTQ=", "number": 23743, "title": "ckpt file only has .meta file , no .index file or .data file in every step to save", "user": {"login": "lei6315", "id": 17965302, "node_id": "MDQ6VXNlcjE3OTY1MzAy", "avatar_url": "https://avatars1.githubusercontent.com/u/17965302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lei6315", "html_url": "https://github.com/lei6315", "followers_url": "https://api.github.com/users/lei6315/followers", "following_url": "https://api.github.com/users/lei6315/following{/other_user}", "gists_url": "https://api.github.com/users/lei6315/gists{/gist_id}", "starred_url": "https://api.github.com/users/lei6315/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lei6315/subscriptions", "organizations_url": "https://api.github.com/users/lei6315/orgs", "repos_url": "https://api.github.com/users/lei6315/repos", "events_url": "https://api.github.com/users/lei6315/events{/privacy}", "received_events_url": "https://api.github.com/users/lei6315/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-11-14T15:09:49Z", "updated_at": "2018-11-22T13:52:06Z", "closed_at": "2018-11-22T13:52:06Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Liunx centos7.2</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary):binary</li>\n<li>TensorFlow version:1.11</li>\n<li>Python version:2.7</li>\n<li>Installed using virtualenv? pip? conda?:pip</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version: cuda9 cndnn7</li>\n<li>GPU model and memory:M40 12GB</li>\n</ul>\n<p><strong>Describe the problem</strong><br>\nI use MonitoredTrainingSession to train distribute tf  on 3 machines(1 ps , 2 workers), and it worked ,but the ckpt file  only has .meta file , no .index file or .data file in every step to save. The max train step was 1000,no errors in the training time.<br>\n<strong>Provide the exact sequence of commands / steps that you executed before running into the problem</strong></p>\n<pre><code>the file like this\n-rw-r--r-- 1 root root      693 11\u6708 14 22:10 checkpoint\n-rw-r--r-- 1 root root 17226852 11\u6708 14 22:12 events.out.tfevents.1542203421.node58\n-rw-r--r-- 1 root root  9268881 11\u6708 14 21:50 graph.pbtxt\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:10 model.ckpt-1000.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:02 model.ckpt-601.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:04 model.ckpt-701.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:06 model.ckpt-801.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:08 model.ckpt-901.meta\n</code></pre>\n<p><strong>Any other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>\n<pre><code>part of the log \nINFO:tensorflow:global_step/sec: 0.876005\nINFO:tensorflow:Saving checkpoints for 501 into /data0/users/haha/tensorflow-test/MonitoredTrainingSession_test/log/model.ckpt.\n2018-11-14 22:54:46.889383 : global step = 500, loss = 1.45 (12.6 examples/sec; 1.265sec/batch)\n2018-11-14 22:54:59.885239 : global step = 510, loss = 1.13 (12.3 examples/sec; 1.300sec/batch)\n2018-11-14 22:55:09.314735 : global step = 520, loss = 0.88 (17.0 examples/sec; 0.943sec/batch)\n2018-11-14 22:55:23.053285 : global step = 530, loss = 1.01 (11.6 examples/sec; 1.374sec/batch)\n\n</code></pre>\n<p>the code</p>\n<pre><code>def main(_):\ntf.logging.set_verbosity(tf.logging.INFO)\n    tf.reset_default_graph()\n    # 1.cluster spec\n    worker_spec = FLAGS.workerSpec.split(',')\n    ps_spec = FLAGS.psSpec.split(',')\n    print('cluster has %d workers, %d ps' % (len(worker_spec), len(ps_spec)))\n    cluster = tf.train.ClusterSpec({'worker': worker_spec,\n                                    'ps': ps_spec})\n    if FLAGS.job_name == 'ps':\n        server.join()\n    elif FLAGS.job_name == 'worker':\n        if FLAGS.gpu_num &gt; 0:\n            worker_device = \"/job:worker/task:{}/gpu:{}\".format(FLAGS.task_index, FLAGS.task_index % FLAGS.gpu_num)\n        else:\n            worker_device = \"/job:worker/task:{}/cpu:0\".format(FLAGS.task_index)\n\n        # 2. data  https://www.tensorflow.org/programmers_guide/datasets\n        with tf.device(tf.train.replica_device_setter(\n                                                      worker_device=worker_device,\n                                                      cluster=cluster)):\n            filenames = get_tfrecord_filenames(FLAGS.dataset_dir)\n            tf.logging.info(\"dataset %s:\" % filenames)\n            dataset = tf.data.TFRecordDataset(filenames)\n            dataset = dataset.map(parse_single_image)\n            dataset = dataset.shuffle(buffer_size=1000)\n            dataset = dataset.batch(FLAGS.batch_size)\n            dataset = dataset.repeat(FLAGS.epochs)\n            iterator = dataset.make_initializable_iterator()\n          \n            batch = iterator.get_next()\n            image_file_name, img_batch, label_batch = batch\n            print(img_batch, label_batch)\n\n            # 3. model\n            with slim.arg_scope(inception_v3_arg_scope()):\n                logits, _ = inception_v3(img_batch, 9)\n            predicts = tf.nn.softmax(logits)\n          \n            loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=tf.one_hot(label_batch, depth=9, on_value=1, off_value=0))\n\n            global_step = tf.train.get_or_create_global_step()\n            opt = tf.train.AdamOptimizer(FLAGS.lr)\n\n            if FLAGS.sync_replicas:\n                if FLAGS.replicas_to_aggregate is None:\n                    replicas_to_aggregate = len(worker_spec)\n                else:\n                    replicas_to_aggregate = FLAGS.replicas_to_aggregate\n                opt = tf.train.SyncReplicasOptimizer(opt,\n                                                     replicas_to_aggregate,\n                                                     total_num_replicas=len(worker_spec),\n                                                     #replica_id=FLAGS.task_index,\n                                                     name=\"sync_replicas_optimizer\")\n\n                sync_replicas_hook = opt.make_session_run_hook(is_chief=(FLAGS.task_index == 0), num_tokens=0)\n\n            train_op = opt.minimize(loss, global_step=global_step)\n\n        class _DatasetInitializerHook(tf.train.SessionRunHook):\n            def __init__(self, data_iterator):\n                super(_DatasetInitializerHook, self).__init__()\n                self._iterator = data_iterator\n\n            def begin(self):\n                self._initializer = self._iterator.initializer\n\n            def after_create_session(self, session, coord):\n                del coord\n                session.run(self._initializer)\n\n        class _LogHook(tf.train.SessionRunHook):\n            def __init__(self, global_step, loss, log_frequency, batch_size):\n                super(_LogHook, self).__init__()\n                self.loss = loss\n                self.global_step = global_step\n                self.log_frequency = log_frequency\n                self.batch_size = batch_size\n\n            def begin(self):\n                self.start_time = time.time()\n\n            def before_run(self, run_context):\n                return tf.train.SessionRunArgs([global_step,loss])\n\n            def after_run(self,\n                          run_context,  # pylint: disable=unused-argument\n                          run_values):\n                global_step_value, loss_value = run_values.results\n                if global_step_value % self.log_frequency == 0:\n                    current_time = time.time()\n                    duration = current_time - self.start_time\n                    self.start_time = current_time\n                    img_per_sec = self.log_frequency * self.batch_size / duration\n                    sec_per_batch = float(duration / self.log_frequency)\n                    format_str = ('%s : global step = %d, loss = %.2f (%.1f imgs/sec; %.3fsec/batch)')\n                    print(format_str % (datetime.now(), global_step_value, loss_value, img_per_sec, sec_per_batch))\n\n        # 4.train\n        saver=tf.train.Saver()\n        scaffold = tf.train.Scaffold(saver=saver)\n\n        hooks = [tf.train.StopAtStepHook(last_step=FLAGS.steps),\n                 tf.train.NanTensorHook(loss),\n                 _LogHook(global_step ,loss, FLAGS.log_frequency, FLAGS.batch_size),\n                 _DatasetInitializerHook(iterator),\n                 sync_replicas_hook]\n\n        config = tf.ConfigProto(allow_soft_placement=True,\n                                log_device_placement=False,\n                                device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\n        config.gpu_options.allow_growth = True\n\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=(FLAGS.task_index == 0),\n                                               checkpoint_dir=FLAGS.train_dir,\n                                               scaffold=scaffold,\n                                               hooks=hooks,\n                                               save_checkpoint_steps=100,\n                                               stop_grace_period_secs=5,\n                                               config=config) as mon_sess:\n\n            try:\n                while not mon_sess.should_stop():\n                    mon_sess.run(train_op)\n            except Exception as e:\n                print(e)\n\n</code></pre>\n<p>So,anyone to help me ? thank you !</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Liunx centos7.2\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary):binary\nTensorFlow version:1.11\nPython version:2.7\nInstalled using virtualenv? pip? conda?:pip\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: cuda9 cndnn7\nGPU model and memory:M40 12GB\n\nDescribe the problem\nI use MonitoredTrainingSession to train distribute tf  on 3 machines(1 ps , 2 workers), and it worked ,but the ckpt file  only has .meta file , no .index file or .data file in every step to save. The max train step was 1000,no errors in the training time.\nProvide the exact sequence of commands / steps that you executed before running into the problem\nthe file like this\n-rw-r--r-- 1 root root      693 11\u6708 14 22:10 checkpoint\n-rw-r--r-- 1 root root 17226852 11\u6708 14 22:12 events.out.tfevents.1542203421.node58\n-rw-r--r-- 1 root root  9268881 11\u6708 14 21:50 graph.pbtxt\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:10 model.ckpt-1000.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:02 model.ckpt-601.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:04 model.ckpt-701.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:06 model.ckpt-801.meta\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:08 model.ckpt-901.meta\n\nAny other info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\npart of the log \nINFO:tensorflow:global_step/sec: 0.876005\nINFO:tensorflow:Saving checkpoints for 501 into /data0/users/haha/tensorflow-test/MonitoredTrainingSession_test/log/model.ckpt.\n2018-11-14 22:54:46.889383 : global step = 500, loss = 1.45 (12.6 examples/sec; 1.265sec/batch)\n2018-11-14 22:54:59.885239 : global step = 510, loss = 1.13 (12.3 examples/sec; 1.300sec/batch)\n2018-11-14 22:55:09.314735 : global step = 520, loss = 0.88 (17.0 examples/sec; 0.943sec/batch)\n2018-11-14 22:55:23.053285 : global step = 530, loss = 1.01 (11.6 examples/sec; 1.374sec/batch)\n\n\nthe code\ndef main(_):\ntf.logging.set_verbosity(tf.logging.INFO)\n    tf.reset_default_graph()\n    # 1.cluster spec\n    worker_spec = FLAGS.workerSpec.split(',')\n    ps_spec = FLAGS.psSpec.split(',')\n    print('cluster has %d workers, %d ps' % (len(worker_spec), len(ps_spec)))\n    cluster = tf.train.ClusterSpec({'worker': worker_spec,\n                                    'ps': ps_spec})\n    if FLAGS.job_name == 'ps':\n        server.join()\n    elif FLAGS.job_name == 'worker':\n        if FLAGS.gpu_num > 0:\n            worker_device = \"/job:worker/task:{}/gpu:{}\".format(FLAGS.task_index, FLAGS.task_index % FLAGS.gpu_num)\n        else:\n            worker_device = \"/job:worker/task:{}/cpu:0\".format(FLAGS.task_index)\n\n        # 2. data  https://www.tensorflow.org/programmers_guide/datasets\n        with tf.device(tf.train.replica_device_setter(\n                                                      worker_device=worker_device,\n                                                      cluster=cluster)):\n            filenames = get_tfrecord_filenames(FLAGS.dataset_dir)\n            tf.logging.info(\"dataset %s:\" % filenames)\n            dataset = tf.data.TFRecordDataset(filenames)\n            dataset = dataset.map(parse_single_image)\n            dataset = dataset.shuffle(buffer_size=1000)\n            dataset = dataset.batch(FLAGS.batch_size)\n            dataset = dataset.repeat(FLAGS.epochs)\n            iterator = dataset.make_initializable_iterator()\n          \n            batch = iterator.get_next()\n            image_file_name, img_batch, label_batch = batch\n            print(img_batch, label_batch)\n\n            # 3. model\n            with slim.arg_scope(inception_v3_arg_scope()):\n                logits, _ = inception_v3(img_batch, 9)\n            predicts = tf.nn.softmax(logits)\n          \n            loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=tf.one_hot(label_batch, depth=9, on_value=1, off_value=0))\n\n            global_step = tf.train.get_or_create_global_step()\n            opt = tf.train.AdamOptimizer(FLAGS.lr)\n\n            if FLAGS.sync_replicas:\n                if FLAGS.replicas_to_aggregate is None:\n                    replicas_to_aggregate = len(worker_spec)\n                else:\n                    replicas_to_aggregate = FLAGS.replicas_to_aggregate\n                opt = tf.train.SyncReplicasOptimizer(opt,\n                                                     replicas_to_aggregate,\n                                                     total_num_replicas=len(worker_spec),\n                                                     #replica_id=FLAGS.task_index,\n                                                     name=\"sync_replicas_optimizer\")\n\n                sync_replicas_hook = opt.make_session_run_hook(is_chief=(FLAGS.task_index == 0), num_tokens=0)\n\n            train_op = opt.minimize(loss, global_step=global_step)\n\n        class _DatasetInitializerHook(tf.train.SessionRunHook):\n            def __init__(self, data_iterator):\n                super(_DatasetInitializerHook, self).__init__()\n                self._iterator = data_iterator\n\n            def begin(self):\n                self._initializer = self._iterator.initializer\n\n            def after_create_session(self, session, coord):\n                del coord\n                session.run(self._initializer)\n\n        class _LogHook(tf.train.SessionRunHook):\n            def __init__(self, global_step, loss, log_frequency, batch_size):\n                super(_LogHook, self).__init__()\n                self.loss = loss\n                self.global_step = global_step\n                self.log_frequency = log_frequency\n                self.batch_size = batch_size\n\n            def begin(self):\n                self.start_time = time.time()\n\n            def before_run(self, run_context):\n                return tf.train.SessionRunArgs([global_step,loss])\n\n            def after_run(self,\n                          run_context,  # pylint: disable=unused-argument\n                          run_values):\n                global_step_value, loss_value = run_values.results\n                if global_step_value % self.log_frequency == 0:\n                    current_time = time.time()\n                    duration = current_time - self.start_time\n                    self.start_time = current_time\n                    img_per_sec = self.log_frequency * self.batch_size / duration\n                    sec_per_batch = float(duration / self.log_frequency)\n                    format_str = ('%s : global step = %d, loss = %.2f (%.1f imgs/sec; %.3fsec/batch)')\n                    print(format_str % (datetime.now(), global_step_value, loss_value, img_per_sec, sec_per_batch))\n\n        # 4.train\n        saver=tf.train.Saver()\n        scaffold = tf.train.Scaffold(saver=saver)\n\n        hooks = [tf.train.StopAtStepHook(last_step=FLAGS.steps),\n                 tf.train.NanTensorHook(loss),\n                 _LogHook(global_step ,loss, FLAGS.log_frequency, FLAGS.batch_size),\n                 _DatasetInitializerHook(iterator),\n                 sync_replicas_hook]\n\n        config = tf.ConfigProto(allow_soft_placement=True,\n                                log_device_placement=False,\n                                device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\n        config.gpu_options.allow_growth = True\n\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=(FLAGS.task_index == 0),\n                                               checkpoint_dir=FLAGS.train_dir,\n                                               scaffold=scaffold,\n                                               hooks=hooks,\n                                               save_checkpoint_steps=100,\n                                               stop_grace_period_secs=5,\n                                               config=config) as mon_sess:\n\n            try:\n                while not mon_sess.should_stop():\n                    mon_sess.run(train_op)\n            except Exception as e:\n                print(e)\n\n\nSo,anyone to help me ? thank you !", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Liunx centos7.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version:1.11\r\n- Python version:2.7\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda9 cndnn7\r\n- GPU model and memory:M40 12GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI use MonitoredTrainingSession to train distribute tf  on 3 machines(1 ps , 2 workers), and it worked ,but the ckpt file  only has .meta file , no .index file or .data file in every step to save. The max train step was 1000,no errors in the training time.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nthe file like this\r\n-rw-r--r-- 1 root root      693 11\u6708 14 22:10 checkpoint\r\n-rw-r--r-- 1 root root 17226852 11\u6708 14 22:12 events.out.tfevents.1542203421.node58\r\n-rw-r--r-- 1 root root  9268881 11\u6708 14 21:50 graph.pbtxt\r\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:10 model.ckpt-1000.meta\r\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:02 model.ckpt-601.meta\r\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:04 model.ckpt-701.meta\r\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:06 model.ckpt-801.meta\r\n-rw-r--r-- 1 root root  4858196 11\u6708 14 22:08 model.ckpt-901.meta\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\npart of the log \r\nINFO:tensorflow:global_step/sec: 0.876005\r\nINFO:tensorflow:Saving checkpoints for 501 into /data0/users/haha/tensorflow-test/MonitoredTrainingSession_test/log/model.ckpt.\r\n2018-11-14 22:54:46.889383 : global step = 500, loss = 1.45 (12.6 examples/sec; 1.265sec/batch)\r\n2018-11-14 22:54:59.885239 : global step = 510, loss = 1.13 (12.3 examples/sec; 1.300sec/batch)\r\n2018-11-14 22:55:09.314735 : global step = 520, loss = 0.88 (17.0 examples/sec; 0.943sec/batch)\r\n2018-11-14 22:55:23.053285 : global step = 530, loss = 1.01 (11.6 examples/sec; 1.374sec/batch)\r\n\r\n```\r\nthe code \r\n```\r\ndef main(_):\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.reset_default_graph()\r\n    # 1.cluster spec\r\n    worker_spec = FLAGS.workerSpec.split(',')\r\n    ps_spec = FLAGS.psSpec.split(',')\r\n    print('cluster has %d workers, %d ps' % (len(worker_spec), len(ps_spec)))\r\n    cluster = tf.train.ClusterSpec({'worker': worker_spec,\r\n                                    'ps': ps_spec})\r\n    if FLAGS.job_name == 'ps':\r\n        server.join()\r\n    elif FLAGS.job_name == 'worker':\r\n        if FLAGS.gpu_num > 0:\r\n            worker_device = \"/job:worker/task:{}/gpu:{}\".format(FLAGS.task_index, FLAGS.task_index % FLAGS.gpu_num)\r\n        else:\r\n            worker_device = \"/job:worker/task:{}/cpu:0\".format(FLAGS.task_index)\r\n\r\n        # 2. data  https://www.tensorflow.org/programmers_guide/datasets\r\n        with tf.device(tf.train.replica_device_setter(\r\n                                                      worker_device=worker_device,\r\n                                                      cluster=cluster)):\r\n            filenames = get_tfrecord_filenames(FLAGS.dataset_dir)\r\n            tf.logging.info(\"dataset %s:\" % filenames)\r\n            dataset = tf.data.TFRecordDataset(filenames)\r\n            dataset = dataset.map(parse_single_image)\r\n            dataset = dataset.shuffle(buffer_size=1000)\r\n            dataset = dataset.batch(FLAGS.batch_size)\r\n            dataset = dataset.repeat(FLAGS.epochs)\r\n            iterator = dataset.make_initializable_iterator()\r\n          \r\n            batch = iterator.get_next()\r\n            image_file_name, img_batch, label_batch = batch\r\n            print(img_batch, label_batch)\r\n\r\n            # 3. model\r\n            with slim.arg_scope(inception_v3_arg_scope()):\r\n                logits, _ = inception_v3(img_batch, 9)\r\n            predicts = tf.nn.softmax(logits)\r\n          \r\n            loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=tf.one_hot(label_batch, depth=9, on_value=1, off_value=0))\r\n\r\n            global_step = tf.train.get_or_create_global_step()\r\n            opt = tf.train.AdamOptimizer(FLAGS.lr)\r\n\r\n            if FLAGS.sync_replicas:\r\n                if FLAGS.replicas_to_aggregate is None:\r\n                    replicas_to_aggregate = len(worker_spec)\r\n                else:\r\n                    replicas_to_aggregate = FLAGS.replicas_to_aggregate\r\n                opt = tf.train.SyncReplicasOptimizer(opt,\r\n                                                     replicas_to_aggregate,\r\n                                                     total_num_replicas=len(worker_spec),\r\n                                                     #replica_id=FLAGS.task_index,\r\n                                                     name=\"sync_replicas_optimizer\")\r\n\r\n                sync_replicas_hook = opt.make_session_run_hook(is_chief=(FLAGS.task_index == 0), num_tokens=0)\r\n\r\n            train_op = opt.minimize(loss, global_step=global_step)\r\n\r\n        class _DatasetInitializerHook(tf.train.SessionRunHook):\r\n            def __init__(self, data_iterator):\r\n                super(_DatasetInitializerHook, self).__init__()\r\n                self._iterator = data_iterator\r\n\r\n            def begin(self):\r\n                self._initializer = self._iterator.initializer\r\n\r\n            def after_create_session(self, session, coord):\r\n                del coord\r\n                session.run(self._initializer)\r\n\r\n        class _LogHook(tf.train.SessionRunHook):\r\n            def __init__(self, global_step, loss, log_frequency, batch_size):\r\n                super(_LogHook, self).__init__()\r\n                self.loss = loss\r\n                self.global_step = global_step\r\n                self.log_frequency = log_frequency\r\n                self.batch_size = batch_size\r\n\r\n            def begin(self):\r\n                self.start_time = time.time()\r\n\r\n            def before_run(self, run_context):\r\n                return tf.train.SessionRunArgs([global_step,loss])\r\n\r\n            def after_run(self,\r\n                          run_context,  # pylint: disable=unused-argument\r\n                          run_values):\r\n                global_step_value, loss_value = run_values.results\r\n                if global_step_value % self.log_frequency == 0:\r\n                    current_time = time.time()\r\n                    duration = current_time - self.start_time\r\n                    self.start_time = current_time\r\n                    img_per_sec = self.log_frequency * self.batch_size / duration\r\n                    sec_per_batch = float(duration / self.log_frequency)\r\n                    format_str = ('%s : global step = %d, loss = %.2f (%.1f imgs/sec; %.3fsec/batch)')\r\n                    print(format_str % (datetime.now(), global_step_value, loss_value, img_per_sec, sec_per_batch))\r\n\r\n        # 4.train\r\n        saver=tf.train.Saver()\r\n        scaffold = tf.train.Scaffold(saver=saver)\r\n\r\n        hooks = [tf.train.StopAtStepHook(last_step=FLAGS.steps),\r\n                 tf.train.NanTensorHook(loss),\r\n                 _LogHook(global_step ,loss, FLAGS.log_frequency, FLAGS.batch_size),\r\n                 _DatasetInitializerHook(iterator),\r\n                 sync_replicas_hook]\r\n\r\n        config = tf.ConfigProto(allow_soft_placement=True,\r\n                                log_device_placement=False,\r\n                                device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\r\n        config.gpu_options.allow_growth = True\r\n\r\n        with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=(FLAGS.task_index == 0),\r\n                                               checkpoint_dir=FLAGS.train_dir,\r\n                                               scaffold=scaffold,\r\n                                               hooks=hooks,\r\n                                               save_checkpoint_steps=100,\r\n                                               stop_grace_period_secs=5,\r\n                                               config=config) as mon_sess:\r\n\r\n            try:\r\n                while not mon_sess.should_stop():\r\n                    mon_sess.run(train_op)\r\n            except Exception as e:\r\n                print(e)\r\n\r\n```\r\nSo,anyone to help me ? thank you ! "}