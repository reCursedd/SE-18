{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163685776", "pull_request_review_id": 91336434, "id": 163685776, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzY4NTc3Ng==", "diff_hunk": "@@ -0,0 +1,253 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/kernels/batch_util.h\"\n+#include \"tensorflow/core/kernels/data/dataset.h\"\n+\n+namespace tensorflow {\n+\n+namespace {\n+\n+// See documentation in ../ops/dataset_ops.cc for a high-level\n+// description of the following op.\n+\n+class SlideDatasetOp : public UnaryDatasetOpKernel {\n+ public:\n+  explicit SlideDatasetOp(OpKernelConstruction* ctx)\n+      : UnaryDatasetOpKernel(ctx) {}\n+\n+  void MakeDataset(OpKernelContext* ctx, DatasetBase* input,\n+                   DatasetBase** output) override {\n+    int64 slide_size = 0;\n+    int64 slide_step = 1;\n+    OP_REQUIRES_OK(ctx,\n+                   ParseScalarArgument<int64>(ctx, \"slide_size\", &slide_size));\n+    OP_REQUIRES_OK(ctx,\n+                   ParseScalarArgument<int64>(ctx, \"slide_step\", &slide_step));\n+    OP_REQUIRES(\n+        ctx, slide_size > 0,\n+        errors::InvalidArgument(\"Slide size must be greater than zero.\"));\n+    OP_REQUIRES(\n+        ctx, slide_step > 0 && slide_step < slide_size,\n+        errors::InvalidArgument(\"Slide step must be in [1, size).\"));\n+\n+    *output = new Dataset(ctx, slide_size, slide_step, input);\n+  }\n+\n+ private:\n+  class Dataset : public GraphDatasetBase {\n+   public:\n+    Dataset(OpKernelContext* ctx, int64 slide_size, int64 slide_step, const DatasetBase* input)\n+        : GraphDatasetBase(ctx), slide_size_(slide_size), slide_step_(slide_step), input_(input) {\n+      input_->Ref();\n+\n+      const auto& input_shapes = input_->output_shapes();\n+      output_shapes_.reserve(input_shapes.size());\n+      for (const auto& input_shape : input_shapes) {\n+        output_shapes_.emplace_back(\n+            PartialTensorShape({-1}).Concatenate(input_shape));\n+      }\n+    }\n+\n+    ~Dataset() override { input_->Unref(); }\n+\n+    std::unique_ptr<IteratorBase> MakeIterator(\n+        const string& prefix) const override {\n+      return std::unique_ptr<IteratorBase>(new Iterator(\n+          Iterator::Params{this, strings::StrCat(prefix, \"::Slide\")}));\n+    }\n+\n+    const DataTypeVector& output_dtypes() const override {\n+      return input_->output_dtypes();\n+    }\n+\n+    const std::vector<PartialTensorShape>& output_shapes() const override {\n+      return output_shapes_;\n+    }\n+\n+    string DebugString() override {\n+      return strings::StrCat(\"SlideDatasetOp(\", slide_size_, \", \", slide_step_, \")::Dataset\");\n+    }\n+\n+   protected:\n+    Status AsGraphDefInternal(OpKernelContext* ctx, DatasetGraphDefBuilder* b,\n+                              Node** output) const override {\n+      Node* input_graph_node = nullptr;\n+      TF_RETURN_IF_ERROR(b->AddParentDataset(ctx, input_, &input_graph_node));\n+      Node* slide_size = nullptr;\n+      Node* slide_step = nullptr;\n+      TF_RETURN_IF_ERROR(b->AddScalar(slide_size_, &slide_size));\n+      TF_RETURN_IF_ERROR(b->AddScalar(slide_step_, &slide_step));\n+      TF_RETURN_IF_ERROR(\n+          b->AddDataset(this, {input_graph_node, slide_size, slide_step}, output));\n+      return Status::OK();\n+    }\n+\n+   private:\n+\n+    class Iterator : public DatasetIterator<Dataset> {\n+     public:\n+      explicit Iterator(const Params& params)\n+          : DatasetIterator<Dataset>(params),\n+            input_impl_(params.dataset->input_->MakeIterator(params.prefix)) {}\n+\n+      Status GetNextInternal(IteratorContext* ctx,\n+                             std::vector<Tensor>* out_tensors,\n+                             bool* end_of_sequence) override {\n+        const int64 slide_size = dataset()->slide_size_;\n+        const int64 slide_step = dataset()->slide_step_;\n+        std::vector<std::vector<Tensor>> batch_elements;\n+        {\n+          mutex_lock l(mu_);\n+          if (!input_impl_) {\n+            *end_of_sequence = true;\n+            return Status::OK();\n+          }\n+          batch_elements.reserve(slide_size);\n+          const bool first_call = cache_.empty();\n+          if (first_call) {\n+            cache_.reserve(slide_size);\n+          } else {\n+            // Reuse cache in previous iteration.\n+            cache_.swap(batch_elements);\n+          }\n+          // Fill up with new elements.\n+          *end_of_sequence = false;\n+          for (size_t i = batch_elements.size(); i < slide_size && !*end_of_sequence;\n+              ++i) {\n+            std::vector<Tensor> batch_element_tuple;\n+            TF_RETURN_IF_ERROR(input_impl_->GetNext(ctx, &batch_element_tuple,\n+                                                    end_of_sequence));\n+            if (!*end_of_sequence) {\n+              batch_elements.emplace_back(std::move(batch_element_tuple));", "path": "tensorflow/core/kernels/data/slide_dataset_op.cc", "position": null, "original_position": 135, "commit_id": "cf49555b958fe192449232b5c6007de5a5fb192b", "original_commit_id": "f4683a3dc7d8d2e13b2c35b15ab64c384d31c8c6", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "body": "Nit: I think `push_back(std::vector<Tensor>&&)` would be preferable here.", "created_at": "2018-01-24T21:36:29Z", "updated_at": "2018-02-21T00:00:39Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16123#discussion_r163685776", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16123", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163685776"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16123#discussion_r163685776"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16123"}}, "body_html": "<p>Nit: I think <code>push_back(std::vector&lt;Tensor&gt;&amp;&amp;)</code> would be preferable here.</p>", "body_text": "Nit: I think push_back(std::vector<Tensor>&&) would be preferable here."}