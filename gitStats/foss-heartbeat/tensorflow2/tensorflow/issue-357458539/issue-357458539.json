{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22104", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22104/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22104/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22104/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22104", "id": 357458539, "node_id": "MDU6SXNzdWUzNTc0NTg1Mzk=", "number": 22104, "title": "tf.keras.layers.CuDNNGRU in eager mode can cause OOM ", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-06T01:10:35Z", "updated_at": "2018-10-12T10:19:55Z", "closed_at": "2018-09-25T03:31:31Z", "author_association": "NONE", "body_html": "<p>tensorflow 1.10.1<br>\nCode like below, with inputs dim 1 can be dynamic length.</p>\n<pre><code>class Model(keras.Model):\n  def __init__(self):\n    super(Model, self).__init__()\n    self.embedding = keras.layers.Embedding(vocab_size, FLAGS.emb_dim)\n    self.encode = keras.layers.CuDNNGRU(units=FLAGS.rnn_hidden_size, \n                                      return_sequences=True, \n                                      return_state=False, \n                                      recurrent_initializer='glorot_uniform')\n    self.pooling = keras.layers.GlobalMaxPool1D()\n    self.logits = keras.layers.Dense(NUM_CLASSES, activation=None)\n\n  def call(self, inputs, training=False):\n    x = inputs.comment\n    x = self.embedding(x)\n    x = self.encode(x)\n    x = self.pooling(x)\n    x = self.logits(x)\n  return x\n\ndef calc_loss(model, inputs, training=False):\n  y_ = model(inputs, training=training)\n  y = inputs.classes\n  return tf.losses.sigmoid_cross_entropy(y, y_)   \n</code></pre>\n<ol>\n<li>\n<p>Using keras.layers.GRU will not OOM</p>\n</li>\n<li>\n<p>Using keras.layers.CuDNNGRU but not in eager mode will not OOM</p>\n</li>\n<li>\n<p>Using keras.layers.CuDNNGRU + eager mode  will OOM (complain self.embedding OOM after training a few steps)</p>\n<p>optimizer.apply_gradients(zip(grads, model.variables))<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients<br>\nupdate_ops.append(processor.update_op(self, grad))<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 165, in update_op<br>\ng.values, self._v, g.indices)<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 958, in _resource_apply_sparse_duplicate_indices<br>\nreturn self._resource_apply_sparse(summed_grad, handle, unique_indices)<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 218, in _resource_apply_sparse<br>\ngrad, var, indices, self._resource_scatter_add)<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 200, in _apply_sparse_shared<br>\nlr * m_t / (v_sqrt + epsilon_t),<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper<br>\nreturn func(x, y, name=name)<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 958, in _truediv_python3<br>\nreturn gen_math_ops.real_div(x, y, name=name)<br>\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5904, in real_div<br>\n_six.raise_from(_core.<em>status_to_exception(e.code, message), None)<br>\nFile \"\", line 3, in raise_from<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[151627,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RealDiv] name: Adam/update</em>/truediv/</p>\n</li>\n</ol>", "body_text": "tensorflow 1.10.1\nCode like below, with inputs dim 1 can be dynamic length.\nclass Model(keras.Model):\n  def __init__(self):\n    super(Model, self).__init__()\n    self.embedding = keras.layers.Embedding(vocab_size, FLAGS.emb_dim)\n    self.encode = keras.layers.CuDNNGRU(units=FLAGS.rnn_hidden_size, \n                                      return_sequences=True, \n                                      return_state=False, \n                                      recurrent_initializer='glorot_uniform')\n    self.pooling = keras.layers.GlobalMaxPool1D()\n    self.logits = keras.layers.Dense(NUM_CLASSES, activation=None)\n\n  def call(self, inputs, training=False):\n    x = inputs.comment\n    x = self.embedding(x)\n    x = self.encode(x)\n    x = self.pooling(x)\n    x = self.logits(x)\n  return x\n\ndef calc_loss(model, inputs, training=False):\n  y_ = model(inputs, training=training)\n  y = inputs.classes\n  return tf.losses.sigmoid_cross_entropy(y, y_)   \n\n\n\nUsing keras.layers.GRU will not OOM\n\n\nUsing keras.layers.CuDNNGRU but not in eager mode will not OOM\n\n\nUsing keras.layers.CuDNNGRU + eager mode  will OOM (complain self.embedding OOM after training a few steps)\noptimizer.apply_gradients(zip(grads, model.variables))\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients\nupdate_ops.append(processor.update_op(self, grad))\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 165, in update_op\ng.values, self._v, g.indices)\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 958, in _resource_apply_sparse_duplicate_indices\nreturn self._resource_apply_sparse(summed_grad, handle, unique_indices)\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 218, in _resource_apply_sparse\ngrad, var, indices, self._resource_scatter_add)\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 200, in _apply_sparse_shared\nlr * m_t / (v_sqrt + epsilon_t),\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\nreturn func(x, y, name=name)\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 958, in _truediv_python3\nreturn gen_math_ops.real_div(x, y, name=name)\nFile \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5904, in real_div\n_six.raise_from(_core.status_to_exception(e.code, message), None)\nFile \"\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[151627,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RealDiv] name: Adam/update/truediv/", "body": "tensorflow 1.10.1 \r\nCode like below, with inputs dim 1 can be dynamic length.\r\n  \r\n    class Model(keras.Model):\r\n      def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.embedding = keras.layers.Embedding(vocab_size, FLAGS.emb_dim)\r\n        self.encode = keras.layers.CuDNNGRU(units=FLAGS.rnn_hidden_size, \r\n                                          return_sequences=True, \r\n                                          return_state=False, \r\n                                          recurrent_initializer='glorot_uniform')\r\n        self.pooling = keras.layers.GlobalMaxPool1D()\r\n        self.logits = keras.layers.Dense(NUM_CLASSES, activation=None)\r\n\r\n      def call(self, inputs, training=False):\r\n        x = inputs.comment\r\n        x = self.embedding(x)\r\n        x = self.encode(x)\r\n        x = self.pooling(x)\r\n        x = self.logits(x)\r\n      return x\r\n\r\n    def calc_loss(model, inputs, training=False):\r\n      y_ = model(inputs, training=training)\r\n      y = inputs.classes\r\n      return tf.losses.sigmoid_cross_entropy(y, y_)   \r\n\r\n\r\n1. Using keras.layers.GRU will not OOM\r\n2. Using keras.layers.CuDNNGRU but not in eager mode will not OOM\r\n3. Using keras.layers.CuDNNGRU + eager mode  will OOM (complain self.embedding OOM after training a few steps)  \r\n\r\n    optimizer.apply_gradients(zip(grads, model.variables))\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients\r\n    update_ops.append(processor.update_op(self, grad))\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 165, in update_op\r\n    g.values, self._v, g.indices)\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 958, in _resource_apply_sparse_duplicate_indices\r\n    return self._resource_apply_sparse(summed_grad, handle, unique_indices)\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 218, in _resource_apply_sparse\r\n    grad, var, indices, self._resource_scatter_add)\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 200, in _apply_sparse_shared\r\n    lr * m_t / (v_sqrt + epsilon_t),\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 958, in _truediv_python3\r\n    return gen_math_ops.real_div(x, y, name=name)\r\n  File \"/home/gezi/py3env/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5904, in real_div\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[151627,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RealDiv] name: Adam/update_/truediv/\r\n"}