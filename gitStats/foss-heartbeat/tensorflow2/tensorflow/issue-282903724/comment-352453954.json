{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352453954", "html_url": "https://github.com/tensorflow/tensorflow/issues/15448#issuecomment-352453954", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15448", "id": 352453954, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjQ1Mzk1NA==", "user": {"login": "kmhofmann", "id": 7887138, "node_id": "MDQ6VXNlcjc4ODcxMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/7887138?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmhofmann", "html_url": "https://github.com/kmhofmann", "followers_url": "https://api.github.com/users/kmhofmann/followers", "following_url": "https://api.github.com/users/kmhofmann/following{/other_user}", "gists_url": "https://api.github.com/users/kmhofmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmhofmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmhofmann/subscriptions", "organizations_url": "https://api.github.com/users/kmhofmann/orgs", "repos_url": "https://api.github.com/users/kmhofmann/repos", "events_url": "https://api.github.com/users/kmhofmann/events{/privacy}", "received_events_url": "https://api.github.com/users/kmhofmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-18T15:13:44Z", "updated_at": "2017-12-18T15:13:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Indeed, I have also observed the same issue.<br>\nPrior to using the Dataset API, I could implement multiple queues that would fetch data in parallel; what was unfortunately not possible was to reset (reuse) them after an epoch, e.g. for repeated evaluation of the validation set.</p>\n<p>Now, with a re-initializable iterator, the queue(s) seem to be coupled to the iterator and will be forcibly reset by switching (if I see this correctly), which makes the whole thing a bit pointless to be used with training data; see OP's example.</p>\n<p>I also cannot see good use cases for this behavior. In our code base, we intend to evaluate the validation set periodically after a certain number of training iterations, multiple times per training epoch. For this (supposedly quite common) use case seamless switching is necessary.</p>", "body_text": "Indeed, I have also observed the same issue.\nPrior to using the Dataset API, I could implement multiple queues that would fetch data in parallel; what was unfortunately not possible was to reset (reuse) them after an epoch, e.g. for repeated evaluation of the validation set.\nNow, with a re-initializable iterator, the queue(s) seem to be coupled to the iterator and will be forcibly reset by switching (if I see this correctly), which makes the whole thing a bit pointless to be used with training data; see OP's example.\nI also cannot see good use cases for this behavior. In our code base, we intend to evaluate the validation set periodically after a certain number of training iterations, multiple times per training epoch. For this (supposedly quite common) use case seamless switching is necessary.", "body": "Indeed, I have also observed the same issue.\r\nPrior to using the Dataset API, I could implement multiple queues that would fetch data in parallel; what was unfortunately not possible was to reset (reuse) them after an epoch, e.g. for repeated evaluation of the validation set.\r\n\r\nNow, with a re-initializable iterator, the queue(s) seem to be coupled to the iterator and will be forcibly reset by switching (if I see this correctly), which makes the whole thing a bit pointless to be used with training data; see OP's example.\r\n\r\nI also cannot see good use cases for this behavior. In our code base, we intend to evaluate the validation set periodically after a certain number of training iterations, multiple times per training epoch. For this (supposedly quite common) use case seamless switching is necessary."}