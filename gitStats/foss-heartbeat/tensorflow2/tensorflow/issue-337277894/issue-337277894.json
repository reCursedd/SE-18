{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20451", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20451/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20451/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20451/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20451", "id": 337277894, "node_id": "MDU6SXNzdWUzMzcyNzc4OTQ=", "number": 20451, "title": "with quantized-training model,PC ok but tf-lite failed.", "user": {"login": "MaeThird", "id": 14851411, "node_id": "MDQ6VXNlcjE0ODUxNDEx", "avatar_url": "https://avatars2.githubusercontent.com/u/14851411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaeThird", "html_url": "https://github.com/MaeThird", "followers_url": "https://api.github.com/users/MaeThird/followers", "following_url": "https://api.github.com/users/MaeThird/following{/other_user}", "gists_url": "https://api.github.com/users/MaeThird/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaeThird/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaeThird/subscriptions", "organizations_url": "https://api.github.com/users/MaeThird/orgs", "repos_url": "https://api.github.com/users/MaeThird/repos", "events_url": "https://api.github.com/users/MaeThird/events{/privacy}", "received_events_url": "https://api.github.com/users/MaeThird/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-01T09:39:44Z", "updated_at": "2018-08-07T06:21:49Z", "closed_at": "2018-08-07T06:21:49Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Y</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Linux  4.17.2-1-ARCH SMP</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>:b'v1.8.0-3238-g52bf2fe0f6' 1.9.0-rc0</li>\n<li><strong>Python version</strong>: 3.6.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:0.14.1- (@non-git)</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:gcc-7.1</li>\n<li><strong>CUDA/cuDNN version</strong>:cuda-9.2 cuDNN-7.1</li>\n<li><strong>GPU model and memory</strong>:16G</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>I trained <strong>label_image</strong> on mobilenetv2 backbone with quantization and everything works well on PC.<br>\nThen I tried to convert it to tf-lite,even the converting processing is well-down(<strong>no error,no unsupported ops</strong>),but when I finally ran it I got <strong>tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier &lt; 1.0 was not true</strong><br>\nThis the log:<br>\n<code>tensors size: 174 nodes size: 66 inputs: 1 input(0) name: input 0: MobilenetV2/Conv/Conv2D_Fold_bias, 128, 2, 0.0408043, 0 1: MobilenetV2/Conv/Relu6, 100352, 3, 0.0235285, 0 2: MobilenetV2/Conv/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0408043, 121 3: MobilenetV2/Conv_1/Conv2D_Fold_bias, 5120, 2, 0.00108845, 0 4: MobilenetV2/Conv_1/Relu6, 20480, 3, 0.0235285, 0 5: MobilenetV2/Conv_1/weights_quant/FakeQuantWithMinMaxVars, 409600, 3, 0.00680513, 119 6: MobilenetV2/Logits/AvgPool, 1280, 3, 0.0235285, 0 7: MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd, 3, 3, 0.174401, 120 8: MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_bias, 12, 2, 2.91482e-05, 0 9: MobilenetV2/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars, 3840, 3, 0.00123885, 125 10: MobilenetV2/Logits/Squeeze, 3, 3, 0.174401, 120 11: MobilenetV2/Logits/Squeeze_shape, 8, 2, 0, 0 12: MobilenetV2/Predictions/Reshape_1, 3, 3, 0.00390625, 0 13: MobilenetV2/expanded_conv/depthwise/Relu6, 100352, 3, 0.0235285, 0 14: MobilenetV2/expanded_conv/depthwise/depthwise_Fold_bias, 128, 2, 0.00805492, 0 15: MobilenetV2/expanded_conv/depthwise/weights_quant/FakeQuantWithMinMaxVars, 288, 3, 0.342348, 165 16: MobilenetV2/expanded_conv/project/Conv2D_Fold_bias, 64, 2, 0.00091254, 0 17: MobilenetV2/expanded_conv/project/add_fold, 50176, 3, 0.354141, 130 18: MobilenetV2/expanded_conv/project/weights_quant/FakeQuantWithMinMaxVars, 512, 3, 0.0387845, 150 19: MobilenetV2/expanded_conv_1/depthwise/Relu6, 75264, 3, 0.0235285, 0 20: MobilenetV2/expanded_conv_1/depthwise/depthwise_Fold_bias, 384, 2, 0.00060018, 0 21: MobilenetV2/expanded_conv_1/depthwise/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0255087, 109 22: MobilenetV2/expanded_conv_1/expand/Conv2D_Fold_bias, 384, 2, 0.00352435, 0 23: MobilenetV2/expanded_conv_1/expand/Relu6, 301056, 3, 0.0235285, 0 24: MobilenetV2/expanded_conv_1/expand/weights_quant/FakeQuantWithMinMaxVars, 1536, 3, 0.00995183, 126 25: MobilenetV2/expanded_conv_1/project/Conv2D_Fold_bias, 96, 2, 0.000607076, 0 26: MobilenetV2/expanded_conv_1/project/add_fold, 18816, 3, 0.294347, 131 27: MobilenetV2/expanded_conv_1/project/weights_quant/FakeQuantWithMinMaxVars, 2304, 3, 0.0258018, 151 28: MobilenetV2/expanded_conv_10/depthwise/Relu6, 18816, 3, 0.0235285, 0 29: MobilenetV2/expanded_conv_10/depthwise/depthwise_Fold_bias, 1536, 2, 0.000711485, 0 30: MobilenetV2/expanded_conv_10/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0302393, 140 31: MobilenetV2/expanded_conv_10/expand/Conv2D_Fold_bias, 1536, 2, 0.000350018, 0 32: MobilenetV2/expanded_conv_10/expand/Relu6, 18816, 3, 0.0235285, 0 33: MobilenetV2/expanded_conv_10/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00174141, 149 34: MobilenetV2/expanded_conv_10/project/Conv2D_Fold_bias, 384, 2, 0.000179579, 0 35: MobilenetV2/expanded_conv_10/project/add_fold, 4704, 3, 0.150007, 128 36: MobilenetV2/expanded_conv_10/project/weights_quant/FakeQuantWithMinMaxVars, 36864, 3, 0.00763239, 134 37: MobilenetV2/expanded_conv_11/add, 4704, 3, 0.149921, 125 38: MobilenetV2/expanded_conv_11/depthwise/Relu6, 28224, 3, 0.0235285, 0 39: MobilenetV2/expanded_conv_11/depthwise/depthwise_Fold_bias, 2304, 2, 0.0013777, 0 40: MobilenetV2/expanded_conv_11/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0585545, 92 41: MobilenetV2/expanded_conv_11/expand/Conv2D_Fold_bias, 2304, 2, 0.000252474, 0 42: MobilenetV2/expanded_conv_11/expand/Relu6, 28224, 3, 0.0235285, 0 43: MobilenetV2/expanded_conv_11/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00168308, 133 44: MobilenetV2/expanded_conv_11/project/Conv2D_Fold_bias, 384, 2, 0.000203408, 0 45: MobilenetV2/expanded_conv_11/project/add_fold, 4704, 3, 0.102331, 126 46: MobilenetV2/expanded_conv_11/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00864519, 141 47: MobilenetV2/expanded_conv_12/add, 4704, 3, 0.213277, 145 48: MobilenetV2/expanded_conv_12/depthwise/Relu6, 28224, 3, 0.0235285, 0 49: MobilenetV2/expanded_conv_12/depthwise/depthwise_Fold_bias, 2304, 2, 0.00214226, 0 50: MobilenetV2/expanded_conv_12/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0910496, 173 51: MobilenetV2/expanded_conv_12/expand/Conv2D_Fold_bias, 2304, 2, 0.000217147, 0 52: MobilenetV2/expanded_conv_12/expand/Relu6, 28224, 3, 0.0235285, 0 53: MobilenetV2/expanded_conv_12/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00144841, 139 54: MobilenetV2/expanded_conv_12/project/Conv2D_Fold_bias, 384, 2, 0.000596996, 0 55: MobilenetV2/expanded_conv_12/project/add_fold, 4704, 3, 0.170068, 144 56: MobilenetV2/expanded_conv_12/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0253734, 149 57: MobilenetV2/expanded_conv_13/depthwise/Relu6, 9216, 3, 0.0235285, 0 58: MobilenetV2/expanded_conv_13/depthwise/depthwise_Fold_bias, 2304, 2, 0.00034101, 0 59: MobilenetV2/expanded_conv_13/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0144935, 90 60: MobilenetV2/expanded_conv_13/expand/Conv2D_Fold_bias, 2304, 2, 0.000297714, 0 61: MobilenetV2/expanded_conv_13/expand/Relu6, 28224, 3, 0.0235285, 0 62: MobilenetV2/expanded_conv_13/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0013959, 122 63: MobilenetV2/expanded_conv_13/project/Conv2D_Fold_bias, 640, 2, 0.000194787, 0 64: MobilenetV2/expanded_conv_13/project/add_fold, 2560, 3, 0.144367, 122 65: MobilenetV2/expanded_conv_13/project/weights_quant/FakeQuantWithMinMaxVars, 92160, 3, 0.00827876, 139 66: MobilenetV2/expanded_conv_14/add, 2560, 3, 0.150496, 130 67: MobilenetV2/expanded_conv_14/depthwise/Relu6, 15360, 3, 0.0235285, 0 68: MobilenetV2/expanded_conv_14/depthwise/depthwise_Fold_bias, 3840, 2, 0.0010313, 0 69: MobilenetV2/expanded_conv_14/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0438318, 148 70: MobilenetV2/expanded_conv_14/expand/Conv2D_Fold_bias, 3840, 2, 0.000355036, 0 71: MobilenetV2/expanded_conv_14/expand/Relu6, 15360, 3, 0.0235285, 0 72: MobilenetV2/expanded_conv_14/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00245926, 111 73: MobilenetV2/expanded_conv_14/project/Conv2D_Fold_bias, 640, 2, 0.000174049, 0 74: MobilenetV2/expanded_conv_14/project/add_fold, 2560, 3, 0.0903757, 130 75: MobilenetV2/expanded_conv_14/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00739738, 137 76: MobilenetV2/expanded_conv_15/add, 2560, 3, 0.300834, 122 77: MobilenetV2/expanded_conv_15/depthwise/Relu6, 15360, 3, 0.0235285, 0 78: MobilenetV2/expanded_conv_15/depthwise/depthwise_Fold_bias, 3840, 2, 0.00129889, 0 79: MobilenetV2/expanded_conv_15/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0552048, 110 80: MobilenetV2/expanded_conv_15/expand/Conv2D_Fold_bias, 3840, 2, 0.000226284, 0 81: MobilenetV2/expanded_conv_15/expand/Relu6, 15360, 3, 0.0235285, 0 82: MobilenetV2/expanded_conv_15/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00150359, 99 83: MobilenetV2/expanded_conv_15/project/Conv2D_Fold_bias, 640, 2, 0.000805016, 0 84: MobilenetV2/expanded_conv_15/project/add_fold, 2560, 3, 0.226103, 131 85: MobilenetV2/expanded_conv_15/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.0342145, 139 86: MobilenetV2/expanded_conv_16/depthwise/Relu6, 15360, 3, 0.0235285, 0 87: MobilenetV2/expanded_conv_16/depthwise/depthwise_Fold_bias, 3840, 2, 0.0040495, 0 88: MobilenetV2/expanded_conv_16/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.17211, 201 89: MobilenetV2/expanded_conv_16/expand/Conv2D_Fold_bias, 3840, 2, 0.000576843, 0 90: MobilenetV2/expanded_conv_16/expand/Relu6, 15360, 3, 0.0235285, 0 91: MobilenetV2/expanded_conv_16/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00191748, 125 92: MobilenetV2/expanded_conv_16/project/Conv2D_Fold_bias, 1280, 2, 0.000119162, 0 93: MobilenetV2/expanded_conv_16/project/add_fold, 5120, 3, 0.159945, 146 94: MobilenetV2/expanded_conv_16/project/weights_quant/FakeQuantWithMinMaxVars, 307200, 3, 0.0050646, 130 95: MobilenetV2/expanded_conv_2/add, 18816, 3, 0.376629, 129 96: MobilenetV2/expanded_conv_2/depthwise/Relu6, 112896, 3, 0.0235285, 0 97: MobilenetV2/expanded_conv_2/depthwise/depthwise_Fold_bias, 576, 2, 0.00397992, 0 98: MobilenetV2/expanded_conv_2/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.169153, 51 99: MobilenetV2/expanded_conv_2/expand/Conv2D_Fold_bias, 576, 2, 0.00106746, 0 100: MobilenetV2/expanded_conv_2/expand/Relu6, 112896, 3, 0.0235285, 0 101: MobilenetV2/expanded_conv_2/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00362654, 142 102: MobilenetV2/expanded_conv_2/project/Conv2D_Fold_bias, 96, 2, 0.000610138, 0 103: MobilenetV2/expanded_conv_2/project/add_fold, 18816, 3, 0.342911, 133 104: MobilenetV2/expanded_conv_2/project/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0259319, 129 105: MobilenetV2/expanded_conv_3/depthwise/Relu6, 28224, 3, 0.0235285, 0 106: MobilenetV2/expanded_conv_3/depthwise/depthwise_Fold_bias, 576, 2, 0.000397524, 0 107: MobilenetV2/expanded_conv_3/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.0168954, 126 108: MobilenetV2/expanded_conv_3/expand/Conv2D_Fold_bias, 576, 2, 0.00108431, 0 109: MobilenetV2/expanded_conv_3/expand/Relu6, 112896, 3, 0.0235285, 0 110: MobilenetV2/expanded_conv_3/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00287898, 107 111: MobilenetV2/expanded_conv_3/project/Conv2D_Fold_bias, 128, 2, 0.000396253, 0 112: MobilenetV2/expanded_conv_3/project/add_fold, 6272, 3, 0.20811, 126 113: MobilenetV2/expanded_conv_3/project/weights_quant/FakeQuantWithMinMaxVars, 4608, 3, 0.0168414, 109 114: MobilenetV2/expanded_conv_4/add, 6272, 3, 0.250818, 134 115: MobilenetV2/expanded_conv_4/depthwise/Relu6, 37632, 3, 0.0235285, 0 116: MobilenetV2/expanded_conv_4/depthwise/depthwise_Fold_bias, 768, 2, 0.00236945, 0 117: MobilenetV2/expanded_conv_4/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.100705, 79 118: MobilenetV2/expanded_conv_4/expand/Conv2D_Fold_bias, 768, 2, 0.000398864, 0 119: MobilenetV2/expanded_conv_4/expand/Relu6, 37632, 3, 0.0235285, 0 120: MobilenetV2/expanded_conv_4/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0019166, 151 121: MobilenetV2/expanded_conv_4/project/Conv2D_Fold_bias, 128, 2, 0.000489459, 0 122: MobilenetV2/expanded_conv_4/project/add_fold, 6272, 3, 0.200968, 132 123: MobilenetV2/expanded_conv_4/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0208029, 147 124: MobilenetV2/expanded_conv_5/add, 6272, 3, 0.276968, 127 125: MobilenetV2/expanded_conv_5/depthwise/Relu6, 37632, 3, 0.0235285, 0 126: MobilenetV2/expanded_conv_5/depthwise/depthwise_Fold_bias, 768, 2, 0.00202895, 0 127: MobilenetV2/expanded_conv_5/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.086234, 63 128: MobilenetV2/expanded_conv_5/expand/Conv2D_Fold_bias, 768, 2, 0.000362468, 0 129: MobilenetV2/expanded_conv_5/expand/Relu6, 37632, 3, 0.0235285, 0 130: MobilenetV2/expanded_conv_5/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00144514, 120 131: MobilenetV2/expanded_conv_5/project/Conv2D_Fold_bias, 128, 2, 0.000435147, 0 132: MobilenetV2/expanded_conv_5/project/add_fold, 6272, 3, 0.205061, 128 133: MobilenetV2/expanded_conv_5/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0184945, 128 134: MobilenetV2/expanded_conv_6/depthwise/Relu6, 9408, 3, 0.0235285, 0 135: MobilenetV2/expanded_conv_6/depthwise/depthwise_Fold_bias, 768, 2, 0.000267618, 0 136: MobilenetV2/expanded_conv_6/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.0113742, 126 137: MobilenetV2/expanded_conv_6/expand/Conv2D_Fold_bias, 768, 2, 0.000528109, 0 138: MobilenetV2/expanded_conv_6/expand/Relu6, 37632, 3, 0.0235285, 0 139: MobilenetV2/expanded_conv_6/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00190675, 128 140: MobilenetV2/expanded_conv_6/project/Conv2D_Fold_bias, 256, 2, 0.00033262, 0 141: MobilenetV2/expanded_conv_6/project/add_fold, 3136, 3, 0.182997, 123 142: MobilenetV2/expanded_conv_6/project/weights_quant/FakeQuantWithMinMaxVars, 12288, 3, 0.0141369, 135 143: MobilenetV2/expanded_conv_7/add, 3136, 3, 0.182534, 120 144: MobilenetV2/expanded_conv_7/depthwise/Relu6, 18816, 3, 0.0235285, 0 145: MobilenetV2/expanded_conv_7/depthwise/depthwise_Fold_bias, 1536, 2, 0.00131166, 0 146: MobilenetV2/expanded_conv_7/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0557479, 130 147: MobilenetV2/expanded_conv_7/expand/Conv2D_Fold_bias, 1536, 2, 0.000259114, 0 148: MobilenetV2/expanded_conv_7/expand/Relu6, 18816, 3, 0.0235285, 0 149: MobilenetV2/expanded_conv_7/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00141595, 134 150: MobilenetV2/expanded_conv_7/project/Conv2D_Fold_bias, 256, 2, 0.000434401, 0 151: MobilenetV2/expanded_conv_7/project/add_fold, 3136, 3, 0.150338, 112 152: MobilenetV2/expanded_conv_7/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0184628, 129 153: MobilenetV2/expanded_conv_8/add, 3136, 3, 0.182103, 121 154: MobilenetV2/expanded_conv_8/depthwise/Relu6, 18816, 3, 0.0235285, 0 155: MobilenetV2/expanded_conv_8/depthwise/depthwise_Fold_bias, 1536, 2, 0.000993556, 0 156: MobilenetV2/expanded_conv_8/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0422278, 135 157: MobilenetV2/expanded_conv_8/expand/Conv2D_Fold_bias, 1536, 2, 0.000266144, 0 158: MobilenetV2/expanded_conv_8/expand/Relu6, 18816, 3, 0.0235285, 0 159: MobilenetV2/expanded_conv_8/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00145805, 128 160: MobilenetV2/expanded_conv_8/project/Conv2D_Fold_bias, 256, 2, 0.000281633, 0 161: MobilenetV2/expanded_conv_8/project/add_fold, 3136, 3, 0.122043, 130 162: MobilenetV2/expanded_conv_8/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0119699, 127 163: MobilenetV2/expanded_conv_9/add, 3136, 3, 0.200997, 130 164: MobilenetV2/expanded_conv_9/depthwise/Relu6, 18816, 3, 0.0235285, 0 165: MobilenetV2/expanded_conv_9/depthwise/depthwise_Fold_bias, 1536, 2, 0.000984803, 0 166: MobilenetV2/expanded_conv_9/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0418558, 151 167: MobilenetV2/expanded_conv_9/expand/Conv2D_Fold_bias, 1536, 2, 0.000224455, 0 168: MobilenetV2/expanded_conv_9/expand/Relu6, 18816, 3, 0.0235285, 0 169: MobilenetV2/expanded_conv_9/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00123257, 123 170: MobilenetV2/expanded_conv_9/project/Conv2D_Fold_bias, 256, 2, 0.000418117, 0 171: MobilenetV2/expanded_conv_9/project/add_fold, 3136, 3, 0.157535, 127 172: MobilenetV2/expanded_conv_9/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0177707, 145 173: input, 37632, 3, 1, 128 number of inputs: 1 number of outputs: 1 tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier &lt; 1.0 was not true.</code></p>\n<p><strong>I just add</strong> <code>tf.contrib.quantize.create_training_graph( input_graph=tf.get_default_graph(),         quant_delay=FLAGS.quan_delay)</code> in training and <code> tf.contrib.quantize.create_eval_graph()</code><br>\nin evaluation compared to the official version.<br>\nIs there any extra processes I need to care? Anyone help ?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux  4.17.2-1-ARCH SMP\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below):b'v1.8.0-3238-g52bf2fe0f6' 1.9.0-rc0\nPython version: 3.6.5\nBazel version (if compiling from source):0.14.1- (@non-git)\nGCC/Compiler version (if compiling from source):gcc-7.1\nCUDA/cuDNN version:cuda-9.2 cuDNN-7.1\nGPU model and memory:16G\nExact command to reproduce:\n\nI trained label_image on mobilenetv2 backbone with quantization and everything works well on PC.\nThen I tried to convert it to tf-lite,even the converting processing is well-down(no error,no unsupported ops),but when I finally ran it I got tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier < 1.0 was not true\nThis the log:\ntensors size: 174 nodes size: 66 inputs: 1 input(0) name: input 0: MobilenetV2/Conv/Conv2D_Fold_bias, 128, 2, 0.0408043, 0 1: MobilenetV2/Conv/Relu6, 100352, 3, 0.0235285, 0 2: MobilenetV2/Conv/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0408043, 121 3: MobilenetV2/Conv_1/Conv2D_Fold_bias, 5120, 2, 0.00108845, 0 4: MobilenetV2/Conv_1/Relu6, 20480, 3, 0.0235285, 0 5: MobilenetV2/Conv_1/weights_quant/FakeQuantWithMinMaxVars, 409600, 3, 0.00680513, 119 6: MobilenetV2/Logits/AvgPool, 1280, 3, 0.0235285, 0 7: MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd, 3, 3, 0.174401, 120 8: MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_bias, 12, 2, 2.91482e-05, 0 9: MobilenetV2/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars, 3840, 3, 0.00123885, 125 10: MobilenetV2/Logits/Squeeze, 3, 3, 0.174401, 120 11: MobilenetV2/Logits/Squeeze_shape, 8, 2, 0, 0 12: MobilenetV2/Predictions/Reshape_1, 3, 3, 0.00390625, 0 13: MobilenetV2/expanded_conv/depthwise/Relu6, 100352, 3, 0.0235285, 0 14: MobilenetV2/expanded_conv/depthwise/depthwise_Fold_bias, 128, 2, 0.00805492, 0 15: MobilenetV2/expanded_conv/depthwise/weights_quant/FakeQuantWithMinMaxVars, 288, 3, 0.342348, 165 16: MobilenetV2/expanded_conv/project/Conv2D_Fold_bias, 64, 2, 0.00091254, 0 17: MobilenetV2/expanded_conv/project/add_fold, 50176, 3, 0.354141, 130 18: MobilenetV2/expanded_conv/project/weights_quant/FakeQuantWithMinMaxVars, 512, 3, 0.0387845, 150 19: MobilenetV2/expanded_conv_1/depthwise/Relu6, 75264, 3, 0.0235285, 0 20: MobilenetV2/expanded_conv_1/depthwise/depthwise_Fold_bias, 384, 2, 0.00060018, 0 21: MobilenetV2/expanded_conv_1/depthwise/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0255087, 109 22: MobilenetV2/expanded_conv_1/expand/Conv2D_Fold_bias, 384, 2, 0.00352435, 0 23: MobilenetV2/expanded_conv_1/expand/Relu6, 301056, 3, 0.0235285, 0 24: MobilenetV2/expanded_conv_1/expand/weights_quant/FakeQuantWithMinMaxVars, 1536, 3, 0.00995183, 126 25: MobilenetV2/expanded_conv_1/project/Conv2D_Fold_bias, 96, 2, 0.000607076, 0 26: MobilenetV2/expanded_conv_1/project/add_fold, 18816, 3, 0.294347, 131 27: MobilenetV2/expanded_conv_1/project/weights_quant/FakeQuantWithMinMaxVars, 2304, 3, 0.0258018, 151 28: MobilenetV2/expanded_conv_10/depthwise/Relu6, 18816, 3, 0.0235285, 0 29: MobilenetV2/expanded_conv_10/depthwise/depthwise_Fold_bias, 1536, 2, 0.000711485, 0 30: MobilenetV2/expanded_conv_10/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0302393, 140 31: MobilenetV2/expanded_conv_10/expand/Conv2D_Fold_bias, 1536, 2, 0.000350018, 0 32: MobilenetV2/expanded_conv_10/expand/Relu6, 18816, 3, 0.0235285, 0 33: MobilenetV2/expanded_conv_10/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00174141, 149 34: MobilenetV2/expanded_conv_10/project/Conv2D_Fold_bias, 384, 2, 0.000179579, 0 35: MobilenetV2/expanded_conv_10/project/add_fold, 4704, 3, 0.150007, 128 36: MobilenetV2/expanded_conv_10/project/weights_quant/FakeQuantWithMinMaxVars, 36864, 3, 0.00763239, 134 37: MobilenetV2/expanded_conv_11/add, 4704, 3, 0.149921, 125 38: MobilenetV2/expanded_conv_11/depthwise/Relu6, 28224, 3, 0.0235285, 0 39: MobilenetV2/expanded_conv_11/depthwise/depthwise_Fold_bias, 2304, 2, 0.0013777, 0 40: MobilenetV2/expanded_conv_11/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0585545, 92 41: MobilenetV2/expanded_conv_11/expand/Conv2D_Fold_bias, 2304, 2, 0.000252474, 0 42: MobilenetV2/expanded_conv_11/expand/Relu6, 28224, 3, 0.0235285, 0 43: MobilenetV2/expanded_conv_11/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00168308, 133 44: MobilenetV2/expanded_conv_11/project/Conv2D_Fold_bias, 384, 2, 0.000203408, 0 45: MobilenetV2/expanded_conv_11/project/add_fold, 4704, 3, 0.102331, 126 46: MobilenetV2/expanded_conv_11/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00864519, 141 47: MobilenetV2/expanded_conv_12/add, 4704, 3, 0.213277, 145 48: MobilenetV2/expanded_conv_12/depthwise/Relu6, 28224, 3, 0.0235285, 0 49: MobilenetV2/expanded_conv_12/depthwise/depthwise_Fold_bias, 2304, 2, 0.00214226, 0 50: MobilenetV2/expanded_conv_12/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0910496, 173 51: MobilenetV2/expanded_conv_12/expand/Conv2D_Fold_bias, 2304, 2, 0.000217147, 0 52: MobilenetV2/expanded_conv_12/expand/Relu6, 28224, 3, 0.0235285, 0 53: MobilenetV2/expanded_conv_12/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00144841, 139 54: MobilenetV2/expanded_conv_12/project/Conv2D_Fold_bias, 384, 2, 0.000596996, 0 55: MobilenetV2/expanded_conv_12/project/add_fold, 4704, 3, 0.170068, 144 56: MobilenetV2/expanded_conv_12/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0253734, 149 57: MobilenetV2/expanded_conv_13/depthwise/Relu6, 9216, 3, 0.0235285, 0 58: MobilenetV2/expanded_conv_13/depthwise/depthwise_Fold_bias, 2304, 2, 0.00034101, 0 59: MobilenetV2/expanded_conv_13/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0144935, 90 60: MobilenetV2/expanded_conv_13/expand/Conv2D_Fold_bias, 2304, 2, 0.000297714, 0 61: MobilenetV2/expanded_conv_13/expand/Relu6, 28224, 3, 0.0235285, 0 62: MobilenetV2/expanded_conv_13/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0013959, 122 63: MobilenetV2/expanded_conv_13/project/Conv2D_Fold_bias, 640, 2, 0.000194787, 0 64: MobilenetV2/expanded_conv_13/project/add_fold, 2560, 3, 0.144367, 122 65: MobilenetV2/expanded_conv_13/project/weights_quant/FakeQuantWithMinMaxVars, 92160, 3, 0.00827876, 139 66: MobilenetV2/expanded_conv_14/add, 2560, 3, 0.150496, 130 67: MobilenetV2/expanded_conv_14/depthwise/Relu6, 15360, 3, 0.0235285, 0 68: MobilenetV2/expanded_conv_14/depthwise/depthwise_Fold_bias, 3840, 2, 0.0010313, 0 69: MobilenetV2/expanded_conv_14/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0438318, 148 70: MobilenetV2/expanded_conv_14/expand/Conv2D_Fold_bias, 3840, 2, 0.000355036, 0 71: MobilenetV2/expanded_conv_14/expand/Relu6, 15360, 3, 0.0235285, 0 72: MobilenetV2/expanded_conv_14/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00245926, 111 73: MobilenetV2/expanded_conv_14/project/Conv2D_Fold_bias, 640, 2, 0.000174049, 0 74: MobilenetV2/expanded_conv_14/project/add_fold, 2560, 3, 0.0903757, 130 75: MobilenetV2/expanded_conv_14/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00739738, 137 76: MobilenetV2/expanded_conv_15/add, 2560, 3, 0.300834, 122 77: MobilenetV2/expanded_conv_15/depthwise/Relu6, 15360, 3, 0.0235285, 0 78: MobilenetV2/expanded_conv_15/depthwise/depthwise_Fold_bias, 3840, 2, 0.00129889, 0 79: MobilenetV2/expanded_conv_15/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0552048, 110 80: MobilenetV2/expanded_conv_15/expand/Conv2D_Fold_bias, 3840, 2, 0.000226284, 0 81: MobilenetV2/expanded_conv_15/expand/Relu6, 15360, 3, 0.0235285, 0 82: MobilenetV2/expanded_conv_15/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00150359, 99 83: MobilenetV2/expanded_conv_15/project/Conv2D_Fold_bias, 640, 2, 0.000805016, 0 84: MobilenetV2/expanded_conv_15/project/add_fold, 2560, 3, 0.226103, 131 85: MobilenetV2/expanded_conv_15/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.0342145, 139 86: MobilenetV2/expanded_conv_16/depthwise/Relu6, 15360, 3, 0.0235285, 0 87: MobilenetV2/expanded_conv_16/depthwise/depthwise_Fold_bias, 3840, 2, 0.0040495, 0 88: MobilenetV2/expanded_conv_16/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.17211, 201 89: MobilenetV2/expanded_conv_16/expand/Conv2D_Fold_bias, 3840, 2, 0.000576843, 0 90: MobilenetV2/expanded_conv_16/expand/Relu6, 15360, 3, 0.0235285, 0 91: MobilenetV2/expanded_conv_16/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00191748, 125 92: MobilenetV2/expanded_conv_16/project/Conv2D_Fold_bias, 1280, 2, 0.000119162, 0 93: MobilenetV2/expanded_conv_16/project/add_fold, 5120, 3, 0.159945, 146 94: MobilenetV2/expanded_conv_16/project/weights_quant/FakeQuantWithMinMaxVars, 307200, 3, 0.0050646, 130 95: MobilenetV2/expanded_conv_2/add, 18816, 3, 0.376629, 129 96: MobilenetV2/expanded_conv_2/depthwise/Relu6, 112896, 3, 0.0235285, 0 97: MobilenetV2/expanded_conv_2/depthwise/depthwise_Fold_bias, 576, 2, 0.00397992, 0 98: MobilenetV2/expanded_conv_2/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.169153, 51 99: MobilenetV2/expanded_conv_2/expand/Conv2D_Fold_bias, 576, 2, 0.00106746, 0 100: MobilenetV2/expanded_conv_2/expand/Relu6, 112896, 3, 0.0235285, 0 101: MobilenetV2/expanded_conv_2/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00362654, 142 102: MobilenetV2/expanded_conv_2/project/Conv2D_Fold_bias, 96, 2, 0.000610138, 0 103: MobilenetV2/expanded_conv_2/project/add_fold, 18816, 3, 0.342911, 133 104: MobilenetV2/expanded_conv_2/project/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0259319, 129 105: MobilenetV2/expanded_conv_3/depthwise/Relu6, 28224, 3, 0.0235285, 0 106: MobilenetV2/expanded_conv_3/depthwise/depthwise_Fold_bias, 576, 2, 0.000397524, 0 107: MobilenetV2/expanded_conv_3/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.0168954, 126 108: MobilenetV2/expanded_conv_3/expand/Conv2D_Fold_bias, 576, 2, 0.00108431, 0 109: MobilenetV2/expanded_conv_3/expand/Relu6, 112896, 3, 0.0235285, 0 110: MobilenetV2/expanded_conv_3/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00287898, 107 111: MobilenetV2/expanded_conv_3/project/Conv2D_Fold_bias, 128, 2, 0.000396253, 0 112: MobilenetV2/expanded_conv_3/project/add_fold, 6272, 3, 0.20811, 126 113: MobilenetV2/expanded_conv_3/project/weights_quant/FakeQuantWithMinMaxVars, 4608, 3, 0.0168414, 109 114: MobilenetV2/expanded_conv_4/add, 6272, 3, 0.250818, 134 115: MobilenetV2/expanded_conv_4/depthwise/Relu6, 37632, 3, 0.0235285, 0 116: MobilenetV2/expanded_conv_4/depthwise/depthwise_Fold_bias, 768, 2, 0.00236945, 0 117: MobilenetV2/expanded_conv_4/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.100705, 79 118: MobilenetV2/expanded_conv_4/expand/Conv2D_Fold_bias, 768, 2, 0.000398864, 0 119: MobilenetV2/expanded_conv_4/expand/Relu6, 37632, 3, 0.0235285, 0 120: MobilenetV2/expanded_conv_4/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0019166, 151 121: MobilenetV2/expanded_conv_4/project/Conv2D_Fold_bias, 128, 2, 0.000489459, 0 122: MobilenetV2/expanded_conv_4/project/add_fold, 6272, 3, 0.200968, 132 123: MobilenetV2/expanded_conv_4/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0208029, 147 124: MobilenetV2/expanded_conv_5/add, 6272, 3, 0.276968, 127 125: MobilenetV2/expanded_conv_5/depthwise/Relu6, 37632, 3, 0.0235285, 0 126: MobilenetV2/expanded_conv_5/depthwise/depthwise_Fold_bias, 768, 2, 0.00202895, 0 127: MobilenetV2/expanded_conv_5/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.086234, 63 128: MobilenetV2/expanded_conv_5/expand/Conv2D_Fold_bias, 768, 2, 0.000362468, 0 129: MobilenetV2/expanded_conv_5/expand/Relu6, 37632, 3, 0.0235285, 0 130: MobilenetV2/expanded_conv_5/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00144514, 120 131: MobilenetV2/expanded_conv_5/project/Conv2D_Fold_bias, 128, 2, 0.000435147, 0 132: MobilenetV2/expanded_conv_5/project/add_fold, 6272, 3, 0.205061, 128 133: MobilenetV2/expanded_conv_5/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0184945, 128 134: MobilenetV2/expanded_conv_6/depthwise/Relu6, 9408, 3, 0.0235285, 0 135: MobilenetV2/expanded_conv_6/depthwise/depthwise_Fold_bias, 768, 2, 0.000267618, 0 136: MobilenetV2/expanded_conv_6/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.0113742, 126 137: MobilenetV2/expanded_conv_6/expand/Conv2D_Fold_bias, 768, 2, 0.000528109, 0 138: MobilenetV2/expanded_conv_6/expand/Relu6, 37632, 3, 0.0235285, 0 139: MobilenetV2/expanded_conv_6/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00190675, 128 140: MobilenetV2/expanded_conv_6/project/Conv2D_Fold_bias, 256, 2, 0.00033262, 0 141: MobilenetV2/expanded_conv_6/project/add_fold, 3136, 3, 0.182997, 123 142: MobilenetV2/expanded_conv_6/project/weights_quant/FakeQuantWithMinMaxVars, 12288, 3, 0.0141369, 135 143: MobilenetV2/expanded_conv_7/add, 3136, 3, 0.182534, 120 144: MobilenetV2/expanded_conv_7/depthwise/Relu6, 18816, 3, 0.0235285, 0 145: MobilenetV2/expanded_conv_7/depthwise/depthwise_Fold_bias, 1536, 2, 0.00131166, 0 146: MobilenetV2/expanded_conv_7/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0557479, 130 147: MobilenetV2/expanded_conv_7/expand/Conv2D_Fold_bias, 1536, 2, 0.000259114, 0 148: MobilenetV2/expanded_conv_7/expand/Relu6, 18816, 3, 0.0235285, 0 149: MobilenetV2/expanded_conv_7/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00141595, 134 150: MobilenetV2/expanded_conv_7/project/Conv2D_Fold_bias, 256, 2, 0.000434401, 0 151: MobilenetV2/expanded_conv_7/project/add_fold, 3136, 3, 0.150338, 112 152: MobilenetV2/expanded_conv_7/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0184628, 129 153: MobilenetV2/expanded_conv_8/add, 3136, 3, 0.182103, 121 154: MobilenetV2/expanded_conv_8/depthwise/Relu6, 18816, 3, 0.0235285, 0 155: MobilenetV2/expanded_conv_8/depthwise/depthwise_Fold_bias, 1536, 2, 0.000993556, 0 156: MobilenetV2/expanded_conv_8/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0422278, 135 157: MobilenetV2/expanded_conv_8/expand/Conv2D_Fold_bias, 1536, 2, 0.000266144, 0 158: MobilenetV2/expanded_conv_8/expand/Relu6, 18816, 3, 0.0235285, 0 159: MobilenetV2/expanded_conv_8/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00145805, 128 160: MobilenetV2/expanded_conv_8/project/Conv2D_Fold_bias, 256, 2, 0.000281633, 0 161: MobilenetV2/expanded_conv_8/project/add_fold, 3136, 3, 0.122043, 130 162: MobilenetV2/expanded_conv_8/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0119699, 127 163: MobilenetV2/expanded_conv_9/add, 3136, 3, 0.200997, 130 164: MobilenetV2/expanded_conv_9/depthwise/Relu6, 18816, 3, 0.0235285, 0 165: MobilenetV2/expanded_conv_9/depthwise/depthwise_Fold_bias, 1536, 2, 0.000984803, 0 166: MobilenetV2/expanded_conv_9/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0418558, 151 167: MobilenetV2/expanded_conv_9/expand/Conv2D_Fold_bias, 1536, 2, 0.000224455, 0 168: MobilenetV2/expanded_conv_9/expand/Relu6, 18816, 3, 0.0235285, 0 169: MobilenetV2/expanded_conv_9/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00123257, 123 170: MobilenetV2/expanded_conv_9/project/Conv2D_Fold_bias, 256, 2, 0.000418117, 0 171: MobilenetV2/expanded_conv_9/project/add_fold, 3136, 3, 0.157535, 127 172: MobilenetV2/expanded_conv_9/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0177707, 145 173: input, 37632, 3, 1, 128 number of inputs: 1 number of outputs: 1 tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier < 1.0 was not true.\nI just add tf.contrib.quantize.create_training_graph( input_graph=tf.get_default_graph(),         quant_delay=FLAGS.quan_delay) in training and  tf.contrib.quantize.create_eval_graph()\nin evaluation compared to the official version.\nIs there any extra processes I need to care? Anyone help ?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux  4.17.2-1-ARCH SMP\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:b'v1.8.0-3238-g52bf2fe0f6' 1.9.0-rc0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**:0.14.1- (@non-git)\r\n- **GCC/Compiler version (if compiling from source)**:gcc-7.1\r\n- **CUDA/cuDNN version**:cuda-9.2 cuDNN-7.1\r\n- **GPU model and memory**:16G\r\n- **Exact command to reproduce**:\r\n\r\nI trained **label_image** on mobilenetv2 backbone with quantization and everything works well on PC.\r\nThen I tried to convert it to tf-lite,even the converting processing is well-down(**no error,no unsupported ops**),but when I finally ran it I got **tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier < 1.0 was not true**\r\nThis the log:\r\n`\r\ntensors size: 174\r\nnodes size: 66\r\ninputs: 1\r\ninput(0) name: input\r\n0: MobilenetV2/Conv/Conv2D_Fold_bias, 128, 2, 0.0408043, 0\r\n1: MobilenetV2/Conv/Relu6, 100352, 3, 0.0235285, 0\r\n2: MobilenetV2/Conv/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0408043, 121\r\n3: MobilenetV2/Conv_1/Conv2D_Fold_bias, 5120, 2, 0.00108845, 0\r\n4: MobilenetV2/Conv_1/Relu6, 20480, 3, 0.0235285, 0\r\n5: MobilenetV2/Conv_1/weights_quant/FakeQuantWithMinMaxVars, 409600, 3, 0.00680513, 119\r\n6: MobilenetV2/Logits/AvgPool, 1280, 3, 0.0235285, 0\r\n7: MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd, 3, 3, 0.174401, 120\r\n8: MobilenetV2/Logits/Conv2d_1c_1x1/Conv2D_bias, 12, 2, 2.91482e-05, 0\r\n9: MobilenetV2/Logits/Conv2d_1c_1x1/weights_quant/FakeQuantWithMinMaxVars, 3840, 3, 0.00123885, 125\r\n10: MobilenetV2/Logits/Squeeze, 3, 3, 0.174401, 120\r\n11: MobilenetV2/Logits/Squeeze_shape, 8, 2, 0, 0\r\n12: MobilenetV2/Predictions/Reshape_1, 3, 3, 0.00390625, 0\r\n13: MobilenetV2/expanded_conv/depthwise/Relu6, 100352, 3, 0.0235285, 0\r\n14: MobilenetV2/expanded_conv/depthwise/depthwise_Fold_bias, 128, 2, 0.00805492, 0\r\n15: MobilenetV2/expanded_conv/depthwise/weights_quant/FakeQuantWithMinMaxVars, 288, 3, 0.342348, 165\r\n16: MobilenetV2/expanded_conv/project/Conv2D_Fold_bias, 64, 2, 0.00091254, 0\r\n17: MobilenetV2/expanded_conv/project/add_fold, 50176, 3, 0.354141, 130\r\n18: MobilenetV2/expanded_conv/project/weights_quant/FakeQuantWithMinMaxVars, 512, 3, 0.0387845, 150\r\n19: MobilenetV2/expanded_conv_1/depthwise/Relu6, 75264, 3, 0.0235285, 0\r\n20: MobilenetV2/expanded_conv_1/depthwise/depthwise_Fold_bias, 384, 2, 0.00060018, 0\r\n21: MobilenetV2/expanded_conv_1/depthwise/weights_quant/FakeQuantWithMinMaxVars, 864, 3, 0.0255087, 109\r\n22: MobilenetV2/expanded_conv_1/expand/Conv2D_Fold_bias, 384, 2, 0.00352435, 0\r\n23: MobilenetV2/expanded_conv_1/expand/Relu6, 301056, 3, 0.0235285, 0\r\n24: MobilenetV2/expanded_conv_1/expand/weights_quant/FakeQuantWithMinMaxVars, 1536, 3, 0.00995183, 126\r\n25: MobilenetV2/expanded_conv_1/project/Conv2D_Fold_bias, 96, 2, 0.000607076, 0\r\n26: MobilenetV2/expanded_conv_1/project/add_fold, 18816, 3, 0.294347, 131\r\n27: MobilenetV2/expanded_conv_1/project/weights_quant/FakeQuantWithMinMaxVars, 2304, 3, 0.0258018, 151\r\n28: MobilenetV2/expanded_conv_10/depthwise/Relu6, 18816, 3, 0.0235285, 0\r\n29: MobilenetV2/expanded_conv_10/depthwise/depthwise_Fold_bias, 1536, 2, 0.000711485, 0\r\n30: MobilenetV2/expanded_conv_10/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0302393, 140\r\n31: MobilenetV2/expanded_conv_10/expand/Conv2D_Fold_bias, 1536, 2, 0.000350018, 0\r\n32: MobilenetV2/expanded_conv_10/expand/Relu6, 18816, 3, 0.0235285, 0\r\n33: MobilenetV2/expanded_conv_10/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00174141, 149\r\n34: MobilenetV2/expanded_conv_10/project/Conv2D_Fold_bias, 384, 2, 0.000179579, 0\r\n35: MobilenetV2/expanded_conv_10/project/add_fold, 4704, 3, 0.150007, 128\r\n36: MobilenetV2/expanded_conv_10/project/weights_quant/FakeQuantWithMinMaxVars, 36864, 3, 0.00763239, 134\r\n37: MobilenetV2/expanded_conv_11/add, 4704, 3, 0.149921, 125\r\n38: MobilenetV2/expanded_conv_11/depthwise/Relu6, 28224, 3, 0.0235285, 0\r\n39: MobilenetV2/expanded_conv_11/depthwise/depthwise_Fold_bias, 2304, 2, 0.0013777, 0\r\n40: MobilenetV2/expanded_conv_11/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0585545, 92\r\n41: MobilenetV2/expanded_conv_11/expand/Conv2D_Fold_bias, 2304, 2, 0.000252474, 0\r\n42: MobilenetV2/expanded_conv_11/expand/Relu6, 28224, 3, 0.0235285, 0\r\n43: MobilenetV2/expanded_conv_11/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00168308, 133\r\n44: MobilenetV2/expanded_conv_11/project/Conv2D_Fold_bias, 384, 2, 0.000203408, 0\r\n45: MobilenetV2/expanded_conv_11/project/add_fold, 4704, 3, 0.102331, 126\r\n46: MobilenetV2/expanded_conv_11/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00864519, 141\r\n47: MobilenetV2/expanded_conv_12/add, 4704, 3, 0.213277, 145\r\n48: MobilenetV2/expanded_conv_12/depthwise/Relu6, 28224, 3, 0.0235285, 0\r\n49: MobilenetV2/expanded_conv_12/depthwise/depthwise_Fold_bias, 2304, 2, 0.00214226, 0\r\n50: MobilenetV2/expanded_conv_12/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0910496, 173\r\n51: MobilenetV2/expanded_conv_12/expand/Conv2D_Fold_bias, 2304, 2, 0.000217147, 0\r\n52: MobilenetV2/expanded_conv_12/expand/Relu6, 28224, 3, 0.0235285, 0\r\n53: MobilenetV2/expanded_conv_12/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.00144841, 139\r\n54: MobilenetV2/expanded_conv_12/project/Conv2D_Fold_bias, 384, 2, 0.000596996, 0\r\n55: MobilenetV2/expanded_conv_12/project/add_fold, 4704, 3, 0.170068, 144\r\n56: MobilenetV2/expanded_conv_12/project/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0253734, 149\r\n57: MobilenetV2/expanded_conv_13/depthwise/Relu6, 9216, 3, 0.0235285, 0\r\n58: MobilenetV2/expanded_conv_13/depthwise/depthwise_Fold_bias, 2304, 2, 0.00034101, 0\r\n59: MobilenetV2/expanded_conv_13/depthwise/weights_quant/FakeQuantWithMinMaxVars, 5184, 3, 0.0144935, 90\r\n60: MobilenetV2/expanded_conv_13/expand/Conv2D_Fold_bias, 2304, 2, 0.000297714, 0\r\n61: MobilenetV2/expanded_conv_13/expand/Relu6, 28224, 3, 0.0235285, 0\r\n62: MobilenetV2/expanded_conv_13/expand/weights_quant/FakeQuantWithMinMaxVars, 55296, 3, 0.0013959, 122\r\n63: MobilenetV2/expanded_conv_13/project/Conv2D_Fold_bias, 640, 2, 0.000194787, 0\r\n64: MobilenetV2/expanded_conv_13/project/add_fold, 2560, 3, 0.144367, 122\r\n65: MobilenetV2/expanded_conv_13/project/weights_quant/FakeQuantWithMinMaxVars, 92160, 3, 0.00827876, 139\r\n66: MobilenetV2/expanded_conv_14/add, 2560, 3, 0.150496, 130\r\n67: MobilenetV2/expanded_conv_14/depthwise/Relu6, 15360, 3, 0.0235285, 0\r\n68: MobilenetV2/expanded_conv_14/depthwise/depthwise_Fold_bias, 3840, 2, 0.0010313, 0\r\n69: MobilenetV2/expanded_conv_14/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0438318, 148\r\n70: MobilenetV2/expanded_conv_14/expand/Conv2D_Fold_bias, 3840, 2, 0.000355036, 0\r\n71: MobilenetV2/expanded_conv_14/expand/Relu6, 15360, 3, 0.0235285, 0\r\n72: MobilenetV2/expanded_conv_14/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00245926, 111\r\n73: MobilenetV2/expanded_conv_14/project/Conv2D_Fold_bias, 640, 2, 0.000174049, 0\r\n74: MobilenetV2/expanded_conv_14/project/add_fold, 2560, 3, 0.0903757, 130\r\n75: MobilenetV2/expanded_conv_14/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00739738, 137\r\n76: MobilenetV2/expanded_conv_15/add, 2560, 3, 0.300834, 122\r\n77: MobilenetV2/expanded_conv_15/depthwise/Relu6, 15360, 3, 0.0235285, 0\r\n78: MobilenetV2/expanded_conv_15/depthwise/depthwise_Fold_bias, 3840, 2, 0.00129889, 0\r\n79: MobilenetV2/expanded_conv_15/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.0552048, 110\r\n80: MobilenetV2/expanded_conv_15/expand/Conv2D_Fold_bias, 3840, 2, 0.000226284, 0\r\n81: MobilenetV2/expanded_conv_15/expand/Relu6, 15360, 3, 0.0235285, 0\r\n82: MobilenetV2/expanded_conv_15/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00150359, 99\r\n83: MobilenetV2/expanded_conv_15/project/Conv2D_Fold_bias, 640, 2, 0.000805016, 0\r\n84: MobilenetV2/expanded_conv_15/project/add_fold, 2560, 3, 0.226103, 131\r\n85: MobilenetV2/expanded_conv_15/project/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.0342145, 139\r\n86: MobilenetV2/expanded_conv_16/depthwise/Relu6, 15360, 3, 0.0235285, 0\r\n87: MobilenetV2/expanded_conv_16/depthwise/depthwise_Fold_bias, 3840, 2, 0.0040495, 0\r\n88: MobilenetV2/expanded_conv_16/depthwise/weights_quant/FakeQuantWithMinMaxVars, 8640, 3, 0.17211, 201\r\n89: MobilenetV2/expanded_conv_16/expand/Conv2D_Fold_bias, 3840, 2, 0.000576843, 0\r\n90: MobilenetV2/expanded_conv_16/expand/Relu6, 15360, 3, 0.0235285, 0\r\n91: MobilenetV2/expanded_conv_16/expand/weights_quant/FakeQuantWithMinMaxVars, 153600, 3, 0.00191748, 125\r\n92: MobilenetV2/expanded_conv_16/project/Conv2D_Fold_bias, 1280, 2, 0.000119162, 0\r\n93: MobilenetV2/expanded_conv_16/project/add_fold, 5120, 3, 0.159945, 146\r\n94: MobilenetV2/expanded_conv_16/project/weights_quant/FakeQuantWithMinMaxVars, 307200, 3, 0.0050646, 130\r\n95: MobilenetV2/expanded_conv_2/add, 18816, 3, 0.376629, 129\r\n96: MobilenetV2/expanded_conv_2/depthwise/Relu6, 112896, 3, 0.0235285, 0\r\n97: MobilenetV2/expanded_conv_2/depthwise/depthwise_Fold_bias, 576, 2, 0.00397992, 0\r\n98: MobilenetV2/expanded_conv_2/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.169153, 51\r\n99: MobilenetV2/expanded_conv_2/expand/Conv2D_Fold_bias, 576, 2, 0.00106746, 0\r\n100: MobilenetV2/expanded_conv_2/expand/Relu6, 112896, 3, 0.0235285, 0\r\n101: MobilenetV2/expanded_conv_2/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00362654, 142\r\n102: MobilenetV2/expanded_conv_2/project/Conv2D_Fold_bias, 96, 2, 0.000610138, 0\r\n103: MobilenetV2/expanded_conv_2/project/add_fold, 18816, 3, 0.342911, 133\r\n104: MobilenetV2/expanded_conv_2/project/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0259319, 129\r\n105: MobilenetV2/expanded_conv_3/depthwise/Relu6, 28224, 3, 0.0235285, 0\r\n106: MobilenetV2/expanded_conv_3/depthwise/depthwise_Fold_bias, 576, 2, 0.000397524, 0\r\n107: MobilenetV2/expanded_conv_3/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1296, 3, 0.0168954, 126\r\n108: MobilenetV2/expanded_conv_3/expand/Conv2D_Fold_bias, 576, 2, 0.00108431, 0\r\n109: MobilenetV2/expanded_conv_3/expand/Relu6, 112896, 3, 0.0235285, 0\r\n110: MobilenetV2/expanded_conv_3/expand/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.00287898, 107\r\n111: MobilenetV2/expanded_conv_3/project/Conv2D_Fold_bias, 128, 2, 0.000396253, 0\r\n112: MobilenetV2/expanded_conv_3/project/add_fold, 6272, 3, 0.20811, 126\r\n113: MobilenetV2/expanded_conv_3/project/weights_quant/FakeQuantWithMinMaxVars, 4608, 3, 0.0168414, 109\r\n114: MobilenetV2/expanded_conv_4/add, 6272, 3, 0.250818, 134\r\n115: MobilenetV2/expanded_conv_4/depthwise/Relu6, 37632, 3, 0.0235285, 0\r\n116: MobilenetV2/expanded_conv_4/depthwise/depthwise_Fold_bias, 768, 2, 0.00236945, 0\r\n117: MobilenetV2/expanded_conv_4/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.100705, 79\r\n118: MobilenetV2/expanded_conv_4/expand/Conv2D_Fold_bias, 768, 2, 0.000398864, 0\r\n119: MobilenetV2/expanded_conv_4/expand/Relu6, 37632, 3, 0.0235285, 0\r\n120: MobilenetV2/expanded_conv_4/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0019166, 151\r\n121: MobilenetV2/expanded_conv_4/project/Conv2D_Fold_bias, 128, 2, 0.000489459, 0\r\n122: MobilenetV2/expanded_conv_4/project/add_fold, 6272, 3, 0.200968, 132\r\n123: MobilenetV2/expanded_conv_4/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0208029, 147\r\n124: MobilenetV2/expanded_conv_5/add, 6272, 3, 0.276968, 127\r\n125: MobilenetV2/expanded_conv_5/depthwise/Relu6, 37632, 3, 0.0235285, 0\r\n126: MobilenetV2/expanded_conv_5/depthwise/depthwise_Fold_bias, 768, 2, 0.00202895, 0\r\n127: MobilenetV2/expanded_conv_5/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.086234, 63\r\n128: MobilenetV2/expanded_conv_5/expand/Conv2D_Fold_bias, 768, 2, 0.000362468, 0\r\n129: MobilenetV2/expanded_conv_5/expand/Relu6, 37632, 3, 0.0235285, 0\r\n130: MobilenetV2/expanded_conv_5/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00144514, 120\r\n131: MobilenetV2/expanded_conv_5/project/Conv2D_Fold_bias, 128, 2, 0.000435147, 0\r\n132: MobilenetV2/expanded_conv_5/project/add_fold, 6272, 3, 0.205061, 128\r\n133: MobilenetV2/expanded_conv_5/project/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.0184945, 128\r\n134: MobilenetV2/expanded_conv_6/depthwise/Relu6, 9408, 3, 0.0235285, 0\r\n135: MobilenetV2/expanded_conv_6/depthwise/depthwise_Fold_bias, 768, 2, 0.000267618, 0\r\n136: MobilenetV2/expanded_conv_6/depthwise/weights_quant/FakeQuantWithMinMaxVars, 1728, 3, 0.0113742, 126\r\n137: MobilenetV2/expanded_conv_6/expand/Conv2D_Fold_bias, 768, 2, 0.000528109, 0\r\n138: MobilenetV2/expanded_conv_6/expand/Relu6, 37632, 3, 0.0235285, 0\r\n139: MobilenetV2/expanded_conv_6/expand/weights_quant/FakeQuantWithMinMaxVars, 6144, 3, 0.00190675, 128\r\n140: MobilenetV2/expanded_conv_6/project/Conv2D_Fold_bias, 256, 2, 0.00033262, 0\r\n141: MobilenetV2/expanded_conv_6/project/add_fold, 3136, 3, 0.182997, 123\r\n142: MobilenetV2/expanded_conv_6/project/weights_quant/FakeQuantWithMinMaxVars, 12288, 3, 0.0141369, 135\r\n143: MobilenetV2/expanded_conv_7/add, 3136, 3, 0.182534, 120\r\n144: MobilenetV2/expanded_conv_7/depthwise/Relu6, 18816, 3, 0.0235285, 0\r\n145: MobilenetV2/expanded_conv_7/depthwise/depthwise_Fold_bias, 1536, 2, 0.00131166, 0\r\n146: MobilenetV2/expanded_conv_7/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0557479, 130\r\n147: MobilenetV2/expanded_conv_7/expand/Conv2D_Fold_bias, 1536, 2, 0.000259114, 0\r\n148: MobilenetV2/expanded_conv_7/expand/Relu6, 18816, 3, 0.0235285, 0\r\n149: MobilenetV2/expanded_conv_7/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00141595, 134\r\n150: MobilenetV2/expanded_conv_7/project/Conv2D_Fold_bias, 256, 2, 0.000434401, 0\r\n151: MobilenetV2/expanded_conv_7/project/add_fold, 3136, 3, 0.150338, 112\r\n152: MobilenetV2/expanded_conv_7/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0184628, 129\r\n153: MobilenetV2/expanded_conv_8/add, 3136, 3, 0.182103, 121\r\n154: MobilenetV2/expanded_conv_8/depthwise/Relu6, 18816, 3, 0.0235285, 0\r\n155: MobilenetV2/expanded_conv_8/depthwise/depthwise_Fold_bias, 1536, 2, 0.000993556, 0\r\n156: MobilenetV2/expanded_conv_8/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0422278, 135\r\n157: MobilenetV2/expanded_conv_8/expand/Conv2D_Fold_bias, 1536, 2, 0.000266144, 0\r\n158: MobilenetV2/expanded_conv_8/expand/Relu6, 18816, 3, 0.0235285, 0\r\n159: MobilenetV2/expanded_conv_8/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00145805, 128\r\n160: MobilenetV2/expanded_conv_8/project/Conv2D_Fold_bias, 256, 2, 0.000281633, 0\r\n161: MobilenetV2/expanded_conv_8/project/add_fold, 3136, 3, 0.122043, 130\r\n162: MobilenetV2/expanded_conv_8/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0119699, 127\r\n163: MobilenetV2/expanded_conv_9/add, 3136, 3, 0.200997, 130\r\n164: MobilenetV2/expanded_conv_9/depthwise/Relu6, 18816, 3, 0.0235285, 0\r\n165: MobilenetV2/expanded_conv_9/depthwise/depthwise_Fold_bias, 1536, 2, 0.000984803, 0\r\n166: MobilenetV2/expanded_conv_9/depthwise/weights_quant/FakeQuantWithMinMaxVars, 3456, 3, 0.0418558, 151\r\n167: MobilenetV2/expanded_conv_9/expand/Conv2D_Fold_bias, 1536, 2, 0.000224455, 0\r\n168: MobilenetV2/expanded_conv_9/expand/Relu6, 18816, 3, 0.0235285, 0\r\n169: MobilenetV2/expanded_conv_9/expand/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.00123257, 123\r\n170: MobilenetV2/expanded_conv_9/project/Conv2D_Fold_bias, 256, 2, 0.000418117, 0\r\n171: MobilenetV2/expanded_conv_9/project/add_fold, 3136, 3, 0.157535, 127\r\n172: MobilenetV2/expanded_conv_9/project/weights_quant/FakeQuantWithMinMaxVars, 24576, 3, 0.0177707, 145\r\n173: input, 37632, 3, 1, 128\r\nnumber of inputs: 1\r\nnumber of outputs: 1\r\ntensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier < 1.0 was not true.\r\n`\r\n\r\n**I just add** `tf.contrib.quantize.create_training_graph( input_graph=tf.get_default_graph(),         quant_delay=FLAGS.quan_delay)` in training and ` tf.contrib.quantize.create_eval_graph()`\r\nin evaluation compared to the official version.\r\nIs there any extra processes I need to care? Anyone help ?  "}