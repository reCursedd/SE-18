{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/301476452", "html_url": "https://github.com/tensorflow/tensorflow/issues/9904#issuecomment-301476452", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9904", "id": 301476452, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTQ3NjQ1Mg==", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-15T13:35:35Z", "updated_at": "2017-05-15T13:54:08Z", "author_association": "NONE", "body_html": "<p>Also there are still bugs if fixing above problem. For BeamSearchDecoder design, it is dynamic and stop when all facing EOS, but is it good for doing beam search by this way? I think done beams should not competing with non finished beams.  Take a small example, comparing the result of out graph beam search(beam_width 2) and beam search by BeamSearchDecoder:<br>\nfor out graph beam search(models\\im2txt\\im2txt\\inference_utils\\caption_generator.py) I got:<br>\n0 [936, 2] \u53e4\u4ee3/[EOS] 0.000512714519986 -7.57579 -7.57579 [-3.9758704, -3.599921]<br>\n1 [1, 2] [UNK]/[EOS] 0.000276204156072 -8.19437 -8.19437 [-4.6221266, -3.5722442]<br>\nfor BeamSearchDecoder, I print predicted_ids, parent_ids and sequence_lengths,  and I transpose final beam search output predicted_ids [0, 2, 1] to print the top 2 best paths.<br>\npredicted_ids:<br>\n[[[936   1]<br>\n[  8   2]<br>\n[  2   2]]]<br>\nparent_ids:<br>\n[[[0 0]<br>\n[0 0]<br>\n[1 0]]]<br>\nsequence_lengths:<br>\n[[3 2]]<br>\ntop2 best paths:<br>\n[936   2   2] \u53e4\u4ee3/[EOS] 0.000512714 -7.57579140233<br>\n[936   2  -1] \u53e4\u4ee3/[EOS] 0.000134506 -8.91390228447</p>\n<p>Which is not as good as out graph result, you see the path [1, 2] will be ignored since we have<br>\n[936, 8] [936, 2] occupy all 2 beam_width positions... (finished competing with non finished)<br>\nAnd the final result has [936, 2, 2] [936, 2, -1] which is also not correct.<br>\nI think should be [936, 2, -1] ([936,2,2]) and [936,8,2] with sequence_lengths [[2, 3]]</p>\n<p>If considering length penalty, we can not assume early finished shorter path be better then longer ones.<br>\nSo may be non dynamic version, just loop max_steps and return top N finished paths will be better.</p>", "body_text": "Also there are still bugs if fixing above problem. For BeamSearchDecoder design, it is dynamic and stop when all facing EOS, but is it good for doing beam search by this way? I think done beams should not competing with non finished beams.  Take a small example, comparing the result of out graph beam search(beam_width 2) and beam search by BeamSearchDecoder:\nfor out graph beam search(models\\im2txt\\im2txt\\inference_utils\\caption_generator.py) I got:\n0 [936, 2] \u53e4\u4ee3/[EOS] 0.000512714519986 -7.57579 -7.57579 [-3.9758704, -3.599921]\n1 [1, 2] [UNK]/[EOS] 0.000276204156072 -8.19437 -8.19437 [-4.6221266, -3.5722442]\nfor BeamSearchDecoder, I print predicted_ids, parent_ids and sequence_lengths,  and I transpose final beam search output predicted_ids [0, 2, 1] to print the top 2 best paths.\npredicted_ids:\n[[[936   1]\n[  8   2]\n[  2   2]]]\nparent_ids:\n[[[0 0]\n[0 0]\n[1 0]]]\nsequence_lengths:\n[[3 2]]\ntop2 best paths:\n[936   2   2] \u53e4\u4ee3/[EOS] 0.000512714 -7.57579140233\n[936   2  -1] \u53e4\u4ee3/[EOS] 0.000134506 -8.91390228447\nWhich is not as good as out graph result, you see the path [1, 2] will be ignored since we have\n[936, 8] [936, 2] occupy all 2 beam_width positions... (finished competing with non finished)\nAnd the final result has [936, 2, 2] [936, 2, -1] which is also not correct.\nI think should be [936, 2, -1] ([936,2,2]) and [936,8,2] with sequence_lengths [[2, 3]]\nIf considering length penalty, we can not assume early finished shorter path be better then longer ones.\nSo may be non dynamic version, just loop max_steps and return top N finished paths will be better.", "body": "Also there are still bugs if fixing above problem. For BeamSearchDecoder design, it is dynamic and stop when all facing EOS, but is it good for doing beam search by this way? I think done beams should not competing with non finished beams.  Take a small example, comparing the result of out graph beam search(beam_width 2) and beam search by BeamSearchDecoder:\r\nfor out graph beam search(models\\im2txt\\im2txt\\inference_utils\\caption_generator.py) I got:\r\n0 [936, 2] \u53e4\u4ee3/[EOS] 0.000512714519986 -7.57579 -7.57579 [-3.9758704, -3.599921]\r\n1 [1, 2] [UNK]/[EOS] 0.000276204156072 -8.19437 -8.19437 [-4.6221266, -3.5722442]\r\nfor BeamSearchDecoder, I print predicted_ids, parent_ids and sequence_lengths,  and I transpose final beam search output predicted_ids [0, 2, 1] to print the top 2 best paths.\r\npredicted_ids:  \r\n[[[936   1]\r\n  [  8   2]\r\n  [  2   2]]]\r\nparent_ids: \r\n[[[0 0]\r\n  [0 0]\r\n  [1 0]]]\r\nsequence_lengths:\r\n[[3 2]]\r\ntop2 best paths:\r\n[936   2   2] \u53e4\u4ee3/[EOS] 0.000512714 -7.57579140233\r\n[936   2  -1] \u53e4\u4ee3/[EOS] 0.000134506 -8.91390228447\r\n\r\nWhich is not as good as out graph result, you see the path [1, 2] will be ignored since we have \r\n[936, 8] [936, 2] occupy all 2 beam_width positions... (finished competing with non finished)\r\nAnd the final result has [936, 2, 2] [936, 2, -1] which is also not correct.\r\nI think should be [936, 2, -1] ([936,2,2]) and [936,8,2] with sequence_lengths [[2, 3]]\r\n\r\nIf considering length penalty, we can not assume early finished shorter path be better then longer ones.\r\nSo may be non dynamic version, just loop max_steps and return top N finished paths will be better."}