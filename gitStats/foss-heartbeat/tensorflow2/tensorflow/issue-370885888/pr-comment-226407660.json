{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226407660", "pull_request_review_id": 166223197, "id": 226407660, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNjQwNzY2MA==", "diff_hunk": "@@ -84,114 +192,135 @@\n         \"import PIL\\n\",\n         \"import imageio\\n\",\n         \"from IPython import display\"\n-      ]\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n     },\n     {\n-      \"cell_type\": \"markdown\",\n       \"metadata\": {\n-        \"colab_type\": \"text\",\n-        \"id\": \"iYn4MdZnKCey\"\n+        \"id\": \"iYn4MdZnKCey\",\n+        \"colab_type\": \"text\"\n       },\n+      \"cell_type\": \"markdown\",\n       \"source\": [\n-        \"## Load the dataset\\n\",\n+        \"### Load the dataset\\n\",\n         \"\\n\",\n-        \"We are going to use the MNIST dataset to train the generator and the discriminator. The generator will then generate handwritten digits.\"\n+        \"We are going to use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data.\"\n       ]\n     },\n     {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": 0,\n       \"metadata\": {\n-        \"colab\": {},\n+        \"id\": \"a4fYMGxGhrna\",\n         \"colab_type\": \"code\",\n-        \"id\": \"a4fYMGxGhrna\"\n+        \"colab\": {\n+          \"base_uri\": \"https://localhost:8080/\",\n+          \"height\": 51\n+        },\n+        \"outputId\": \"065f5f41-bdd6-4f4e-bdb6-addce8ff011d\"\n       },\n-      \"outputs\": [],\n+      \"cell_type\": \"code\",\n       \"source\": [\n         \"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\"\n+      ],\n+      \"execution_count\": 3,\n+      \"outputs\": [\n+        {\n+          \"output_type\": \"stream\",\n+          \"text\": [\n+            \"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\\n\",\n+            \"11493376/11490434 [==============================] - 0s 0us/step\\n\"\n+          ],\n+          \"name\": \"stdout\"\n+        }\n       ]\n     },\n     {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": 0,\n       \"metadata\": {\n-        \"colab\": {},\n+        \"id\": \"NFC2ghIdiZYE\",\n         \"colab_type\": \"code\",\n-        \"id\": \"NFC2ghIdiZYE\"\n+        \"colab\": {}\n       },\n-      \"outputs\": [],\n+      \"cell_type\": \"code\",\n       \"source\": [\n         \"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\\n\",\n         \"# We are normalizing the images to the range of [-1, 1]\\n\",\n         \"train_images = (train_images - 127.5) / 127.5\"\n-      ]\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n     },\n     {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": 0,\n       \"metadata\": {\n-        \"colab\": {},\n+        \"id\": \"S4PIDhoDLbsZ\",\n         \"colab_type\": \"code\",\n-        \"id\": \"S4PIDhoDLbsZ\"\n+        \"colab\": {}\n       },\n-      \"outputs\": [],\n+      \"cell_type\": \"code\",\n       \"source\": [\n         \"BUFFER_SIZE = 60000\\n\",\n         \"BATCH_SIZE = 256\"\n-      ]\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n     },\n     {\n-      \"cell_type\": \"markdown\",\n       \"metadata\": {\n-        \"colab_type\": \"text\",\n-        \"id\": \"PIGN6ouoQxt3\"\n+        \"id\": \"PIGN6ouoQxt3\",\n+        \"colab_type\": \"text\"\n       },\n+      \"cell_type\": \"markdown\",\n       \"source\": [\n-        \"## Use tf.data to create batches and shuffle the dataset\"\n+        \"### Use tf.data to create batches and shuffle the dataset\"\n       ]\n     },\n     {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": 0,\n       \"metadata\": {\n-        \"colab\": {},\n+        \"id\": \"-yKCCQOoJ7cn\",\n         \"colab_type\": \"code\",\n-        \"id\": \"-yKCCQOoJ7cn\"\n+        \"colab\": {}\n       },\n-      \"outputs\": [],\n+      \"cell_type\": \"code\",\n       \"source\": [\n         \"train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\"\n-      ]\n+      ],\n+      \"execution_count\": 0,\n+      \"outputs\": []\n     },\n     {\n+      \"metadata\": {\n+        \"id\": \"THY-sZMiQ4UV\",\n+        \"colab_type\": \"text\"\n+      },\n       \"cell_type\": \"markdown\",\n+      \"source\": [\n+        \"## Create the models\\n\",\n+        \"\\n\",\n+        \"We will use tf.keras model subclassing to create the generator and discriminator. We will create layers in the __init__ method and set them as attributes of the class instance. And then define the forward pass in the **call **method.\"\n+      ]\n+    },\n+    {\n       \"metadata\": {\n-        \"colab_type\": \"text\",\n-        \"id\": \"THY-sZMiQ4UV\"\n+        \"id\": \"-tEyxE-GMC48\",\n+        \"colab_type\": \"text\"\n       },\n+      \"cell_type\": \"markdown\",\n       \"source\": [\n-        \"## Write the generator and discriminator models\\n\",\n+        \"### The Generator Model\\n\",\n         \"\\n\",\n-        \"* **Generator** \\n\",\n-        \"  * It is responsible for **creating convincing images that are good enough to fool the discriminator**.\\n\",\n-        \"  * It consists of Conv2DTranspose (Upsampling) layers. We start with a fully connected layer and upsample the image 2 times so as to reach the desired image size (mnist image size) which is (28, 28, 1). \\n\",\n-        \"  * We use **leaky relu** activation except for the **last layer** which uses **tanh** activation.\\n\",\n-        \"  \\n\",\n-        \"* **Discriminator**\\n\",\n-        \"  * **The discriminator is responsible for classifying the fake images from the real images.**\\n\",\n-        \"  * In other words, the discriminator is given generated images (from the generator) and the real MNIST images. The job of the discriminator is to classify these images into fake (generated) and real (MNIST images).\\n\",\n-        \"  * **Basically the generator should be good enough to fool the discriminator that the generated images are real**.\"\n+        \"The **generator **is responsible for **creating convincing images that are good enough to fool the discriminator**. \\n\",\n+        \"\\n\",\n+        \"Here is the network architecture for the generator:\\n\",\n+        \" * It consists of Conv2DTranspose (Upsampling) layers. We start with a fully connected layer and **upsample** the image 2 times in order to reach the desired image size as mnist image size of (28, 28, 1). We increase the width and height, and reduce the depth as we move through the layers in the network.\\n\",\n+        \" * We use **leaky relu** activation except for the **last layer** which uses **tanh** activation.\"\n       ]\n     },\n     {\n-      \"cell_type\": \"code\",\n-      \"execution_count\": 0,\n       \"metadata\": {\n-        \"colab\": {},\n+        \"id\": \"VGLbvBEmjK0a\",\n         \"colab_type\": \"code\",\n-        \"id\": \"VGLbvBEmjK0a\"\n+        \"colab\": {}\n       },\n-      \"outputs\": [],\n+      \"cell_type\": \"code\",\n       \"source\": [\n         \"class Generator(tf.keras.Model):\\n\",", "path": "tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb", "position": null, "original_position": 402, "commit_id": "459bfb3b324e194be33aa66f38a71291f3d82b95", "original_commit_id": "a4013c51f07180c4b8946357ee3daf18043a8acc", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "body": "Both this and the discriminator class seems like they will be well served by `tf.keras.Sequential`, making the code even more compact. Should we write them instead as:\r\n\r\n```python\r\ndef make_generator_model():\r\n  return tf.keras.Sequential([\r\n    tf.keras.layers.Dense(7*7*64, use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Relu(),\r\n    ...])\r\n```\r\n", "created_at": "2018-10-18T18:00:07Z", "updated_at": "2018-10-24T17:54:02Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/23035#discussion_r226407660", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23035", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226407660"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23035#discussion_r226407660"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23035"}}, "body_html": "<p>Both this and the discriminator class seems like they will be well served by <code>tf.keras.Sequential</code>, making the code even more compact. Should we write them instead as:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">make_generator_model</span>():\n  <span class=\"pl-k\">return</span> tf.keras.Sequential([\n    tf.keras.layers.Dense(<span class=\"pl-c1\">7</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">7</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">64</span>, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Relu(),\n    <span class=\"pl-c1\">...</span>])</pre></div>", "body_text": "Both this and the discriminator class seems like they will be well served by tf.keras.Sequential, making the code even more compact. Should we write them instead as:\ndef make_generator_model():\n  return tf.keras.Sequential([\n    tf.keras.layers.Dense(7*7*64, use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Relu(),\n    ...])"}