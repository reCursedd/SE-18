{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/378607206", "html_url": "https://github.com/tensorflow/tensorflow/issues/2033#issuecomment-378607206", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2033", "id": 378607206, "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODYwNzIwNg==", "user": {"login": "nicolefinnie", "id": 15970573, "node_id": "MDQ6VXNlcjE1OTcwNTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/15970573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicolefinnie", "html_url": "https://github.com/nicolefinnie", "followers_url": "https://api.github.com/users/nicolefinnie/followers", "following_url": "https://api.github.com/users/nicolefinnie/following{/other_user}", "gists_url": "https://api.github.com/users/nicolefinnie/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicolefinnie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicolefinnie/subscriptions", "organizations_url": "https://api.github.com/users/nicolefinnie/orgs", "repos_url": "https://api.github.com/users/nicolefinnie/repos", "events_url": "https://api.github.com/users/nicolefinnie/events{/privacy}", "received_events_url": "https://api.github.com/users/nicolefinnie/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-04T13:52:11Z", "updated_at": "2018-04-04T13:52:11Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4516927\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/philipperemy\">@philipperemy</a>  was right, we didn't hit this issue when we just had one GPU, but when we trained our model with multiple GPUs, the error kicked in. You need to calculate your batch size for each GPU carefully. For example, if each batch size is 64 and you have 4 GPUs with 47 training samples, it will be split to 16, 16, 15, 0, the last batch will get zero sample. It's not obvious when there are many samples like our case.</p>", "body_text": "@philipperemy  was right, we didn't hit this issue when we just had one GPU, but when we trained our model with multiple GPUs, the error kicked in. You need to calculate your batch size for each GPU carefully. For example, if each batch size is 64 and you have 4 GPUs with 47 training samples, it will be split to 16, 16, 15, 0, the last batch will get zero sample. It's not obvious when there are many samples like our case.", "body": "@philipperemy  was right, we didn't hit this issue when we just had one GPU, but when we trained our model with multiple GPUs, the error kicked in. You need to calculate your batch size for each GPU carefully. For example, if each batch size is 64 and you have 4 GPUs with 47 training samples, it will be split to 16, 16, 15, 0, the last batch will get zero sample. It's not obvious when there are many samples like our case."}