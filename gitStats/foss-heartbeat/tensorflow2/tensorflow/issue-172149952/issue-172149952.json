{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3926", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3926/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3926/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3926/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3926", "id": 172149952, "node_id": "MDU6SXNzdWUxNzIxNDk5NTI=", "number": 3926, "title": "Failing to restore net", "user": {"login": "kalle", "id": 370192, "node_id": "MDQ6VXNlcjM3MDE5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/370192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kalle", "html_url": "https://github.com/kalle", "followers_url": "https://api.github.com/users/kalle/followers", "following_url": "https://api.github.com/users/kalle/following{/other_user}", "gists_url": "https://api.github.com/users/kalle/gists{/gist_id}", "starred_url": "https://api.github.com/users/kalle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kalle/subscriptions", "organizations_url": "https://api.github.com/users/kalle/orgs", "repos_url": "https://api.github.com/users/kalle/repos", "events_url": "https://api.github.com/users/kalle/events{/privacy}", "received_events_url": "https://api.github.com/users/kalle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ilblackdragon", "id": 175486, "node_id": "MDQ6VXNlcjE3NTQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/175486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilblackdragon", "html_url": "https://github.com/ilblackdragon", "followers_url": "https://api.github.com/users/ilblackdragon/followers", "following_url": "https://api.github.com/users/ilblackdragon/following{/other_user}", "gists_url": "https://api.github.com/users/ilblackdragon/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilblackdragon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilblackdragon/subscriptions", "organizations_url": "https://api.github.com/users/ilblackdragon/orgs", "repos_url": "https://api.github.com/users/ilblackdragon/repos", "events_url": "https://api.github.com/users/ilblackdragon/events{/privacy}", "received_events_url": "https://api.github.com/users/ilblackdragon/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ilblackdragon", "id": 175486, "node_id": "MDQ6VXNlcjE3NTQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/175486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilblackdragon", "html_url": "https://github.com/ilblackdragon", "followers_url": "https://api.github.com/users/ilblackdragon/followers", "following_url": "https://api.github.com/users/ilblackdragon/following{/other_user}", "gists_url": "https://api.github.com/users/ilblackdragon/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilblackdragon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilblackdragon/subscriptions", "organizations_url": "https://api.github.com/users/ilblackdragon/orgs", "repos_url": "https://api.github.com/users/ilblackdragon/repos", "events_url": "https://api.github.com/users/ilblackdragon/events{/privacy}", "received_events_url": "https://api.github.com/users/ilblackdragon/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2016-08-19T14:54:05Z", "updated_at": "2016-08-27T22:13:43Z", "closed_at": "2016-08-27T22:13:43Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nMac OS X 10.11.4<br>\nTensorflow installed from pre-built pip (no CUDA):<br>\n0.10.0rc0</p>\n<h3>Problem</h3>\n<p>I have problems with restoring my net <a href=\"http://stackoverflow.com/questions/39035041/trouble-restoring-checkpointed-tensorflow-net\" rel=\"nofollow\">(from SO)</a>. I have created a short <a href=\"https://github.com/tensorflow/tensorflow/files/427240/bug_report.zip\">test program</a> that have the same problem as my real program.</p>\n<p>The program train a net, run one inference with it and then checkpoints the model. Then it loads the checkpointed model and run the inference with the same data and compare the result. I expected the results to be very similar but they weren't:</p>\n<pre><code>Restoring graph from /tmp/bugreport/model.ckpt-0\nInference after training gave 2.40740537643\nInference after restoring net gave 62579.6210938\n</code></pre>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.layers <span class=\"pl-k\">as</span> contrib\n\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> tf.app.flags.<span class=\"pl-c1\">FLAGS</span>\n\ntf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>tmp_dir<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/bugreport<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Temp dir<span class=\"pl-pds\">\"\"\"</span></span>)\n\n<span class=\"pl-c1\">SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n<span class=\"pl-c1\">NUM_DATA</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n<span class=\"pl-c1\">BATCH_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n<span class=\"pl-c1\">DEPTH</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">inference</span>(<span class=\"pl-smi\">input_tensor</span>, <span class=\"pl-smi\">is_training</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Define a stupid net<span class=\"pl-pds\">\"</span></span>\n    bn_params <span class=\"pl-k\">=</span> {\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>is_training<span class=\"pl-pds\">\"</span></span>: is_training,\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>center<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-c1\">True</span>,\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>scale<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-c1\">True</span>\n            }\n    tensor <span class=\"pl-k\">=</span> contrib.convolution2d(input_tensor, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">3</span>,\n            <span class=\"pl-v\">normalizer_fn</span><span class=\"pl-k\">=</span>contrib.batch_norm,\n            <span class=\"pl-v\">normalizer_params</span><span class=\"pl-k\">=</span>bn_params,\n            <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>conv1<span class=\"pl-pds\">\"</span></span>)\n    tensor <span class=\"pl-k\">=</span> tf.reduce_sum(tensor)\n    <span class=\"pl-k\">return</span> tensor\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">training</span>(<span class=\"pl-smi\">input_data</span>, <span class=\"pl-smi\">label_data</span>, <span class=\"pl-smi\">test_data</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>1. Train the net</span>\n<span class=\"pl-s\">    2. Do an inference pass with the trained net</span>\n<span class=\"pl-s\">    3. Checkpoint the trained net</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.Graph().as_default():\n        input_tensor <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">DEPT</span><span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n        label_tensor = tf.placeholder(tf.float32, [<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">DEPTH</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>la#<span class=\"pl-ii\"></span></span>\n\n        <span class=\"pl-v\">output</span> <span class=\"pl-k\">=</span> inference(input_tensor, tf.constant(<span class=\"pl-c1\">True</span>))\n        <span class=\"pl-v\">loss</span> <span class=\"pl-k\">=</span> tf.nn.l2_loss(output <span class=\"pl-k\">-</span> label_tensor, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>loss<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-v\">train_op</span> <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-c1\">0.9999</span>).minimize(loss)\n        <span class=\"pl-v\">init</span> <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n        <span class=\"pl-v\">saver</span> <span class=\"pl-k\">=</span> tf.train.Saver(tf.all_variables())\n\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n            sess.run([init])\n            <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">NUM_DATA</span>):\n                <span class=\"pl-v\">_</span> <span class=\"pl-k\">=</span> sess.run(train_op, { input_tensor: input_data[i],\n                                         label_tensor: label_data[i] })\n            <span class=\"pl-v\">training_out</span> <span class=\"pl-k\">=</span> sess.run(output, { input_tensor: test_data })\n            <span class=\"pl-v\">cp_path</span> <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.tmp_dir, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>model.ckpt<span class=\"pl-pds\">\"</span></span>)\n            saver.save(sess, cp_path,\n                       <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">write_meta_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n    <span class=\"pl-k\">return</span> training_out\n\n<span class=\"pl-k\">def</span> use_restored_net(test_data):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>1. Load checkpointed net</span>\n<span class=\"pl-s\">    2. Do an inference pass with the trained net</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.Graph().as_default():\n        <span class=\"pl-v\">input_tensor</span> <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">DEPT</span><span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n\n        output = inference(input_tensor, tf.constant(<span class=\"pl-c1\">False</span>))\n        init = tf.initialize_all_variables()\n\n        ckpt = tf.train.get_checkpoint_state(<span class=\"pl-c1\">FLAGS</span>.tmp_dir)\n        <span class=\"pl-k\">if</span> ckpt <span class=\"pl-k\">and</span> ckpt.model_checkpoint_path:\n            <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Restoring graph from <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(ckpt.model_checkpoint_path)\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Could not find a checkpointed model<span class=\"pl-pds\">\"</span></span>)\n        saver = tf.train.Saver(tf.all_variables())\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n            sess.run([init])\n            saver.restore(sess, ckpt.model_checkpoint_path)\n            inference_out = sess.run(output, { input_tensor: test_data })\n    <span class=\"pl-k\">return</span> inference_out\n\n<span class=\"pl-k\">def</span> main(argv):\n    <span class=\"pl-k\">if</span> tf.gfile.Exists(<span class=\"pl-c1\">FLAGS</span>.tmp_dir):\n        tf.gfile.DeleteRecursively(<span class=\"pl-c1\">FLAGS</span>.tmp_dir)\n    tf.gfile.MakeDirs(<span class=\"pl-c1\">FLAGS</span>.tmp_dir)\n\n    input_data = np.random.rand(<span class=\"pl-c1\">NUM_DATA</span>, <span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">DEPTH</span>)\n    label_data = np.random.rand(<span class=\"pl-c1\">NUM_DATA</span>, <span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">DEPTH</span>)\n    test_data = np.random.rand(<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">SIZE</span>, <span class=\"pl-c1\">DEPTH</span>)\n\n    training_out = training(input_data, label_data, test_data)\n    inference_out = use_restored_net(test_data)\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Inference after training gave <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(training_out)\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Inference after restoring net gave <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(inference_out)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.app.run()\n</pre></div>", "body_text": "Environment info\nOperating System:\nMac OS X 10.11.4\nTensorflow installed from pre-built pip (no CUDA):\n0.10.0rc0\nProblem\nI have problems with restoring my net (from SO). I have created a short test program that have the same problem as my real program.\nThe program train a net, run one inference with it and then checkpoints the model. Then it loads the checkpointed model and run the inference with the same data and compare the result. I expected the results to be very similar but they weren't:\nRestoring graph from /tmp/bugreport/model.ckpt-0\nInference after training gave 2.40740537643\nInference after restoring net gave 62579.6210938\n\nimport os\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.layers as contrib\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string('tmp_dir', '/tmp/bugreport', \"\"\"Temp dir\"\"\")\n\nSIZE = 5\nNUM_DATA = 10\nBATCH_SIZE = 1\nDEPTH = 1\n\ndef inference(input_tensor, is_training):\n    \"Define a stupid net\"\n    bn_params = {\n            \"is_training\": is_training,\n            \"center\": True,\n            \"scale\": True\n            }\n    tensor = contrib.convolution2d(input_tensor, 8, 3,\n            normalizer_fn=contrib.batch_norm,\n            normalizer_params=bn_params,\n            scope=\"conv1\")\n    tensor = tf.reduce_sum(tensor)\n    return tensor\n\ndef training(input_data, label_data, test_data):\n    \"\"\"1. Train the net\n    2. Do an inference pass with the trained net\n    3. Checkpoint the trained net\n    \"\"\"\n    with tf.Graph().as_default():\n        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#\n        label_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, DEPTH], name=\"la#\n\n        output = inference(input_tensor, tf.constant(True))\n        loss = tf.nn.l2_loss(output - label_tensor, name=\"loss\")\n        train_op = tf.train.AdamOptimizer(0.9999).minimize(loss)\n        init = tf.initialize_all_variables()\n        saver = tf.train.Saver(tf.all_variables())\n\n        with tf.Session() as sess:\n            sess.run([init])\n            for i in range(NUM_DATA):\n                _ = sess.run(train_op, { input_tensor: input_data[i],\n                                         label_tensor: label_data[i] })\n            training_out = sess.run(output, { input_tensor: test_data })\n            cp_path = os.path.join(FLAGS.tmp_dir, \"model.ckpt\")\n            saver.save(sess, cp_path,\n                       global_step=0, write_meta_graph=None)\n    return training_out\n\ndef use_restored_net(test_data):\n    \"\"\"1. Load checkpointed net\n    2. Do an inference pass with the trained net\n    \"\"\"\n    with tf.Graph().as_default():\n        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#\n\n        output = inference(input_tensor, tf.constant(False))\n        init = tf.initialize_all_variables()\n\n        ckpt = tf.train.get_checkpoint_state(FLAGS.tmp_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            print \"Restoring graph from {}\".format(ckpt.model_checkpoint_path)\n        else:\n            raise ValueError(\"Could not find a checkpointed model\")\n        saver = tf.train.Saver(tf.all_variables())\n        with tf.Session() as sess:\n            sess.run([init])\n            saver.restore(sess, ckpt.model_checkpoint_path)\n            inference_out = sess.run(output, { input_tensor: test_data })\n    return inference_out\n\ndef main(argv):\n    if tf.gfile.Exists(FLAGS.tmp_dir):\n        tf.gfile.DeleteRecursively(FLAGS.tmp_dir)\n    tf.gfile.MakeDirs(FLAGS.tmp_dir)\n\n    input_data = np.random.rand(NUM_DATA, BATCH_SIZE, SIZE, SIZE, DEPTH)\n    label_data = np.random.rand(NUM_DATA, BATCH_SIZE, DEPTH)\n    test_data = np.random.rand(BATCH_SIZE, SIZE, SIZE, DEPTH)\n\n    training_out = training(input_data, label_data, test_data)\n    inference_out = use_restored_net(test_data)\n    print \"Inference after training gave {}\".format(training_out)\n    print \"Inference after restoring net gave {}\".format(inference_out)\n\n\nif __name__ == '__main__':\n    tf.app.run()", "body": "### Environment info\n\nOperating System:\nMac OS X 10.11.4\nTensorflow installed from pre-built pip (no CUDA):\n0.10.0rc0\n### Problem\n\nI have problems with restoring my net [(from SO)](http://stackoverflow.com/questions/39035041/trouble-restoring-checkpointed-tensorflow-net). I have created a short [test program](https://github.com/tensorflow/tensorflow/files/427240/bug_report.zip) that have the same problem as my real program.\n\nThe program train a net, run one inference with it and then checkpoints the model. Then it loads the checkpointed model and run the inference with the same data and compare the result. I expected the results to be very similar but they weren't:\n\n```\nRestoring graph from /tmp/bugreport/model.ckpt-0\nInference after training gave 2.40740537643\nInference after restoring net gave 62579.6210938\n```\n\n``` python\nimport os\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.layers as contrib\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string('tmp_dir', '/tmp/bugreport', \"\"\"Temp dir\"\"\")\n\nSIZE = 5\nNUM_DATA = 10\nBATCH_SIZE = 1\nDEPTH = 1\n\ndef inference(input_tensor, is_training):\n    \"Define a stupid net\"\n    bn_params = {\n            \"is_training\": is_training,\n            \"center\": True,\n            \"scale\": True\n            }\n    tensor = contrib.convolution2d(input_tensor, 8, 3,\n            normalizer_fn=contrib.batch_norm,\n            normalizer_params=bn_params,\n            scope=\"conv1\")\n    tensor = tf.reduce_sum(tensor)\n    return tensor\n\ndef training(input_data, label_data, test_data):\n    \"\"\"1. Train the net\n    2. Do an inference pass with the trained net\n    3. Checkpoint the trained net\n    \"\"\"\n    with tf.Graph().as_default():\n        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#\n        label_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, DEPTH], name=\"la#\n\n        output = inference(input_tensor, tf.constant(True))\n        loss = tf.nn.l2_loss(output - label_tensor, name=\"loss\")\n        train_op = tf.train.AdamOptimizer(0.9999).minimize(loss)\n        init = tf.initialize_all_variables()\n        saver = tf.train.Saver(tf.all_variables())\n\n        with tf.Session() as sess:\n            sess.run([init])\n            for i in range(NUM_DATA):\n                _ = sess.run(train_op, { input_tensor: input_data[i],\n                                         label_tensor: label_data[i] })\n            training_out = sess.run(output, { input_tensor: test_data })\n            cp_path = os.path.join(FLAGS.tmp_dir, \"model.ckpt\")\n            saver.save(sess, cp_path,\n                       global_step=0, write_meta_graph=None)\n    return training_out\n\ndef use_restored_net(test_data):\n    \"\"\"1. Load checkpointed net\n    2. Do an inference pass with the trained net\n    \"\"\"\n    with tf.Graph().as_default():\n        input_tensor = tf.placeholder(tf.float32, [BATCH_SIZE, SIZE, SIZE, DEPT#\n\n        output = inference(input_tensor, tf.constant(False))\n        init = tf.initialize_all_variables()\n\n        ckpt = tf.train.get_checkpoint_state(FLAGS.tmp_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            print \"Restoring graph from {}\".format(ckpt.model_checkpoint_path)\n        else:\n            raise ValueError(\"Could not find a checkpointed model\")\n        saver = tf.train.Saver(tf.all_variables())\n        with tf.Session() as sess:\n            sess.run([init])\n            saver.restore(sess, ckpt.model_checkpoint_path)\n            inference_out = sess.run(output, { input_tensor: test_data })\n    return inference_out\n\ndef main(argv):\n    if tf.gfile.Exists(FLAGS.tmp_dir):\n        tf.gfile.DeleteRecursively(FLAGS.tmp_dir)\n    tf.gfile.MakeDirs(FLAGS.tmp_dir)\n\n    input_data = np.random.rand(NUM_DATA, BATCH_SIZE, SIZE, SIZE, DEPTH)\n    label_data = np.random.rand(NUM_DATA, BATCH_SIZE, DEPTH)\n    test_data = np.random.rand(BATCH_SIZE, SIZE, SIZE, DEPTH)\n\n    training_out = training(input_data, label_data, test_data)\n    inference_out = use_restored_net(test_data)\n    print \"Inference after training gave {}\".format(training_out)\n    print \"Inference after restoring net gave {}\".format(inference_out)\n\n\nif __name__ == '__main__':\n    tf.app.run()\n\n```\n"}