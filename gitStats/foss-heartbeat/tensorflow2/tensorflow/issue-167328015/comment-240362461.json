{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/240362461", "html_url": "https://github.com/tensorflow/tensorflow/issues/3491#issuecomment-240362461", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3491", "id": 240362461, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MDM2MjQ2MQ==", "user": {"login": "llhe", "id": 192829, "node_id": "MDQ6VXNlcjE5MjgyOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/192829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/llhe", "html_url": "https://github.com/llhe", "followers_url": "https://api.github.com/users/llhe/followers", "following_url": "https://api.github.com/users/llhe/following{/other_user}", "gists_url": "https://api.github.com/users/llhe/gists{/gist_id}", "starred_url": "https://api.github.com/users/llhe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/llhe/subscriptions", "organizations_url": "https://api.github.com/users/llhe/orgs", "repos_url": "https://api.github.com/users/llhe/repos", "events_url": "https://api.github.com/users/llhe/events{/privacy}", "received_events_url": "https://api.github.com/users/llhe/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-17T09:35:03Z", "updated_at": "2016-08-17T09:35:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> By the way, I noticed two facts:</p>\n<ol>\n<li>file_io.py only support read_file_to_string for reading, will it be problematic for large files?</li>\n<li>the GCS implemented recently added read ahead buffer. In fact we also support this improvement for our DFS implementation. I wondering will the sequential access pattern guaranteed by the upper level? Or else the performance can be very bad when the caching/buffering failed. If not, may be exposing a config parameter for NewRandomAccessFile to allow flexible caching a better solution?</li>\n</ol>", "body_text": "@vrv By the way, I noticed two facts:\n\nfile_io.py only support read_file_to_string for reading, will it be problematic for large files?\nthe GCS implemented recently added read ahead buffer. In fact we also support this improvement for our DFS implementation. I wondering will the sequential access pattern guaranteed by the upper level? Or else the performance can be very bad when the caching/buffering failed. If not, may be exposing a config parameter for NewRandomAccessFile to allow flexible caching a better solution?", "body": "@vrv By the way, I noticed two facts:\n1. file_io.py only support read_file_to_string for reading, will it be problematic for large files?\n2. the GCS implemented recently added read ahead buffer. In fact we also support this improvement for our DFS implementation. I wondering will the sequential access pattern guaranteed by the upper level? Or else the performance can be very bad when the caching/buffering failed. If not, may be exposing a config parameter for NewRandomAccessFile to allow flexible caching a better solution?\n"}