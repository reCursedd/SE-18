{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20119", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20119/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20119/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20119/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20119", "id": 333650797, "node_id": "MDU6SXNzdWUzMzM2NTA3OTc=", "number": 20119, "title": "toco aborts on converting quantized graph to TFLite", "user": {"login": "shiftsayan", "id": 8451336, "node_id": "MDQ6VXNlcjg0NTEzMzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8451336?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shiftsayan", "html_url": "https://github.com/shiftsayan", "followers_url": "https://api.github.com/users/shiftsayan/followers", "following_url": "https://api.github.com/users/shiftsayan/following{/other_user}", "gists_url": "https://api.github.com/users/shiftsayan/gists{/gist_id}", "starred_url": "https://api.github.com/users/shiftsayan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shiftsayan/subscriptions", "organizations_url": "https://api.github.com/users/shiftsayan/orgs", "repos_url": "https://api.github.com/users/shiftsayan/repos", "events_url": "https://api.github.com/users/shiftsayan/events{/privacy}", "received_events_url": "https://api.github.com/users/shiftsayan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-06-19T12:33:33Z", "updated_at": "2018-07-06T18:56:17Z", "closed_at": "2018-07-06T18:56:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: macOS High Sierra 10.13.5</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.1</li>\n<li><strong>Python version</strong>: 2.7.10</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>toco \\\n--input_file=tmp/killfie_detector.pb \\\n--output_file=tmp/quantized_killfie_detector.lite \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\n--input_array=input1 \\\n--output_array=output_node0 \\\n--inference_type=FLOAT \\\n--input_data_type=FLOAT \\\n--inference_type=QUANTIZED_UINT8 \\\n--quantize_weights=true \\\n--mean_value=127.5 \\\n--std_value=127.5\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I am trying to convert a ResNet-50 model to TFLite after quantization. The quantized graph was obtained using <code>transform_graph</code> and <code>--transforms='quantize_weights'</code> on a .pb file. However, on running <code>toco</code> on the quantized graph using the command above, I am first asked to enter the max/min values and the following error:</p>\n<pre><code>Array input_1, which is an input to the Conv operator producing the output array conv1/convolution, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\n</code></pre>\n<p>On adding <code>--default_ranges_min=0</code> and <code>--default_ranges_max=6</code> based on the suggestions <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#use-dummy-quantization-to-try-out-quantized-inference-on-a-float-graph-\">here</a>.</p>\n<p>When I ran that script, I got this error message:</p>\n<pre><code>F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:519] Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\n</code></pre>\n<p>Is there any way around this to get a quantized TFLite model?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra 10.13.5\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7.1\nPython version: 2.7.10\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce:\n\ntoco \\\n--input_file=tmp/killfie_detector.pb \\\n--output_file=tmp/quantized_killfie_detector.lite \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\n--input_array=input1 \\\n--output_array=output_node0 \\\n--inference_type=FLOAT \\\n--input_data_type=FLOAT \\\n--inference_type=QUANTIZED_UINT8 \\\n--quantize_weights=true \\\n--mean_value=127.5 \\\n--std_value=127.5\n\nDescribe the problem\nI am trying to convert a ResNet-50 model to TFLite after quantization. The quantized graph was obtained using transform_graph and --transforms='quantize_weights' on a .pb file. However, on running toco on the quantized graph using the command above, I am first asked to enter the max/min values and the following error:\nArray input_1, which is an input to the Conv operator producing the output array conv1/convolution, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\n\nOn adding --default_ranges_min=0 and --default_ranges_max=6 based on the suggestions here.\nWhen I ran that script, I got this error message:\nF tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:519] Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\n\nIs there any way around this to get a quantized TFLite model?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.5\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.1\r\n- **Python version**: 2.7.10\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n```\r\ntoco \\\r\n--input_file=tmp/killfie_detector.pb \\\r\n--output_file=tmp/quantized_killfie_detector.lite \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\r\n--input_array=input1 \\\r\n--output_array=output_node0 \\\r\n--inference_type=FLOAT \\\r\n--input_data_type=FLOAT \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--quantize_weights=true \\\r\n--mean_value=127.5 \\\r\n--std_value=127.5\r\n```\r\n\r\n### Describe the problem\r\nI am trying to convert a ResNet-50 model to TFLite after quantization. The quantized graph was obtained using `transform_graph` and `--transforms='quantize_weights'` on a .pb file. However, on running `toco` on the quantized graph using the command above, I am first asked to enter the max/min values and the following error:\r\n```\r\nArray input_1, which is an input to the Conv operator producing the output array conv1/convolution, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\n```\r\n\r\nOn adding `--default_ranges_min=0` and `--default_ranges_max=6` based on the suggestions [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#use-dummy-quantization-to-try-out-quantized-inference-on-a-float-graph-).\r\n\r\nWhen I ran that script, I got this error message:\r\n```\r\nF tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:519] Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\r\n```\r\n\r\nIs there any way around this to get a quantized TFLite model?\r\n"}