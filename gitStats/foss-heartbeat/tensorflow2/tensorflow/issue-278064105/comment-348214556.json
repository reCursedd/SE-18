{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348214556", "html_url": "https://github.com/tensorflow/tensorflow/issues/14998#issuecomment-348214556", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14998", "id": 348214556, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODIxNDU1Ng==", "user": {"login": "boeddeker", "id": 13744128, "node_id": "MDQ6VXNlcjEzNzQ0MTI4", "avatar_url": "https://avatars3.githubusercontent.com/u/13744128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boeddeker", "html_url": "https://github.com/boeddeker", "followers_url": "https://api.github.com/users/boeddeker/followers", "following_url": "https://api.github.com/users/boeddeker/following{/other_user}", "gists_url": "https://api.github.com/users/boeddeker/gists{/gist_id}", "starred_url": "https://api.github.com/users/boeddeker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boeddeker/subscriptions", "organizations_url": "https://api.github.com/users/boeddeker/orgs", "repos_url": "https://api.github.com/users/boeddeker/repos", "events_url": "https://api.github.com/users/boeddeker/events{/privacy}", "received_events_url": "https://api.github.com/users/boeddeker/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-30T15:04:29Z", "updated_at": "2017-11-30T15:04:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Currently <code>tf.reshape</code> is powerful enough to solve all problems, but there are two reasons in my mind, why the further arguments are useful, not necessary.</p>\n<p>First: Less \"hidden bugs\" on user side<br>\nExample: I modified your example (swapped 6 and 4), it is still executable, but the intent was to flatten the inner dims.<br>\nSo the output shape is correct, but it hides a bug in user code.</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">4</span>])\ny <span class=\"pl-k\">=</span> tf.reshape(x, (<span class=\"pl-c1\">3</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">6</span>))</pre></div>\n<p>Second: It is easier when there are unknown dimensions<br>\nFor example the following does not work</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">None</span>])\ny <span class=\"pl-k\">=</span> tf.reshape(x, (<span class=\"pl-c1\">3</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>))</pre></div>\n<p>For above example I had to learn the difference between <code>tensor.shape</code> and <code>tf.shape(tensor)</code> to make it possible</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">None</span>])\nshape <span class=\"pl-k\">=</span> x.shape  <span class=\"pl-c\"><span class=\"pl-c\">#</span> does not work, first shape[-1] is None, second shape[-1] can not be set to -1, because there is already a -1</span>\nshape <span class=\"pl-k\">=</span> tf.shape(x)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> work</span>\ny <span class=\"pl-k\">=</span> tf.reshape(x, (shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]))\ny <span class=\"pl-k\">=</span> tf.reshape(x, (<span class=\"pl-k\">*</span>shape[:<span class=\"pl-c1\">1</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-k\">*</span>shape[<span class=\"pl-c1\">3</span>:]))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> does not work, because the code `*tensor` is not allowed, but `*tensor.shape` work.</span></pre></div>\n<p>Further with the new arguments you can easily flatten the inner dims, while the tensor has a unkown shape.</p>", "body_text": "Currently tf.reshape is powerful enough to solve all problems, but there are two reasons in my mind, why the further arguments are useful, not necessary.\nFirst: Less \"hidden bugs\" on user side\nExample: I modified your example (swapped 6 and 4), it is still executable, but the intent was to flatten the inner dims.\nSo the output shape is correct, but it hides a bug in user code.\nx = tf.placeholder(tf.float32, shape=[3, 6, 5, 4])\ny = tf.reshape(x, (3, -1, 6))\nSecond: It is easier when there are unknown dimensions\nFor example the following does not work\nx = tf.placeholder(tf.float32, shape=[3, None, 5, None])\ny = tf.reshape(x, (3, -1, -1))\nFor above example I had to learn the difference between tensor.shape and tf.shape(tensor) to make it possible\nx = tf.placeholder(tf.float32, shape=[3, None, 5, None])\nshape = x.shape  # does not work, first shape[-1] is None, second shape[-1] can not be set to -1, because there is already a -1\nshape = tf.shape(x)  # work\ny = tf.reshape(x, (shape[0], -1, shape[-1]))\ny = tf.reshape(x, (*shape[:1], -1, *shape[3:]))  # does not work, because the code `*tensor` is not allowed, but `*tensor.shape` work.\nFurther with the new arguments you can easily flatten the inner dims, while the tensor has a unkown shape.", "body": "Currently `tf.reshape` is powerful enough to solve all problems, but there are two reasons in my mind, why the further arguments are useful, not necessary.\r\n\r\nFirst: Less \"hidden bugs\" on user side\r\nExample: I modified your example (swapped 6 and 4), it is still executable, but the intent was to flatten the inner dims.\r\nSo the output shape is correct, but it hides a bug in user code.\r\n```python\r\nx = tf.placeholder(tf.float32, shape=[3, 6, 5, 4])\r\ny = tf.reshape(x, (3, -1, 6))\r\n```\r\n\r\nSecond: It is easier when there are unknown dimensions\r\nFor example the following does not work\r\n```python\r\nx = tf.placeholder(tf.float32, shape=[3, None, 5, None])\r\ny = tf.reshape(x, (3, -1, -1))\r\n```\r\nFor above example I had to learn the difference between `tensor.shape` and `tf.shape(tensor)` to make it possible\r\n```python\r\nx = tf.placeholder(tf.float32, shape=[3, None, 5, None])\r\nshape = x.shape  # does not work, first shape[-1] is None, second shape[-1] can not be set to -1, because there is already a -1\r\nshape = tf.shape(x)  # work\r\ny = tf.reshape(x, (shape[0], -1, shape[-1]))\r\ny = tf.reshape(x, (*shape[:1], -1, *shape[3:]))  # does not work, because the code `*tensor` is not allowed, but `*tensor.shape` work.\r\n```\r\nFurther with the new arguments you can easily flatten the inner dims, while the tensor has a unkown shape.\r\n\r\n"}