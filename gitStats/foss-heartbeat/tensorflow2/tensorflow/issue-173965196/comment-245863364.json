{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245863364", "html_url": "https://github.com/tensorflow/tensorflow/issues/4101#issuecomment-245863364", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4101", "id": 245863364, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTg2MzM2NA==", "user": {"login": "Bonnevie", "id": 5861991, "node_id": "MDQ6VXNlcjU4NjE5OTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5861991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Bonnevie", "html_url": "https://github.com/Bonnevie", "followers_url": "https://api.github.com/users/Bonnevie/followers", "following_url": "https://api.github.com/users/Bonnevie/following{/other_user}", "gists_url": "https://api.github.com/users/Bonnevie/gists{/gist_id}", "starred_url": "https://api.github.com/users/Bonnevie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Bonnevie/subscriptions", "organizations_url": "https://api.github.com/users/Bonnevie/orgs", "repos_url": "https://api.github.com/users/Bonnevie/repos", "events_url": "https://api.github.com/users/Bonnevie/events{/privacy}", "received_events_url": "https://api.github.com/users/Bonnevie/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-09T09:21:00Z", "updated_at": "2016-09-09T09:21:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16907534\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rmlarsen\">@rmlarsen</a> yes, my logdet_chol function is comparable (the linked package looks interesting). And I moved to double precision without effect.</p>\n<p>Hmm, it sounds like the tensorflow gradient code takes care to keep things optimized, although I'm guessing that propagated matrices aren't checked for i.e. triangularity?</p>\n<p>How does the automatic differentiation engine handle matrix-matrix derivatives, and submatrices/indexings of complicated matrix expressions? Does it calculate the entire matrix efficiently and then index, or does it try to calculate the submatrix independently using simpler routines?</p>\n<p>I have tried writing out the gradients mathematically in the following file, along with my working hypothesis about what's causing the problem:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/463609/gradients.pdf\">gradients.pdf</a></p>\n<p>I think it's only for particular choices of ell that this is a real problem. My problem is not exactly as written, there are a few more moving parts.</p>", "body_text": "@rmlarsen yes, my logdet_chol function is comparable (the linked package looks interesting). And I moved to double precision without effect.\nHmm, it sounds like the tensorflow gradient code takes care to keep things optimized, although I'm guessing that propagated matrices aren't checked for i.e. triangularity?\nHow does the automatic differentiation engine handle matrix-matrix derivatives, and submatrices/indexings of complicated matrix expressions? Does it calculate the entire matrix efficiently and then index, or does it try to calculate the submatrix independently using simpler routines?\nI have tried writing out the gradients mathematically in the following file, along with my working hypothesis about what's causing the problem:\ngradients.pdf\nI think it's only for particular choices of ell that this is a real problem. My problem is not exactly as written, there are a few more moving parts.", "body": "@rmlarsen yes, my logdet_chol function is comparable (the linked package looks interesting). And I moved to double precision without effect.\n\nHmm, it sounds like the tensorflow gradient code takes care to keep things optimized, although I'm guessing that propagated matrices aren't checked for i.e. triangularity? \n\nHow does the automatic differentiation engine handle matrix-matrix derivatives, and submatrices/indexings of complicated matrix expressions? Does it calculate the entire matrix efficiently and then index, or does it try to calculate the submatrix independently using simpler routines? \n\nI have tried writing out the gradients mathematically in the following file, along with my working hypothesis about what's causing the problem:\n[gradients.pdf](https://github.com/tensorflow/tensorflow/files/463609/gradients.pdf)\n\nI think it's only for particular choices of ell that this is a real problem. My problem is not exactly as written, there are a few more moving parts.  \n"}