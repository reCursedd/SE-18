{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/301009036", "html_url": "https://github.com/tensorflow/tensorflow/issues/8833#issuecomment-301009036", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8833", "id": 301009036, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTAwOTAzNg==", "user": {"login": "neural22", "id": 10474831, "node_id": "MDQ6VXNlcjEwNDc0ODMx", "avatar_url": "https://avatars3.githubusercontent.com/u/10474831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neural22", "html_url": "https://github.com/neural22", "followers_url": "https://api.github.com/users/neural22/followers", "following_url": "https://api.github.com/users/neural22/following{/other_user}", "gists_url": "https://api.github.com/users/neural22/gists{/gist_id}", "starred_url": "https://api.github.com/users/neural22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neural22/subscriptions", "organizations_url": "https://api.github.com/users/neural22/orgs", "repos_url": "https://api.github.com/users/neural22/repos", "events_url": "https://api.github.com/users/neural22/events{/privacy}", "received_events_url": "https://api.github.com/users/neural22/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-12T07:51:44Z", "updated_at": "2017-05-12T09:14:42Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> I tried to use your previous code as explained. But If I put the encoder_state of the previous level (2 bidirectional encoders with GRU), I have a memory leak on GPU.<br>\nMore precisely, here my code:</p>\n<pre><code>        W_embedding_output = tf.Variable(tf.random_uniform([decoder_output_dim, self.vocab_size], -0.01, 0.01), name=\"embedding_output\")\n        W_t = tf.transpose(W_embedding_output, [1, 0])\n        output_y_embedded = tf.nn.embedding_lookup(W_t, output_y)\n\n        # base cell to use for the decoder (same of inference, also for attention technique)\n        base_cell = DropoutWrapper(GRUCell(decoder_output_dim), self.dropout, 1.0, self.dropout)\n        attention_technique = BahdanauAttention(decoder_output_dim, encoded)\n        # helper to fit the previous state into decoder\n        helper = TrainingHelper(output_y_embedded, output_batch_length)\n        # cell to use, with attention method\n        cell = DynamicAttentionWrapper(\n            base_cell,\n            attention_technique,\n            self.encoder_dim,\n            output_attention=False\n        )\n        # initial state of the decoder, should be use the last encoder state as initial point?\n        zero_state = cell.zero_state(self.batch_size, tf.float32)\n\n        # zero_state = zero_state.clone(cell_state=encoder_state)\n\n        # decode\n        (outputs, index), final_state = dynamic_decode(\n            BasicDecoder(\n                cell,\n                helper,\n                zero_state)\n        )\n</code></pre>\n<p>So, If I remove use the line <strong>zero_state = zero_state.clone(cell_state=encoder_state)</strong> during the session.run the program continuously allocate memory on GPU and finally it crashes due to device memory become full.<br>\nHere the error.</p>\n<pre><code>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9024,1024]\n\t [[Node: gradients/tower2/Decoder/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, _class=[\"loc:@tower2/Decoder/MatMul\"], transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:2\"](gradients/tower2/Decoder/output_grad/Reshape, tower2/Decoder/embedding_output/read)]]\n\t [[Node: gradients/Sub_2/_942 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_9973_gradients/Sub_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/tower2/Decoder/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_828)]]\n</code></pre>\n<p>Am I using these classes in a wrong way? Could it be a bug?</p>", "body_text": "@ebrevdo I tried to use your previous code as explained. But If I put the encoder_state of the previous level (2 bidirectional encoders with GRU), I have a memory leak on GPU.\nMore precisely, here my code:\n        W_embedding_output = tf.Variable(tf.random_uniform([decoder_output_dim, self.vocab_size], -0.01, 0.01), name=\"embedding_output\")\n        W_t = tf.transpose(W_embedding_output, [1, 0])\n        output_y_embedded = tf.nn.embedding_lookup(W_t, output_y)\n\n        # base cell to use for the decoder (same of inference, also for attention technique)\n        base_cell = DropoutWrapper(GRUCell(decoder_output_dim), self.dropout, 1.0, self.dropout)\n        attention_technique = BahdanauAttention(decoder_output_dim, encoded)\n        # helper to fit the previous state into decoder\n        helper = TrainingHelper(output_y_embedded, output_batch_length)\n        # cell to use, with attention method\n        cell = DynamicAttentionWrapper(\n            base_cell,\n            attention_technique,\n            self.encoder_dim,\n            output_attention=False\n        )\n        # initial state of the decoder, should be use the last encoder state as initial point?\n        zero_state = cell.zero_state(self.batch_size, tf.float32)\n\n        # zero_state = zero_state.clone(cell_state=encoder_state)\n\n        # decode\n        (outputs, index), final_state = dynamic_decode(\n            BasicDecoder(\n                cell,\n                helper,\n                zero_state)\n        )\n\nSo, If I remove use the line zero_state = zero_state.clone(cell_state=encoder_state) during the session.run the program continuously allocate memory on GPU and finally it crashes due to device memory become full.\nHere the error.\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9024,1024]\n\t [[Node: gradients/tower2/Decoder/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, _class=[\"loc:@tower2/Decoder/MatMul\"], transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:2\"](gradients/tower2/Decoder/output_grad/Reshape, tower2/Decoder/embedding_output/read)]]\n\t [[Node: gradients/Sub_2/_942 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_9973_gradients/Sub_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/tower2/Decoder/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_828)]]\n\nAm I using these classes in a wrong way? Could it be a bug?", "body": "@ebrevdo I tried to use your previous code as explained. But If I put the encoder_state of the previous level (2 bidirectional encoders with GRU), I have a memory leak on GPU.\r\nMore precisely, here my code:\r\n```\r\n        W_embedding_output = tf.Variable(tf.random_uniform([decoder_output_dim, self.vocab_size], -0.01, 0.01), name=\"embedding_output\")\r\n        W_t = tf.transpose(W_embedding_output, [1, 0])\r\n        output_y_embedded = tf.nn.embedding_lookup(W_t, output_y)\r\n\r\n        # base cell to use for the decoder (same of inference, also for attention technique)\r\n        base_cell = DropoutWrapper(GRUCell(decoder_output_dim), self.dropout, 1.0, self.dropout)\r\n        attention_technique = BahdanauAttention(decoder_output_dim, encoded)\r\n        # helper to fit the previous state into decoder\r\n        helper = TrainingHelper(output_y_embedded, output_batch_length)\r\n        # cell to use, with attention method\r\n        cell = DynamicAttentionWrapper(\r\n            base_cell,\r\n            attention_technique,\r\n            self.encoder_dim,\r\n            output_attention=False\r\n        )\r\n        # initial state of the decoder, should be use the last encoder state as initial point?\r\n        zero_state = cell.zero_state(self.batch_size, tf.float32)\r\n\r\n        # zero_state = zero_state.clone(cell_state=encoder_state)\r\n\r\n        # decode\r\n        (outputs, index), final_state = dynamic_decode(\r\n            BasicDecoder(\r\n                cell,\r\n                helper,\r\n                zero_state)\r\n        )\r\n```\r\nSo, If I remove use the line **zero_state = zero_state.clone(cell_state=encoder_state)** during the session.run the program continuously allocate memory on GPU and finally it crashes due to device memory become full.\r\nHere the error.\r\n```\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9024,1024]\r\n\t [[Node: gradients/tower2/Decoder/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, _class=[\"loc:@tower2/Decoder/MatMul\"], transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:2\"](gradients/tower2/Decoder/output_grad/Reshape, tower2/Decoder/embedding_output/read)]]\r\n\t [[Node: gradients/Sub_2/_942 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device_incarnation=1, tensor_name=\"edge_9973_gradients/Sub_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/tower2/Decoder/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_828)]]\r\n```\r\nAm I using these classes in a wrong way? Could it be a bug?"}