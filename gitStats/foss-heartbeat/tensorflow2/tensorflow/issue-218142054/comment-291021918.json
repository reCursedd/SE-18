{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291021918", "html_url": "https://github.com/tensorflow/tensorflow/issues/8833#issuecomment-291021918", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8833", "id": 291021918, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTAyMTkxOA==", "user": {"login": "andrecianflone", "id": 19253511, "node_id": "MDQ6VXNlcjE5MjUzNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/19253511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrecianflone", "html_url": "https://github.com/andrecianflone", "followers_url": "https://api.github.com/users/andrecianflone/followers", "following_url": "https://api.github.com/users/andrecianflone/following{/other_user}", "gists_url": "https://api.github.com/users/andrecianflone/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrecianflone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrecianflone/subscriptions", "organizations_url": "https://api.github.com/users/andrecianflone/orgs", "repos_url": "https://api.github.com/users/andrecianflone/repos", "events_url": "https://api.github.com/users/andrecianflone/events{/privacy}", "received_events_url": "https://api.github.com/users/andrecianflone/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-02T23:10:37Z", "updated_at": "2017-04-02T23:10:37Z", "author_association": "NONE", "body_html": "<p>Ok, nope. I tried to set the initial cell state and attention, based on the other attention's zero_state method, but no go.</p>\n<p>Here's what I tried</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Attention Mechanisms. Bahdanau is additive style attention</span>\n    attn_mech <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BahdanauAttention(\n        <span class=\"pl-v\">num_units</span> <span class=\"pl-k\">=</span> mem_units, <span class=\"pl-c\"><span class=\"pl-c\">#</span> depth of query mechanism</span>\n        <span class=\"pl-v\">memory</span> <span class=\"pl-k\">=</span> attention_states, <span class=\"pl-c\"><span class=\"pl-c\">#</span> hidden states to attend (output of RNN)</span>\n        <span class=\"pl-v\">memory_sequence_length</span><span class=\"pl-k\">=</span>seq_len_enc, <span class=\"pl-c\"><span class=\"pl-c\">#</span> masks false memories</span>\n        <span class=\"pl-v\">normalize</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-c\"><span class=\"pl-c\">#</span> normalize energy term</span>\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>BahdanauAttention<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Attention Wrapper: adds the attention mechanism to the cell</span>\n    attn_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n        <span class=\"pl-v\">cell</span> <span class=\"pl-k\">=</span> cell,<span class=\"pl-c\"><span class=\"pl-c\">#</span> Instance of RNNCell</span>\n        <span class=\"pl-v\">attention_mechanism</span> <span class=\"pl-k\">=</span> attn_mech, <span class=\"pl-c\"><span class=\"pl-c\">#</span> Instance of AttentionMechanism</span>\n        <span class=\"pl-v\">attention_size</span> <span class=\"pl-k\">=</span> attn_units, <span class=\"pl-c\"><span class=\"pl-c\">#</span> Int, depth of attention (output) tensor</span>\n        <span class=\"pl-v\">attention_history</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-c\"><span class=\"pl-c\">#</span> whether to store history in final output</span>\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>attention_wrapper<span class=\"pl-pds\">\"</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> TrainingHelper does no sampling, only uses inputs</span>\n    helper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n        <span class=\"pl-v\">inputs</span> <span class=\"pl-k\">=</span> x, <span class=\"pl-c\"><span class=\"pl-c\">#</span> decoder inputs</span>\n        <span class=\"pl-v\">sequence_length</span> <span class=\"pl-k\">=</span> seq_len_dec, <span class=\"pl-c\"><span class=\"pl-c\">#</span> decoder input length</span>\n        <span class=\"pl-v\">name</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>decoder_training_helper<span class=\"pl-pds\">\"</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decoder setup</span>\n    batch_size <span class=\"pl-k\">=</span> tf.shape(x)[<span class=\"pl-c1\">0</span>]\n    attn_zero <span class=\"pl-k\">=</span> attn_cell.zero_state(<span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    init_state <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapperState(\\\n                <span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>encoder_state,\n                <span class=\"pl-v\">attention</span><span class=\"pl-k\">=</span>attn_zero,\n                <span class=\"pl-v\">time</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n                <span class=\"pl-v\">attention_history</span><span class=\"pl-k\">=</span>())\n    decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n              <span class=\"pl-v\">cell</span> <span class=\"pl-k\">=</span> attn_cell,\n              <span class=\"pl-v\">helper</span> <span class=\"pl-k\">=</span> helper, <span class=\"pl-c\"><span class=\"pl-c\">#</span> A Helper instance</span>\n              <span class=\"pl-v\">initial_state</span> <span class=\"pl-k\">=</span> init_state, <span class=\"pl-c\"><span class=\"pl-c\">#</span> initial state of decoder</span>\n              <span class=\"pl-v\">output_layer</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> instance of tf.layers.Layer, like Dense</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Perform dynamic decoding with decoder object</span>\n    outputs, final_state <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder)</pre></div>\n<p>But got an error on the <code>dynamic_decode</code> (below). Maybe you have instructions on how to properly set this up?</p>\n<div class=\"highlight highlight-source-shell\"><pre>  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/projects/seq2seq_drr/enc_dec.py<span class=\"pl-pds\">\"</span></span>, line 232, <span class=\"pl-k\">in</span> decoder_train_attn\n    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py<span class=\"pl-pds\">\"</span></span>, line 278, <span class=\"pl-k\">in</span> dynamic_decode\n    swap_memory=swap_memory)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py<span class=\"pl-pds\">\"</span></span>, line 2623, <span class=\"pl-k\">in</span> while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py<span class=\"pl-pds\">\"</span></span>, line 2456, <span class=\"pl-k\">in</span> BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py<span class=\"pl-pds\">\"</span></span>, line 2406, <span class=\"pl-k\">in</span> _BuildLoop\n    body_result = body(<span class=\"pl-k\">*</span>packed_vars_for_body)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py<span class=\"pl-pds\">\"</span></span>, line 231, <span class=\"pl-k\">in</span> body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py<span class=\"pl-pds\">\"</span></span>, line 140, <span class=\"pl-k\">in</span> step\n    cell_outputs, cell_state = self._cell(inputs, state)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py<span class=\"pl-pds\">\"</span></span>, line 532, <span class=\"pl-k\">in</span> __call__\n    cell_inputs = self._cell_input_fn(inputs, state.attention)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py<span class=\"pl-pds\">\"</span></span>, line 443, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>lambda<span class=\"pl-k\">&gt;</span>\n    lambda inputs, attention: array_ops.concat([inputs, attention], -1))\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py<span class=\"pl-pds\">\"</span></span>, line 1036, <span class=\"pl-k\">in</span> concat\n    name=name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py<span class=\"pl-pds\">\"</span></span>, line 519, <span class=\"pl-k\">in</span> _concat_v2\n    name=name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py<span class=\"pl-pds\">\"</span></span>, line 464, <span class=\"pl-k\">in</span> apply_op\n    raise TypeError(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>%s that don't all match.<span class=\"pl-pds\">\"</span></span> % prefix)\nTypeError: Tensors <span class=\"pl-k\">in</span> list passed to <span class=\"pl-s\"><span class=\"pl-pds\">'</span>values<span class=\"pl-pds\">'</span></span> of <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ConcatV2<span class=\"pl-pds\">'</span></span> Op have types [float32, <span class=\"pl-k\">&lt;</span>NOT CONVERTIBLE TO TENSOR<span class=\"pl-k\">&gt;</span>] that don<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t all match.</span></pre></div>", "body_text": "Ok, nope. I tried to set the initial cell state and attention, based on the other attention's zero_state method, but no go.\nHere's what I tried\n    # Attention Mechanisms. Bahdanau is additive style attention\n    attn_mech = tf.contrib.seq2seq.BahdanauAttention(\n        num_units = mem_units, # depth of query mechanism\n        memory = attention_states, # hidden states to attend (output of RNN)\n        memory_sequence_length=seq_len_enc, # masks false memories\n        normalize=False, # normalize energy term\n        name='BahdanauAttention')\n\n    # Attention Wrapper: adds the attention mechanism to the cell\n    attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n        cell = cell,# Instance of RNNCell\n        attention_mechanism = attn_mech, # Instance of AttentionMechanism\n        attention_size = attn_units, # Int, depth of attention (output) tensor\n        attention_history=False, # whether to store history in final output\n        name=\"attention_wrapper\")\n\n    # TrainingHelper does no sampling, only uses inputs\n    helper = tf.contrib.seq2seq.TrainingHelper(\n        inputs = x, # decoder inputs\n        sequence_length = seq_len_dec, # decoder input length\n        name = \"decoder_training_helper\")\n\n    # Decoder setup\n    batch_size = tf.shape(x)[0]\n    attn_zero = attn_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n    init_state = tf.contrib.seq2seq.AttentionWrapperState(\\\n                cell_state=encoder_state,\n                attention=attn_zero,\n                time=0,\n                attention_history=())\n    decoder = tf.contrib.seq2seq.BasicDecoder(\n              cell = attn_cell,\n              helper = helper, # A Helper instance\n              initial_state = init_state, # initial state of decoder\n              output_layer = None) # instance of tf.layers.Layer, like Dense\n\n    # Perform dynamic decoding with decoder object\n    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\nBut got an error on the dynamic_decode (below). Maybe you have instructions on how to properly set this up?\n  File \"/home/andre/projects/seq2seq_drr/enc_dec.py\", line 232, in decoder_train_attn\n    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 278, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 231, in body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\", line 140, in step\n    cell_outputs, cell_state = self._cell(inputs, state)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 532, in __call__\n    cell_inputs = self._cell_input_fn(inputs, state.attention)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 443, in <lambda>\n    lambda inputs, attention: array_ops.concat([inputs, attention], -1))\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1036, in concat\n    name=name)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\n    name=name)\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 464, in apply_op\n    raise TypeError(\"%s that don't all match.\" % prefix)\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, <NOT CONVERTIBLE TO TENSOR>] that don't all match.", "body": "Ok, nope. I tried to set the initial cell state and attention, based on the other attention's zero_state method, but no go.\r\n\r\nHere's what I tried\r\n```python    \r\n    # Attention Mechanisms. Bahdanau is additive style attention\r\n    attn_mech = tf.contrib.seq2seq.BahdanauAttention(\r\n        num_units = mem_units, # depth of query mechanism\r\n        memory = attention_states, # hidden states to attend (output of RNN)\r\n        memory_sequence_length=seq_len_enc, # masks false memories\r\n        normalize=False, # normalize energy term\r\n        name='BahdanauAttention')\r\n\r\n    # Attention Wrapper: adds the attention mechanism to the cell\r\n    attn_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n        cell = cell,# Instance of RNNCell\r\n        attention_mechanism = attn_mech, # Instance of AttentionMechanism\r\n        attention_size = attn_units, # Int, depth of attention (output) tensor\r\n        attention_history=False, # whether to store history in final output\r\n        name=\"attention_wrapper\")\r\n\r\n    # TrainingHelper does no sampling, only uses inputs\r\n    helper = tf.contrib.seq2seq.TrainingHelper(\r\n        inputs = x, # decoder inputs\r\n        sequence_length = seq_len_dec, # decoder input length\r\n        name = \"decoder_training_helper\")\r\n\r\n    # Decoder setup\r\n    batch_size = tf.shape(x)[0]\r\n    attn_zero = attn_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\r\n    init_state = tf.contrib.seq2seq.AttentionWrapperState(\\\r\n                cell_state=encoder_state,\r\n                attention=attn_zero,\r\n                time=0,\r\n                attention_history=())\r\n    decoder = tf.contrib.seq2seq.BasicDecoder(\r\n              cell = attn_cell,\r\n              helper = helper, # A Helper instance\r\n              initial_state = init_state, # initial state of decoder\r\n              output_layer = None) # instance of tf.layers.Layer, like Dense\r\n\r\n    # Perform dynamic decoding with decoder object\r\n    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\r\n```\r\n\r\nBut got an error on the `dynamic_decode` (below). Maybe you have instructions on how to properly set this up?\r\n\r\n```shell\r\n  File \"/home/andre/projects/seq2seq_drr/enc_dec.py\", line 232, in decoder_train_attn\r\n    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 278, in dynamic_decode\r\n    swap_memory=swap_memory)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 231, in body\r\n    decoder_finished) = decoder.step(time, inputs, state)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\", line 140, in step\r\n    cell_outputs, cell_state = self._cell(inputs, state)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 532, in __call__\r\n    cell_inputs = self._cell_input_fn(inputs, state.attention)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 443, in <lambda>\r\n    lambda inputs, attention: array_ops.concat([inputs, attention], -1))\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1036, in concat\r\n    name=name)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\r\n    name=name)\r\n  File \"/home/andre/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 464, in apply_op\r\n    raise TypeError(\"%s that don't all match.\" % prefix)\r\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, <NOT CONVERTIBLE TO TENSOR>] that don't all match.\r\n```"}