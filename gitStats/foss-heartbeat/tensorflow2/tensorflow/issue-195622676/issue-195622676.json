{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6316", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6316/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6316/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6316/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6316", "id": 195622676, "node_id": "MDU6SXNzdWUxOTU2MjI2NzY=", "number": 6316, "title": "training on one GPU, but the other one is also occupied", "user": {"login": "karlTUM", "id": 15608199, "node_id": "MDQ6VXNlcjE1NjA4MTk5", "avatar_url": "https://avatars2.githubusercontent.com/u/15608199?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karlTUM", "html_url": "https://github.com/karlTUM", "followers_url": "https://api.github.com/users/karlTUM/followers", "following_url": "https://api.github.com/users/karlTUM/following{/other_user}", "gists_url": "https://api.github.com/users/karlTUM/gists{/gist_id}", "starred_url": "https://api.github.com/users/karlTUM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karlTUM/subscriptions", "organizations_url": "https://api.github.com/users/karlTUM/orgs", "repos_url": "https://api.github.com/users/karlTUM/repos", "events_url": "https://api.github.com/users/karlTUM/events{/privacy}", "received_events_url": "https://api.github.com/users/karlTUM/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-12-14T19:27:13Z", "updated_at": "2016-12-15T18:15:04Z", "closed_at": "2016-12-15T18:15:04Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI have two GPUs, and I just would like to use one GPU to train a network by tensorflow. When I train it, the code use all the memories of two GPUs, but only one GPU is working:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/15608199/21197459/cfbcc86a-c23b-11e6-88d5-e04f7537e676.png\"><img src=\"https://cloud.githubusercontent.com/assets/15608199/21197459/cfbcc86a-c23b-11e6-88d5-e04f7537e676.png\" alt=\"screenshot from 2016-12-14 20-12-57\" style=\"max-width:100%;\"></a></p>\n<p>How to solve this problem? I would like just one to work, but not occupy the other.</p>", "body_text": "Hi,\nI have two GPUs, and I just would like to use one GPU to train a network by tensorflow. When I train it, the code use all the memories of two GPUs, but only one GPU is working:\n\nHow to solve this problem? I would like just one to work, but not occupy the other.", "body": "Hi,\r\nI have two GPUs, and I just would like to use one GPU to train a network by tensorflow. When I train it, the code use all the memories of two GPUs, but only one GPU is working:\r\n![screenshot from 2016-12-14 20-12-57](https://cloud.githubusercontent.com/assets/15608199/21197459/cfbcc86a-c23b-11e6-88d5-e04f7537e676.png)\r\n\r\n\r\nHow to solve this problem? I would like just one to work, but not occupy the other.\r\n\r\n"}