{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/194396066", "html_url": "https://github.com/tensorflow/tensorflow/issues/375#issuecomment-194396066", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/375", "id": 194396066, "node_id": "MDEyOklzc3VlQ29tbWVudDE5NDM5NjA2Ng==", "user": {"login": "psycharo", "id": 78526, "node_id": "MDQ6VXNlcjc4NTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/78526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/psycharo", "html_url": "https://github.com/psycharo", "followers_url": "https://api.github.com/users/psycharo/followers", "following_url": "https://api.github.com/users/psycharo/following{/other_user}", "gists_url": "https://api.github.com/users/psycharo/gists{/gist_id}", "starred_url": "https://api.github.com/users/psycharo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/psycharo/subscriptions", "organizations_url": "https://api.github.com/users/psycharo/orgs", "repos_url": "https://api.github.com/users/psycharo/repos", "events_url": "https://api.github.com/users/psycharo/events{/privacy}", "received_events_url": "https://api.github.com/users/psycharo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-09T16:57:39Z", "updated_at": "2016-03-09T16:57:39Z", "author_association": "NONE", "body_html": "<p>The instructions work fine for CPU-only ops, but seem to be insufficient for building an op with a GPU kernel. A slightly modified <code>BUILD</code> works fine though (for GPU-only kernels):</p>\n<div class=\"highlight highlight-source-python\"><pre>cc_binary(\n    <span class=\"pl-v\">name</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax4d_op.so<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-v\">srcs</span> <span class=\"pl-k\">=</span> [\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax4d_op.cc<span class=\"pl-pds\">\"</span></span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax4d_op.h<span class=\"pl-pds\">\"</span></span>\n    ],\n    <span class=\"pl-v\">copts</span> <span class=\"pl-k\">=</span> [\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-x<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda<span class=\"pl-pds\">\"</span></span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-DGOOGLE_CUDA=1<span class=\"pl-pds\">\"</span></span>\n    ],\n    <span class=\"pl-v\">linkopts</span> <span class=\"pl-k\">=</span> [\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-Wl,-Bsymbolic<span class=\"pl-pds\">\"</span></span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-lm<span class=\"pl-pds\">\"</span></span>,\n    ],\n    <span class=\"pl-v\">linkshared</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>,\n    <span class=\"pl-v\">linkstatic</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>,\n    <span class=\"pl-v\">deps</span> <span class=\"pl-k\">=</span> [\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>//tensorflow/core:framework<span class=\"pl-pds\">\"</span></span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>//tensorflow/core:cuda<span class=\"pl-pds\">\"</span></span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>//third_party/eigen3<span class=\"pl-pds\">\"</span></span>\n    ],\n)</pre></div>\n<p>I think it would be great to have a bit more details in the docs, and maybe even have a bazel rule for building custom ops, similar to <code>tf_kernel_library()</code>.</p>", "body_text": "The instructions work fine for CPU-only ops, but seem to be insufficient for building an op with a GPU kernel. A slightly modified BUILD works fine though (for GPU-only kernels):\ncc_binary(\n    name = \"softmax4d_op.so\",\n    srcs = [\n        \"softmax4d_op.cc\",\n        \"softmax4d_op.h\"\n    ],\n    copts = [\n        \"-x\", \"cuda\",\n        \"-DGOOGLE_CUDA=1\"\n    ],\n    linkopts = [\n        \"-Wl,-Bsymbolic\",\n        \"-lm\",\n    ],\n    linkshared = 1,\n    linkstatic = 1,\n    deps = [\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:cuda\",\n        \"//third_party/eigen3\"\n    ],\n)\nI think it would be great to have a bit more details in the docs, and maybe even have a bazel rule for building custom ops, similar to tf_kernel_library().", "body": "The instructions work fine for CPU-only ops, but seem to be insufficient for building an op with a GPU kernel. A slightly modified `BUILD` works fine though (for GPU-only kernels):\n\n``` python\ncc_binary(\n    name = \"softmax4d_op.so\",\n    srcs = [\n        \"softmax4d_op.cc\",\n        \"softmax4d_op.h\"\n    ],\n    copts = [\n        \"-x\", \"cuda\",\n        \"-DGOOGLE_CUDA=1\"\n    ],\n    linkopts = [\n        \"-Wl,-Bsymbolic\",\n        \"-lm\",\n    ],\n    linkshared = 1,\n    linkstatic = 1,\n    deps = [\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:cuda\",\n        \"//third_party/eigen3\"\n    ],\n)\n```\n\nI think it would be great to have a bit more details in the docs, and maybe even have a bazel rule for building custom ops, similar to `tf_kernel_library()`.\n"}