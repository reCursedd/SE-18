{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402259371", "html_url": "https://github.com/tensorflow/tensorflow/issues/20529#issuecomment-402259371", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20529", "id": 402259371, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjI1OTM3MQ==", "user": {"login": "brge17", "id": 33430930, "node_id": "MDQ6VXNlcjMzNDMwOTMw", "avatar_url": "https://avatars3.githubusercontent.com/u/33430930?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brge17", "html_url": "https://github.com/brge17", "followers_url": "https://api.github.com/users/brge17/followers", "following_url": "https://api.github.com/users/brge17/following{/other_user}", "gists_url": "https://api.github.com/users/brge17/gists{/gist_id}", "starred_url": "https://api.github.com/users/brge17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brge17/subscriptions", "organizations_url": "https://api.github.com/users/brge17/orgs", "repos_url": "https://api.github.com/users/brge17/repos", "events_url": "https://api.github.com/users/brge17/events{/privacy}", "received_events_url": "https://api.github.com/users/brge17/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-03T18:55:45Z", "updated_at": "2018-07-16T15:49:00Z", "author_association": "NONE", "body_html": "<h3>Problem 2</h3>\n<p>Batchwise averaging with <code>fit_generator</code></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.keras.layers <span class=\"pl-k\">import</span> Input, Dense\n<span class=\"pl-k\">from</span> tensorflow.python.keras.models <span class=\"pl-k\">import</span> Model\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">BatchCounter</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">keras</span>.<span class=\"pl-e\">layers</span>.<span class=\"pl-e\">Layer</span>):\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch_counter<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n            <span class=\"pl-c1\">super</span>(BatchCounter, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name, <span class=\"pl-k\">**</span>kwargs)\n            <span class=\"pl-c1\">self</span>.stateful <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n            <span class=\"pl-c1\">self</span>.batches <span class=\"pl-k\">=</span> tf.keras.backend.variable(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>int32<span class=\"pl-pds\">\"</span></span>)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">reset_states</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            tf.keras.backend.set_value(<span class=\"pl-c1\">self</span>.batches, <span class=\"pl-c1\">0</span>)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">y_pred</span>):\n            updates <span class=\"pl-k\">=</span> [\n                tf.keras.backend.update_add(\n                    <span class=\"pl-c1\">self</span>.batches, \n                    tf.keras.backend.variable(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>int32<span class=\"pl-pds\">\"</span></span>))]\n            <span class=\"pl-c1\">self</span>.add_update(updates)\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.batches\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">DummyGenerator</span>(<span class=\"pl-c1\">object</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Dummy data generator. <span class=\"pl-pds\">\"\"\"</span></span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n            <span class=\"pl-k\">yield</span> np.ones((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1</span>)), np.zeros((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1</span>))\n\ntrain_gen <span class=\"pl-k\">=</span> DummyGenerator()\nval_gen <span class=\"pl-k\">=</span> DummyGenerator()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Dummy model</span>\ninputs <span class=\"pl-k\">=</span> Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,))\noutputs <span class=\"pl-k\">=</span> Dense(<span class=\"pl-c1\">1</span>)(inputs)\nmodel <span class=\"pl-k\">=</span> Model(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>inputs, <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>outputs)\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>mse<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>adam<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[BatchCounter()])\n\nmodel.fit_generator(\n    train_gen.run(), \n    <span class=\"pl-v\">steps_per_epoch</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, \n    <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>, \n    <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>val_gen.run(), \n    <span class=\"pl-v\">validation_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>)</pre></div>\n<pre><code>5/5 [==============================] - 0s 58ms/step - loss: 2.5346 - batch_counter: 2.2000 - val_loss: 2.5155 - val_batch_counter: 4.0000\nEpoch 2/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.5029 - batch_counter: 2.2000 - val_loss: 2.4839 - val_batch_counter: 5.0000\nEpoch 3/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.4713 - batch_counter: 2.6000 - val_loss: 2.4525 - val_batch_counter: 4.0000\nEpoch 4/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.4400 - batch_counter: 2.4000 - val_loss: 2.4214 - val_batch_counter: 5.0000\nEpoch 5/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.4090 - batch_counter: 2.2000 - val_loss: 2.3905 - val_batch_counter: 4.0000\nEpoch 6/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.3782 - batch_counter: 2.4000 - val_loss: 2.3598 - val_batch_counter: 4.0000\nEpoch 7/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.3476 - batch_counter: 2.8000 - val_loss: 2.3293 - val_batch_counter: 4.0000\nEpoch 8/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.3173 - batch_counter: 2.4000 - val_loss: 2.2993 - val_batch_counter: 4.0000\nEpoch 9/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.2873 - batch_counter: 2.8000 - val_loss: 2.2695 - val_batch_counter: 4.0000\nEpoch 10/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.2577 - batch_counter: 2.0000 - val_loss: 2.2400 - val_batch_counter: 4.0000\n</code></pre>\n<p>The training batch counter is a non-integer -&gt; batch averaging.</p>", "body_text": "Problem 2\nBatchwise averaging with fit_generator\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Input, Dense\nfrom tensorflow.python.keras.models import Model\n\nimport numpy as np\n\nclass BatchCounter(tf.keras.layers.Layer):\n\n        def __init__(self, name=\"batch_counter\", **kwargs):\n            super(BatchCounter, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.batches = tf.keras.backend.variable(value=0, dtype=\"int32\")\n\n        def reset_states(self):\n            tf.keras.backend.set_value(self.batches, 0)\n\n        def __call__(self, y_true, y_pred):\n            updates = [\n                tf.keras.backend.update_add(\n                    self.batches, \n                    tf.keras.backend.variable(value=1, dtype=\"int32\"))]\n            self.add_update(updates)\n            return self.batches\n\nclass DummyGenerator(object):\n    \"\"\" Dummy data generator. \"\"\"\n\n    def run(self):\n        while True:\n            yield np.ones((10, 1)), np.zeros((10, 1))\n\ntrain_gen = DummyGenerator()\nval_gen = DummyGenerator()\n\n# Dummy model\ninputs = Input(shape=(1,))\noutputs = Dense(1)(inputs)\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss=\"mse\", optimizer=\"adam\", metrics=[BatchCounter()])\n\nmodel.fit_generator(\n    train_gen.run(), \n    steps_per_epoch=5, \n    epochs=10, \n    validation_data=val_gen.run(), \n    validation_steps=5)\n5/5 [==============================] - 0s 58ms/step - loss: 2.5346 - batch_counter: 2.2000 - val_loss: 2.5155 - val_batch_counter: 4.0000\nEpoch 2/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.5029 - batch_counter: 2.2000 - val_loss: 2.4839 - val_batch_counter: 5.0000\nEpoch 3/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.4713 - batch_counter: 2.6000 - val_loss: 2.4525 - val_batch_counter: 4.0000\nEpoch 4/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.4400 - batch_counter: 2.4000 - val_loss: 2.4214 - val_batch_counter: 5.0000\nEpoch 5/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.4090 - batch_counter: 2.2000 - val_loss: 2.3905 - val_batch_counter: 4.0000\nEpoch 6/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.3782 - batch_counter: 2.4000 - val_loss: 2.3598 - val_batch_counter: 4.0000\nEpoch 7/10\n5/5 [==============================] - 0s 3ms/step - loss: 2.3476 - batch_counter: 2.8000 - val_loss: 2.3293 - val_batch_counter: 4.0000\nEpoch 8/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.3173 - batch_counter: 2.4000 - val_loss: 2.2993 - val_batch_counter: 4.0000\nEpoch 9/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.2873 - batch_counter: 2.8000 - val_loss: 2.2695 - val_batch_counter: 4.0000\nEpoch 10/10\n5/5 [==============================] - 0s 4ms/step - loss: 2.2577 - batch_counter: 2.0000 - val_loss: 2.2400 - val_batch_counter: 4.0000\n\nThe training batch counter is a non-integer -> batch averaging.", "body": "### Problem 2\r\n\r\nBatchwise averaging with ``fit_generator``\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.layers import Input, Dense\r\nfrom tensorflow.python.keras.models import Model\r\n\r\nimport numpy as np\r\n\r\nclass BatchCounter(tf.keras.layers.Layer):\r\n\r\n        def __init__(self, name=\"batch_counter\", **kwargs):\r\n            super(BatchCounter, self).__init__(name=name, **kwargs)\r\n            self.stateful = True\r\n            self.batches = tf.keras.backend.variable(value=0, dtype=\"int32\")\r\n\r\n        def reset_states(self):\r\n            tf.keras.backend.set_value(self.batches, 0)\r\n\r\n        def __call__(self, y_true, y_pred):\r\n            updates = [\r\n                tf.keras.backend.update_add(\r\n                    self.batches, \r\n                    tf.keras.backend.variable(value=1, dtype=\"int32\"))]\r\n            self.add_update(updates)\r\n            return self.batches\r\n\r\nclass DummyGenerator(object):\r\n    \"\"\" Dummy data generator. \"\"\"\r\n\r\n    def run(self):\r\n        while True:\r\n            yield np.ones((10, 1)), np.zeros((10, 1))\r\n\r\ntrain_gen = DummyGenerator()\r\nval_gen = DummyGenerator()\r\n\r\n# Dummy model\r\ninputs = Input(shape=(1,))\r\noutputs = Dense(1)(inputs)\r\nmodel = Model(inputs=inputs, outputs=outputs)\r\nmodel.compile(loss=\"mse\", optimizer=\"adam\", metrics=[BatchCounter()])\r\n\r\nmodel.fit_generator(\r\n    train_gen.run(), \r\n    steps_per_epoch=5, \r\n    epochs=10, \r\n    validation_data=val_gen.run(), \r\n    validation_steps=5)\r\n```\r\n\r\n```\r\n5/5 [==============================] - 0s 58ms/step - loss: 2.5346 - batch_counter: 2.2000 - val_loss: 2.5155 - val_batch_counter: 4.0000\r\nEpoch 2/10\r\n5/5 [==============================] - 0s 3ms/step - loss: 2.5029 - batch_counter: 2.2000 - val_loss: 2.4839 - val_batch_counter: 5.0000\r\nEpoch 3/10\r\n5/5 [==============================] - 0s 3ms/step - loss: 2.4713 - batch_counter: 2.6000 - val_loss: 2.4525 - val_batch_counter: 4.0000\r\nEpoch 4/10\r\n5/5 [==============================] - 0s 4ms/step - loss: 2.4400 - batch_counter: 2.4000 - val_loss: 2.4214 - val_batch_counter: 5.0000\r\nEpoch 5/10\r\n5/5 [==============================] - 0s 4ms/step - loss: 2.4090 - batch_counter: 2.2000 - val_loss: 2.3905 - val_batch_counter: 4.0000\r\nEpoch 6/10\r\n5/5 [==============================] - 0s 3ms/step - loss: 2.3782 - batch_counter: 2.4000 - val_loss: 2.3598 - val_batch_counter: 4.0000\r\nEpoch 7/10\r\n5/5 [==============================] - 0s 3ms/step - loss: 2.3476 - batch_counter: 2.8000 - val_loss: 2.3293 - val_batch_counter: 4.0000\r\nEpoch 8/10\r\n5/5 [==============================] - 0s 4ms/step - loss: 2.3173 - batch_counter: 2.4000 - val_loss: 2.2993 - val_batch_counter: 4.0000\r\nEpoch 9/10\r\n5/5 [==============================] - 0s 4ms/step - loss: 2.2873 - batch_counter: 2.8000 - val_loss: 2.2695 - val_batch_counter: 4.0000\r\nEpoch 10/10\r\n5/5 [==============================] - 0s 4ms/step - loss: 2.2577 - batch_counter: 2.0000 - val_loss: 2.2400 - val_batch_counter: 4.0000\r\n```\r\n\r\nThe training batch counter is a non-integer -> batch averaging."}