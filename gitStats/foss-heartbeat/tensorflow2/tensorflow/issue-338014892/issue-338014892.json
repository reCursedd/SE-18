{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20529", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20529/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20529/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20529/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20529", "id": 338014892, "node_id": "MDU6SXNzdWUzMzgwMTQ4OTI=", "number": 20529, "title": "[tf.keras] Stateful Metrics assorted errors.", "user": {"login": "brge17", "id": 33430930, "node_id": "MDQ6VXNlcjMzNDMwOTMw", "avatar_url": "https://avatars3.githubusercontent.com/u/33430930?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brge17", "html_url": "https://github.com/brge17", "followers_url": "https://api.github.com/users/brge17/followers", "following_url": "https://api.github.com/users/brge17/following{/other_user}", "gists_url": "https://api.github.com/users/brge17/gists{/gist_id}", "starred_url": "https://api.github.com/users/brge17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brge17/subscriptions", "organizations_url": "https://api.github.com/users/brge17/orgs", "repos_url": "https://api.github.com/users/brge17/repos", "events_url": "https://api.github.com/users/brge17/events{/privacy}", "received_events_url": "https://api.github.com/users/brge17/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-07-03T18:46:52Z", "updated_at": "2018-11-10T18:49:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I will break this issue down into several code snippets each displaying a different error. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a>. In total 3 issues. All of these issues are only relevant to <code>tf.keras</code> implementation. The <code>keras</code> implementation works as intended.</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary.</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Python version</strong>: 3.6.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<h3>Problem 1</h3>\n<p>Issues with multi-input/multi-output and batch averaging. This happens for both train and validation metrics.</p>\n<h3>Source code/logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">from</span> tensorflow.python.keras.datasets <span class=\"pl-k\">import</span> mnist\n<span class=\"pl-k\">from</span> tensorflow.python.keras.models <span class=\"pl-k\">import</span> Model\n<span class=\"pl-k\">from</span> tensorflow.python.keras.layers <span class=\"pl-k\">import</span> Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">BatchCounter</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">keras</span>.<span class=\"pl-e\">layers</span>.<span class=\"pl-e\">Layer</span>):\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>batch_counter<span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n            <span class=\"pl-c1\">super</span>(BatchCounter, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name, <span class=\"pl-k\">**</span>kwargs)\n            <span class=\"pl-c1\">self</span>.stateful <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n            <span class=\"pl-c1\">self</span>.batches <span class=\"pl-k\">=</span> tf.keras.backend.variable(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">reset_states</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            tf.keras.backend.set_value(<span class=\"pl-c1\">self</span>.batches, <span class=\"pl-c1\">0</span>)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">y_pred</span>):\n            updates <span class=\"pl-k\">=</span> [tf.keras.backend.update_add(<span class=\"pl-c1\">self</span>.batches, tf.keras.backend.variable(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>))]\n            <span class=\"pl-c1\">self</span>.add_update(updates)\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.batches\n\n\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nnum_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\nepochs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> input image dimensions</span>\nimg_rows, img_cols <span class=\"pl-k\">=</span> <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Data</span>\n(x_train, y_train), (x_test, y_test) <span class=\"pl-k\">=</span> mnist.load_data()\nx_train <span class=\"pl-k\">=</span> x_train.reshape(x_train.shape[<span class=\"pl-c1\">0</span>], img_rows, img_cols, <span class=\"pl-c1\">1</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>\nx_test <span class=\"pl-k\">=</span> x_test.reshape(x_test.shape[<span class=\"pl-c1\">0</span>], img_rows, img_cols, <span class=\"pl-c1\">1</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>\ny_train <span class=\"pl-k\">=</span> tf.keras.utils.to_categorical(y_train, num_classes)\ny_test <span class=\"pl-k\">=</span> tf.keras.utils.to_categorical(y_test, num_classes)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Convolutional Encoder</span>\ninput_img <span class=\"pl-k\">=</span> Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(img_rows, img_cols, <span class=\"pl-c1\">1</span>))\nconv_1 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">16</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(input_img)\npool_1 <span class=\"pl-k\">=</span> MaxPooling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(conv_1)\nconv_2 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">8</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(pool_1)\npool_2 <span class=\"pl-k\">=</span> MaxPooling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(conv_2)\nconv_3 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">8</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(pool_2)\nencoded<span class=\"pl-k\">=</span> MaxPooling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(conv_3)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Classification</span>\nflatten <span class=\"pl-k\">=</span> Flatten()(encoded)\nfc <span class=\"pl-k\">=</span> Dense(<span class=\"pl-c1\">128</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(flatten)\nsoftmax <span class=\"pl-k\">=</span> Dense(num_classes, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>)(fc)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Decoder</span>\nconv_4 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">8</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(encoded)\nup_1 <span class=\"pl-k\">=</span> UpSampling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))(conv_4)\nconv_5 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">8</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>)(up_1)\nup_2 <span class=\"pl-k\">=</span> UpSampling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))(conv_5)\nconv_6 <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">16</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(up_2)\nup_3 <span class=\"pl-k\">=</span> UpSampling2D((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))(conv_6)\ndecoded <span class=\"pl-k\">=</span> Conv2D(<span class=\"pl-c1\">1</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sigmoid<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>)(up_3)\n\nmodel <span class=\"pl-k\">=</span> Model(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>input_img, <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>[softmax, decoded])\n\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>categorical_crossentropy<span class=\"pl-pds\">'</span></span>,\n                    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>binary_crossentropy<span class=\"pl-pds\">'</span></span>},\n              <span class=\"pl-v\">loss_weights</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">1.0</span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0.5</span>},\n              <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adam<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>: BatchCounter()})\n\nhistory <span class=\"pl-k\">=</span> model.fit(x_train,\n          {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>: y_train, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>: x_train},\n          <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size,\n          <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span>epochs,\n          <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span> (x_test, {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>classification<span class=\"pl-pds\">'</span></span>: y_test, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>autoencoder<span class=\"pl-pds\">'</span></span>: x_test}),\n          <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)</pre></div>\n<pre><code>Epoch 1/1\n60000/60000 [==============================] - 41s 677us/step - loss: 0.5086 - classification_loss: 0.4051 - autoencoder_loss: 0.2069 - classification_acc: 0.8755 - autoencoder_batch_counter: 299.7983 - val_loss: 0.2001 - val_classification_loss: 0.1242 - val_autoencoder_loss: 0.1518 - val_classification_acc: 0.9596 - val_autoencoder_batch_counter: 50.1000\n</code></pre>\n<p><code>autoencoder_batch_counter</code> &amp; <code>val_autoencoder_batch_counter</code> should always be (600, 100) respectively.  These metrics are batch averaged. This does not happen in the Keras implementation.</p>", "body_text": "I will break this issue down into several code snippets each displaying a different error. @fchollet. In total 3 issues. All of these issues are only relevant to tf.keras implementation. The keras implementation works as intended.\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary.\nTensorFlow version (use command below): 1.9.0\nPython version: 3.6.5\nBazel version (if compiling from source): n/a\nGCC/Compiler version (if compiling from source): n/a\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: n/a\n\nProblem 1\nIssues with multi-input/multi-output and batch averaging. This happens for both train and validation metrics.\nSource code/logs\nimport tensorflow as tf\n\nfrom tensorflow.python.keras.datasets import mnist\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n\n\nclass BatchCounter(tf.keras.layers.Layer):\n\n        def __init__(self, name='batch_counter', **kwargs):\n            super(BatchCounter, self).__init__(name=name, **kwargs)\n            self.stateful = True\n            self.batches = tf.keras.backend.variable(value=0, dtype='int32')\n\n        def reset_states(self):\n            tf.keras.backend.set_value(self.batches, 0)\n\n        def __call__(self, y_true, y_pred):\n            updates = [tf.keras.backend.update_add(self.batches, tf.keras.backend.variable(value=1, dtype='int32'))]\n            self.add_update(updates)\n            return self.batches\n\n\nbatch_size = 100\nnum_classes = 10\nepochs = 1\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32') / 255\nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32') / 255\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n# Convolutional Encoder\ninput_img = Input(shape=(img_rows, img_cols, 1))\nconv_1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\npool_1 = MaxPooling2D((2, 2), padding='same')(conv_1)\nconv_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool_1)\npool_2 = MaxPooling2D((2, 2), padding='same')(conv_2)\nconv_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool_2)\nencoded= MaxPooling2D((2, 2), padding='same')(conv_3)\n\n# Classification\nflatten = Flatten()(encoded)\nfc = Dense(128, activation='relu')(flatten)\nsoftmax = Dense(num_classes, activation='softmax', name='classification')(fc)\n\n# Decoder\nconv_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nup_1 = UpSampling2D((2, 2))(conv_4)\nconv_5 = Conv2D(8, (3, 3), activation='relu', padding='same')(up_1)\nup_2 = UpSampling2D((2, 2))(conv_5)\nconv_6 = Conv2D(16, (3, 3), activation='relu')(up_2)\nup_3 = UpSampling2D((2, 2))(conv_6)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='autoencoder')(up_3)\n\nmodel = Model(inputs=input_img, outputs=[softmax, decoded])\n\nmodel.compile(loss={'classification': 'categorical_crossentropy',\n                    'autoencoder': 'binary_crossentropy'},\n              loss_weights={'classification': 1.0,\n                            'autoencoder': 0.5},\n              optimizer='adam',\n              metrics={'classification': 'accuracy', 'autoencoder': BatchCounter()})\n\nhistory = model.fit(x_train,\n          {'classification': y_train, 'autoencoder': x_train},\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data= (x_test, {'classification': y_test, 'autoencoder': x_test}),\n          verbose=1)\nEpoch 1/1\n60000/60000 [==============================] - 41s 677us/step - loss: 0.5086 - classification_loss: 0.4051 - autoencoder_loss: 0.2069 - classification_acc: 0.8755 - autoencoder_batch_counter: 299.7983 - val_loss: 0.2001 - val_classification_loss: 0.1242 - val_autoencoder_loss: 0.1518 - val_classification_acc: 0.9596 - val_autoencoder_batch_counter: 50.1000\n\nautoencoder_batch_counter & val_autoencoder_batch_counter should always be (600, 100) respectively.  These metrics are batch averaged. This does not happen in the Keras implementation.", "body": "I will break this issue down into several code snippets each displaying a different error. @fchollet. In total 3 issues. All of these issues are only relevant to ``tf.keras`` implementation. The ``keras`` implementation works as intended.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary.\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\n### Problem 1\r\nIssues with multi-input/multi-output and batch averaging. This happens for both train and validation metrics.\r\n\r\n\r\n### Source code/logs\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python.keras.datasets import mnist\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\r\n\r\n\r\nclass BatchCounter(tf.keras.layers.Layer):\r\n\r\n        def __init__(self, name='batch_counter', **kwargs):\r\n            super(BatchCounter, self).__init__(name=name, **kwargs)\r\n            self.stateful = True\r\n            self.batches = tf.keras.backend.variable(value=0, dtype='int32')\r\n\r\n        def reset_states(self):\r\n            tf.keras.backend.set_value(self.batches, 0)\r\n\r\n        def __call__(self, y_true, y_pred):\r\n            updates = [tf.keras.backend.update_add(self.batches, tf.keras.backend.variable(value=1, dtype='int32'))]\r\n            self.add_update(updates)\r\n            return self.batches\r\n\r\n\r\nbatch_size = 100\r\nnum_classes = 10\r\nepochs = 1\r\n\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n# Data\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32') / 255\r\nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32') / 255\r\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\r\n\r\n# Convolutional Encoder\r\ninput_img = Input(shape=(img_rows, img_cols, 1))\r\nconv_1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\r\npool_1 = MaxPooling2D((2, 2), padding='same')(conv_1)\r\nconv_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool_1)\r\npool_2 = MaxPooling2D((2, 2), padding='same')(conv_2)\r\nconv_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool_2)\r\nencoded= MaxPooling2D((2, 2), padding='same')(conv_3)\r\n\r\n# Classification\r\nflatten = Flatten()(encoded)\r\nfc = Dense(128, activation='relu')(flatten)\r\nsoftmax = Dense(num_classes, activation='softmax', name='classification')(fc)\r\n\r\n# Decoder\r\nconv_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\r\nup_1 = UpSampling2D((2, 2))(conv_4)\r\nconv_5 = Conv2D(8, (3, 3), activation='relu', padding='same')(up_1)\r\nup_2 = UpSampling2D((2, 2))(conv_5)\r\nconv_6 = Conv2D(16, (3, 3), activation='relu')(up_2)\r\nup_3 = UpSampling2D((2, 2))(conv_6)\r\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='autoencoder')(up_3)\r\n\r\nmodel = Model(inputs=input_img, outputs=[softmax, decoded])\r\n\r\nmodel.compile(loss={'classification': 'categorical_crossentropy',\r\n                    'autoencoder': 'binary_crossentropy'},\r\n              loss_weights={'classification': 1.0,\r\n                            'autoencoder': 0.5},\r\n              optimizer='adam',\r\n              metrics={'classification': 'accuracy', 'autoencoder': BatchCounter()})\r\n\r\nhistory = model.fit(x_train,\r\n          {'classification': y_train, 'autoencoder': x_train},\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          validation_data= (x_test, {'classification': y_test, 'autoencoder': x_test}),\r\n          verbose=1)\r\n```\r\n\r\n```\r\nEpoch 1/1\r\n60000/60000 [==============================] - 41s 677us/step - loss: 0.5086 - classification_loss: 0.4051 - autoencoder_loss: 0.2069 - classification_acc: 0.8755 - autoencoder_batch_counter: 299.7983 - val_loss: 0.2001 - val_classification_loss: 0.1242 - val_autoencoder_loss: 0.1518 - val_classification_acc: 0.9596 - val_autoencoder_batch_counter: 50.1000\r\n```\r\n\r\n``autoencoder_batch_counter`` & ``val_autoencoder_batch_counter`` should always be (600, 100) respectively.  These metrics are batch averaged. This does not happen in the Keras implementation."}