{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3471", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3471/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3471/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3471/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3471", "id": 167142322, "node_id": "MDU6SXNzdWUxNjcxNDIzMjI=", "number": 3471, "title": "C++ api runs much slower than Python API (compile flags)", "user": {"login": "lingz", "id": 3147213, "node_id": "MDQ6VXNlcjMxNDcyMTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3147213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lingz", "html_url": "https://github.com/lingz", "followers_url": "https://api.github.com/users/lingz/followers", "following_url": "https://api.github.com/users/lingz/following{/other_user}", "gists_url": "https://api.github.com/users/lingz/gists{/gist_id}", "starred_url": "https://api.github.com/users/lingz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lingz/subscriptions", "organizations_url": "https://api.github.com/users/lingz/orgs", "repos_url": "https://api.github.com/users/lingz/repos", "events_url": "https://api.github.com/users/lingz/events{/privacy}", "received_events_url": "https://api.github.com/users/lingz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-07-22T22:12:07Z", "updated_at": "2018-05-02T12:51:03Z", "closed_at": "2016-07-22T23:37:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My graph run in Python only takes 6 seconds for one batch, but when I run the identical batch on the same graph (graph_freeze) in the C++ Api, the time is 80 seconds. I'm guessing this 13x slowdown is probably from using the wrong C flags during compilation. This is all running on CPU only.</p>\n<p>I'm loading the graphs using the same way as in the label_images example.</p>\n<p>I took a look at: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"159085945\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2721\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2721/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2721\">#2721</a>, and added the -mavx C flag, which increased it by about double, but still 13x slower than the python.</p>\n<p>The graph is a mostly a large multi layered regular RNN but with some feedforward as well.</p>\n<p>Any ideas on how to get it to the same speed as python? Is there somewhere I can see what flags tensorflow installed from source is compiled with?</p>\n<h3>Environment info</h3>\n<p>Operating System: Linux ubuntu 64 bit 14.04</p>\n<p>Installed version of CUDA and cuDNN:  None (CPU Only)<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.<br>\nLinux 64 Bit CPU Python 3.5</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n0.9.0</li>\n</ol>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Create graph in python</li>\n<li>freeze_graph.py</li>\n<li>Load graph in C++</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>adding -mavx C flag</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>", "body_text": "My graph run in Python only takes 6 seconds for one batch, but when I run the identical batch on the same graph (graph_freeze) in the C++ Api, the time is 80 seconds. I'm guessing this 13x slowdown is probably from using the wrong C flags during compilation. This is all running on CPU only.\nI'm loading the graphs using the same way as in the label_images example.\nI took a look at: #2721, and added the -mavx C flag, which increased it by about double, but still 13x slower than the python.\nThe graph is a mostly a large multi layered regular RNN but with some feedforward as well.\nAny ideas on how to get it to the same speed as python? Is there somewhere I can see what flags tensorflow installed from source is compiled with?\nEnvironment info\nOperating System: Linux ubuntu 64 bit 14.04\nInstalled version of CUDA and cuDNN:  None (CPU Only)\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\nLinux 64 Bit CPU Python 3.5\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.9.0\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\nThe output of bazel version\n\nSteps to reproduce\n\nCreate graph in python\nfreeze_graph.py\nLoad graph in C++\n\nWhat have you tried?\n\nadding -mavx C flag\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).", "body": "My graph run in Python only takes 6 seconds for one batch, but when I run the identical batch on the same graph (graph_freeze) in the C++ Api, the time is 80 seconds. I'm guessing this 13x slowdown is probably from using the wrong C flags during compilation. This is all running on CPU only. \n\nI'm loading the graphs using the same way as in the label_images example. \n\nI took a look at: https://github.com/tensorflow/tensorflow/issues/2721, and added the -mavx C flag, which increased it by about double, but still 13x slower than the python.\n\nThe graph is a mostly a large multi layered regular RNN but with some feedforward as well. \n\nAny ideas on how to get it to the same speed as python? Is there somewhere I can see what flags tensorflow installed from source is compiled with?\n### Environment info\n\nOperating System: Linux ubuntu 64 bit 14.04\n\nInstalled version of CUDA and cuDNN:  None (CPU Only)\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   Linux 64 Bit CPU Python 3.5\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.9.0\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### Steps to reproduce\n1. Create graph in python\n2. freeze_graph.py\n3. Load graph in C++\n### What have you tried?\n1. adding -mavx C flag\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n"}