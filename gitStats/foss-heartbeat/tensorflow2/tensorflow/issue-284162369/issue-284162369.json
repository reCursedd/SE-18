{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15587", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15587/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15587/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15587/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15587", "id": 284162369, "node_id": "MDU6SXNzdWUyODQxNjIzNjk=", "number": 15587, "title": "lite model file size", "user": {"login": "xuelinchao", "id": 6327825, "node_id": "MDQ6VXNlcjYzMjc4MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6327825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xuelinchao", "html_url": "https://github.com/xuelinchao", "followers_url": "https://api.github.com/users/xuelinchao/followers", "following_url": "https://api.github.com/users/xuelinchao/following{/other_user}", "gists_url": "https://api.github.com/users/xuelinchao/gists{/gist_id}", "starred_url": "https://api.github.com/users/xuelinchao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xuelinchao/subscriptions", "organizations_url": "https://api.github.com/users/xuelinchao/orgs", "repos_url": "https://api.github.com/users/xuelinchao/repos", "events_url": "https://api.github.com/users/xuelinchao/events{/privacy}", "received_events_url": "https://api.github.com/users/xuelinchao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-22T13:22:38Z", "updated_at": "2017-12-22T22:30:39Z", "closed_at": "2017-12-22T22:30:39Z", "author_association": "NONE", "body_html": "<h2>how to reduce my model size(my own trained tensorflow model )<br>\ni want to use tensorflow lite converter get a smaller tflite file, but the tflite file has the same size with my trained model,</h2>\n<p>bazel-bin/tensorflow/contrib/lite/toco/toco <br>\n--allow_custom_ops <br>\n--input_file=/data/log/frozen_model.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE <br>\n--output_file=/data/log//mobilenet.tflite --inference_type=FLOAT <br>\n--input_data_types=FLOAT --input_arrays=input <br>\n--output_arrays=output --input_shapes=1,224,224,3</p>\n<hr>", "body_text": "how to reduce my model size(my own trained tensorflow model )\ni want to use tensorflow lite converter get a smaller tflite file, but the tflite file has the same size with my trained model,\nbazel-bin/tensorflow/contrib/lite/toco/toco \n--allow_custom_ops \n--input_file=/data/log/frozen_model.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \n--output_file=/data/log//mobilenet.tflite --inference_type=FLOAT \n--input_data_types=FLOAT --input_arrays=input \n--output_arrays=output --input_shapes=1,224,224,3", "body": "how to reduce my model size(my own trained tensorflow model )\r\ni want to use tensorflow lite converter get a smaller tflite file, but the tflite file has the same size with my trained model,\r\n-------------------------------------------------------------------------\r\n\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --allow_custom_ops \\\r\n  --input_file=/data/log/frozen_model.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n  --output_file=/data/log//mobilenet.tflite --inference_type=FLOAT \\\r\n  --input_data_types=FLOAT --input_arrays=input \\\r\n  --output_arrays=output --input_shapes=1,224,224,3\r\n\r\n--------------------------------------------------------------------------"}