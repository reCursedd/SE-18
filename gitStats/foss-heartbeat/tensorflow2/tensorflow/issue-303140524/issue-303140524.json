{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17510", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17510/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17510/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17510/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17510", "id": 303140524, "node_id": "MDU6SXNzdWUzMDMxNDA1MjQ=", "number": 17510, "title": "Feature request: size of memory vectors in LSTM", "user": {"login": "dkoguciuk", "id": 9368849, "node_id": "MDQ6VXNlcjkzNjg4NDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/9368849?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dkoguciuk", "html_url": "https://github.com/dkoguciuk", "followers_url": "https://api.github.com/users/dkoguciuk/followers", "following_url": "https://api.github.com/users/dkoguciuk/following{/other_user}", "gists_url": "https://api.github.com/users/dkoguciuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/dkoguciuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dkoguciuk/subscriptions", "organizations_url": "https://api.github.com/users/dkoguciuk/orgs", "repos_url": "https://api.github.com/users/dkoguciuk/repos", "events_url": "https://api.github.com/users/dkoguciuk/events{/privacy}", "received_events_url": "https://api.github.com/users/dkoguciuk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2018-03-07T15:22:28Z", "updated_at": "2018-07-09T11:03:01Z", "closed_at": "2018-07-09T11:03:01Z", "author_association": "NONE", "body_html": "<h2>Motivation</h2>\n<p>There are two different memory vectors used in LSTM cell: internal state vector (<em><strong>c</strong></em> symbol in tensorflow convention) and output vector (<em><strong>h</strong></em> in tensorflow convention). Let\u2019s consider the possible sizes of both vectors:</p>\n<ul>\n<li>\n<p><em><strong>c</strong></em> (internal state vector) \u2013 has to be the same size for both input and output of a single cell (equation 5 below)</p>\n</li>\n<li>\n<p><em><strong>h</strong></em> (output vector) \u2013 doesn\u2019t have to be the same (1-4), to be more specific: input size could be arbitrary, but the output size has to be the same as <em><strong>c</strong></em> (6)</p>\n</li>\n</ul>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9368849/37099738-671646fa-2221-11e8-9de6-30c46bc36988.png\"><img src=\"https://user-images.githubusercontent.com/9368849/37099738-671646fa-2221-11e8-9de6-30c46bc36988.png\" alt=\"lstm_eq\" style=\"max-width:100%;\"></a></p>\n<p>The equations are copied from <a href=\"https://arxiv.org/pdf/1506.00019.pdf\" rel=\"nofollow\">a great paper</a> of Lipton, Berkowitz and Elkan and again the notation is different: <em><strong>s</strong></em>=<em><strong>c</strong></em>).</p>\n<p>Why setting different input and output size of <em><strong>h</strong></em> vector is it useful? If \u2018because we can\u2019 doesn\u2019t satisfy you I can cite <a href=\"https://arxiv.org/pdf/1511.06391.pdf\" rel=\"nofollow\">OrderMatters paper</a> (their notation is a bit different <em><strong>h</strong></em>=<em><strong>q</strong></em>).</p>\n<h2>Current implementation</h2>\n<p>Currently, in different LSTM cells constructors, there is only one parameter responsible for setting the size of both <em><strong>c</strong></em> and <em><strong>h</strong></em> vectors and it\u2019s called <em><strong>num_units</strong></em>. IMO it\u2019s not the best name for this param, but that\u2019s not my point here \u2013 there is no way to set different input and output size of <em><strong>h</strong></em> vector.</p>\n<h2>Proposal</h2>\n<p>We could leave the <em><strong>num_units</strong></em> param for backward compatibility with an integer value and the current behavior. On the other hand, if a user pass a tuple of length 2, we could interpret the param as : (input_size of h, output_size of h). Those two numbers are sufficient for describing both <em><strong>c</strong></em> and <em><strong>h</strong></em> sizes.</p>\n<h2>Implementation</h2>\n<p>I have already implemented proposed modification for LSTMCell class and it works fine. I could implement the proposed feature for all LSTM-like cells and create PR, but first wanted to ask the community and tensorflowers if it useful form your perspective?</p>\n<h2>System information</h2>\n<ul>\n<li><strong>Have I written custom code</strong>: N/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: N/A</li>\n<li><strong>TensorFlow version (use command below)</strong>: N/A</li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>", "body_text": "Motivation\nThere are two different memory vectors used in LSTM cell: internal state vector (c symbol in tensorflow convention) and output vector (h in tensorflow convention). Let\u2019s consider the possible sizes of both vectors:\n\n\nc (internal state vector) \u2013 has to be the same size for both input and output of a single cell (equation 5 below)\n\n\nh (output vector) \u2013 doesn\u2019t have to be the same (1-4), to be more specific: input size could be arbitrary, but the output size has to be the same as c (6)\n\n\n\nThe equations are copied from a great paper of Lipton, Berkowitz and Elkan and again the notation is different: s=c).\nWhy setting different input and output size of h vector is it useful? If \u2018because we can\u2019 doesn\u2019t satisfy you I can cite OrderMatters paper (their notation is a bit different h=q).\nCurrent implementation\nCurrently, in different LSTM cells constructors, there is only one parameter responsible for setting the size of both c and h vectors and it\u2019s called num_units. IMO it\u2019s not the best name for this param, but that\u2019s not my point here \u2013 there is no way to set different input and output size of h vector.\nProposal\nWe could leave the num_units param for backward compatibility with an integer value and the current behavior. On the other hand, if a user pass a tuple of length 2, we could interpret the param as : (input_size of h, output_size of h). Those two numbers are sufficient for describing both c and h sizes.\nImplementation\nI have already implemented proposed modification for LSTMCell class and it works fine. I could implement the proposed feature for all LSTM-like cells and create PR, but first wanted to ask the community and tensorflowers if it useful form your perspective?\nSystem information\n\nHave I written custom code: N/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\nTensorFlow installed from (source or binary): N/A\nTensorFlow version (use command below): N/A\nPython version: N/A\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A", "body": "## Motivation\r\n\r\nThere are two different memory vectors used in LSTM cell: internal state vector (_**c**_ symbol in tensorflow convention) and output vector (_**h**_ in tensorflow convention). Let\u2019s consider the possible sizes of both vectors:\r\n\r\n- _**c**_ (internal state vector) \u2013 has to be the same size for both input and output of a single cell (equation 5 below)\r\n\r\n- _**h**_ (output vector) \u2013 doesn\u2019t have to be the same (1-4), to be more specific: input size could be arbitrary, but the output size has to be the same as _**c**_ (6)\r\n\r\n![lstm_eq](https://user-images.githubusercontent.com/9368849/37099738-671646fa-2221-11e8-9de6-30c46bc36988.png)\r\n\r\nThe equations are copied from [a great paper](https://arxiv.org/pdf/1506.00019.pdf) of Lipton, Berkowitz and Elkan and again the notation is different: _**s**_=_**c**_).\r\n\r\nWhy setting different input and output size of _**h**_ vector is it useful? If \u2018because we can\u2019 doesn\u2019t satisfy you I can cite [OrderMatters paper](https://arxiv.org/pdf/1511.06391.pdf) (their notation is a bit different _**h**_=_**q**_).\r\n\r\n## Current implementation\r\n\r\nCurrently, in different LSTM cells constructors, there is only one parameter responsible for setting the size of both _**c**_ and _**h**_ vectors and it\u2019s called _**num_units**_. IMO it\u2019s not the best name for this param, but that\u2019s not my point here \u2013 there is no way to set different input and output size of _**h**_ vector.\r\n\r\n## Proposal\r\n\r\nWe could leave the _**num_units**_ param for backward compatibility with an integer value and the current behavior. On the other hand, if a user pass a tuple of length 2, we could interpret the param as : (input_size of h, output_size of h). Those two numbers are sufficient for describing both _**c**_ and _**h**_ sizes.\r\n\r\n## Implementation\r\n\r\nI have already implemented proposed modification for LSTMCell class and it works fine. I could implement the proposed feature for all LSTM-like cells and create PR, but first wanted to ask the community and tensorflowers if it useful form your perspective?\r\n\r\n## System information\r\n- **Have I written custom code**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n"}