{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/74711665", "pull_request_review_id": null, "id": 74711665, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc0NzExNjY1", "diff_hunk": "@@ -411,6 +417,16 @@ def _SigmoidGrad(op, grad):\n     return gen_math_ops._sigmoid_grad(y, grad)\n \n \n+@ops.RegisterGradient(\"SigmoidGrad\")\n+def _SigmoidGradGrad(op, grad):\n+  y = op.outputs[0]\n+  with ops.control_dependencies([grad.op]):\n+    if y.dtype.is_complex:\n+      y = math_ops.conj(y)\n+    return (- math.ops.exp(x) * (math.ops.exp(x) - 1) *\n+            math_ops.pow(math.ops.exp(x) + 1, -3))", "path": "tensorflow/python/ops/math_grad.py", "position": null, "original_position": 58, "commit_id": "502f358b954a0f86d68e474fd23238b88c7e34f4", "original_commit_id": "253c86d7783dca1c844ff77afad5342c40691e66", "user": {"login": "chemelnucfin", "id": 3982092, "node_id": "MDQ6VXNlcjM5ODIwOTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3982092?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chemelnucfin", "html_url": "https://github.com/chemelnucfin", "followers_url": "https://api.github.com/users/chemelnucfin/followers", "following_url": "https://api.github.com/users/chemelnucfin/following{/other_user}", "gists_url": "https://api.github.com/users/chemelnucfin/gists{/gist_id}", "starred_url": "https://api.github.com/users/chemelnucfin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chemelnucfin/subscriptions", "organizations_url": "https://api.github.com/users/chemelnucfin/orgs", "repos_url": "https://api.github.com/users/chemelnucfin/repos", "events_url": "https://api.github.com/users/chemelnucfin/events{/privacy}", "received_events_url": "https://api.github.com/users/chemelnucfin/received_events", "type": "User", "site_admin": false}, "body": "@girving Yes, I missed the grad and the math.ops instead of math_ops.  Is\nthere a reason you associated the grad with s? or would you like grad \\* s *\n(1 - s) \\* (1 - 2 \\* x)?\n\nI will add the tests into math_grad_test.py\n\nOn Sun, Aug 14, 2016 at 4:58 PM, Geoffrey Irving notifications@github.com\nwrote:\n\n> In tensorflow/python/ops/math_grad.py\n> https://github.com/tensorflow/tensorflow/pull/3807#discussion_r74711318:\n> \n> > @@ -411,6 +417,16 @@ def _SigmoidGrad(op, grad):\n> >      return gen_math_ops._sigmoid_grad(y, grad)\n> > \n> > +@ops.RegisterGradient(\"SigmoidGrad\")\n> > +def _SigmoidGradGrad(op, grad):\n> > -  y = op.outputs[0]\n> > -  with ops.control_dependencies([grad.op]):\n> > -    if y.dtype.is_complex:\n> > -      y = math_ops.conj(y)\n> > -    return (- math.ops.exp(x) \\* (math.ops.exp(x) - 1) *\n> > -            math_ops.pow(math.ops.exp(x) + 1, -3))\n> \n> This explodes for large x and has the downside of being a constant\n> function of grad (unusual for a gradient, so maybe a test is in order).\n> Instead, do\n> \n> s = math_ops.sigmoid(x)\n> return (grad \\* s) \\* (1 - s) \\* (1 - 2 \\* x)\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3807/files/253c86d7783dca1c844ff77afad5342c40691e66#r74711318,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADzDDDQKqJ_DtWtjp5PJSc98VuY_JlfMks5qf6uugaJpZM4Jj8mC\n> .\n", "created_at": "2016-08-15T00:13:59Z", "updated_at": "2016-08-15T15:53:30Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3807#discussion_r74711665", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3807", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/74711665"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3807#discussion_r74711665"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3807"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> Yes, I missed the grad and the math.ops instead of math_ops.  Is<br>\nthere a reason you associated the grad with s? or would you like grad * s *<br>\n(1 - s) * (1 - 2 * x)?</p>\n<p>I will add the tests into math_grad_test.py</p>\n<p>On Sun, Aug 14, 2016 at 4:58 PM, Geoffrey Irving <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>In tensorflow/python/ops/math_grad.py<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171069923\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3807\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/3807/hovercard?comment_id=74711318&amp;comment_type=review_comment\" href=\"https://github.com/tensorflow/tensorflow/pull/3807#discussion_r74711318\">#3807 (comment)</a>:</p>\n<blockquote>\n<p>@@ -411,6 +417,16 @@ def _SigmoidGrad(op, grad):<br>\nreturn gen_math_ops._sigmoid_grad(y, grad)</p>\n<p><a href=\"mailto:+@ops.RegisterGradient\">+@ops.RegisterGradient</a>(\"SigmoidGrad\")<br>\n+def _SigmoidGradGrad(op, grad):</p>\n<ul>\n<li>y = op.outputs[0]</li>\n<li>with ops.control_dependencies([grad.op]):</li>\n<li>if y.dtype.is_complex:</li>\n<li>\n<pre><code> y = math_ops.conj(y)\n</code></pre>\n</li>\n<li>return (- math.ops.exp(x) * (math.ops.exp(x) - 1) *</li>\n<li>\n<pre><code>       math_ops.pow(math.ops.exp(x) + 1, -3))\n</code></pre>\n</li>\n</ul>\n</blockquote>\n<p>This explodes for large x and has the downside of being a constant<br>\nfunction of grad (unusual for a gradient, so maybe a test is in order).<br>\nInstead, do</p>\n<p>s = math_ops.sigmoid(x)<br>\nreturn (grad * s) * (1 - s) * (1 - 2 * x)</p>\n<p>\u2014<br>\nYou are receiving this because you authored the thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a href=\"https://github.com/tensorflow/tensorflow/pull/3807/files/253c86d7783dca1c844ff77afad5342c40691e66#r74711318\">https://github.com/tensorflow/tensorflow/pull/3807/files/253c86d7783dca1c844ff77afad5342c40691e66#r74711318</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/ADzDDDQKqJ_DtWtjp5PJSc98VuY_JlfMks5qf6uugaJpZM4Jj8mC\">https://github.com/notifications/unsubscribe-auth/ADzDDDQKqJ_DtWtjp5PJSc98VuY_JlfMks5qf6uugaJpZM4Jj8mC</a><br>\n.</p>\n</blockquote>", "body_text": "@girving Yes, I missed the grad and the math.ops instead of math_ops.  Is\nthere a reason you associated the grad with s? or would you like grad * s *\n(1 - s) * (1 - 2 * x)?\nI will add the tests into math_grad_test.py\nOn Sun, Aug 14, 2016 at 4:58 PM, Geoffrey Irving notifications@github.com\nwrote:\n\nIn tensorflow/python/ops/math_grad.py\n#3807 (comment):\n\n@@ -411,6 +417,16 @@ def _SigmoidGrad(op, grad):\nreturn gen_math_ops._sigmoid_grad(y, grad)\n+@ops.RegisterGradient(\"SigmoidGrad\")\n+def _SigmoidGradGrad(op, grad):\n\ny = op.outputs[0]\nwith ops.control_dependencies([grad.op]):\nif y.dtype.is_complex:\n\n y = math_ops.conj(y)\n\n\nreturn (- math.ops.exp(x) * (math.ops.exp(x) - 1) *\n\n       math_ops.pow(math.ops.exp(x) + 1, -3))\n\n\n\n\nThis explodes for large x and has the downside of being a constant\nfunction of grad (unusual for a gradient, so maybe a test is in order).\nInstead, do\ns = math_ops.sigmoid(x)\nreturn (grad * s) * (1 - s) * (1 - 2 * x)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/tensorflow/tensorflow/pull/3807/files/253c86d7783dca1c844ff77afad5342c40691e66#r74711318,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADzDDDQKqJ_DtWtjp5PJSc98VuY_JlfMks5qf6uugaJpZM4Jj8mC\n."}