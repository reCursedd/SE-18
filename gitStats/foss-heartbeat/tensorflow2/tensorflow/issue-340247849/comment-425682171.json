{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425682171", "html_url": "https://github.com/tensorflow/tensorflow/issues/20698#issuecomment-425682171", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20698", "id": 425682171, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTY4MjE3MQ==", "user": {"login": "ricoms", "id": 5393732, "node_id": "MDQ6VXNlcjUzOTM3MzI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5393732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ricoms", "html_url": "https://github.com/ricoms", "followers_url": "https://api.github.com/users/ricoms/followers", "following_url": "https://api.github.com/users/ricoms/following{/other_user}", "gists_url": "https://api.github.com/users/ricoms/gists{/gist_id}", "starred_url": "https://api.github.com/users/ricoms/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ricoms/subscriptions", "organizations_url": "https://api.github.com/users/ricoms/orgs", "repos_url": "https://api.github.com/users/ricoms/repos", "events_url": "https://api.github.com/users/ricoms/events{/privacy}", "received_events_url": "https://api.github.com/users/ricoms/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-29T23:32:44Z", "updated_at": "2018-09-29T23:37:19Z", "author_association": "NONE", "body_html": "<p>The final example at <a href=\"https://www.tensorflow.org/guide/datasets\" rel=\"nofollow\">here</a> is interesting:</p>\n<pre><code>def dataset_input_fn():\n  filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\n  dataset = tf.data.TFRecordDataset(filenames)\n\n  # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n  # protocol buffer, and perform any additional per-record preprocessing.\n  def parser(record):\n    keys_to_features = {\n        \"image_data\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n        \"date_time\": tf.FixedLenFeature((), tf.int64, default_value=\"\"),\n        \"label\": tf.FixedLenFeature((), tf.int64,\n                                    default_value=tf.zeros([], dtype=tf.int64)),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n\n    # Perform additional preprocessing on the parsed data.\n    image = tf.image.decode_jpeg(parsed[\"image_data\"])\n    image = tf.reshape(image, [299, 299, 1])\n    label = tf.cast(parsed[\"label\"], tf.int32)\n\n    return {\"image_data\": image, \"date_time\": parsed[\"date_time\"]}, label\n\n  # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n  # tensor for each example.\n  dataset = dataset.map(parser)\n  dataset = dataset.shuffle(buffer_size=10000)\n  dataset = dataset.batch(32)\n  dataset = dataset.repeat(num_epochs)\n\n  # Each element of `dataset` is tuple containing a dictionary of features\n  # (in which each value is a batch of values for that feature), and a batch of\n  # labels.\n  return dataset\n</code></pre>\n<p>now, how to define a model that accepts and trains correctly with that datase? Is the full example available somewhere?</p>", "body_text": "The final example at here is interesting:\ndef dataset_input_fn():\n  filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\n  dataset = tf.data.TFRecordDataset(filenames)\n\n  # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n  # protocol buffer, and perform any additional per-record preprocessing.\n  def parser(record):\n    keys_to_features = {\n        \"image_data\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n        \"date_time\": tf.FixedLenFeature((), tf.int64, default_value=\"\"),\n        \"label\": tf.FixedLenFeature((), tf.int64,\n                                    default_value=tf.zeros([], dtype=tf.int64)),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n\n    # Perform additional preprocessing on the parsed data.\n    image = tf.image.decode_jpeg(parsed[\"image_data\"])\n    image = tf.reshape(image, [299, 299, 1])\n    label = tf.cast(parsed[\"label\"], tf.int32)\n\n    return {\"image_data\": image, \"date_time\": parsed[\"date_time\"]}, label\n\n  # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n  # tensor for each example.\n  dataset = dataset.map(parser)\n  dataset = dataset.shuffle(buffer_size=10000)\n  dataset = dataset.batch(32)\n  dataset = dataset.repeat(num_epochs)\n\n  # Each element of `dataset` is tuple containing a dictionary of features\n  # (in which each value is a batch of values for that feature), and a batch of\n  # labels.\n  return dataset\n\nnow, how to define a model that accepts and trains correctly with that datase? Is the full example available somewhere?", "body": "The final example at [here](https://www.tensorflow.org/guide/datasets) is interesting:\r\n\r\n```\r\ndef dataset_input_fn():\r\n  filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\r\n  dataset = tf.data.TFRecordDataset(filenames)\r\n\r\n  # Use `tf.parse_single_example()` to extract data from a `tf.Example`\r\n  # protocol buffer, and perform any additional per-record preprocessing.\r\n  def parser(record):\r\n    keys_to_features = {\r\n        \"image_data\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n        \"date_time\": tf.FixedLenFeature((), tf.int64, default_value=\"\"),\r\n        \"label\": tf.FixedLenFeature((), tf.int64,\r\n                                    default_value=tf.zeros([], dtype=tf.int64)),\r\n    }\r\n    parsed = tf.parse_single_example(record, keys_to_features)\r\n\r\n    # Perform additional preprocessing on the parsed data.\r\n    image = tf.image.decode_jpeg(parsed[\"image_data\"])\r\n    image = tf.reshape(image, [299, 299, 1])\r\n    label = tf.cast(parsed[\"label\"], tf.int32)\r\n\r\n    return {\"image_data\": image, \"date_time\": parsed[\"date_time\"]}, label\r\n\r\n  # Use `Dataset.map()` to build a pair of a feature dictionary and a label\r\n  # tensor for each example.\r\n  dataset = dataset.map(parser)\r\n  dataset = dataset.shuffle(buffer_size=10000)\r\n  dataset = dataset.batch(32)\r\n  dataset = dataset.repeat(num_epochs)\r\n\r\n  # Each element of `dataset` is tuple containing a dictionary of features\r\n  # (in which each value is a batch of values for that feature), and a batch of\r\n  # labels.\r\n  return dataset\r\n```\r\n\r\nnow, how to define a model that accepts and trains correctly with that datase? Is the full example available somewhere?"}