{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245124311", "html_url": "https://github.com/tensorflow/tensorflow/issues/4116#issuecomment-245124311", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4116", "id": 245124311, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTEyNDMxMQ==", "user": {"login": "craigcitro", "id": 468559, "node_id": "MDQ6VXNlcjQ2ODU1OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/468559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/craigcitro", "html_url": "https://github.com/craigcitro", "followers_url": "https://api.github.com/users/craigcitro/followers", "following_url": "https://api.github.com/users/craigcitro/following{/other_user}", "gists_url": "https://api.github.com/users/craigcitro/gists{/gist_id}", "starred_url": "https://api.github.com/users/craigcitro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/craigcitro/subscriptions", "organizations_url": "https://api.github.com/users/craigcitro/orgs", "repos_url": "https://api.github.com/users/craigcitro/repos", "events_url": "https://api.github.com/users/craigcitro/events{/privacy}", "received_events_url": "https://api.github.com/users/craigcitro/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-06T23:09:38Z", "updated_at": "2016-09-06T23:09:38Z", "author_association": "MEMBER", "body_html": "<p>Ah, I think I probably left out a bit of detail.</p>\n<p>As you mentioned, what you want is to build the equivalent of the <code>tensorflow:gpu</code> build, but with custom flags (different compute capability support), and without depending on the existing <code>.whl</code> file on <code>storage.googleapis.com</code>.</p>\n<p>The way the <code>:gpu</code> image is built is by</p>\n<ol>\n<li>building the <code>tensorflow:devel-gpu</code> container,</li>\n<li>producing a new <code>.whl</code> file from that container,</li>\n<li>copying it to <code>storage.googleapis.com</code>, and</li>\n<li>building the <code>tensorflow:gpu</code> image with that newly-created file.</li>\n</ol>\n<p>What you want is a variant of this, where you do (1) and (2) with custom options, but then directly go to (4) without copying the file to <code>storage.googleapis.com</code> at all.</p>\n<p>I believe the linked build script does precisely that, since that's what happens in the process of doing our CI builds; the only question is getting the flags right. I was thinking you could just make use of that script, since then you don't end up owning your own set of custom build scripts.</p>\n<p>That said, you're totally welcome to write your own if that's easier for you.</p>", "body_text": "Ah, I think I probably left out a bit of detail.\nAs you mentioned, what you want is to build the equivalent of the tensorflow:gpu build, but with custom flags (different compute capability support), and without depending on the existing .whl file on storage.googleapis.com.\nThe way the :gpu image is built is by\n\nbuilding the tensorflow:devel-gpu container,\nproducing a new .whl file from that container,\ncopying it to storage.googleapis.com, and\nbuilding the tensorflow:gpu image with that newly-created file.\n\nWhat you want is a variant of this, where you do (1) and (2) with custom options, but then directly go to (4) without copying the file to storage.googleapis.com at all.\nI believe the linked build script does precisely that, since that's what happens in the process of doing our CI builds; the only question is getting the flags right. I was thinking you could just make use of that script, since then you don't end up owning your own set of custom build scripts.\nThat said, you're totally welcome to write your own if that's easier for you.", "body": "Ah, I think I probably left out a bit of detail.\n\nAs you mentioned, what you want is to build the equivalent of the `tensorflow:gpu` build, but with custom flags (different compute capability support), and without depending on the existing `.whl` file on `storage.googleapis.com`. \n\nThe way the `:gpu` image is built is by\n1. building the `tensorflow:devel-gpu` container, \n2. producing a new `.whl` file from that container, \n3. copying it to `storage.googleapis.com`, and \n4. building the `tensorflow:gpu` image with that newly-created file.\n\nWhat you want is a variant of this, where you do (1) and (2) with custom options, but then directly go to (4) without copying the file to `storage.googleapis.com` at all. \n\nI believe the linked build script does precisely that, since that's what happens in the process of doing our CI builds; the only question is getting the flags right. I was thinking you could just make use of that script, since then you don't end up owning your own set of custom build scripts.\n\nThat said, you're totally welcome to write your own if that's easier for you.\n"}