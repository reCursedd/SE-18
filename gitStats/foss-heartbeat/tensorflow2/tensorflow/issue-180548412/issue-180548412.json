{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4722", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4722/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4722/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4722/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4722", "id": 180548412, "node_id": "MDU6SXNzdWUxODA1NDg0MTI=", "number": 4722, "title": "einsum not fully implemented", "user": {"login": "xuancong84", "id": 10172392, "node_id": "MDQ6VXNlcjEwMTcyMzky", "avatar_url": "https://avatars0.githubusercontent.com/u/10172392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xuancong84", "html_url": "https://github.com/xuancong84", "followers_url": "https://api.github.com/users/xuancong84/followers", "following_url": "https://api.github.com/users/xuancong84/following{/other_user}", "gists_url": "https://api.github.com/users/xuancong84/gists{/gist_id}", "starred_url": "https://api.github.com/users/xuancong84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xuancong84/subscriptions", "organizations_url": "https://api.github.com/users/xuancong84/orgs", "repos_url": "https://api.github.com/users/xuancong84/repos", "events_url": "https://api.github.com/users/xuancong84/events{/privacy}", "received_events_url": "https://api.github.com/users/xuancong84/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2016-10-03T01:21:59Z", "updated_at": "2017-09-25T16:13:28Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I am glad to see the newly added einsum function. The documentation claims that its usage is the same as numpy. However, it can do almost nothing as compared to numpy. For example, it only supports subscripts in the form of '<em>-&gt;</em>'. Unfortunately, even matrix transpose does not work, i.e., 'ij-&gt;ji'.<br>\nNumpy works:</p>\n<pre><code>&gt;&gt;&gt; A\narray([[ 0.3828997 , -0.39114848, -0.09727838, -0.20430113],\n       [ 0.48020577, -0.47122706,  0.42830791,  0.25665744],\n       [-0.30885863,  0.21669025,  0.31648793,  0.22417514],\n       [ 0.32505724,  0.30478035,  0.48655034,  0.20040547]])\n&gt;&gt;&gt; einsum('ij-&gt;ji',A)\narray([[ 0.3828997 ,  0.48020577, -0.30885863,  0.32505724],\n       [-0.39114848, -0.47122706,  0.21669025,  0.30478035],\n       [-0.09727838,  0.42830791,  0.31648793,  0.48655034],\n       [-0.20430113,  0.25665744,  0.22417514,  0.20040547]])\n</code></pre>\n<p>Tensorflow does not work:</p>\n<pre><code>pseudo-code:\nM_ = tf.Variable(tf.random_normal([4,4]))\nN_ = tf.einsum('ij-&gt;ji',M_)              \nprint [M_, N_]\n\noutput:\n[array([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32), \narray([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32)]\n</code></pre>\n<p>I want to multiply a matrix with every frame vector in every batch. Or similar operations which can be done by a simple tensor product. It seems that I still have to duplicate the matrix so many times and perform a batch_matmul, which is very inconvenient and slow and memory consuming.</p>\n<p>I suggest tensorflow to implement either the tensordot or einsum function which can perform tensor product.</p>\n<p>It is quite a shame that tensorflow cannot even perform basic tensor product so far :(</p>", "body_text": "I am glad to see the newly added einsum function. The documentation claims that its usage is the same as numpy. However, it can do almost nothing as compared to numpy. For example, it only supports subscripts in the form of '->'. Unfortunately, even matrix transpose does not work, i.e., 'ij->ji'.\nNumpy works:\n>>> A\narray([[ 0.3828997 , -0.39114848, -0.09727838, -0.20430113],\n       [ 0.48020577, -0.47122706,  0.42830791,  0.25665744],\n       [-0.30885863,  0.21669025,  0.31648793,  0.22417514],\n       [ 0.32505724,  0.30478035,  0.48655034,  0.20040547]])\n>>> einsum('ij->ji',A)\narray([[ 0.3828997 ,  0.48020577, -0.30885863,  0.32505724],\n       [-0.39114848, -0.47122706,  0.21669025,  0.30478035],\n       [-0.09727838,  0.42830791,  0.31648793,  0.48655034],\n       [-0.20430113,  0.25665744,  0.22417514,  0.20040547]])\n\nTensorflow does not work:\npseudo-code:\nM_ = tf.Variable(tf.random_normal([4,4]))\nN_ = tf.einsum('ij->ji',M_)              \nprint [M_, N_]\n\noutput:\n[array([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32), \narray([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32)]\n\nI want to multiply a matrix with every frame vector in every batch. Or similar operations which can be done by a simple tensor product. It seems that I still have to duplicate the matrix so many times and perform a batch_matmul, which is very inconvenient and slow and memory consuming.\nI suggest tensorflow to implement either the tensordot or einsum function which can perform tensor product.\nIt is quite a shame that tensorflow cannot even perform basic tensor product so far :(", "body": "I am glad to see the newly added einsum function. The documentation claims that its usage is the same as numpy. However, it can do almost nothing as compared to numpy. For example, it only supports subscripts in the form of '_->_'. Unfortunately, even matrix transpose does not work, i.e., 'ij->ji'. \nNumpy works:\n\n```\n>>> A\narray([[ 0.3828997 , -0.39114848, -0.09727838, -0.20430113],\n       [ 0.48020577, -0.47122706,  0.42830791,  0.25665744],\n       [-0.30885863,  0.21669025,  0.31648793,  0.22417514],\n       [ 0.32505724,  0.30478035,  0.48655034,  0.20040547]])\n>>> einsum('ij->ji',A)\narray([[ 0.3828997 ,  0.48020577, -0.30885863,  0.32505724],\n       [-0.39114848, -0.47122706,  0.21669025,  0.30478035],\n       [-0.09727838,  0.42830791,  0.31648793,  0.48655034],\n       [-0.20430113,  0.25665744,  0.22417514,  0.20040547]])\n```\n\nTensorflow does not work:\n\n```\npseudo-code:\nM_ = tf.Variable(tf.random_normal([4,4]))\nN_ = tf.einsum('ij->ji',M_)              \nprint [M_, N_]\n\noutput:\n[array([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32), \narray([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],\n       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],\n       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],\n       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32)]\n```\n\nI want to multiply a matrix with every frame vector in every batch. Or similar operations which can be done by a simple tensor product. It seems that I still have to duplicate the matrix so many times and perform a batch_matmul, which is very inconvenient and slow and memory consuming.\n\nI suggest tensorflow to implement either the tensordot or einsum function which can perform tensor product.\n\nIt is quite a shame that tensorflow cannot even perform basic tensor product so far :(\n"}