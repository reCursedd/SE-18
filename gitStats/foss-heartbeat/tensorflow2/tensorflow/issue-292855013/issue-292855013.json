{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16590", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16590/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16590/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16590/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16590", "id": 292855013, "node_id": "MDU6SXNzdWUyOTI4NTUwMTM=", "number": 16590, "title": "how to save model for tensroflwo serving for lstm in tensorflow/contrib/timeseries/examples/lstm.py", "user": {"login": "yangfengKAUST", "id": 16612252, "node_id": "MDQ6VXNlcjE2NjEyMjUy", "avatar_url": "https://avatars3.githubusercontent.com/u/16612252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yangfengKAUST", "html_url": "https://github.com/yangfengKAUST", "followers_url": "https://api.github.com/users/yangfengKAUST/followers", "following_url": "https://api.github.com/users/yangfengKAUST/following{/other_user}", "gists_url": "https://api.github.com/users/yangfengKAUST/gists{/gist_id}", "starred_url": "https://api.github.com/users/yangfengKAUST/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yangfengKAUST/subscriptions", "organizations_url": "https://api.github.com/users/yangfengKAUST/orgs", "repos_url": "https://api.github.com/users/yangfengKAUST/repos", "events_url": "https://api.github.com/users/yangfengKAUST/events{/privacy}", "received_events_url": "https://api.github.com/users/yangfengKAUST/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-01-30T16:46:48Z", "updated_at": "2018-04-04T23:08:50Z", "closed_at": "2018-04-04T23:08:50Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug or a feature request.</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>when I run lstm in tensorflow/contrib/timeseries/examples/lstm.py, I tried to add methods to save model into savedModel, but it gives back errors.</p>\n<p>File \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 504, in export_savedmodel<br>\nserving_input_receiver = serving_input_receiver_fn()<br>\nFile \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/contrib/timeseries/python/timeseries/estimators.py\", line 133, in _serving_input_receiver_fn<br>\nself._model.initialize_graph()<br>\nTypeError: initialize_graph() missing 1 required positional argument: 'input_statistics'</p>\n<p>The issue I guess is that, in self._model.initialize_graph(), no parameters are given, but in</p>\n<pre><code>def initialize_graph(self, input_statistics):\n    \"\"\"Save templates for components, which can then be used repeatedly.\n    This method is called every time a new graph is created. It's safe to start\n    adding ops to the current default graph here, but the graph should be\n    constructed from scratch.\n    Args:\n      input_statistics: A math_utils.InputStatistics object.\n    \"\"\"\n    super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)\n    with tf.variable_scope(\"\", use_resource=True):\n      # Use ResourceVariables to avoid race conditions.\n      self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)\n      # Create templates so we don't have to worry about variable reuse.\n      self._lstm_cell_run = tf.make_template(\n          name_=\"lstm_cell\",\n          func_=self._lstm_cell,\n          create_scope_now_=True)\n      # Transforms LSTM output into mean predictions.\n      self._predict_from_lstm_output = tf.make_template(\n          name_=\"predict_from_lstm_output\",\n          func_=functools.partial(tf.layers.dense, units=self.num_features),\n          create_scope_now_=True)\n</code></pre>\n<p>one param input_statistics is asked. But how to fix this issue</p>\n<h3>Source code / logs</h3>\n<pre><code>serving_input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\nestimator.export_savedmodel(\n    \"../model\",\n    serving_input_receiver_fn\n)\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug or a feature request.\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nwhen I run lstm in tensorflow/contrib/timeseries/examples/lstm.py, I tried to add methods to save model into savedModel, but it gives back errors.\nFile \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 504, in export_savedmodel\nserving_input_receiver = serving_input_receiver_fn()\nFile \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/contrib/timeseries/python/timeseries/estimators.py\", line 133, in _serving_input_receiver_fn\nself._model.initialize_graph()\nTypeError: initialize_graph() missing 1 required positional argument: 'input_statistics'\nThe issue I guess is that, in self._model.initialize_graph(), no parameters are given, but in\ndef initialize_graph(self, input_statistics):\n    \"\"\"Save templates for components, which can then be used repeatedly.\n    This method is called every time a new graph is created. It's safe to start\n    adding ops to the current default graph here, but the graph should be\n    constructed from scratch.\n    Args:\n      input_statistics: A math_utils.InputStatistics object.\n    \"\"\"\n    super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)\n    with tf.variable_scope(\"\", use_resource=True):\n      # Use ResourceVariables to avoid race conditions.\n      self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)\n      # Create templates so we don't have to worry about variable reuse.\n      self._lstm_cell_run = tf.make_template(\n          name_=\"lstm_cell\",\n          func_=self._lstm_cell,\n          create_scope_now_=True)\n      # Transforms LSTM output into mean predictions.\n      self._predict_from_lstm_output = tf.make_template(\n          name_=\"predict_from_lstm_output\",\n          func_=functools.partial(tf.layers.dense, units=self.num_features),\n          create_scope_now_=True)\n\none param input_statistics is asked. But how to fix this issue\nSource code / logs\nserving_input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\nestimator.export_savedmodel(\n    \"../model\",\n    serving_input_receiver_fn\n)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nwhen I run lstm in tensorflow/contrib/timeseries/examples/lstm.py, I tried to add methods to save model into savedModel, but it gives back errors.\r\n\r\n  File \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py\", line 504, in export_savedmodel\r\n    serving_input_receiver = serving_input_receiver_fn()\r\n  File \"/Users/yang/.local/lib/python3.4/site-packages/tensorflow/contrib/timeseries/python/timeseries/estimators.py\", line 133, in _serving_input_receiver_fn\r\n    self._model.initialize_graph()\r\nTypeError: initialize_graph() missing 1 required positional argument: 'input_statistics'\r\n\r\nThe issue I guess is that, in self._model.initialize_graph(), no parameters are given, but in \r\n\r\n    def initialize_graph(self, input_statistics):\r\n        \"\"\"Save templates for components, which can then be used repeatedly.\r\n        This method is called every time a new graph is created. It's safe to start\r\n        adding ops to the current default graph here, but the graph should be\r\n        constructed from scratch.\r\n        Args:\r\n          input_statistics: A math_utils.InputStatistics object.\r\n        \"\"\"\r\n        super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)\r\n        with tf.variable_scope(\"\", use_resource=True):\r\n          # Use ResourceVariables to avoid race conditions.\r\n          self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)\r\n          # Create templates so we don't have to worry about variable reuse.\r\n          self._lstm_cell_run = tf.make_template(\r\n              name_=\"lstm_cell\",\r\n              func_=self._lstm_cell,\r\n              create_scope_now_=True)\r\n          # Transforms LSTM output into mean predictions.\r\n          self._predict_from_lstm_output = tf.make_template(\r\n              name_=\"predict_from_lstm_output\",\r\n              func_=functools.partial(tf.layers.dense, units=self.num_features),\r\n              create_scope_now_=True)\r\n\r\none param input_statistics is asked. But how to fix this issue\r\n\r\n### Source code / logs\r\n    \r\n    serving_input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\r\n    estimator.export_savedmodel(\r\n        \"../model\",\r\n        serving_input_receiver_fn\r\n    )\r\n"}