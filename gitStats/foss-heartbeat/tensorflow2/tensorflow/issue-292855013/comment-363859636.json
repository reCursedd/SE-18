{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363859636", "html_url": "https://github.com/tensorflow/tensorflow/issues/16590#issuecomment-363859636", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16590", "id": 363859636, "node_id": "MDEyOklzc3VlQ29tbWVudDM2Mzg1OTYzNg==", "user": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-07T18:13:32Z", "updated_at": "2018-02-07T18:13:32Z", "author_association": "MEMBER", "body_html": "<p>Getting the fix code reviewed is taking a bit longer than I was thinking. Here's the patch:</p>\n<pre><code>diff --git a/tensorflow/contrib/timeseries/examples/lstm.py b/tensorflow/contrib/timeseries/examples/lstm.py\nindex c834430b9..630f4fc05 100644\n--- a/tensorflow/contrib/timeseries/examples/lstm.py\n+++ b/tensorflow/contrib/timeseries/examples/lstm.py\n@@ -20,12 +20,14 @@ from __future__ import print_function\n \n import functools\n from os import path\n+import tempfile\n \n import numpy\n import tensorflow as tf\n \n from tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimators\n from tensorflow.contrib.timeseries.python.timeseries import model as ts_model\n+from tensorflow.contrib.timeseries.python.timeseries import state_management\n \n try:\n   import matplotlib  # pylint: disable=g-import-not-at-top\n@@ -70,7 +72,7 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n     self._lstm_cell_run = None\n     self._predict_from_lstm_output = None\n \n-  def initialize_graph(self, input_statistics):\n+  def initialize_graph(self, input_statistics=None):\n     \"\"\"Save templates for components, which can then be used repeatedly.\n \n     This method is called every time a new graph is created. It's safe to start\n@@ -168,12 +170,15 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n \n \n def train_and_predict(\n-    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None):\n+    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None,\n+    export_directory=None):\n   \"\"\"Train and predict using a custom time series model.\"\"\"\n   # Construct an Estimator from our LSTM model.\n   estimator = ts_estimators.TimeSeriesRegressor(\n       model=_LSTMModel(num_features=5, num_units=128),\n-      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config)\n+      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config,\n+      # Set state to be saved across windows.\n+      state_manager=state_management.ChainingStateManager())\n   reader = tf.contrib.timeseries.CSVReader(\n       csv_file_name,\n       column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)\n@@ -192,6 +197,28 @@ def train_and_predict(\n   predicted_mean = numpy.squeeze(numpy.concatenate(\n       [evaluation[\"mean\"][0], predictions[\"mean\"]], axis=0))\n   all_times = numpy.concatenate([times, predictions[\"times\"]], axis=0)\n+\n+  # Export the model in SavedModel format.\n+  if export_directory is None:\n+    export_directory = tempfile.mkdtemp()\n+  input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\n+  export_location = estimator.export_savedmodel(\n+      export_directory, input_receiver_fn)\n+\n+  # Predict using the SavedModel\n+  with tf.Graph().as_default():\n+    with tf.Session() as session:\n+      signatures = tf.saved_model.loader.load(\n+          session, [tf.saved_model.tag_constants.SERVING], export_location)\n+      saved_model_output = (\n+          tf.contrib.timeseries.saved_model_utils.predict_continuation(\n+              continue_from=evaluation, signatures=signatures,\n+              session=session, steps=100))\n+      # The exported model gives the same results as the Estimator.predict()\n+      # call above.\n+      numpy.testing.assert_allclose(\n+          predictions[\"mean\"],\n+          numpy.squeeze(saved_model_output[\"mean\"], axis=0))\n   return times, observed, all_times, predicted_mean\n \n \ndiff --git a/tensorflow/contrib/timeseries/examples/lstm_test.py b/tensorflow/contrib/timeseries/examples/lstm_test.py\nindex 3cace5672..ca56e38ca 100644\n--- a/tensorflow/contrib/timeseries/examples/lstm_test.py\n+++ b/tensorflow/contrib/timeseries/examples/lstm_test.py\n@@ -36,7 +36,8 @@ class LSTMExampleTest(test.TestCase):\n   def test_periodicity_learned(self):\n     (observed_times, observed_values,\n      all_times, predicted_values) = lstm.train_and_predict(\n-         training_steps=100, estimator_config=_SeedRunConfig())\n+         training_steps=100, estimator_config=_SeedRunConfig(),\n+         export_directory=self.get_temp_dir())\n     self.assertAllEqual([100], observed_times.shape)\n     self.assertAllEqual([100, 5], observed_values.shape)\n     self.assertAllEqual([200], all_times.shape)\n\n</code></pre>", "body_text": "Getting the fix code reviewed is taking a bit longer than I was thinking. Here's the patch:\ndiff --git a/tensorflow/contrib/timeseries/examples/lstm.py b/tensorflow/contrib/timeseries/examples/lstm.py\nindex c834430b9..630f4fc05 100644\n--- a/tensorflow/contrib/timeseries/examples/lstm.py\n+++ b/tensorflow/contrib/timeseries/examples/lstm.py\n@@ -20,12 +20,14 @@ from __future__ import print_function\n \n import functools\n from os import path\n+import tempfile\n \n import numpy\n import tensorflow as tf\n \n from tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimators\n from tensorflow.contrib.timeseries.python.timeseries import model as ts_model\n+from tensorflow.contrib.timeseries.python.timeseries import state_management\n \n try:\n   import matplotlib  # pylint: disable=g-import-not-at-top\n@@ -70,7 +72,7 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n     self._lstm_cell_run = None\n     self._predict_from_lstm_output = None\n \n-  def initialize_graph(self, input_statistics):\n+  def initialize_graph(self, input_statistics=None):\n     \"\"\"Save templates for components, which can then be used repeatedly.\n \n     This method is called every time a new graph is created. It's safe to start\n@@ -168,12 +170,15 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n \n \n def train_and_predict(\n-    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None):\n+    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None,\n+    export_directory=None):\n   \"\"\"Train and predict using a custom time series model.\"\"\"\n   # Construct an Estimator from our LSTM model.\n   estimator = ts_estimators.TimeSeriesRegressor(\n       model=_LSTMModel(num_features=5, num_units=128),\n-      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config)\n+      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config,\n+      # Set state to be saved across windows.\n+      state_manager=state_management.ChainingStateManager())\n   reader = tf.contrib.timeseries.CSVReader(\n       csv_file_name,\n       column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)\n@@ -192,6 +197,28 @@ def train_and_predict(\n   predicted_mean = numpy.squeeze(numpy.concatenate(\n       [evaluation[\"mean\"][0], predictions[\"mean\"]], axis=0))\n   all_times = numpy.concatenate([times, predictions[\"times\"]], axis=0)\n+\n+  # Export the model in SavedModel format.\n+  if export_directory is None:\n+    export_directory = tempfile.mkdtemp()\n+  input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\n+  export_location = estimator.export_savedmodel(\n+      export_directory, input_receiver_fn)\n+\n+  # Predict using the SavedModel\n+  with tf.Graph().as_default():\n+    with tf.Session() as session:\n+      signatures = tf.saved_model.loader.load(\n+          session, [tf.saved_model.tag_constants.SERVING], export_location)\n+      saved_model_output = (\n+          tf.contrib.timeseries.saved_model_utils.predict_continuation(\n+              continue_from=evaluation, signatures=signatures,\n+              session=session, steps=100))\n+      # The exported model gives the same results as the Estimator.predict()\n+      # call above.\n+      numpy.testing.assert_allclose(\n+          predictions[\"mean\"],\n+          numpy.squeeze(saved_model_output[\"mean\"], axis=0))\n   return times, observed, all_times, predicted_mean\n \n \ndiff --git a/tensorflow/contrib/timeseries/examples/lstm_test.py b/tensorflow/contrib/timeseries/examples/lstm_test.py\nindex 3cace5672..ca56e38ca 100644\n--- a/tensorflow/contrib/timeseries/examples/lstm_test.py\n+++ b/tensorflow/contrib/timeseries/examples/lstm_test.py\n@@ -36,7 +36,8 @@ class LSTMExampleTest(test.TestCase):\n   def test_periodicity_learned(self):\n     (observed_times, observed_values,\n      all_times, predicted_values) = lstm.train_and_predict(\n-         training_steps=100, estimator_config=_SeedRunConfig())\n+         training_steps=100, estimator_config=_SeedRunConfig(),\n+         export_directory=self.get_temp_dir())\n     self.assertAllEqual([100], observed_times.shape)\n     self.assertAllEqual([100, 5], observed_values.shape)\n     self.assertAllEqual([200], all_times.shape)", "body": "Getting the fix code reviewed is taking a bit longer than I was thinking. Here's the patch:\r\n\r\n```\r\ndiff --git a/tensorflow/contrib/timeseries/examples/lstm.py b/tensorflow/contrib/timeseries/examples/lstm.py\r\nindex c834430b9..630f4fc05 100644\r\n--- a/tensorflow/contrib/timeseries/examples/lstm.py\r\n+++ b/tensorflow/contrib/timeseries/examples/lstm.py\r\n@@ -20,12 +20,14 @@ from __future__ import print_function\r\n \r\n import functools\r\n from os import path\r\n+import tempfile\r\n \r\n import numpy\r\n import tensorflow as tf\r\n \r\n from tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimators\r\n from tensorflow.contrib.timeseries.python.timeseries import model as ts_model\r\n+from tensorflow.contrib.timeseries.python.timeseries import state_management\r\n \r\n try:\r\n   import matplotlib  # pylint: disable=g-import-not-at-top\r\n@@ -70,7 +72,7 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\r\n     self._lstm_cell_run = None\r\n     self._predict_from_lstm_output = None\r\n \r\n-  def initialize_graph(self, input_statistics):\r\n+  def initialize_graph(self, input_statistics=None):\r\n     \"\"\"Save templates for components, which can then be used repeatedly.\r\n \r\n     This method is called every time a new graph is created. It's safe to start\r\n@@ -168,12 +170,15 @@ class _LSTMModel(ts_model.SequentialTimeSeriesModel):\r\n \r\n \r\n def train_and_predict(\r\n-    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None):\r\n+    csv_file_name=_DATA_FILE, training_steps=200, estimator_config=None,\r\n+    export_directory=None):\r\n   \"\"\"Train and predict using a custom time series model.\"\"\"\r\n   # Construct an Estimator from our LSTM model.\r\n   estimator = ts_estimators.TimeSeriesRegressor(\r\n       model=_LSTMModel(num_features=5, num_units=128),\r\n-      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config)\r\n+      optimizer=tf.train.AdamOptimizer(0.001), config=estimator_config,\r\n+      # Set state to be saved across windows.\r\n+      state_manager=state_management.ChainingStateManager())\r\n   reader = tf.contrib.timeseries.CSVReader(\r\n       csv_file_name,\r\n       column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)\r\n@@ -192,6 +197,28 @@ def train_and_predict(\r\n   predicted_mean = numpy.squeeze(numpy.concatenate(\r\n       [evaluation[\"mean\"][0], predictions[\"mean\"]], axis=0))\r\n   all_times = numpy.concatenate([times, predictions[\"times\"]], axis=0)\r\n+\r\n+  # Export the model in SavedModel format.\r\n+  if export_directory is None:\r\n+    export_directory = tempfile.mkdtemp()\r\n+  input_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\r\n+  export_location = estimator.export_savedmodel(\r\n+      export_directory, input_receiver_fn)\r\n+\r\n+  # Predict using the SavedModel\r\n+  with tf.Graph().as_default():\r\n+    with tf.Session() as session:\r\n+      signatures = tf.saved_model.loader.load(\r\n+          session, [tf.saved_model.tag_constants.SERVING], export_location)\r\n+      saved_model_output = (\r\n+          tf.contrib.timeseries.saved_model_utils.predict_continuation(\r\n+              continue_from=evaluation, signatures=signatures,\r\n+              session=session, steps=100))\r\n+      # The exported model gives the same results as the Estimator.predict()\r\n+      # call above.\r\n+      numpy.testing.assert_allclose(\r\n+          predictions[\"mean\"],\r\n+          numpy.squeeze(saved_model_output[\"mean\"], axis=0))\r\n   return times, observed, all_times, predicted_mean\r\n \r\n \r\ndiff --git a/tensorflow/contrib/timeseries/examples/lstm_test.py b/tensorflow/contrib/timeseries/examples/lstm_test.py\r\nindex 3cace5672..ca56e38ca 100644\r\n--- a/tensorflow/contrib/timeseries/examples/lstm_test.py\r\n+++ b/tensorflow/contrib/timeseries/examples/lstm_test.py\r\n@@ -36,7 +36,8 @@ class LSTMExampleTest(test.TestCase):\r\n   def test_periodicity_learned(self):\r\n     (observed_times, observed_values,\r\n      all_times, predicted_values) = lstm.train_and_predict(\r\n-         training_steps=100, estimator_config=_SeedRunConfig())\r\n+         training_steps=100, estimator_config=_SeedRunConfig(),\r\n+         export_directory=self.get_temp_dir())\r\n     self.assertAllEqual([100], observed_times.shape)\r\n     self.assertAllEqual([100, 5], observed_values.shape)\r\n     self.assertAllEqual([200], all_times.shape)\r\n\r\n```"}