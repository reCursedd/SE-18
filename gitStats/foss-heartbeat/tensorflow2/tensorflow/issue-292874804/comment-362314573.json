{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362314573", "html_url": "https://github.com/tensorflow/tensorflow/issues/16592#issuecomment-362314573", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16592", "id": 362314573, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjMxNDU3Mw==", "user": {"login": "k22jung", "id": 14689505, "node_id": "MDQ6VXNlcjE0Njg5NTA1", "avatar_url": "https://avatars2.githubusercontent.com/u/14689505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/k22jung", "html_url": "https://github.com/k22jung", "followers_url": "https://api.github.com/users/k22jung/followers", "following_url": "https://api.github.com/users/k22jung/following{/other_user}", "gists_url": "https://api.github.com/users/k22jung/gists{/gist_id}", "starred_url": "https://api.github.com/users/k22jung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/k22jung/subscriptions", "organizations_url": "https://api.github.com/users/k22jung/orgs", "repos_url": "https://api.github.com/users/k22jung/repos", "events_url": "https://api.github.com/users/k22jung/events{/privacy}", "received_events_url": "https://api.github.com/users/k22jung/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-01T16:09:03Z", "updated_at": "2018-02-01T16:18:14Z", "author_association": "NONE", "body_html": "<p>We will be using smaller, mobile nets for our deployment. But I think it is important to consider and understand why <code>sess.run</code> uses this large amount of memory, even for AlexNet. We might come across this issue again, even if we were to move to a smaller model.<br>\nI'll get to memory-mapping the model soon, here is the profiler output for the time being:</p>\n<pre><code>Line #    Mem usage    Increment   Line Contents\n================================================\n    10  194.477 MiB  194.477 MiB   @profile\n    11                             def infer():\n    12  194.477 MiB    0.000 MiB   \tfrozen_graph='frozen-graphs/frozen_alexnet.pb'\n    13                             \n    14  196.004 MiB    0.000 MiB   \tdef load_graph(frozen_graph_filename):\n    15  196.004 MiB    0.000 MiB   \t    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n    16  196.004 MiB    0.000 MiB   \t\tgraph_def = tf.GraphDef()\n    17  431.656 MiB  235.652 MiB   \t\tgraph_def.ParseFromString(f.read())\n    18                             \n    19  431.656 MiB    0.000 MiB   \t    with tf.Graph().as_default() as graph:\n    20  433.652 MiB    1.996 MiB   \t\ttf.import_graph_def(graph_def, name=\"prefix\")\n    21  433.652 MiB    0.000 MiB   \t    return graph\n    22                             \n    23  194.477 MiB    0.000 MiB   \timagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n    24                             \n    25  194.477 MiB    0.000 MiB   \tcurrent_dir = os.getcwd()\n    26  194.477 MiB    0.000 MiB   \timage_dir = os.path.join(current_dir, 'images')\n    27                             \n    28  194.477 MiB    0.000 MiB   \timg_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpeg')]\n    29                             \n    30  194.477 MiB    0.000 MiB   \timgs = []\n    31  196.004 MiB    0.000 MiB   \tfor f in img_files:\n    32  196.004 MiB    1.527 MiB   \t    imgs.append(cv2.imread(f))\n    33                             \n    34  433.652 MiB    0.000 MiB   \tg=load_graph(frozen_graph)\n    35  435.652 MiB    2.000 MiB   \twith tf.Session(graph=g) as sess:\n    36                             \n    37  435.652 MiB    0.000 MiB   \t    softmax=g.get_tensor_by_name('prefix/softmax:0')\n    38  435.652 MiB    0.000 MiB   \t    x = g.get_tensor_by_name(\"prefix/input:0\")\n    39  435.652 MiB    0.000 MiB   \t    keep_prob = g.get_tensor_by_name(\"prefix/keepProbs:0\")\n    40                             \n    41 1664.207 MiB    0.000 MiB   \t    for i, image in enumerate(imgs):\n    42                             \t\t\n    43  437.680 MiB    2.027 MiB   \t\timg = cv2.resize(image.astype(np.float32), (227,227))\n    44  437.680 MiB    0.000 MiB   \t\timg -= imagenet_mean\n    45  437.680 MiB    0.000 MiB   \t\timg = img.reshape((1,227,227,3))\n    46                             \n    47  437.680 MiB    0.000 MiB   \t\toptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    48  437.680 MiB    0.000 MiB   \t\trun_metadata = tf.RunMetadata()\n    49                             \t\t\n    50  437.680 MiB    0.000 MiB   \t\tprint 'Begin session:'\n    51  437.680 MiB    0.000 MiB   \t\tprobs = sess.run(softmax, feed_dict={x: img, keep_prob: 1}, \\\n    52 1663.305 MiB 1225.625 MiB   \t\t\t\toptions=options, run_metadata=run_metadata)\n    53 1663.305 MiB    0.000 MiB   \t\tprint 'Ended session'\n    54                             \t\tprint 'Class: ' + str(class_names[np.argmax(probs)]) \\\n    55 1663.305 MiB    0.000 MiB   \t\t+ ', Prob: ' + str(probs[0,np.argmax(probs)])\n    56 1663.305 MiB    0.000 MiB   \t\tfetched_timeline = timeline.Timeline(run_metadata.step_stats)\n    57 1664.207 MiB    0.902 MiB   \t\tchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\n    58 1664.207 MiB    0.000 MiB   \t\twith open('./forward_timeline.json', 'w') as f:\n    59 1664.207 MiB    0.000 MiB   \t\t\tf.write(chrome_trace)\n</code></pre>", "body_text": "We will be using smaller, mobile nets for our deployment. But I think it is important to consider and understand why sess.run uses this large amount of memory, even for AlexNet. We might come across this issue again, even if we were to move to a smaller model.\nI'll get to memory-mapping the model soon, here is the profiler output for the time being:\nLine #    Mem usage    Increment   Line Contents\n================================================\n    10  194.477 MiB  194.477 MiB   @profile\n    11                             def infer():\n    12  194.477 MiB    0.000 MiB   \tfrozen_graph='frozen-graphs/frozen_alexnet.pb'\n    13                             \n    14  196.004 MiB    0.000 MiB   \tdef load_graph(frozen_graph_filename):\n    15  196.004 MiB    0.000 MiB   \t    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n    16  196.004 MiB    0.000 MiB   \t\tgraph_def = tf.GraphDef()\n    17  431.656 MiB  235.652 MiB   \t\tgraph_def.ParseFromString(f.read())\n    18                             \n    19  431.656 MiB    0.000 MiB   \t    with tf.Graph().as_default() as graph:\n    20  433.652 MiB    1.996 MiB   \t\ttf.import_graph_def(graph_def, name=\"prefix\")\n    21  433.652 MiB    0.000 MiB   \t    return graph\n    22                             \n    23  194.477 MiB    0.000 MiB   \timagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n    24                             \n    25  194.477 MiB    0.000 MiB   \tcurrent_dir = os.getcwd()\n    26  194.477 MiB    0.000 MiB   \timage_dir = os.path.join(current_dir, 'images')\n    27                             \n    28  194.477 MiB    0.000 MiB   \timg_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpeg')]\n    29                             \n    30  194.477 MiB    0.000 MiB   \timgs = []\n    31  196.004 MiB    0.000 MiB   \tfor f in img_files:\n    32  196.004 MiB    1.527 MiB   \t    imgs.append(cv2.imread(f))\n    33                             \n    34  433.652 MiB    0.000 MiB   \tg=load_graph(frozen_graph)\n    35  435.652 MiB    2.000 MiB   \twith tf.Session(graph=g) as sess:\n    36                             \n    37  435.652 MiB    0.000 MiB   \t    softmax=g.get_tensor_by_name('prefix/softmax:0')\n    38  435.652 MiB    0.000 MiB   \t    x = g.get_tensor_by_name(\"prefix/input:0\")\n    39  435.652 MiB    0.000 MiB   \t    keep_prob = g.get_tensor_by_name(\"prefix/keepProbs:0\")\n    40                             \n    41 1664.207 MiB    0.000 MiB   \t    for i, image in enumerate(imgs):\n    42                             \t\t\n    43  437.680 MiB    2.027 MiB   \t\timg = cv2.resize(image.astype(np.float32), (227,227))\n    44  437.680 MiB    0.000 MiB   \t\timg -= imagenet_mean\n    45  437.680 MiB    0.000 MiB   \t\timg = img.reshape((1,227,227,3))\n    46                             \n    47  437.680 MiB    0.000 MiB   \t\toptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    48  437.680 MiB    0.000 MiB   \t\trun_metadata = tf.RunMetadata()\n    49                             \t\t\n    50  437.680 MiB    0.000 MiB   \t\tprint 'Begin session:'\n    51  437.680 MiB    0.000 MiB   \t\tprobs = sess.run(softmax, feed_dict={x: img, keep_prob: 1}, \\\n    52 1663.305 MiB 1225.625 MiB   \t\t\t\toptions=options, run_metadata=run_metadata)\n    53 1663.305 MiB    0.000 MiB   \t\tprint 'Ended session'\n    54                             \t\tprint 'Class: ' + str(class_names[np.argmax(probs)]) \\\n    55 1663.305 MiB    0.000 MiB   \t\t+ ', Prob: ' + str(probs[0,np.argmax(probs)])\n    56 1663.305 MiB    0.000 MiB   \t\tfetched_timeline = timeline.Timeline(run_metadata.step_stats)\n    57 1664.207 MiB    0.902 MiB   \t\tchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\n    58 1664.207 MiB    0.000 MiB   \t\twith open('./forward_timeline.json', 'w') as f:\n    59 1664.207 MiB    0.000 MiB   \t\t\tf.write(chrome_trace)", "body": "We will be using smaller, mobile nets for our deployment. But I think it is important to consider and understand why `sess.run` uses this large amount of memory, even for AlexNet. We might come across this issue again, even if we were to move to a smaller model.\r\nI'll get to memory-mapping the model soon, here is the profiler output for the time being:\r\n\r\n```\r\nLine #    Mem usage    Increment   Line Contents\r\n================================================\r\n    10  194.477 MiB  194.477 MiB   @profile\r\n    11                             def infer():\r\n    12  194.477 MiB    0.000 MiB   \tfrozen_graph='frozen-graphs/frozen_alexnet.pb'\r\n    13                             \r\n    14  196.004 MiB    0.000 MiB   \tdef load_graph(frozen_graph_filename):\r\n    15  196.004 MiB    0.000 MiB   \t    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\r\n    16  196.004 MiB    0.000 MiB   \t\tgraph_def = tf.GraphDef()\r\n    17  431.656 MiB  235.652 MiB   \t\tgraph_def.ParseFromString(f.read())\r\n    18                             \r\n    19  431.656 MiB    0.000 MiB   \t    with tf.Graph().as_default() as graph:\r\n    20  433.652 MiB    1.996 MiB   \t\ttf.import_graph_def(graph_def, name=\"prefix\")\r\n    21  433.652 MiB    0.000 MiB   \t    return graph\r\n    22                             \r\n    23  194.477 MiB    0.000 MiB   \timagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\r\n    24                             \r\n    25  194.477 MiB    0.000 MiB   \tcurrent_dir = os.getcwd()\r\n    26  194.477 MiB    0.000 MiB   \timage_dir = os.path.join(current_dir, 'images')\r\n    27                             \r\n    28  194.477 MiB    0.000 MiB   \timg_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpeg')]\r\n    29                             \r\n    30  194.477 MiB    0.000 MiB   \timgs = []\r\n    31  196.004 MiB    0.000 MiB   \tfor f in img_files:\r\n    32  196.004 MiB    1.527 MiB   \t    imgs.append(cv2.imread(f))\r\n    33                             \r\n    34  433.652 MiB    0.000 MiB   \tg=load_graph(frozen_graph)\r\n    35  435.652 MiB    2.000 MiB   \twith tf.Session(graph=g) as sess:\r\n    36                             \r\n    37  435.652 MiB    0.000 MiB   \t    softmax=g.get_tensor_by_name('prefix/softmax:0')\r\n    38  435.652 MiB    0.000 MiB   \t    x = g.get_tensor_by_name(\"prefix/input:0\")\r\n    39  435.652 MiB    0.000 MiB   \t    keep_prob = g.get_tensor_by_name(\"prefix/keepProbs:0\")\r\n    40                             \r\n    41 1664.207 MiB    0.000 MiB   \t    for i, image in enumerate(imgs):\r\n    42                             \t\t\r\n    43  437.680 MiB    2.027 MiB   \t\timg = cv2.resize(image.astype(np.float32), (227,227))\r\n    44  437.680 MiB    0.000 MiB   \t\timg -= imagenet_mean\r\n    45  437.680 MiB    0.000 MiB   \t\timg = img.reshape((1,227,227,3))\r\n    46                             \r\n    47  437.680 MiB    0.000 MiB   \t\toptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n    48  437.680 MiB    0.000 MiB   \t\trun_metadata = tf.RunMetadata()\r\n    49                             \t\t\r\n    50  437.680 MiB    0.000 MiB   \t\tprint 'Begin session:'\r\n    51  437.680 MiB    0.000 MiB   \t\tprobs = sess.run(softmax, feed_dict={x: img, keep_prob: 1}, \\\r\n    52 1663.305 MiB 1225.625 MiB   \t\t\t\toptions=options, run_metadata=run_metadata)\r\n    53 1663.305 MiB    0.000 MiB   \t\tprint 'Ended session'\r\n    54                             \t\tprint 'Class: ' + str(class_names[np.argmax(probs)]) \\\r\n    55 1663.305 MiB    0.000 MiB   \t\t+ ', Prob: ' + str(probs[0,np.argmax(probs)])\r\n    56 1663.305 MiB    0.000 MiB   \t\tfetched_timeline = timeline.Timeline(run_metadata.step_stats)\r\n    57 1664.207 MiB    0.902 MiB   \t\tchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\r\n    58 1664.207 MiB    0.000 MiB   \t\twith open('./forward_timeline.json', 'w') as f:\r\n    59 1664.207 MiB    0.000 MiB   \t\t\tf.write(chrome_trace)\r\n``` "}