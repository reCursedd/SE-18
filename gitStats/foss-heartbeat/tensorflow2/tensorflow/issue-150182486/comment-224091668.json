{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224091668", "html_url": "https://github.com/tensorflow/tensorflow/issues/2054#issuecomment-224091668", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2054", "id": 224091668, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDA5MTY2OA==", "user": {"login": "keveman", "id": 229914, "node_id": "MDQ6VXNlcjIyOTkxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/229914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keveman", "html_url": "https://github.com/keveman", "followers_url": "https://api.github.com/users/keveman/followers", "following_url": "https://api.github.com/users/keveman/following{/other_user}", "gists_url": "https://api.github.com/users/keveman/gists{/gist_id}", "starred_url": "https://api.github.com/users/keveman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keveman/subscriptions", "organizations_url": "https://api.github.com/users/keveman/orgs", "repos_url": "https://api.github.com/users/keveman/repos", "events_url": "https://api.github.com/users/keveman/events{/privacy}", "received_events_url": "https://api.github.com/users/keveman/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-06T21:19:01Z", "updated_at": "2016-06-06T21:19:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11547801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prb12\">@prb12</a> for debugging this with me.<br>\nThe TensorFlow runtime optimizes the graph before it runs it the first time. One particular optimization of interest here is constant folding, that replaces a node whose input is a constant, with the output of the node after executing it. The 'execution' of the node during constant folding always happens on the CPU. Note that this is functionally correct, as both the CPU and GPU kernel implementations for an op are supposed to produce the same result. To make sure your op runs on the GPU in tests (where you presumably feed in constant values as inputs), use <code>self.test_session</code> to run your test. That <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L246\">disables</a> optimization when running the graph. Note that when you use your custom op in a larger program that has real inputs instead of constants, it will run on the GPU as expected. Closing this issue because this is the expected behavior. Please feel free to add follow up comments in case you need more info.</p>", "body_text": "Thanks to @prb12 for debugging this with me.\nThe TensorFlow runtime optimizes the graph before it runs it the first time. One particular optimization of interest here is constant folding, that replaces a node whose input is a constant, with the output of the node after executing it. The 'execution' of the node during constant folding always happens on the CPU. Note that this is functionally correct, as both the CPU and GPU kernel implementations for an op are supposed to produce the same result. To make sure your op runs on the GPU in tests (where you presumably feed in constant values as inputs), use self.test_session to run your test. That disables optimization when running the graph. Note that when you use your custom op in a larger program that has real inputs instead of constants, it will run on the GPU as expected. Closing this issue because this is the expected behavior. Please feel free to add follow up comments in case you need more info.", "body": "Thanks to @prb12 for debugging this with me.\nThe TensorFlow runtime optimizes the graph before it runs it the first time. One particular optimization of interest here is constant folding, that replaces a node whose input is a constant, with the output of the node after executing it. The 'execution' of the node during constant folding always happens on the CPU. Note that this is functionally correct, as both the CPU and GPU kernel implementations for an op are supposed to produce the same result. To make sure your op runs on the GPU in tests (where you presumably feed in constant values as inputs), use `self.test_session` to run your test. That [disables](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L246) optimization when running the graph. Note that when you use your custom op in a larger program that has real inputs instead of constants, it will run on the GPU as expected. Closing this issue because this is the expected behavior. Please feel free to add follow up comments in case you need more info.\n"}