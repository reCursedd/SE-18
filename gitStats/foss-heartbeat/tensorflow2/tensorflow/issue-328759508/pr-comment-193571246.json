{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/193571246", "pull_request_review_id": 126559342, "id": 193571246, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MzU3MTI0Ng==", "diff_hunk": "@@ -0,0 +1,139 @@\n+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+# use this file except in compliance with the License.  You may obtain a copy of\n+# the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+# License for the specific language governing permissions and limitations under\n+# the License.\n+# ==============================================================================\n+\"\"\"Tests for KinesisDataset.\n+NOTE: boto3 is needed and the test has to be invoked manually:\n+```\n+$ bazel test -s --verbose_failures --config=opt \\\n+    --action_env=AWS_ACCESS_KEY_ID=XXXXXX       \\\n+    --action_env=AWS_SECRET_ACCESS_KEY=XXXXXX   \\\n+    //tensorflow/contrib/kinesis:kinesis_test\n+```\n+\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import boto3\n+\n+from tensorflow.contrib.kinesis.python.ops import kinesis_dataset_ops\n+from tensorflow.python.data.ops import iterator_ops\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.platform import test\n+\n+\n+class KinesisDatasetTest(test.TestCase):\n+\n+  def testKinesisDatasetOneShard(self):\n+    client = boto3.client('kinesis', region_name='us-east-1')\n+\n+    # Setup the Kinesis with 1 shard.\n+    stream_name = \"tf_kinesis_test_1\"\n+    client.create_stream(StreamName=stream_name, ShardCount=1)\n+    # Wait until stream exists, default is 10 * 18 seconds.\n+    client.get_waiter('stream_exists').wait(StreamName=stream_name)\n+    for i in range(10):\n+      data = \"D\" + str(i)\n+      client.put_record(\n+          StreamName=stream_name, Data=data, PartitionKey=\"TensorFlow\" + str(i))\n+\n+    stream = array_ops.placeholder(dtypes.string, shape=[])\n+    num_epochs = array_ops.placeholder(dtypes.int64, shape=[])\n+    batch_size = array_ops.placeholder(dtypes.int64, shape=[])\n+\n+    repeat_dataset = kinesis_dataset_ops.KinesisDataset(\n+        stream, eof=True).repeat(num_epochs)\n+    batch_dataset = repeat_dataset.batch(batch_size)\n+\n+    iterator = iterator_ops.Iterator.from_structure(batch_dataset.output_types)\n+    init_op = iterator.make_initializer(repeat_dataset)\n+    init_batch_op = iterator.make_initializer(batch_dataset)\n+    get_next = iterator.get_next()\n+\n+    with self.test_session() as sess:\n+      # Basic test: read from shard 0 of stream 1.\n+      sess.run(init_op, feed_dict={stream: stream_name, num_epochs: 1})\n+      for i in range(10):\n+        self.assertEqual(\"D\" + str(i), sess.run(get_next))\n+      with self.assertRaises(errors.OutOfRangeError):\n+        sess.run(get_next)\n+\n+    client.delete_stream(StreamName=stream_name)\n+    # Wait until stream deleted, default is 10 * 18 seconds.\n+    client.get_waiter('stream_not_exists').wait(StreamName=stream_name)\n+\n+  def testKinesisDatasetTwoShards(self):\n+    client = boto3.client('kinesis', region_name='us-east-1')\n+\n+    # Setup the Kinesis with 2 shards.\n+    stream_name = \"tf_kinesis_test_2\"\n+    client.create_stream(StreamName=stream_name, ShardCount=2)\n+    # Wait until stream exists, default is 10 * 18 seconds.\n+    client.get_waiter('stream_exists').wait(StreamName=stream_name)\n+\n+    for i in range(10):\n+      data = \"D\" + str(i)\n+      client.put_record(\n+          StreamName=stream_name, Data=data, PartitionKey=\"TensorFlow\" + str(i))\n+    response = client.describe_stream(StreamName=stream_name)\n+    shard_id_0 = response[\"StreamDescription\"][\"Shards\"][0][\"ShardId\"]\n+    shard_id_1 = response[\"StreamDescription\"][\"Shards\"][1][\"ShardId\"]\n+\n+    stream = array_ops.placeholder(dtypes.string, shape=[])\n+    shard = array_ops.placeholder(dtypes.string, shape=[])\n+    num_epochs = array_ops.placeholder(dtypes.int64, shape=[])\n+    batch_size = array_ops.placeholder(dtypes.int64, shape=[])\n+\n+    repeat_dataset = kinesis_dataset_ops.KinesisDataset(\n+        stream, shard, eof=True).repeat(num_epochs)\n+    batch_dataset = repeat_dataset.batch(batch_size)\n+\n+    iterator = iterator_ops.Iterator.from_structure(batch_dataset.output_types)\n+    init_op = iterator.make_initializer(repeat_dataset)\n+    init_batch_op = iterator.make_initializer(batch_dataset)\n+    get_next = iterator.get_next()\n+\n+    data = list()\n+    with self.test_session() as sess:\n+      # Basic test: read from shard 0 of stream 2.\n+      sess.run(\n+          init_op, feed_dict={\n+              stream: stream_name, shard: shard_id_0, num_epochs: 1})\n+      with self.assertRaises(errors.OutOfRangeError):\n+        # Use range(11) to guaranteee the OutOfRangeError.\n+        for i in range(11):\n+          data.append(sess.run(get_next))\n+\n+      # Basic test: read from shard 1 of stream 2.\n+      sess.run(\n+          init_op, feed_dict={\n+              stream: stream_name, shard: shard_id_1, num_epochs: 1})\n+      with self.assertRaises(errors.OutOfRangeError):\n+        # Use range(11) to guaranteee the OutOfRangeError.", "path": "tensorflow/contrib/kinesis/python/kernel_tests/kinesis_test.py", "position": null, "original_position": 126, "commit_id": "9d119a1df765b5d45b6680a1d33b180648f102bf", "original_commit_id": "6e78998783dbb457f12286c5f2ca58cd5b635e96", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "body": "s/guaranteee/guarantee/", "created_at": "2018-06-06T21:53:40Z", "updated_at": "2018-06-29T23:15:25Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19712#discussion_r193571246", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19712", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/193571246"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19712#discussion_r193571246"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19712"}}, "body_html": "<p>s/guaranteee/guarantee/</p>", "body_text": "s/guaranteee/guarantee/"}