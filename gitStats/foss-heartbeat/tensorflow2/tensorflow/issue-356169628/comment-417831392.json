{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/417831392", "html_url": "https://github.com/tensorflow/tensorflow/issues/22001#issuecomment-417831392", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22001", "id": 417831392, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzgzMTM5Mg==", "user": {"login": "jianxucsm", "id": 22060946, "node_id": "MDQ6VXNlcjIyMDYwOTQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/22060946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jianxucsm", "html_url": "https://github.com/jianxucsm", "followers_url": "https://api.github.com/users/jianxucsm/followers", "following_url": "https://api.github.com/users/jianxucsm/following{/other_user}", "gists_url": "https://api.github.com/users/jianxucsm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jianxucsm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jianxucsm/subscriptions", "organizations_url": "https://api.github.com/users/jianxucsm/orgs", "repos_url": "https://api.github.com/users/jianxucsm/repos", "events_url": "https://api.github.com/users/jianxucsm/events{/privacy}", "received_events_url": "https://api.github.com/users/jianxucsm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-01T04:16:19Z", "updated_at": "2018-09-01T04:16:19Z", "author_association": "NONE", "body_html": "<p>Hi There;</p>\n<p>I experienced serious bug out of tf.dataset.fromgenerator call.</p>\n<p>if the callable function applies tf.device('cpu:0'):</p>\n<p>the receiving side of the data record is very unstable. it differs from time to time and machine from machine.</p>\n<p>a lot of times I got exactly same output for each batch from receiving side. If I take out the tf.device('cpu:0'), it seems to work fine. Seems to me the data/memory during the transform were messed up.</p>\n<p>following is sample code for reference;</p>\n<p>import tensorflow as tf<br>\nimport numpy as np<br>\nimport pandas as pd</p>\n<p>NEPOCHES = 5<br>\nBATCHSIZE = 10<br>\nNUMFEATURES = 2<br>\nPROCCOLS = ['item1', 'item2']<br>\nFILENAME = 'test.csv'<br>\nGENLOG = 'gen.log'<br>\nRECLOG = 'rec.log'</p>\n<p>def getNextBatch():</p>\n<pre><code>with tf.device('cpu:0'):\n    f = open(GENLOG, mode='w')\n    x = np.empty(shape=[BATCHSIZE, NUMFEATURES], dtype=np.float32)\n    y = np.empty(shape=[BATCHSIZE], dtype=np.float32)\n    z = np.int64(0)\n    r = np.empty(shape=[BATCHSIZE], dtype=np.int64)\n\n    x.fill(0)\n    y.fill(0)\n    z = 0\n    r.fill(0)\n    # print('start yield data')\n    f.write('start the data send from generator z: {} \\n x - \\n {}; \\n y - {}; \\n  r - {}\\n'.format(z, x, y, r))\n    yield (x, y, z, r)\n\n\n    df = pd.read_csv(filepath_or_buffer=FILENAME)\n\n\n    nrows = len(df)\n\n    ie = -1\n    ibatch = 0\n\n    while (ie + 1) &lt; nrows:\n        ie += 1\n\n        if not ((df.loc[ie, 'item1'] &gt; 3.68888) and (df.loc[ie, 'item2'] == 8)):\n            continue\n\n        x[ibatch] = df.loc[ie, ['item1', 'item2']].values\n        y[ibatch] = df.loc[ie, 'item3']\n        r[ibatch] = ie\n\n        ibatch += 1\n\n        if ibatch == BATCHSIZE:\n            ibatch = 0\n            z += 1\n\n            #print('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}'.format(z, x, y, r))\n            f.write('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}\\n'.format(z, x, y, r))\n            yield (x, y, z, r)\n    f.close()\n</code></pre>\n<p>def getDataSet():<br>\nds = tf.data.Dataset.from_generator(generator=getNextBatch, output_types=(tf.float32, tf.float32, tf.int64, tf.int64),<br>\noutput_shapes=(tf.TensorShape(dims=[BATCHSIZE, NUMFEATURES]), tf.TensorShape(dims=[BATCHSIZE]),<br>\ntf.TensorShape(dims=[]), tf.TensorShape(dims=[BATCHSIZE])))</p>\n<pre><code>return ds\n</code></pre>\n<p>def recDataSet():<br>\ncurSess = tf.Session()<br>\ndsn = getDataSet()<br>\ndsn = dsn.prefetch(10)<br>\ndsn = dsn.cache()<br>\ndsn = dsn.repeat(NEPOCHES)<br>\ndsn_it = dsn.make_initializable_iterator()<br>\ncurSess.run(dsn_it.initializer)<br>\ndsn_it_nt = dsn_it.get_next()<br>\nf = open(RECLOG, mode='w')</p>\n<pre><code>while True:\n    try:\n        ndt = curSess.run(dsn_it_nt)\n\n        f.write('receive data from generator, z -- {}\\n'.format(ndt[2]))\n        f.write('x: {}\\n'.format(ndt[0]))\n        f.write('y: {}\\n'.format(ndt[1]))\n        f.write('r: {}\\n'.format(ndt[3]))\n    except:\n        break\n\nf.close()\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\nrecDataSet()</p>", "body_text": "Hi There;\nI experienced serious bug out of tf.dataset.fromgenerator call.\nif the callable function applies tf.device('cpu:0'):\nthe receiving side of the data record is very unstable. it differs from time to time and machine from machine.\na lot of times I got exactly same output for each batch from receiving side. If I take out the tf.device('cpu:0'), it seems to work fine. Seems to me the data/memory during the transform were messed up.\nfollowing is sample code for reference;\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nNEPOCHES = 5\nBATCHSIZE = 10\nNUMFEATURES = 2\nPROCCOLS = ['item1', 'item2']\nFILENAME = 'test.csv'\nGENLOG = 'gen.log'\nRECLOG = 'rec.log'\ndef getNextBatch():\nwith tf.device('cpu:0'):\n    f = open(GENLOG, mode='w')\n    x = np.empty(shape=[BATCHSIZE, NUMFEATURES], dtype=np.float32)\n    y = np.empty(shape=[BATCHSIZE], dtype=np.float32)\n    z = np.int64(0)\n    r = np.empty(shape=[BATCHSIZE], dtype=np.int64)\n\n    x.fill(0)\n    y.fill(0)\n    z = 0\n    r.fill(0)\n    # print('start yield data')\n    f.write('start the data send from generator z: {} \\n x - \\n {}; \\n y - {}; \\n  r - {}\\n'.format(z, x, y, r))\n    yield (x, y, z, r)\n\n\n    df = pd.read_csv(filepath_or_buffer=FILENAME)\n\n\n    nrows = len(df)\n\n    ie = -1\n    ibatch = 0\n\n    while (ie + 1) < nrows:\n        ie += 1\n\n        if not ((df.loc[ie, 'item1'] > 3.68888) and (df.loc[ie, 'item2'] == 8)):\n            continue\n\n        x[ibatch] = df.loc[ie, ['item1', 'item2']].values\n        y[ibatch] = df.loc[ie, 'item3']\n        r[ibatch] = ie\n\n        ibatch += 1\n\n        if ibatch == BATCHSIZE:\n            ibatch = 0\n            z += 1\n\n            #print('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}'.format(z, x, y, r))\n            f.write('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}\\n'.format(z, x, y, r))\n            yield (x, y, z, r)\n    f.close()\n\ndef getDataSet():\nds = tf.data.Dataset.from_generator(generator=getNextBatch, output_types=(tf.float32, tf.float32, tf.int64, tf.int64),\noutput_shapes=(tf.TensorShape(dims=[BATCHSIZE, NUMFEATURES]), tf.TensorShape(dims=[BATCHSIZE]),\ntf.TensorShape(dims=[]), tf.TensorShape(dims=[BATCHSIZE])))\nreturn ds\n\ndef recDataSet():\ncurSess = tf.Session()\ndsn = getDataSet()\ndsn = dsn.prefetch(10)\ndsn = dsn.cache()\ndsn = dsn.repeat(NEPOCHES)\ndsn_it = dsn.make_initializable_iterator()\ncurSess.run(dsn_it.initializer)\ndsn_it_nt = dsn_it.get_next()\nf = open(RECLOG, mode='w')\nwhile True:\n    try:\n        ndt = curSess.run(dsn_it_nt)\n\n        f.write('receive data from generator, z -- {}\\n'.format(ndt[2]))\n        f.write('x: {}\\n'.format(ndt[0]))\n        f.write('y: {}\\n'.format(ndt[1]))\n        f.write('r: {}\\n'.format(ndt[3]))\n    except:\n        break\n\nf.close()\n\nif name == 'main':\nrecDataSet()", "body": "Hi There;\r\n\r\nI experienced serious bug out of tf.dataset.fromgenerator call.\r\n\r\nif the callable function applies tf.device('cpu:0'):\r\n\r\nthe receiving side of the data record is very unstable. it differs from time to time and machine from machine. \r\n\r\na lot of times I got exactly same output for each batch from receiving side. If I take out the tf.device('cpu:0'), it seems to work fine. Seems to me the data/memory during the transform were messed up.\r\n\r\nfollowing is sample code for reference;\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nNEPOCHES = 5\r\nBATCHSIZE = 10\r\nNUMFEATURES = 2\r\nPROCCOLS = ['item1', 'item2']\r\nFILENAME = 'test.csv'\r\nGENLOG = 'gen.log'\r\nRECLOG = 'rec.log'\r\n\r\ndef getNextBatch():\r\n\r\n    with tf.device('cpu:0'):\r\n        f = open(GENLOG, mode='w')\r\n        x = np.empty(shape=[BATCHSIZE, NUMFEATURES], dtype=np.float32)\r\n        y = np.empty(shape=[BATCHSIZE], dtype=np.float32)\r\n        z = np.int64(0)\r\n        r = np.empty(shape=[BATCHSIZE], dtype=np.int64)\r\n\r\n        x.fill(0)\r\n        y.fill(0)\r\n        z = 0\r\n        r.fill(0)\r\n        # print('start yield data')\r\n        f.write('start the data send from generator z: {} \\n x - \\n {}; \\n y - {}; \\n  r - {}\\n'.format(z, x, y, r))\r\n        yield (x, y, z, r)\r\n\r\n\r\n        df = pd.read_csv(filepath_or_buffer=FILENAME)\r\n\r\n\r\n        nrows = len(df)\r\n\r\n        ie = -1\r\n        ibatch = 0\r\n\r\n        while (ie + 1) < nrows:\r\n            ie += 1\r\n\r\n            if not ((df.loc[ie, 'item1'] > 3.68888) and (df.loc[ie, 'item2'] == 8)):\r\n                continue\r\n\r\n            x[ibatch] = df.loc[ie, ['item1', 'item2']].values\r\n            y[ibatch] = df.loc[ie, 'item3']\r\n            r[ibatch] = ie\r\n\r\n            ibatch += 1\r\n\r\n            if ibatch == BATCHSIZE:\r\n                ibatch = 0\r\n                z += 1\r\n\r\n                #print('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}'.format(z, x, y, r))\r\n                f.write('{} th the data send from generator: x - \\n {}; \\n y - {}; \\n r - {}\\n'.format(z, x, y, r))\r\n                yield (x, y, z, r)\r\n        f.close()\r\n\r\n\r\ndef getDataSet():\r\n    ds = tf.data.Dataset.from_generator(generator=getNextBatch, output_types=(tf.float32, tf.float32, tf.int64, tf.int64),\r\n                                        output_shapes=(tf.TensorShape(dims=[BATCHSIZE, NUMFEATURES]), tf.TensorShape(dims=[BATCHSIZE]),\r\n                                                       tf.TensorShape(dims=[]), tf.TensorShape(dims=[BATCHSIZE])))\r\n\r\n\r\n    return ds\r\n\r\n\r\ndef recDataSet():\r\n    curSess = tf.Session()\r\n    dsn = getDataSet()\r\n    dsn = dsn.prefetch(10)\r\n    dsn = dsn.cache()\r\n    dsn = dsn.repeat(NEPOCHES)\r\n    dsn_it = dsn.make_initializable_iterator()\r\n    curSess.run(dsn_it.initializer)\r\n    dsn_it_nt = dsn_it.get_next()\r\n    f = open(RECLOG, mode='w')\r\n\r\n    while True:\r\n        try:\r\n            ndt = curSess.run(dsn_it_nt)\r\n\r\n            f.write('receive data from generator, z -- {}\\n'.format(ndt[2]))\r\n            f.write('x: {}\\n'.format(ndt[0]))\r\n            f.write('y: {}\\n'.format(ndt[1]))\r\n            f.write('r: {}\\n'.format(ndt[3]))\r\n        except:\r\n            break\r\n\r\n    f.close()\r\nif __name__ == '__main__':\r\n    recDataSet()"}