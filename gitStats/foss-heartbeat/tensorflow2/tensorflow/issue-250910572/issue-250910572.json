{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12358", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12358/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12358/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12358/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12358", "id": 250910572, "node_id": "MDU6SXNzdWUyNTA5MTA1NzI=", "number": 12358, "title": "[Feature Request]  Add an extra argument `is_duplicated` to `scatter_sub/*` Ops and make the kernel to multi-thread for speedup. ", "user": {"login": "nolanliou", "id": 30223680, "node_id": "MDQ6VXNlcjMwMjIzNjgw", "avatar_url": "https://avatars3.githubusercontent.com/u/30223680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nolanliou", "html_url": "https://github.com/nolanliou", "followers_url": "https://api.github.com/users/nolanliou/followers", "following_url": "https://api.github.com/users/nolanliou/following{/other_user}", "gists_url": "https://api.github.com/users/nolanliou/gists{/gist_id}", "starred_url": "https://api.github.com/users/nolanliou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nolanliou/subscriptions", "organizations_url": "https://api.github.com/users/nolanliou/orgs", "repos_url": "https://api.github.com/users/nolanliou/repos", "events_url": "https://api.github.com/users/nolanliou/events{/privacy}", "received_events_url": "https://api.github.com/users/nolanliou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-17T11:20:09Z", "updated_at": "2017-08-28T03:50:54Z", "closed_at": "2017-08-28T03:50:54Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nubuntu 16.04</li>\n<li><strong>TenorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nv1.3.0-rc2</li>\n<li><strong>Python version</strong>:<br>\n2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.5.2</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n8.0/5.1.10</li>\n<li><strong>GPU model and memory</strong>:<br>\nnvidia M40</li>\n<li><strong>CPU</strong><br>\n32-cores</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I profile the <code>embedding_lookup_sparse</code> on single machine with tfprof, in which i put the <code>params</code> on cpu. So the <code>gather</code> and <code>scatter_sub</code> Op are also put on cpu.<br>\nProfiling result shows <code>gather</code> and <code>scatter_sub</code> Op takes so much time, the former takes about 33%, the latter takes about 43%. Making the <code>gather</code> op kernel to multi-thread gain about 10x speedup, relate to <a href=\"https://github.com/tensorflow/tensorflow/pull/12246\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/12246/hovercard\">PR</a> and <a href=\"https://github.com/tensorflow/tensorflow/issues/11709\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/11709/hovercard\">11709</a>.<br>\nFollow the same thought, I want to make the <code>scatter_sub</code> to be multi-thread.</p>\n<ul>\n<li>If there is no duplicate index, we can realize lock-free code which could gain about 10x speedup too.</li>\n<li>If there are duplicate indices, use lock which can gain little speedup.</li>\n</ul>\n<p>So, I think an extra argument <code>is_duplicated</code> is a good choice to divide the two situation.</p>\n<p>Here is some profiling result:</p>\n<h3>tfprof</h3>\n<pre><code># orignial\nScatterSub                   8589.93MB (65.56%, 32.67%),       45.63ms (62.09%, 43.75%),            0us (45.25%, 0.00%),       45.63ms (62.90%, 45.87%)\n# with lock\nScatterSub                   8589.93MB (65.56%, 32.67%),       38.10ms (86.95%, 54.44%),            0us (48.97%, 0.00%),       38.10ms (89.98%, 58.78%)\n# without lock\nScatterSub                   8589.93MB (65.56%, 32.67%),        4.22ms (73.05%, 12.58%),            0us (48.86%, 0.00%),        4.22ms (76.99%, 14.63%)\n</code></pre>\n<h3>Code</h3>\n<p><a href=\"https://gist.github.com/nolanliou/c00af5938b2aecfdc5ea1189426b8624\">embedding_lookup_sparse</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nubuntu 16.04\nTenorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\nv1.3.0-rc2\nPython version:\n2.7\nBazel version (if compiling from source):\n0.5.2\nCUDA/cuDNN version:\n8.0/5.1.10\nGPU model and memory:\nnvidia M40\nCPU\n32-cores\n\nDescribe the problem\nI profile the embedding_lookup_sparse on single machine with tfprof, in which i put the params on cpu. So the gather and scatter_sub Op are also put on cpu.\nProfiling result shows gather and scatter_sub Op takes so much time, the former takes about 33%, the latter takes about 43%. Making the gather op kernel to multi-thread gain about 10x speedup, relate to PR and 11709.\nFollow the same thought, I want to make the scatter_sub to be multi-thread.\n\nIf there is no duplicate index, we can realize lock-free code which could gain about 10x speedup too.\nIf there are duplicate indices, use lock which can gain little speedup.\n\nSo, I think an extra argument is_duplicated is a good choice to divide the two situation.\nHere is some profiling result:\ntfprof\n# orignial\nScatterSub                   8589.93MB (65.56%, 32.67%),       45.63ms (62.09%, 43.75%),            0us (45.25%, 0.00%),       45.63ms (62.90%, 45.87%)\n# with lock\nScatterSub                   8589.93MB (65.56%, 32.67%),       38.10ms (86.95%, 54.44%),            0us (48.97%, 0.00%),       38.10ms (89.98%, 58.78%)\n# without lock\nScatterSub                   8589.93MB (65.56%, 32.67%),        4.22ms (73.05%, 12.58%),            0us (48.86%, 0.00%),        4.22ms (76.99%, 14.63%)\n\nCode\nembedding_lookup_sparse", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nubuntu 16.04\r\n- **TenorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nv1.3.0-rc2\r\n- **Python version**: \r\n2.7\r\n- **Bazel version (if compiling from source)**:\r\n0.5.2\r\n- **CUDA/cuDNN version**:\r\n8.0/5.1.10\r\n- **GPU model and memory**:\r\nnvidia M40\r\n- **CPU**\r\n32-cores\r\n\r\n\r\n### Describe the problem\r\nI profile the `embedding_lookup_sparse` on single machine with tfprof, in which i put the `params` on cpu. So the `gather` and `scatter_sub` Op are also put on cpu.\r\nProfiling result shows `gather` and `scatter_sub` Op takes so much time, the former takes about 33%, the latter takes about 43%. Making the `gather` op kernel to multi-thread gain about 10x speedup, relate to [PR](https://github.com/tensorflow/tensorflow/pull/12246) and [11709](https://github.com/tensorflow/tensorflow/issues/11709).\r\nFollow the same thought, I want to make the `scatter_sub` to be multi-thread. \r\n- If there is no duplicate index, we can realize lock-free code which could gain about 10x speedup too. \r\n- If there are duplicate indices, use lock which can gain little speedup.\r\n\r\nSo, I think an extra argument `is_duplicated` is a good choice to divide the two situation.\r\n\r\nHere is some profiling result:\r\n### tfprof\r\n```\r\n# orignial\r\nScatterSub                   8589.93MB (65.56%, 32.67%),       45.63ms (62.09%, 43.75%),            0us (45.25%, 0.00%),       45.63ms (62.90%, 45.87%)\r\n# with lock\r\nScatterSub                   8589.93MB (65.56%, 32.67%),       38.10ms (86.95%, 54.44%),            0us (48.97%, 0.00%),       38.10ms (89.98%, 58.78%)\r\n# without lock\r\nScatterSub                   8589.93MB (65.56%, 32.67%),        4.22ms (73.05%, 12.58%),            0us (48.86%, 0.00%),        4.22ms (76.99%, 14.63%)\r\n```\r\n### Code\r\n[embedding_lookup_sparse](https://gist.github.com/nolanliou/c00af5938b2aecfdc5ea1189426b8624)"}