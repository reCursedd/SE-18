{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260549420", "html_url": "https://github.com/tensorflow/tensorflow/issues/5608#issuecomment-260549420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5608", "id": 260549420, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDU0OTQyMA==", "user": {"login": "DeNeutoy", "id": 16001974, "node_id": "MDQ6VXNlcjE2MDAxOTc0", "avatar_url": "https://avatars1.githubusercontent.com/u/16001974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeNeutoy", "html_url": "https://github.com/DeNeutoy", "followers_url": "https://api.github.com/users/DeNeutoy/followers", "following_url": "https://api.github.com/users/DeNeutoy/following{/other_user}", "gists_url": "https://api.github.com/users/DeNeutoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeNeutoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeNeutoy/subscriptions", "organizations_url": "https://api.github.com/users/DeNeutoy/orgs", "repos_url": "https://api.github.com/users/DeNeutoy/repos", "events_url": "https://api.github.com/users/DeNeutoy/events{/privacy}", "received_events_url": "https://api.github.com/users/DeNeutoy/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-15T05:14:32Z", "updated_at": "2016-11-15T05:37:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Another idea would be to use TensorArrays:</p>\n<p>As before:</p>\n<pre><code>\nwith tf.variable_scope(\"one_weight_to_rule_them_all\"):\n    large_weight = tf.get_variable(\"Wt\", [max_steps*input_size, output_size])\n\n# The clear_after_read variable must be False, otherwise the TA will \n# only allow you to read from that index once.\nweight_container = tf.TensorArray(tf.float32, max_steps, \n                             clear_after_read=False, dynamic_size=None)\n\n# This initialises the TensorArray with the weights broken up in to pieces.\n# The reason this has to be a TensorArray is so that we can index it with a tensor(!)\nweight_container = weight_container.unpack(large_weight)\n\n# Now inside the while_loop with a counter variable AND the \n# weight_container as a loop_var:\n\nweight_to_use = weight_container.read(counter)\n\n</code></pre>\n<p>Counter needs to be a integer scalar tensor which is incremented by one within the while_loop.</p>\n<p>Hope either of these ideas helps!</p>", "body_text": "Another idea would be to use TensorArrays:\nAs before:\n\nwith tf.variable_scope(\"one_weight_to_rule_them_all\"):\n    large_weight = tf.get_variable(\"Wt\", [max_steps*input_size, output_size])\n\n# The clear_after_read variable must be False, otherwise the TA will \n# only allow you to read from that index once.\nweight_container = tf.TensorArray(tf.float32, max_steps, \n                             clear_after_read=False, dynamic_size=None)\n\n# This initialises the TensorArray with the weights broken up in to pieces.\n# The reason this has to be a TensorArray is so that we can index it with a tensor(!)\nweight_container = weight_container.unpack(large_weight)\n\n# Now inside the while_loop with a counter variable AND the \n# weight_container as a loop_var:\n\nweight_to_use = weight_container.read(counter)\n\n\nCounter needs to be a integer scalar tensor which is incremented by one within the while_loop.\nHope either of these ideas helps!", "body": "Another idea would be to use TensorArrays:\n\nAs before:\n\n```\n\nwith tf.variable_scope(\"one_weight_to_rule_them_all\"):\n    large_weight = tf.get_variable(\"Wt\", [max_steps*input_size, output_size])\n\n# The clear_after_read variable must be False, otherwise the TA will \n# only allow you to read from that index once.\nweight_container = tf.TensorArray(tf.float32, max_steps, \n                             clear_after_read=False, dynamic_size=None)\n\n# This initialises the TensorArray with the weights broken up in to pieces.\n# The reason this has to be a TensorArray is so that we can index it with a tensor(!)\nweight_container = weight_container.unpack(large_weight)\n\n# Now inside the while_loop with a counter variable AND the \n# weight_container as a loop_var:\n\nweight_to_use = weight_container.read(counter)\n\n```\n\nCounter needs to be a integer scalar tensor which is incremented by one within the while_loop.\n\nHope either of these ideas helps!\n"}