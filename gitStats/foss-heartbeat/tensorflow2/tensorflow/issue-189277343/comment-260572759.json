{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260572759", "html_url": "https://github.com/tensorflow/tensorflow/issues/5608#issuecomment-260572759", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5608", "id": 260572759, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDU3Mjc1OQ==", "user": {"login": "ethancaballero", "id": 5994634, "node_id": "MDQ6VXNlcjU5OTQ2MzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5994634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethancaballero", "html_url": "https://github.com/ethancaballero", "followers_url": "https://api.github.com/users/ethancaballero/followers", "following_url": "https://api.github.com/users/ethancaballero/following{/other_user}", "gists_url": "https://api.github.com/users/ethancaballero/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethancaballero/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethancaballero/subscriptions", "organizations_url": "https://api.github.com/users/ethancaballero/orgs", "repos_url": "https://api.github.com/users/ethancaballero/repos", "events_url": "https://api.github.com/users/ethancaballero/events{/privacy}", "received_events_url": "https://api.github.com/users/ethancaballero/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-15T07:58:27Z", "updated_at": "2016-11-15T08:13:51Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16001974\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DeNeutoy\">@DeNeutoy</a> Thanks for the quick reply.</p>\n<p>^Does one of those ideas run faster than the other?</p>\n<p>Also, do you have any advice for dealing with asynchronous halting times within a batch. For example, if one member of batch decides to take 20 hops (which finishes slower) and the rest of the batch decides to take \u2264 3 hops (which finish quickly), the next batch can't be processed until the longer 20 hop member finishes.</p>\n<p>Was this your workaround, and is there a reason that the cost isn't fetched in the asynchronous version? :<br>\n<a href=\"https://github.com/DeNeutoy/act-rte-inference/blob/master/epoch.py#L108\">https://github.com/DeNeutoy/act-rte-inference/blob/master/epoch.py#L108</a></p>", "body_text": "@DeNeutoy Thanks for the quick reply.\n^Does one of those ideas run faster than the other?\nAlso, do you have any advice for dealing with asynchronous halting times within a batch. For example, if one member of batch decides to take 20 hops (which finishes slower) and the rest of the batch decides to take \u2264 3 hops (which finish quickly), the next batch can't be processed until the longer 20 hop member finishes.\nWas this your workaround, and is there a reason that the cost isn't fetched in the asynchronous version? :\nhttps://github.com/DeNeutoy/act-rte-inference/blob/master/epoch.py#L108", "body": "@DeNeutoy Thanks for the quick reply.\n\n^Does one of those ideas run faster than the other?\n\nAlso, do you have any advice for dealing with asynchronous halting times within a batch. For example, if one member of batch decides to take 20 hops (which finishes slower) and the rest of the batch decides to take \u2264 3 hops (which finish quickly), the next batch can't be processed until the longer 20 hop member finishes.\n\nWas this your workaround, and is there a reason that the cost isn't fetched in the asynchronous version? :\nhttps://github.com/DeNeutoy/act-rte-inference/blob/master/epoch.py#L108\n"}