{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14391", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14391/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14391/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14391/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14391", "id": 272445402, "node_id": "MDU6SXNzdWUyNzI0NDU0MDI=", "number": 14391, "title": "MonitoredTrainingSession does not initialize after restore", "user": {"login": "BastiaanBergman", "id": 478375, "node_id": "MDQ6VXNlcjQ3ODM3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/478375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BastiaanBergman", "html_url": "https://github.com/BastiaanBergman", "followers_url": "https://api.github.com/users/BastiaanBergman/followers", "following_url": "https://api.github.com/users/BastiaanBergman/following{/other_user}", "gists_url": "https://api.github.com/users/BastiaanBergman/gists{/gist_id}", "starred_url": "https://api.github.com/users/BastiaanBergman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BastiaanBergman/subscriptions", "organizations_url": "https://api.github.com/users/BastiaanBergman/orgs", "repos_url": "https://api.github.com/users/BastiaanBergman/repos", "events_url": "https://api.github.com/users/BastiaanBergman/events{/privacy}", "received_events_url": "https://api.github.com/users/BastiaanBergman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-09T05:31:44Z", "updated_at": "2018-02-02T09:19:02Z", "closed_at": "2017-11-09T16:56:50Z", "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p><code>local_init_op</code> can be passed to the SessionManager through the scaffold argument in MonitoredTrainingSession. From the doc's from session manager: The <code>local_init_op</code> is an <code>Operation</code> that is run always after a new session was created. This does not work as expected in the below example.</p>\n<h3>Exact command to reproduce</h3>\n<pre><code>global_step = tf.contrib.framework.get_or_create_global_step()\na1 = tf.Variable([1,2,3], name='a1')\na2 = tf.Variable([1,2,3], name='a2')\ntrain = tf.assign(global_step, global_step +1)\nsaver = tf.train.Saver(var_list=[a1],\n                        reshape = False,\n                        sharded = False,\n                        max_to_keep = 100,\n                        keep_checkpoint_every_n_hours = 10000.0,\n                        name = \"CheckpointSaver\",\n                        restore_sequentially = False,\n                        saver_def = None,\n                        builder = None,\n                        defer_build = False,\n                        allow_empty = False,\n                        write_version = tf.train.SaverDef.V2,\n                        pad_step_number = False,\n                        save_relative_paths = False)\nhooks = [tf.train.CheckpointSaverHook(checkpoint_dir = \"ckpt/\",\n                         save_secs = None,\n                         save_steps = 1,\n                         saver = saver,\n                         checkpoint_basename = 'model_to_test.ckpt',\n                         scaffold = None,\n                         listeners = None)]\nscaffold = tf.train.Scaffold(saver=saver, local_init_op = tf.variables_initializer([a2]))\nwith tf.train.MonitoredTrainingSession(master = '',\n                         is_chief = True,\n                         checkpoint_dir = \"ckpt/\",\n                         scaffold=scaffold,\n                         hooks = hooks,\n                         chief_only_hooks = [],\n                         save_checkpoint_secs=None,\n                         save_summaries_steps=None,\n                         save_summaries_secs=None,\n                         config=None,\n                         stop_grace_period_secs=120,\n                         log_step_count_steps=100) as mon_sess:\n    print(mon_sess.run(a1))\n    print(mon_sess.run(a2))\n    mon_sess.run(train)\n</code></pre>\n<p>The first time you run this, two variables <code>a1</code> and <code>a2</code> will be initialized by the implied (default) initializer from the <code>MonitoredTrainingSession</code> and a checkpoint file will be written to disk for only a1; expected behavior, no errors. The second time you run this, it should load a1 from the previous checkpoint and initialize <code>a2</code> through the <code>local_init_op</code> given through the scaffold. But it doesn't, instead:</p>\n<blockquote>\n<p>RuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: global_step, a2</p>\n</blockquote>\n<p>A hack that circumvents the problem by not using <code>local_init_op</code> is suggested here (as well as a reiteration of the expected behavior):<br>\n<a href=\"https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables\" rel=\"nofollow\">https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables</a></p>\n<h3>System information</h3>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n('v1.2.0-rc2-21-g12f033d', '1.2.0')</li>\n<li><strong>Python version</strong>:<br>\n2.7.10</li>\n</ul>", "body_text": "Describe the problem\nlocal_init_op can be passed to the SessionManager through the scaffold argument in MonitoredTrainingSession. From the doc's from session manager: The local_init_op is an Operation that is run always after a new session was created. This does not work as expected in the below example.\nExact command to reproduce\nglobal_step = tf.contrib.framework.get_or_create_global_step()\na1 = tf.Variable([1,2,3], name='a1')\na2 = tf.Variable([1,2,3], name='a2')\ntrain = tf.assign(global_step, global_step +1)\nsaver = tf.train.Saver(var_list=[a1],\n                        reshape = False,\n                        sharded = False,\n                        max_to_keep = 100,\n                        keep_checkpoint_every_n_hours = 10000.0,\n                        name = \"CheckpointSaver\",\n                        restore_sequentially = False,\n                        saver_def = None,\n                        builder = None,\n                        defer_build = False,\n                        allow_empty = False,\n                        write_version = tf.train.SaverDef.V2,\n                        pad_step_number = False,\n                        save_relative_paths = False)\nhooks = [tf.train.CheckpointSaverHook(checkpoint_dir = \"ckpt/\",\n                         save_secs = None,\n                         save_steps = 1,\n                         saver = saver,\n                         checkpoint_basename = 'model_to_test.ckpt',\n                         scaffold = None,\n                         listeners = None)]\nscaffold = tf.train.Scaffold(saver=saver, local_init_op = tf.variables_initializer([a2]))\nwith tf.train.MonitoredTrainingSession(master = '',\n                         is_chief = True,\n                         checkpoint_dir = \"ckpt/\",\n                         scaffold=scaffold,\n                         hooks = hooks,\n                         chief_only_hooks = [],\n                         save_checkpoint_secs=None,\n                         save_summaries_steps=None,\n                         save_summaries_secs=None,\n                         config=None,\n                         stop_grace_period_secs=120,\n                         log_step_count_steps=100) as mon_sess:\n    print(mon_sess.run(a1))\n    print(mon_sess.run(a2))\n    mon_sess.run(train)\n\nThe first time you run this, two variables a1 and a2 will be initialized by the implied (default) initializer from the MonitoredTrainingSession and a checkpoint file will be written to disk for only a1; expected behavior, no errors. The second time you run this, it should load a1 from the previous checkpoint and initialize a2 through the local_init_op given through the scaffold. But it doesn't, instead:\n\nRuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: global_step, a2\n\nA hack that circumvents the problem by not using local_init_op is suggested here (as well as a reiteration of the expected behavior):\nhttps://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables\nSystem information\n\nTensorFlow version (use command below):\n('v1.2.0-rc2-21-g12f033d', '1.2.0')\nPython version:\n2.7.10", "body": "### Describe the problem\r\n`local_init_op` can be passed to the SessionManager through the scaffold argument in MonitoredTrainingSession. From the doc's from session manager: The `local_init_op` is an `Operation` that is run always after a new session was created. This does not work as expected in the below example.\r\n\r\n### Exact command to reproduce\r\n```\r\nglobal_step = tf.contrib.framework.get_or_create_global_step()\r\na1 = tf.Variable([1,2,3], name='a1')\r\na2 = tf.Variable([1,2,3], name='a2')\r\ntrain = tf.assign(global_step, global_step +1)\r\nsaver = tf.train.Saver(var_list=[a1],\r\n                        reshape = False,\r\n                        sharded = False,\r\n                        max_to_keep = 100,\r\n                        keep_checkpoint_every_n_hours = 10000.0,\r\n                        name = \"CheckpointSaver\",\r\n                        restore_sequentially = False,\r\n                        saver_def = None,\r\n                        builder = None,\r\n                        defer_build = False,\r\n                        allow_empty = False,\r\n                        write_version = tf.train.SaverDef.V2,\r\n                        pad_step_number = False,\r\n                        save_relative_paths = False)\r\nhooks = [tf.train.CheckpointSaverHook(checkpoint_dir = \"ckpt/\",\r\n                         save_secs = None,\r\n                         save_steps = 1,\r\n                         saver = saver,\r\n                         checkpoint_basename = 'model_to_test.ckpt',\r\n                         scaffold = None,\r\n                         listeners = None)]\r\nscaffold = tf.train.Scaffold(saver=saver, local_init_op = tf.variables_initializer([a2]))\r\nwith tf.train.MonitoredTrainingSession(master = '',\r\n                         is_chief = True,\r\n                         checkpoint_dir = \"ckpt/\",\r\n                         scaffold=scaffold,\r\n                         hooks = hooks,\r\n                         chief_only_hooks = [],\r\n                         save_checkpoint_secs=None,\r\n                         save_summaries_steps=None,\r\n                         save_summaries_secs=None,\r\n                         config=None,\r\n                         stop_grace_period_secs=120,\r\n                         log_step_count_steps=100) as mon_sess:\r\n    print(mon_sess.run(a1))\r\n    print(mon_sess.run(a2))\r\n    mon_sess.run(train)\r\n```\r\nThe first time you run this, two variables `a1` and `a2` will be initialized by the implied (default) initializer from the `MonitoredTrainingSession` and a checkpoint file will be written to disk for only a1; expected behavior, no errors. The second time you run this, it should load a1 from the previous checkpoint and initialize `a2` through the `local_init_op` given through the scaffold. But it doesn't, instead: \r\n\r\n> RuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: global_step, a2\r\n\r\nA hack that circumvents the problem by not using `local_init_op` is suggested here (as well as a reiteration of the expected behavior):\r\nhttps://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables\r\n\r\n\r\n\r\n\r\n### System information\r\n- **TensorFlow version (use command below)**:\r\n('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **Python version**: \r\n2.7.10\r\n\r\n"}