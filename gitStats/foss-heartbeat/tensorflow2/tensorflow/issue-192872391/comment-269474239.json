{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269474239", "html_url": "https://github.com/tensorflow/tensorflow/issues/6011#issuecomment-269474239", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011", "id": 269474239, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTQ3NDIzOQ==", "user": {"login": "DrSleep", "id": 7841432, "node_id": "MDQ6VXNlcjc4NDE0MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7841432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DrSleep", "html_url": "https://github.com/DrSleep", "followers_url": "https://api.github.com/users/DrSleep/followers", "following_url": "https://api.github.com/users/DrSleep/following{/other_user}", "gists_url": "https://api.github.com/users/DrSleep/gists{/gist_id}", "starred_url": "https://api.github.com/users/DrSleep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DrSleep/subscriptions", "organizations_url": "https://api.github.com/users/DrSleep/orgs", "repos_url": "https://api.github.com/users/DrSleep/repos", "events_url": "https://api.github.com/users/DrSleep/events{/privacy}", "received_events_url": "https://api.github.com/users/DrSleep/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-28T13:03:28Z", "updated_at": "2016-12-28T13:03:28Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15608199\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/karlTUM\">@karlTUM</a>, you can try the code below:</p>\n<pre><code>def spp_layer2(input_, levels=[2, 1], name = 'SPP_layer'):\n    '''Multiple Level SPP layer.\n       Works for levels=[1, 2, 3, 6].'''\n    shape = input_.get_shape().as_list()\n    with tf.variable_scope(name):\n        pool_outputs = []\n        for l in levels:\n            pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1] * 1. / l).astype(np.int32), np.ceil(shape[2] * 1. / l).astype(np.int32), 1], \n                                      strides=[1, np.floor(shape[1] * 1. / l + 1).astype(np.int32), np.floor(shape[2] * 1. / l + 1), 1], \n                                      padding='SAME')\n            print \"Pool Level {:}: shape {:}\".format(l, pool.get_shape().as_list())\n            pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\n        spp_pool = tf.concat(1, pool_outputs)\n    return spp_pool\n</code></pre>\n<p>I haven't extensively tested it, but it outputs a vector of the same length (in case of <code>levels=[1, 2, 3, 6]</code>): <code>50=[1x1 + 2x2 + 3x3 + 6x6]x(channels)</code> for every input with each spatial dimension more (or equal) than <code>36=6x6</code>.</p>", "body_text": "@karlTUM, you can try the code below:\ndef spp_layer2(input_, levels=[2, 1], name = 'SPP_layer'):\n    '''Multiple Level SPP layer.\n       Works for levels=[1, 2, 3, 6].'''\n    shape = input_.get_shape().as_list()\n    with tf.variable_scope(name):\n        pool_outputs = []\n        for l in levels:\n            pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1] * 1. / l).astype(np.int32), np.ceil(shape[2] * 1. / l).astype(np.int32), 1], \n                                      strides=[1, np.floor(shape[1] * 1. / l + 1).astype(np.int32), np.floor(shape[2] * 1. / l + 1), 1], \n                                      padding='SAME')\n            print \"Pool Level {:}: shape {:}\".format(l, pool.get_shape().as_list())\n            pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\n        spp_pool = tf.concat(1, pool_outputs)\n    return spp_pool\n\nI haven't extensively tested it, but it outputs a vector of the same length (in case of levels=[1, 2, 3, 6]): 50=[1x1 + 2x2 + 3x3 + 6x6]x(channels) for every input with each spatial dimension more (or equal) than 36=6x6.", "body": "@karlTUM, you can try the code below:\r\n\r\n```\r\ndef spp_layer2(input_, levels=[2, 1], name = 'SPP_layer'):\r\n    '''Multiple Level SPP layer.\r\n       Works for levels=[1, 2, 3, 6].'''\r\n    shape = input_.get_shape().as_list()\r\n    with tf.variable_scope(name):\r\n        pool_outputs = []\r\n        for l in levels:\r\n            pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1] * 1. / l).astype(np.int32), np.ceil(shape[2] * 1. / l).astype(np.int32), 1], \r\n                                      strides=[1, np.floor(shape[1] * 1. / l + 1).astype(np.int32), np.floor(shape[2] * 1. / l + 1), 1], \r\n                                      padding='SAME')\r\n            print \"Pool Level {:}: shape {:}\".format(l, pool.get_shape().as_list())\r\n            pool_outputs.append(tf.reshape(pool, [shape[0], -1]))\r\n        spp_pool = tf.concat(1, pool_outputs)\r\n    return spp_pool\r\n```\r\n\r\nI haven't extensively tested it, but it outputs a vector of the same length (in case of `levels=[1, 2, 3, 6]`): `50=[1x1 + 2x2 + 3x3 + 6x6]x(channels)` for every input with each spatial dimension more (or equal) than `36=6x6`."}