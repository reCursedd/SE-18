{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6011", "id": 192872391, "node_id": "MDU6SXNzdWUxOTI4NzIzOTE=", "number": 6011, "title": "Is it possible to implement spatial pyramid pooling layer with tensorflow?", "user": {"login": "karlTUM", "id": 15608199, "node_id": "MDQ6VXNlcjE1NjA4MTk5", "avatar_url": "https://avatars2.githubusercontent.com/u/15608199?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karlTUM", "html_url": "https://github.com/karlTUM", "followers_url": "https://api.github.com/users/karlTUM/followers", "following_url": "https://api.github.com/users/karlTUM/following{/other_user}", "gists_url": "https://api.github.com/users/karlTUM/gists{/gist_id}", "starred_url": "https://api.github.com/users/karlTUM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karlTUM/subscriptions", "organizations_url": "https://api.github.com/users/karlTUM/orgs", "repos_url": "https://api.github.com/users/karlTUM/repos", "events_url": "https://api.github.com/users/karlTUM/events{/privacy}", "received_events_url": "https://api.github.com/users/karlTUM/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2016-12-01T15:10:47Z", "updated_at": "2018-06-05T17:47:03Z", "closed_at": "2017-06-16T19:07:20Z", "author_association": "NONE", "body_html": "<p>I would like to implement the spatial pyramid pooling layer as introduced <a href=\"https://arxiv.org/pdf/1406.4729v4.pdf\" rel=\"nofollow\">in this paper.</a><br>\nAs the paper setting, the keypoint is to define variant kernel size and stride size of max_pooling layer, which is:</p>\n<pre><code>kernel_size = ceil(a/n)\nstride_size = floor(a/n)\n</code></pre>\n<p>where <code>a</code> is the input tensor spatial size, and <code>n</code> is the pyramid level, i.e. spatial bins of the pooling output.</p>\n<p>I try to implement this layer with tensorflow, the code is:</p>\n<pre><code>def spp_layer(input_, name = 'SPP_layer'):\n    '''4 level spp layer \n    spatial bins: [6_6, 3_3, 2_2, 1_1] '''\n\n    shape = input_.get_shape().as_list()\n\n    with tf.variable_scope(name):\n\n        spp_6_6_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/6).astype(np.int32), np.ceil(shape[1]/6).astype(np.int32), 1], \n                                      strides=[1, shape[1]//6, shape[2]//6, 1], \n                                      padding='SAME')\n        print('SPP layer level 6:', spp_6_6_pool.get_shape().as_list())\n\n        spp_3_3_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/3).astype(np.int32), np.ceil(shape[2]/3).astype(np.int32), 1], \n                                      strides=[1, shape[1]//3, shape[2]//3, 1], \n                                      padding='SAME')\n        print('SPP layer level 3:', spp_3_3_pool.get_shape().as_list())\n\n        spp_2_2_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/2).astype(np.int32), np.ceil(shape[2]/2).astype(np.int32), 1], \n                                      strides=[1, shape[1]//2, shape[2]//2, 1], \n                                      padding='SAME')\n        print('SPP layer level 2:', spp_2_2_pool.get_shape().as_list())\n\n        spp_1_1_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/1).astype(np.int32), np.ceil(shape[2]/1).astype(np.int32), 1], \n                                      strides=[1, shape[1]//1, shape[2]//1, 1], \n                                      padding='SAME')\n        print('SPP layer level 1:', spp_1_1_pool.get_shape().as_list())\n\n\n        spp_6_6_pool_flat = tf.reshape(spp_6_6_pool, [shape[0], -1])\n        spp_3_3_pool_flat = tf.reshape(spp_3_3_pool, [shape[0], -1])\n        spp_2_2_pool_flat = tf.reshape(spp_2_2_pool, [shape[0], -1])\n        spp_1_1_pool_flat = tf.reshape(spp_1_1_pool, [shape[0], -1])\n\n        spp_pool = tf.concat(1, [spp_6_6_pool_flat, spp_3_3_pool_flat, spp_2_2_pool_flat, spp_1_1_pool_flat])\n\n    return spp_pool\n</code></pre>\n<p>But it cannot gurantee the same length pooling output, when the input sizes are different.</p>\n<p>Does tensorflow support the fixed length spatial pyramid pooling layer?</p>\n<p>I also post the question on the <a href=\"http://stackoverflow.com/questions/40913794/tensorflow-how-to-implement-the-fixed-length-spatial-pyramid-pooling-layer\" rel=\"nofollow\">stackoverflow</a>.</p>", "body_text": "I would like to implement the spatial pyramid pooling layer as introduced in this paper.\nAs the paper setting, the keypoint is to define variant kernel size and stride size of max_pooling layer, which is:\nkernel_size = ceil(a/n)\nstride_size = floor(a/n)\n\nwhere a is the input tensor spatial size, and n is the pyramid level, i.e. spatial bins of the pooling output.\nI try to implement this layer with tensorflow, the code is:\ndef spp_layer(input_, name = 'SPP_layer'):\n    '''4 level spp layer \n    spatial bins: [6_6, 3_3, 2_2, 1_1] '''\n\n    shape = input_.get_shape().as_list()\n\n    with tf.variable_scope(name):\n\n        spp_6_6_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/6).astype(np.int32), np.ceil(shape[1]/6).astype(np.int32), 1], \n                                      strides=[1, shape[1]//6, shape[2]//6, 1], \n                                      padding='SAME')\n        print('SPP layer level 6:', spp_6_6_pool.get_shape().as_list())\n\n        spp_3_3_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/3).astype(np.int32), np.ceil(shape[2]/3).astype(np.int32), 1], \n                                      strides=[1, shape[1]//3, shape[2]//3, 1], \n                                      padding='SAME')\n        print('SPP layer level 3:', spp_3_3_pool.get_shape().as_list())\n\n        spp_2_2_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/2).astype(np.int32), np.ceil(shape[2]/2).astype(np.int32), 1], \n                                      strides=[1, shape[1]//2, shape[2]//2, 1], \n                                      padding='SAME')\n        print('SPP layer level 2:', spp_2_2_pool.get_shape().as_list())\n\n        spp_1_1_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/1).astype(np.int32), np.ceil(shape[2]/1).astype(np.int32), 1], \n                                      strides=[1, shape[1]//1, shape[2]//1, 1], \n                                      padding='SAME')\n        print('SPP layer level 1:', spp_1_1_pool.get_shape().as_list())\n\n\n        spp_6_6_pool_flat = tf.reshape(spp_6_6_pool, [shape[0], -1])\n        spp_3_3_pool_flat = tf.reshape(spp_3_3_pool, [shape[0], -1])\n        spp_2_2_pool_flat = tf.reshape(spp_2_2_pool, [shape[0], -1])\n        spp_1_1_pool_flat = tf.reshape(spp_1_1_pool, [shape[0], -1])\n\n        spp_pool = tf.concat(1, [spp_6_6_pool_flat, spp_3_3_pool_flat, spp_2_2_pool_flat, spp_1_1_pool_flat])\n\n    return spp_pool\n\nBut it cannot gurantee the same length pooling output, when the input sizes are different.\nDoes tensorflow support the fixed length spatial pyramid pooling layer?\nI also post the question on the stackoverflow.", "body": "I would like to implement the spatial pyramid pooling layer as introduced [in this paper.](https://arxiv.org/pdf/1406.4729v4.pdf)\r\nAs the paper setting, the keypoint is to define variant kernel size and stride size of max_pooling layer, which is:\r\n```\r\nkernel_size = ceil(a/n)\r\nstride_size = floor(a/n)\r\n```\r\nwhere `a` is the input tensor spatial size, and `n` is the pyramid level, i.e. spatial bins of the pooling output.\r\n\r\nI try to implement this layer with tensorflow, the code is:\r\n\r\n```\r\ndef spp_layer(input_, name = 'SPP_layer'):\r\n    '''4 level spp layer \r\n    spatial bins: [6_6, 3_3, 2_2, 1_1] '''\r\n\r\n    shape = input_.get_shape().as_list()\r\n\r\n    with tf.variable_scope(name):\r\n\r\n        spp_6_6_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/6).astype(np.int32), np.ceil(shape[1]/6).astype(np.int32), 1], \r\n                                      strides=[1, shape[1]//6, shape[2]//6, 1], \r\n                                      padding='SAME')\r\n        print('SPP layer level 6:', spp_6_6_pool.get_shape().as_list())\r\n\r\n        spp_3_3_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/3).astype(np.int32), np.ceil(shape[2]/3).astype(np.int32), 1], \r\n                                      strides=[1, shape[1]//3, shape[2]//3, 1], \r\n                                      padding='SAME')\r\n        print('SPP layer level 3:', spp_3_3_pool.get_shape().as_list())\r\n\r\n        spp_2_2_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/2).astype(np.int32), np.ceil(shape[2]/2).astype(np.int32), 1], \r\n                                      strides=[1, shape[1]//2, shape[2]//2, 1], \r\n                                      padding='SAME')\r\n        print('SPP layer level 2:', spp_2_2_pool.get_shape().as_list())\r\n\r\n        spp_1_1_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/1).astype(np.int32), np.ceil(shape[2]/1).astype(np.int32), 1], \r\n                                      strides=[1, shape[1]//1, shape[2]//1, 1], \r\n                                      padding='SAME')\r\n        print('SPP layer level 1:', spp_1_1_pool.get_shape().as_list())\r\n\r\n\r\n        spp_6_6_pool_flat = tf.reshape(spp_6_6_pool, [shape[0], -1])\r\n        spp_3_3_pool_flat = tf.reshape(spp_3_3_pool, [shape[0], -1])\r\n        spp_2_2_pool_flat = tf.reshape(spp_2_2_pool, [shape[0], -1])\r\n        spp_1_1_pool_flat = tf.reshape(spp_1_1_pool, [shape[0], -1])\r\n\r\n        spp_pool = tf.concat(1, [spp_6_6_pool_flat, spp_3_3_pool_flat, spp_2_2_pool_flat, spp_1_1_pool_flat])\r\n\r\n    return spp_pool\r\n```\r\n\r\nBut it cannot gurantee the same length pooling output, when the input sizes are different.\r\n\r\nDoes tensorflow support the fixed length spatial pyramid pooling layer?\r\n\r\nI also post the question on the [stackoverflow](http://stackoverflow.com/questions/40913794/tensorflow-how-to-implement-the-fixed-length-spatial-pyramid-pooling-layer).\r\n\r\n\r\n"}