{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290720367", "html_url": "https://github.com/tensorflow/tensorflow/issues/6011#issuecomment-290720367", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6011", "id": 290720367, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDcyMDM2Nw==", "user": {"login": "RikHeijdens", "id": 7520719, "node_id": "MDQ6VXNlcjc1MjA3MTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/7520719?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RikHeijdens", "html_url": "https://github.com/RikHeijdens", "followers_url": "https://api.github.com/users/RikHeijdens/followers", "following_url": "https://api.github.com/users/RikHeijdens/following{/other_user}", "gists_url": "https://api.github.com/users/RikHeijdens/gists{/gist_id}", "starred_url": "https://api.github.com/users/RikHeijdens/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RikHeijdens/subscriptions", "organizations_url": "https://api.github.com/users/RikHeijdens/orgs", "repos_url": "https://api.github.com/users/RikHeijdens/repos", "events_url": "https://api.github.com/users/RikHeijdens/events{/privacy}", "received_events_url": "https://api.github.com/users/RikHeijdens/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-31T14:02:02Z", "updated_at": "2017-04-04T09:04:56Z", "author_association": "NONE", "body_html": "<p>I gave it a shot and tried to port the Lasagne implementation by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1473080\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/luizgh\">@luizgh</a> to TensorFlow:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">max_pool_2d_nxn_regions</span>(<span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">output_size</span>: <span class=\"pl-c1\">int</span>, <span class=\"pl-smi\">mode</span>: <span class=\"pl-c1\">str</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Performs a pooling operation that results in a fixed size:</span>\n<span class=\"pl-s\">    output_size x output_size.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Used by spatial_pyramid_pool. Refer to appendix A in [1].</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">        inputs: A 4D Tensor (B, H, W, C)</span>\n<span class=\"pl-s\">        output_size: The output size of the pooling operation.</span>\n<span class=\"pl-s\">        mode: The pooling mode {max, avg}</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">        A list of tensors, for each output bin.</span>\n<span class=\"pl-s\">        The list contains output_size * output_size elements, where</span>\n<span class=\"pl-s\">        each elment is a Tensor (N, C).</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">    References:</span>\n<span class=\"pl-s\">        [1] He, Kaiming et al (2015):</span>\n<span class=\"pl-s\">            Spatial Pyramid Pooling in Deep Convolutional Networks</span>\n<span class=\"pl-s\">            for Visual Recognition.</span>\n<span class=\"pl-s\">            https://arxiv.org/pdf/1406.4729.pdf.</span>\n<span class=\"pl-s\">            </span>\n<span class=\"pl-s\">    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    inputs_shape <span class=\"pl-k\">=</span> tf.shape(inputs)\n    h <span class=\"pl-k\">=</span> tf.cast(tf.gather(inputs_shape, <span class=\"pl-c1\">1</span>), tf.int32)\n    w <span class=\"pl-k\">=</span> tf.cast(tf.gather(inputs_shape, <span class=\"pl-c1\">2</span>), tf.int32)\n    \n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>max<span class=\"pl-pds\">'</span></span>:\n        pooling_op <span class=\"pl-k\">=</span> tf.reduce_max\n    <span class=\"pl-k\">elif</span> mode <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>avg<span class=\"pl-pds\">'</span></span>:\n        pooling_op <span class=\"pl-k\">=</span> tf.reduce_mean\n    <span class=\"pl-k\">else</span>:\n        msg <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Mode must be either 'max' or 'avg'. Got '<span class=\"pl-c1\">{0}</span>'<span class=\"pl-pds\">\"</span></span>\n        <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(msg.format(mode))\n        \n    result <span class=\"pl-k\">=</span> []\n    n <span class=\"pl-k\">=</span> output_size\n    <span class=\"pl-k\">for</span> row <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(output_size):\n        <span class=\"pl-k\">for</span> col <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(output_size):\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> start_h = floor(row / n * h)</span>\n            start_h <span class=\"pl-k\">=</span> tf.cast(tf.floor(tf.mul(tf.divide(row, n), tf.cast(h, tf.float32))), tf.int32)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> end_h = ceil((row + 1) / n * h)</span>\n            end_h <span class=\"pl-k\">=</span> tf.cast(tf.ceil(tf.mul(tf.divide((row <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>), n), tf.cast(h, tf.float32))), tf.int32)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> start_w = floor(col / n * w)</span>\n            start_w <span class=\"pl-k\">=</span> tf.cast(tf.floor(tf.mul(tf.divide(col, n), tf.cast(w, tf.float32))), tf.int32)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> end_w = ceil((col + 1) / n * w)</span>\n            end_w <span class=\"pl-k\">=</span> tf.cast(tf.ceil(tf.mul(tf.divide((col <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>), n), tf.cast(w, tf.float32))), tf.int32)\n            pooling_region <span class=\"pl-k\">=</span> inputs[:, start_h:end_h, start_w:end_w, :]\n            pool_result <span class=\"pl-k\">=</span> pooling_op(pooling_region, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>))\n            result.append(pool_result)\n    <span class=\"pl-k\">return</span> result\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">spatial_pyramid_pool</span>(<span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">dimensions</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>], <span class=\"pl-smi\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>max<span class=\"pl-pds\">'</span></span>, <span class=\"pl-smi\">implementation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>kaiming<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Performs spatial pyramid pooling (SPP) over the input.</span>\n<span class=\"pl-s\">    It will turn a 2D input of arbitrary size into an output of fixed</span>\n<span class=\"pl-s\">    dimenson.</span>\n<span class=\"pl-s\">    Hence, the convlutional part of a DNN can be connected to a dense part</span>\n<span class=\"pl-s\">    with a fixed number of nodes even if the dimensions of the input</span>\n<span class=\"pl-s\">    image are unknown.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    The pooling is performed over :math:`l` pooling levels.</span>\n<span class=\"pl-s\">    Each pooling level :math:`i` will create :math:`M_i` output features.</span>\n<span class=\"pl-s\">    :math:`M_i` is given by :math:`n_i * n_i`, with :math:`n_i` as the number</span>\n<span class=\"pl-s\">    of pooling operations per dimension level :math:`i`.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    The length of the parameter dimensions is the level of the spatial pyramid.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">        inputs: A 4D Tensor (B, H, W, C).</span>\n<span class=\"pl-s\">        dimensions: The list of :math:`n_i`'s that define the output dimension</span>\n<span class=\"pl-s\">        of each pooling level :math:`i`. The length of dimensions is the level of</span>\n<span class=\"pl-s\">        the spatial pyramid.</span>\n<span class=\"pl-s\">        mode: Pooling mode 'max' or 'avg'.</span>\n<span class=\"pl-s\">        implementation: The implementation to use, either 'kaiming' or 'fast'.</span>\n<span class=\"pl-s\">        kamming is the original implementation from the paper, and supports variable</span>\n<span class=\"pl-s\">        sizes of input vectors, which fast does not support.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">        A fixed length vector representing the inputs.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Notes:</span>\n<span class=\"pl-s\">        SPP should be inserted between the convolutional part of a DNN and it's</span>\n<span class=\"pl-s\">        dense part. Convolutions can be used for arbitrary input dimensions, but</span>\n<span class=\"pl-s\">        the size of their output will depend on their input dimensions.</span>\n<span class=\"pl-s\">        Connecting the output of the convolutional to the dense part then</span>\n<span class=\"pl-s\">        usually demands us to fix the dimensons of the network's input.</span>\n<span class=\"pl-s\">        The spatial pyramid pooling layer, however, allows us to leave </span>\n<span class=\"pl-s\">        the network input dimensions arbitrary. </span>\n<span class=\"pl-s\">        The advantage over a global pooling layer is the added robustness </span>\n<span class=\"pl-s\">        against object deformations due to the pooling on different scales.</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">    References:</span>\n<span class=\"pl-s\">        [1] He, Kaiming et al (2015):</span>\n<span class=\"pl-s\">            Spatial Pyramid Pooling in Deep Convolutional Networks</span>\n<span class=\"pl-s\">            for Visual Recognition.</span>\n<span class=\"pl-s\">            https://arxiv.org/pdf/1406.4729.pdf.</span>\n<span class=\"pl-s\">            </span>\n<span class=\"pl-s\">    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    pool_list <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">if</span> implementation <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>kaiming<span class=\"pl-pds\">'</span></span>:\n        <span class=\"pl-k\">for</span> pool_dim <span class=\"pl-k\">in</span> dimensions:\n            pool_list <span class=\"pl-k\">+=</span> max_pool_2d_nxn_regions(inputs, pool_dim, mode)\n    <span class=\"pl-k\">else</span>:\n        shape <span class=\"pl-k\">=</span> inputs.get_shape().as_list()\n        <span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> dimensions:\n            h <span class=\"pl-k\">=</span> shape[<span class=\"pl-c1\">1</span>]\n            w <span class=\"pl-k\">=</span> shape[<span class=\"pl-c1\">2</span>]\n            ph <span class=\"pl-k\">=</span> np.ceil(h <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> d).astype(np.int32)\n            pw <span class=\"pl-k\">=</span> np.ceil(w <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> d).astype(np.int32)\n            sh <span class=\"pl-k\">=</span> np.floor(h <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> d <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>).astype(np.int32)\n            sw <span class=\"pl-k\">=</span> np.floor(w <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> d <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>).astype(np.int32)\n            pool_result <span class=\"pl-k\">=</span> tf.nn.max_pool(inputs,\n                                         <span class=\"pl-v\">ksize</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, ph, pw, <span class=\"pl-c1\">1</span>], \n                                         <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, sh, sw, <span class=\"pl-c1\">1</span>],\n                                         <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n            pool_list.append(tf.reshape(pool_result, [tf.shape(inputs)[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]))\n    <span class=\"pl-k\">return</span> tf.concat(<span class=\"pl-c1\">1</span>, pool_list)</pre></div>", "body_text": "I gave it a shot and tried to port the Lasagne implementation by @luizgh to TensorFlow:\ndef max_pool_2d_nxn_regions(inputs, output_size: int, mode: str):\n    \"\"\"\n    Performs a pooling operation that results in a fixed size:\n    output_size x output_size.\n    \n    Used by spatial_pyramid_pool. Refer to appendix A in [1].\n    \n    Args:\n        inputs: A 4D Tensor (B, H, W, C)\n        output_size: The output size of the pooling operation.\n        mode: The pooling mode {max, avg}\n        \n    Returns:\n        A list of tensors, for each output bin.\n        The list contains output_size * output_size elements, where\n        each elment is a Tensor (N, C).\n        \n    References:\n        [1] He, Kaiming et al (2015):\n            Spatial Pyramid Pooling in Deep Convolutional Networks\n            for Visual Recognition.\n            https://arxiv.org/pdf/1406.4729.pdf.\n            \n    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c\n    \"\"\"\n    inputs_shape = tf.shape(inputs)\n    h = tf.cast(tf.gather(inputs_shape, 1), tf.int32)\n    w = tf.cast(tf.gather(inputs_shape, 2), tf.int32)\n    \n    if mode == 'max':\n        pooling_op = tf.reduce_max\n    elif mode == 'avg':\n        pooling_op = tf.reduce_mean\n    else:\n        msg = \"Mode must be either 'max' or 'avg'. Got '{0}'\"\n        raise ValueError(msg.format(mode))\n        \n    result = []\n    n = output_size\n    for row in range(output_size):\n        for col in range(output_size):\n            # start_h = floor(row / n * h)\n            start_h = tf.cast(tf.floor(tf.mul(tf.divide(row, n), tf.cast(h, tf.float32))), tf.int32)\n            # end_h = ceil((row + 1) / n * h)\n            end_h = tf.cast(tf.ceil(tf.mul(tf.divide((row + 1), n), tf.cast(h, tf.float32))), tf.int32)\n            # start_w = floor(col / n * w)\n            start_w = tf.cast(tf.floor(tf.mul(tf.divide(col, n), tf.cast(w, tf.float32))), tf.int32)\n            # end_w = ceil((col + 1) / n * w)\n            end_w = tf.cast(tf.ceil(tf.mul(tf.divide((col + 1), n), tf.cast(w, tf.float32))), tf.int32)\n            pooling_region = inputs[:, start_h:end_h, start_w:end_w, :]\n            pool_result = pooling_op(pooling_region, axis=(1, 2))\n            result.append(pool_result)\n    return result\n\ndef spatial_pyramid_pool(inputs, dimensions=[2,1], mode='max', implementation='kaiming'):\n    \"\"\"\n    Performs spatial pyramid pooling (SPP) over the input.\n    It will turn a 2D input of arbitrary size into an output of fixed\n    dimenson.\n    Hence, the convlutional part of a DNN can be connected to a dense part\n    with a fixed number of nodes even if the dimensions of the input\n    image are unknown.\n    \n    The pooling is performed over :math:`l` pooling levels.\n    Each pooling level :math:`i` will create :math:`M_i` output features.\n    :math:`M_i` is given by :math:`n_i * n_i`, with :math:`n_i` as the number\n    of pooling operations per dimension level :math:`i`.\n    \n    The length of the parameter dimensions is the level of the spatial pyramid.\n    \n    Args:\n        inputs: A 4D Tensor (B, H, W, C).\n        dimensions: The list of :math:`n_i`'s that define the output dimension\n        of each pooling level :math:`i`. The length of dimensions is the level of\n        the spatial pyramid.\n        mode: Pooling mode 'max' or 'avg'.\n        implementation: The implementation to use, either 'kaiming' or 'fast'.\n        kamming is the original implementation from the paper, and supports variable\n        sizes of input vectors, which fast does not support.\n    \n    Returns:\n        A fixed length vector representing the inputs.\n    \n    Notes:\n        SPP should be inserted between the convolutional part of a DNN and it's\n        dense part. Convolutions can be used for arbitrary input dimensions, but\n        the size of their output will depend on their input dimensions.\n        Connecting the output of the convolutional to the dense part then\n        usually demands us to fix the dimensons of the network's input.\n        The spatial pyramid pooling layer, however, allows us to leave \n        the network input dimensions arbitrary. \n        The advantage over a global pooling layer is the added robustness \n        against object deformations due to the pooling on different scales.\n        \n    References:\n        [1] He, Kaiming et al (2015):\n            Spatial Pyramid Pooling in Deep Convolutional Networks\n            for Visual Recognition.\n            https://arxiv.org/pdf/1406.4729.pdf.\n            \n    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c\n    \"\"\"\n    pool_list = []\n    if implementation == 'kaiming':\n        for pool_dim in dimensions:\n            pool_list += max_pool_2d_nxn_regions(inputs, pool_dim, mode)\n    else:\n        shape = inputs.get_shape().as_list()\n        for d in dimensions:\n            h = shape[1]\n            w = shape[2]\n            ph = np.ceil(h * 1.0 / d).astype(np.int32)\n            pw = np.ceil(w * 1.0 / d).astype(np.int32)\n            sh = np.floor(h * 1.0 / d + 1).astype(np.int32)\n            sw = np.floor(w * 1.0 / d + 1).astype(np.int32)\n            pool_result = tf.nn.max_pool(inputs,\n                                         ksize=[1, ph, pw, 1], \n                                         strides=[1, sh, sw, 1],\n                                         padding='SAME')\n            pool_list.append(tf.reshape(pool_result, [tf.shape(inputs)[0], -1]))\n    return tf.concat(1, pool_list)", "body": "I gave it a shot and tried to port the Lasagne implementation by @luizgh to TensorFlow:\r\n\r\n```python\r\ndef max_pool_2d_nxn_regions(inputs, output_size: int, mode: str):\r\n    \"\"\"\r\n    Performs a pooling operation that results in a fixed size:\r\n    output_size x output_size.\r\n    \r\n    Used by spatial_pyramid_pool. Refer to appendix A in [1].\r\n    \r\n    Args:\r\n        inputs: A 4D Tensor (B, H, W, C)\r\n        output_size: The output size of the pooling operation.\r\n        mode: The pooling mode {max, avg}\r\n        \r\n    Returns:\r\n        A list of tensors, for each output bin.\r\n        The list contains output_size * output_size elements, where\r\n        each elment is a Tensor (N, C).\r\n        \r\n    References:\r\n        [1] He, Kaiming et al (2015):\r\n            Spatial Pyramid Pooling in Deep Convolutional Networks\r\n            for Visual Recognition.\r\n            https://arxiv.org/pdf/1406.4729.pdf.\r\n            \r\n    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c\r\n    \"\"\"\r\n    inputs_shape = tf.shape(inputs)\r\n    h = tf.cast(tf.gather(inputs_shape, 1), tf.int32)\r\n    w = tf.cast(tf.gather(inputs_shape, 2), tf.int32)\r\n    \r\n    if mode == 'max':\r\n        pooling_op = tf.reduce_max\r\n    elif mode == 'avg':\r\n        pooling_op = tf.reduce_mean\r\n    else:\r\n        msg = \"Mode must be either 'max' or 'avg'. Got '{0}'\"\r\n        raise ValueError(msg.format(mode))\r\n        \r\n    result = []\r\n    n = output_size\r\n    for row in range(output_size):\r\n        for col in range(output_size):\r\n            # start_h = floor(row / n * h)\r\n            start_h = tf.cast(tf.floor(tf.mul(tf.divide(row, n), tf.cast(h, tf.float32))), tf.int32)\r\n            # end_h = ceil((row + 1) / n * h)\r\n            end_h = tf.cast(tf.ceil(tf.mul(tf.divide((row + 1), n), tf.cast(h, tf.float32))), tf.int32)\r\n            # start_w = floor(col / n * w)\r\n            start_w = tf.cast(tf.floor(tf.mul(tf.divide(col, n), tf.cast(w, tf.float32))), tf.int32)\r\n            # end_w = ceil((col + 1) / n * w)\r\n            end_w = tf.cast(tf.ceil(tf.mul(tf.divide((col + 1), n), tf.cast(w, tf.float32))), tf.int32)\r\n            pooling_region = inputs[:, start_h:end_h, start_w:end_w, :]\r\n            pool_result = pooling_op(pooling_region, axis=(1, 2))\r\n            result.append(pool_result)\r\n    return result\r\n\r\ndef spatial_pyramid_pool(inputs, dimensions=[2,1], mode='max', implementation='kaiming'):\r\n    \"\"\"\r\n    Performs spatial pyramid pooling (SPP) over the input.\r\n    It will turn a 2D input of arbitrary size into an output of fixed\r\n    dimenson.\r\n    Hence, the convlutional part of a DNN can be connected to a dense part\r\n    with a fixed number of nodes even if the dimensions of the input\r\n    image are unknown.\r\n    \r\n    The pooling is performed over :math:`l` pooling levels.\r\n    Each pooling level :math:`i` will create :math:`M_i` output features.\r\n    :math:`M_i` is given by :math:`n_i * n_i`, with :math:`n_i` as the number\r\n    of pooling operations per dimension level :math:`i`.\r\n    \r\n    The length of the parameter dimensions is the level of the spatial pyramid.\r\n    \r\n    Args:\r\n        inputs: A 4D Tensor (B, H, W, C).\r\n        dimensions: The list of :math:`n_i`'s that define the output dimension\r\n        of each pooling level :math:`i`. The length of dimensions is the level of\r\n        the spatial pyramid.\r\n        mode: Pooling mode 'max' or 'avg'.\r\n        implementation: The implementation to use, either 'kaiming' or 'fast'.\r\n        kamming is the original implementation from the paper, and supports variable\r\n        sizes of input vectors, which fast does not support.\r\n    \r\n    Returns:\r\n        A fixed length vector representing the inputs.\r\n    \r\n    Notes:\r\n        SPP should be inserted between the convolutional part of a DNN and it's\r\n        dense part. Convolutions can be used for arbitrary input dimensions, but\r\n        the size of their output will depend on their input dimensions.\r\n        Connecting the output of the convolutional to the dense part then\r\n        usually demands us to fix the dimensons of the network's input.\r\n        The spatial pyramid pooling layer, however, allows us to leave \r\n        the network input dimensions arbitrary. \r\n        The advantage over a global pooling layer is the added robustness \r\n        against object deformations due to the pooling on different scales.\r\n        \r\n    References:\r\n        [1] He, Kaiming et al (2015):\r\n            Spatial Pyramid Pooling in Deep Convolutional Networks\r\n            for Visual Recognition.\r\n            https://arxiv.org/pdf/1406.4729.pdf.\r\n            \r\n    Ported from: https://github.com/luizgh/Lasagne/commit/c01e3d922a5712ca4c54617a15a794c23746ac8c\r\n    \"\"\"\r\n    pool_list = []\r\n    if implementation == 'kaiming':\r\n        for pool_dim in dimensions:\r\n            pool_list += max_pool_2d_nxn_regions(inputs, pool_dim, mode)\r\n    else:\r\n        shape = inputs.get_shape().as_list()\r\n        for d in dimensions:\r\n            h = shape[1]\r\n            w = shape[2]\r\n            ph = np.ceil(h * 1.0 / d).astype(np.int32)\r\n            pw = np.ceil(w * 1.0 / d).astype(np.int32)\r\n            sh = np.floor(h * 1.0 / d + 1).astype(np.int32)\r\n            sw = np.floor(w * 1.0 / d + 1).astype(np.int32)\r\n            pool_result = tf.nn.max_pool(inputs,\r\n                                         ksize=[1, ph, pw, 1], \r\n                                         strides=[1, sh, sw, 1],\r\n                                         padding='SAME')\r\n            pool_list.append(tf.reshape(pool_result, [tf.shape(inputs)[0], -1]))\r\n    return tf.concat(1, pool_list)\r\n```"}