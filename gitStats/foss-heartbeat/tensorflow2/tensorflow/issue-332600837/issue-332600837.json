{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20042", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20042/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20042/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20042/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20042", "id": 332600837, "node_id": "MDU6SXNzdWUzMzI2MDA4Mzc=", "number": 20042, "title": "Failed to convert to Tensorflow Lite - TensorFlowMax, TensorFlowMinimum, TensorFlowSum not supported", "user": {"login": "lun0522", "id": 24245729, "node_id": "MDQ6VXNlcjI0MjQ1NzI5", "avatar_url": "https://avatars0.githubusercontent.com/u/24245729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lun0522", "html_url": "https://github.com/lun0522", "followers_url": "https://api.github.com/users/lun0522/followers", "following_url": "https://api.github.com/users/lun0522/following{/other_user}", "gists_url": "https://api.github.com/users/lun0522/gists{/gist_id}", "starred_url": "https://api.github.com/users/lun0522/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lun0522/subscriptions", "organizations_url": "https://api.github.com/users/lun0522/orgs", "repos_url": "https://api.github.com/users/lun0522/repos", "events_url": "https://api.github.com/users/lun0522/events{/privacy}", "received_events_url": "https://api.github.com/users/lun0522/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-06-14T23:43:35Z", "updated_at": "2018-06-22T03:56:47Z", "closed_at": "2018-06-15T17:29:11Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS 10.13.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8.0</li>\n<li><strong>Python version</strong>: 3.6.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.14.0-homebrew</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Apple LLVM version 9.1.0 (clang-902.0.39.2)</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=.tfmodel --output_file=/Users/plun/Downloads/mobilenet_v2.tflite --input_shape=1,224,224,3 --input_array=input_1 --output_array=reshape_2/Reshape --inference_type=FLOAT</li>\n</ul>\n<p>I am trying to convert a MobileNetV2 model to Tensorflow Lite. I was able to convert the model here: <a href=\"https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models\">https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models</a>, but when I try to convert a model trained by myself using Keras, the following error occurs:</p>\n<p>\"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: <strong>TensorFlowMax</strong>, <strong>TensorFlowMinimum</strong>, <strong>TensorFlowSum</strong>.\"</p>\n<p>I ran <code>convert_variables_to_constants</code> to freeze the model, and <code> bazel-bin/tensorflow/contrib/lite/toco/toco</code> to do conversion. I inspected the structure of the frozen graph, and found that TensorFlowMax, TensorFlowMinimum, TensorFlowSum are in relu layers and softmax layer. Are they really unsupported yet, or did I miss some steps?</p>\n<p>Complete console output:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/24245729/41443425-9e22e676-6ff1-11e8-90eb-583c9e209698.png\"><img src=\"https://user-images.githubusercontent.com/24245729/41443425-9e22e676-6ff1-11e8-90eb-583c9e209698.png\" alt=\"screen shot 2018-06-14 at 4 39 54 pm\" style=\"max-width:100%;\"></a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.4\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.8.0\nPython version: 3.6.5\nBazel version (if compiling from source): 0.14.0-homebrew\nGCC/Compiler version (if compiling from source): Apple LLVM version 9.1.0 (clang-902.0.39.2)\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=.tfmodel --output_file=/Users/plun/Downloads/mobilenet_v2.tflite --input_shape=1,224,224,3 --input_array=input_1 --output_array=reshape_2/Reshape --inference_type=FLOAT\n\nI am trying to convert a MobileNetV2 model to Tensorflow Lite. I was able to convert the model here: https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models, but when I try to convert a model trained by myself using Keras, the following error occurs:\n\"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMax, TensorFlowMinimum, TensorFlowSum.\"\nI ran convert_variables_to_constants to freeze the model, and  bazel-bin/tensorflow/contrib/lite/toco/toco to do conversion. I inspected the structure of the frozen graph, and found that TensorFlowMax, TensorFlowMinimum, TensorFlowSum are in relu layers and softmax layer. Are they really unsupported yet, or did I miss some steps?\nComplete console output:", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.4\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.14.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=.tfmodel --output_file=/Users/plun/Downloads/mobilenet_v2.tflite --input_shape=1,224,224,3 --input_array=input_1 --output_array=reshape_2/Reshape --inference_type=FLOAT\r\n\r\nI am trying to convert a MobileNetV2 model to Tensorflow Lite. I was able to convert the model here: https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models, but when I try to convert a model trained by myself using Keras, the following error occurs:\r\n\r\n\"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: **TensorFlowMax**, **TensorFlowMinimum**, **TensorFlowSum**.\"\r\n\r\nI ran `convert_variables_to_constants` to freeze the model, and ` bazel-bin/tensorflow/contrib/lite/toco/toco` to do conversion. I inspected the structure of the frozen graph, and found that TensorFlowMax, TensorFlowMinimum, TensorFlowSum are in relu layers and softmax layer. Are they really unsupported yet, or did I miss some steps?\r\n\r\nComplete console output:\r\n![screen shot 2018-06-14 at 4 39 54 pm](https://user-images.githubusercontent.com/24245729/41443425-9e22e676-6ff1-11e8-90eb-583c9e209698.png)\r\n"}