{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224076777", "html_url": "https://github.com/tensorflow/tensorflow/issues/916#issuecomment-224076777", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/916", "id": 224076777, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDA3Njc3Nw==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-06T20:24:27Z", "updated_at": "2016-06-06T20:24:27Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Using TensorFlow with other frameworks is a bit tricky, since there are many places assuming it has exclusive access to the GPU. So disables GPU functionalities in one of them sounds reasonable.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=456665\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kbrems\">@kbrems</a>, with your use case, it is not recommended to use TensorFlow operators in the same thread as other Cuda runtime calls. TensorFlow uses stream-executor a faster Cuda runtime alternative. If standard Cuda runtime APIs is called on the same context, it confuses stream-executor with what context is bound to what thread, and many of its internal data structure.</p>\n<p>If you have to make Cuda calls, either:</p>\n<ol>\n<li>Call the stream-executor alternative.</li>\n<li>Call the Cuda driver API similar to what stream-executor does, and make sure you restore the context binding after you are done.</li>\n</ol>", "body_text": "Using TensorFlow with other frameworks is a bit tricky, since there are many places assuming it has exclusive access to the GPU. So disables GPU functionalities in one of them sounds reasonable.\n@kbrems, with your use case, it is not recommended to use TensorFlow operators in the same thread as other Cuda runtime calls. TensorFlow uses stream-executor a faster Cuda runtime alternative. If standard Cuda runtime APIs is called on the same context, it confuses stream-executor with what context is bound to what thread, and many of its internal data structure.\nIf you have to make Cuda calls, either:\n\nCall the stream-executor alternative.\nCall the Cuda driver API similar to what stream-executor does, and make sure you restore the context binding after you are done.", "body": "Using TensorFlow with other frameworks is a bit tricky, since there are many places assuming it has exclusive access to the GPU. So disables GPU functionalities in one of them sounds reasonable. \n\n@kbrems, with your use case, it is not recommended to use TensorFlow operators in the same thread as other Cuda runtime calls. TensorFlow uses stream-executor a faster Cuda runtime alternative. If standard Cuda runtime APIs is called on the same context, it confuses stream-executor with what context is bound to what thread, and many of its internal data structure. \n\nIf you have to make Cuda calls, either: \n1. Call the stream-executor alternative. \n2. Call the Cuda driver API similar to what stream-executor does, and make sure you restore the context binding after you are done. \n"}