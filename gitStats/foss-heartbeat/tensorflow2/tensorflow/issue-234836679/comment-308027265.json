{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/308027265", "html_url": "https://github.com/tensorflow/tensorflow/issues/10597#issuecomment-308027265", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10597", "id": 308027265, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODAyNzI2NQ==", "user": {"login": "Scitator", "id": 7606451, "node_id": "MDQ6VXNlcjc2MDY0NTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7606451?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Scitator", "html_url": "https://github.com/Scitator", "followers_url": "https://api.github.com/users/Scitator/followers", "following_url": "https://api.github.com/users/Scitator/following{/other_user}", "gists_url": "https://api.github.com/users/Scitator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Scitator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Scitator/subscriptions", "organizations_url": "https://api.github.com/users/Scitator/orgs", "repos_url": "https://api.github.com/users/Scitator/repos", "events_url": "https://api.github.com/users/Scitator/events{/privacy}", "received_events_url": "https://api.github.com/users/Scitator/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-13T07:08:33Z", "updated_at": "2017-06-13T07:20:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=577277\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinwicke\">@martinwicke</a> Thanks, now I understand. <strong>And it's not a bug, it's a feature :)</strong><br>\nPython generator cannot be used from several threads, so the best way to give each thread it own one.<br>\nBut now we have an issue, when the data from threads is the same. For me, I solve it through adding a thread number parameter in <code>generator_input_fn</code> and split data correctly in it. <a href=\"https://github.com/Scitator/rstools/blob/master/rstools/tf/data_iterator.py\">link</a>.<br>\nAs I understand TF source code, it uses different seeds to prevent such same data yielding. Although, it only set it for python random, strange a bit. Looks like all this done for better code reusing, or it really works correctly....need to test.</p>\n<p>Nevertheless, I cannot understand such loss explosion. But still, thanks for help.</p>\n<p>PS. Also update <a href=\"https://gist.github.com/Scitator/184c8d676f36a9b7c04fb504d9088590\">notebook</a> with simple solution. (still need to test memory usage with large data, but should work)</p>", "body_text": "@martinwicke Thanks, now I understand. And it's not a bug, it's a feature :)\nPython generator cannot be used from several threads, so the best way to give each thread it own one.\nBut now we have an issue, when the data from threads is the same. For me, I solve it through adding a thread number parameter in generator_input_fn and split data correctly in it. link.\nAs I understand TF source code, it uses different seeds to prevent such same data yielding. Although, it only set it for python random, strange a bit. Looks like all this done for better code reusing, or it really works correctly....need to test.\nNevertheless, I cannot understand such loss explosion. But still, thanks for help.\nPS. Also update notebook with simple solution. (still need to test memory usage with large data, but should work)", "body": "@martinwicke Thanks, now I understand. **And it's not a bug, it's a feature :)**\r\nPython generator cannot be used from several threads, so the best way to give each thread it own one.\r\nBut now we have an issue, when the data from threads is the same. For me, I solve it through adding a thread number parameter in `generator_input_fn` and split data correctly in it. [link](https://github.com/Scitator/rstools/blob/master/rstools/tf/data_iterator.py). \r\nAs I understand TF source code, it uses different seeds to prevent such same data yielding. Although, it only set it for python random, strange a bit. Looks like all this done for better code reusing, or it really works correctly....need to test.\r\n\r\nNevertheless, I cannot understand such loss explosion. But still, thanks for help.\r\n\r\nPS. Also update [notebook](https://gist.github.com/Scitator/184c8d676f36a9b7c04fb504d9088590) with simple solution. (still need to test memory usage with large data, but should work)"}