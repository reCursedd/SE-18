{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227892455", "html_url": "https://github.com/tensorflow/tensorflow/issues/2840#issuecomment-227892455", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2840", "id": 227892455, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzg5MjQ1NQ==", "user": {"login": "mhng1580", "id": 5089625, "node_id": "MDQ6VXNlcjUwODk2MjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/5089625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhng1580", "html_url": "https://github.com/mhng1580", "followers_url": "https://api.github.com/users/mhng1580/followers", "following_url": "https://api.github.com/users/mhng1580/following{/other_user}", "gists_url": "https://api.github.com/users/mhng1580/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhng1580/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhng1580/subscriptions", "organizations_url": "https://api.github.com/users/mhng1580/orgs", "repos_url": "https://api.github.com/users/mhng1580/repos", "events_url": "https://api.github.com/users/mhng1580/events{/privacy}", "received_events_url": "https://api.github.com/users/mhng1580/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-22T22:08:15Z", "updated_at": "2016-06-22T22:08:15Z", "author_association": "NONE", "body_html": "<p>Hi there,</p>\n<p>I think I get the similar error as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5229267\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MInner\">@MInner</a><br>\nAlso, this happens on only when I run on a 6G GPU. The program works normally on a 12G GPU card.<br>\nIt would be great if there's any followup.<br>\nHere's my debug output and backtrace</p>\n<pre><code>Starting program: /data/sls/scratch/wnhsu/pyenv_tf/r08/bin/python dnn_train_galebc2_debug.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n[New Thread 0x7fffd82e6700 (LWP 9747)]\n[New Thread 0x7fffd7ae5700 (LWP 9748)]\n[New Thread 0x7fffd52e4700 (LWP 9749)]\n[New Thread 0x7fffd2ae3700 (LWP 9750)]\n[New Thread 0x7fffd02e2700 (LWP 9751)]\n[New Thread 0x7fffcdae1700 (LWP 9752)]\n[New Thread 0x7fffcb2e0700 (LWP 9753)]\n[Thread 0x7fffd7ae5700 (LWP 9748) exited]\n[Thread 0x7fffd52e4700 (LWP 9749) exited]\n[Thread 0x7fffd82e6700 (LWP 9747) exited]\n[Thread 0x7fffcdae1700 (LWP 9752) exited]\n[Thread 0x7fffd02e2700 (LWP 9751) exited]\n[Thread 0x7fffd2ae3700 (LWP 9750) exited]\n[Thread 0x7fffcb2e0700 (LWP 9753) exited]\nbuilding DNN model with 5 hidden layers of 1024 hidden units\nbuilding train_op with constant learning rate 0.001\nLoading data into memory...\nali-to-post ark:- ark:- \nali-to-pdf /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/final.mdl 'ark:gunzip -c /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/ali.*.gz |' ark:- \nLOG (ali-to-pdf:main():ali-to-pdf.cc:68) Converted 76184 alignments to pdf sequences.\nLOG (ali-to-post:main():ali-to-post.cc:65) Converted 76184 alignments.\n   7804 utterances loaded...\n   avg-sequence-len = 608\n[New Thread 0x7fffcb2e0700 (LWP 9764)]\n[New Thread 0x7fffcdae1700 (LWP 9765)]\n[New Thread 0x7fffd02e2700 (LWP 9766)]\n[New Thread 0x7fffd2ae3700 (LWP 9767)]\n[New Thread 0x7fffa9dda700 (LWP 9768)]\n[New Thread 0x7fffa95d9700 (LWP 9769)]\n[New Thread 0x7fffa8dd8700 (LWP 9770)]\n[New Thread 0x7fffa5484700 (LWP 9771)]\n[New Thread 0x7fffa4c83700 (LWP 9772)]\n[Thread 0x7fffa4c83700 (LWP 9772) exited]\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n(gdb) backtrace\n#0  0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#1  0x00007fffed40e258 in tensorflow::GPUMachineManager() () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#2  0x00007fffed40c4d0 in tensorflow::BaseGPUDeviceFactory::GetValidDeviceIds(std::vector&lt;int, std::allocator&lt;int&gt; &gt;*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#3  0x00007fffed40cd50 in tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&amp;, std::string const&amp;, std::vector&lt;tensorflow::Device*, std::allocator&lt;tensorflow::Device*&gt; &gt;*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#4  0x00007fffed5e50d6 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&amp;, std::string const&amp;, std::vector&lt;tensorflow::Device*, std::allocator&lt;tensorflow::Device*&gt; &gt;*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#5  0x00007fffed3d0b71 in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&amp;) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#6  0x00007fffed6076d7 in tensorflow::NewSession(tensorflow::SessionOptions const&amp;, tensorflow::Session**) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#7  0x00007fffed5d60e1 in TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#8  0x00007fffec839c3b in _wrap_TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#9  0x000000000049968d in PyEval_EvalFrameEx ()\n#10 0x00000000004a090c in PyEval_EvalCodeEx ()\n#11 0x0000000000499a52 in PyEval_EvalFrameEx ()\n#12 0x00000000004a1c9a in ?? ()\n#13 0x00000000004dfe94 in ?? ()\n#14 0x0000000000505f96 in PyObject_Call ()\n#15 0x00000000004de41a in ?? ()\n#16 0x00000000005039eb in ?? ()\n#17 0x0000000000499be5 in PyEval_EvalFrameEx ()\n#18 0x00000000004a090c in PyEval_EvalCodeEx ()\n#19 0x000000000049ab45 in PyEval_EvalFrameEx ()\n#20 0x00000000004a1634 in ?? ()\n#21 0x000000000044e4a5 in PyRun_FileExFlags ()\n#22 0x000000000044ec9f in PyRun_SimpleFileExFlags ()\n#23 0x000000000044f904 in Py_Main ()\n#24 0x00007ffff7818f45 in __libc_start_main (main=0x44f9c2 &lt;main&gt;, argc=2, argv=0x7fffffffd3b8, init=&lt;optimized out&gt;, fini=&lt;optimized out&gt;, rtld_fini=&lt;optimized out&gt;, stack_end=0x7fffffffd3a8)\n    at libc-start.c:287\n#25 0x0000000000578c4e in _start ()\n</code></pre>", "body_text": "Hi there,\nI think I get the similar error as @MInner\nAlso, this happens on only when I run on a 6G GPU. The program works normally on a 12G GPU card.\nIt would be great if there's any followup.\nHere's my debug output and backtrace\nStarting program: /data/sls/scratch/wnhsu/pyenv_tf/r08/bin/python dnn_train_galebc2_debug.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n[New Thread 0x7fffd82e6700 (LWP 9747)]\n[New Thread 0x7fffd7ae5700 (LWP 9748)]\n[New Thread 0x7fffd52e4700 (LWP 9749)]\n[New Thread 0x7fffd2ae3700 (LWP 9750)]\n[New Thread 0x7fffd02e2700 (LWP 9751)]\n[New Thread 0x7fffcdae1700 (LWP 9752)]\n[New Thread 0x7fffcb2e0700 (LWP 9753)]\n[Thread 0x7fffd7ae5700 (LWP 9748) exited]\n[Thread 0x7fffd52e4700 (LWP 9749) exited]\n[Thread 0x7fffd82e6700 (LWP 9747) exited]\n[Thread 0x7fffcdae1700 (LWP 9752) exited]\n[Thread 0x7fffd02e2700 (LWP 9751) exited]\n[Thread 0x7fffd2ae3700 (LWP 9750) exited]\n[Thread 0x7fffcb2e0700 (LWP 9753) exited]\nbuilding DNN model with 5 hidden layers of 1024 hidden units\nbuilding train_op with constant learning rate 0.001\nLoading data into memory...\nali-to-post ark:- ark:- \nali-to-pdf /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/final.mdl 'ark:gunzip -c /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/ali.*.gz |' ark:- \nLOG (ali-to-pdf:main():ali-to-pdf.cc:68) Converted 76184 alignments to pdf sequences.\nLOG (ali-to-post:main():ali-to-post.cc:65) Converted 76184 alignments.\n   7804 utterances loaded...\n   avg-sequence-len = 608\n[New Thread 0x7fffcb2e0700 (LWP 9764)]\n[New Thread 0x7fffcdae1700 (LWP 9765)]\n[New Thread 0x7fffd02e2700 (LWP 9766)]\n[New Thread 0x7fffd2ae3700 (LWP 9767)]\n[New Thread 0x7fffa9dda700 (LWP 9768)]\n[New Thread 0x7fffa95d9700 (LWP 9769)]\n[New Thread 0x7fffa8dd8700 (LWP 9770)]\n[New Thread 0x7fffa5484700 (LWP 9771)]\n[New Thread 0x7fffa4c83700 (LWP 9772)]\n[Thread 0x7fffa4c83700 (LWP 9772) exited]\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n(gdb) backtrace\n#0  0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#1  0x00007fffed40e258 in tensorflow::GPUMachineManager() () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#2  0x00007fffed40c4d0 in tensorflow::BaseGPUDeviceFactory::GetValidDeviceIds(std::vector<int, std::allocator<int> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#3  0x00007fffed40cd50 in tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#4  0x00007fffed5e50d6 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#5  0x00007fffed3d0b71 in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#6  0x00007fffed6076d7 in tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#7  0x00007fffed5d60e1 in TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#8  0x00007fffec839c3b in _wrap_TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#9  0x000000000049968d in PyEval_EvalFrameEx ()\n#10 0x00000000004a090c in PyEval_EvalCodeEx ()\n#11 0x0000000000499a52 in PyEval_EvalFrameEx ()\n#12 0x00000000004a1c9a in ?? ()\n#13 0x00000000004dfe94 in ?? ()\n#14 0x0000000000505f96 in PyObject_Call ()\n#15 0x00000000004de41a in ?? ()\n#16 0x00000000005039eb in ?? ()\n#17 0x0000000000499be5 in PyEval_EvalFrameEx ()\n#18 0x00000000004a090c in PyEval_EvalCodeEx ()\n#19 0x000000000049ab45 in PyEval_EvalFrameEx ()\n#20 0x00000000004a1634 in ?? ()\n#21 0x000000000044e4a5 in PyRun_FileExFlags ()\n#22 0x000000000044ec9f in PyRun_SimpleFileExFlags ()\n#23 0x000000000044f904 in Py_Main ()\n#24 0x00007ffff7818f45 in __libc_start_main (main=0x44f9c2 <main>, argc=2, argv=0x7fffffffd3b8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffd3a8)\n    at libc-start.c:287\n#25 0x0000000000578c4e in _start ()", "body": "Hi there,\n\nI think I get the similar error as @MInner\nAlso, this happens on only when I run on a 6G GPU. The program works normally on a 12G GPU card. \nIt would be great if there's any followup. \nHere's my debug output and backtrace\n\n```\nStarting program: /data/sls/scratch/wnhsu/pyenv_tf/r08/bin/python dnn_train_galebc2_debug.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n[New Thread 0x7fffd82e6700 (LWP 9747)]\n[New Thread 0x7fffd7ae5700 (LWP 9748)]\n[New Thread 0x7fffd52e4700 (LWP 9749)]\n[New Thread 0x7fffd2ae3700 (LWP 9750)]\n[New Thread 0x7fffd02e2700 (LWP 9751)]\n[New Thread 0x7fffcdae1700 (LWP 9752)]\n[New Thread 0x7fffcb2e0700 (LWP 9753)]\n[Thread 0x7fffd7ae5700 (LWP 9748) exited]\n[Thread 0x7fffd52e4700 (LWP 9749) exited]\n[Thread 0x7fffd82e6700 (LWP 9747) exited]\n[Thread 0x7fffcdae1700 (LWP 9752) exited]\n[Thread 0x7fffd02e2700 (LWP 9751) exited]\n[Thread 0x7fffd2ae3700 (LWP 9750) exited]\n[Thread 0x7fffcb2e0700 (LWP 9753) exited]\nbuilding DNN model with 5 hidden layers of 1024 hidden units\nbuilding train_op with constant learning rate 0.001\nLoading data into memory...\nali-to-post ark:- ark:- \nali-to-pdf /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/final.mdl 'ark:gunzip -c /data/sls/scratch/wnhsu/gale_mandarin_bc_phase2/exp/tri3b_dnn_2048x5_ali/ali.*.gz |' ark:- \nLOG (ali-to-pdf:main():ali-to-pdf.cc:68) Converted 76184 alignments to pdf sequences.\nLOG (ali-to-post:main():ali-to-post.cc:65) Converted 76184 alignments.\n   7804 utterances loaded...\n   avg-sequence-len = 608\n[New Thread 0x7fffcb2e0700 (LWP 9764)]\n[New Thread 0x7fffcdae1700 (LWP 9765)]\n[New Thread 0x7fffd02e2700 (LWP 9766)]\n[New Thread 0x7fffd2ae3700 (LWP 9767)]\n[New Thread 0x7fffa9dda700 (LWP 9768)]\n[New Thread 0x7fffa95d9700 (LWP 9769)]\n[New Thread 0x7fffa8dd8700 (LWP 9770)]\n[New Thread 0x7fffa5484700 (LWP 9771)]\n[New Thread 0x7fffa4c83700 (LWP 9772)]\n[Thread 0x7fffa4c83700 (LWP 9772) exited]\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n(gdb) backtrace\n#0  0x00007fffed6730b8 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#1  0x00007fffed40e258 in tensorflow::GPUMachineManager() () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#2  0x00007fffed40c4d0 in tensorflow::BaseGPUDeviceFactory::GetValidDeviceIds(std::vector<int, std::allocator<int> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#3  0x00007fffed40cd50 in tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#4  0x00007fffed5e50d6 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> >*) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#5  0x00007fffed3d0b71 in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#6  0x00007fffed6076d7 in tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) ()\n   from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#7  0x00007fffed5d60e1 in TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#8  0x00007fffec839c3b in _wrap_TF_NewSession () from /data/sls/scratch/wnhsu/pyenv_tf/r08/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#9  0x000000000049968d in PyEval_EvalFrameEx ()\n#10 0x00000000004a090c in PyEval_EvalCodeEx ()\n#11 0x0000000000499a52 in PyEval_EvalFrameEx ()\n#12 0x00000000004a1c9a in ?? ()\n#13 0x00000000004dfe94 in ?? ()\n#14 0x0000000000505f96 in PyObject_Call ()\n#15 0x00000000004de41a in ?? ()\n#16 0x00000000005039eb in ?? ()\n#17 0x0000000000499be5 in PyEval_EvalFrameEx ()\n#18 0x00000000004a090c in PyEval_EvalCodeEx ()\n#19 0x000000000049ab45 in PyEval_EvalFrameEx ()\n#20 0x00000000004a1634 in ?? ()\n#21 0x000000000044e4a5 in PyRun_FileExFlags ()\n#22 0x000000000044ec9f in PyRun_SimpleFileExFlags ()\n#23 0x000000000044f904 in Py_Main ()\n#24 0x00007ffff7818f45 in __libc_start_main (main=0x44f9c2 <main>, argc=2, argv=0x7fffffffd3b8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffd3a8)\n    at libc-start.c:287\n#25 0x0000000000578c4e in _start ()\n```\n"}