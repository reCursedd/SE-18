{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12694", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12694/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12694/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12694/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12694", "id": 253845246, "node_id": "MDU6SXNzdWUyNTM4NDUyNDY=", "number": 12694, "title": "queue skips first few elements under multiple enqueue threads", "user": {"login": "sunziping2016", "id": 8998546, "node_id": "MDQ6VXNlcjg5OTg1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8998546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunziping2016", "html_url": "https://github.com/sunziping2016", "followers_url": "https://api.github.com/users/sunziping2016/followers", "following_url": "https://api.github.com/users/sunziping2016/following{/other_user}", "gists_url": "https://api.github.com/users/sunziping2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunziping2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunziping2016/subscriptions", "organizations_url": "https://api.github.com/users/sunziping2016/orgs", "repos_url": "https://api.github.com/users/sunziping2016/repos", "events_url": "https://api.github.com/users/sunziping2016/events{/privacy}", "received_events_url": "https://api.github.com/users/sunziping2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2017-08-30T00:42:35Z", "updated_at": "2017-09-04T15:43:09Z", "closed_at": "2017-09-04T15:43:09Z", "author_association": "NONE", "body_html": "<h3>Possible problems</h3>\n<p>I want to use <code>tf.slice_input_producer</code> to produce a list of filenames, and then use multiple threads to load data and feed it to a <code>tf.FIFOQueue</code>. It seems first few elements have been skipped unexpectedly.</p>\n<p>It only happens when there exist multiple enqueue threads.</p>\n<p>I have searched the web, and only find one similar question on <code>stackoverflow.com</code> with zero answer.<br>\n<a href=\"https://stackoverflow.com/questions/44725917/tensorflow-train-batch-skip-3-examples\" rel=\"nofollow\">https://stackoverflow.com/questions/44725917/tensorflow-train-batch-skip-3-examples</a></p>\n<p>Sorry for creating this issue. Maybe I missed something. However, I really feel deeply puzzled about this and tried a lot to solve this.</p>\n<h3>Minimum reproducible example</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\na, <span class=\"pl-k\">=</span> tf.train.slice_input_producer([tf.range(<span class=\"pl-c1\">100</span>)], <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nq <span class=\"pl-k\">=</span> tf.FIFOQueue(<span class=\"pl-c1\">32</span>, [tf.int32], <span class=\"pl-v\">shapes</span><span class=\"pl-k\">=</span>[[]])\ntf.train.queue_runner.add_queue_runner(\n    tf.train.queue_runner.QueueRunner(q, [q.enqueue([a])] <span class=\"pl-k\">*</span> <span class=\"pl-c1\">8</span>)\n)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    tf.train.start_queue_runners(<span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess)\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n        <span class=\"pl-c1\">print</span>(sess.run(q.dequeue()))</pre></div>\n<h3>Expected output</h3>\n<p>Some reordering may take place, but roughly, the programs count from 0 to 99.</p>\n<h3>Actual output</h3>\n<pre><code>7\n8\n9\n...\n96\n97\n98\n99\n0\n1\n2\n3\n4\n5\n6\n</code></pre>\n<h3>System information</h3>\n<p>My TensorFlow is installed from <code>pip install tensorflow-gpu --user</code> the day before yesterday.</p>\n<ul>\n<li>System: ArchLinux x86_64</li>\n<li>CUDA: V8.0.61</li>\n<li>Python: 3.6.2</li>\n<li>GPU: GTX 860M (2G memory)</li>\n<li>CPU: i7-4710MQ (4 cores 8 threads)</li>\n</ul>\n<pre><code>== cat /etc/issue ===============================================\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\nLSB_VERSION=1.4\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (GCC) 7.1.1 20170630\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.2)\ntensorflow (1.3.0)\ntensorflow-gpu (1.3.0)\ntensorflow-tensorboard (0.1.5)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/lib/nvidia:/usr/lib32/nvidia:/usr/lib:/usr/lib32:/usr/lib:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Aug 30 08:42:01 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 860M    Off  | 00000000:01:00.0 Off |                  N/A |\n| N/A   53C    P0    N/A /  N/A |      5MiB /  2002MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      4172    G   /usr/lib/xorg-server/Xorg                        4MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n</code></pre>", "body_text": "Possible problems\nI want to use tf.slice_input_producer to produce a list of filenames, and then use multiple threads to load data and feed it to a tf.FIFOQueue. It seems first few elements have been skipped unexpectedly.\nIt only happens when there exist multiple enqueue threads.\nI have searched the web, and only find one similar question on stackoverflow.com with zero answer.\nhttps://stackoverflow.com/questions/44725917/tensorflow-train-batch-skip-3-examples\nSorry for creating this issue. Maybe I missed something. However, I really feel deeply puzzled about this and tried a lot to solve this.\nMinimum reproducible example\nimport tensorflow as tf\n\na, = tf.train.slice_input_producer([tf.range(100)], shuffle=False)\nq = tf.FIFOQueue(32, [tf.int32], shapes=[[]])\ntf.train.queue_runner.add_queue_runner(\n    tf.train.queue_runner.QueueRunner(q, [q.enqueue([a])] * 8)\n)\nwith tf.Session() as sess:\n    tf.train.start_queue_runners(sess=sess)\n    for _ in range(100):\n        print(sess.run(q.dequeue()))\nExpected output\nSome reordering may take place, but roughly, the programs count from 0 to 99.\nActual output\n7\n8\n9\n...\n96\n97\n98\n99\n0\n1\n2\n3\n4\n5\n6\n\nSystem information\nMy TensorFlow is installed from pip install tensorflow-gpu --user the day before yesterday.\n\nSystem: ArchLinux x86_64\nCUDA: V8.0.61\nPython: 3.6.2\nGPU: GTX 860M (2G memory)\nCPU: i7-4710MQ (4 cores 8 threads)\n\n== cat /etc/issue ===============================================\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\nLSB_VERSION=1.4\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (GCC) 7.1.1 20170630\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.2)\ntensorflow (1.3.0)\ntensorflow-gpu (1.3.0)\ntensorflow-tensorboard (0.1.5)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/lib/nvidia:/usr/lib32/nvidia:/usr/lib:/usr/lib32:/usr/lib:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Aug 30 08:42:01 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 860M    Off  | 00000000:01:00.0 Off |                  N/A |\n| N/A   53C    P0    N/A /  N/A |      5MiB /  2002MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      4172    G   /usr/lib/xorg-server/Xorg                        4MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================", "body": "### Possible problems\r\nI want to use `tf.slice_input_producer` to produce a list of filenames, and then use multiple threads to load data and feed it to a `tf.FIFOQueue`. It seems first few elements have been skipped unexpectedly.\r\n\r\nIt only happens when there exist multiple enqueue threads.\r\n\r\nI have searched the web, and only find one similar question on `stackoverflow.com` with zero answer.\r\nhttps://stackoverflow.com/questions/44725917/tensorflow-train-batch-skip-3-examples\r\n\r\nSorry for creating this issue. Maybe I missed something. However, I really feel deeply puzzled about this and tried a lot to solve this.\r\n\r\n### Minimum reproducible example\r\n```python\r\nimport tensorflow as tf\r\n\r\na, = tf.train.slice_input_producer([tf.range(100)], shuffle=False)\r\nq = tf.FIFOQueue(32, [tf.int32], shapes=[[]])\r\ntf.train.queue_runner.add_queue_runner(\r\n    tf.train.queue_runner.QueueRunner(q, [q.enqueue([a])] * 8)\r\n)\r\nwith tf.Session() as sess:\r\n    tf.train.start_queue_runners(sess=sess)\r\n    for _ in range(100):\r\n        print(sess.run(q.dequeue()))\r\n```\r\n\r\n### Expected output\r\nSome reordering may take place, but roughly, the programs count from 0 to 99.\r\n\r\n### Actual output\r\n```\r\n7\r\n8\r\n9\r\n...\r\n96\r\n97\r\n98\r\n99\r\n0\r\n1\r\n2\r\n3\r\n4\r\n5\r\n6\r\n```\r\n\r\n### System information\r\nMy TensorFlow is installed from `pip install tensorflow-gpu --user` the day before yesterday.\r\n* System: ArchLinux x86_64\r\n* CUDA: V8.0.61\r\n* Python: 3.6.2\r\n* GPU: GTX 860M (2G memory)\r\n* CPU: i7-4710MQ (4 cores 8 threads)\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\r\nLSB_VERSION=1.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 7.1.1 20170630\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux archlinux-sun 4.12.8-2-ARCH #1 SMP PREEMPT Fri Aug 18 14:08:02 UTC 2017 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.2)\r\ntensorflow (1.3.0)\r\ntensorflow-gpu (1.3.0)\r\ntensorflow-tensorboard (0.1.5)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/lib/nvidia:/usr/lib32/nvidia:/usr/lib:/usr/lib32:/usr/lib:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Aug 30 08:42:01 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 860M    Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   53C    P0    N/A /  N/A |      5MiB /  2002MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      4172    G   /usr/lib/xorg-server/Xorg                        4MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n```"}