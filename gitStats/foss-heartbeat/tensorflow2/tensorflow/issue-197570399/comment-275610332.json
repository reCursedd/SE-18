{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275610332", "html_url": "https://github.com/tensorflow/tensorflow/pull/6498#issuecomment-275610332", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6498", "id": 275610332, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTYxMDMzMg==", "user": {"login": "raviqqe", "id": 9584358, "node_id": "MDQ6VXNlcjk1ODQzNTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/9584358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raviqqe", "html_url": "https://github.com/raviqqe", "followers_url": "https://api.github.com/users/raviqqe/followers", "following_url": "https://api.github.com/users/raviqqe/following{/other_user}", "gists_url": "https://api.github.com/users/raviqqe/gists{/gist_id}", "starred_url": "https://api.github.com/users/raviqqe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raviqqe/subscriptions", "organizations_url": "https://api.github.com/users/raviqqe/orgs", "repos_url": "https://api.github.com/users/raviqqe/repos", "events_url": "https://api.github.com/users/raviqqe/events{/privacy}", "received_events_url": "https://api.github.com/users/raviqqe/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-27T08:08:59Z", "updated_at": "2017-01-27T08:20:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1217238\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shoyer\">@shoyer</a> Sorry for being dumb for a while.<br>\nI run <a href=\"https://gist.github.com/raviqqe/50c34493c07e2973d88ed9ca05888c42\">a benchmark test</a> which incorporates <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a>'s opinion. As a result, it seems to be reasonable to keep current behavior of the update op.</p>\n<p>But, I have no idea about why it shows such significant speed difference. I thought that <code>tf.shape()</code> just reads some metadata in a <code>tf.Tensor</code> object and therefore it needs little computation cost.</p>\n<pre lang=\"ipython\"><code>In [1]: from strm_concat_op_bench import *\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/l\nib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n\n... (omitted)\n\nIn [3]: %time exec_update()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -&gt; (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n6400\nCPU times: user 325 ms, sys: 97.6 ms, total: 423 ms\nWall time: 458 ms\n\nIn [4]: %time exec_update_and_calc_len()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -&gt; (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n[6400, 6336]\nCPU times: user 2.77 s, sys: 252 ms, total: 3.02 s\nWall time: 3.17 s\n</code></pre>", "body_text": "@drpngx @shoyer Sorry for being dumb for a while.\nI run a benchmark test which incorporates @drpngx's opinion. As a result, it seems to be reasonable to keep current behavior of the update op.\nBut, I have no idea about why it shows such significant speed difference. I thought that tf.shape() just reads some metadata in a tf.Tensor object and therefore it needs little computation cost.\nIn [1]: from strm_concat_op_bench import *\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/l\nib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n\n... (omitted)\n\nIn [3]: %time exec_update()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n6400\nCPU times: user 325 ms, sys: 97.6 ms, total: 423 ms\nWall time: 458 ms\n\nIn [4]: %time exec_update_and_calc_len()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n[6400, 6336]\nCPU times: user 2.77 s, sys: 252 ms, total: 3.02 s\nWall time: 3.17 s", "body": "@drpngx @shoyer Sorry for being dumb for a while.\r\nI run [a benchmark test](https://gist.github.com/raviqqe/50c34493c07e2973d88ed9ca05888c42) which incorporates @drpngx's opinion. As a result, it seems to be reasonable to keep current behavior of the update op.\r\n\r\nBut, I have no idea about why it shows such significant speed difference. I thought that `tf.shape()` just reads some metadata in a `tf.Tensor` object and therefore it needs little computation cost.\r\n\r\n```ipython\r\nIn [1]: from strm_concat_op_bench import *\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/l\r\nib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n\r\n... (omitted)\r\n\r\nIn [3]: %time exec_update()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n6400\r\nCPU times: user 325 ms, sys: 97.6 ms, total: 423 ms\r\nWall time: 458 ms\r\n\r\nIn [4]: %time exec_update_and_calc_len()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n[6400, 6336]\r\nCPU times: user 2.77 s, sys: 252 ms, total: 3.02 s\r\nWall time: 3.17 s\r\n```"}