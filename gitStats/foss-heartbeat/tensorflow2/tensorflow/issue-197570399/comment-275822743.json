{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275822743", "html_url": "https://github.com/tensorflow/tensorflow/pull/6498#issuecomment-275822743", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6498", "id": 275822743, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTgyMjc0Mw==", "user": {"login": "raviqqe", "id": 9584358, "node_id": "MDQ6VXNlcjk1ODQzNTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/9584358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raviqqe", "html_url": "https://github.com/raviqqe", "followers_url": "https://api.github.com/users/raviqqe/followers", "following_url": "https://api.github.com/users/raviqqe/following{/other_user}", "gists_url": "https://api.github.com/users/raviqqe/gists{/gist_id}", "starred_url": "https://api.github.com/users/raviqqe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raviqqe/subscriptions", "organizations_url": "https://api.github.com/users/raviqqe/orgs", "repos_url": "https://api.github.com/users/raviqqe/repos", "events_url": "https://api.github.com/users/raviqqe/events{/privacy}", "received_events_url": "https://api.github.com/users/raviqqe/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-28T02:59:43Z", "updated_at": "2017-01-28T03:02:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> Sorry. My benchmark code was wrong. <a href=\"https://gist.github.com/raviqqe/b3cd26119a9e108e03bed089903b0e79\">This</a> is the fixed version and the following is its result.<br>\nThere is no difference between returning length by the update op and calculating it from <code>tf.Tensor</code> in terms of computational cost. But, we may need to check their memory usage difference.</p>\n<pre><code>$ ipython3 -i fixed_strm_concat_op_bench.py\nPython 3.4.3 (default, Aug  9 2016, 15:36:17) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 3.2.1 -- An enhanced Interactive Python.\n?         -&gt; Introduction and overview of IPython's features.\n%quickref -&gt; Quick reference.\nhelp      -&gt; Python's own help system.\nobject?   -&gt; Details about 'object', use 'object??' for extra details.\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n\n... (omitted)\n\nIn [2]: %time exec_update()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -&gt; (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n6400\nCPU times: user 397 ms, sys: 42 ms, total: 439 ms\nWall time: 396 ms\n\nIn [3]: %time exec_update_and_calc_len()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -&gt; (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n[6400, 6336]\nCPU times: user 353 ms, sys: 43 ms, total: 396 ms\nWall time: 361 ms\n</code></pre>", "body_text": "@drpngx Sorry. My benchmark code was wrong. This is the fixed version and the following is its result.\nThere is no difference between returning length by the update op and calculating it from tf.Tensor in terms of computational cost. But, we may need to check their memory usage difference.\n$ ipython3 -i fixed_strm_concat_op_bench.py\nPython 3.4.3 (default, Aug  9 2016, 15:36:17) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 3.2.1 -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n\n... (omitted)\n\nIn [2]: %time exec_update()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n6400\nCPU times: user 397 ms, sys: 42 ms, total: 439 ms\nWall time: 396 ms\n\nIn [3]: %time exec_update_and_calc_len()\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n[6400, 6336]\nCPU times: user 353 ms, sys: 43 ms, total: 396 ms\nWall time: 361 ms", "body": "@drpngx Sorry. My benchmark code was wrong. [This](https://gist.github.com/raviqqe/b3cd26119a9e108e03bed089903b0e79) is the fixed version and the following is its result.\r\nThere is no difference between returning length by the update op and calculating it from `tf.Tensor` in terms of computational cost. But, we may need to check their memory usage difference.\r\n\r\n```\r\n$ ipython3 -i fixed_strm_concat_op_bench.py\r\nPython 3.4.3 (default, Aug  9 2016, 15:36:17) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 3.2.1 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n\r\n... (omitted)\r\n\r\nIn [2]: %time exec_update()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n6400\r\nCPU times: user 397 ms, sys: 42 ms, total: 439 ms\r\nWall time: 396 ms\r\n\r\nIn [3]: %time exec_update_and_calc_len()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n[6400, 6336]\r\nCPU times: user 353 ms, sys: 43 ms, total: 396 ms\r\nWall time: 361 ms\r\n```"}