{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/272730205", "html_url": "https://github.com/tensorflow/tensorflow/pull/6498#issuecomment-272730205", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6498", "id": 272730205, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjczMDIwNQ==", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-15T22:09:54Z", "updated_at": "2017-01-15T22:09:54Z", "author_association": "MEMBER", "body_html": "<p>It looks like it could indeed make a significant difference in speed:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = np.random.randn(64, 1000).astype(np.float32)\nph = tf.placeholder(tf.float32, (64, 1000))\nvalue, update = tf.contrib.metrics.streaming_concat(ph)\n</code></pre>\n<p>The existing code, which doesn't return the value from tensorflow as part of the update op:</p>\n<pre><code>%%time\nsess = tf.Session()\nsess.run(tf.initialize_local_variables())\nfor i in range(500):\n  sess.run(update, feed_dict={ph: x})\nprint sess.run(value).shape\n</code></pre>\n<pre><code>(32000, 1000)\nCPU times: user 2.46 s, sys: 1.04 s, total: 3.5 s\nWall time: 691 ms\n</code></pre>\n<p>vs the same code, running <code>value</code> at each step:</p>\n<pre><code>%%time\nsess = tf.Session()\nsess.run(tf.initialize_local_variables())\nfor i in range(500):\n  sess.run([update, value], feed_dict={ph: x})\nprint sess.run(value).shape\n</code></pre>\n<pre><code>(32000, 1000)\nCPU times: user 8.98 s, sys: 8.48 s, total: 17.5 s\nWall time: 15.3 s\n</code></pre>\n<p>Based on my experiments, it returning <code>value</code> at the same time as <code>update</code> changes the run-time from linear to quadratic in terms of the number of update operations. This could be because copying the tensor into NumPy entails a copy and/or because running the ops to slice and transpose the variable does a copy. In either case, it looks like returning the concatenated tensor as part of the update is a non-starter with the current version of TensorFlow.</p>", "body_text": "It looks like it could indeed make a significant difference in speed:\nimport tensorflow as tf\nimport numpy as np\n\nx = np.random.randn(64, 1000).astype(np.float32)\nph = tf.placeholder(tf.float32, (64, 1000))\nvalue, update = tf.contrib.metrics.streaming_concat(ph)\n\nThe existing code, which doesn't return the value from tensorflow as part of the update op:\n%%time\nsess = tf.Session()\nsess.run(tf.initialize_local_variables())\nfor i in range(500):\n  sess.run(update, feed_dict={ph: x})\nprint sess.run(value).shape\n\n(32000, 1000)\nCPU times: user 2.46 s, sys: 1.04 s, total: 3.5 s\nWall time: 691 ms\n\nvs the same code, running value at each step:\n%%time\nsess = tf.Session()\nsess.run(tf.initialize_local_variables())\nfor i in range(500):\n  sess.run([update, value], feed_dict={ph: x})\nprint sess.run(value).shape\n\n(32000, 1000)\nCPU times: user 8.98 s, sys: 8.48 s, total: 17.5 s\nWall time: 15.3 s\n\nBased on my experiments, it returning value at the same time as update changes the run-time from linear to quadratic in terms of the number of update operations. This could be because copying the tensor into NumPy entails a copy and/or because running the ops to slice and transpose the variable does a copy. In either case, it looks like returning the concatenated tensor as part of the update is a non-starter with the current version of TensorFlow.", "body": "It looks like it could indeed make a significant difference in speed:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = np.random.randn(64, 1000).astype(np.float32)\r\nph = tf.placeholder(tf.float32, (64, 1000))\r\nvalue, update = tf.contrib.metrics.streaming_concat(ph)\r\n```\r\n\r\nThe existing code, which doesn't return the value from tensorflow as part of the update op:\r\n```\r\n%%time\r\nsess = tf.Session()\r\nsess.run(tf.initialize_local_variables())\r\nfor i in range(500):\r\n  sess.run(update, feed_dict={ph: x})\r\nprint sess.run(value).shape\r\n```\r\n```\r\n(32000, 1000)\r\nCPU times: user 2.46 s, sys: 1.04 s, total: 3.5 s\r\nWall time: 691 ms\r\n```\r\nvs the same code, running `value` at each step:\r\n```\r\n%%time\r\nsess = tf.Session()\r\nsess.run(tf.initialize_local_variables())\r\nfor i in range(500):\r\n  sess.run([update, value], feed_dict={ph: x})\r\nprint sess.run(value).shape\r\n```\r\n```\r\n(32000, 1000)\r\nCPU times: user 8.98 s, sys: 8.48 s, total: 17.5 s\r\nWall time: 15.3 s\r\n```\r\n\r\nBased on my experiments, it returning `value` at the same time as `update` changes the run-time from linear to quadratic in terms of the number of update operations. This could be because copying the tensor into NumPy entails a copy and/or because running the ops to slice and transpose the variable does a copy. In either case, it looks like returning the concatenated tensor as part of the update is a non-starter with the current version of TensorFlow."}