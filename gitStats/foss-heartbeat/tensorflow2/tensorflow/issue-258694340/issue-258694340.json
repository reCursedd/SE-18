{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13144", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13144/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13144/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13144/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13144", "id": 258694340, "node_id": "MDU6SXNzdWUyNTg2OTQzNDA=", "number": 13144, "title": "No gradient defined for Relu6Grad", "user": {"login": "oxinabox", "id": 5127634, "node_id": "MDQ6VXNlcjUxMjc2MzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5127634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oxinabox", "html_url": "https://github.com/oxinabox", "followers_url": "https://api.github.com/users/oxinabox/followers", "following_url": "https://api.github.com/users/oxinabox/following{/other_user}", "gists_url": "https://api.github.com/users/oxinabox/gists{/gist_id}", "starred_url": "https://api.github.com/users/oxinabox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oxinabox/subscriptions", "organizations_url": "https://api.github.com/users/oxinabox/orgs", "repos_url": "https://api.github.com/users/oxinabox/repos", "events_url": "https://api.github.com/users/oxinabox/events{/privacy}", "received_events_url": "https://api.github.com/users/oxinabox/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-09-19T04:40:33Z", "updated_at": "2017-10-20T23:08:49Z", "closed_at": "2017-10-20T23:08:49Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes. MWE below is not a stock example.</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary (Miniconda)</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\nprint(tf.GIT_VERSION, tf.VERSION)<br>\n('v1.2.0-5-g435cdfc', '1.2.1')</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7.13</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\nN/A</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nCUDA 8.0.61<br>\nCuDNN 5.1.10</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nGeForce GTX TITAN X<br>\nTotal Memory 11.91GiB</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nSee below.</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>One can not apply the <code>gradient</code> operator to a <code>nn.Relu6</code> more than once.<br>\nApplying it once gives a <code>Relu6Grad</code> node,<br>\napplying it a second time (i.e applying it to the <code>Relu6Grad</code>)  throws an error.</p>\n<p>Unless I have messed up my math (quiet possible),<br>\nRelu6 is infinitely differentiable, except at 2 points,<br>\nalbeit very boring</p>\n<ul>\n<li>f(x) = relu6(x)</li>\n<li>df/dx = 1 if 0&lt;x&lt;6 else 0</li>\n<li>d2f/dxx = 0</li>\n<li>all further derivatives also 0.</li>\n</ul>\n<p>How-ever, it is marginally more interesting if one is applying the chain rule to it</p>\n<ul>\n<li>f(x1,x2) = relu6(x1*x2)</li>\n<li>df/dx1 = x2 if 0&lt;x1*x2&lt;6 else 0</li>\n<li>d2f/dx1x2 = 1 if 0&lt;x1*x2&lt;6 else 0</li>\n</ul>\n<p>This is a feature request to make the gradient of <code>Relu6Grad</code> defined.</p>\n<h3>Source code / logs</h3>\n<p>MWE:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nsess <span class=\"pl-k\">=</span> tf.Session()\n\nx1 <span class=\"pl-k\">=</span> tf.placeholder(tf.float32)\nx2 <span class=\"pl-k\">=</span> tf.placeholder(tf.float32)\n\ny <span class=\"pl-k\">=</span> tf.nn.relu6(x1<span class=\"pl-k\">*</span>x2)\nd1 <span class=\"pl-k\">=</span> tf.gradients(y,x1)\nd2 <span class=\"pl-k\">=</span> tf.gradients(d1, x2)</pre></div>\n<p>Errors on the final line  with</p>\n<pre><code>---------------------------------------------------------------------------\nLookupError                               Traceback (most recent call last)\n&lt;ipython-input-7-4250ab355a8b&gt; in &lt;module&gt;()\n----&gt; 1 d2 = tf.gradients(d1, x2)\n\n...usr/lib/python2.7/site-packages/te\nnsorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n gate_gradients, aggregation_method)\n    512               raise LookupError(\n    513                   \"No gradient defined for operation '%s' (op type: %s)\" %\n--&gt; 514                   (op.name, op.type))\n    515         if loop_state:\n    516           loop_state.EnterGradWhileContext(op, before=False)\n\nLookupError: No gradient defined for operation 'gradients/Relu6_grad/Relu6Grad' (op type: Relu6Grad)\n</code></pre>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes. MWE below is not a stock example.\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\n\n\nTensorFlow installed from (source or binary):\nBinary (Miniconda)\n\n\nTensorFlow version (use command below):\nprint(tf.GIT_VERSION, tf.VERSION)\n('v1.2.0-5-g435cdfc', '1.2.1')\n\n\nPython version:\n2.7.13\n\n\nBazel version (if compiling from source):\nN/A\n\n\nCUDA/cuDNN version:\nCUDA 8.0.61\nCuDNN 5.1.10\n\n\nGPU model and memory:\nGeForce GTX TITAN X\nTotal Memory 11.91GiB\n\n\nExact command to reproduce:\nSee below.\n\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nOne can not apply the gradient operator to a nn.Relu6 more than once.\nApplying it once gives a Relu6Grad node,\napplying it a second time (i.e applying it to the Relu6Grad)  throws an error.\nUnless I have messed up my math (quiet possible),\nRelu6 is infinitely differentiable, except at 2 points,\nalbeit very boring\n\nf(x) = relu6(x)\ndf/dx = 1 if 0<x<6 else 0\nd2f/dxx = 0\nall further derivatives also 0.\n\nHow-ever, it is marginally more interesting if one is applying the chain rule to it\n\nf(x1,x2) = relu6(x1*x2)\ndf/dx1 = x2 if 0<x1*x2<6 else 0\nd2f/dx1x2 = 1 if 0<x1*x2<6 else 0\n\nThis is a feature request to make the gradient of Relu6Grad defined.\nSource code / logs\nMWE:\nimport tensorflow as tf\nsess = tf.Session()\n\nx1 = tf.placeholder(tf.float32)\nx2 = tf.placeholder(tf.float32)\n\ny = tf.nn.relu6(x1*x2)\nd1 = tf.gradients(y,x1)\nd2 = tf.gradients(d1, x2)\nErrors on the final line  with\n---------------------------------------------------------------------------\nLookupError                               Traceback (most recent call last)\n<ipython-input-7-4250ab355a8b> in <module>()\n----> 1 d2 = tf.gradients(d1, x2)\n\n...usr/lib/python2.7/site-packages/te\nnsorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n gate_gradients, aggregation_method)\n    512               raise LookupError(\n    513                   \"No gradient defined for operation '%s' (op type: %s)\" %\n--> 514                   (op.name, op.type))\n    515         if loop_state:\n    516           loop_state.EnterGradWhileContext(op, before=False)\n\nLookupError: No gradient defined for operation 'gradients/Relu6_grad/Relu6Grad' (op type: Relu6Grad)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. MWE below is not a stock example.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary (Miniconda)\r\n\r\n- **TensorFlow version (use command below)**:\r\nprint(tf.GIT_VERSION, tf.VERSION)\r\n('v1.2.0-5-g435cdfc', '1.2.1')\r\n\r\n- **Python version**: \r\n2.7.13\r\n\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA 8.0.61\r\nCuDNN 5.1.10\r\n\r\n- **GPU model and memory**:\r\nGeForce GTX TITAN X\r\nTotal Memory 11.91GiB\r\n\r\n- **Exact command to reproduce**:\r\nSee below.\r\n\r\n### Describe the problem\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nOne can not apply the `gradient` operator to a `nn.Relu6` more than once.\r\nApplying it once gives a `Relu6Grad` node,\r\napplying it a second time (i.e applying it to the `Relu6Grad`)  throws an error.\r\n\r\nUnless I have messed up my math (quiet possible),\r\nRelu6 is infinitely differentiable, except at 2 points,\r\nalbeit very boring\r\n\r\n - f(x) = relu6(x) \r\n - df/dx = 1 if 0<x<6 else 0\r\n - d2f/dxx = 0\r\n - all further derivatives also 0.\r\n\r\nHow-ever, it is marginally more interesting if one is applying the chain rule to it\r\n\r\n - f(x1,x2) = relu6(x1*x2) \r\n - df/dx1 = x2 if 0<x1*x2<6 else 0\r\n - d2f/dx1x2 = 1 if 0<x1*x2<6 else 0\r\n\r\nThis is a feature request to make the gradient of `Relu6Grad` defined.\r\n\r\n\r\n### Source code / logs\r\n\r\nMWE:\r\n```python\r\n\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n\r\nx1 = tf.placeholder(tf.float32)\r\nx2 = tf.placeholder(tf.float32)\r\n\r\ny = tf.nn.relu6(x1*x2)\r\nd1 = tf.gradients(y,x1)\r\nd2 = tf.gradients(d1, x2)\r\n```\r\n\r\nErrors on the final line  with\r\n```\r\n---------------------------------------------------------------------------\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-7-4250ab355a8b> in <module>()\r\n----> 1 d2 = tf.gradients(d1, x2)\r\n\r\n...usr/lib/python2.7/site-packages/te\r\nnsorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops,\r\n gate_gradients, aggregation_method)\r\n    512               raise LookupError(\r\n    513                   \"No gradient defined for operation '%s' (op type: %s)\" %\r\n--> 514                   (op.name, op.type))\r\n    515         if loop_state:\r\n    516           loop_state.EnterGradWhileContext(op, before=False)\r\n\r\nLookupError: No gradient defined for operation 'gradients/Relu6_grad/Relu6Grad' (op type: Relu6Grad)\r\n```\r\n"}