{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/152", "id": 116428689, "node_id": "MDU6SXNzdWUxMTY0Mjg2ODk=", "number": 152, "title": "Segmentation fault when GPUs are already used", "user": {"login": "nouiz", "id": 180987, "node_id": "MDQ6VXNlcjE4MDk4Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/180987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nouiz", "html_url": "https://github.com/nouiz", "followers_url": "https://api.github.com/users/nouiz/followers", "following_url": "https://api.github.com/users/nouiz/following{/other_user}", "gists_url": "https://api.github.com/users/nouiz/gists{/gist_id}", "starred_url": "https://api.github.com/users/nouiz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nouiz/subscriptions", "organizations_url": "https://api.github.com/users/nouiz/orgs", "repos_url": "https://api.github.com/users/nouiz/repos", "events_url": "https://api.github.com/users/nouiz/events{/privacy}", "received_events_url": "https://api.github.com/users/nouiz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 41, "created_at": "2015-11-11T21:50:05Z", "updated_at": "2018-11-10T03:14:20Z", "closed_at": "2018-11-10T03:14:20Z", "author_association": "NONE", "body_html": "<p>When I set the nvidia driver in exclusive mode and one of the GPU is already used by another process, I get a segmentation fault:</p>\n<pre><code>$ python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nSegmentation fault (core dumped)\n</code></pre>\n<p>If I limit the visible GPUs to only GPUs that have nothing running on them, it don't segfault:</p>\n<pre><code>$CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 12105628263\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 12\n</code></pre>\n<p>Here is my output of nvidia-smi:</p>\n<pre><code>$ nvidia-smi \nWed Nov 11 16:48:27 2015       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 750     Off  | 0000:05:00.0      On |                  N/A |\n| N/A   48C    P8     0W /  38W |     25MiB /  2047MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 42%   82C    P2   127W / 250W |    262MiB / 12287MiB |     39%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   46C    P8    17W / 250W |     23MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   37C    P8    15W / 250W |    361MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1171    G   /usr/bin/X                                      17MiB |\n|    1     32740    C   python                                         209MiB |\n|    3      9429    C   python                                         336MiB |\n+-----------------------------------------------------------------------------+\n\n</code></pre>\n<p>I suppose that in the code that check the available GPUs, it don't handle correctly a case when one of the GPUs can't be used.</p>", "body_text": "When I set the nvidia driver in exclusive mode and one of the GPU is already used by another process, I get a segmentation fault:\n$ python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nSegmentation fault (core dumped)\n\nIf I limit the visible GPUs to only GPUs that have nothing running on them, it don't segfault:\n$CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 12105628263\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 12\n\nHere is my output of nvidia-smi:\n$ nvidia-smi \nWed Nov 11 16:48:27 2015       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 750     Off  | 0000:05:00.0      On |                  N/A |\n| N/A   48C    P8     0W /  38W |     25MiB /  2047MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 42%   82C    P2   127W / 250W |    262MiB / 12287MiB |     39%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   46C    P8    17W / 250W |     23MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   37C    P8    15W / 250W |    361MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1171    G   /usr/bin/X                                      17MiB |\n|    1     32740    C   python                                         209MiB |\n|    3      9429    C   python                                         336MiB |\n+-----------------------------------------------------------------------------+\n\n\nI suppose that in the code that check the available GPUs, it don't handle correctly a case when one of the GPUs can't be used.", "body": "When I set the nvidia driver in exclusive mode and one of the GPU is already used by another process, I get a segmentation fault:\n\n```\n$ python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nSegmentation fault (core dumped)\n```\n\nIf I limit the visible GPUs to only GPUs that have nothing running on them, it don't segfault:\n\n```\n$CUDA_VISIBLE_DEVICES=1 python -c \"import tensorflow as tf;tf.InteractiveSession()\"\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 12105628263\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 12\n```\n\nHere is my output of nvidia-smi:\n\n```\n$ nvidia-smi \nWed Nov 11 16:48:27 2015       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 750     Off  | 0000:05:00.0      On |                  N/A |\n| N/A   48C    P8     0W /  38W |     25MiB /  2047MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\n| 42%   82C    P2   127W / 250W |    262MiB / 12287MiB |     39%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\n| 22%   46C    P8    17W / 250W |     23MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\n| 22%   37C    P8    15W / 250W |    361MiB / 12287MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1171    G   /usr/bin/X                                      17MiB |\n|    1     32740    C   python                                         209MiB |\n|    3      9429    C   python                                         336MiB |\n+-----------------------------------------------------------------------------+\n\n```\n\nI suppose that in the code that check the available GPUs, it don't handle correctly a case when one of the GPUs can't be used.\n"}