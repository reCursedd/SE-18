{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164008117", "html_url": "https://github.com/tensorflow/tensorflow/issues/152#issuecomment-164008117", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152", "id": 164008117, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDAwODExNw==", "user": {"login": "noisychannel", "id": 807183, "node_id": "MDQ6VXNlcjgwNzE4Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/807183?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noisychannel", "html_url": "https://github.com/noisychannel", "followers_url": "https://api.github.com/users/noisychannel/followers", "following_url": "https://api.github.com/users/noisychannel/following{/other_user}", "gists_url": "https://api.github.com/users/noisychannel/gists{/gist_id}", "starred_url": "https://api.github.com/users/noisychannel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noisychannel/subscriptions", "organizations_url": "https://api.github.com/users/noisychannel/orgs", "repos_url": "https://api.github.com/users/noisychannel/repos", "events_url": "https://api.github.com/users/noisychannel/events{/privacy}", "received_events_url": "https://api.github.com/users/noisychannel/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-11T18:17:52Z", "updated_at": "2015-12-11T18:17:52Z", "author_association": "NONE", "body_html": "<p>The established way to do this seems to be:</p>\n<ol>\n<li>Set the GPUs to operate in exclusive mode.</li>\n<li>Do not call <code>cudaSetDevice()</code>.</li>\n<li>When you run your program, it will try and create the context on the first GPU and fail if the GPU is busy.  Assuming you're using CUDART, it should <em>silently</em> try and create the context on the next GPUs and fail if all GPUs are busy.</li>\n</ol>\n<p>As for exception handling while creating the context, it seems like the this scenario can be handled with the exceptions returned by <code>cuCtxCreate()</code>.</p>\n<p>A solution like this is optimal when you delegate the scheduling of your jobs to something like SGE and cannot trust the script based querying approach which I think is common for large clusters.</p>", "body_text": "The established way to do this seems to be:\n\nSet the GPUs to operate in exclusive mode.\nDo not call cudaSetDevice().\nWhen you run your program, it will try and create the context on the first GPU and fail if the GPU is busy.  Assuming you're using CUDART, it should silently try and create the context on the next GPUs and fail if all GPUs are busy.\n\nAs for exception handling while creating the context, it seems like the this scenario can be handled with the exceptions returned by cuCtxCreate().\nA solution like this is optimal when you delegate the scheduling of your jobs to something like SGE and cannot trust the script based querying approach which I think is common for large clusters.", "body": "The established way to do this seems to be: \n1. Set the GPUs to operate in exclusive mode.\n2. Do not call `cudaSetDevice()`.\n3. When you run your program, it will try and create the context on the first GPU and fail if the GPU is busy.  Assuming you're using CUDART, it should _silently_ try and create the context on the next GPUs and fail if all GPUs are busy. \n\nAs for exception handling while creating the context, it seems like the this scenario can be handled with the exceptions returned by `cuCtxCreate()`. \n\nA solution like this is optimal when you delegate the scheduling of your jobs to something like SGE and cannot trust the script based querying approach which I think is common for large clusters.  \n"}