{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164023652", "html_url": "https://github.com/tensorflow/tensorflow/issues/152#issuecomment-164023652", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152", "id": 164023652, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDAyMzY1Mg==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-11T19:15:52Z", "updated_at": "2015-12-11T19:15:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This would work fine if the framework only wants to use a single GPU. TensorFlow is designed to use multiple GPU seamlessly at the same time. So at the initialization stage, it grabs all the visible devices that are compatible, since the client program might use all of them. The actual device used is only known at the graph construction/execution time, which is at a much later stage.</p>\n<p>For most of our existing users, the GPUs that are available to a particular job is known when it starts. So it is okay for TensorFlow to take all of them. A few options to think about:</p>\n<ol>\n<li>Is it possible for the job scheduler to reserve the GPUs in your clusters? That would work best with TensorFlow.</li>\n<li>If you only know the list of candidate GPUs, and the number of GPUs to use, we can add a special mode where we try to create context in the candidate list, and stops if desired number of GPUs are taken. This requires more plumbing to both TensorFlow and the underlying Stream-Executor that actually manages GPUs. We would much prefer <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> if that is possible for you.</li>\n</ol>", "body_text": "This would work fine if the framework only wants to use a single GPU. TensorFlow is designed to use multiple GPU seamlessly at the same time. So at the initialization stage, it grabs all the visible devices that are compatible, since the client program might use all of them. The actual device used is only known at the graph construction/execution time, which is at a much later stage.\nFor most of our existing users, the GPUs that are available to a particular job is known when it starts. So it is okay for TensorFlow to take all of them. A few options to think about:\n\nIs it possible for the job scheduler to reserve the GPUs in your clusters? That would work best with TensorFlow.\nIf you only know the list of candidate GPUs, and the number of GPUs to use, we can add a special mode where we try to create context in the candidate list, and stops if desired number of GPUs are taken. This requires more plumbing to both TensorFlow and the underlying Stream-Executor that actually manages GPUs. We would much prefer #1 if that is possible for you.", "body": "This would work fine if the framework only wants to use a single GPU. TensorFlow is designed to use multiple GPU seamlessly at the same time. So at the initialization stage, it grabs all the visible devices that are compatible, since the client program might use all of them. The actual device used is only known at the graph construction/execution time, which is at a much later stage.\n\nFor most of our existing users, the GPUs that are available to a particular job is known when it starts. So it is okay for TensorFlow to take all of them. A few options to think about: \n1. Is it possible for the job scheduler to reserve the GPUs in your clusters? That would work best with TensorFlow. \n2. If you only know the list of candidate GPUs, and the number of GPUs to use, we can add a special mode where we try to create context in the candidate list, and stops if desired number of GPUs are taken. This requires more plumbing to both TensorFlow and the underlying Stream-Executor that actually manages GPUs. We would much prefer #1 if that is possible for you. \n"}