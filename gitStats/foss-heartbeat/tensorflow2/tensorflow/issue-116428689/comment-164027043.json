{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164027043", "html_url": "https://github.com/tensorflow/tensorflow/issues/152#issuecomment-164027043", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/152", "id": 164027043, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDAyNzA0Mw==", "user": {"login": "noisychannel", "id": 807183, "node_id": "MDQ6VXNlcjgwNzE4Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/807183?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noisychannel", "html_url": "https://github.com/noisychannel", "followers_url": "https://api.github.com/users/noisychannel/followers", "following_url": "https://api.github.com/users/noisychannel/following{/other_user}", "gists_url": "https://api.github.com/users/noisychannel/gists{/gist_id}", "starred_url": "https://api.github.com/users/noisychannel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noisychannel/subscriptions", "organizations_url": "https://api.github.com/users/noisychannel/orgs", "repos_url": "https://api.github.com/users/noisychannel/repos", "events_url": "https://api.github.com/users/noisychannel/events{/privacy}", "received_events_url": "https://api.github.com/users/noisychannel/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-11T19:29:45Z", "updated_at": "2015-12-11T19:30:03Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> For 1: AFAIK, the only responsibility of most job schedulers is to ensure that you will have access to the number of GPUs you have asked for on the machine which has been assigned to you. It leaves the actual CPU/GPU scheduling of the processes on that machine to the OS/Cuda driver. Also, hypothetically, if the scheduler was to attempt something of this sort, it would not be able to block the GPU without creating something like a context.</p>\n<p>For 2 : I understand that this is probably painful. However, it does add a more general set of features. The case where I want <code>k</code> out of <code>n</code> GPUs on the machine is most prominent. Eg,, it would be able to handle the case where the candidate list is the set of all GPUs on the machine and I want only 2 available and compatible GPUs from that list. Having the ability to specify how many GPUs you want to use will be a great addition and this will tie in perfectly with most job schedulers. So to tensorflow, I specify, I want to run this thing on 2 GPUs and I tell the job scheduler that I need 2 GPUs.</p>", "body_text": "@zheng-xq For 1: AFAIK, the only responsibility of most job schedulers is to ensure that you will have access to the number of GPUs you have asked for on the machine which has been assigned to you. It leaves the actual CPU/GPU scheduling of the processes on that machine to the OS/Cuda driver. Also, hypothetically, if the scheduler was to attempt something of this sort, it would not be able to block the GPU without creating something like a context.\nFor 2 : I understand that this is probably painful. However, it does add a more general set of features. The case where I want k out of n GPUs on the machine is most prominent. Eg,, it would be able to handle the case where the candidate list is the set of all GPUs on the machine and I want only 2 available and compatible GPUs from that list. Having the ability to specify how many GPUs you want to use will be a great addition and this will tie in perfectly with most job schedulers. So to tensorflow, I specify, I want to run this thing on 2 GPUs and I tell the job scheduler that I need 2 GPUs.", "body": "@zheng-xq For 1: AFAIK, the only responsibility of most job schedulers is to ensure that you will have access to the number of GPUs you have asked for on the machine which has been assigned to you. It leaves the actual CPU/GPU scheduling of the processes on that machine to the OS/Cuda driver. Also, hypothetically, if the scheduler was to attempt something of this sort, it would not be able to block the GPU without creating something like a context. \n\nFor 2 : I understand that this is probably painful. However, it does add a more general set of features. The case where I want `k` out of `n` GPUs on the machine is most prominent. Eg,, it would be able to handle the case where the candidate list is the set of all GPUs on the machine and I want only 2 available and compatible GPUs from that list. Having the ability to specify how many GPUs you want to use will be a great addition and this will tie in perfectly with most job schedulers. So to tensorflow, I specify, I want to run this thing on 2 GPUs and I tell the job scheduler that I need 2 GPUs. \n"}