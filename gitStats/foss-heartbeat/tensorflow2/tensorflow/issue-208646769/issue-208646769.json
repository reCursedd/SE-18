{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7648", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7648/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7648/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7648/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7648", "id": 208646769, "node_id": "MDU6SXNzdWUyMDg2NDY3Njk=", "number": 7648, "title": "GPU: no known devices, despite cuda's deviceQuery returning a \"PASS\" result", "user": {"login": "oelmekki", "id": 54562, "node_id": "MDQ6VXNlcjU0NTYy", "avatar_url": "https://avatars1.githubusercontent.com/u/54562?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oelmekki", "html_url": "https://github.com/oelmekki", "followers_url": "https://api.github.com/users/oelmekki/followers", "following_url": "https://api.github.com/users/oelmekki/following{/other_user}", "gists_url": "https://api.github.com/users/oelmekki/gists{/gist_id}", "starred_url": "https://api.github.com/users/oelmekki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oelmekki/subscriptions", "organizations_url": "https://api.github.com/users/oelmekki/orgs", "repos_url": "https://api.github.com/users/oelmekki/repos", "events_url": "https://api.github.com/users/oelmekki/events{/privacy}", "received_events_url": "https://api.github.com/users/oelmekki/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2017-02-18T15:02:10Z", "updated_at": "2018-02-27T17:39:57Z", "closed_at": "2017-02-18T19:06:32Z", "author_association": "NONE", "body_html": "<p>Hi guys,</p>\n<p>Sorry, I know there's already been tons of GPU related issues, but I could not find any that seems to be related to my problem.</p>\n<p>The main symptom: when running tensorflow, my gpu is not detected (<a href=\"https://gist.github.com/oelmekki/cafda411bf5c2ea695d984fa98e0995b\">the code being run</a>, and <a href=\"https://gist.github.com/oelmekki/77235c6b0dde99b3438f190eb557f40f\">its output</a>).</p>\n<p>What differs from usual issues is that cuda seems properly installed and running <code>./deviceQuery</code> from cuda samples is successful (<a href=\"https://gist.github.com/oelmekki/fe65a15daec45aa90ec33b10b51d3aae\">output</a>).</p>\n<p>I have two graphical cards:</p>\n<ul>\n<li>an old GTX 650 used for my monitors (I don't want to use that one with tensorflow)</li>\n<li>a GTX 1060 that I want to dedicate to tensorflow</li>\n</ul>\n<p>I use:</p>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/tensorflow\" rel=\"nofollow\">tensorflow-1.0.0</a></li>\n<li>cuda-8.0 (<a href=\"https://gist.github.com/oelmekki/6e5e9d7d1ea871e1d73efae307efe9ce\">ls -l /usr/local/cuda/lib64/libcud*</a>)</li>\n<li>cudnn-5.1.10</li>\n<li>python-2.7.12</li>\n<li>nvidia-drivers-375.26 (this was installed by cuda and replaced my distro driver package)</li>\n</ul>\n<p>I've tried:</p>\n<ul>\n<li>adding <code>/usr/local/cuda/bin/</code> to <code>$PATH</code></li>\n<li>forcing gpu placement in tensorflow script using <code>with tf.device('/gpu:1'):</code> (and <code>with tf.device('/gpu:0'):</code> when it failed, for good measure)</li>\n<li>whitelisting the gpu I wanted to use with <code>CUDA_VISIBLE_DEVICES</code>, in case the presence of my old unsupported card did cause problems</li>\n<li>running the script with sudo (because why not)</li>\n</ul>\n<p>Here are the outputs of <a href=\"https://gist.github.com/oelmekki/7bdcb5cc2f791cea561a60f8b21e87b5\">nvidia-smi</a> and <a href=\"https://gist.github.com/oelmekki/b83a5a0a72e8924aeb44b70b3598f9b4\">nvidia-debugdump -l</a>, in case it's useful.</p>\n<p>At this point, I feel like I have followed all the breadcrumbs and have no idea what I could try else. I'm not even sure if I'm contemplating a bug or a configuration problem. Any advice about how to debug this would be greatly appreciated. Thanks!</p>", "body_text": "Hi guys,\nSorry, I know there's already been tons of GPU related issues, but I could not find any that seems to be related to my problem.\nThe main symptom: when running tensorflow, my gpu is not detected (the code being run, and its output).\nWhat differs from usual issues is that cuda seems properly installed and running ./deviceQuery from cuda samples is successful (output).\nI have two graphical cards:\n\nan old GTX 650 used for my monitors (I don't want to use that one with tensorflow)\na GTX 1060 that I want to dedicate to tensorflow\n\nI use:\n\ntensorflow-1.0.0\ncuda-8.0 (ls -l /usr/local/cuda/lib64/libcud*)\ncudnn-5.1.10\npython-2.7.12\nnvidia-drivers-375.26 (this was installed by cuda and replaced my distro driver package)\n\nI've tried:\n\nadding /usr/local/cuda/bin/ to $PATH\nforcing gpu placement in tensorflow script using with tf.device('/gpu:1'): (and with tf.device('/gpu:0'): when it failed, for good measure)\nwhitelisting the gpu I wanted to use with CUDA_VISIBLE_DEVICES, in case the presence of my old unsupported card did cause problems\nrunning the script with sudo (because why not)\n\nHere are the outputs of nvidia-smi and nvidia-debugdump -l, in case it's useful.\nAt this point, I feel like I have followed all the breadcrumbs and have no idea what I could try else. I'm not even sure if I'm contemplating a bug or a configuration problem. Any advice about how to debug this would be greatly appreciated. Thanks!", "body": "Hi guys,\r\n\r\nSorry, I know there's already been tons of GPU related issues, but I could not find any that seems to be related to my problem.\r\n\r\nThe main symptom: when running tensorflow, my gpu is not detected ([the code being run](https://gist.github.com/oelmekki/cafda411bf5c2ea695d984fa98e0995b), and [its output](https://gist.github.com/oelmekki/77235c6b0dde99b3438f190eb557f40f)).\r\n\r\nWhat differs from usual issues is that cuda seems properly installed and running `./deviceQuery` from cuda samples is successful ([output](https://gist.github.com/oelmekki/fe65a15daec45aa90ec33b10b51d3aae)).\r\n\r\nI have two graphical cards:\r\n\r\n* an old GTX 650 used for my monitors (I don't want to use that one with tensorflow)\r\n* a GTX 1060 that I want to dedicate to tensorflow\r\n\r\nI use:\r\n\r\n* [tensorflow-1.0.0](https://pypi.python.org/pypi/tensorflow)\r\n* cuda-8.0 ([ls -l /usr/local/cuda/lib64/libcud*](https://gist.github.com/oelmekki/6e5e9d7d1ea871e1d73efae307efe9ce))\r\n* cudnn-5.1.10\r\n* python-2.7.12\r\n* nvidia-drivers-375.26 (this was installed by cuda and replaced my distro driver package)\r\n\r\n\r\nI've tried:\r\n\r\n* adding `/usr/local/cuda/bin/` to `$PATH`\r\n* forcing gpu placement in tensorflow script using `with tf.device('/gpu:1'):` (and `with tf.device('/gpu:0'):` when it failed, for good measure)\r\n* whitelisting the gpu I wanted to use with `CUDA_VISIBLE_DEVICES`, in case the presence of my old unsupported card did cause problems\r\n* running the script with sudo (because why not)\r\n\r\nHere are the outputs of [nvidia-smi](https://gist.github.com/oelmekki/7bdcb5cc2f791cea561a60f8b21e87b5) and [nvidia-debugdump -l](https://gist.github.com/oelmekki/b83a5a0a72e8924aeb44b70b3598f9b4), in case it's useful.\r\n\r\nAt this point, I feel like I have followed all the breadcrumbs and have no idea what I could try else. I'm not even sure if I'm contemplating a bug or a configuration problem. Any advice about how to debug this would be greatly appreciated. Thanks!\r\n"}