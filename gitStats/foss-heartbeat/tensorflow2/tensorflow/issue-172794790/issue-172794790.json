{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3994", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3994/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3994/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3994/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3994", "id": 172794790, "node_id": "MDU6SXNzdWUxNzI3OTQ3OTA=", "number": 3994, "title": "Cannot use Variables as gradients in apply_gradients", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-08-23T20:12:30Z", "updated_at": "2016-09-07T23:25:36Z", "closed_at": "2016-09-07T23:25:36Z", "author_association": "NONE", "body_html": "<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L287\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L287</a> prevents the user from using a variable as a gradient when calling apply_gradients.</p>\n<p>I'd like to do this to accumulate gradients over multiple minibatches, and then do a single gradient update.</p>\n<p>The current code I have is</p>\n<div class=\"highlight highlight-source-python\"><pre>opt <span class=\"pl-k\">=</span> tf.train.AdamOptimizer()                                                                                                   \n\ntvs <span class=\"pl-k\">=</span> tf.trainable_variables()\naccum_vars <span class=\"pl-k\">=</span> [tf.Variable(tf.zeros_like(tv.initialized_value()), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>) <span class=\"pl-k\">for</span> tv <span class=\"pl-k\">in</span> tvs]                                        \nzero_ops <span class=\"pl-k\">=</span> [tv.assign(tf.zeros_like(tv)) <span class=\"pl-k\">for</span> tv <span class=\"pl-k\">in</span> accum_vars]\n\ngvs <span class=\"pl-k\">=</span> opt.compute_gradients(rmse, tvs)\naccum_ops <span class=\"pl-k\">=</span> [accum_vars[i].assign_add(gv[<span class=\"pl-c1\">0</span>]) <span class=\"pl-k\">for</span> i, gv <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(gvs)]\n\ntrain_step <span class=\"pl-k\">=</span> opt.apply_gradients([(accum_vars[i], gv[<span class=\"pl-c1\">1</span>]) <span class=\"pl-k\">for</span> i, gv <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(gvs)])  </pre></div>\n<p>that I'd like to run with logic like</p>\n<pre><code>while True:\n    sess.run(zero_ops)\n\n    for i in xrange(n_minibatches):\n        sess.run(accum_ops, feed_dict=dict(X: Xs[i], y: ys[i]))\n\n    sess.run(train_step)\n</code></pre>\n<p>Is there any reason variables cannot be used as arguments to apply_gradients? It seems to me that they should be able to be used as gradients. If there is a good reason, is there a recommended way to have the pattern I desire? I'm currently using the ugly hack of replacing the <code>train_step</code> definition with</p>\n<pre><code>train_step = opt.apply_gradients([(accum_vars[i].assign(accum_vars[i]), gv[1]) \n                                  for i, gv in enumerate(gvs)])\n</code></pre>\n<p>because <code>Variable.assign</code> returns a tensor.</p>", "body_text": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L287 prevents the user from using a variable as a gradient when calling apply_gradients.\nI'd like to do this to accumulate gradients over multiple minibatches, and then do a single gradient update.\nThe current code I have is\nopt = tf.train.AdamOptimizer()                                                                                                   \n\ntvs = tf.trainable_variables()\naccum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        \nzero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n\ngvs = opt.compute_gradients(rmse, tvs)\naccum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n\ntrain_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])  \nthat I'd like to run with logic like\nwhile True:\n    sess.run(zero_ops)\n\n    for i in xrange(n_minibatches):\n        sess.run(accum_ops, feed_dict=dict(X: Xs[i], y: ys[i]))\n\n    sess.run(train_step)\n\nIs there any reason variables cannot be used as arguments to apply_gradients? It seems to me that they should be able to be used as gradients. If there is a good reason, is there a recommended way to have the pattern I desire? I'm currently using the ugly hack of replacing the train_step definition with\ntrain_step = opt.apply_gradients([(accum_vars[i].assign(accum_vars[i]), gv[1]) \n                                  for i, gv in enumerate(gvs)])\n\nbecause Variable.assign returns a tensor.", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L287 prevents the user from using a variable as a gradient when calling apply_gradients.\n\nI'd like to do this to accumulate gradients over multiple minibatches, and then do a single gradient update.\n\nThe current code I have is\n\n``` python\nopt = tf.train.AdamOptimizer()                                                                                                   \n\ntvs = tf.trainable_variables()\naccum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        \nzero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n\ngvs = opt.compute_gradients(rmse, tvs)\naccum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n\ntrain_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])  \n```\n\nthat I'd like to run with logic like\n\n```\nwhile True:\n    sess.run(zero_ops)\n\n    for i in xrange(n_minibatches):\n        sess.run(accum_ops, feed_dict=dict(X: Xs[i], y: ys[i]))\n\n    sess.run(train_step)\n```\n\nIs there any reason variables cannot be used as arguments to apply_gradients? It seems to me that they should be able to be used as gradients. If there is a good reason, is there a recommended way to have the pattern I desire? I'm currently using the ugly hack of replacing the `train_step` definition with \n\n```\ntrain_step = opt.apply_gradients([(accum_vars[i].assign(accum_vars[i]), gv[1]) \n                                  for i, gv in enumerate(gvs)])\n```\n\nbecause `Variable.assign` returns a tensor.\n"}