{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8840", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8840/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8840/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8840/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8840", "id": 218201143, "node_id": "MDU6SXNzdWUyMTgyMDExNDM=", "number": 8840, "title": "BasicDecoder error", "user": {"login": "mhnatiuk", "id": 2299492, "node_id": "MDQ6VXNlcjIyOTk0OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2299492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhnatiuk", "html_url": "https://github.com/mhnatiuk", "followers_url": "https://api.github.com/users/mhnatiuk/followers", "following_url": "https://api.github.com/users/mhnatiuk/following{/other_user}", "gists_url": "https://api.github.com/users/mhnatiuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhnatiuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhnatiuk/subscriptions", "organizations_url": "https://api.github.com/users/mhnatiuk/orgs", "repos_url": "https://api.github.com/users/mhnatiuk/repos", "events_url": "https://api.github.com/users/mhnatiuk/events{/privacy}", "received_events_url": "https://api.github.com/users/mhnatiuk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-03-30T13:42:02Z", "updated_at": "2017-05-06T07:06:48Z", "closed_at": "2017-04-02T17:55:29Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI am trying to use BasicDecoder for a sequence-to-sequence translation model and I get error:<br>\n<code> InvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]]</code><br>\nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]</p>\n<p>My target_vocab_size is 500K<br>\nsize of RNN = 64, for testing<br>\ndec_inp : &lt;tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32&gt;<br>\ndecoder seq len is batch-sized (64) &lt;tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32&gt;</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>tf.<strong>version</strong><br>\n'1.1.0-rc0'</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<pre><code>\nW_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n\nhalf = tf.constant(0.5)\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\nif not forward_only:\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\n\t\nelse:\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\n\t\ndecoder_cell = LSTMBlockCell(num_units=size)\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\n\nmy_decoder = seq2seq.BasicDecoder(\n\t\tcell=decoder_cell,\n\t\thelper=helper,\n\t\tinitial_state=encoder_final_state)\n\n\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n\t\t\t   swap_memory = True)\n</code></pre>", "body_text": "Hi,\nI am trying to use BasicDecoder for a sequence-to-sequence translation model and I get error:\n InvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]]\nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]\nMy target_vocab_size is 500K\nsize of RNN = 64, for testing\ndec_inp : <tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32>\ndecoder seq len is batch-sized (64) <tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32>\n\n\n\ntf.version\n'1.1.0-rc0'\n\n\n\n\nW_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n\nhalf = tf.constant(0.5)\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\nif not forward_only:\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\n\t\nelse:\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\n\t\ndecoder_cell = LSTMBlockCell(num_units=size)\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\n\nmy_decoder = seq2seq.BasicDecoder(\n\t\tcell=decoder_cell,\n\t\thelper=helper,\n\t\tinitial_state=encoder_final_state)\n\n\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n\t\t\t   swap_memory = True)", "body": "Hi,\r\nI am trying to use BasicDecoder for a sequence-to-sequence translation model and I get error:\r\n`\r\nInvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:5\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4293_rnn/while/Identity_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:5\"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]]`\r\nI can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]\r\n\r\nMy target_vocab_size is 500K\r\nsize of RNN = 64, for testing\r\ndec_inp : <tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32>\r\ndecoder seq len is batch-sized (64) <tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32>\r\n\r\n>>> tf.__version__\r\n'1.1.0-rc0'\r\n>>>\r\n\r\n\r\n```\r\n\r\nW_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\r\n\r\nhalf = tf.constant(0.5)\r\ndec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\r\ndec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = \"embedded_inputs\")\r\nif not forward_only:\r\n\t#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\r\n\thelper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t  sequence_length = self.decoder_seq_len,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t embedding = W_target_emb,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t sampling_probability = half,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t time_major=True)\r\n\t\r\nelse:\r\n\thelper = seq2seq.GreedyEmbeddingHelper(dec_inp, \r\n\t\t\t\t\t\t\t\t\t\t   start_tokens=self.decoder_inputs[0],\r\n\t\t\t\t\t\t\t\t\t\t   end_token=data_utils.EOS_ID)\r\n\t\r\ndecoder_cell = LSTMBlockCell(num_units=size)\r\ndecoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device=\"/gpu:%d\" % i) for i in range(8) ])\r\n\r\nmy_decoder = seq2seq.BasicDecoder(\r\n\t\tcell=decoder_cell,\r\n\t\thelper=helper,\r\n\t\tinitial_state=encoder_final_state)\r\n\r\n\r\ndecoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\r\n\t\t\t   swap_memory = True)\r\n```"}