{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421224238", "html_url": "https://github.com/tensorflow/tensorflow/issues/19838#issuecomment-421224238", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19838", "id": 421224238, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTIyNDIzOA==", "user": {"login": "zh794390558", "id": 3038472, "node_id": "MDQ6VXNlcjMwMzg0NzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3038472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zh794390558", "html_url": "https://github.com/zh794390558", "followers_url": "https://api.github.com/users/zh794390558/followers", "following_url": "https://api.github.com/users/zh794390558/following{/other_user}", "gists_url": "https://api.github.com/users/zh794390558/gists{/gist_id}", "starred_url": "https://api.github.com/users/zh794390558/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zh794390558/subscriptions", "organizations_url": "https://api.github.com/users/zh794390558/orgs", "repos_url": "https://api.github.com/users/zh794390558/repos", "events_url": "https://api.github.com/users/zh794390558/events{/privacy}", "received_events_url": "https://api.github.com/users/zh794390558/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-14T04:02:08Z", "updated_at": "2018-09-14T04:14:23Z", "author_association": "NONE", "body_html": "<p>optimized it using optimize_for_inference (works error)</p>\n<pre><code>${ROOT}/bazel-bin/tensorflow/python/tools/optimize_for_inference  \\\n--input=$graph \\\n--output=optimized_for_inference_graph.pb \\\n--frozen_graph=True \\\n--input_names=\"input\" \\\n--output_names=\"softmax_output\"\n\n$ ./summarize_graph.sh optimized_for_inference_graph.pb\nFound 1 possible inputs: (name=input, type=float(1), shape=None)\nNo variables spotted.\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 0 control_edges\nOp types used: 221 Const, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 Transpose, 8 FloorDiv, 8 GatherV2, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=optimized_for_inference_graph.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape= --output_layer=softmax_output\n\n ./summarize_graph.sh frozen_graph.pb\nFound 1 possible inputs: (name=input, type=float(1), shape=[?,480000])\nNo variables spotted.\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 129 control_edges\nOp types used: 221 Const, 32 Identity, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 FloorDiv, 8 GatherV2, 8 Transpose, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\n</code></pre>\n<p>After using optimized_for_inference bin, the input shape changed. tf version 1.9</p>", "body_text": "optimized it using optimize_for_inference (works error)\n${ROOT}/bazel-bin/tensorflow/python/tools/optimize_for_inference  \\\n--input=$graph \\\n--output=optimized_for_inference_graph.pb \\\n--frozen_graph=True \\\n--input_names=\"input\" \\\n--output_names=\"softmax_output\"\n\n$ ./summarize_graph.sh optimized_for_inference_graph.pb\nFound 1 possible inputs: (name=input, type=float(1), shape=None)\nNo variables spotted.\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 0 control_edges\nOp types used: 221 Const, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 Transpose, 8 FloorDiv, 8 GatherV2, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=optimized_for_inference_graph.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape= --output_layer=softmax_output\n\n ./summarize_graph.sh frozen_graph.pb\nFound 1 possible inputs: (name=input, type=float(1), shape=[?,480000])\nNo variables spotted.\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 129 control_edges\nOp types used: 221 Const, 32 Identity, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 FloorDiv, 8 GatherV2, 8 Transpose, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\n\nAfter using optimized_for_inference bin, the input shape changed. tf version 1.9", "body": "optimized it using optimize_for_inference (works error)\r\n\r\n```\r\n${ROOT}/bazel-bin/tensorflow/python/tools/optimize_for_inference  \\\r\n--input=$graph \\\r\n--output=optimized_for_inference_graph.pb \\\r\n--frozen_graph=True \\\r\n--input_names=\"input\" \\\r\n--output_names=\"softmax_output\"\r\n\r\n$ ./summarize_graph.sh optimized_for_inference_graph.pb\r\nFound 1 possible inputs: (name=input, type=float(1), shape=None)\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\r\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 221 Const, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 Transpose, 8 FloorDiv, 8 GatherV2, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=optimized_for_inference_graph.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape= --output_layer=softmax_output\r\n\r\n ./summarize_graph.sh frozen_graph.pb\r\nFound 1 possible inputs: (name=input, type=float(1), shape=[?,480000])\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=softmax_output, op=Softmax)\r\nFound 3156821 (3.16M) const parameters, 0 (0) variable parameters, and 129 control_edges\r\nOp types used: 221 Const, 32 Identity, 28 Mul, 27 Reshape, 26 Pack, 25 Add, 18 Sub, 14 ConcatV2, 12 Range, 10 StridedSlice, 10 Cast, 8 FloorDiv, 8 GatherV2, 8 Transpose, 8 Less, 7 Enter, 7 RealDiv, 6 Shape, 6 Prod, 6 MatMul, 5 BiasAdd, 5 Fill, 4 Log, 4 Maximum, 4 ExpandDims, 3 ListDiff, 3 Conv2D, 3 Merge, 3 Select, 3 NextIteration, 3 GreaterEqual, 3 Switch, 2 SplitV, 2 Softmax, 2 Size, 2 Rsqrt, 2 FusedBatchNorm, 2 Pad, 2 Neg, 2 LinSpace, 2 TensorArrayV3, 2 Mean, 2 MaxPool, 1 TensorArrayScatterV3, 1 TensorArrayReadV3, 1 TensorArrayGatherV3, 1 TensorArraySizeV3, 1 Sum, 1 TensorArrayWriteV3, 1 Cos, 1 ComplexAbs, 1 Square, 1 Split, 1 Sigmoid, 1 Exit, 1 FloorMod, 1 RandomStandardNormal, 1 RFFT, 1 Placeholder, 1 PadV2, 1 Minimum, 1 LoopCond, 1 LogicalAnd\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\n```\r\n\r\nAfter using optimized_for_inference bin, the input shape changed. tf version 1.9"}