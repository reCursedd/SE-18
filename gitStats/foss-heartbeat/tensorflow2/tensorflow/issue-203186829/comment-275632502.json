{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275632502", "html_url": "https://github.com/tensorflow/tensorflow/issues/7065#issuecomment-275632502", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7065", "id": 275632502, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTYzMjUwMg==", "user": {"login": "SeguinBe", "id": 7132817, "node_id": "MDQ6VXNlcjcxMzI4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/7132817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SeguinBe", "html_url": "https://github.com/SeguinBe", "followers_url": "https://api.github.com/users/SeguinBe/followers", "following_url": "https://api.github.com/users/SeguinBe/following{/other_user}", "gists_url": "https://api.github.com/users/SeguinBe/gists{/gist_id}", "starred_url": "https://api.github.com/users/SeguinBe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SeguinBe/subscriptions", "organizations_url": "https://api.github.com/users/SeguinBe/orgs", "repos_url": "https://api.github.com/users/SeguinBe/repos", "events_url": "https://api.github.com/users/SeguinBe/events{/privacy}", "received_events_url": "https://api.github.com/users/SeguinBe/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-27T10:16:59Z", "updated_at": "2017-01-27T10:19:46Z", "author_association": "NONE", "body_html": "<p>So I think that was mainly the solution, the tensorflow definition of the network was using a convolution instead of the fully connected linear matrix multiplication for fc6 fc7 fc8 (<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/vgg.py#L116\">here</a>). Did not think originally it would be a big problem but to recapitulate :</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Timing</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>TF-slim default</td>\n<td>160ms</td>\n</tr>\n<tr>\n<td>TF-slim + NCHW</td>\n<td>150ms</td>\n</tr>\n<tr>\n<td>fc layers instead of conv</td>\n<td>94ms</td>\n</tr>\n<tr>\n<td>fc layers instead of conv + NCHW</td>\n<td>82ms</td>\n</tr>\n<tr>\n<td>pytorch</td>\n<td>65ms</td>\n</tr>\n</tbody>\n</table>\n<p>There is still a gap but it is definitely more acceptable, should we consider this as resolved?</p>", "body_text": "So I think that was mainly the solution, the tensorflow definition of the network was using a convolution instead of the fully connected linear matrix multiplication for fc6 fc7 fc8 (here). Did not think originally it would be a big problem but to recapitulate :\n\n\n\nModel\nTiming\n\n\n\n\nTF-slim default\n160ms\n\n\nTF-slim + NCHW\n150ms\n\n\nfc layers instead of conv\n94ms\n\n\nfc layers instead of conv + NCHW\n82ms\n\n\npytorch\n65ms\n\n\n\nThere is still a gap but it is definitely more acceptable, should we consider this as resolved?", "body": "So I think that was mainly the solution, the tensorflow definition of the network was using a convolution instead of the fully connected linear matrix multiplication for fc6 fc7 fc8 ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/vgg.py#L116)). Did not think originally it would be a big problem but to recapitulate : \r\n\r\nModel | Timing\r\n--- | ---\r\nTF-slim default | 160ms\r\nTF-slim + NCHW | 150ms\r\nfc layers instead of conv | 94ms\r\nfc layers instead of conv + NCHW | 82ms\r\npytorch | 65ms\r\n\r\nThere is still a gap but it is definitely more acceptable, should we consider this as resolved?"}