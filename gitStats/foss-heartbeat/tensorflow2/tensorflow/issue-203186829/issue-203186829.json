{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7065", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7065/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7065/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7065/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7065", "id": 203186829, "node_id": "MDU6SXNzdWUyMDMxODY4Mjk=", "number": 7065, "title": "pytorch 2.5x faster on VGG16", "user": {"login": "SeguinBe", "id": 7132817, "node_id": "MDQ6VXNlcjcxMzI4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/7132817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SeguinBe", "html_url": "https://github.com/SeguinBe", "followers_url": "https://api.github.com/users/SeguinBe/followers", "following_url": "https://api.github.com/users/SeguinBe/following{/other_user}", "gists_url": "https://api.github.com/users/SeguinBe/gists{/gist_id}", "starred_url": "https://api.github.com/users/SeguinBe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SeguinBe/subscriptions", "organizations_url": "https://api.github.com/users/SeguinBe/orgs", "repos_url": "https://api.github.com/users/SeguinBe/repos", "events_url": "https://api.github.com/users/SeguinBe/events{/privacy}", "received_events_url": "https://api.github.com/users/SeguinBe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2017-01-25T18:40:58Z", "updated_at": "2018-09-07T14:51:18Z", "closed_at": "2017-05-10T03:03:31Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Started on SO, and was told to post here (<a href=\"http://stackoverflow.com/questions/41832779/tensorflow-2-5x-slower-than-pytorch-on-vgg16-architecture?noredirect=1#comment70901342_41832779\" rel=\"nofollow\">SO post</a>)</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 14.04 + Maxwell Titan X</p>\n<p>Installed version of CUDA and cuDNN:<br>\nCUDA 8.0, cuDNN 5.1</p>\n<div class=\"highlight highlight-source-python\"><pre>:<span class=\"pl-k\">~</span><span class=\"pl-ii\">$</span> ls <span class=\"pl-k\">-</span>l <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcud<span class=\"pl-k\">*</span>\n<span class=\"pl-k\">-</span>rw<span class=\"pl-k\">-</span>r<span class=\"pl-ii\">--</span>r<span class=\"pl-ii\">--</span> <span class=\"pl-c1\">1</span> root root    <span class=\"pl-c1\">558720</span> Jan <span class=\"pl-c1\">25</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span>:<span class=\"pl-c1\">23</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudadevrt.a\nlrwxrwxrwx <span class=\"pl-c1\">1</span> root root        <span class=\"pl-c1\">16</span> Jan <span class=\"pl-c1\">25</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span>:<span class=\"pl-c1\">23</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudart.so <span class=\"pl-ii\">-&gt;</span> libcudart.so.8.0\nlrwxrwxrwx <span class=\"pl-c1\">1</span> root root        <span class=\"pl-c1\">19</span> Jan <span class=\"pl-c1\">25</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span>:<span class=\"pl-c1\">23</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudart.so.8.0 <span class=\"pl-ii\">-&gt;</span> libcudart.so.8.0.44\n<span class=\"pl-k\">-</span>rwxr<span class=\"pl-k\">-</span>xr<span class=\"pl-k\">-</span>x <span class=\"pl-c1\">1</span> root root    <span class=\"pl-c1\">415432</span> Jan <span class=\"pl-c1\">25</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span>:<span class=\"pl-c1\">23</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudart.so.8.0.44\n<span class=\"pl-k\">-</span>rw<span class=\"pl-k\">-</span>r<span class=\"pl-ii\">--</span>r<span class=\"pl-ii\">--</span> <span class=\"pl-c1\">1</span> root root    <span class=\"pl-c1\">775162</span> Jan <span class=\"pl-c1\">25</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span>:<span class=\"pl-c1\">23</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudart_static.a\nlrwxrwxrwx <span class=\"pl-c1\">1</span> <span class=\"pl-c1\">1000</span> users       <span class=\"pl-c1\">13</span> Jul <span class=\"pl-c1\">27</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">7</span></span>:<span class=\"pl-c1\">55</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudnn.so <span class=\"pl-ii\">-&gt;</span> libcudnn.so.5\nlrwxrwxrwx <span class=\"pl-c1\">1</span> <span class=\"pl-c1\">1000</span> users       <span class=\"pl-c1\">17</span> Jul <span class=\"pl-c1\">27</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">7</span></span>:<span class=\"pl-c1\">55</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudnn.so.5 <span class=\"pl-ii\">-&gt;</span> libcudnn.so.5.1.5\n<span class=\"pl-k\">-</span>rwxrwxr<span class=\"pl-k\">-</span>x <span class=\"pl-c1\">1</span> <span class=\"pl-c1\">1000</span> users <span class=\"pl-c1\">79337624</span> Jul <span class=\"pl-c1\">27</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">7</span></span>:<span class=\"pl-c1\">53</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudnn.so.5.1.5\n<span class=\"pl-k\">-</span>rw<span class=\"pl-k\">-</span>rw<span class=\"pl-k\">-</span>r<span class=\"pl-ii\">--</span> <span class=\"pl-c1\">1</span> <span class=\"pl-c1\">1000</span> users <span class=\"pl-c1\">69756172</span> Jul <span class=\"pl-c1\">27</span> <span class=\"pl-c1\">0<span class=\"pl-ii\">7</span></span>:<span class=\"pl-c1\">53</span> <span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib64<span class=\"pl-k\">/</span>libcudnn_static.a</pre></div>\n<p>Installed from binary pip package :</p>\n<ol>\n<li><a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-linux_x86_64.whl</a> with an Anaconda distribution</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>:</li>\n</ol>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n0.12.1\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Using the following code to do a forward pass on a pretrained VGG16 :</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib <span class=\"pl-k\">import</span> slim\n<span class=\"pl-k\">from</span> tensorflow.contrib.slim <span class=\"pl-k\">import</span> nets\n\ntf.reset_default_graph()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Use RNG to avoid the feed_dict argument</span>\ninput_images <span class=\"pl-k\">=</span> tf.random_uniform((<span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">maxval</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">255</span>)  \npreds <span class=\"pl-k\">=</span> nets.vgg.vgg_16(input_images, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)[<span class=\"pl-c1\">0</span>]\nsaver <span class=\"pl-k\">=</span> tf.train.Saver()\n\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">log_device_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nsess <span class=\"pl-k\">=</span> tf.InteractiveSession(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\nsaver.restore(sess, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>./vgg_16.ckpt<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> With jupyter notebook magic</span>\n<span class=\"pl-k\">%</span>timeit sess.run(preds)</pre></div>\n<p>Compared to the pytorch version on the same machine :</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torchvision.models <span class=\"pl-k\">as</span> models\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\ntorch.backends.cudnn.benchmark <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\nnet <span class=\"pl-k\">=</span> models.vgg16()\nnet.cuda()\n\n_in <span class=\"pl-k\">=</span> Variable(torch.from_numpy(np.random.randn(<span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>).astype(np.float32)).cuda())\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> With jupyter notebook magic</span>\n<span class=\"pl-k\">%</span>timeit net(_in)</pre></div>\n<p>I get the following results by comparing the frameworks. Surprisingly, there is a small difference with the more complicated resnet-50 while I get a huge gap for the VGG16 architecture which (almost) just uses 3x3 convolutions.</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>TF</th>\n<th>pytorch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>VGG16</td>\n<td>160ms</td>\n<td>65ms</td>\n</tr>\n<tr>\n<td>resnet-50</td>\n<td>58ms</td>\n<td>48ms</td>\n</tr>\n</tbody>\n</table>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nStarted on SO, and was told to post here (SO post)\nEnvironment info\nOperating System:\nUbuntu 14.04 + Maxwell Titan X\nInstalled version of CUDA and cuDNN:\nCUDA 8.0, cuDNN 5.1\n:~$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root    558720 Jan 25 08:23 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root    415432 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root    775162 Jan 25 08:23 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 users       13 Jul 27 07:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 1000 users       17 Jul 27 07:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxrwxr-x 1 1000 users 79337624 Jul 27 07:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-rw-r-- 1 1000 users 69756172 Jul 27 07:53 /usr/local/cuda/lib64/libcudnn_static.a\nInstalled from binary pip package :\n\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-linux_x86_64.whl with an Anaconda distribution\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\":\n\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n0.12.1\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nUsing the following code to do a forward pass on a pretrained VGG16 :\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nfrom tensorflow.contrib.slim import nets\n\ntf.reset_default_graph()\n# Use RNG to avoid the feed_dict argument\ninput_images = tf.random_uniform((16, 224, 224, 3), maxval=255)  \npreds = nets.vgg.vgg_16(input_images, is_training=False)[0]\nsaver = tf.train.Saver()\n\nconfig = tf.ConfigProto(log_device_placement=True)\nsess = tf.InteractiveSession(config=config)\nsaver.restore(sess, './vgg_16.ckpt')\n\n# With jupyter notebook magic\n%timeit sess.run(preds)\nCompared to the pytorch version on the same machine :\nimport numpy as np\nimport torch\nimport torchvision.models as models\nfrom torch.autograd import Variable\ntorch.backends.cudnn.benchmark = True\n\nnet = models.vgg16()\nnet.cuda()\n\n_in = Variable(torch.from_numpy(np.random.randn(16, 3, 224, 224).astype(np.float32)).cuda())\n\n# With jupyter notebook magic\n%timeit net(_in)\nI get the following results by comparing the frameworks. Surprisingly, there is a small difference with the more complicated resnet-50 while I get a huge gap for the VGG16 architecture which (almost) just uses 3x3 convolutions.\n\n\n\nModel\nTF\npytorch\n\n\n\n\nVGG16\n160ms\n65ms\n\n\nresnet-50\n58ms\n48ms", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nStarted on SO, and was told to post here ([SO post](http://stackoverflow.com/questions/41832779/tensorflow-2-5x-slower-than-pytorch-on-vgg16-architecture?noredirect=1#comment70901342_41832779))\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04 + Maxwell Titan X\r\n\r\nInstalled version of CUDA and cuDNN: \r\nCUDA 8.0, cuDNN 5.1\r\n```python\r\n:~$ ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root    558720 Jan 25 08:23 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root        16 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root        19 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root    415432 Jan 25 08:23 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    775162 Jan 25 08:23 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 1000 users       13 Jul 27 07:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 1000 users       17 Jul 27 07:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxrwxr-x 1 1000 users 79337624 Jul 27 07:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-rw-r-- 1 1000 users 69756172 Jul 27 07:53 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nInstalled from binary pip package :\r\n1. https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-linux_x86_64.whl with an Anaconda distribution\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\r\n````\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.1\r\n````\r\n\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nUsing the following code to do a forward pass on a pretrained VGG16 :\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import slim\r\nfrom tensorflow.contrib.slim import nets\r\n\r\ntf.reset_default_graph()\r\n# Use RNG to avoid the feed_dict argument\r\ninput_images = tf.random_uniform((16, 224, 224, 3), maxval=255)  \r\npreds = nets.vgg.vgg_16(input_images, is_training=False)[0]\r\nsaver = tf.train.Saver()\r\n\r\nconfig = tf.ConfigProto(log_device_placement=True)\r\nsess = tf.InteractiveSession(config=config)\r\nsaver.restore(sess, './vgg_16.ckpt')\r\n\r\n# With jupyter notebook magic\r\n%timeit sess.run(preds)\r\n```\r\n\r\nCompared to the pytorch version on the same machine :\r\n```python\r\nimport numpy as np\r\nimport torch\r\nimport torchvision.models as models\r\nfrom torch.autograd import Variable\r\ntorch.backends.cudnn.benchmark = True\r\n\r\nnet = models.vgg16()\r\nnet.cuda()\r\n\r\n_in = Variable(torch.from_numpy(np.random.randn(16, 3, 224, 224).astype(np.float32)).cuda())\r\n\r\n# With jupyter notebook magic\r\n%timeit net(_in)\r\n```\r\n\r\nI get the following results by comparing the frameworks. Surprisingly, there is a small difference with the more complicated resnet-50 while I get a huge gap for the VGG16 architecture which (almost) just uses 3x3 convolutions.\r\n\r\n\r\nModel | TF | pytorch\r\n--- | --- | ---\r\nVGG16 | 160ms | 65ms\r\nresnet-50 | 58ms | 48ms"}