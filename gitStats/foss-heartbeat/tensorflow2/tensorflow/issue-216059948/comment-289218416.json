{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289218416", "html_url": "https://github.com/tensorflow/tensorflow/issues/8624#issuecomment-289218416", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8624", "id": 289218416, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTIxODQxNg==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-25T15:22:17Z", "updated_at": "2017-03-25T15:22:17Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">Right. When xla is enabled, all that is jit'ed shows as a single node. So\nit may or may not be folded inside.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mar 25, 2017 8:19 AM, \"Huazuo Gao\" ***@***.***&gt; wrote:\n I have tried enabling XLA with both session config and jit_scope. With the\n session config approach, nothing changed. With jit_scope, all nodes became\n shaded, but even when a was fed, so it is more likely an incompatibility\n between XLA and tracing than an indication that constant folding is working.\n\n Global constant folding has its own problem, in that a full graph can only\n be run using a session, while a partition graph requires just an executor.\n Therefore, constant folding sounds more suitable as an JIT optimization to\n me. For example, a session triggers constant folding at the second run,\n then it identifies constant foldable tensors and add them to fetches, and\n finally substitute them at the third run.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"216059948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8624\" href=\"https://github.com/tensorflow/tensorflow/issues/8624#issuecomment-289218123\">#8624 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AT_SbbebDW61-pTcM9cp9tgmg3z2UEzlks5rpTBogaJpZM4MlL8n\">https://github.com/notifications/unsubscribe-auth/AT_SbbebDW61-pTcM9cp9tgmg3z2UEzlks5rpTBogaJpZM4MlL8n</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Right. When xla is enabled, all that is jit'ed shows as a single node. So\nit may or may not be folded inside.\n\u2026\nOn Mar 25, 2017 8:19 AM, \"Huazuo Gao\" ***@***.***> wrote:\n I have tried enabling XLA with both session config and jit_scope. With the\n session config approach, nothing changed. With jit_scope, all nodes became\n shaded, but even when a was fed, so it is more likely an incompatibility\n between XLA and tracing than an indication that constant folding is working.\n\n Global constant folding has its own problem, in that a full graph can only\n be run using a session, while a partition graph requires just an executor.\n Therefore, constant folding sounds more suitable as an JIT optimization to\n me. For example, a session triggers constant folding at the second run,\n then it identifies constant foldable tensors and add them to fetches, and\n finally substitute them at the third run.\n\n \u2014\n You are receiving this because you commented.\n Reply to this email directly, view it on GitHub\n <#8624 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AT_SbbebDW61-pTcM9cp9tgmg3z2UEzlks5rpTBogaJpZM4MlL8n>\n .", "body": "Right. When xla is enabled, all that is jit'ed shows as a single node. So\nit may or may not be folded inside.\n\nOn Mar 25, 2017 8:19 AM, \"Huazuo Gao\" <notifications@github.com> wrote:\n\n> I have tried enabling XLA with both session config and jit_scope. With the\n> session config approach, nothing changed. With jit_scope, all nodes became\n> shaded, but even when a was fed, so it is more likely an incompatibility\n> between XLA and tracing than an indication that constant folding is working.\n>\n> Global constant folding has its own problem, in that a full graph can only\n> be run using a session, while a partition graph requires just an executor.\n> Therefore, constant folding sounds more suitable as an JIT optimization to\n> me. For example, a session triggers constant folding at the second run,\n> then it identifies constant foldable tensors and add them to fetches, and\n> finally substitute them at the third run.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8624#issuecomment-289218123>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbbebDW61-pTcM9cp9tgmg3z2UEzlks5rpTBogaJpZM4MlL8n>\n> .\n>\n"}