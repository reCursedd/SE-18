{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14646", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14646/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14646/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14646/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14646", "id": 274777204, "node_id": "MDU6SXNzdWUyNzQ3NzcyMDQ=", "number": 14646, "title": "tf.bitwise.bitwise_and and friends have bad shape functions", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-17T07:36:31Z", "updated_at": "2017-12-27T22:44:18Z", "closed_at": "2017-12-27T22:44:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The bitwise ops are componentwise and do normal broadcasting at the kernel level.  However, they claim unchanged shape during op registration:</p>\n<pre><code>#define BINARY_BITWISE()                                                     \\\n  Input(\"x: T\")                                                              \\\n      .Input(\"y: T\")                                                         \\\n      .Output(\"z: T\")                                                        \\\n      .SetIsCommutative()                                                    \\\n      .Attr(\"T: {int8, int16, int32, int64, uint8, uint16, uint32, uint64}\") \\\n      .SetShapeFn(shape_inference::UnchangedShape)\n</code></pre>\n<p>To reproduce, do</p>\n<pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; tf.bitwise.bitwise_and(tf.zeros([3,1], dtype=tf.int32), tf.zeros([1,3], dtype=tf.int32))\n&lt;tf.Tensor 'BitwiseAnd:0' shape=(3, 1) dtype=int32&gt;\n</code></pre>\n<p>The result shape should be <code>(3, 3)</code>, not <code>(3, 1)</code>.</p>", "body_text": "The bitwise ops are componentwise and do normal broadcasting at the kernel level.  However, they claim unchanged shape during op registration:\n#define BINARY_BITWISE()                                                     \\\n  Input(\"x: T\")                                                              \\\n      .Input(\"y: T\")                                                         \\\n      .Output(\"z: T\")                                                        \\\n      .SetIsCommutative()                                                    \\\n      .Attr(\"T: {int8, int16, int32, int64, uint8, uint16, uint32, uint64}\") \\\n      .SetShapeFn(shape_inference::UnchangedShape)\n\nTo reproduce, do\n>>> import tensorflow as tf\n>>> tf.bitwise.bitwise_and(tf.zeros([3,1], dtype=tf.int32), tf.zeros([1,3], dtype=tf.int32))\n<tf.Tensor 'BitwiseAnd:0' shape=(3, 1) dtype=int32>\n\nThe result shape should be (3, 3), not (3, 1).", "body": "The bitwise ops are componentwise and do normal broadcasting at the kernel level.  However, they claim unchanged shape during op registration:\r\n\r\n    #define BINARY_BITWISE()                                                     \\\r\n      Input(\"x: T\")                                                              \\\r\n          .Input(\"y: T\")                                                         \\\r\n          .Output(\"z: T\")                                                        \\\r\n          .SetIsCommutative()                                                    \\\r\n          .Attr(\"T: {int8, int16, int32, int64, uint8, uint16, uint32, uint64}\") \\\r\n          .SetShapeFn(shape_inference::UnchangedShape)\r\n\r\nTo reproduce, do\r\n\r\n    >>> import tensorflow as tf\r\n    >>> tf.bitwise.bitwise_and(tf.zeros([3,1], dtype=tf.int32), tf.zeros([1,3], dtype=tf.int32))\r\n    <tf.Tensor 'BitwiseAnd:0' shape=(3, 1) dtype=int32>\r\n\r\nThe result shape should be `(3, 3)`, not `(3, 1)`."}