{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10166", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10166/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10166/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10166/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10166", "id": 231119119, "node_id": "MDU6SXNzdWUyMzExMTkxMTk=", "number": 10166, "title": "OOM error when initializing float tensors 1/2 the size of the VRAM (in bytes)", "user": {"login": "oleg-trott", "id": 2914939, "node_id": "MDQ6VXNlcjI5MTQ5Mzk=", "avatar_url": "https://avatars1.githubusercontent.com/u/2914939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oleg-trott", "html_url": "https://github.com/oleg-trott", "followers_url": "https://api.github.com/users/oleg-trott/followers", "following_url": "https://api.github.com/users/oleg-trott/following{/other_user}", "gists_url": "https://api.github.com/users/oleg-trott/gists{/gist_id}", "starred_url": "https://api.github.com/users/oleg-trott/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oleg-trott/subscriptions", "organizations_url": "https://api.github.com/users/oleg-trott/orgs", "repos_url": "https://api.github.com/users/oleg-trott/repos", "events_url": "https://api.github.com/users/oleg-trott/events{/privacy}", "received_events_url": "https://api.github.com/users/oleg-trott/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-05-24T17:44:48Z", "updated_at": "2017-12-22T17:02:05Z", "closed_at": "2017-12-22T17:02:05Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14.04 (64 bit)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip install tensorflow-gpu</li>\n<li><strong>TensorFlow version (use command below)</strong>:  ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/5.1.10-1</li>\n<li><strong>GPU model and memory</strong>: K40 / 12 GB (also GTX 980 / 4 GB)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p><code>time CUDA_VISIBLE_DEVICES=1 python memory_usage.py</code></p>\n<p>TF encounters OOM when I try to initialize an array half the size of the VRAM, but only when it's a FLOAT type (float16, float32, float64). This happens even when <code>trainable=False</code>.</p>\n<p>I checked via <code>nvidia-smi</code> that no other process is using the GPU.</p>\n<pre><code>import tensorflow as tf\n\nvram = 12 * 1024 ** 3 # 12 GB\n\ndef use_half_vram(dtype):\n    n = vram // dtype.size // 2\n    x = tf.get_variable('x', shape=[n], dtype=dtype, \\\n        initializer=tf.constant_initializer(7), trainable=False)\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n# use_half_vram(tf.uint8) # OK\n# use_half_vram(tf.int32) # OK\n# use_half_vram(tf.int64) # OK\n# use_half_vram(tf.float16) # OOM\nuse_half_vram(tf.float32) # OOM\n# use_half_vram(tf.float64) # OOM\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04 (64 bit)\nTensorFlow installed from (source or binary): pip install tensorflow-gpu\nTensorFlow version (use command below):  ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: 8.0/5.1.10-1\nGPU model and memory: K40 / 12 GB (also GTX 980 / 4 GB)\nExact command to reproduce:\n\ntime CUDA_VISIBLE_DEVICES=1 python memory_usage.py\nTF encounters OOM when I try to initialize an array half the size of the VRAM, but only when it's a FLOAT type (float16, float32, float64). This happens even when trainable=False.\nI checked via nvidia-smi that no other process is using the GPU.\nimport tensorflow as tf\n\nvram = 12 * 1024 ** 3 # 12 GB\n\ndef use_half_vram(dtype):\n    n = vram // dtype.size // 2\n    x = tf.get_variable('x', shape=[n], dtype=dtype, \\\n        initializer=tf.constant_initializer(7), trainable=False)\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n# use_half_vram(tf.uint8) # OK\n# use_half_vram(tf.int32) # OK\n# use_half_vram(tf.int64) # OK\n# use_half_vram(tf.float16) # OOM\nuse_half_vram(tf.float32) # OOM\n# use_half_vram(tf.float64) # OOM", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04 (64 bit)\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**:  ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8.0/5.1.10-1\r\n- **GPU model and memory**: K40 / 12 GB (also GTX 980 / 4 GB)\r\n- **Exact command to reproduce**:\r\n\r\n`time CUDA_VISIBLE_DEVICES=1 python memory_usage.py`\r\n\r\nTF encounters OOM when I try to initialize an array half the size of the VRAM, but only when it's a FLOAT type (float16, float32, float64). This happens even when `trainable=False`.\r\n\r\nI checked via `nvidia-smi` that no other process is using the GPU.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nvram = 12 * 1024 ** 3 # 12 GB\r\n\r\ndef use_half_vram(dtype):\r\n    n = vram // dtype.size // 2\r\n    x = tf.get_variable('x', shape=[n], dtype=dtype, \\\r\n        initializer=tf.constant_initializer(7), trainable=False)\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n# use_half_vram(tf.uint8) # OK\r\n# use_half_vram(tf.int32) # OK\r\n# use_half_vram(tf.int64) # OK\r\n# use_half_vram(tf.float16) # OOM\r\nuse_half_vram(tf.float32) # OOM\r\n# use_half_vram(tf.float64) # OOM\r\n```\r\n\r\n"}