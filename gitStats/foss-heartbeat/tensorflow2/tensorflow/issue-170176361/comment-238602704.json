{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238602704", "html_url": "https://github.com/tensorflow/tensorflow/issues/3710#issuecomment-238602704", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3710", "id": 238602704, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODYwMjcwNA==", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-09T16:06:55Z", "updated_at": "2016-08-09T16:06:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If you comment out the <code>Defun</code>, it's computing the gradient of softplus correctly.  Your gradient function is wrong, since softplus isn't the identity function and doesn't have derivative 1, but computes what I'd expect given its implementation.</p>\n<p>The fact that you can't apply a Defun to a variable is a bug.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15696327\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andydavis1\">@andydavis1</a>: Could you take a look?</p>", "body_text": "If you comment out the Defun, it's computing the gradient of softplus correctly.  Your gradient function is wrong, since softplus isn't the identity function and doesn't have derivative 1, but computes what I'd expect given its implementation.\nThe fact that you can't apply a Defun to a variable is a bug.  @andydavis1: Could you take a look?", "body": "If you comment out the `Defun`, it's computing the gradient of softplus correctly.  Your gradient function is wrong, since softplus isn't the identity function and doesn't have derivative 1, but computes what I'd expect given its implementation.\n\nThe fact that you can't apply a Defun to a variable is a bug.  @andydavis1: Could you take a look?\n"}