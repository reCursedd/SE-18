{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2627", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2627/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2627/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2627/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2627", "id": 158243930, "node_id": "MDU6SXNzdWUxNTgyNDM5MzA=", "number": 2627, "title": "Complex Gradients in gather", "user": {"login": "ynashed", "id": 696719, "node_id": "MDQ6VXNlcjY5NjcxOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/696719?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ynashed", "html_url": "https://github.com/ynashed", "followers_url": "https://api.github.com/users/ynashed/followers", "following_url": "https://api.github.com/users/ynashed/following{/other_user}", "gists_url": "https://api.github.com/users/ynashed/gists{/gist_id}", "starred_url": "https://api.github.com/users/ynashed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ynashed/subscriptions", "organizations_url": "https://api.github.com/users/ynashed/orgs", "repos_url": "https://api.github.com/users/ynashed/repos", "events_url": "https://api.github.com/users/ynashed/events{/privacy}", "received_events_url": "https://api.github.com/users/ynashed/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-06-02T21:28:09Z", "updated_at": "2017-02-09T22:37:14Z", "closed_at": "2016-06-04T03:06:43Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Linux Ubuntu 14.04 LTS (64bit)</p>\n<p>Installed version of CUDA and cuDNN: CUDA 7.5.18 and CUDNN 5.0.4<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed. Tensorflow 0.8.0 Nightly Python2.7 Linux (GPU) <a href=\"http://ci.tensorflow.org/job/nigntly-matrix-linux-gpu/118/\" rel=\"nofollow\">Build 118</a></li>\n</ol>\n<h3>Steps to reproduce</h3>\n<p>I tried to run the following code using the tensorflow pip package  <code>storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl</code></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nW <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform( (<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">1</span>) ), tf.float32)\nW <span class=\"pl-k\">=</span> tf.complex(W, <span class=\"pl-c1\">1.0</span>)\nC <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">1</span>))\n\nviews <span class=\"pl-k\">=</span> tf.gather(W, [<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">5</span>])\nloss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.square( tf.complex_abs(views) <span class=\"pl-k\">-</span> C))\n\noptimizer <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-v\">learning_rate</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>)\ntrain <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n\ninit <span class=\"pl-k\">=</span> tf.initialize_all_variables()\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(init)</pre></div>\n<p>I got<br>\n<code>TypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16</code></p>\n<p>I looked it up and found issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153518419\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2255\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2255/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2255\">#2255</a> so I installed the nightly build 118, and now I get this when trying to run the same code snippet</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span><span class=\"pl-ii\">0671dcd6f73e</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n      <span class=\"pl-c1\">9</span> \n     <span class=\"pl-c1\">10</span> optimizer <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-v\">learning_rate</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">11</span> train <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n     <span class=\"pl-c1\">12</span> \n     <span class=\"pl-c1\">13</span> init <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n\n<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>dist<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>training<span class=\"pl-k\">/</span>optimizer.pyc <span class=\"pl-k\">in</span> minimize(<span class=\"pl-c1\">self</span>, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\n    <span class=\"pl-c1\">191</span>         aggregation_method<span class=\"pl-k\">=</span>aggregation_method,\n    <span class=\"pl-c1\">192</span>         colocate_gradients_with_ops<span class=\"pl-k\">=</span>colocate_gradients_with_ops,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">193</span>         grad_loss<span class=\"pl-k\">=</span>grad_loss)\n    <span class=\"pl-c1\">194</span>     <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.apply_gradients(grads_and_vars, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>global_step,\n    <span class=\"pl-c1\">195</span>                                 <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n\n<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>dist<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>training<span class=\"pl-k\">/</span>optimizer.pyc <span class=\"pl-k\">in</span> compute_gradients(<span class=\"pl-c1\">self</span>, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\n    <span class=\"pl-c1\">248</span>         gate_gradients<span class=\"pl-k\">=</span>(gate_gradients <span class=\"pl-k\">==</span> Optimizer.<span class=\"pl-c1\">GATE_OP</span>),\n    <span class=\"pl-c1\">249</span>         aggregation_method<span class=\"pl-k\">=</span>aggregation_method,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">250</span>         colocate_gradients_with_ops<span class=\"pl-k\">=</span>colocate_gradients_with_ops)\n    <span class=\"pl-c1\">251</span>     <span class=\"pl-k\">if</span> gate_gradients <span class=\"pl-k\">==</span> Optimizer.<span class=\"pl-c1\">GATE_GRAPH</span>:\n    <span class=\"pl-c1\">252</span>       grads <span class=\"pl-k\">=</span> control_flow_ops.tuple(grads)\n\n<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>dist<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gradients.pyc <span class=\"pl-k\">in</span> gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\n    <span class=\"pl-c1\">503</span>           <span class=\"pl-k\">if</span> in_grad <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n    <span class=\"pl-c1\">504</span>             <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(in_grad, ops.Tensor):\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">505</span>               in_grad.set_shape(t_in.get_shape())\n    <span class=\"pl-c1\">506</span>             _SetGrad(grads, t_in, in_grad)\n    <span class=\"pl-c1\">507</span>         <span class=\"pl-k\">if</span> loop_state:\n\n<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>dist<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>framework<span class=\"pl-k\">/</span>ops.pyc <span class=\"pl-k\">in</span> set_shape(<span class=\"pl-c1\">self</span>, shape)\n    <span class=\"pl-c1\">402</span>         this tensor.\n    <span class=\"pl-c1\">403</span>     <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">--&gt; 404     self._shape = self._shape.merge_with(shape)</span>\n<span class=\"pl-s\">    405 </span>\n<span class=\"pl-s\">    406   @property</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)</span>\n<span class=\"pl-s\">    568       except ValueError:</span>\n<span class=\"pl-s\">    569         raise ValueError(\"Shapes <span class=\"pl-c1\">%s</span> and <span class=\"pl-c1\">%s</span> are not compatible\" %</span>\n<span class=\"pl-s\">--&gt; 570                          (self, other))</span>\n<span class=\"pl-s\">    571 </span>\n<span class=\"pl-s\">    572   def concatenate(self, other):</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">ValueError: Shapes (?, 1) and () are not compatible</span></pre></div>", "body_text": "Environment info\nOperating System: Linux Ubuntu 14.04 LTS (64bit)\nInstalled version of CUDA and cuDNN: CUDA 7.5.18 and CUDNN 5.0.4\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n\nIf installed from binary pip package, provide:\n\nWhich pip package you installed. Tensorflow 0.8.0 Nightly Python2.7 Linux (GPU) Build 118\n\nSteps to reproduce\nI tried to run the following code using the tensorflow pip package  storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\nimport tensorflow as tf\n\nW = tf.Variable(tf.random_uniform( (10,1) ), tf.float32)\nW = tf.complex(W, 1.0)\nC = tf.constant(1.0, dtype=tf.float32, shape=(3,1))\n\nviews = tf.gather(W, [2,1,5])\nloss = tf.reduce_mean(tf.square( tf.complex_abs(views) - C))\n\noptimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\ntrain = optimizer.minimize(loss)\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\nI got\nTypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16\nI looked it up and found issue #2255 so I installed the nightly build 118, and now I get this when trying to run the same code snippet\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-1-0671dcd6f73e> in <module>()\n      9 \n     10 optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n---> 11 train = optimizer.minimize(loss)\n     12 \n     13 init = tf.initialize_all_variables()\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\n    191         aggregation_method=aggregation_method,\n    192         colocate_gradients_with_ops=colocate_gradients_with_ops,\n--> 193         grad_loss=grad_loss)\n    194     return self.apply_gradients(grads_and_vars, global_step=global_step,\n    195                                 name=name)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\n    248         gate_gradients=(gate_gradients == Optimizer.GATE_OP),\n    249         aggregation_method=aggregation_method,\n--> 250         colocate_gradients_with_ops=colocate_gradients_with_ops)\n    251     if gate_gradients == Optimizer.GATE_GRAPH:\n    252       grads = control_flow_ops.tuple(grads)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\n    503           if in_grad is not None:\n    504             if isinstance(in_grad, ops.Tensor):\n--> 505               in_grad.set_shape(t_in.get_shape())\n    506             _SetGrad(grads, t_in, in_grad)\n    507         if loop_state:\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shape(self, shape)\n    402         this tensor.\n    403     \"\"\"\n--> 404     self._shape = self._shape.merge_with(shape)\n    405 \n    406   @property\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)\n    568       except ValueError:\n    569         raise ValueError(\"Shapes %s and %s are not compatible\" %\n--> 570                          (self, other))\n    571 \n    572   def concatenate(self, other):\n\nValueError: Shapes (?, 1) and () are not compatible", "body": "### Environment info\n\nOperating System: Linux Ubuntu 14.04 LTS (64bit)\n\nInstalled version of CUDA and cuDNN: CUDA 7.5.18 and CUDNN 5.0.4\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\nls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. Tensorflow 0.8.0 Nightly Python2.7 Linux (GPU) [Build 118](http://ci.tensorflow.org/job/nigntly-matrix-linux-gpu/118/)\n### Steps to reproduce\n\nI tried to run the following code using the tensorflow pip package  `storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl` \n\n``` python\nimport tensorflow as tf\n\nW = tf.Variable(tf.random_uniform( (10,1) ), tf.float32)\nW = tf.complex(W, 1.0)\nC = tf.constant(1.0, dtype=tf.float32, shape=(3,1))\n\nviews = tf.gather(W, [2,1,5])\nloss = tf.reduce_mean(tf.square( tf.complex_abs(views) - C))\n\noptimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\ntrain = optimizer.minimize(loss)\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n```\n\nI got\n`TypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16`\n\nI looked it up and found issue #2255 so I installed the nightly build 118, and now I get this when trying to run the same code snippet\n\n``` python\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-1-0671dcd6f73e> in <module>()\n      9 \n     10 optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n---> 11 train = optimizer.minimize(loss)\n     12 \n     13 init = tf.initialize_all_variables()\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\n    191         aggregation_method=aggregation_method,\n    192         colocate_gradients_with_ops=colocate_gradients_with_ops,\n--> 193         grad_loss=grad_loss)\n    194     return self.apply_gradients(grads_and_vars, global_step=global_step,\n    195                                 name=name)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc in compute_gradients(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\n    248         gate_gradients=(gate_gradients == Optimizer.GATE_OP),\n    249         aggregation_method=aggregation_method,\n--> 250         colocate_gradients_with_ops=colocate_gradients_with_ops)\n    251     if gate_gradients == Optimizer.GATE_GRAPH:\n    252       grads = control_flow_ops.tuple(grads)\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\n    503           if in_grad is not None:\n    504             if isinstance(in_grad, ops.Tensor):\n--> 505               in_grad.set_shape(t_in.get_shape())\n    506             _SetGrad(grads, t_in, in_grad)\n    507         if loop_state:\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shape(self, shape)\n    402         this tensor.\n    403     \"\"\"\n--> 404     self._shape = self._shape.merge_with(shape)\n    405 \n    406   @property\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc in merge_with(self, other)\n    568       except ValueError:\n    569         raise ValueError(\"Shapes %s and %s are not compatible\" %\n--> 570                          (self, other))\n    571 \n    572   def concatenate(self, other):\n\nValueError: Shapes (?, 1) and () are not compatible\n```\n"}