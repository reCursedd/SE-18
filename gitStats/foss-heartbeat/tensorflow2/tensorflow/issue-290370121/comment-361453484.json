{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361453484", "html_url": "https://github.com/tensorflow/tensorflow/issues/16279#issuecomment-361453484", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16279", "id": 361453484, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTQ1MzQ4NA==", "user": {"login": "Aashit-Sharma", "id": 29089622, "node_id": "MDQ6VXNlcjI5MDg5NjIy", "avatar_url": "https://avatars0.githubusercontent.com/u/29089622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aashit-Sharma", "html_url": "https://github.com/Aashit-Sharma", "followers_url": "https://api.github.com/users/Aashit-Sharma/followers", "following_url": "https://api.github.com/users/Aashit-Sharma/following{/other_user}", "gists_url": "https://api.github.com/users/Aashit-Sharma/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aashit-Sharma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aashit-Sharma/subscriptions", "organizations_url": "https://api.github.com/users/Aashit-Sharma/orgs", "repos_url": "https://api.github.com/users/Aashit-Sharma/repos", "events_url": "https://api.github.com/users/Aashit-Sharma/events{/privacy}", "received_events_url": "https://api.github.com/users/Aashit-Sharma/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T02:10:32Z", "updated_at": "2018-01-30T02:23:44Z", "author_association": "NONE", "body_html": "<p>Generate.py -</p>\n<pre><code>\nimport pickle\nfrom mrrnn import MRRNN\nfrom mrrnn import Configuration\n\n\n# tokenid's for end of utterance\nend_nl = 12575\nend_c = 15\n\nif __name__ == \"__main__\":\n\n\t# import dictionaries and test data\n\tnldict_path = \"./data/Dataset.dict.pkl\"\n\twith open(nldict_path,\"rb\") as file:\n\t\tnlvocab = pickle.load(file)\n\t\tnlvocab = sorted( nlvocab,key=lambda tup: tup[1] )\n\t\n\tcdict_path = \"./data/AE_Rep/abstract_dict.pkl\"\n\twith open(cdict_path,\"rb\") as file:\n\t\tcvocab = pickle.load(file)\n\t\tcvocab = sorted(cvocab,key=lambda tup: tup[1] )\n\n\t\t\n\tnltest_path = \"./data/Test.dialogues.pkl\"\n\twith open(nltest_path,\"rb\") as file:\n\t\tnltest = pickle.load(file)\n\t\t\n\tctest_path = \"./data/AE_Rep/abstract_test.pkl\"\n\twith open(ctest_path,\"rb\") as file:\n\t\tctest = pickle.load(file)\n\n\tconfig = Configuration()\n\tconfig.learning_rate = 0.0003\n\tconfig.nlvocab = len(nlvocab) \n\tconfig.cvocab = len(cvocab)\n\tconfig.end_of_word_utt = end_nl \n\tconfig.end_of_coarse_utt = end_c\n\t\n\n#the model\n\tmodel = MRRNN(config)\n\tN_dialogue = 10\n\n\tfile_name = \"./ckpts/training_5/trained.ckpt\"\n\tmodel.restore(file_name)\n\tnlDialog,cDialog = model.split_utterances([nltest[N_dialogue]],[ctest[N_dialogue]])\n\tprediction = model.generate(nlDialog[0][:-1],cDialog[0][:-1],20,20)\n\t# print nlDialog[0]\n\tfor curr_utt in xrange(len(nlDialog[0])-1):\n\t\tcurr_str = \"\"\n\t\tfor k in xrange(len(nlDialog[0][curr_utt])-1):\n\t\t\tcurr_str += nlvocab[nlDialog[0][curr_utt][k]][0] + \" \"\n\t\t\tprint (curr_str)\n\n\tcurr_str = \"\"\n\tfor k in xrange(len(prediction)):\n\t\tcurr_str += nlvocab[prediction[k]][0] + \" \"\n\t\tprint (curr_str)\n</code></pre>", "body_text": "Generate.py -\n\nimport pickle\nfrom mrrnn import MRRNN\nfrom mrrnn import Configuration\n\n\n# tokenid's for end of utterance\nend_nl = 12575\nend_c = 15\n\nif __name__ == \"__main__\":\n\n\t# import dictionaries and test data\n\tnldict_path = \"./data/Dataset.dict.pkl\"\n\twith open(nldict_path,\"rb\") as file:\n\t\tnlvocab = pickle.load(file)\n\t\tnlvocab = sorted( nlvocab,key=lambda tup: tup[1] )\n\t\n\tcdict_path = \"./data/AE_Rep/abstract_dict.pkl\"\n\twith open(cdict_path,\"rb\") as file:\n\t\tcvocab = pickle.load(file)\n\t\tcvocab = sorted(cvocab,key=lambda tup: tup[1] )\n\n\t\t\n\tnltest_path = \"./data/Test.dialogues.pkl\"\n\twith open(nltest_path,\"rb\") as file:\n\t\tnltest = pickle.load(file)\n\t\t\n\tctest_path = \"./data/AE_Rep/abstract_test.pkl\"\n\twith open(ctest_path,\"rb\") as file:\n\t\tctest = pickle.load(file)\n\n\tconfig = Configuration()\n\tconfig.learning_rate = 0.0003\n\tconfig.nlvocab = len(nlvocab) \n\tconfig.cvocab = len(cvocab)\n\tconfig.end_of_word_utt = end_nl \n\tconfig.end_of_coarse_utt = end_c\n\t\n\n#the model\n\tmodel = MRRNN(config)\n\tN_dialogue = 10\n\n\tfile_name = \"./ckpts/training_5/trained.ckpt\"\n\tmodel.restore(file_name)\n\tnlDialog,cDialog = model.split_utterances([nltest[N_dialogue]],[ctest[N_dialogue]])\n\tprediction = model.generate(nlDialog[0][:-1],cDialog[0][:-1],20,20)\n\t# print nlDialog[0]\n\tfor curr_utt in xrange(len(nlDialog[0])-1):\n\t\tcurr_str = \"\"\n\t\tfor k in xrange(len(nlDialog[0][curr_utt])-1):\n\t\t\tcurr_str += nlvocab[nlDialog[0][curr_utt][k]][0] + \" \"\n\t\t\tprint (curr_str)\n\n\tcurr_str = \"\"\n\tfor k in xrange(len(prediction)):\n\t\tcurr_str += nlvocab[prediction[k]][0] + \" \"\n\t\tprint (curr_str)", "body": "Generate.py -\r\n\r\n```\r\n\r\nimport pickle\r\nfrom mrrnn import MRRNN\r\nfrom mrrnn import Configuration\r\n\r\n\r\n# tokenid's for end of utterance\r\nend_nl = 12575\r\nend_c = 15\r\n\r\nif __name__ == \"__main__\":\r\n\r\n\t# import dictionaries and test data\r\n\tnldict_path = \"./data/Dataset.dict.pkl\"\r\n\twith open(nldict_path,\"rb\") as file:\r\n\t\tnlvocab = pickle.load(file)\r\n\t\tnlvocab = sorted( nlvocab,key=lambda tup: tup[1] )\r\n\t\r\n\tcdict_path = \"./data/AE_Rep/abstract_dict.pkl\"\r\n\twith open(cdict_path,\"rb\") as file:\r\n\t\tcvocab = pickle.load(file)\r\n\t\tcvocab = sorted(cvocab,key=lambda tup: tup[1] )\r\n\r\n\t\t\r\n\tnltest_path = \"./data/Test.dialogues.pkl\"\r\n\twith open(nltest_path,\"rb\") as file:\r\n\t\tnltest = pickle.load(file)\r\n\t\t\r\n\tctest_path = \"./data/AE_Rep/abstract_test.pkl\"\r\n\twith open(ctest_path,\"rb\") as file:\r\n\t\tctest = pickle.load(file)\r\n\r\n\tconfig = Configuration()\r\n\tconfig.learning_rate = 0.0003\r\n\tconfig.nlvocab = len(nlvocab) \r\n\tconfig.cvocab = len(cvocab)\r\n\tconfig.end_of_word_utt = end_nl \r\n\tconfig.end_of_coarse_utt = end_c\r\n\t\r\n\r\n#the model\r\n\tmodel = MRRNN(config)\r\n\tN_dialogue = 10\r\n\r\n\tfile_name = \"./ckpts/training_5/trained.ckpt\"\r\n\tmodel.restore(file_name)\r\n\tnlDialog,cDialog = model.split_utterances([nltest[N_dialogue]],[ctest[N_dialogue]])\r\n\tprediction = model.generate(nlDialog[0][:-1],cDialog[0][:-1],20,20)\r\n\t# print nlDialog[0]\r\n\tfor curr_utt in xrange(len(nlDialog[0])-1):\r\n\t\tcurr_str = \"\"\r\n\t\tfor k in xrange(len(nlDialog[0][curr_utt])-1):\r\n\t\t\tcurr_str += nlvocab[nlDialog[0][curr_utt][k]][0] + \" \"\r\n\t\t\tprint (curr_str)\r\n\r\n\tcurr_str = \"\"\r\n\tfor k in xrange(len(prediction)):\r\n\t\tcurr_str += nlvocab[prediction[k]][0] + \" \"\r\n\t\tprint (curr_str)\r\n```"}