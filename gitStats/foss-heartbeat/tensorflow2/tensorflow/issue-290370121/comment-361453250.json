{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/361453250", "html_url": "https://github.com/tensorflow/tensorflow/issues/16279#issuecomment-361453250", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16279", "id": 361453250, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTQ1MzI1MA==", "user": {"login": "Aashit-Sharma", "id": 29089622, "node_id": "MDQ6VXNlcjI5MDg5NjIy", "avatar_url": "https://avatars0.githubusercontent.com/u/29089622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aashit-Sharma", "html_url": "https://github.com/Aashit-Sharma", "followers_url": "https://api.github.com/users/Aashit-Sharma/followers", "following_url": "https://api.github.com/users/Aashit-Sharma/following{/other_user}", "gists_url": "https://api.github.com/users/Aashit-Sharma/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aashit-Sharma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aashit-Sharma/subscriptions", "organizations_url": "https://api.github.com/users/Aashit-Sharma/orgs", "repos_url": "https://api.github.com/users/Aashit-Sharma/repos", "events_url": "https://api.github.com/users/Aashit-Sharma/events{/privacy}", "received_events_url": "https://api.github.com/users/Aashit-Sharma/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T02:09:13Z", "updated_at": "2018-01-30T02:22:28Z", "author_association": "NONE", "body_html": "<p>Sure. MrRNN.py:</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nclass Configuration:\n\tdef __init__(self):\n\t\t\n\t\tself.nl_embed_size = 50\n\t\tself.c_embed_size = 50\n\t\t\n\t\tself.nlvocab = 10\n\t\tself.cvocab = 10\n\t\t\n\t\tself.nl_enc_size = 100\n\t\tself.c_enc_size = 100\n\t\t\n\t\tself.nl_context = 100\n\t\tself.c_context = 100\n\t\t\n\t\tself.c_dec_size = 100\n\t\tself.nl_dec_size = 100\n\t\t\n\t\tself.pred_enc_size = 100\n\t\t\n\t\tself.learning_rate = 0.0002\n\t\t\n\t\tself.end_of_nl_utt = 0\n\t\tself.end_of_coarse_utt = 0\n\t\treturn\n\t\t\nclass MRRNN():\n\t\n\tdef __init__(self,config):\n\t\t\n\t\tself.nlvocab = config.nlvocab\n\t\tself.cvocab = config.cvocab\n\t\tself.nl_context = config.nl_context\n\t\tself.c_context = config.c_context\n\t\t\n\t\tself.nl_dec_size = config.nl_dec_size\n\t\tself.c_dec_size = config.c_dec_size\n\t\n\t\tself.nl_enc_size = config.nl_enc_size\n\t\tself.c_enc_size = config.c_enc_size\n\t\t\n\t\tself.nl_embed_size = config.nl_embed_size\n\t\tself.c_embed_size = config.c_embed_size\n\t\t\n\t\tself.pred_enc_size = config.pred_enc_size\n\t\tself.learning_rate = config.learning_rate\n\t\tself.end_of_nl_utt = config.end_of_nl_utt\n\t\tself.end_of_coarse_utt = config.end_of_coarse_utt\n\n\t\t#input embeddings\n\t\tself.ipemb_nl = tf.placeholder(tf.int32,[None],name=\"nl_embedding\")\t\t\n\t\tself.ipemb_c = tf.placeholder(tf.int32,[None],name=\"coarse_embedding\")\n\t\t\n\t\t#output nl/coarse length\n\t\tself.oplen_nl = tf.placeholder(tf.int32,[1],name=\"nl_oplen\")\n\t\tself.oplen_c = tf.placeholder(tf.int32,[1],name=\"c_oplen\")\n\n\t\t#tarlab =&gt; target label\n\t\tself.tarlab_nl = tf.placeholder(tf.int32,[None],name=\"tarlab_nl\")\n\t\tself.tarlab_c = tf.placeholder(tf.int32,[None],name=\"tarlab_c\")\n\t\t\n\t\t#prevcont =&gt; previous context(state)\n\t\tself.prevcont_nl = tf.placeholder(tf.float32,[1,self.c_context],name=\"prevcont_nl\")\n\t\tself.prevcont_c = tf.placeholder(tf.float32,[1,self.nl_context],name=\"prevcont_c\")\n\t\t#self.eou_c = tf.placeholder(self.end_of_coarse_utt,dtype)\n\t\t#self.eou_nl = tf.placeholder(self.end_of_nl_utt,dtype)\n\n\t\t\n\t\t#embedding variable\n\t\tself.nl_embedding = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_embed_size],-1,1))\n\t\tself.c_embedding = tf.Variable(tf.random_uniform([self.cvocab,self.c_embed_size],-1,1))\n\t\t\n\t\t#nlop_emb :: cop_emb =&gt; NL output embedding :: Coarse ****\n\t\tself.nlop_emb = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_dec_size],-1,1))\n\t\tself.cop_emb = tf.Variable(tf.random_uniform([self.cvocab,self.c_dec_size],-1,1))\n\t\t\n\t\t##GRAPH and LOSS##\n\t\t\n\t\tself._make_graph()\n\t\tself.loss_N_optimize()\n\t\tself.make_grad_acmul()\n\t\t\n\t\tinit = tf.initialize_all_vairables()\n\t\t\n\t\tself.sess = tf.Session()\n\t\tself.sess.run(init)\n\t\t\n\t\tself.writer = tf.summary.FileWriter(\"./log\",graph=self.see.graph)\n\t\t\n\t\tself.saver =tf.train.Saver()\n\t\t\n##########FUNCTIONS############################################################################################################################################################\n\t\t\n\t\n\t## makin the graf\n\t\n\tdef _make_graph(self):\n\t\t\n\t\tself.cRepresentation = self.coarse_embed_ip()\n\t\tself.encoded_coarse = self.coarse_encoder()\n\t\tself.current_hidden_coarse_context = self.coarse_context()\n\t\t\n\t\tself.coarse_prediction = self.coarse_decoder()\n\t\t\n\t\tself.encoded_prediction = self.coarse_prediction_encoder()\n\t\tself.nlRepresentation = self.nl_embed_ip()\n\t\t\n\t\tself.encoded_nl = self.nl_encoder()\n\t\tself.current_hidden_nl_context =self.nl_context()\n\t\t\n\t\tself.nl_context_concat = tf.concat(0,[self.current_hidden_nl_context,self.encoded_prediction])\n\t\t\n\t\tself.nl_prediction = self.nl_decoder()\n\t\t\n\t\tself.logits_nl,self.logits_coarse = self.compute_logits()\n\t\t\n\t\t\n##########NL TOKENS############################################################################################################################################################\n\t\n\tdef nl_embed_ip(self):\n\t\tselected_embedding = tf.nn.embedding_lookup(self.nl_embedding,self.ipemb_nl)\n\t\t\n\t\treturn tf.stack([selected_embedding])\n\t\n\tdef nl_encoder(self):\n\t\t\n\t\twith tf.variable_scope(\"NL_Encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_enc_size)\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,self.nlRepresentation,dtype=tf.float32)\n\t\t\t\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\n\t\t\n\tdef nl_context(self):\n\t\n\t\twith tf.variable_scope(\"NL_Context\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_context)\n\t\t\t\n\t\t\tself.reset_nl_state = cell.zero_state(1,dtype=tf.float32)\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_nl,initial_state = self.prevcont_nl)\n\t\t\t\t\t\t\t\n\t\treturn hidden[-1,:]\n\t\t\n###################################################################################################################################################\n\tdef nl_decoder_condition(self,it,outputs,hidden):\n\t\treturn it[0] &lt; self.oplen_nl[0]\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t# This is the step where we concatenate hidden state with context hidden state \t\t\t\n\tdef nl_decoder_function(self,it,outputs,hidden):\n\t\tout,hidden = self.decoder_nl_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.nl_context_concat])]) , tf.stack([hidden]))\n\t\t\n\t\toutputs = tf.concat(0,[outputs,out])\n\t\treturn it+1,outputs,hidden[0,:]\t\t\n###################################################################################################################################################\n\tdef nl_decoder(self):\n\t\t\n\t\twith tf.variable_scope(\"NL_Decoder\"):\n\t\t\tself.decoder_nl_cell = tf.contrib.rnn.GRUCell(self.nl_dec_size)\n\t\t\t\n\t\t\tself.iter_decoder_nl = tf.constant(0)\n\t\t\tself.iter_decoder_nl_test = tf.constant(0)\n\t\t\t\n\t\t\ttrain_decoder = tf.while_loop(self.nl_decoder_condition,self.nl_decoder_function, [ self.iter_decoder_nl, tf.zeros([1,self.nl_dec_size]) , tf.ones([self.nl_dec_size])],\\\n\t\t\tshape_invariants = [self.iter_decoder_nl.get_shape(), tf.TensorShape([None,self.nl_dec_size]),\\\n\t\t\ttf.TensorShape([self.nl_dec_size])])\n\n\t\treturn train_decoder[1][1:]\n\n\t\t\n############ COARSE TOKENS ##########################################################################################################################\n\t\n\tdef coarse_embed_ip(self):\n\t\t#this will go into the encoder\n\t\tselected_embedding = tf.nn.embedding_lookup(self.c_embedding,self.ipemb_c)\n\t\t\n\t\treturn tf.stack([selected_embedding])\n\t\n\tdef coarse_encoder(self):\n\t\n\t\twith tf.variable_scope(\"Coarse_Encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_enc_size)\n\t\t\t_, hidden_state= tf.nn.dynamic_rnn(cell,self.cRepresentation,dtype=tf.float32)\n\t\t\t\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\n\t\t\n\tdef coarse_context(self):\n\t\t\n\t\twith tf.variable_scope(\"Coarse_Context\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_context)\n\t\t\t\n\t\t\tself.reset_coarse_state = cell.zero_state(1,dtype=tf.int64)\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_coarse,initial_state = self.prevcont_c)\n\t\t\t\n\t\treturn hidden[-1,:]\n\t\t\n#################################################################################################\n\t\t\t\n\tdef coarse_decoder_condition(self,it,outputs,hidden):\n\t\treturn it[0] &lt; self.oplen_c[0]\n\t\t\n\t# This is the step where we concatenate hidden state with context hidden state  \n\tdef coarse_decoder_function(self,it,outputs,hidden):\n\t\tout,hidden = self.decoder_coarse_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.current_hidden_coarse_context])]), tf.stack([hidden]))\n\t\t\n\t\toutputs = tf.concat(0,[outputs,out])\n\t\treturn it+1,outputs,hidden[0,:]\n\t\n####################################################################################################\n\n\tdef coarse_decoder(self):\n\t\n\t\twith tf.variable_scope(\"Coarse_Decoder\"):\n\t\t\tself.decoder_coarse_cell = tf.contrib.rnn.GRUCell(self.c_dec_size)\n\t\t\t\n\t\t\tself.iter_decoder_c = tf.constant(0.0)\n\t\t\t#self.iter_decoder_c_test = tf.constant(0)\n\t\t\t\n\t\t\t#while_loop for parallel iterations\n\t\t\ttrain_decoder = tf.while_loop(self.coarse_decoder_condition, self.coarse_decoder_function ,\\\n\t\t\t\tloop_vars=[self.iter_decoder_c,\\\n\t\t\t\t\ttf.ones([self.c_dec_size]),\\\n\t\t\t\t\ttf.zeros([1,self.c_dec_size])],\\\n\t\t\t\tshape_invariants = [\\\n\t\t\t\t\t\t\t\t\tself.iter_decoder_c.get_shape(),\\\n\t\t\t\t\t\t\t\t\ttf.TensorShape([self.c_dec_size]),\\\n\t\t\t\t\t\t\t\t\ttf.TensorShape([None,self.c_dec_size])\\\n\t\t\t\t\t\t\t\t\t] )\n\t\t\t\t\t\t\t\t\t\t\n\t\treturn train_decoder[1][1:]\n\t\t\t\t\n\n\t## PREDICTION ENCODER ##\n\t\n\tdef coarse_prediction_encoder(self):\n\t\twith tf.variable_scope(\"prediction_encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.pred_enc_size)\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,tf.stack([self.coarse_prediction]),dtype = tf.float32)\n\t\t\t\n\n\t\treturn hidden_state[-1,:]\n\t\t\t\n\t\t\n\tdef compute_logits(self):\n\t\tlogits_nl = tf.matmul(self.nlop_emb,tf.transpose(self.nl_prediction))\n\t\t\n\t\tlogits_coarse = tf.matmul(self.cop_emb,tf.transpose(self.coarse_prediction))\n\t\t\n\t\treturn tf.transpose(logits_nl),tf.transpose(logits_coarse)\n\t\t\n\t\n\tdef loss_N_optimize(self):\n\t\tnl_onehot_target = tf.one_hot(self.tarlab_nl,self.nlvocab)\n\t\t\n\t\tcoarse_onehot_target = tf.one_hot(self.tarlab_c,self.cvocab)\n\t\t\n\t\tmap_nl = tf.nn.softmax_cross_entropy_with_logits(self.logits_nl, nl_onehot_target)\n\t\tmap_coarse = tf.nn.softmax_cross_entropy_with_logits(self.logits_coarse, coarse_onehot_target)\n\t\t\n\t\tself.loss = (tf.reduce_sum(map_nl) + tf.reduce_sum(map_coarse))\n\t\tseld.optimzer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n\t\t\t\n\t\n\t\n\tdef make_grad_acmul(self):\n\t\ttvs = tf.trainable_variables()\n\t\t\n\t\taccum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()) , trainable = False) for tv in tvs]\n\t\t\n\t\tzero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n\t\t\n\t\tgvs = self.optimizer.compute_gradients(self.loss, tvs)\n\t\t\n\t\taccum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n\t\t\n\t\tself.zero_grads = zero_ops\n\t\t\n\t\tself.grad_accumul = accum_ops\n\t\tself.grad_apply = self.optimizer.apply_gradients([(accum_vars[i],gv[1]) for i, gv in enumerate(gvs)])\n\t\t\n\t\n\tdef split_utterances(self,NL_X,C_X):\n\t\t#NL_X and C_X are batch of dialogues and their respective coarse utterances , respectively\n\t\tn_dialogues = len(NL_X)\n\t\tdialogues_nl = []\n\t\tdialogues_coarse = []\n\t\t\n\t\tfor i in xrange(n_dialogues):\n\t\t\t# splitting dialogues / utterances\n\t\t\tend_of_nl_utt = np.where( np.array(NL_X[i]) == self.end_of_nl_utt)[0]\n\t\t\tend_of_coarse_utt = np.where(np.array(C_X[i]) == self.end_of_coarse_utt)[0]\n\t\t\t\n\t\t\tcurrent_dialogue_nl = np.split(NL_X[i], end_of_nl_utt[:-1]+1)\n\t\t\tcurrent_dialogue_coarse = np.split(C_X[i], end_of_coarse_utt[:-1]+1)\n\t\t\t\n\t\t\tdialogues_nl.append(current_dialogue_nl)\n\t\t\tdialogues_coarse.append(current_dialogue_coarse)\n\t\t\t\n\t\t\n\t\treturn dialogues_nl,dialogues_coarse\n\t\t\n\t\t\n\tdef partial_fit(self,NL_X,C_X):\n\t\t\n\t\t#reset gradient computation\n\t\tself.sess.run(self.zero_grads)\t\t\n\t\tdialogues_nl,dialogues_coarse = self.split_utterances(NL_X,C_X)\n\t\t\n\t\t\n\t\t#Train\n\t\tfor dialogue in xrange(len(dialogues_nl)):\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue]) - 1):\n\t\t\t\tif u_id ==0:\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\t\n\t\t\t\tfeed_dict = {\\\n\t\t\t\tself.ipemb_nl : dialogues_nl[dialogue][u_id],\\\n\t\t\t\tself.ipemb_c : dialogues_coarse[dialogue][u_id],\\\n\t\t\t\tself.tarlab_nl : dialogues_nl[dialogue][u_id+1],\\\n\t\t\t\tself.tarlab_c : dialogues_coarse[dialogue][u_id+1],\\\n\t\t\t\tself.oplen_nl : [len(dialogues_nl[dialogue][u_id+1])],\\\n\t\t\t\tself.oplen_c : [len(dialogues_coarse[dialogue][u_id+1])],\\\n\t\t\t\tself.prevcont_nl : prev_nl,\\\n\t\t\t\tself.prevcont_c : prev_coarse\\\n\t\t\t\t}\n\t\t\t\n\t\t\t\tprev_coarse,prev_nl,_ = self.sess.run(\\\n\t\t\t\t\t\t(\\\n\t\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\t\tself.current_hidden_nl_context,\\\n\t\t\t\t\t\t\tself.grad_accumul),\\\n\t\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\t\tprev_coarse = [prev_coarse]\n\t\t\t\tprev_nl = [prev_nl]\n\t\tself.sess.run(self.grad_apply)\n\t\n\t\n\tdef cost(self,NL_X,C_X):\n\t\tdialogues_nl, dialogues_coarse = self.split_utterances(NL_X,C_X)\n\t\tfor dialogue in xrange(len(dialogues_nl)):\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue])-1):\n\t\t\t\tif u_id == 0 :\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\ttotal_loss = 0\n\t\t\t\t\t\n\t\t\t\tfeed_dict = {\\\n\t\t\t\t\tself.ipemb_nl: dialogues_nl[u_id],\\\n\t\t\t\t\tself.ipemb_c: dialogues_coarse[u_id],\\\n\t\t\t\t\tself.tarlab_nl: dialogues_nl[u_id+1],\\\n\t\t\t\t\tself.tarlab_c: dialogues_coarse[u_id+1],\\\n\t\t\t\t\tself.oplen_nl: [len(dialogues_nl[u_id+1])],\\\n\t\t\t\t\tself.oplen_c: [len(dialogues_coarse[u_id+1])],\\\n\t\t\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\t\t\tself.prevcont_nl: prev_nl\\\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprev_coarse,prev_nl,loss=self.sess.run(\\\n\t\t\t\t\t(\\\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\tself.current_hidden_nl_context,\\\n\t\t\t\t\t\tself.loss),\\\n\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\t\t\t\n\t\t\t\tprev_coarse = [prev_coarse]\n\t\t\t\tprev_nl = [prev_nl]\n\t\t\t\ttotal_loss += loss\n\t\t\t\n\t\t\ttotal_loss /= float(len(NL_X))\n\t\t\treturn total_loss\n\t\t\t\n\t\n\tdef generate(self,dialogue_nl,dialogue_coarse,max_coarse_generation=10,max_nl_generation=10):\n\t\t\n\t\tfor u_id in xrange(len(dialogue_nl)-1):\n\t\t\tif u_id == 0:\n\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\n\t\t\tfeed_dict = {\\\n\t\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\n\t\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\n\t\t\t\tself.tarlab_nl: dialogue_nl[u_id+1],\\\n\t\t\t\tself.tarlab_c: dialogue_coarse[u_id+1],\\\n\t\t\t\tself.oplen_nl: [len(dialogue_nl[u_id+1])],\\\n\t\t\t\tself.oplen_c: [len(dialogue_coarse[u_id+1])],\\\n\t\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\t\tself.prevcont_nl: prev_nl\\\n\t\t\t}\n\t\t\tprev_coarse,prev_nl=self.sess.run(\\\n\t\t\t\t\t(\\\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\tself.current_hidden_nl_context),\\\n\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\tprev_coarse = [prev_coarse]\n\t\t\tprev_nl = [prev_nl]\n\t\t\t\n\t\tu_id = len(dialogue_nl)-1\n\t\tfeed_dict = {\\\n\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\n\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\n\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\tself.prevcont_nl: prev_nl,\\\n\t\t\tself.oplen_nl: [max_nl_generation],\\\n\t\t\tself.oplen_c: [max_coarse_generation]\\\n\t\t}\n\t\t\n\t\tw_logits = self.sess.run(self.logits_nl,feed_dict=feed_dict)\n\t\tprediction = np.zeros([w_logits.shape[0]],dtype=int)\n\t\t\n\t\tfor i in xrange(len(prediction)):\n\t\t\tprobs = np.exp(w_logits[i])\n\t\t\tprobs /= probs.sum()\n\t\t\tprediction[i] = np.random.choice(self.nlvocab,p=probs)\n\t\treturn prediction \n\t\t\n\n\n\tdef save(self,file_path):\n\t\tself.saver.save(self.sess,file_path)\n\n\tdef restore(self,file_path):\n\t\tself.saver.restore(self.sess,file_path)\n\n\n\tif __name__ == \"__main__\":\n\n\t\tconfig = Configuration()\n\t\tconfig.nlvocab = 11\n\t\tconfig.cvocab = 11\n\t\tconfig.end_of_nl_utt = 10\n\t\tconfig.end_of_coarse_utt = 10\n\n\t\t# dummy input\n\t\tx_w = [ [ 3,5,8,3,10,2,3,5,9,9,10,8,7,6,1,0,10] ]\n\t\tx_z = [ [ 2,4,1,2,7,8,10,1,6,8,8,10,9,0,0,1,10] ]\n\t\tx_w_test = [ [3,5,8,3,10],[2,3,5,9,9,10] ] \n\t\tx_z_test = [ [2,4,1,2,7,8,10],[1,6,8,8,10] ]\n\n\t\tmodel = MRRNN(config)\n\t\tfor i in xrange(1000):\n\t\t\tmodel.partial_fit(x_w,x_z)\n\t\t\tloss = model.cost(x_w,x_z)\n\t\t\tprint (loss)\n\t\t\tprediction = model.generate(x_w_test,x_z_test,5,6)\n\t\t\t# should learn to predict the sequence [8,7,6,1,1,10]\n\t\t\tprint (prediction)\n\t\t\t\n\t\t\t\n\t\n\t\t\t\n\t\t\n\t'''\n\tKey points:\n\t- MrRNN is an advancement to the HRED model (proposed by Sordoni et al)\n\t- Utternace refers to dialogue in sequence ; it is , in turn , a sequence of words\n\t'''\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\n\t`\n</code></pre>", "body_text": "Sure. MrRNN.py:\nimport numpy as np\nimport tensorflow as tf\n\nclass Configuration:\n\tdef __init__(self):\n\t\t\n\t\tself.nl_embed_size = 50\n\t\tself.c_embed_size = 50\n\t\t\n\t\tself.nlvocab = 10\n\t\tself.cvocab = 10\n\t\t\n\t\tself.nl_enc_size = 100\n\t\tself.c_enc_size = 100\n\t\t\n\t\tself.nl_context = 100\n\t\tself.c_context = 100\n\t\t\n\t\tself.c_dec_size = 100\n\t\tself.nl_dec_size = 100\n\t\t\n\t\tself.pred_enc_size = 100\n\t\t\n\t\tself.learning_rate = 0.0002\n\t\t\n\t\tself.end_of_nl_utt = 0\n\t\tself.end_of_coarse_utt = 0\n\t\treturn\n\t\t\nclass MRRNN():\n\t\n\tdef __init__(self,config):\n\t\t\n\t\tself.nlvocab = config.nlvocab\n\t\tself.cvocab = config.cvocab\n\t\tself.nl_context = config.nl_context\n\t\tself.c_context = config.c_context\n\t\t\n\t\tself.nl_dec_size = config.nl_dec_size\n\t\tself.c_dec_size = config.c_dec_size\n\t\n\t\tself.nl_enc_size = config.nl_enc_size\n\t\tself.c_enc_size = config.c_enc_size\n\t\t\n\t\tself.nl_embed_size = config.nl_embed_size\n\t\tself.c_embed_size = config.c_embed_size\n\t\t\n\t\tself.pred_enc_size = config.pred_enc_size\n\t\tself.learning_rate = config.learning_rate\n\t\tself.end_of_nl_utt = config.end_of_nl_utt\n\t\tself.end_of_coarse_utt = config.end_of_coarse_utt\n\n\t\t#input embeddings\n\t\tself.ipemb_nl = tf.placeholder(tf.int32,[None],name=\"nl_embedding\")\t\t\n\t\tself.ipemb_c = tf.placeholder(tf.int32,[None],name=\"coarse_embedding\")\n\t\t\n\t\t#output nl/coarse length\n\t\tself.oplen_nl = tf.placeholder(tf.int32,[1],name=\"nl_oplen\")\n\t\tself.oplen_c = tf.placeholder(tf.int32,[1],name=\"c_oplen\")\n\n\t\t#tarlab => target label\n\t\tself.tarlab_nl = tf.placeholder(tf.int32,[None],name=\"tarlab_nl\")\n\t\tself.tarlab_c = tf.placeholder(tf.int32,[None],name=\"tarlab_c\")\n\t\t\n\t\t#prevcont => previous context(state)\n\t\tself.prevcont_nl = tf.placeholder(tf.float32,[1,self.c_context],name=\"prevcont_nl\")\n\t\tself.prevcont_c = tf.placeholder(tf.float32,[1,self.nl_context],name=\"prevcont_c\")\n\t\t#self.eou_c = tf.placeholder(self.end_of_coarse_utt,dtype)\n\t\t#self.eou_nl = tf.placeholder(self.end_of_nl_utt,dtype)\n\n\t\t\n\t\t#embedding variable\n\t\tself.nl_embedding = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_embed_size],-1,1))\n\t\tself.c_embedding = tf.Variable(tf.random_uniform([self.cvocab,self.c_embed_size],-1,1))\n\t\t\n\t\t#nlop_emb :: cop_emb => NL output embedding :: Coarse ****\n\t\tself.nlop_emb = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_dec_size],-1,1))\n\t\tself.cop_emb = tf.Variable(tf.random_uniform([self.cvocab,self.c_dec_size],-1,1))\n\t\t\n\t\t##GRAPH and LOSS##\n\t\t\n\t\tself._make_graph()\n\t\tself.loss_N_optimize()\n\t\tself.make_grad_acmul()\n\t\t\n\t\tinit = tf.initialize_all_vairables()\n\t\t\n\t\tself.sess = tf.Session()\n\t\tself.sess.run(init)\n\t\t\n\t\tself.writer = tf.summary.FileWriter(\"./log\",graph=self.see.graph)\n\t\t\n\t\tself.saver =tf.train.Saver()\n\t\t\n##########FUNCTIONS############################################################################################################################################################\n\t\t\n\t\n\t## makin the graf\n\t\n\tdef _make_graph(self):\n\t\t\n\t\tself.cRepresentation = self.coarse_embed_ip()\n\t\tself.encoded_coarse = self.coarse_encoder()\n\t\tself.current_hidden_coarse_context = self.coarse_context()\n\t\t\n\t\tself.coarse_prediction = self.coarse_decoder()\n\t\t\n\t\tself.encoded_prediction = self.coarse_prediction_encoder()\n\t\tself.nlRepresentation = self.nl_embed_ip()\n\t\t\n\t\tself.encoded_nl = self.nl_encoder()\n\t\tself.current_hidden_nl_context =self.nl_context()\n\t\t\n\t\tself.nl_context_concat = tf.concat(0,[self.current_hidden_nl_context,self.encoded_prediction])\n\t\t\n\t\tself.nl_prediction = self.nl_decoder()\n\t\t\n\t\tself.logits_nl,self.logits_coarse = self.compute_logits()\n\t\t\n\t\t\n##########NL TOKENS############################################################################################################################################################\n\t\n\tdef nl_embed_ip(self):\n\t\tselected_embedding = tf.nn.embedding_lookup(self.nl_embedding,self.ipemb_nl)\n\t\t\n\t\treturn tf.stack([selected_embedding])\n\t\n\tdef nl_encoder(self):\n\t\t\n\t\twith tf.variable_scope(\"NL_Encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_enc_size)\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,self.nlRepresentation,dtype=tf.float32)\n\t\t\t\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\n\t\t\n\tdef nl_context(self):\n\t\n\t\twith tf.variable_scope(\"NL_Context\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_context)\n\t\t\t\n\t\t\tself.reset_nl_state = cell.zero_state(1,dtype=tf.float32)\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_nl,initial_state = self.prevcont_nl)\n\t\t\t\t\t\t\t\n\t\treturn hidden[-1,:]\n\t\t\n###################################################################################################################################################\n\tdef nl_decoder_condition(self,it,outputs,hidden):\n\t\treturn it[0] < self.oplen_nl[0]\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t# This is the step where we concatenate hidden state with context hidden state \t\t\t\n\tdef nl_decoder_function(self,it,outputs,hidden):\n\t\tout,hidden = self.decoder_nl_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.nl_context_concat])]) , tf.stack([hidden]))\n\t\t\n\t\toutputs = tf.concat(0,[outputs,out])\n\t\treturn it+1,outputs,hidden[0,:]\t\t\n###################################################################################################################################################\n\tdef nl_decoder(self):\n\t\t\n\t\twith tf.variable_scope(\"NL_Decoder\"):\n\t\t\tself.decoder_nl_cell = tf.contrib.rnn.GRUCell(self.nl_dec_size)\n\t\t\t\n\t\t\tself.iter_decoder_nl = tf.constant(0)\n\t\t\tself.iter_decoder_nl_test = tf.constant(0)\n\t\t\t\n\t\t\ttrain_decoder = tf.while_loop(self.nl_decoder_condition,self.nl_decoder_function, [ self.iter_decoder_nl, tf.zeros([1,self.nl_dec_size]) , tf.ones([self.nl_dec_size])],\\\n\t\t\tshape_invariants = [self.iter_decoder_nl.get_shape(), tf.TensorShape([None,self.nl_dec_size]),\\\n\t\t\ttf.TensorShape([self.nl_dec_size])])\n\n\t\treturn train_decoder[1][1:]\n\n\t\t\n############ COARSE TOKENS ##########################################################################################################################\n\t\n\tdef coarse_embed_ip(self):\n\t\t#this will go into the encoder\n\t\tselected_embedding = tf.nn.embedding_lookup(self.c_embedding,self.ipemb_c)\n\t\t\n\t\treturn tf.stack([selected_embedding])\n\t\n\tdef coarse_encoder(self):\n\t\n\t\twith tf.variable_scope(\"Coarse_Encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_enc_size)\n\t\t\t_, hidden_state= tf.nn.dynamic_rnn(cell,self.cRepresentation,dtype=tf.float32)\n\t\t\t\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\n\t\t\n\tdef coarse_context(self):\n\t\t\n\t\twith tf.variable_scope(\"Coarse_Context\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_context)\n\t\t\t\n\t\t\tself.reset_coarse_state = cell.zero_state(1,dtype=tf.int64)\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_coarse,initial_state = self.prevcont_c)\n\t\t\t\n\t\treturn hidden[-1,:]\n\t\t\n#################################################################################################\n\t\t\t\n\tdef coarse_decoder_condition(self,it,outputs,hidden):\n\t\treturn it[0] < self.oplen_c[0]\n\t\t\n\t# This is the step where we concatenate hidden state with context hidden state  \n\tdef coarse_decoder_function(self,it,outputs,hidden):\n\t\tout,hidden = self.decoder_coarse_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.current_hidden_coarse_context])]), tf.stack([hidden]))\n\t\t\n\t\toutputs = tf.concat(0,[outputs,out])\n\t\treturn it+1,outputs,hidden[0,:]\n\t\n####################################################################################################\n\n\tdef coarse_decoder(self):\n\t\n\t\twith tf.variable_scope(\"Coarse_Decoder\"):\n\t\t\tself.decoder_coarse_cell = tf.contrib.rnn.GRUCell(self.c_dec_size)\n\t\t\t\n\t\t\tself.iter_decoder_c = tf.constant(0.0)\n\t\t\t#self.iter_decoder_c_test = tf.constant(0)\n\t\t\t\n\t\t\t#while_loop for parallel iterations\n\t\t\ttrain_decoder = tf.while_loop(self.coarse_decoder_condition, self.coarse_decoder_function ,\\\n\t\t\t\tloop_vars=[self.iter_decoder_c,\\\n\t\t\t\t\ttf.ones([self.c_dec_size]),\\\n\t\t\t\t\ttf.zeros([1,self.c_dec_size])],\\\n\t\t\t\tshape_invariants = [\\\n\t\t\t\t\t\t\t\t\tself.iter_decoder_c.get_shape(),\\\n\t\t\t\t\t\t\t\t\ttf.TensorShape([self.c_dec_size]),\\\n\t\t\t\t\t\t\t\t\ttf.TensorShape([None,self.c_dec_size])\\\n\t\t\t\t\t\t\t\t\t] )\n\t\t\t\t\t\t\t\t\t\t\n\t\treturn train_decoder[1][1:]\n\t\t\t\t\n\n\t## PREDICTION ENCODER ##\n\t\n\tdef coarse_prediction_encoder(self):\n\t\twith tf.variable_scope(\"prediction_encoder\"):\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.pred_enc_size)\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,tf.stack([self.coarse_prediction]),dtype = tf.float32)\n\t\t\t\n\n\t\treturn hidden_state[-1,:]\n\t\t\t\n\t\t\n\tdef compute_logits(self):\n\t\tlogits_nl = tf.matmul(self.nlop_emb,tf.transpose(self.nl_prediction))\n\t\t\n\t\tlogits_coarse = tf.matmul(self.cop_emb,tf.transpose(self.coarse_prediction))\n\t\t\n\t\treturn tf.transpose(logits_nl),tf.transpose(logits_coarse)\n\t\t\n\t\n\tdef loss_N_optimize(self):\n\t\tnl_onehot_target = tf.one_hot(self.tarlab_nl,self.nlvocab)\n\t\t\n\t\tcoarse_onehot_target = tf.one_hot(self.tarlab_c,self.cvocab)\n\t\t\n\t\tmap_nl = tf.nn.softmax_cross_entropy_with_logits(self.logits_nl, nl_onehot_target)\n\t\tmap_coarse = tf.nn.softmax_cross_entropy_with_logits(self.logits_coarse, coarse_onehot_target)\n\t\t\n\t\tself.loss = (tf.reduce_sum(map_nl) + tf.reduce_sum(map_coarse))\n\t\tseld.optimzer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n\t\t\t\n\t\n\t\n\tdef make_grad_acmul(self):\n\t\ttvs = tf.trainable_variables()\n\t\t\n\t\taccum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()) , trainable = False) for tv in tvs]\n\t\t\n\t\tzero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n\t\t\n\t\tgvs = self.optimizer.compute_gradients(self.loss, tvs)\n\t\t\n\t\taccum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n\t\t\n\t\tself.zero_grads = zero_ops\n\t\t\n\t\tself.grad_accumul = accum_ops\n\t\tself.grad_apply = self.optimizer.apply_gradients([(accum_vars[i],gv[1]) for i, gv in enumerate(gvs)])\n\t\t\n\t\n\tdef split_utterances(self,NL_X,C_X):\n\t\t#NL_X and C_X are batch of dialogues and their respective coarse utterances , respectively\n\t\tn_dialogues = len(NL_X)\n\t\tdialogues_nl = []\n\t\tdialogues_coarse = []\n\t\t\n\t\tfor i in xrange(n_dialogues):\n\t\t\t# splitting dialogues / utterances\n\t\t\tend_of_nl_utt = np.where( np.array(NL_X[i]) == self.end_of_nl_utt)[0]\n\t\t\tend_of_coarse_utt = np.where(np.array(C_X[i]) == self.end_of_coarse_utt)[0]\n\t\t\t\n\t\t\tcurrent_dialogue_nl = np.split(NL_X[i], end_of_nl_utt[:-1]+1)\n\t\t\tcurrent_dialogue_coarse = np.split(C_X[i], end_of_coarse_utt[:-1]+1)\n\t\t\t\n\t\t\tdialogues_nl.append(current_dialogue_nl)\n\t\t\tdialogues_coarse.append(current_dialogue_coarse)\n\t\t\t\n\t\t\n\t\treturn dialogues_nl,dialogues_coarse\n\t\t\n\t\t\n\tdef partial_fit(self,NL_X,C_X):\n\t\t\n\t\t#reset gradient computation\n\t\tself.sess.run(self.zero_grads)\t\t\n\t\tdialogues_nl,dialogues_coarse = self.split_utterances(NL_X,C_X)\n\t\t\n\t\t\n\t\t#Train\n\t\tfor dialogue in xrange(len(dialogues_nl)):\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue]) - 1):\n\t\t\t\tif u_id ==0:\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\t\n\t\t\t\tfeed_dict = {\\\n\t\t\t\tself.ipemb_nl : dialogues_nl[dialogue][u_id],\\\n\t\t\t\tself.ipemb_c : dialogues_coarse[dialogue][u_id],\\\n\t\t\t\tself.tarlab_nl : dialogues_nl[dialogue][u_id+1],\\\n\t\t\t\tself.tarlab_c : dialogues_coarse[dialogue][u_id+1],\\\n\t\t\t\tself.oplen_nl : [len(dialogues_nl[dialogue][u_id+1])],\\\n\t\t\t\tself.oplen_c : [len(dialogues_coarse[dialogue][u_id+1])],\\\n\t\t\t\tself.prevcont_nl : prev_nl,\\\n\t\t\t\tself.prevcont_c : prev_coarse\\\n\t\t\t\t}\n\t\t\t\n\t\t\t\tprev_coarse,prev_nl,_ = self.sess.run(\\\n\t\t\t\t\t\t(\\\n\t\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\t\tself.current_hidden_nl_context,\\\n\t\t\t\t\t\t\tself.grad_accumul),\\\n\t\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\t\tprev_coarse = [prev_coarse]\n\t\t\t\tprev_nl = [prev_nl]\n\t\tself.sess.run(self.grad_apply)\n\t\n\t\n\tdef cost(self,NL_X,C_X):\n\t\tdialogues_nl, dialogues_coarse = self.split_utterances(NL_X,C_X)\n\t\tfor dialogue in xrange(len(dialogues_nl)):\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue])-1):\n\t\t\t\tif u_id == 0 :\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\ttotal_loss = 0\n\t\t\t\t\t\n\t\t\t\tfeed_dict = {\\\n\t\t\t\t\tself.ipemb_nl: dialogues_nl[u_id],\\\n\t\t\t\t\tself.ipemb_c: dialogues_coarse[u_id],\\\n\t\t\t\t\tself.tarlab_nl: dialogues_nl[u_id+1],\\\n\t\t\t\t\tself.tarlab_c: dialogues_coarse[u_id+1],\\\n\t\t\t\t\tself.oplen_nl: [len(dialogues_nl[u_id+1])],\\\n\t\t\t\t\tself.oplen_c: [len(dialogues_coarse[u_id+1])],\\\n\t\t\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\t\t\tself.prevcont_nl: prev_nl\\\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprev_coarse,prev_nl,loss=self.sess.run(\\\n\t\t\t\t\t(\\\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\tself.current_hidden_nl_context,\\\n\t\t\t\t\t\tself.loss),\\\n\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\t\t\t\n\t\t\t\tprev_coarse = [prev_coarse]\n\t\t\t\tprev_nl = [prev_nl]\n\t\t\t\ttotal_loss += loss\n\t\t\t\n\t\t\ttotal_loss /= float(len(NL_X))\n\t\t\treturn total_loss\n\t\t\t\n\t\n\tdef generate(self,dialogue_nl,dialogue_coarse,max_coarse_generation=10,max_nl_generation=10):\n\t\t\n\t\tfor u_id in xrange(len(dialogue_nl)-1):\n\t\t\tif u_id == 0:\n\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\n\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\n\t\t\t\t\n\t\t\tfeed_dict = {\\\n\t\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\n\t\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\n\t\t\t\tself.tarlab_nl: dialogue_nl[u_id+1],\\\n\t\t\t\tself.tarlab_c: dialogue_coarse[u_id+1],\\\n\t\t\t\tself.oplen_nl: [len(dialogue_nl[u_id+1])],\\\n\t\t\t\tself.oplen_c: [len(dialogue_coarse[u_id+1])],\\\n\t\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\t\tself.prevcont_nl: prev_nl\\\n\t\t\t}\n\t\t\tprev_coarse,prev_nl=self.sess.run(\\\n\t\t\t\t\t(\\\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\n\t\t\t\t\t\tself.current_hidden_nl_context),\\\n\t\t\t\t\tfeed_dict=feed_dict)\n\t\t\tprev_coarse = [prev_coarse]\n\t\t\tprev_nl = [prev_nl]\n\t\t\t\n\t\tu_id = len(dialogue_nl)-1\n\t\tfeed_dict = {\\\n\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\n\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\n\t\t\tself.prevcont_c: prev_coarse, \\\n\t\t\tself.prevcont_nl: prev_nl,\\\n\t\t\tself.oplen_nl: [max_nl_generation],\\\n\t\t\tself.oplen_c: [max_coarse_generation]\\\n\t\t}\n\t\t\n\t\tw_logits = self.sess.run(self.logits_nl,feed_dict=feed_dict)\n\t\tprediction = np.zeros([w_logits.shape[0]],dtype=int)\n\t\t\n\t\tfor i in xrange(len(prediction)):\n\t\t\tprobs = np.exp(w_logits[i])\n\t\t\tprobs /= probs.sum()\n\t\t\tprediction[i] = np.random.choice(self.nlvocab,p=probs)\n\t\treturn prediction \n\t\t\n\n\n\tdef save(self,file_path):\n\t\tself.saver.save(self.sess,file_path)\n\n\tdef restore(self,file_path):\n\t\tself.saver.restore(self.sess,file_path)\n\n\n\tif __name__ == \"__main__\":\n\n\t\tconfig = Configuration()\n\t\tconfig.nlvocab = 11\n\t\tconfig.cvocab = 11\n\t\tconfig.end_of_nl_utt = 10\n\t\tconfig.end_of_coarse_utt = 10\n\n\t\t# dummy input\n\t\tx_w = [ [ 3,5,8,3,10,2,3,5,9,9,10,8,7,6,1,0,10] ]\n\t\tx_z = [ [ 2,4,1,2,7,8,10,1,6,8,8,10,9,0,0,1,10] ]\n\t\tx_w_test = [ [3,5,8,3,10],[2,3,5,9,9,10] ] \n\t\tx_z_test = [ [2,4,1,2,7,8,10],[1,6,8,8,10] ]\n\n\t\tmodel = MRRNN(config)\n\t\tfor i in xrange(1000):\n\t\t\tmodel.partial_fit(x_w,x_z)\n\t\t\tloss = model.cost(x_w,x_z)\n\t\t\tprint (loss)\n\t\t\tprediction = model.generate(x_w_test,x_z_test,5,6)\n\t\t\t# should learn to predict the sequence [8,7,6,1,1,10]\n\t\t\tprint (prediction)\n\t\t\t\n\t\t\t\n\t\n\t\t\t\n\t\t\n\t'''\n\tKey points:\n\t- MrRNN is an advancement to the HRED model (proposed by Sordoni et al)\n\t- Utternace refers to dialogue in sequence ; it is , in turn , a sequence of words\n\t'''\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\n\t`", "body": "Sure. MrRNN.py:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nclass Configuration:\r\n\tdef __init__(self):\r\n\t\t\r\n\t\tself.nl_embed_size = 50\r\n\t\tself.c_embed_size = 50\r\n\t\t\r\n\t\tself.nlvocab = 10\r\n\t\tself.cvocab = 10\r\n\t\t\r\n\t\tself.nl_enc_size = 100\r\n\t\tself.c_enc_size = 100\r\n\t\t\r\n\t\tself.nl_context = 100\r\n\t\tself.c_context = 100\r\n\t\t\r\n\t\tself.c_dec_size = 100\r\n\t\tself.nl_dec_size = 100\r\n\t\t\r\n\t\tself.pred_enc_size = 100\r\n\t\t\r\n\t\tself.learning_rate = 0.0002\r\n\t\t\r\n\t\tself.end_of_nl_utt = 0\r\n\t\tself.end_of_coarse_utt = 0\r\n\t\treturn\r\n\t\t\r\nclass MRRNN():\r\n\t\r\n\tdef __init__(self,config):\r\n\t\t\r\n\t\tself.nlvocab = config.nlvocab\r\n\t\tself.cvocab = config.cvocab\r\n\t\tself.nl_context = config.nl_context\r\n\t\tself.c_context = config.c_context\r\n\t\t\r\n\t\tself.nl_dec_size = config.nl_dec_size\r\n\t\tself.c_dec_size = config.c_dec_size\r\n\t\r\n\t\tself.nl_enc_size = config.nl_enc_size\r\n\t\tself.c_enc_size = config.c_enc_size\r\n\t\t\r\n\t\tself.nl_embed_size = config.nl_embed_size\r\n\t\tself.c_embed_size = config.c_embed_size\r\n\t\t\r\n\t\tself.pred_enc_size = config.pred_enc_size\r\n\t\tself.learning_rate = config.learning_rate\r\n\t\tself.end_of_nl_utt = config.end_of_nl_utt\r\n\t\tself.end_of_coarse_utt = config.end_of_coarse_utt\r\n\r\n\t\t#input embeddings\r\n\t\tself.ipemb_nl = tf.placeholder(tf.int32,[None],name=\"nl_embedding\")\t\t\r\n\t\tself.ipemb_c = tf.placeholder(tf.int32,[None],name=\"coarse_embedding\")\r\n\t\t\r\n\t\t#output nl/coarse length\r\n\t\tself.oplen_nl = tf.placeholder(tf.int32,[1],name=\"nl_oplen\")\r\n\t\tself.oplen_c = tf.placeholder(tf.int32,[1],name=\"c_oplen\")\r\n\r\n\t\t#tarlab => target label\r\n\t\tself.tarlab_nl = tf.placeholder(tf.int32,[None],name=\"tarlab_nl\")\r\n\t\tself.tarlab_c = tf.placeholder(tf.int32,[None],name=\"tarlab_c\")\r\n\t\t\r\n\t\t#prevcont => previous context(state)\r\n\t\tself.prevcont_nl = tf.placeholder(tf.float32,[1,self.c_context],name=\"prevcont_nl\")\r\n\t\tself.prevcont_c = tf.placeholder(tf.float32,[1,self.nl_context],name=\"prevcont_c\")\r\n\t\t#self.eou_c = tf.placeholder(self.end_of_coarse_utt,dtype)\r\n\t\t#self.eou_nl = tf.placeholder(self.end_of_nl_utt,dtype)\r\n\r\n\t\t\r\n\t\t#embedding variable\r\n\t\tself.nl_embedding = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_embed_size],-1,1))\r\n\t\tself.c_embedding = tf.Variable(tf.random_uniform([self.cvocab,self.c_embed_size],-1,1))\r\n\t\t\r\n\t\t#nlop_emb :: cop_emb => NL output embedding :: Coarse ****\r\n\t\tself.nlop_emb = tf.Variable(tf.random_uniform([self.nlvocab,self.nl_dec_size],-1,1))\r\n\t\tself.cop_emb = tf.Variable(tf.random_uniform([self.cvocab,self.c_dec_size],-1,1))\r\n\t\t\r\n\t\t##GRAPH and LOSS##\r\n\t\t\r\n\t\tself._make_graph()\r\n\t\tself.loss_N_optimize()\r\n\t\tself.make_grad_acmul()\r\n\t\t\r\n\t\tinit = tf.initialize_all_vairables()\r\n\t\t\r\n\t\tself.sess = tf.Session()\r\n\t\tself.sess.run(init)\r\n\t\t\r\n\t\tself.writer = tf.summary.FileWriter(\"./log\",graph=self.see.graph)\r\n\t\t\r\n\t\tself.saver =tf.train.Saver()\r\n\t\t\r\n##########FUNCTIONS############################################################################################################################################################\r\n\t\t\r\n\t\r\n\t## makin the graf\r\n\t\r\n\tdef _make_graph(self):\r\n\t\t\r\n\t\tself.cRepresentation = self.coarse_embed_ip()\r\n\t\tself.encoded_coarse = self.coarse_encoder()\r\n\t\tself.current_hidden_coarse_context = self.coarse_context()\r\n\t\t\r\n\t\tself.coarse_prediction = self.coarse_decoder()\r\n\t\t\r\n\t\tself.encoded_prediction = self.coarse_prediction_encoder()\r\n\t\tself.nlRepresentation = self.nl_embed_ip()\r\n\t\t\r\n\t\tself.encoded_nl = self.nl_encoder()\r\n\t\tself.current_hidden_nl_context =self.nl_context()\r\n\t\t\r\n\t\tself.nl_context_concat = tf.concat(0,[self.current_hidden_nl_context,self.encoded_prediction])\r\n\t\t\r\n\t\tself.nl_prediction = self.nl_decoder()\r\n\t\t\r\n\t\tself.logits_nl,self.logits_coarse = self.compute_logits()\r\n\t\t\r\n\t\t\r\n##########NL TOKENS############################################################################################################################################################\r\n\t\r\n\tdef nl_embed_ip(self):\r\n\t\tselected_embedding = tf.nn.embedding_lookup(self.nl_embedding,self.ipemb_nl)\r\n\t\t\r\n\t\treturn tf.stack([selected_embedding])\r\n\t\r\n\tdef nl_encoder(self):\r\n\t\t\r\n\t\twith tf.variable_scope(\"NL_Encoder\"):\r\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_enc_size)\r\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,self.nlRepresentation,dtype=tf.float32)\r\n\t\t\t\r\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\r\n\t\t\r\n\tdef nl_context(self):\r\n\t\r\n\t\twith tf.variable_scope(\"NL_Context\"):\r\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.nl_context)\r\n\t\t\t\r\n\t\t\tself.reset_nl_state = cell.zero_state(1,dtype=tf.float32)\r\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_nl,initial_state = self.prevcont_nl)\r\n\t\t\t\t\t\t\t\r\n\t\treturn hidden[-1,:]\r\n\t\t\r\n###################################################################################################################################################\r\n\tdef nl_decoder_condition(self,it,outputs,hidden):\r\n\t\treturn it[0] < self.oplen_nl[0]\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\r\n\t# This is the step where we concatenate hidden state with context hidden state \t\t\t\r\n\tdef nl_decoder_function(self,it,outputs,hidden):\r\n\t\tout,hidden = self.decoder_nl_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.nl_context_concat])]) , tf.stack([hidden]))\r\n\t\t\r\n\t\toutputs = tf.concat(0,[outputs,out])\r\n\t\treturn it+1,outputs,hidden[0,:]\t\t\r\n###################################################################################################################################################\r\n\tdef nl_decoder(self):\r\n\t\t\r\n\t\twith tf.variable_scope(\"NL_Decoder\"):\r\n\t\t\tself.decoder_nl_cell = tf.contrib.rnn.GRUCell(self.nl_dec_size)\r\n\t\t\t\r\n\t\t\tself.iter_decoder_nl = tf.constant(0)\r\n\t\t\tself.iter_decoder_nl_test = tf.constant(0)\r\n\t\t\t\r\n\t\t\ttrain_decoder = tf.while_loop(self.nl_decoder_condition,self.nl_decoder_function, [ self.iter_decoder_nl, tf.zeros([1,self.nl_dec_size]) , tf.ones([self.nl_dec_size])],\\\r\n\t\t\tshape_invariants = [self.iter_decoder_nl.get_shape(), tf.TensorShape([None,self.nl_dec_size]),\\\r\n\t\t\ttf.TensorShape([self.nl_dec_size])])\r\n\r\n\t\treturn train_decoder[1][1:]\r\n\r\n\t\t\r\n############ COARSE TOKENS ##########################################################################################################################\r\n\t\r\n\tdef coarse_embed_ip(self):\r\n\t\t#this will go into the encoder\r\n\t\tselected_embedding = tf.nn.embedding_lookup(self.c_embedding,self.ipemb_c)\r\n\t\t\r\n\t\treturn tf.stack([selected_embedding])\r\n\t\r\n\tdef coarse_encoder(self):\r\n\t\r\n\t\twith tf.variable_scope(\"Coarse_Encoder\"):\r\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_enc_size)\r\n\t\t\t_, hidden_state= tf.nn.dynamic_rnn(cell,self.cRepresentation,dtype=tf.float32)\r\n\t\t\t\r\n\t\treturn [tf.stack([hidden_state[-1,:]]) ]\r\n\t\t\r\n\tdef coarse_context(self):\r\n\t\t\r\n\t\twith tf.variable_scope(\"Coarse_Context\"):\r\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.c_context)\r\n\t\t\t\r\n\t\t\tself.reset_coarse_state = cell.zero_state(1,dtype=tf.int64)\r\n\t\t\t_,hidden = tf.nn.static_rnn(cell,self.encoded_coarse,initial_state = self.prevcont_c)\r\n\t\t\t\r\n\t\treturn hidden[-1,:]\r\n\t\t\r\n#################################################################################################\r\n\t\t\t\r\n\tdef coarse_decoder_condition(self,it,outputs,hidden):\r\n\t\treturn it[0] < self.oplen_c[0]\r\n\t\t\r\n\t# This is the step where we concatenate hidden state with context hidden state  \r\n\tdef coarse_decoder_function(self,it,outputs,hidden):\r\n\t\tout,hidden = self.decoder_coarse_cell(tf.stack([tf.concat(0,[outputs[-1,:],self.current_hidden_coarse_context])]), tf.stack([hidden]))\r\n\t\t\r\n\t\toutputs = tf.concat(0,[outputs,out])\r\n\t\treturn it+1,outputs,hidden[0,:]\r\n\t\r\n####################################################################################################\r\n\r\n\tdef coarse_decoder(self):\r\n\t\r\n\t\twith tf.variable_scope(\"Coarse_Decoder\"):\r\n\t\t\tself.decoder_coarse_cell = tf.contrib.rnn.GRUCell(self.c_dec_size)\r\n\t\t\t\r\n\t\t\tself.iter_decoder_c = tf.constant(0.0)\r\n\t\t\t#self.iter_decoder_c_test = tf.constant(0)\r\n\t\t\t\r\n\t\t\t#while_loop for parallel iterations\r\n\t\t\ttrain_decoder = tf.while_loop(self.coarse_decoder_condition, self.coarse_decoder_function ,\\\r\n\t\t\t\tloop_vars=[self.iter_decoder_c,\\\r\n\t\t\t\t\ttf.ones([self.c_dec_size]),\\\r\n\t\t\t\t\ttf.zeros([1,self.c_dec_size])],\\\r\n\t\t\t\tshape_invariants = [\\\r\n\t\t\t\t\t\t\t\t\tself.iter_decoder_c.get_shape(),\\\r\n\t\t\t\t\t\t\t\t\ttf.TensorShape([self.c_dec_size]),\\\r\n\t\t\t\t\t\t\t\t\ttf.TensorShape([None,self.c_dec_size])\\\r\n\t\t\t\t\t\t\t\t\t] )\r\n\t\t\t\t\t\t\t\t\t\t\r\n\t\treturn train_decoder[1][1:]\r\n\t\t\t\t\r\n\r\n\t## PREDICTION ENCODER ##\r\n\t\r\n\tdef coarse_prediction_encoder(self):\r\n\t\twith tf.variable_scope(\"prediction_encoder\"):\r\n\t\t\tcell = tf.contrib.rnn.GRUCell(self.pred_enc_size)\r\n\t\t\t_,hidden_state = tf.nn.dynamic_rnn(cell,tf.stack([self.coarse_prediction]),dtype = tf.float32)\r\n\t\t\t\r\n\r\n\t\treturn hidden_state[-1,:]\r\n\t\t\t\r\n\t\t\r\n\tdef compute_logits(self):\r\n\t\tlogits_nl = tf.matmul(self.nlop_emb,tf.transpose(self.nl_prediction))\r\n\t\t\r\n\t\tlogits_coarse = tf.matmul(self.cop_emb,tf.transpose(self.coarse_prediction))\r\n\t\t\r\n\t\treturn tf.transpose(logits_nl),tf.transpose(logits_coarse)\r\n\t\t\r\n\t\r\n\tdef loss_N_optimize(self):\r\n\t\tnl_onehot_target = tf.one_hot(self.tarlab_nl,self.nlvocab)\r\n\t\t\r\n\t\tcoarse_onehot_target = tf.one_hot(self.tarlab_c,self.cvocab)\r\n\t\t\r\n\t\tmap_nl = tf.nn.softmax_cross_entropy_with_logits(self.logits_nl, nl_onehot_target)\r\n\t\tmap_coarse = tf.nn.softmax_cross_entropy_with_logits(self.logits_coarse, coarse_onehot_target)\r\n\t\t\r\n\t\tself.loss = (tf.reduce_sum(map_nl) + tf.reduce_sum(map_coarse))\r\n\t\tseld.optimzer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\r\n\t\t\t\r\n\t\r\n\t\r\n\tdef make_grad_acmul(self):\r\n\t\ttvs = tf.trainable_variables()\r\n\t\t\r\n\t\taccum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()) , trainable = False) for tv in tvs]\r\n\t\t\r\n\t\tzero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\r\n\t\t\r\n\t\tgvs = self.optimizer.compute_gradients(self.loss, tvs)\r\n\t\t\r\n\t\taccum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\r\n\t\t\r\n\t\tself.zero_grads = zero_ops\r\n\t\t\r\n\t\tself.grad_accumul = accum_ops\r\n\t\tself.grad_apply = self.optimizer.apply_gradients([(accum_vars[i],gv[1]) for i, gv in enumerate(gvs)])\r\n\t\t\r\n\t\r\n\tdef split_utterances(self,NL_X,C_X):\r\n\t\t#NL_X and C_X are batch of dialogues and their respective coarse utterances , respectively\r\n\t\tn_dialogues = len(NL_X)\r\n\t\tdialogues_nl = []\r\n\t\tdialogues_coarse = []\r\n\t\t\r\n\t\tfor i in xrange(n_dialogues):\r\n\t\t\t# splitting dialogues / utterances\r\n\t\t\tend_of_nl_utt = np.where( np.array(NL_X[i]) == self.end_of_nl_utt)[0]\r\n\t\t\tend_of_coarse_utt = np.where(np.array(C_X[i]) == self.end_of_coarse_utt)[0]\r\n\t\t\t\r\n\t\t\tcurrent_dialogue_nl = np.split(NL_X[i], end_of_nl_utt[:-1]+1)\r\n\t\t\tcurrent_dialogue_coarse = np.split(C_X[i], end_of_coarse_utt[:-1]+1)\r\n\t\t\t\r\n\t\t\tdialogues_nl.append(current_dialogue_nl)\r\n\t\t\tdialogues_coarse.append(current_dialogue_coarse)\r\n\t\t\t\r\n\t\t\r\n\t\treturn dialogues_nl,dialogues_coarse\r\n\t\t\r\n\t\t\r\n\tdef partial_fit(self,NL_X,C_X):\r\n\t\t\r\n\t\t#reset gradient computation\r\n\t\tself.sess.run(self.zero_grads)\t\t\r\n\t\tdialogues_nl,dialogues_coarse = self.split_utterances(NL_X,C_X)\r\n\t\t\r\n\t\t\r\n\t\t#Train\r\n\t\tfor dialogue in xrange(len(dialogues_nl)):\r\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue]) - 1):\r\n\t\t\t\tif u_id ==0:\r\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\r\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\r\n\t\t\t\t\r\n\t\t\t\tfeed_dict = {\\\r\n\t\t\t\tself.ipemb_nl : dialogues_nl[dialogue][u_id],\\\r\n\t\t\t\tself.ipemb_c : dialogues_coarse[dialogue][u_id],\\\r\n\t\t\t\tself.tarlab_nl : dialogues_nl[dialogue][u_id+1],\\\r\n\t\t\t\tself.tarlab_c : dialogues_coarse[dialogue][u_id+1],\\\r\n\t\t\t\tself.oplen_nl : [len(dialogues_nl[dialogue][u_id+1])],\\\r\n\t\t\t\tself.oplen_c : [len(dialogues_coarse[dialogue][u_id+1])],\\\r\n\t\t\t\tself.prevcont_nl : prev_nl,\\\r\n\t\t\t\tself.prevcont_c : prev_coarse\\\r\n\t\t\t\t}\r\n\t\t\t\r\n\t\t\t\tprev_coarse,prev_nl,_ = self.sess.run(\\\r\n\t\t\t\t\t\t(\\\r\n\t\t\t\t\t\t\tself.current_hidden_coarse_context,\\\r\n\t\t\t\t\t\t\tself.current_hidden_nl_context,\\\r\n\t\t\t\t\t\t\tself.grad_accumul),\\\r\n\t\t\t\t\t\tfeed_dict=feed_dict)\r\n\t\t\t\tprev_coarse = [prev_coarse]\r\n\t\t\t\tprev_nl = [prev_nl]\r\n\t\tself.sess.run(self.grad_apply)\r\n\t\r\n\t\r\n\tdef cost(self,NL_X,C_X):\r\n\t\tdialogues_nl, dialogues_coarse = self.split_utterances(NL_X,C_X)\r\n\t\tfor dialogue in xrange(len(dialogues_nl)):\r\n\t\t\tfor u_id in xrange(len(dialogues_nl[dialogue])-1):\r\n\t\t\t\tif u_id == 0 :\r\n\t\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\r\n\t\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\r\n\t\t\t\t\ttotal_loss = 0\r\n\t\t\t\t\t\r\n\t\t\t\tfeed_dict = {\\\r\n\t\t\t\t\tself.ipemb_nl: dialogues_nl[u_id],\\\r\n\t\t\t\t\tself.ipemb_c: dialogues_coarse[u_id],\\\r\n\t\t\t\t\tself.tarlab_nl: dialogues_nl[u_id+1],\\\r\n\t\t\t\t\tself.tarlab_c: dialogues_coarse[u_id+1],\\\r\n\t\t\t\t\tself.oplen_nl: [len(dialogues_nl[u_id+1])],\\\r\n\t\t\t\t\tself.oplen_c: [len(dialogues_coarse[u_id+1])],\\\r\n\t\t\t\t\tself.prevcont_c: prev_coarse, \\\r\n\t\t\t\t\tself.prevcont_nl: prev_nl\\\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tprev_coarse,prev_nl,loss=self.sess.run(\\\r\n\t\t\t\t\t(\\\r\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\r\n\t\t\t\t\t\tself.current_hidden_nl_context,\\\r\n\t\t\t\t\t\tself.loss),\\\r\n\t\t\t\t\tfeed_dict=feed_dict)\r\n\t\t\t\t\t\r\n\t\t\t\tprev_coarse = [prev_coarse]\r\n\t\t\t\tprev_nl = [prev_nl]\r\n\t\t\t\ttotal_loss += loss\r\n\t\t\t\r\n\t\t\ttotal_loss /= float(len(NL_X))\r\n\t\t\treturn total_loss\r\n\t\t\t\r\n\t\r\n\tdef generate(self,dialogue_nl,dialogue_coarse,max_coarse_generation=10,max_nl_generation=10):\r\n\t\t\r\n\t\tfor u_id in xrange(len(dialogue_nl)-1):\r\n\t\t\tif u_id == 0:\r\n\t\t\t\tprev_coarse = np.zeros([1,self.c_context])\r\n\t\t\t\tprev_nl = np.zeros([1,self.nl_context])\r\n\t\t\t\t\r\n\t\t\tfeed_dict = {\\\r\n\t\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\r\n\t\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\r\n\t\t\t\tself.tarlab_nl: dialogue_nl[u_id+1],\\\r\n\t\t\t\tself.tarlab_c: dialogue_coarse[u_id+1],\\\r\n\t\t\t\tself.oplen_nl: [len(dialogue_nl[u_id+1])],\\\r\n\t\t\t\tself.oplen_c: [len(dialogue_coarse[u_id+1])],\\\r\n\t\t\t\tself.prevcont_c: prev_coarse, \\\r\n\t\t\t\tself.prevcont_nl: prev_nl\\\r\n\t\t\t}\r\n\t\t\tprev_coarse,prev_nl=self.sess.run(\\\r\n\t\t\t\t\t(\\\r\n\t\t\t\t\t\tself.current_hidden_coarse_context,\\\r\n\t\t\t\t\t\tself.current_hidden_nl_context),\\\r\n\t\t\t\t\tfeed_dict=feed_dict)\r\n\t\t\tprev_coarse = [prev_coarse]\r\n\t\t\tprev_nl = [prev_nl]\r\n\t\t\t\r\n\t\tu_id = len(dialogue_nl)-1\r\n\t\tfeed_dict = {\\\r\n\t\t\tself.ipemb_nl: dialogue_nl[u_id],\\\r\n\t\t\tself.ipemb_c: dialogue_coarse[u_id],\\\r\n\t\t\tself.prevcont_c: prev_coarse, \\\r\n\t\t\tself.prevcont_nl: prev_nl,\\\r\n\t\t\tself.oplen_nl: [max_nl_generation],\\\r\n\t\t\tself.oplen_c: [max_coarse_generation]\\\r\n\t\t}\r\n\t\t\r\n\t\tw_logits = self.sess.run(self.logits_nl,feed_dict=feed_dict)\r\n\t\tprediction = np.zeros([w_logits.shape[0]],dtype=int)\r\n\t\t\r\n\t\tfor i in xrange(len(prediction)):\r\n\t\t\tprobs = np.exp(w_logits[i])\r\n\t\t\tprobs /= probs.sum()\r\n\t\t\tprediction[i] = np.random.choice(self.nlvocab,p=probs)\r\n\t\treturn prediction \r\n\t\t\r\n\r\n\r\n\tdef save(self,file_path):\r\n\t\tself.saver.save(self.sess,file_path)\r\n\r\n\tdef restore(self,file_path):\r\n\t\tself.saver.restore(self.sess,file_path)\r\n\r\n\r\n\tif __name__ == \"__main__\":\r\n\r\n\t\tconfig = Configuration()\r\n\t\tconfig.nlvocab = 11\r\n\t\tconfig.cvocab = 11\r\n\t\tconfig.end_of_nl_utt = 10\r\n\t\tconfig.end_of_coarse_utt = 10\r\n\r\n\t\t# dummy input\r\n\t\tx_w = [ [ 3,5,8,3,10,2,3,5,9,9,10,8,7,6,1,0,10] ]\r\n\t\tx_z = [ [ 2,4,1,2,7,8,10,1,6,8,8,10,9,0,0,1,10] ]\r\n\t\tx_w_test = [ [3,5,8,3,10],[2,3,5,9,9,10] ] \r\n\t\tx_z_test = [ [2,4,1,2,7,8,10],[1,6,8,8,10] ]\r\n\r\n\t\tmodel = MRRNN(config)\r\n\t\tfor i in xrange(1000):\r\n\t\t\tmodel.partial_fit(x_w,x_z)\r\n\t\t\tloss = model.cost(x_w,x_z)\r\n\t\t\tprint (loss)\r\n\t\t\tprediction = model.generate(x_w_test,x_z_test,5,6)\r\n\t\t\t# should learn to predict the sequence [8,7,6,1,1,10]\r\n\t\t\tprint (prediction)\r\n\t\t\t\r\n\t\t\t\r\n\t\r\n\t\t\t\r\n\t\t\r\n\t'''\r\n\tKey points:\r\n\t- MrRNN is an advancement to the HRED model (proposed by Sordoni et al)\r\n\t- Utternace refers to dialogue in sequence ; it is , in turn , a sequence of words\r\n\t'''\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\t\r\n\t\t\r\n\t`\r\n```"}