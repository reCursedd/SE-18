{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9833", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9833/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9833/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9833/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9833", "id": 227942397, "node_id": "MDU6SXNzdWUyMjc5NDIzOTc=", "number": 9833, "title": "New seq2seq interface(basic_decoder) does not support sampled softmax?", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-11T10:11:39Z", "updated_at": "2017-05-11T20:14:10Z", "closed_at": "2017-05-11T20:14:10Z", "author_association": "NONE", "body_html": "<p>basic_decoder init function has param output_layer which must be a type of layer like Dense.<br>\nBut for using sampled softmax we need some code like below, as w_t and v is needed by tf.nn.sampled_softmax_loss<br>\nwith tf.variable_scope('output_projection'):<br>\nself.w_t = melt.variable.get_weights_truncated('w',<br>\n[vocab_size, num_units],<br>\nstddev=FLAGS.weight_stddev)<br>\n#weights<br>\nself.w = tf.transpose(self.w_t)<br>\n#biases<br>\nself.v = melt.variable.get_weights_truncated('v',<br>\n[vocab_size],<br>\nstddev=FLAGS.weight_stddev)<br>\nfor old seq2seq interface, we can just pass output_function like<br>\ndef output_fn(output):<br>\nreturn tf.nn.xw_plus_b(output, self.w, self.v )</p>\n<p>How can we do sampled softmax with seq2seq new internface ?</p>", "body_text": "basic_decoder init function has param output_layer which must be a type of layer like Dense.\nBut for using sampled softmax we need some code like below, as w_t and v is needed by tf.nn.sampled_softmax_loss\nwith tf.variable_scope('output_projection'):\nself.w_t = melt.variable.get_weights_truncated('w',\n[vocab_size, num_units],\nstddev=FLAGS.weight_stddev)\n#weights\nself.w = tf.transpose(self.w_t)\n#biases\nself.v = melt.variable.get_weights_truncated('v',\n[vocab_size],\nstddev=FLAGS.weight_stddev)\nfor old seq2seq interface, we can just pass output_function like\ndef output_fn(output):\nreturn tf.nn.xw_plus_b(output, self.w, self.v )\nHow can we do sampled softmax with seq2seq new internface ?", "body": "basic_decoder init function has param output_layer which must be a type of layer like Dense.\r\nBut for using sampled softmax we need some code like below, as w_t and v is needed by tf.nn.sampled_softmax_loss \r\n      with tf.variable_scope('output_projection'):\r\n          self.w_t = melt.variable.get_weights_truncated('w',   \r\n                                               [vocab_size, num_units],   \r\n                                               stddev=FLAGS.weight_stddev)   \r\n          #weights  \r\n          self.w = tf.transpose(self.w_t)    \r\n          #biases  \r\n          self.v = melt.variable.get_weights_truncated('v',     \r\n                                              [vocab_size], \r\n                                              stddev=FLAGS.weight_stddev)   \r\nfor old seq2seq interface, we can just pass output_function like \r\n      def output_fn(output):  \r\n          return tf.nn.xw_plus_b(output, self.w, self.v )  \r\n\r\nHow can we do sampled softmax with seq2seq new internface ?"}