{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341277145", "html_url": "https://github.com/tensorflow/tensorflow/issues/6633#issuecomment-341277145", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6633", "id": 341277145, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTI3NzE0NQ==", "user": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-01T23:50:31Z", "updated_at": "2017-11-01T23:50:31Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=59132\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/albertz\">@albertz</a><br>\nI think it's actually more of a question to Nvidia than to TF.</p>\n<ol>\n<li>I'm not sure why we chose 3 dimension, for the TensorNdDescriptor -- but from Cudnn 7.0 it actually suggests at least 4 dims:</li>\n</ol>\n<blockquote>\n<p>The total size of a tensor including the potential padding between dimensions is<br>\nlimited to 2 Giga-elements of type datatype . Tensors are restricted to having at least<br>\n4 dimensions, and at most CUDNN_DIM_MAX dimensions (defined in cudnn.h). When<br>\nworking with lower dimensional data, it is recommended that the user create a 4D<br>\ntensor, and set the size along unused dimensions to 1.</p>\n</blockquote>\n<ol start=\"2\">\n<li>We don't yet have functions to help doing that. The sorting and packing (and later unsorting/unpacking) is very expensive.</li>\n</ol>", "body_text": "@albertz\nI think it's actually more of a question to Nvidia than to TF.\n\nI'm not sure why we chose 3 dimension, for the TensorNdDescriptor -- but from Cudnn 7.0 it actually suggests at least 4 dims:\n\n\nThe total size of a tensor including the potential padding between dimensions is\nlimited to 2 Giga-elements of type datatype . Tensors are restricted to having at least\n4 dimensions, and at most CUDNN_DIM_MAX dimensions (defined in cudnn.h). When\nworking with lower dimensional data, it is recommended that the user create a 4D\ntensor, and set the size along unused dimensions to 1.\n\n\nWe don't yet have functions to help doing that. The sorting and packing (and later unsorting/unpacking) is very expensive.", "body": "@albertz \r\nI think it's actually more of a question to Nvidia than to TF.\r\n1. I'm not sure why we chose 3 dimension, for the TensorNdDescriptor -- but from Cudnn 7.0 it actually suggests at least 4 dims:\r\n> The total size of a tensor including the potential padding between dimensions is\r\nlimited to 2 Giga-elements of type datatype . Tensors are restricted to having at least\r\n4 dimensions, and at most CUDNN_DIM_MAX dimensions (defined in cudnn.h). When\r\nworking with lower dimensional data, it is recommended that the user create a 4D\r\ntensor, and set the size along unused dimensions to 1.\r\n\r\n2. We don't yet have functions to help doing that. The sorting and packing (and later unsorting/unpacking) is very expensive."}