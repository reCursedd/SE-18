{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345558384", "html_url": "https://github.com/tensorflow/tensorflow/issues/6633#issuecomment-345558384", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6633", "id": 345558384, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTU1ODM4NA==", "user": {"login": "alquraishi", "id": 5205204, "node_id": "MDQ6VXNlcjUyMDUyMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/5205204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alquraishi", "html_url": "https://github.com/alquraishi", "followers_url": "https://api.github.com/users/alquraishi/followers", "following_url": "https://api.github.com/users/alquraishi/following{/other_user}", "gists_url": "https://api.github.com/users/alquraishi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alquraishi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alquraishi/subscriptions", "organizations_url": "https://api.github.com/users/alquraishi/orgs", "repos_url": "https://api.github.com/users/alquraishi/repos", "events_url": "https://api.github.com/users/alquraishi/events{/privacy}", "received_events_url": "https://api.github.com/users/alquraishi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-19T23:12:53Z", "updated_at": "2017-11-19T23:12:53Z", "author_association": "NONE", "body_html": "<p>Yes you're right, I didn't think about the bias terms. I did some numerical tests and the outputs came out identical, but that must be because the bias terms were small enough that things cancelled out. That's too bad :(</p>\n<p>Regarding speed, in the tests I've done I did not find a detectable difference between manual stacking and CuDNN fused layers. It's possible that other parts of the model are adding sufficient overhead to mask the difference, but it also makes sense that it wouldn't make a huge difference, since both directions have to be integrated before the next layer can begin to be computed, and so there's no real extra parallelism that can be exploited, and presumably whatever overhead is added due to taking outputs from one layer and feeding them into the next is negligible for reasonably large LSTMs. I'm running with ~1000 units per direction and hundreds of time steps, and the slowdown, if any, is less than 1%.</p>\n<p>Given that my idea is wrong... any chance this'll be implemented soon or should I look into splitting directions and using <code>tf.reverse_sequence</code>?</p>\n<p>Sorry about the false alarm.</p>", "body_text": "Yes you're right, I didn't think about the bias terms. I did some numerical tests and the outputs came out identical, but that must be because the bias terms were small enough that things cancelled out. That's too bad :(\nRegarding speed, in the tests I've done I did not find a detectable difference between manual stacking and CuDNN fused layers. It's possible that other parts of the model are adding sufficient overhead to mask the difference, but it also makes sense that it wouldn't make a huge difference, since both directions have to be integrated before the next layer can begin to be computed, and so there's no real extra parallelism that can be exploited, and presumably whatever overhead is added due to taking outputs from one layer and feeding them into the next is negligible for reasonably large LSTMs. I'm running with ~1000 units per direction and hundreds of time steps, and the slowdown, if any, is less than 1%.\nGiven that my idea is wrong... any chance this'll be implemented soon or should I look into splitting directions and using tf.reverse_sequence?\nSorry about the false alarm.", "body": "Yes you're right, I didn't think about the bias terms. I did some numerical tests and the outputs came out identical, but that must be because the bias terms were small enough that things cancelled out. That's too bad :(\r\n\r\nRegarding speed, in the tests I've done I did not find a detectable difference between manual stacking and CuDNN fused layers. It's possible that other parts of the model are adding sufficient overhead to mask the difference, but it also makes sense that it wouldn't make a huge difference, since both directions have to be integrated before the next layer can begin to be computed, and so there's no real extra parallelism that can be exploited, and presumably whatever overhead is added due to taking outputs from one layer and feeding them into the next is negligible for reasonably large LSTMs. I'm running with ~1000 units per direction and hundreds of time steps, and the slowdown, if any, is less than 1%.\r\n\r\nGiven that my idea is wrong... any chance this'll be implemented soon or should I look into splitting directions and using `tf.reverse_sequence`?\r\n\r\nSorry about the false alarm.\r\n"}