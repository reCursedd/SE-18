{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/353333590", "html_url": "https://github.com/tensorflow/tensorflow/issues/14929#issuecomment-353333590", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14929", "id": 353333590, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzMzMzU5MA==", "user": {"login": "apollo-time", "id": 9794932, "node_id": "MDQ6VXNlcjk3OTQ5MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9794932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apollo-time", "html_url": "https://github.com/apollo-time", "followers_url": "https://api.github.com/users/apollo-time/followers", "following_url": "https://api.github.com/users/apollo-time/following{/other_user}", "gists_url": "https://api.github.com/users/apollo-time/gists{/gist_id}", "starred_url": "https://api.github.com/users/apollo-time/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apollo-time/subscriptions", "organizations_url": "https://api.github.com/users/apollo-time/orgs", "repos_url": "https://api.github.com/users/apollo-time/repos", "events_url": "https://api.github.com/users/apollo-time/events{/privacy}", "received_events_url": "https://api.github.com/users/apollo-time/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-21T11:58:34Z", "updated_at": "2017-12-21T13:10:38Z", "author_association": "NONE", "body_html": "<p>I got the same error.<br>\nMy model is defined by</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">make_model</span>(<span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">scope</span>, <span class=\"pl-smi\">output_count</span>, <span class=\"pl-smi\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    net <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>\n    batch_norm_params <span class=\"pl-k\">=</span> {\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decay for the moving averages.</span>\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0.995</span>,\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> epsilon to prevent 0s in variance.</span>\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>epsilon<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0.001</span>,\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> calculate moving average or using exist one</span>\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>is_training<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">False</span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>variables_collections<span class=\"pl-pds\">'</span></span>: [ tf.GraphKeys.<span class=\"pl-c1\">TRAINABLE_VARIABLES</span> ],\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>updates_collections<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">None</span>,\n    }\n    <span class=\"pl-k\">with</span> tf.variable_scope(scope, [<span class=\"pl-c1\">input</span>], <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse) <span class=\"pl-k\">as</span> sc:\n        <span class=\"pl-k\">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected],\n                            <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu,\n                            <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.truncated_normal_initializer(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.01</span>),\n                            <span class=\"pl-v\">weights_regularizer</span><span class=\"pl-k\">=</span>slim.l2_regularizer(<span class=\"pl-c1\">0.00005</span>),\n                            <span class=\"pl-v\">biases_initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(),\n                            <span class=\"pl-v\">normalizer_fn</span><span class=\"pl-k\">=</span>slim.batch_norm,\n                            <span class=\"pl-v\">normalizer_params</span><span class=\"pl-k\">=</span>batch_norm_params):\n            <span class=\"pl-k\">with</span> slim.arg_scope([slim.batch_norm], <span class=\"pl-k\">**</span>batch_norm_params):\n                net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.max_pool2d(net, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool1<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv2<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.max_pool2d(net, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool2<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv3<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.max_pool2d(net, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool3<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv4<span class=\"pl-pds\">'</span></span>)\n                net <span class=\"pl-k\">=</span> slim.flatten(net)\n                net <span class=\"pl-k\">=</span> slim.fully_connected(net, <span class=\"pl-c1\">256</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc1<span class=\"pl-pds\">'</span></span>)\n                label <span class=\"pl-k\">=</span> slim.fully_connected(net, output_count, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc_label<span class=\"pl-pds\">'</span></span>)\n                offset <span class=\"pl-k\">=</span> slim.fully_connected(net, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc_offset<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">return</span> label, offset</pre></div>\n<p>and input has shape [1,48,48,3], output_count is 3.<br>\nI got error \"tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 28 is invalidly specified in schema.\\ntensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 38 is invalidly specified in schema.\\n\", when in tflite::InterpreterBuilder function.</p>", "body_text": "I got the same error.\nMy model is defined by\ndef make_model(input, scope, output_count, reuse=None):\n    net = input\n    batch_norm_params = {\n        # Decay for the moving averages.\n        'decay': 0.995,\n        # epsilon to prevent 0s in variance.\n        'epsilon': 0.001,\n        # calculate moving average or using exist one\n        'is_training': False,\n        'variables_collections': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\n        'updates_collections': None,\n    }\n    with tf.variable_scope(scope, [input], reuse=reuse) as sc:\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                            activation_fn=tf.nn.relu,\n                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n                            weights_regularizer=slim.l2_regularizer(0.00005),\n                            biases_initializer=tf.constant_initializer(),\n                            normalizer_fn=slim.batch_norm,\n                            normalizer_params=batch_norm_params):\n            with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n                net = slim.conv2d(net, 32, 3, padding='VALID', scope='conv1')\n                net = slim.max_pool2d(net, 3, 2, scope='pool1')\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv2')\n                net = slim.max_pool2d(net, 3, 2, scope='pool2')\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv3')\n                net = slim.max_pool2d(net, 2, 2, scope='pool3')\n                net = slim.conv2d(net, 128, 2, padding='VALID', scope='conv4')\n                net = slim.flatten(net)\n                net = slim.fully_connected(net, 256, scope='fc1')\n                label = slim.fully_connected(net, output_count, activation_fn=None, scope='fc_label')\n                offset = slim.fully_connected(net, 2, activation_fn=None, scope='fc_offset')\n    return label, offset\nand input has shape [1,48,48,3], output_count is 3.\nI got error \"tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 28 is invalidly specified in schema.\\ntensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 38 is invalidly specified in schema.\\n\", when in tflite::InterpreterBuilder function.", "body": "I got the same error.\r\nMy model is defined by \r\n```python\r\ndef make_model(input, scope, output_count, reuse=None):\r\n    net = input\r\n    batch_norm_params = {\r\n        # Decay for the moving averages.\r\n        'decay': 0.995,\r\n        # epsilon to prevent 0s in variance.\r\n        'epsilon': 0.001,\r\n        # calculate moving average or using exist one\r\n        'is_training': False,\r\n        'variables_collections': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\r\n        'updates_collections': None,\r\n    }\r\n    with tf.variable_scope(scope, [input], reuse=reuse) as sc:\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                            activation_fn=tf.nn.relu,\r\n                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\r\n                            weights_regularizer=slim.l2_regularizer(0.00005),\r\n                            biases_initializer=tf.constant_initializer(),\r\n                            normalizer_fn=slim.batch_norm,\r\n                            normalizer_params=batch_norm_params):\r\n            with slim.arg_scope([slim.batch_norm], **batch_norm_params):\r\n                net = slim.conv2d(net, 32, 3, padding='VALID', scope='conv1')\r\n                net = slim.max_pool2d(net, 3, 2, scope='pool1')\r\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv2')\r\n                net = slim.max_pool2d(net, 3, 2, scope='pool2')\r\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv3')\r\n                net = slim.max_pool2d(net, 2, 2, scope='pool3')\r\n                net = slim.conv2d(net, 128, 2, padding='VALID', scope='conv4')\r\n                net = slim.flatten(net)\r\n                net = slim.fully_connected(net, 256, scope='fc1')\r\n                label = slim.fully_connected(net, output_count, activation_fn=None, scope='fc_label')\r\n                offset = slim.fully_connected(net, 2, activation_fn=None, scope='fc_offset')\r\n    return label, offset\r\n```\r\nand input has shape [1,48,48,3], output_count is 3.\r\nI got error \"tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 28 is invalidly specified in schema.\\ntensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 38 is invalidly specified in schema.\\n\", when in tflite::InterpreterBuilder function."}