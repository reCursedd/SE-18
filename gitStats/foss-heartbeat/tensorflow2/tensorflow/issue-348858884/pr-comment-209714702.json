{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209714702", "pull_request_review_id": 145782558, "id": 209714702, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwOTcxNDcwMg==", "diff_hunk": "@@ -123,8 +169,9 @@ def __init__(self,\n                ea_custom_getter,\n                communication_period=10,\n                moving_rate=None,\n-               rho=None,\n+               rho=0.0,", "path": "tensorflow/contrib/opt/python/training/elastic_average_optimizer.py", "position": null, "original_position": 141, "commit_id": "7d9a839a26b7b801ffc53eff59688672021d6a43", "original_commit_id": "167487ebf7e50e13779fb344038b2002056e9b81", "user": {"login": "weidankong", "id": 42156564, "node_id": "MDQ6VXNlcjQyMTU2NTY0", "avatar_url": "https://avatars2.githubusercontent.com/u/42156564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weidankong", "html_url": "https://github.com/weidankong", "followers_url": "https://api.github.com/users/weidankong/followers", "following_url": "https://api.github.com/users/weidankong/following{/other_user}", "gists_url": "https://api.github.com/users/weidankong/gists{/gist_id}", "starred_url": "https://api.github.com/users/weidankong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weidankong/subscriptions", "organizations_url": "https://api.github.com/users/weidankong/orgs", "repos_url": "https://api.github.com/users/weidankong/repos", "events_url": "https://api.github.com/users/weidankong/events{/privacy}", "received_events_url": "https://api.github.com/users/weidankong/received_events", "type": "User", "site_admin": false}, "body": "1. in async mode, rho is not used in original paper\r\n2. in my experiments, rho=0 works well\r\n    when rho=None, default value: self._rho = self._moving_rate / self._opt._learning_rate, may result a large value.  e..g, moving_rate=self.BETA / communication_period / num_worker=0.9/8/4=0.028125, while the initial learning_rate might be 1e-4, which makes rho=281.25, and this makes the workers not able to do perform exploitation.", "created_at": "2018-08-13T18:37:26Z", "updated_at": "2018-08-16T18:44:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21486#discussion_r209714702", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21486", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209714702"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21486#discussion_r209714702"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21486"}}, "body_html": "<ol>\n<li>in async mode, rho is not used in original paper</li>\n<li>in my experiments, rho=0 works well<br>\nwhen rho=None, default value: self._rho = self._moving_rate / self._opt._learning_rate, may result a large value.  e..g, moving_rate=self.BETA / communication_period / num_worker=0.9/8/4=0.028125, while the initial learning_rate might be 1e-4, which makes rho=281.25, and this makes the workers not able to do perform exploitation.</li>\n</ol>", "body_text": "in async mode, rho is not used in original paper\nin my experiments, rho=0 works well\nwhen rho=None, default value: self._rho = self._moving_rate / self._opt._learning_rate, may result a large value.  e..g, moving_rate=self.BETA / communication_period / num_worker=0.9/8/4=0.028125, while the initial learning_rate might be 1e-4, which makes rho=281.25, and this makes the workers not able to do perform exploitation.", "in_reply_to_id": 209676025}