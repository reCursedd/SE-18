{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265847551", "html_url": "https://github.com/tensorflow/tensorflow/issues/6189#issuecomment-265847551", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6189", "id": 265847551, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTg0NzU1MQ==", "user": {"login": "nasimrahaman", "id": 7032458, "node_id": "MDQ6VXNlcjcwMzI0NTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/7032458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nasimrahaman", "html_url": "https://github.com/nasimrahaman", "followers_url": "https://api.github.com/users/nasimrahaman/followers", "following_url": "https://api.github.com/users/nasimrahaman/following{/other_user}", "gists_url": "https://api.github.com/users/nasimrahaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/nasimrahaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nasimrahaman/subscriptions", "organizations_url": "https://api.github.com/users/nasimrahaman/orgs", "repos_url": "https://api.github.com/users/nasimrahaman/repos", "events_url": "https://api.github.com/users/nasimrahaman/events{/privacy}", "received_events_url": "https://api.github.com/users/nasimrahaman/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-08T20:33:47Z", "updated_at": "2016-12-08T20:45:08Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> I understand that w is a <code>Tensor</code> resulting from the <code>mul</code> op, and that it's not possible to access it via something like <code>tf.get_variable('mul')</code>. I just need the <code>mul</code> op to reside in the same \"name-group\" as the variable <code>v</code> (such that <code>w.name == layer123/mul:0</code>), for prettier Tensorboard visualization. Certainly, this is possible when <code>w</code> is defined immediately after <code>v</code> without exiting the first <code>variable_scope</code>, as shown in the very first example. I was looking for a way for this to work after I had once exited the first <code>variable_scope</code>.</p>\n<p>Also, I've tried the following, which also doesn't work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>layer123<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> varscope:\n    v <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>v<span class=\"pl-pds\">'</span></span>, [], <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">3</span>., tf.float32))\n\n<span class=\"pl-k\">with</span> tf.variable_scope(varscope, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n    w <span class=\"pl-k\">=</span> v <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>\n\n<span class=\"pl-c1\">print</span>(w.name)    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Prints 'layer123_1/mul:0'</span></pre></div>\n<p>EDIT/CLARIFICATION: I understand that your reply:</p>\n<blockquote>\n<p>w is not a variable, it's a Tensor.  w.name gives the Tensor's name, but<br>\nv.name returns the variable's name as you would see in the checkpoint.</p>\n</blockquote>\n<p>was a reply to my statement:</p>\n<blockquote>\n<p>This is quite unsatisfactory, for obvious reasons (e.g. get_variable functionality is rendered useless, encapsulation is broken, etc.).</p>\n</blockquote>\n<p>I was referring to having to use <code>tf.name_scope</code> instead of <code>tf.variable_scope</code> to have consistent naming behaviour, because the former is ignored by <code>tf.get_variable</code>. :)</p>", "body_text": "@ebrevdo I understand that w is a Tensor resulting from the mul op, and that it's not possible to access it via something like tf.get_variable('mul'). I just need the mul op to reside in the same \"name-group\" as the variable v (such that w.name == layer123/mul:0), for prettier Tensorboard visualization. Certainly, this is possible when w is defined immediately after v without exiting the first variable_scope, as shown in the very first example. I was looking for a way for this to work after I had once exited the first variable_scope.\nAlso, I've tried the following, which also doesn't work:\nwith tf.variable_scope('layer123') as varscope:\n    v = tf.get_variable('v', [], initializer=tf.constant_initializer(3., tf.float32))\n\nwith tf.variable_scope(varscope, reuse=True):\n    w = v * 2\n\nprint(w.name)    # Prints 'layer123_1/mul:0'\nEDIT/CLARIFICATION: I understand that your reply:\n\nw is not a variable, it's a Tensor.  w.name gives the Tensor's name, but\nv.name returns the variable's name as you would see in the checkpoint.\n\nwas a reply to my statement:\n\nThis is quite unsatisfactory, for obvious reasons (e.g. get_variable functionality is rendered useless, encapsulation is broken, etc.).\n\nI was referring to having to use tf.name_scope instead of tf.variable_scope to have consistent naming behaviour, because the former is ignored by tf.get_variable. :)", "body": "@ebrevdo I understand that w is a `Tensor` resulting from the `mul` op, and that it's not possible to access it via something like `tf.get_variable('mul')`. I just need the `mul` op to reside in the same \"name-group\" as the variable `v` (such that `w.name == layer123/mul:0`), for prettier Tensorboard visualization. Certainly, this is possible when `w` is defined immediately after `v` without exiting the first `variable_scope`, as shown in the very first example. I was looking for a way for this to work after I had once exited the first `variable_scope`.\r\n\r\nAlso, I've tried the following, which also doesn't work:\r\n\r\n```python\r\nwith tf.variable_scope('layer123') as varscope:\r\n    v = tf.get_variable('v', [], initializer=tf.constant_initializer(3., tf.float32))\r\n\r\nwith tf.variable_scope(varscope, reuse=True):\r\n    w = v * 2\r\n\r\nprint(w.name)    # Prints 'layer123_1/mul:0'\r\n```\r\n\r\nEDIT/CLARIFICATION: I understand that your reply:\r\n> w is not a variable, it's a Tensor.  w.name gives the Tensor's name, but\r\nv.name returns the variable's name as you would see in the checkpoint.\r\n\r\nwas a reply to my statement: \r\n\r\n> This is quite unsatisfactory, for obvious reasons (e.g. get_variable functionality is rendered useless, encapsulation is broken, etc.).\r\n\r\nI was referring to having to use `tf.name_scope` instead of `tf.variable_scope` to have consistent naming behaviour, because the former is ignored by `tf.get_variable`. :)"}