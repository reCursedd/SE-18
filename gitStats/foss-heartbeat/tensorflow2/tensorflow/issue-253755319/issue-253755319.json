{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12689", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12689/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12689/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12689/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12689", "id": 253755319, "node_id": "MDU6SXNzdWUyNTM3NTUzMTk=", "number": 12689, "title": "multi-GPU training too slow when L2 regularizer enabled ", "user": {"login": "TianwenWei", "id": 22830466, "node_id": "MDQ6VXNlcjIyODMwNDY2", "avatar_url": "https://avatars1.githubusercontent.com/u/22830466?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TianwenWei", "html_url": "https://github.com/TianwenWei", "followers_url": "https://api.github.com/users/TianwenWei/followers", "following_url": "https://api.github.com/users/TianwenWei/following{/other_user}", "gists_url": "https://api.github.com/users/TianwenWei/gists{/gist_id}", "starred_url": "https://api.github.com/users/TianwenWei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TianwenWei/subscriptions", "organizations_url": "https://api.github.com/users/TianwenWei/orgs", "repos_url": "https://api.github.com/users/TianwenWei/repos", "events_url": "https://api.github.com/users/TianwenWei/events{/privacy}", "received_events_url": "https://api.github.com/users/TianwenWei/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-08-29T18:11:41Z", "updated_at": "2017-12-06T15:04:30Z", "closed_at": "2017-08-30T13:11:03Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10 home edition</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.3.0</li>\n<li><strong>Python version</strong>:<br>\n3.5.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nCuda 8.0 / cudnn 6.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nNvidia 1080 GTX 8GB x 2</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I try to train a face recognition classifier using inception-resnet-v1 model with 2 GPUs. On single GPU the training proceeds just fine, with a processing capacity around 220 images/sec, but when I train with 2 GPUs I only observe marginal benefit (capacity increases to around 280 images/sec). After some profiling I found out that the poor performance was somehow due to the introduced L2 regularizer. When the regularizer is enabled, the computation of the gradient becomes unexpectedly slow, resulting in the slowdown of the entire training cycle. As a comparison, if the regularizer is disabled, I could obtain a processing capacity around 350 images/sec, which although not perfect, is more or less satisfactory. The boost in the performance in the latter scenario cannot be attributed to the reduced computation complexity from the removal of the regularizer. This is evidenced by a reference experiment with exactly the same parameter except for on a single GPU, see below.</p>\n<p>I cannot figure out an explanation for this. It took me several days to narrow down the problem to, seemingly,  the introduction of L2 regularizer and the computation of gradient.</p>\n<p>In my program I used standard tf.slim layers together with a downloaded inception-resnet-v1 model script.  The main part of the code is the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">args</span>):\n    num_gpus <span class=\"pl-k\">=</span> args.num_gpus\n    batch_size_per_gpu <span class=\"pl-k\">=</span> args.batch_size_per_gpu\n    batch_size <span class=\"pl-k\">=</span> batch_size_per_gpu <span class=\"pl-k\">*</span> num_gpus\n\n    num_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10000</span>\n    synthetic_images <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.01</span> <span class=\"pl-k\">*</span> np.random.randn(batch_size, <span class=\"pl-c1\">160</span>, <span class=\"pl-c1\">160</span>, <span class=\"pl-c1\">3</span>)\n    synthetic_labels <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">10000</span>, batch_size)\n\n    <span class=\"pl-k\">with</span> tf.Graph().as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> the synthetic array is converted to a tf.Variable</span>\n        images <span class=\"pl-k\">=</span> tf.Variable(tf.convert_to_tensor(synthetic_images, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        labels <span class=\"pl-k\">=</span> tf.Variable(tf.convert_to_tensor(synthetic_labels, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32), <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n        image_batches <span class=\"pl-k\">=</span> tf.split(images, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span>num_gpus)\n        label_batches <span class=\"pl-k\">=</span> tf.split(labels, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span>num_gpus)\n\n        total_loss <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">None</span>] <span class=\"pl-k\">*</span> num_gpus\n        grads <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">None</span>] <span class=\"pl-k\">*</span> num_gpus\n\n        opt <span class=\"pl-k\">=</span> tf.train.RMSPropOptimizer(<span class=\"pl-c1\">0.01</span>, <span class=\"pl-v\">epsilon</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.01</span>)\n\n        reuse_variables <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_gpus):\n            <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:<span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(i)), tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tower<span class=\"pl-c1\">{0}</span><span class=\"pl-pds\">\"</span></span>.format(i)) <span class=\"pl-k\">as</span> scope:\n                <span class=\"pl-k\">with</span> slim.arg_scope([slim.variable], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n                    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Building graph for tower<span class=\"pl-c1\">{0}</span>...<span class=\"pl-pds\">\"</span></span>.format(i))\n\n                    total_loss[i] <span class=\"pl-k\">=</span> tower_loss(<span class=\"pl-v\">images</span><span class=\"pl-k\">=</span>image_batches[i],\n                                               <span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>label_batches[i],\n                                               <span class=\"pl-v\">num_classes</span><span class=\"pl-k\">=</span>num_classes,\n                                               <span class=\"pl-v\">keep_probability</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n                                               <span class=\"pl-v\">phase_train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                                               <span class=\"pl-v\">embedding_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">512</span>,\n                                               <span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span>args.weight_decay,\n                                               <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse_variables)\n\n                    grads[i] <span class=\"pl-k\">=</span> opt.compute_gradients(total_loss[i])\n                    reuse_variables <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> then open a session and calculate the tower gradients</span>\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n            sess.run(init)\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Warming up...<span class=\"pl-pds\">\"</span></span>)\n            <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n                _ <span class=\"pl-k\">=</span> sess.run(grads)\n\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Benchmarking...<span class=\"pl-pds\">\"</span></span>)\n            <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_iterations):\n                _ <span class=\"pl-k\">=</span> sess.run(grads)</pre></div>\n<p>where <code>tower_loss()</code> is defined as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">tower_loss</span>(<span class=\"pl-smi\">images</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">num_classes</span>, <span class=\"pl-smi\">keep_probability</span>, <span class=\"pl-smi\">phase_train</span>, <span class=\"pl-smi\">embedding_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>, <span class=\"pl-smi\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>,\n               <span class=\"pl-smi\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    batch_norm_params <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0.995</span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>epsilon<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0.001</span>,\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>fused<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">True</span>\n    }\n\n    <span class=\"pl-k\">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected],\n                        <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.truncated_normal_initializer(<span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>),\n                        <span class=\"pl-v\">weights_regularizer</span><span class=\"pl-k\">=</span>slim.l2_regularizer(weight_decay),\n                        <span class=\"pl-v\">normalizer_fn</span><span class=\"pl-k\">=</span>slim.batch_norm,\n                        <span class=\"pl-v\">normalizer_params</span><span class=\"pl-k\">=</span>batch_norm_params\n                        ):\n        embeddings <span class=\"pl-k\">=</span> inception_resnet_v1(images, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span>phase_train,\n                                         <span class=\"pl-v\">dropout_keep_prob</span><span class=\"pl-k\">=</span>keep_probability,\n                                         <span class=\"pl-v\">bottleneck_layer_size</span><span class=\"pl-k\">=</span>embedding_size,\n                                         <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse)\n\n    logits <span class=\"pl-k\">=</span> slim.fully_connected(embeddings,\n                                  num_classes,\n                                  <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                                  <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse,\n                                  <span class=\"pl-v\">weights_regularizer</span><span class=\"pl-k\">=</span>slim.l2_regularizer(weight_decay),\n                                  <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>fc<span class=\"pl-pds\">\"</span></span>)\n    entropy_loss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(<span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits, <span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>labels))\n    <span class=\"pl-k\">if</span> weight_decay <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>L2 regularizer disabled.<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-k\">return</span> entropy_loss\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Regularization losses added to total loss.<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-k\">return</span> tf.add_n([entropy_loss] <span class=\"pl-k\">+</span> tf.get_collection(tf.GraphKeys.<span class=\"pl-c1\">REGULARIZATION_LOSSES</span>))</pre></div>\n<p>The whole script (contains codes to generate synthetic data) can be found <a href=\"https://github.com/TianwenWei/TianwenWei/blob/master/issue.py\">here</a>. The inception-resnet-v1 model script can be found <a href=\"https://github.com/TianwenWei/TianwenWei/blob/master/inception_resnet_modified.py\">here</a>.</p>\n<p>To reproduce the problem, just run<br>\n<code>python issue.py --num_gpus 2  --weight_decay 0 </code><br>\nThe output would be something like</p>\n<pre><code>Duration: 7.1 secs; 358.1 images/sec or 0.71 sec/batch\nDuration: 7.5 secs; 343.1 images/sec or 0.75 sec/batch\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\nDuration: 7.1 secs; 358.8 images/sec or 0.71 sec/batch\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\nTotal duration: 36.2sec        Performance: 353.9 images/sec\n</code></pre>\n<p>In contrast, with the presence of L2 regularizer, running<br>\n<code>python issue.py --num_gpus 2  --weight_decay 0.0001 </code><br>\none would obtain</p>\n<pre><code>Duration: 9.0 secs; 284.9 images/sec or 0.90 sec/batch\nDuration: 9.1 secs; 279.9 images/sec or 0.91 sec/batch\nDuration: 8.7 secs; 292.8 images/sec or 0.87 sec/batch\nDuration: 9.3 secs; 276.7 images/sec or 0.93 sec/batch\nDuration: 8.5 secs; 302.4 images/sec or 0.85 sec/batch\nTotal duration: 44.6 sec        Performance: 287.0 images/sec\n</code></pre>\n<p>As a reference, with single GPU, the difference of processing capacity between with and without regularizer is negligeable, at least in this demo. To check it, run<br>\n<code>python issue.py --num_gpus 1  --weight_decay 0 </code><br>\ngives</p>\n<pre><code>Duration: 5.6 secs; 228.1 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 228.7 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 225.8 images/sec or 0.57 sec/batch\nDuration: 5.6 secs; 230.3 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 226.8 images/sec or 0.56 sec/batch\nTotal duration: 28.1 sec        Performance: 227.9 images/sec\n</code></pre>\n<p>and<br>\n<code>python issue.py --num_gpus 1  --weight_decay 0.0001 </code><br>\ngives</p>\n<pre><code>Duration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 226.3 images/sec or 0.57 sec/batch\nDuration: 5.6 secs; 229.4 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 224.3 images/sec or 0.57 sec/batch\nTotal duration: 28.2 sec        Performance: 227.0 images/sec\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10 home edition\nTensorFlow installed from (source or binary):\nbinary\nTensorFlow version (use command below):\n1.3.0\nPython version:\n3.5.3\nBazel version (if compiling from source):\nCUDA/cuDNN version:\nCuda 8.0 / cudnn 6.0\nGPU model and memory:\nNvidia 1080 GTX 8GB x 2\nExact command to reproduce:\n\nDescribe the problem\nI try to train a face recognition classifier using inception-resnet-v1 model with 2 GPUs. On single GPU the training proceeds just fine, with a processing capacity around 220 images/sec, but when I train with 2 GPUs I only observe marginal benefit (capacity increases to around 280 images/sec). After some profiling I found out that the poor performance was somehow due to the introduced L2 regularizer. When the regularizer is enabled, the computation of the gradient becomes unexpectedly slow, resulting in the slowdown of the entire training cycle. As a comparison, if the regularizer is disabled, I could obtain a processing capacity around 350 images/sec, which although not perfect, is more or less satisfactory. The boost in the performance in the latter scenario cannot be attributed to the reduced computation complexity from the removal of the regularizer. This is evidenced by a reference experiment with exactly the same parameter except for on a single GPU, see below.\nI cannot figure out an explanation for this. It took me several days to narrow down the problem to, seemingly,  the introduction of L2 regularizer and the computation of gradient.\nIn my program I used standard tf.slim layers together with a downloaded inception-resnet-v1 model script.  The main part of the code is the following:\ndef main(args):\n    num_gpus = args.num_gpus\n    batch_size_per_gpu = args.batch_size_per_gpu\n    batch_size = batch_size_per_gpu * num_gpus\n\n    num_classes = 10000\n    synthetic_images = 0.01 * np.random.randn(batch_size, 160, 160, 3)\n    synthetic_labels = np.random.randint(0, 10000, batch_size)\n\n    with tf.Graph().as_default(), tf.device('/cpu:0'):\n        # the synthetic array is converted to a tf.Variable\n        images = tf.Variable(tf.convert_to_tensor(synthetic_images, dtype=tf.float32), trainable=False)\n        labels = tf.Variable(tf.convert_to_tensor(synthetic_labels, dtype=tf.int32), trainable=False)\n\n        image_batches = tf.split(images, num_or_size_splits=num_gpus)\n        label_batches = tf.split(labels, num_or_size_splits=num_gpus)\n\n        total_loss = [None] * num_gpus\n        grads = [None] * num_gpus\n\n        opt = tf.train.RMSPropOptimizer(0.01, epsilon=0.01)\n\n        reuse_variables = False\n        for i in range(num_gpus):\n            with tf.device(\"/gpu:{0}\".format(i)), tf.name_scope(\"tower{0}\".format(i)) as scope:\n                with slim.arg_scope([slim.variable], device='/cpu:0'):\n                    print(\"Building graph for tower{0}...\".format(i))\n\n                    total_loss[i] = tower_loss(images=image_batches[i],\n                                               labels=label_batches[i],\n                                               num_classes=num_classes,\n                                               keep_probability=1,\n                                               phase_train=True,\n                                               embedding_size=512,\n                                               weight_decay=args.weight_decay,\n                                               reuse=reuse_variables)\n\n                    grads[i] = opt.compute_gradients(total_loss[i])\n                    reuse_variables = True\n\n        # then open a session and calculate the tower gradients\n        with tf.Session() as sess:\n            sess.run(init)\n            print(\"Warming up...\")\n            for i in range(10):\n                _ = sess.run(grads)\n\n            print(\"Benchmarking...\")\n            for i in range(num_iterations):\n                _ = sess.run(grads)\nwhere tower_loss() is defined as follows:\ndef tower_loss(images, labels, num_classes, keep_probability, phase_train, embedding_size=128, weight_decay=0.0,\n               reuse=None):\n    batch_norm_params = {\n        'decay': 0.995,\n        'epsilon': 0.001,\n        'fused': True\n    }\n\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n                        weights_regularizer=slim.l2_regularizer(weight_decay),\n                        normalizer_fn=slim.batch_norm,\n                        normalizer_params=batch_norm_params\n                        ):\n        embeddings = inception_resnet_v1(images, is_training=phase_train,\n                                         dropout_keep_prob=keep_probability,\n                                         bottleneck_layer_size=embedding_size,\n                                         reuse=reuse)\n\n    logits = slim.fully_connected(embeddings,\n                                  num_classes,\n                                  activation_fn=None,\n                                  reuse=reuse,\n                                  weights_regularizer=slim.l2_regularizer(weight_decay),\n                                  scope=\"fc\")\n    entropy_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n    if weight_decay == 0:\n        print(\"L2 regularizer disabled.\")\n        return entropy_loss\n    else:\n        print(\"Regularization losses added to total loss.\")\n        return tf.add_n([entropy_loss] + tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\nThe whole script (contains codes to generate synthetic data) can be found here. The inception-resnet-v1 model script can be found here.\nTo reproduce the problem, just run\npython issue.py --num_gpus 2  --weight_decay 0 \nThe output would be something like\nDuration: 7.1 secs; 358.1 images/sec or 0.71 sec/batch\nDuration: 7.5 secs; 343.1 images/sec or 0.75 sec/batch\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\nDuration: 7.1 secs; 358.8 images/sec or 0.71 sec/batch\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\nTotal duration: 36.2sec        Performance: 353.9 images/sec\n\nIn contrast, with the presence of L2 regularizer, running\npython issue.py --num_gpus 2  --weight_decay 0.0001 \none would obtain\nDuration: 9.0 secs; 284.9 images/sec or 0.90 sec/batch\nDuration: 9.1 secs; 279.9 images/sec or 0.91 sec/batch\nDuration: 8.7 secs; 292.8 images/sec or 0.87 sec/batch\nDuration: 9.3 secs; 276.7 images/sec or 0.93 sec/batch\nDuration: 8.5 secs; 302.4 images/sec or 0.85 sec/batch\nTotal duration: 44.6 sec        Performance: 287.0 images/sec\n\nAs a reference, with single GPU, the difference of processing capacity between with and without regularizer is negligeable, at least in this demo. To check it, run\npython issue.py --num_gpus 1  --weight_decay 0 \ngives\nDuration: 5.6 secs; 228.1 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 228.7 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 225.8 images/sec or 0.57 sec/batch\nDuration: 5.6 secs; 230.3 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 226.8 images/sec or 0.56 sec/batch\nTotal duration: 28.1 sec        Performance: 227.9 images/sec\n\nand\npython issue.py --num_gpus 1  --weight_decay 0.0001 \ngives\nDuration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 226.3 images/sec or 0.57 sec/batch\nDuration: 5.6 secs; 229.4 images/sec or 0.56 sec/batch\nDuration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\nDuration: 5.7 secs; 224.3 images/sec or 0.57 sec/batch\nTotal duration: 28.2 sec        Performance: 227.0 images/sec", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 home edition\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.3.0\r\n- **Python version**: \r\n3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCuda 8.0 / cudnn 6.0\r\n- **GPU model and memory**:\r\nNvidia 1080 GTX 8GB x 2\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI try to train a face recognition classifier using inception-resnet-v1 model with 2 GPUs. On single GPU the training proceeds just fine, with a processing capacity around 220 images/sec, but when I train with 2 GPUs I only observe marginal benefit (capacity increases to around 280 images/sec). After some profiling I found out that the poor performance was somehow due to the introduced L2 regularizer. When the regularizer is enabled, the computation of the gradient becomes unexpectedly slow, resulting in the slowdown of the entire training cycle. As a comparison, if the regularizer is disabled, I could obtain a processing capacity around 350 images/sec, which although not perfect, is more or less satisfactory. The boost in the performance in the latter scenario cannot be attributed to the reduced computation complexity from the removal of the regularizer. This is evidenced by a reference experiment with exactly the same parameter except for on a single GPU, see below. \r\n\r\nI cannot figure out an explanation for this. It took me several days to narrow down the problem to, seemingly,  the introduction of L2 regularizer and the computation of gradient.\r\n\r\nIn my program I used standard tf.slim layers together with a downloaded inception-resnet-v1 model script.  The main part of the code is the following:\r\n\r\n```python\r\ndef main(args):\r\n    num_gpus = args.num_gpus\r\n    batch_size_per_gpu = args.batch_size_per_gpu\r\n    batch_size = batch_size_per_gpu * num_gpus\r\n\r\n    num_classes = 10000\r\n    synthetic_images = 0.01 * np.random.randn(batch_size, 160, 160, 3)\r\n    synthetic_labels = np.random.randint(0, 10000, batch_size)\r\n\r\n    with tf.Graph().as_default(), tf.device('/cpu:0'):\r\n        # the synthetic array is converted to a tf.Variable\r\n        images = tf.Variable(tf.convert_to_tensor(synthetic_images, dtype=tf.float32), trainable=False)\r\n        labels = tf.Variable(tf.convert_to_tensor(synthetic_labels, dtype=tf.int32), trainable=False)\r\n\r\n        image_batches = tf.split(images, num_or_size_splits=num_gpus)\r\n        label_batches = tf.split(labels, num_or_size_splits=num_gpus)\r\n\r\n        total_loss = [None] * num_gpus\r\n        grads = [None] * num_gpus\r\n\r\n        opt = tf.train.RMSPropOptimizer(0.01, epsilon=0.01)\r\n\r\n        reuse_variables = False\r\n        for i in range(num_gpus):\r\n            with tf.device(\"/gpu:{0}\".format(i)), tf.name_scope(\"tower{0}\".format(i)) as scope:\r\n                with slim.arg_scope([slim.variable], device='/cpu:0'):\r\n                    print(\"Building graph for tower{0}...\".format(i))\r\n\r\n                    total_loss[i] = tower_loss(images=image_batches[i],\r\n                                               labels=label_batches[i],\r\n                                               num_classes=num_classes,\r\n                                               keep_probability=1,\r\n                                               phase_train=True,\r\n                                               embedding_size=512,\r\n                                               weight_decay=args.weight_decay,\r\n                                               reuse=reuse_variables)\r\n\r\n                    grads[i] = opt.compute_gradients(total_loss[i])\r\n                    reuse_variables = True\r\n\r\n        # then open a session and calculate the tower gradients\r\n        with tf.Session() as sess:\r\n            sess.run(init)\r\n            print(\"Warming up...\")\r\n            for i in range(10):\r\n                _ = sess.run(grads)\r\n\r\n            print(\"Benchmarking...\")\r\n            for i in range(num_iterations):\r\n                _ = sess.run(grads)\r\n```\r\nwhere `tower_loss()` is defined as follows:\r\n\r\n``` python   \r\ndef tower_loss(images, labels, num_classes, keep_probability, phase_train, embedding_size=128, weight_decay=0.0,\r\n               reuse=None):\r\n    batch_norm_params = {\r\n        'decay': 0.995,\r\n        'epsilon': 0.001,\r\n        'fused': True\r\n    }\r\n\r\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\r\n                        weights_regularizer=slim.l2_regularizer(weight_decay),\r\n                        normalizer_fn=slim.batch_norm,\r\n                        normalizer_params=batch_norm_params\r\n                        ):\r\n        embeddings = inception_resnet_v1(images, is_training=phase_train,\r\n                                         dropout_keep_prob=keep_probability,\r\n                                         bottleneck_layer_size=embedding_size,\r\n                                         reuse=reuse)\r\n\r\n    logits = slim.fully_connected(embeddings,\r\n                                  num_classes,\r\n                                  activation_fn=None,\r\n                                  reuse=reuse,\r\n                                  weights_regularizer=slim.l2_regularizer(weight_decay),\r\n                                  scope=\"fc\")\r\n    entropy_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\r\n    if weight_decay == 0:\r\n        print(\"L2 regularizer disabled.\")\r\n        return entropy_loss\r\n    else:\r\n        print(\"Regularization losses added to total loss.\")\r\n        return tf.add_n([entropy_loss] + tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\r\n```\r\n\r\nThe whole script (contains codes to generate synthetic data) can be found [here](https://github.com/TianwenWei/TianwenWei/blob/master/issue.py). The inception-resnet-v1 model script can be found [here](https://github.com/TianwenWei/TianwenWei/blob/master/inception_resnet_modified.py).\r\n\r\nTo reproduce the problem, just run \r\n`python issue.py --num_gpus 2  --weight_decay 0\r\n`\r\nThe output would be something like\r\n```\r\nDuration: 7.1 secs; 358.1 images/sec or 0.71 sec/batch\r\nDuration: 7.5 secs; 343.1 images/sec or 0.75 sec/batch\r\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\r\nDuration: 7.1 secs; 358.8 images/sec or 0.71 sec/batch\r\nDuration: 7.2 secs; 354.9 images/sec or 0.72 sec/batch\r\nTotal duration: 36.2sec        Performance: 353.9 images/sec\r\n```\r\nIn contrast, with the presence of L2 regularizer, running\r\n`python issue.py --num_gpus 2  --weight_decay 0.0001\r\n`\r\none would obtain\r\n```\r\nDuration: 9.0 secs; 284.9 images/sec or 0.90 sec/batch\r\nDuration: 9.1 secs; 279.9 images/sec or 0.91 sec/batch\r\nDuration: 8.7 secs; 292.8 images/sec or 0.87 sec/batch\r\nDuration: 9.3 secs; 276.7 images/sec or 0.93 sec/batch\r\nDuration: 8.5 secs; 302.4 images/sec or 0.85 sec/batch\r\nTotal duration: 44.6 sec        Performance: 287.0 images/sec\r\n```\r\n\r\nAs a reference, with single GPU, the difference of processing capacity between with and without regularizer is negligeable, at least in this demo. To check it, run\r\n`python issue.py --num_gpus 1  --weight_decay 0\r\n`\r\ngives\r\n```\r\nDuration: 5.6 secs; 228.1 images/sec or 0.56 sec/batch\r\nDuration: 5.6 secs; 228.7 images/sec or 0.56 sec/batch\r\nDuration: 5.7 secs; 225.8 images/sec or 0.57 sec/batch\r\nDuration: 5.6 secs; 230.3 images/sec or 0.56 sec/batch\r\nDuration: 5.6 secs; 226.8 images/sec or 0.56 sec/batch\r\nTotal duration: 28.1 sec        Performance: 227.9 images/sec\r\n```\r\nand\r\n`python issue.py --num_gpus 1  --weight_decay 0.0001\r\n`\r\ngives\r\n```\r\nDuration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\r\nDuration: 5.7 secs; 226.3 images/sec or 0.57 sec/batch\r\nDuration: 5.6 secs; 229.4 images/sec or 0.56 sec/batch\r\nDuration: 5.6 secs; 227.5 images/sec or 0.56 sec/batch\r\nDuration: 5.7 secs; 224.3 images/sec or 0.57 sec/batch\r\nTotal duration: 28.2 sec        Performance: 227.0 images/sec\r\n```\r\n\r\n"}