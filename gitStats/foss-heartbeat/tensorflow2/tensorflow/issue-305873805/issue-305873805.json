{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17762", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17762/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17762/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17762/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17762", "id": 305873805, "node_id": "MDU6SXNzdWUzMDU4NzM4MDU=", "number": 17762, "title": "UnimplementedError: Broadcast between <Tensor> and <Tensor> is not supported yet.", "user": {"login": "aforslow", "id": 17109848, "node_id": "MDQ6VXNlcjE3MTA5ODQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/17109848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aforslow", "html_url": "https://github.com/aforslow", "followers_url": "https://api.github.com/users/aforslow/followers", "following_url": "https://api.github.com/users/aforslow/following{/other_user}", "gists_url": "https://api.github.com/users/aforslow/gists{/gist_id}", "starred_url": "https://api.github.com/users/aforslow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aforslow/subscriptions", "organizations_url": "https://api.github.com/users/aforslow/orgs", "repos_url": "https://api.github.com/users/aforslow/repos", "events_url": "https://api.github.com/users/aforslow/events{/privacy}", "received_events_url": "https://api.github.com/users/aforslow/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-16T10:22:20Z", "updated_at": "2018-11-22T18:54:34Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10 Pro 64-bit (10.0, Build 16299)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nb'unknown' 1.5.0</li>\n<li><strong>Python version</strong>:<br>\n3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I get 'UnimplementedError (see above for traceback): Broadcast between  and  is not supported yet' when trying to broadcast between different kinds of tensors.</p>\n<p>What I take from this is that the broadcasting system in tensorflow has limits on how many dimensions that can be broadcasted. After having tried multiple tensor permutations, I have further concluded that  the constraints on broadcasting for tensors is a bit unintuitive. For example:</p>\n<p>This works:<br>\n[1,2,1,1,2,2,2,2]*<br>\n[2,2,2,2,1,2,2,2]</p>\n<p>This doesn't work:<br>\n[1,2,1,1,2,2,2,2]*<br>\n[2,2,2,2,1,2,2,1]</p>\n<p>This works:<br>\n[2,2,2,2,1]*<br>\n[1,2,1,2,2]</p>\n<p>This doesn't work:<br>\n[2,2,2,2,1,2]*<br>\n[1,2,1,2,2,2]</p>\n<p>What I take from this is that broadcasting works for any permutation when the tensor rank is less than 6. When it is above 6, broadcasting only works when there is a maximum of 2 regions of consecutive 1's (both tensors' 1's taken into consideration). For example:</p>\n<p>This has two regions of consecutive 1's:<br>\n[1,2,1,1,2,2,2,2]*<br>\n[2,2,2,2,1,2,2,2]</p>\n<p>This has three regions of consecutive 1's:<br>\n[1,2,1,1,2,2,2,2]*<br>\n[2,2,2,2,2,1,2,2]</p>\n<p>Although, this rule seems to be wrong when calculating the product below. This doesn't work:<br>\n[1,2,1,1,2,1,2,2]*<br>\n[2,2,2,2,1,2,2,2]</p>\n<p>Maybe there is also a constraint on each individual tensor that it cannot contain more than two regions of consecutive 1's. An example of this:</p>\n<p>This works:<br>\n[1,2,1,1,2,2,2,2]*<br>\n[2,1,2,2,1,2,2,2]</p>\n<p>Nevertheless, I hope that I have demonstrated that the underlying constraints for broadcasting are confusing and unintuitive, so could you please show me the current constraints on broadcasting or confirm that above constraints are the only ones?</p>\n<p>Configurations aside, is it possible to fix the broadcasting system such that it can support any broadcasting configuration? If not, is there at least a way to increase the number of regions of consecutive 1's in the constraints for broadcastability between two tensors? I.e. is there a way to increase the maximum of 2 regions of consecutive 1's to a maximum of e.g. 4 regions?</p>\n<p>I understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.</p>\n<h3>Source code / logs</h3>\n<p>An example of case 1 and 2 above:</p>\n<pre><code>import tensorflow as tf\nt1 = tf.random_normal([1,2,1,1,2,2,2,2])\nt2 = tf.random_normal([2,2,2,2,1,2,2,2])\nt3 = d*e\n\nt4 = tf.random_normal([1,2,1,1,2,2,2,2])\nt5 = tf.random_normal([2,2,2,2,1,2,2,1])\nt6 = d*e\n\nsess = tf.InteractiveSession()\nsess.run(t3)\nsess.run(t6)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10 Pro 64-bit (10.0, Build 16299)\nTensorFlow installed from (source or binary):\nbinary\nTensorFlow version (use command below):\nb'unknown' 1.5.0\nPython version:\n3.6.4\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI get 'UnimplementedError (see above for traceback): Broadcast between  and  is not supported yet' when trying to broadcast between different kinds of tensors.\nWhat I take from this is that the broadcasting system in tensorflow has limits on how many dimensions that can be broadcasted. After having tried multiple tensor permutations, I have further concluded that  the constraints on broadcasting for tensors is a bit unintuitive. For example:\nThis works:\n[1,2,1,1,2,2,2,2]*\n[2,2,2,2,1,2,2,2]\nThis doesn't work:\n[1,2,1,1,2,2,2,2]*\n[2,2,2,2,1,2,2,1]\nThis works:\n[2,2,2,2,1]*\n[1,2,1,2,2]\nThis doesn't work:\n[2,2,2,2,1,2]*\n[1,2,1,2,2,2]\nWhat I take from this is that broadcasting works for any permutation when the tensor rank is less than 6. When it is above 6, broadcasting only works when there is a maximum of 2 regions of consecutive 1's (both tensors' 1's taken into consideration). For example:\nThis has two regions of consecutive 1's:\n[1,2,1,1,2,2,2,2]*\n[2,2,2,2,1,2,2,2]\nThis has three regions of consecutive 1's:\n[1,2,1,1,2,2,2,2]*\n[2,2,2,2,2,1,2,2]\nAlthough, this rule seems to be wrong when calculating the product below. This doesn't work:\n[1,2,1,1,2,1,2,2]*\n[2,2,2,2,1,2,2,2]\nMaybe there is also a constraint on each individual tensor that it cannot contain more than two regions of consecutive 1's. An example of this:\nThis works:\n[1,2,1,1,2,2,2,2]*\n[2,1,2,2,1,2,2,2]\nNevertheless, I hope that I have demonstrated that the underlying constraints for broadcasting are confusing and unintuitive, so could you please show me the current constraints on broadcasting or confirm that above constraints are the only ones?\nConfigurations aside, is it possible to fix the broadcasting system such that it can support any broadcasting configuration? If not, is there at least a way to increase the number of regions of consecutive 1's in the constraints for broadcastability between two tensors? I.e. is there a way to increase the maximum of 2 regions of consecutive 1's to a maximum of e.g. 4 regions?\nI understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.\nSource code / logs\nAn example of case 1 and 2 above:\nimport tensorflow as tf\nt1 = tf.random_normal([1,2,1,1,2,2,2,2])\nt2 = tf.random_normal([2,2,2,2,1,2,2,2])\nt3 = d*e\n\nt4 = tf.random_normal([1,2,1,1,2,2,2,2])\nt5 = tf.random_normal([2,2,2,2,1,2,2,1])\nt6 = d*e\n\nsess = tf.InteractiveSession()\nsess.run(t3)\nsess.run(t6)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Pro 64-bit (10.0, Build 16299)\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nb'unknown' 1.5.0\r\n- **Python version**: \r\n3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI get 'UnimplementedError (see above for traceback): Broadcast between <Tensor> and <Tensor> is not supported yet' when trying to broadcast between different kinds of tensors.\r\n\r\nWhat I take from this is that the broadcasting system in tensorflow has limits on how many dimensions that can be broadcasted. After having tried multiple tensor permutations, I have further concluded that  the constraints on broadcasting for tensors is a bit unintuitive. For example:\r\n\r\nThis works:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nThis doesn't work:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,1]\r\n\r\nThis works:\r\n[2,2,2,2,1]*\r\n[1,2,1,2,2]\r\n\r\nThis doesn't work:\r\n[2,2,2,2,1,2]*\r\n[1,2,1,2,2,2]\r\n\r\nWhat I take from this is that broadcasting works for any permutation when the tensor rank is less than 6. When it is above 6, broadcasting only works when there is a maximum of 2 regions of consecutive 1's (both tensors' 1's taken into consideration). For example:\r\n\r\nThis has two regions of consecutive 1's:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nThis has three regions of consecutive 1's:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,2,2,2,2,1,2,2]\r\n\r\nAlthough, this rule seems to be wrong when calculating the product below. This doesn't work:\r\n[1,2,1,1,2,1,2,2]*\r\n[2,2,2,2,1,2,2,2]\r\n\r\nMaybe there is also a constraint on each individual tensor that it cannot contain more than two regions of consecutive 1's. An example of this:\r\n\r\nThis works:\r\n[1,2,1,1,2,2,2,2]*\r\n[2,1,2,2,1,2,2,2]\r\n\r\nNevertheless, I hope that I have demonstrated that the underlying constraints for broadcasting are confusing and unintuitive, so could you please show me the current constraints on broadcasting or confirm that above constraints are the only ones? \r\n\r\nConfigurations aside, is it possible to fix the broadcasting system such that it can support any broadcasting configuration? If not, is there at least a way to increase the number of regions of consecutive 1's in the constraints for broadcastability between two tensors? I.e. is there a way to increase the maximum of 2 regions of consecutive 1's to a maximum of e.g. 4 regions?\r\n\r\nI understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.\r\n\r\n### Source code / logs\r\nAn example of case 1 and 2 above:\r\n\r\n```\r\nimport tensorflow as tf\r\nt1 = tf.random_normal([1,2,1,1,2,2,2,2])\r\nt2 = tf.random_normal([2,2,2,2,1,2,2,2])\r\nt3 = d*e\r\n\r\nt4 = tf.random_normal([1,2,1,1,2,2,2,2])\r\nt5 = tf.random_normal([2,2,2,2,1,2,2,1])\r\nt6 = d*e\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(t3)\r\nsess.run(t6)\r\n```\r\n"}