{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21335", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21335/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21335/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21335/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21335", "id": 346928909, "node_id": "MDU6SXNzdWUzNDY5Mjg5MDk=", "number": 21335, "title": "Possible bug / Documentation Suggestion - Dataset API + Estimator API does not throw an exception when the input filepath to the dataset is incorrect", "user": {"login": "tejaswid", "id": 11408325, "node_id": "MDQ6VXNlcjExNDA4MzI1", "avatar_url": "https://avatars2.githubusercontent.com/u/11408325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tejaswid", "html_url": "https://github.com/tejaswid", "followers_url": "https://api.github.com/users/tejaswid/followers", "following_url": "https://api.github.com/users/tejaswid/following{/other_user}", "gists_url": "https://api.github.com/users/tejaswid/gists{/gist_id}", "starred_url": "https://api.github.com/users/tejaswid/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tejaswid/subscriptions", "organizations_url": "https://api.github.com/users/tejaswid/orgs", "repos_url": "https://api.github.com/users/tejaswid/repos", "events_url": "https://api.github.com/users/tejaswid/events{/privacy}", "received_events_url": "https://api.github.com/users/tejaswid/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-08-02T09:21:28Z", "updated_at": "2018-10-22T16:22:54Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.9.0-0-g25c197e023 1.9.0</li>\n<li><strong>Python version</strong>: 3.6.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0  / CUDNN 7.1.4.18</li>\n<li><strong>GPU model and memory</strong>: GTX 1080 Ti - 9710 MB</li>\n<li><strong>Exact command to reproduce</strong>: See below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When using the Dataset API along with the Estimator API, if the input file path to the dataset, while initializing <strong>tf.data.TFRecordDataset</strong> or <strong>tf.data.FixedLengthRecordDataset</strong>, is incorrect/ file does not exist, it does not immediately throw an exception. Instead the entire network graph is constructed, weights are initialized and checkpoints (if present) are loaded.</p>\n<p>The only indication that something is wrong is when the session.run is called inside the function <strong>_train_with_estimator_spec</strong> in the train loop of the estimator.** The loss remains <em>None</em> and the global_step is not updated**. Moreover, the training runs for as many epochs as requested with nothing being updated.</p>\n<p>However, even if one were to use the Dataset API with an incorrect file path but still overwrite the features and labels returned by it with manually set values, the loss is still not computed and remains as <em>None</em> and the same problem as above persists. This is very counter-intuitive and hard to debug.</p>\n<p>It would be better if the Dataset API somehow threw an exception in the beginning itself. If this is not possible, it would be nice if this was documented somewhere.</p>\n<h3>Source code</h3>\n<ol>\n<li>\n<p>Clone the tensorflow models from the official repository.<br>\n<code>git clone https://github.com/tensorflow/models.git tfmodels</code><br>\n<code>cd tfmodels</code></p>\n</li>\n<li>\n<p>Run the <strong>cifar10_download_and_extract.py</strong> file to download and extract the cifar10 dataset.</p>\n</li>\n<li>\n<p>Run the <strong>cifar10_main.py</strong> file to check that the original model is running correctly.</p>\n</li>\n<li>\n<p>Delete the .bin files inside the <strong>cifar-10-batches-bin</strong> folder that was created in step 2. Keep the folder but only delete the contents inside it. By doing so we are passing an empty string to the dataset initializer and hence the dataset iterator is probably returning garbage values.</p>\n</li>\n<li>\n<p>Re-run step 3 and you see the error described.</p>\n</li>\n<li>\n<p>Make a copy of the file <strong>cifar10_main.py</strong> and edit it by adding the following lines just before the return statement in the function <strong>parse_record</strong>.<br>\n<code>image = tf.constant(value=0.0, shape=[32, 32, 3], dtype=tf.float32)</code><br>\n<code>label = tf.constant(value=0, shape=[], dtype=tf.int32)</code><br>\nBy doing so we are still using an incorrect initializer but are now replacing the garbage values returned by the reader with known constants (zeros in this case).</p>\n</li>\n<li>\n<p>Re-run the modified file and you still see the error described.</p>\n</li>\n</ol>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.9.0-0-g25c197e023 1.9.0\nPython version: 3.6.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: CUDA 9.0  / CUDNN 7.1.4.18\nGPU model and memory: GTX 1080 Ti - 9710 MB\nExact command to reproduce: See below\n\nDescribe the problem\nWhen using the Dataset API along with the Estimator API, if the input file path to the dataset, while initializing tf.data.TFRecordDataset or tf.data.FixedLengthRecordDataset, is incorrect/ file does not exist, it does not immediately throw an exception. Instead the entire network graph is constructed, weights are initialized and checkpoints (if present) are loaded.\nThe only indication that something is wrong is when the session.run is called inside the function _train_with_estimator_spec in the train loop of the estimator.** The loss remains None and the global_step is not updated**. Moreover, the training runs for as many epochs as requested with nothing being updated.\nHowever, even if one were to use the Dataset API with an incorrect file path but still overwrite the features and labels returned by it with manually set values, the loss is still not computed and remains as None and the same problem as above persists. This is very counter-intuitive and hard to debug.\nIt would be better if the Dataset API somehow threw an exception in the beginning itself. If this is not possible, it would be nice if this was documented somewhere.\nSource code\n\n\nClone the tensorflow models from the official repository.\ngit clone https://github.com/tensorflow/models.git tfmodels\ncd tfmodels\n\n\nRun the cifar10_download_and_extract.py file to download and extract the cifar10 dataset.\n\n\nRun the cifar10_main.py file to check that the original model is running correctly.\n\n\nDelete the .bin files inside the cifar-10-batches-bin folder that was created in step 2. Keep the folder but only delete the contents inside it. By doing so we are passing an empty string to the dataset initializer and hence the dataset iterator is probably returning garbage values.\n\n\nRe-run step 3 and you see the error described.\n\n\nMake a copy of the file cifar10_main.py and edit it by adding the following lines just before the return statement in the function parse_record.\nimage = tf.constant(value=0.0, shape=[32, 32, 3], dtype=tf.float32)\nlabel = tf.constant(value=0, shape=[], dtype=tf.int32)\nBy doing so we are still using an incorrect initializer but are now replacing the garbage values returned by the reader with known constants (zeros in this case).\n\n\nRe-run the modified file and you still see the error described.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.9.0-0-g25c197e023 1.9.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: CUDA 9.0  / CUDNN 7.1.4.18\r\n- **GPU model and memory**: GTX 1080 Ti - 9710 MB\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nWhen using the Dataset API along with the Estimator API, if the input file path to the dataset, while initializing **tf.data.TFRecordDataset** or **tf.data.FixedLengthRecordDataset**, is incorrect/ file does not exist, it does not immediately throw an exception. Instead the entire network graph is constructed, weights are initialized and checkpoints (if present) are loaded.\r\n\r\nThe only indication that something is wrong is when the session.run is called inside the function **_train_with_estimator_spec** in the train loop of the estimator.** The loss remains _None_ and the global_step is not updated**. Moreover, the training runs for as many epochs as requested with nothing being updated. \r\n\r\nHowever, even if one were to use the Dataset API with an incorrect file path but still overwrite the features and labels returned by it with manually set values, the loss is still not computed and remains as _None_ and the same problem as above persists. This is very counter-intuitive and hard to debug.\r\n\r\nIt would be better if the Dataset API somehow threw an exception in the beginning itself. If this is not possible, it would be nice if this was documented somewhere.\r\n\r\n### Source code\r\n\r\n1. Clone the tensorflow models from the official repository.\r\n`git clone https://github.com/tensorflow/models.git tfmodels`\r\n`cd tfmodels`\r\n\r\n2. Run the **cifar10_download_and_extract.py** file to download and extract the cifar10 dataset.\r\n3. Run the **cifar10_main.py** file to check that the original model is running correctly.\r\n\r\n4. Delete the .bin files inside the **cifar-10-batches-bin** folder that was created in step 2. Keep the folder but only delete the contents inside it. By doing so we are passing an empty string to the dataset initializer and hence the dataset iterator is probably returning garbage values.\r\n5. Re-run step 3 and you see the error described.\r\n\r\n6. Make a copy of the file **cifar10_main.py** and edit it by adding the following lines just before the return statement in the function **parse_record**.\r\n`image = tf.constant(value=0.0, shape=[32, 32, 3], dtype=tf.float32)`\r\n`label = tf.constant(value=0, shape=[], dtype=tf.int32)`\r\nBy doing so we are still using an incorrect initializer but are now replacing the garbage values returned by the reader with known constants (zeros in this case).\r\n7. Re-run the modified file and you still see the error described."}