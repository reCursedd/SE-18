{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391981229", "html_url": "https://github.com/tensorflow/tensorflow/issues/8057#issuecomment-391981229", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8057", "id": 391981229, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTk4MTIyOQ==", "user": {"login": "sdr2002", "id": 27024712, "node_id": "MDQ6VXNlcjI3MDI0NzEy", "avatar_url": "https://avatars3.githubusercontent.com/u/27024712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdr2002", "html_url": "https://github.com/sdr2002", "followers_url": "https://api.github.com/users/sdr2002/followers", "following_url": "https://api.github.com/users/sdr2002/following{/other_user}", "gists_url": "https://api.github.com/users/sdr2002/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdr2002/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdr2002/subscriptions", "organizations_url": "https://api.github.com/users/sdr2002/orgs", "repos_url": "https://api.github.com/users/sdr2002/repos", "events_url": "https://api.github.com/users/sdr2002/events{/privacy}", "received_events_url": "https://api.github.com/users/sdr2002/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T08:28:57Z", "updated_at": "2018-05-25T08:45:19Z", "author_association": "NONE", "body_html": "<p>I do not know why this issue is closed, but for TF1.8.0 this issue is still alive.<br>\nThose 'beta1_power' and 'beta2_power' are not within the variable_scope unlike other variables.</p>\n<p>For some cases, \"The solution for you will be to place call to model.optimizer.minimize within the model class itself, and store its result in model`s attribute.\" does not help because you may want to separate(*) the part where you define the 'network model' with the one you define 'training method'.</p>\n<p>(*) If you wanna build modular programming having a catalog of learning algorithms, then this is the case to separate 'network builder' from 'network trainer'</p>\n<p>My take on this is to set two variable_scope context managers(a.k.a with) for each '_build' and '_train' parts for each with a same word 'network' starting with, and then use the word to aggregate whole variables within the two scopes:<br>\nex)<br>\nwith tf.variable_scope('network_build') as net_build:<br>\nbuild_network()</p>\n<p>...<br>\nwith tf.variable_scope('network_train') as net_train:<br>\ndefine_training_method()</p>\n<p>...<br>\ntf.Session.run(tf.variables_initializer(var_list=tf.global_variables(scope='network')))</p>", "body_text": "I do not know why this issue is closed, but for TF1.8.0 this issue is still alive.\nThose 'beta1_power' and 'beta2_power' are not within the variable_scope unlike other variables.\nFor some cases, \"The solution for you will be to place call to model.optimizer.minimize within the model class itself, and store its result in model`s attribute.\" does not help because you may want to separate(*) the part where you define the 'network model' with the one you define 'training method'.\n(*) If you wanna build modular programming having a catalog of learning algorithms, then this is the case to separate 'network builder' from 'network trainer'\nMy take on this is to set two variable_scope context managers(a.k.a with) for each '_build' and '_train' parts for each with a same word 'network' starting with, and then use the word to aggregate whole variables within the two scopes:\nex)\nwith tf.variable_scope('network_build') as net_build:\nbuild_network()\n...\nwith tf.variable_scope('network_train') as net_train:\ndefine_training_method()\n...\ntf.Session.run(tf.variables_initializer(var_list=tf.global_variables(scope='network')))", "body": "I do not know why this issue is closed, but for TF1.8.0 this issue is still alive. \r\nThose 'beta1_power' and 'beta2_power' are not within the variable_scope unlike other variables.\r\n\r\nFor some cases, \"The solution for you will be to place call to model.optimizer.minimize within the model class itself, and store its result in model`s attribute.\" does not help because you may want to separate(*) the part where you define the 'network model' with the one you define 'training method'.\r\n\r\n(*) If you wanna build modular programming having a catalog of learning algorithms, then this is the case to separate 'network builder' from 'network trainer'\r\n\r\nMy take on this is to set two variable_scope context managers(a.k.a with) for each '_build' and '_train' parts for each with a same word 'network' starting with, and then use the word to aggregate whole variables within the two scopes:\r\nex) \r\nwith tf.variable_scope('network_build') as net_build:\r\n       build_network()\r\n\r\n...\r\nwith tf.variable_scope('network_train') as net_train:\r\n      define_training_method()\r\n\r\n...\r\ntf.Session.run(tf.variables_initializer(var_list=tf.global_variables(scope='network')))\r\n"}