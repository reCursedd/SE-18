{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310505897", "html_url": "https://github.com/tensorflow/tensorflow/issues/8057#issuecomment-310505897", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8057", "id": 310505897, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDUwNTg5Nw==", "user": {"login": "faddey-w", "id": 12978216, "node_id": "MDQ6VXNlcjEyOTc4MjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/12978216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/faddey-w", "html_url": "https://github.com/faddey-w", "followers_url": "https://api.github.com/users/faddey-w/followers", "following_url": "https://api.github.com/users/faddey-w/following{/other_user}", "gists_url": "https://api.github.com/users/faddey-w/gists{/gist_id}", "starred_url": "https://api.github.com/users/faddey-w/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/faddey-w/subscriptions", "organizations_url": "https://api.github.com/users/faddey-w/orgs", "repos_url": "https://api.github.com/users/faddey-w/repos", "events_url": "https://api.github.com/users/faddey-w/events{/privacy}", "received_events_url": "https://api.github.com/users/faddey-w/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-22T21:20:22Z", "updated_at": "2017-06-22T21:20:22Z", "author_association": "NONE", "body_html": "<p>The problem is that you call <code>model.optimizer.minimize</code> too late. This methods creates additional tensors within your graph, so calling it within a loop is bad idea - it is something similar to a memory leak. Also, in case of stateful optimizers (such as AdamOptimizer) <code>minimize</code> creates additional variables. That's why you get exception you described - your initializer runs before you create them. The solution for you will be to place call to <code>model.optimizer.minimize</code> within the model class itself, and store its result in model`s attribute.</p>\n<p>So, your problem does not refer to this issue.</p>", "body_text": "The problem is that you call model.optimizer.minimize too late. This methods creates additional tensors within your graph, so calling it within a loop is bad idea - it is something similar to a memory leak. Also, in case of stateful optimizers (such as AdamOptimizer) minimize creates additional variables. That's why you get exception you described - your initializer runs before you create them. The solution for you will be to place call to model.optimizer.minimize within the model class itself, and store its result in model`s attribute.\nSo, your problem does not refer to this issue.", "body": "The problem is that you call `model.optimizer.minimize` too late. This methods creates additional tensors within your graph, so calling it within a loop is bad idea - it is something similar to a memory leak. Also, in case of stateful optimizers (such as AdamOptimizer) `minimize` creates additional variables. That's why you get exception you described - your initializer runs before you create them. The solution for you will be to place call to `model.optimizer.minimize` within the model class itself, and store its result in model`s attribute. \r\n\r\nSo, your problem does not refer to this issue."}