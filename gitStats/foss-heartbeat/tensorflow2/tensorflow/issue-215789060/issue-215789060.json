{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8589", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8589/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8589/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8589/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8589", "id": 215789060, "node_id": "MDU6SXNzdWUyMTU3ODkwNjA=", "number": 8589, "title": "contrib.crf + XLA doesn't work", "user": {"login": "hugman", "id": 2958929, "node_id": "MDQ6VXNlcjI5NTg5Mjk=", "avatar_url": "https://avatars3.githubusercontent.com/u/2958929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hugman", "html_url": "https://github.com/hugman", "followers_url": "https://api.github.com/users/hugman/followers", "following_url": "https://api.github.com/users/hugman/following{/other_user}", "gists_url": "https://api.github.com/users/hugman/gists{/gist_id}", "starred_url": "https://api.github.com/users/hugman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hugman/subscriptions", "organizations_url": "https://api.github.com/users/hugman/orgs", "repos_url": "https://api.github.com/users/hugman/repos", "events_url": "https://api.github.com/users/hugman/events{/privacy}", "received_events_url": "https://api.github.com/users/hugman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-03-21T15:56:19Z", "updated_at": "2017-06-16T20:44:53Z", "closed_at": "2017-06-16T20:44:53Z", "author_association": "NONE", "body_html": "<p>The combination of tf.contrib.crf + XLA seems not working (sometimes hang forever).</p>\n<p>Following code is for reproducing errors.<br>\nThe code is from standard example - <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf\">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf</a><br>\nThe only difference is XLA part.</p>\n<p>When XLA is enabled, loss is not reducing.<br>\nIn more large network(real NLP applications), it hangs forever after graph building.</p>\n<p>My settings is</p>\n<ul>\n<li>tensorflow 1.0.1</li>\n<li>python 3.6 (anaconda 4.3.0 )</li>\n<li>cuda 7.5</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Data settings.</span>\nnum_examples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\nnum_words <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\nnum_features <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nnum_tags <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Random features.</span>\nx <span class=\"pl-k\">=</span> np.random.rand(num_examples, num_words, num_features).astype(np.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Random tag indices representing the gold sequence.</span>\ny <span class=\"pl-k\">=</span> np.random.randint(num_tags, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[num_examples, num_words]).astype(np.int32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> All sequences in this example have the same length, but they can be variable in a real model.</span>\nsequence_lengths <span class=\"pl-k\">=</span> np.full(num_examples, num_words <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.int32)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> to enable XLA</span>\ntf_config <span class=\"pl-k\">=</span> tf.ConfigProto()\ntf_config.graph_options.optimizer_options.global_jit_level <span class=\"pl-k\">=</span> tf.OptimizerOptions.<span class=\"pl-c1\">ON_1</span>\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Train and evaluate the model.</span>\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n  <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>tf_config) <span class=\"pl-k\">as</span> session:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the data to the TensorFlow graph.</span>\n    x_t <span class=\"pl-k\">=</span> tf.constant(x)\n    y_t <span class=\"pl-k\">=</span> tf.constant(y)\n    sequence_lengths_t <span class=\"pl-k\">=</span> tf.constant(sequence_lengths)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Compute unary scores from a linear layer.</span>\n    weights <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weights<span class=\"pl-pds\">\"</span></span>, [num_features, num_tags])\n    matricized_x_t <span class=\"pl-k\">=</span> tf.reshape(x_t, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, num_features])\n    matricized_unary_scores <span class=\"pl-k\">=</span> tf.matmul(matricized_x_t, weights)\n    unary_scores <span class=\"pl-k\">=</span> tf.reshape(matricized_unary_scores,\n                              [num_examples, num_words, num_tags])\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Compute the log-likelihood of the gold sequences and keep the transition</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> params for inference at test time.</span>\n    log_likelihood, transition_params <span class=\"pl-k\">=</span> tf.contrib.crf.crf_log_likelihood(\n        unary_scores, y_t, sequence_lengths_t)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add a training op to tune the parameters.</span>\n    loss <span class=\"pl-k\">=</span> tf.reduce_mean(<span class=\"pl-k\">-</span>log_likelihood)\n    \n    train_op <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.01</span>).minimize(loss)\n\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Train for a fixed number of iterations.</span>\n    session.run(tf.global_variables_initializer())\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n      tf_unary_scores, tf_transition_params, _ <span class=\"pl-k\">=</span> session.run(\n          [unary_scores, transition_params, train_op])\n      <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> <span class=\"pl-c1\">100</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        correct_labels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n        total_labels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n        <span class=\"pl-k\">for</span> tf_unary_scores_, y_, sequence_length_ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(tf_unary_scores, y,\n                                                          sequence_lengths):\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Remove padding from the scores and tag sequence.</span>\n          tf_unary_scores_ <span class=\"pl-k\">=</span> tf_unary_scores_[:sequence_length_]\n          y_ <span class=\"pl-k\">=</span> y_[:sequence_length_]\n\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Compute the highest scoring sequence.</span>\n          viterbi_sequence, _ <span class=\"pl-k\">=</span> tf.contrib.crf.viterbi_decode(\n              tf_unary_scores_, tf_transition_params)\n\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Evaluate word-level accuracy.</span>\n          correct_labels <span class=\"pl-k\">+=</span> np.sum(np.equal(viterbi_sequence, y_))\n          total_labels <span class=\"pl-k\">+=</span> sequence_length_\n        accuracy <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100.0</span> <span class=\"pl-k\">*</span> correct_labels <span class=\"pl-k\">/</span> <span class=\"pl-c1\">float</span>(total_labels)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Accuracy: <span class=\"pl-c1\">%.2f%%</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> accuracy)</pre></div>\n<p>it generates following outputs</p>\n<div class=\"highlight highlight-source-shell\"><pre>2017-03-22 00:40:01.110489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.110631: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active<span class=\"pl-k\">;</span> existing: 0x2b8c6d0\n2017-03-22 00:40:01.337723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:07:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.337815: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active<span class=\"pl-k\">;</span> existing: 0x2b90150\n2017-03-22 00:40:01.544460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 2 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:84:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.544569: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active<span class=\"pl-k\">;</span> existing: 0x2b93e00\n2017-03-22 00:40:01.750146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 3 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:85:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.750302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 2\n2017-03-22 00:40:01.750319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 3\n2017-03-22 00:40:01.750346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 2\n2017-03-22 00:40:01.750358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 3\n2017-03-22 00:40:01.750369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 0\n2017-03-22 00:40:01.750380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 1\n2017-03-22 00:40:01.750479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 0\n2017-03-22 00:40:01.750519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 1\n2017-03-22 00:40:01.750597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2 3\n2017-03-22 00:40:01.750608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y N N\n2017-03-22 00:40:01.750614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y N N\n2017-03-22 00:40:01.750619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 2:   N N Y Y\n2017-03-22 00:40:01.750625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 3:   N N Y Y\n2017-03-22 00:40:01.750643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -<span class=\"pl-k\">&gt;</span> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\n2017-03-22 00:40:01.750650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -<span class=\"pl-k\">&gt;</span> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)\n2017-03-22 00:40:01.750656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:2) -<span class=\"pl-k\">&gt;</span> (device: 2, name: Tesla K80, pci bus id: 0000:84:00.0)\n2017-03-22 00:40:01.750662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:3) -<span class=\"pl-k\">&gt;</span> (device: 3, name: Tesla K80, pci bus id: 0000:85:00.0)\n2017-03-22 00:40:03.347959: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\n2017-03-22 00:40:03.347994: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\n2017-03-22 00:40:03.358665: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b47600 executing computations on platform Host. Devices:\n2017-03-22 00:40:03.358682: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): <span class=\"pl-k\">&lt;</span>undefined<span class=\"pl-k\">&gt;</span>, <span class=\"pl-k\">&lt;</span>undefined<span class=\"pl-k\">&gt;</span>\n2017-03-22 00:40:03.359012: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\n2017-03-22 00:40:03.359026: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\n2017-03-22 00:40:03.367439: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b6fcb0 executing computations on platform CUDA. Devices:\n2017-03-22 00:40:03.367459: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367468: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367475: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367482: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%</pre></div>", "body_text": "The combination of tf.contrib.crf + XLA seems not working (sometimes hang forever).\nFollowing code is for reproducing errors.\nThe code is from standard example - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf\nThe only difference is XLA part.\nWhen XLA is enabled, loss is not reducing.\nIn more large network(real NLP applications), it hangs forever after graph building.\nMy settings is\n\ntensorflow 1.0.1\npython 3.6 (anaconda 4.3.0 )\ncuda 7.5\n\nimport numpy as np\nimport tensorflow as tf\n\n# Data settings.\nnum_examples = 10\nnum_words = 20\nnum_features = 100\nnum_tags = 5\n\n# Random features.\nx = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\n\n# Random tag indices representing the gold sequence.\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\n\n# All sequences in this example have the same length, but they can be variable in a real model.\nsequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\n\n\n# to enable XLA\ntf_config = tf.ConfigProto()\ntf_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n\n\n# Train and evaluate the model.\nwith tf.Graph().as_default():\n  with tf.Session(config=tf_config) as session:\n    # Add the data to the TensorFlow graph.\n    x_t = tf.constant(x)\n    y_t = tf.constant(y)\n    sequence_lengths_t = tf.constant(sequence_lengths)\n\n    # Compute unary scores from a linear layer.\n    weights = tf.get_variable(\"weights\", [num_features, num_tags])\n    matricized_x_t = tf.reshape(x_t, [-1, num_features])\n    matricized_unary_scores = tf.matmul(matricized_x_t, weights)\n    unary_scores = tf.reshape(matricized_unary_scores,\n                              [num_examples, num_words, num_tags])\n\n    # Compute the log-likelihood of the gold sequences and keep the transition\n    # params for inference at test time.\n    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n        unary_scores, y_t, sequence_lengths_t)\n\n    # Add a training op to tune the parameters.\n    loss = tf.reduce_mean(-log_likelihood)\n    \n    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n\n\n    # Train for a fixed number of iterations.\n    session.run(tf.global_variables_initializer())\n    for i in range(1000):\n      tf_unary_scores, tf_transition_params, _ = session.run(\n          [unary_scores, transition_params, train_op])\n      if i % 100 == 0:\n        correct_labels = 0\n        total_labels = 0\n        for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\n                                                          sequence_lengths):\n          # Remove padding from the scores and tag sequence.\n          tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\n          y_ = y_[:sequence_length_]\n\n          # Compute the highest scoring sequence.\n          viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\n              tf_unary_scores_, tf_transition_params)\n\n          # Evaluate word-level accuracy.\n          correct_labels += np.sum(np.equal(viterbi_sequence, y_))\n          total_labels += sequence_length_\n        accuracy = 100.0 * correct_labels / float(total_labels)\n        print(\"Accuracy: %.2f%%\" % accuracy)\nit generates following outputs\n2017-03-22 00:40:01.110489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.110631: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b8c6d0\n2017-03-22 00:40:01.337723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:07:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.337815: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b90150\n2017-03-22 00:40:01.544460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 2 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:84:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.544569: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b93e00\n2017-03-22 00:40:01.750146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 3 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:85:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\n2017-03-22 00:40:01.750302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 2\n2017-03-22 00:40:01.750319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 3\n2017-03-22 00:40:01.750346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 2\n2017-03-22 00:40:01.750358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 3\n2017-03-22 00:40:01.750369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 0\n2017-03-22 00:40:01.750380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 1\n2017-03-22 00:40:01.750479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 0\n2017-03-22 00:40:01.750519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 1\n2017-03-22 00:40:01.750597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2 3\n2017-03-22 00:40:01.750608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y N N\n2017-03-22 00:40:01.750614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y N N\n2017-03-22 00:40:01.750619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 2:   N N Y Y\n2017-03-22 00:40:01.750625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 3:   N N Y Y\n2017-03-22 00:40:01.750643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\n2017-03-22 00:40:01.750650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)\n2017-03-22 00:40:01.750656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:84:00.0)\n2017-03-22 00:40:01.750662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:85:00.0)\n2017-03-22 00:40:03.347959: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\n2017-03-22 00:40:03.347994: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\n2017-03-22 00:40:03.358665: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b47600 executing computations on platform Host. Devices:\n2017-03-22 00:40:03.358682: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): <undefined>, <undefined>\n2017-03-22 00:40:03.359012: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\n2017-03-22 00:40:03.359026: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\n2017-03-22 00:40:03.367439: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b6fcb0 executing computations on platform CUDA. Devices:\n2017-03-22 00:40:03.367459: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367468: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367475: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7\n2017-03-22 00:40:03.367482: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%\nAccuracy: 15.26%", "body": "The combination of tf.contrib.crf + XLA seems not working (sometimes hang forever).\r\n\r\nFollowing code is for reproducing errors.\r\nThe code is from standard example - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf\r\nThe only difference is XLA part. \r\n\r\nWhen XLA is enabled, loss is not reducing.\r\nIn more large network(real NLP applications), it hangs forever after graph building. \r\n\r\nMy settings is \r\n- tensorflow 1.0.1\r\n- python 3.6 (anaconda 4.3.0 )\r\n- cuda 7.5 \r\n \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Data settings.\r\nnum_examples = 10\r\nnum_words = 20\r\nnum_features = 100\r\nnum_tags = 5\r\n\r\n# Random features.\r\nx = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\r\n\r\n# Random tag indices representing the gold sequence.\r\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\r\n\r\n# All sequences in this example have the same length, but they can be variable in a real model.\r\nsequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\r\n\r\n\r\n# to enable XLA\r\ntf_config = tf.ConfigProto()\r\ntf_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\n\r\n\r\n# Train and evaluate the model.\r\nwith tf.Graph().as_default():\r\n  with tf.Session(config=tf_config) as session:\r\n    # Add the data to the TensorFlow graph.\r\n    x_t = tf.constant(x)\r\n    y_t = tf.constant(y)\r\n    sequence_lengths_t = tf.constant(sequence_lengths)\r\n\r\n    # Compute unary scores from a linear layer.\r\n    weights = tf.get_variable(\"weights\", [num_features, num_tags])\r\n    matricized_x_t = tf.reshape(x_t, [-1, num_features])\r\n    matricized_unary_scores = tf.matmul(matricized_x_t, weights)\r\n    unary_scores = tf.reshape(matricized_unary_scores,\r\n                              [num_examples, num_words, num_tags])\r\n\r\n    # Compute the log-likelihood of the gold sequences and keep the transition\r\n    # params for inference at test time.\r\n    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\r\n        unary_scores, y_t, sequence_lengths_t)\r\n\r\n    # Add a training op to tune the parameters.\r\n    loss = tf.reduce_mean(-log_likelihood)\r\n    \r\n    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\r\n\r\n\r\n    # Train for a fixed number of iterations.\r\n    session.run(tf.global_variables_initializer())\r\n    for i in range(1000):\r\n      tf_unary_scores, tf_transition_params, _ = session.run(\r\n          [unary_scores, transition_params, train_op])\r\n      if i % 100 == 0:\r\n        correct_labels = 0\r\n        total_labels = 0\r\n        for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\r\n                                                          sequence_lengths):\r\n          # Remove padding from the scores and tag sequence.\r\n          tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\r\n          y_ = y_[:sequence_length_]\r\n\r\n          # Compute the highest scoring sequence.\r\n          viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\r\n              tf_unary_scores_, tf_transition_params)\r\n\r\n          # Evaluate word-level accuracy.\r\n          correct_labels += np.sum(np.equal(viterbi_sequence, y_))\r\n          total_labels += sequence_length_\r\n        accuracy = 100.0 * correct_labels / float(total_labels)\r\n        print(\"Accuracy: %.2f%%\" % accuracy)\r\n```\r\n\r\nit generates following outputs\r\n```sh\r\n2017-03-22 00:40:01.110489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:06:00.0\r\nTotal memory: 11.25GiB\r\nFree memory: 11.16GiB\r\n2017-03-22 00:40:01.110631: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b8c6d0\r\n2017-03-22 00:40:01.337723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties:\r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:07:00.0\r\nTotal memory: 11.25GiB\r\nFree memory: 11.16GiB\r\n2017-03-22 00:40:01.337815: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b90150\r\n2017-03-22 00:40:01.544460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 2 with properties:\r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:84:00.0\r\nTotal memory: 11.25GiB\r\nFree memory: 11.16GiB\r\n2017-03-22 00:40:01.544569: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x2b93e00\r\n2017-03-22 00:40:01.750146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 3 with properties:\r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:85:00.0\r\nTotal memory: 11.25GiB\r\nFree memory: 11.16GiB\r\n2017-03-22 00:40:01.750302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 2\r\n2017-03-22 00:40:01.750319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 0 and 3\r\n2017-03-22 00:40:01.750346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 2\r\n2017-03-22 00:40:01.750358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 1 and 3\r\n2017-03-22 00:40:01.750369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 0\r\n2017-03-22 00:40:01.750380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 2 and 1\r\n2017-03-22 00:40:01.750479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 0\r\n2017-03-22 00:40:01.750519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:779] Peer access not supported between device ordinals 3 and 1\r\n2017-03-22 00:40:01.750597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2 3\r\n2017-03-22 00:40:01.750608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y N N\r\n2017-03-22 00:40:01.750614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y N N\r\n2017-03-22 00:40:01.750619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 2:   N N Y Y\r\n2017-03-22 00:40:01.750625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 3:   N N Y Y\r\n2017-03-22 00:40:01.750643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)\r\n2017-03-22 00:40:01.750650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)\r\n2017-03-22 00:40:01.750656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:84:00.0)\r\n2017-03-22 00:40:01.750662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:85:00.0)\r\n2017-03-22 00:40:03.347959: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\r\n2017-03-22 00:40:03.347994: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\r\n2017-03-22 00:40:03.358665: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b47600 executing computations on platform Host. Devices:\r\n2017-03-22 00:40:03.358682: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): <undefined>, <undefined>\r\n2017-03-22 00:40:03.359012: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 4 visible devices\r\n2017-03-22 00:40:03.359026: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 48 visible devices\r\n2017-03-22 00:40:03.367439: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4b6fcb0 executing computations on platform CUDA. Devices:\r\n2017-03-22 00:40:03.367459: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\r\n2017-03-22 00:40:03.367468: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\r\n2017-03-22 00:40:03.367475: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7\r\n2017-03-22 00:40:03.367482: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (3): Tesla K80, Compute Capability 3.7\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\nAccuracy: 15.26%\r\n```\r\n\r\n\r\n\r\n"}