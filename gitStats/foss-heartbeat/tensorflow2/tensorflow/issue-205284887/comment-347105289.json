{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347105289", "html_url": "https://github.com/tensorflow/tensorflow/issues/7253#issuecomment-347105289", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7253", "id": 347105289, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzEwNTI4OQ==", "user": {"login": "SMZCC", "id": 26531452, "node_id": "MDQ6VXNlcjI2NTMxNDUy", "avatar_url": "https://avatars3.githubusercontent.com/u/26531452?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SMZCC", "html_url": "https://github.com/SMZCC", "followers_url": "https://api.github.com/users/SMZCC/followers", "following_url": "https://api.github.com/users/SMZCC/following{/other_user}", "gists_url": "https://api.github.com/users/SMZCC/gists{/gist_id}", "starred_url": "https://api.github.com/users/SMZCC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SMZCC/subscriptions", "organizations_url": "https://api.github.com/users/SMZCC/orgs", "repos_url": "https://api.github.com/users/SMZCC/repos", "events_url": "https://api.github.com/users/SMZCC/events{/privacy}", "received_events_url": "https://api.github.com/users/SMZCC/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T08:02:37Z", "updated_at": "2017-11-27T08:02:37Z", "author_association": "NONE", "body_html": "<ul>\n<li>I have successfully used tf.shape()[0] to flat a  tensor with  none dim  as a vector, thanks</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>tensor_vector <span class=\"pl-k\">=</span> tf.reshape(<span class=\"pl-v\">tensor</span><span class=\"pl-k\">=</span>some_tensor, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, tf.shape(some_tensor)[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">*</span>tf.shape(some_tensor)[<span class=\"pl-c1\">2</span>])</pre></div>\n<ul>\n<li>however , I want to connect a full connected layer behind the  <code>tensor_vector</code>, so I have to define the weight matrix's shape, then the contradiction is occurred ,because when I\u3000using the <code>wshape = (tf.shape(some_tensor)[1] *tf.shape(some_tensor)[\uff12] , 1000)</code> to define the weight matrix , the error is that the dim of the weight matrix must be an integer not a tensor,  however ,the dim I have to use tf.shape(some_tensor) to get which is a tensor ,so ,how can I\u3000solve it ?</li>\n</ul>", "body_text": "I have successfully used tf.shape()[0] to flat a  tensor with  none dim  as a vector, thanks\n\ntensor_vector = tf.reshape(tensor=some_tensor, shape=(-1, tf.shape(some_tensor)[1]*tf.shape(some_tensor)[2])\n\nhowever , I want to connect a full connected layer behind the  tensor_vector, so I have to define the weight matrix's shape, then the contradiction is occurred ,because when I\u3000using the wshape = (tf.shape(some_tensor)[1] *tf.shape(some_tensor)[\uff12] , 1000) to define the weight matrix , the error is that the dim of the weight matrix must be an integer not a tensor,  however ,the dim I have to use tf.shape(some_tensor) to get which is a tensor ,so ,how can I\u3000solve it ?", "body": "- I have successfully used tf.shape()[0] to flat a  tensor with  none dim  as a vector, thanks\r\n```python\r\ntensor_vector = tf.reshape(tensor=some_tensor, shape=(-1, tf.shape(some_tensor)[1]*tf.shape(some_tensor)[2])\r\n```\r\n- however , I want to connect a full connected layer behind the  `tensor_vector`, so I have to define the weight matrix's shape, then the contradiction is occurred ,because when I\u3000using the `wshape = (tf.shape(some_tensor)[1] *tf.shape(some_tensor)[\uff12] , 1000)` to define the weight matrix , the error is that the dim of the weight matrix must be an integer not a tensor,  however ,the dim I have to use tf.shape(some_tensor) to get which is a tensor ,so ,how can I\u3000solve it ?   "}