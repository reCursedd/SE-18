{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23527", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23527/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23527/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23527/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23527", "id": 377446685, "node_id": "MDU6SXNzdWUzNzc0NDY2ODU=", "number": 23527, "title": "Acc and loss evaluate to 0.00 and trains for only 1 global steps.", "user": {"login": "aaryapatel007", "id": 30631425, "node_id": "MDQ6VXNlcjMwNjMxNDI1", "avatar_url": "https://avatars0.githubusercontent.com/u/30631425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaryapatel007", "html_url": "https://github.com/aaryapatel007", "followers_url": "https://api.github.com/users/aaryapatel007/followers", "following_url": "https://api.github.com/users/aaryapatel007/following{/other_user}", "gists_url": "https://api.github.com/users/aaryapatel007/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaryapatel007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaryapatel007/subscriptions", "organizations_url": "https://api.github.com/users/aaryapatel007/orgs", "repos_url": "https://api.github.com/users/aaryapatel007/repos", "events_url": "https://api.github.com/users/aaryapatel007/events{/privacy}", "received_events_url": "https://api.github.com/users/aaryapatel007/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-05T15:20:53Z", "updated_at": "2018-11-07T20:47:01Z", "closed_at": "2018-11-07T20:47:01Z", "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No</li>\n<li>TensorFlow installed from (source or binary):</li>\n<li>TensorFlow version (use command below):1.12</li>\n<li>Python version:3.6</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU model and memory:1xTesla K80  12GB GDDR5 VRAM</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p><strong>Describe the current behavior</strong><br>\nMy model's accuracy and loss are evaluating to 0.</p>\n<p><strong>Describe the expected behavior</strong><br>\nThe global steps should be 1625 but it's 1.<br>\nThe acc and loss shouldn't be equal to 0 as both of them are contradicting each other.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.<br>\nmy input function,keras estimator,train_and_evaluate are as follows:</p>\n<pre><code>def make_input_fn(addrs,labels,batch_size,mode):\n    \n    filename_dataset = tf.data.Dataset.from_tensor_slices((addrs,labels))     \n    \n    dataset = filename_dataset.apply(tf.contrib.data.map_and_batch(lambda addrs, labels: tuple(tf.py_func(\n        process, [addrs, labels], [tf.uint8, labels.dtype])),\n                                                                   batch_size,\n                                                                   num_parallel_batches=2,\n                                                                   drop_remainder=False))\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      num_epochs = None # indefinitely\n      dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size = 10000))\n    else:\n      num_epochs = 1\n      dataset = dataset.repeat(num_epochs)\n   \n    dataset = dataset.prefetch(buffer_size=batch_size)\n    images,labels = dataset.make_one_shot_iterator().get_next()\n    images.set_shape([None,512,512,3])\n    labels.set_shape([None,1])\n    return images,labels\n`\n\ndef keras_estimator(model_dir,config):\n  base_model = Xception(weights='imagenet', include_top=False,input_shape = (512,512,3),classes = 5)\n\n\n  x = base_model.output\n  x = GlobalAveragePooling2D()(x)\n  \n  x = Dense(1024, activation='relu')(x)\n  x = Dropout(0.2)(x)\n  x = Dense(256, activation='relu')(x)\n  x = Dropout(0.2)(x)\n  \n  predictions = Dense(5, activation='softmax')(x)\n\n  \n  model = Model(inputs=base_model.input, outputs=predictions)\n\n  \n  for layer in base_model.layers:\n      layer.trainable = False\n  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n  estimator = tf.keras.estimator.model_to_estimator(keras_model=model,model_dir=model_dir,\n    config=config)\n  return estimator\n\n\ndef train_and_evaluate(model_dir):\n  t_batch_size = 512\n  e_batch_size = 64\n  num_epochs = 25\n  import pandas as pd\n  df = pd.read_csv('/content/trainLabels.csv')\n  from random import shuffle\n  addrs = ['/content/train/train/' + str(df.iloc[i]['image']) + '.jpeg' for i in range(len(df))]\n  labels = df['level'].values.tolist()\n  c = list(zip(addrs, labels))\n  shuffle(c)\n  addrs1, labels1 = zip(*c)\n  train_addrs = addrs1[0 : int(0.9 * len(addrs))]\n  train_labels = labels1[0 : int(0.9 * len(labels))]\n  val_addrs = addrs1[ int(0.9 * len(addrs)) : ]\n  val_labels = labels1[ int(0.9 * len(addrs)) : ]\n  train_addrs = list(train_addrs)\n  train_labels = list(train_labels)\n  val_addrs = list(val_addrs)\n  val_labels = list(val_labels)\n  \n  run_config = tf.estimator.RunConfig(save_checkpoints_secs=300)\n  \n  estimator = keras_estimator(model_dir,run_config)\n  \n  t_max_steps = (len(train_addrs) // t_batch_size) * num_epochs\n  \n  train_spec = tf.estimator.TrainSpec(input_fn = lambda : make_input_fn(train_addrs,train_labels,t_batch_size,mode=tf.estimator.ModeKeys.TRAIN),max_steps = t_max_steps)\n  \n  eval_spec = tf.estimator.EvalSpec(input_fn = lambda : make_input_fn(val_addrs,val_labels,e_batch_size,mode=tf.estimator.ModeKeys.EVAL),steps = None,start_delay_secs=10,\n        throttle_secs=300)\n  \n  \n  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n</code></pre>\n<p><strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.<br>\n<code>INFO:tensorflow:Running training and evaluation locally (non-distributed). INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300. WARNING:tensorflow:From &lt;ipython-input-7-80b5bdaf35df&gt;:9: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version. Instructions for updating: Use </code>tf.data.experimental.map_and_batch(...)<code>. WARNING:tensorflow:From &lt;ipython-input-7-80b5bdaf35df&gt;:12: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version. Instructions for updating: Use </code>tf.data.experimental.shuffle_and_repeat(...)<code>. INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/content/training/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={}) INFO:tensorflow:Warm-starting from: ('/content/training/keras/keras_model.ckpt',) INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged INFO:tensorflow:Create CheckpointSaverHook. INFO:tensorflow:Graph was finalized. INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Saving checkpoints for 0 into /content/training/model.ckpt. INFO:tensorflow:Saving checkpoints for 1 into /content/training/model.ckpt. INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Starting evaluation at 2018-11-05-13:21:17 INFO:tensorflow:Graph was finalized. INFO:tensorflow:Restoring parameters from /content/training/model.ckpt-1 INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Finished evaluation at 2018-11-05-13:22:08 INFO:tensorflow:Saving dict for global step 1: acc = 0.0, global_step = 1, loss = 0.0 INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: /content/training/model.ckpt-1 INFO:tensorflow:Loss for final step: None.</code></p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):1.12\nPython version:3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:1xTesla K80  12GB GDDR5 VRAM\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the current behavior\nMy model's accuracy and loss are evaluating to 0.\nDescribe the expected behavior\nThe global steps should be 1625 but it's 1.\nThe acc and loss shouldn't be equal to 0 as both of them are contradicting each other.\nCode to reproduce the issue\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\nmy input function,keras estimator,train_and_evaluate are as follows:\ndef make_input_fn(addrs,labels,batch_size,mode):\n    \n    filename_dataset = tf.data.Dataset.from_tensor_slices((addrs,labels))     \n    \n    dataset = filename_dataset.apply(tf.contrib.data.map_and_batch(lambda addrs, labels: tuple(tf.py_func(\n        process, [addrs, labels], [tf.uint8, labels.dtype])),\n                                                                   batch_size,\n                                                                   num_parallel_batches=2,\n                                                                   drop_remainder=False))\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      num_epochs = None # indefinitely\n      dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size = 10000))\n    else:\n      num_epochs = 1\n      dataset = dataset.repeat(num_epochs)\n   \n    dataset = dataset.prefetch(buffer_size=batch_size)\n    images,labels = dataset.make_one_shot_iterator().get_next()\n    images.set_shape([None,512,512,3])\n    labels.set_shape([None,1])\n    return images,labels\n`\n\ndef keras_estimator(model_dir,config):\n  base_model = Xception(weights='imagenet', include_top=False,input_shape = (512,512,3),classes = 5)\n\n\n  x = base_model.output\n  x = GlobalAveragePooling2D()(x)\n  \n  x = Dense(1024, activation='relu')(x)\n  x = Dropout(0.2)(x)\n  x = Dense(256, activation='relu')(x)\n  x = Dropout(0.2)(x)\n  \n  predictions = Dense(5, activation='softmax')(x)\n\n  \n  model = Model(inputs=base_model.input, outputs=predictions)\n\n  \n  for layer in base_model.layers:\n      layer.trainable = False\n  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n  estimator = tf.keras.estimator.model_to_estimator(keras_model=model,model_dir=model_dir,\n    config=config)\n  return estimator\n\n\ndef train_and_evaluate(model_dir):\n  t_batch_size = 512\n  e_batch_size = 64\n  num_epochs = 25\n  import pandas as pd\n  df = pd.read_csv('/content/trainLabels.csv')\n  from random import shuffle\n  addrs = ['/content/train/train/' + str(df.iloc[i]['image']) + '.jpeg' for i in range(len(df))]\n  labels = df['level'].values.tolist()\n  c = list(zip(addrs, labels))\n  shuffle(c)\n  addrs1, labels1 = zip(*c)\n  train_addrs = addrs1[0 : int(0.9 * len(addrs))]\n  train_labels = labels1[0 : int(0.9 * len(labels))]\n  val_addrs = addrs1[ int(0.9 * len(addrs)) : ]\n  val_labels = labels1[ int(0.9 * len(addrs)) : ]\n  train_addrs = list(train_addrs)\n  train_labels = list(train_labels)\n  val_addrs = list(val_addrs)\n  val_labels = list(val_labels)\n  \n  run_config = tf.estimator.RunConfig(save_checkpoints_secs=300)\n  \n  estimator = keras_estimator(model_dir,run_config)\n  \n  t_max_steps = (len(train_addrs) // t_batch_size) * num_epochs\n  \n  train_spec = tf.estimator.TrainSpec(input_fn = lambda : make_input_fn(train_addrs,train_labels,t_batch_size,mode=tf.estimator.ModeKeys.TRAIN),max_steps = t_max_steps)\n  \n  eval_spec = tf.estimator.EvalSpec(input_fn = lambda : make_input_fn(val_addrs,val_labels,e_batch_size,mode=tf.estimator.ModeKeys.EVAL),steps = None,start_delay_secs=10,\n        throttle_secs=300)\n  \n  \n  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\nINFO:tensorflow:Running training and evaluation locally (non-distributed). INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300. WARNING:tensorflow:From <ipython-input-7-80b5bdaf35df>:9: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version. Instructions for updating: Use tf.data.experimental.map_and_batch(...). WARNING:tensorflow:From <ipython-input-7-80b5bdaf35df>:12: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.data.experimental.shuffle_and_repeat(...). INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/content/training/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={}) INFO:tensorflow:Warm-starting from: ('/content/training/keras/keras_model.ckpt',) INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged INFO:tensorflow:Create CheckpointSaverHook. INFO:tensorflow:Graph was finalized. INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Saving checkpoints for 0 into /content/training/model.ckpt. INFO:tensorflow:Saving checkpoints for 1 into /content/training/model.ckpt. INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Starting evaluation at 2018-11-05-13:21:17 INFO:tensorflow:Graph was finalized. INFO:tensorflow:Restoring parameters from /content/training/model.ckpt-1 INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Finished evaluation at 2018-11-05-13:22:08 INFO:tensorflow:Saving dict for global step 1: acc = 0.0, global_step = 1, loss = 0.0 INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: /content/training/model.ckpt-1 INFO:tensorflow:Loss for final step: None.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):1.12\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:1xTesla K80  12GB GDDR5 VRAM\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nMy model's accuracy and loss are evaluating to 0.\r\n\r\n**Describe the expected behavior**\r\nThe global steps should be 1625 but it's 1.\r\nThe acc and loss shouldn't be equal to 0 as both of them are contradicting each other.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nmy input function,keras estimator,train_and_evaluate are as follows:\r\n```\r\ndef make_input_fn(addrs,labels,batch_size,mode):\r\n    \r\n    filename_dataset = tf.data.Dataset.from_tensor_slices((addrs,labels))     \r\n    \r\n    dataset = filename_dataset.apply(tf.contrib.data.map_and_batch(lambda addrs, labels: tuple(tf.py_func(\r\n        process, [addrs, labels], [tf.uint8, labels.dtype])),\r\n                                                                   batch_size,\r\n                                                                   num_parallel_batches=2,\r\n                                                                   drop_remainder=False))\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n      num_epochs = None # indefinitely\r\n      dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size = 10000))\r\n    else:\r\n      num_epochs = 1\r\n      dataset = dataset.repeat(num_epochs)\r\n   \r\n    dataset = dataset.prefetch(buffer_size=batch_size)\r\n    images,labels = dataset.make_one_shot_iterator().get_next()\r\n    images.set_shape([None,512,512,3])\r\n    labels.set_shape([None,1])\r\n    return images,labels\r\n`\r\n\r\ndef keras_estimator(model_dir,config):\r\n  base_model = Xception(weights='imagenet', include_top=False,input_shape = (512,512,3),classes = 5)\r\n\r\n\r\n  x = base_model.output\r\n  x = GlobalAveragePooling2D()(x)\r\n  \r\n  x = Dense(1024, activation='relu')(x)\r\n  x = Dropout(0.2)(x)\r\n  x = Dense(256, activation='relu')(x)\r\n  x = Dropout(0.2)(x)\r\n  \r\n  predictions = Dense(5, activation='softmax')(x)\r\n\r\n  \r\n  model = Model(inputs=base_model.input, outputs=predictions)\r\n\r\n  \r\n  for layer in base_model.layers:\r\n      layer.trainable = False\r\n  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\r\n  estimator = tf.keras.estimator.model_to_estimator(keras_model=model,model_dir=model_dir,\r\n    config=config)\r\n  return estimator\r\n\r\n\r\ndef train_and_evaluate(model_dir):\r\n  t_batch_size = 512\r\n  e_batch_size = 64\r\n  num_epochs = 25\r\n  import pandas as pd\r\n  df = pd.read_csv('/content/trainLabels.csv')\r\n  from random import shuffle\r\n  addrs = ['/content/train/train/' + str(df.iloc[i]['image']) + '.jpeg' for i in range(len(df))]\r\n  labels = df['level'].values.tolist()\r\n  c = list(zip(addrs, labels))\r\n  shuffle(c)\r\n  addrs1, labels1 = zip(*c)\r\n  train_addrs = addrs1[0 : int(0.9 * len(addrs))]\r\n  train_labels = labels1[0 : int(0.9 * len(labels))]\r\n  val_addrs = addrs1[ int(0.9 * len(addrs)) : ]\r\n  val_labels = labels1[ int(0.9 * len(addrs)) : ]\r\n  train_addrs = list(train_addrs)\r\n  train_labels = list(train_labels)\r\n  val_addrs = list(val_addrs)\r\n  val_labels = list(val_labels)\r\n  \r\n  run_config = tf.estimator.RunConfig(save_checkpoints_secs=300)\r\n  \r\n  estimator = keras_estimator(model_dir,run_config)\r\n  \r\n  t_max_steps = (len(train_addrs) // t_batch_size) * num_epochs\r\n  \r\n  train_spec = tf.estimator.TrainSpec(input_fn = lambda : make_input_fn(train_addrs,train_labels,t_batch_size,mode=tf.estimator.ModeKeys.TRAIN),max_steps = t_max_steps)\r\n  \r\n  eval_spec = tf.estimator.EvalSpec(input_fn = lambda : make_input_fn(val_addrs,val_labels,e_batch_size,mode=tf.estimator.ModeKeys.EVAL),steps = None,start_delay_secs=10,\r\n        throttle_secs=300)\r\n  \r\n  \r\n  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\n    \r\n\r\n\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`INFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\r\nWARNING:tensorflow:From <ipython-input-7-80b5bdaf35df>:9: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.map_and_batch(...)`.\r\nWARNING:tensorflow:From <ipython-input-7-80b5bdaf35df>:12: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.shuffle_and_repeat(...)`.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/content/training/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: ('/content/training/keras/keras_model.ckpt',)\r\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /content/training/model.ckpt.\r\nINFO:tensorflow:Saving checkpoints for 1 into /content/training/model.ckpt.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2018-11-05-13:21:17\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Restoring parameters from /content/training/model.ckpt-1\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Finished evaluation at 2018-11-05-13:22:08\r\nINFO:tensorflow:Saving dict for global step 1: acc = 0.0, global_step = 1, loss = 0.0\r\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: /content/training/model.ckpt-1\r\nINFO:tensorflow:Loss for final step: None.`\r\n\r\n"}