{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6416", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6416/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6416/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6416/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6416", "id": 196625831, "node_id": "MDU6SXNzdWUxOTY2MjU4MzE=", "number": 6416, "title": "Tensorflow fault tolerance", "user": {"login": "chaitanya2692", "id": 8254695, "node_id": "MDQ6VXNlcjgyNTQ2OTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8254695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chaitanya2692", "html_url": "https://github.com/chaitanya2692", "followers_url": "https://api.github.com/users/chaitanya2692/followers", "following_url": "https://api.github.com/users/chaitanya2692/following{/other_user}", "gists_url": "https://api.github.com/users/chaitanya2692/gists{/gist_id}", "starred_url": "https://api.github.com/users/chaitanya2692/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chaitanya2692/subscriptions", "organizations_url": "https://api.github.com/users/chaitanya2692/orgs", "repos_url": "https://api.github.com/users/chaitanya2692/repos", "events_url": "https://api.github.com/users/chaitanya2692/events{/privacy}", "received_events_url": "https://api.github.com/users/chaitanya2692/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-12-20T09:36:41Z", "updated_at": "2018-02-08T11:40:30Z", "closed_at": "2016-12-21T01:27:21Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>I have been using the following simple code to learn about the behavior of distributed tensorflow (which claims to be fault tolerant):-</p>\n<pre><code>import tensorflow as tf\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\nx = tf.constant(2)\nwith tf.device(\"/job:local/task:1\"):\n  y1 = x + 300\nwith tf.device(\"/job:local/task:2\"):\n  y2 = x**2\nwith tf.device(\"/job:local/task:3\"):\n  y3 = 5*x\nwith tf.device(\"/job:local/task:0\"):\n  y0 = x - 66\n  y = y0 + y1 + y2 + y3\n\nmodel = tf.initialize_all_variables()\n\nwith tf.Session(\"grpc://localhost:2222\") as sess:\n  sess.run(model)\n  print(sess.run(y0))\n  print('\\n')\n  print(sess.run(y1))\n  print('\\n')\n  print(sess.run(y2))\n  print('\\n')\n  print(sess.run(y3))\n  print('\\n')\n  result = sess.run(y)\n  print(result)\n</code></pre>\n<p>I create workers by running a separate program as given below:-</p>\n<pre><code>#get task number from command line\nimport sys\ntask_number = int(sys.argv[1])\n\nimport tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\", \"localhost:2225\"]})\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=task_number)\n\nprint(\"Starting server #{}\".format(task_number))\n\nserver.start()\nserver.join()\n\n</code></pre>\n<p>But when I stop one of the servers(machines), the whole program stops functioning instead of assigning the job to another machine. Is tensorflow fault tolerant when a machine goes down?</p>", "body_text": "Hello,\nI have been using the following simple code to learn about the behavior of distributed tensorflow (which claims to be fault tolerant):-\nimport tensorflow as tf\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\nx = tf.constant(2)\nwith tf.device(\"/job:local/task:1\"):\n  y1 = x + 300\nwith tf.device(\"/job:local/task:2\"):\n  y2 = x**2\nwith tf.device(\"/job:local/task:3\"):\n  y3 = 5*x\nwith tf.device(\"/job:local/task:0\"):\n  y0 = x - 66\n  y = y0 + y1 + y2 + y3\n\nmodel = tf.initialize_all_variables()\n\nwith tf.Session(\"grpc://localhost:2222\") as sess:\n  sess.run(model)\n  print(sess.run(y0))\n  print('\\n')\n  print(sess.run(y1))\n  print('\\n')\n  print(sess.run(y2))\n  print('\\n')\n  print(sess.run(y3))\n  print('\\n')\n  result = sess.run(y)\n  print(result)\n\nI create workers by running a separate program as given below:-\n#get task number from command line\nimport sys\ntask_number = int(sys.argv[1])\n\nimport tensorflow as tf\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\", \"localhost:2225\"]})\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=task_number)\n\nprint(\"Starting server #{}\".format(task_number))\n\nserver.start()\nserver.join()\n\n\nBut when I stop one of the servers(machines), the whole program stops functioning instead of assigning the job to another machine. Is tensorflow fault tolerant when a machine goes down?", "body": "Hello,\r\n\r\nI have been using the following simple code to learn about the behavior of distributed tensorflow (which claims to be fault tolerant):-\r\n\r\n  ```\r\nimport tensorflow as tf\r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\r\nx = tf.constant(2)\r\nwith tf.device(\"/job:local/task:1\"):\r\n    y1 = x + 300\r\n with tf.device(\"/job:local/task:2\"):\r\n    y2 = x**2\r\nwith tf.device(\"/job:local/task:3\"):\r\n    y3 = 5*x\r\nwith tf.device(\"/job:local/task:0\"):\r\n    y0 = x - 66\r\n    y = y0 + y1 + y2 + y3\r\n\r\nmodel = tf.initialize_all_variables()\r\n\r\nwith tf.Session(\"grpc://localhost:2222\") as sess:\r\n    sess.run(model)\r\n    print(sess.run(y0))\r\n    print('\\n')\r\n    print(sess.run(y1))\r\n    print('\\n')\r\n    print(sess.run(y2))\r\n    print('\\n')\r\n    print(sess.run(y3))\r\n    print('\\n')\r\n    result = sess.run(y)\r\n    print(result)\r\n```\r\n\r\nI create workers by running a separate program as given below:-\r\n\r\n```\r\n#get task number from command line\r\nimport sys\r\ntask_number = int(sys.argv[1])\r\n\r\nimport tensorflow as tf\r\n\r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\", \"localhost:2225\"]})\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=task_number)\r\n\r\nprint(\"Starting server #{}\".format(task_number))\r\n\r\nserver.start()\r\nserver.join()\r\n\r\n```\r\nBut when I stop one of the servers(machines), the whole program stops functioning instead of assigning the job to another machine. Is tensorflow fault tolerant when a machine goes down? "}