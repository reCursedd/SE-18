{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/165889108", "html_url": "https://github.com/tensorflow/tensorflow/issues/543#issuecomment-165889108", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/543", "id": 165889108, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTg4OTEwOA==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-18T20:17:15Z", "updated_at": "2015-12-18T20:17:15Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<blockquote>\n<p>cannot enable peer access from device ordinal 0 to device ordinal 2\"</p>\n</blockquote>\n</blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5636133\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lglhuada\">@lglhuada</a>, This is not an error, just log. It just means there is no efficient way to transfer data from gpu:0 to gpu:2. You can exclude either one of them through CUDA_VISIBLE_DEVICES</p>\n<blockquote>\n<blockquote>\n<p>the GPU usage is 95% while the volatile GPU-Util is 0.</p>\n</blockquote>\n</blockquote>\n<p>This is also expected. TensorFlow always reserves most the GPU memory when it initializes, even before the first GPU kernels are received. So you will see a high memory usage at the beginning. But the fact GPU is not actually utilized means none of the kernels are running on GPU.</p>\n<p>Could you try to run the tutorials and see if you can get any GPU utilized?</p>\n<blockquote>\n<blockquote>\n<p>bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer<br>\nbazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu</p>\n</blockquote>\n</blockquote>\n<p>If you still have problems after that, please provide more information about your machine set up.</p>", "body_text": "cannot enable peer access from device ordinal 0 to device ordinal 2\"\n\n\n@lglhuada, This is not an error, just log. It just means there is no efficient way to transfer data from gpu:0 to gpu:2. You can exclude either one of them through CUDA_VISIBLE_DEVICES\n\n\nthe GPU usage is 95% while the volatile GPU-Util is 0.\n\n\nThis is also expected. TensorFlow always reserves most the GPU memory when it initializes, even before the first GPU kernels are received. So you will see a high memory usage at the beginning. But the fact GPU is not actually utilized means none of the kernels are running on GPU.\nCould you try to run the tutorials and see if you can get any GPU utilized?\n\n\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nbazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n\n\nIf you still have problems after that, please provide more information about your machine set up.", "body": "> > cannot enable peer access from device ordinal 0 to device ordinal 2\"\n\n@lglhuada, This is not an error, just log. It just means there is no efficient way to transfer data from gpu:0 to gpu:2. You can exclude either one of them through CUDA_VISIBLE_DEVICES\n\n> > the GPU usage is 95% while the volatile GPU-Util is 0.\n\nThis is also expected. TensorFlow always reserves most the GPU memory when it initializes, even before the first GPU kernels are received. So you will see a high memory usage at the beginning. But the fact GPU is not actually utilized means none of the kernels are running on GPU.\n\nCould you try to run the tutorials and see if you can get any GPU utilized? \n\n> > bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n> > bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n\nIf you still have problems after that, please provide more information about your machine set up. \n"}