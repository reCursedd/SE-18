{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339180122", "html_url": "https://github.com/tensorflow/tensorflow/issues/13865#issuecomment-339180122", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13865", "id": 339180122, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTE4MDEyMg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-25T00:54:39Z", "updated_at": "2017-10-25T00:54:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hmm, I'm concerned that using <code>None</code> for this purpose doesn't give enough information. For example,  let's take the code fragment defining <code>data_test</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>X_test <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\ny_test <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(<span class=\"pl-c1\">None</span>)\ndata_test <span class=\"pl-k\">=</span> tf.conrib.Dataset.zip((X_test, y_test))</pre></div>\n<p>At this point, what is the value of <code>data_test.output_types[1]</code> and <code>data_test.output_shapes[1]</code>? It's only implied by code later in the snippet:</p>\n<pre><code>iterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\n# ...\ntest_init_op = iterator.make_initializer(data_test)\n</code></pre>\n<p>...and I don't see how the two <code>assert</code> statements would be able to pass. It seems like you want something \"stronger\" than an <code>assert</code>, which can go back a few lines in the code and cause <code>y_test</code> to have the appropriate type and shape.</p>\n<p>Did you have an approach in mind that would make this work?</p>\n<hr>\n<p>For the record though, you don't need to waste memory to tack on a dummy value to the test dataset. For example <code>Dataset.from_tensors(0).repeat(len(X_test_data))</code> only allocates a single tensor containing 0 and returns shallow copies of it for each element. This allows it to be used with much larger datasets than ones that fit in a NumPy array.</p>", "body_text": "Hmm, I'm concerned that using None for this purpose doesn't give enough information. For example,  let's take the code fragment defining data_test:\nX_test = tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\ny_test = tf.contrib.data.Dataset.from_tensor_slices(None)\ndata_test = tf.conrib.Dataset.zip((X_test, y_test))\nAt this point, what is the value of data_test.output_types[1] and data_test.output_shapes[1]? It's only implied by code later in the snippet:\niterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\n# ...\ntest_init_op = iterator.make_initializer(data_test)\n\n...and I don't see how the two assert statements would be able to pass. It seems like you want something \"stronger\" than an assert, which can go back a few lines in the code and cause y_test to have the appropriate type and shape.\nDid you have an approach in mind that would make this work?\n\nFor the record though, you don't need to waste memory to tack on a dummy value to the test dataset. For example Dataset.from_tensors(0).repeat(len(X_test_data)) only allocates a single tensor containing 0 and returns shallow copies of it for each element. This allows it to be used with much larger datasets than ones that fit in a NumPy array.", "body": "Hmm, I'm concerned that using `None` for this purpose doesn't give enough information. For example,  let's take the code fragment defining `data_test`:\r\n\r\n```python\r\nX_test = tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\r\ny_test = tf.contrib.data.Dataset.from_tensor_slices(None)\r\ndata_test = tf.conrib.Dataset.zip((X_test, y_test))\r\n```\r\n\r\nAt this point, what is the value of `data_test.output_types[1]` and `data_test.output_shapes[1]`? It's only implied by code later in the snippet:\r\n\r\n```\r\niterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\r\n# ...\r\ntest_init_op = iterator.make_initializer(data_test)\r\n```\r\n\r\n...and I don't see how the two `assert` statements would be able to pass. It seems like you want something \"stronger\" than an `assert`, which can go back a few lines in the code and cause `y_test` to have the appropriate type and shape.\r\n\r\nDid you have an approach in mind that would make this work?\r\n\r\n---\r\n\r\nFor the record though, you don't need to waste memory to tack on a dummy value to the test dataset. For example `Dataset.from_tensors(0).repeat(len(X_test_data))` only allocates a single tensor containing 0 and returns shallow copies of it for each element. This allows it to be used with much larger datasets than ones that fit in a NumPy array."}