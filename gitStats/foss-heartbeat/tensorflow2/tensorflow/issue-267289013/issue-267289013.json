{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13865", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13865/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13865/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13865/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13865", "id": 267289013, "node_id": "MDU6SXNzdWUyNjcyODkwMTM=", "number": 13865, "title": "Feature Request: Support for None values in tf.contrib.data.Dataset", "user": {"login": "nikonikolov", "id": 11044035, "node_id": "MDQ6VXNlcjExMDQ0MDM1", "avatar_url": "https://avatars3.githubusercontent.com/u/11044035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikonikolov", "html_url": "https://github.com/nikonikolov", "followers_url": "https://api.github.com/users/nikonikolov/followers", "following_url": "https://api.github.com/users/nikonikolov/following{/other_user}", "gists_url": "https://api.github.com/users/nikonikolov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikonikolov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikonikolov/subscriptions", "organizations_url": "https://api.github.com/users/nikonikolov/orgs", "repos_url": "https://api.github.com/users/nikonikolov/repos", "events_url": "https://api.github.com/users/nikonikolov/events{/privacy}", "received_events_url": "https://api.github.com/users/nikonikolov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-10-20T19:59:50Z", "updated_at": "2018-01-03T06:42:47Z", "closed_at": "2018-01-03T06:42:47Z", "author_association": "NONE", "body_html": "<p>It would be very handy if the Dataset API supports <code>None</code> types. The idea is to be able to use the same <code>Iterator</code> object for the training and the test datasets. As the training dataset contains labels and the test dataset does not, the only workaround I know at the moment is to use some dummy labels in order to make the two datasets compatible with the same <code>Iterator</code>. This can waste a lot of memory though and is not a clean solution. Instead, maybe it can be possible to create a <code>Dataset</code> from <code>None</code>, that behaves in a way such that its <code>output_types</code> and <code>output_shapes</code> are compatible with any other type and shape, but does not consume so much memory. Here is a quick example:</p>\n<pre><code>X_train = tf.contrib.data.Dataset.from_tensor_slices(X_train_data)\ny_train = tf.contrib.data.Dataset.from_tensor_slices(y_train_data)\ndata_train = tf.conrib.Dataset.zip((X_train, y_train))\n\nX_test = tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\ny_test = tf.contrib.data.Dataset.from_tensor_slices(None)\ndata_test = tf.conrib.Dataset.zip((X_test, y_test))\n\nassert data_train.output_types == data_test.output_types\nassert data_train.output_shapes == data_test.output_shapes\n\niterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\n\ntrain_init_op = iterator.make_initializer(data_train)\ntest_init_op = iterator.make_initializer(data_test)\n\n# Build the graph ...\n\n# Train network\nwith tf.Session() as sess:\n  sess.run(train_init_op)\n  # Train ...\n\n# Run in prediction mode\nwith tf.Session() as sess:\n  sess.run(test_init_op)\n  # Get predictions ...\n\n</code></pre>", "body_text": "It would be very handy if the Dataset API supports None types. The idea is to be able to use the same Iterator object for the training and the test datasets. As the training dataset contains labels and the test dataset does not, the only workaround I know at the moment is to use some dummy labels in order to make the two datasets compatible with the same Iterator. This can waste a lot of memory though and is not a clean solution. Instead, maybe it can be possible to create a Dataset from None, that behaves in a way such that its output_types and output_shapes are compatible with any other type and shape, but does not consume so much memory. Here is a quick example:\nX_train = tf.contrib.data.Dataset.from_tensor_slices(X_train_data)\ny_train = tf.contrib.data.Dataset.from_tensor_slices(y_train_data)\ndata_train = tf.conrib.Dataset.zip((X_train, y_train))\n\nX_test = tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\ny_test = tf.contrib.data.Dataset.from_tensor_slices(None)\ndata_test = tf.conrib.Dataset.zip((X_test, y_test))\n\nassert data_train.output_types == data_test.output_types\nassert data_train.output_shapes == data_test.output_shapes\n\niterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\n\ntrain_init_op = iterator.make_initializer(data_train)\ntest_init_op = iterator.make_initializer(data_test)\n\n# Build the graph ...\n\n# Train network\nwith tf.Session() as sess:\n  sess.run(train_init_op)\n  # Train ...\n\n# Run in prediction mode\nwith tf.Session() as sess:\n  sess.run(test_init_op)\n  # Get predictions ...", "body": "It would be very handy if the Dataset API supports `None` types. The idea is to be able to use the same `Iterator` object for the training and the test datasets. As the training dataset contains labels and the test dataset does not, the only workaround I know at the moment is to use some dummy labels in order to make the two datasets compatible with the same `Iterator`. This can waste a lot of memory though and is not a clean solution. Instead, maybe it can be possible to create a `Dataset` from `None`, that behaves in a way such that its `output_types` and `output_shapes` are compatible with any other type and shape, but does not consume so much memory. Here is a quick example:\r\n\r\n```\r\nX_train = tf.contrib.data.Dataset.from_tensor_slices(X_train_data)\r\ny_train = tf.contrib.data.Dataset.from_tensor_slices(y_train_data)\r\ndata_train = tf.conrib.Dataset.zip((X_train, y_train))\r\n\r\nX_test = tf.contrib.data.Dataset.from_tensor_slices(X_test_data)\r\ny_test = tf.contrib.data.Dataset.from_tensor_slices(None)\r\ndata_test = tf.conrib.Dataset.zip((X_test, y_test))\r\n\r\nassert data_train.output_types == data_test.output_types\r\nassert data_train.output_shapes == data_test.output_shapes\r\n\r\niterator = Iterator.from_structure(data_train.output_types, data_train.output_shapes)\r\n\r\ntrain_init_op = iterator.make_initializer(data_train)\r\ntest_init_op = iterator.make_initializer(data_test)\r\n\r\n# Build the graph ...\r\n\r\n# Train network\r\nwith tf.Session() as sess:\r\n  sess.run(train_init_op)\r\n  # Train ...\r\n\r\n# Run in prediction mode\r\nwith tf.Session() as sess:\r\n  sess.run(test_init_op)\r\n  # Get predictions ...\r\n\r\n```\r\n"}