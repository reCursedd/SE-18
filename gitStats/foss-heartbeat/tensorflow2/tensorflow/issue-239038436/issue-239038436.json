{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11095", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11095/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11095/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11095/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11095", "id": 239038436, "node_id": "MDU6SXNzdWUyMzkwMzg0MzY=", "number": 11095, "title": "Symbol not found with adding new op", "user": {"login": "sampepose", "id": 1855931, "node_id": "MDQ6VXNlcjE4NTU5MzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1855931?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sampepose", "html_url": "https://github.com/sampepose", "followers_url": "https://api.github.com/users/sampepose/followers", "following_url": "https://api.github.com/users/sampepose/following{/other_user}", "gists_url": "https://api.github.com/users/sampepose/gists{/gist_id}", "starred_url": "https://api.github.com/users/sampepose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sampepose/subscriptions", "organizations_url": "https://api.github.com/users/sampepose/orgs", "repos_url": "https://api.github.com/users/sampepose/repos", "events_url": "https://api.github.com/users/sampepose/events{/privacy}", "received_events_url": "https://api.github.com/users/sampepose/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-06-28T02:49:59Z", "updated_at": "2018-05-17T00:02:49Z", "closed_at": "2018-05-17T00:02:49Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Mac Sierra</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>: python test.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Created a custom op, but cannot import it from python. Error at command line:</p>\n<pre><code>tensorflow.python.framework.errors_impl.NotFoundError: dlopen(src/./ops/build/preprocessing.so, 6): Symbol not found: __ZN10tensorflow14AugmentFunctorIN5Eigen9GpuDeviceEEclERKS2_iiiiiiiPKfPfS7_\n  Referenced from: src/./ops/build/preprocessing.so\n  Expected in: flat namespace\n in src/./ops/build/preprocessing.so\n\n</code></pre>\n<h3>Source code / logs</h3>\n<p>Makefile</p>\n<pre><code>TF_INC = `python -c \"import tensorflow; print(tensorflow.sysconfig.get_include())\"`\n\nifndef CUDA_HOME\n    CUDA_HOME := /usr/local/cuda\nendif\n\nCC        = gcc -O2 -pthread\nCXX       = g++\nGPUCC     = nvcc\nCFLAGS    = -std=c++11 -I$(TF_INC) -I\"$(CUDA_HOME)/include\" -DGOOGLE_CUDA=1\nGPUCFLAGS = -c\nLFLAGS    = -pthread -shared -fPIC\nGPULFLAGS = -x cu -Xcompiler -fPIC\nCGPUFLAGS = -L$(CUDA_HOME)/lib -L$(CUDA_HOME)/lib64 -lcudart -undefined dynamic_lookup\n\nOUT_DIR   = src/ops/build\nPREPROCESSING_SRC = \"src/ops/preprocessing/preprocessing.cc\" \"src/ops/preprocessing/kernels/data_augmentation.cc\"\nGPU_SRC_DATA_AUG  \t= \"src/ops/preprocessing/kernels/data_augmentation.cu.cc\"\nGPU_PROD_DATA_AUG \t= $(OUT_DIR)/data_augmentation.o\nPREPROCESSING_PROD\t= $(OUT_DIR)/preprocessing.so\n\npreprocessing:\n\t$(GPUCC) -g $(CFLAGS) $(GPUCFLAGS) $(GPU_SRC_DATA_AUG) $(GPULFLAGS) $(GPUDEF) -o $(GPU_PROD_DATA_AUG)\n\t$(CXX) -g $(CFLAGS)  $(PREPROCESSING_SRC) $(GPU_PROD_DATA_AUG) $(LFLAGS) $(CGPUFLAGS) -o $(PREPROCESSING_PROD)\n\n</code></pre>\n<p>test.py</p>\n<pre><code>import tensorflow as tf\n_preprocessing_ops = tf.load_op_library(\n    tf.resource_loader.get_path_to_datafile(\"./ops/build/preprocessing.so\"))\n</code></pre>\n<p>data_augmentation.h</p>\n<pre><code>#ifndef FLOWNET_DATA_AUGMENTATION_H_\n#define FLOWNET_DATA_AUGMENTATION_H_\n\nnamespace tensorflow {\ntemplate&lt;typename Device&gt;\nstruct AugmentFunctor {\n  void operator()(const Device&amp; d);\n};\n} // namespace tensorflow\n#endif // FLOWNET_DATA_AUGMENTATION_H_\n</code></pre>\n<p>data_augmentation.cc</p>\n<pre><code>#define EIGEN_USE_THREADS\n\n#include \"data_augmentation.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nnamespace tensorflow {\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice        GPUDevice;\n\ntemplate&lt;&gt;\nstruct AugmentFunctor&lt;CPUDevice&gt;{\n  void operator()(const CPUDevice&amp; d) {\n    // CPU implementation here\n  }\n};\n\ntemplate&lt;typename Device&gt;\nclass DataAugmentation : public OpKernel {\n  public:\n    explicit DataAugmentation(OpKernelConstruction *ctx) : OpKernel(ctx) {}\n\n    void Compute(OpKernelContext *ctx) override {\n      // Perform augmentation either on CPU or GPU\n      AugmentFunctor&lt;Device&gt;()(ctx-&gt;eigen_device&lt;Device&gt;());\n    }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\n                        .Device(DEVICE_CPU),\n                        DataAugmentation&lt;CPUDevice&gt;)\n\n#if GOOGLE_CUDA\n\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\n                        .Device(DEVICE_GPU),\n                        DataAugmentation&lt;GPUDevice&gt;)\n#endif // GOOGLE_CUDA\n} // namespace tensorflow\n</code></pre>\n<p>data_augmentation.cu.cc</p>\n<pre><code>#if GOOGLE_CUDA\n\n#define EIGEN_USE_GPU\n\n#include \"augmentation_base.h\"\n#include \"data_augmentation.h\"\n#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n\nnamespace tensorflow {\n__global__ void SpatialAugmentation() {\n   // CUDA kernel code goes here\n}\n\ntemplate&lt;&gt;\nstruct AugmentFunctor&lt;GPUDevice&gt;{\n  void operator()(const GPUDevice&amp; d) {\n    // GPU implementation goes here\n    CudaLaunchConfig config = GetCudaLaunchConfig(10, d);\n    SpatialAugmentation&lt;&lt;&lt;config.block_count, config.thread_per_block, 0, d.stream()&gt;&gt;&gt;(config.virtual_thread_count);\n  }\n};\n\ntypedef Eigen::GpuDevice GPUDevice;\ntemplate struct AugmentFunctor&lt;GPUDevice&gt;;\n} // namespace tensorflow\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac Sierra\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.1.0\nBazel version (if compiling from source):\nCUDA/cuDNN version: 8.0\nGPU model and memory:\nExact command to reproduce: python test.py\n\nDescribe the problem\nCreated a custom op, but cannot import it from python. Error at command line:\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(src/./ops/build/preprocessing.so, 6): Symbol not found: __ZN10tensorflow14AugmentFunctorIN5Eigen9GpuDeviceEEclERKS2_iiiiiiiPKfPfS7_\n  Referenced from: src/./ops/build/preprocessing.so\n  Expected in: flat namespace\n in src/./ops/build/preprocessing.so\n\n\nSource code / logs\nMakefile\nTF_INC = `python -c \"import tensorflow; print(tensorflow.sysconfig.get_include())\"`\n\nifndef CUDA_HOME\n    CUDA_HOME := /usr/local/cuda\nendif\n\nCC        = gcc -O2 -pthread\nCXX       = g++\nGPUCC     = nvcc\nCFLAGS    = -std=c++11 -I$(TF_INC) -I\"$(CUDA_HOME)/include\" -DGOOGLE_CUDA=1\nGPUCFLAGS = -c\nLFLAGS    = -pthread -shared -fPIC\nGPULFLAGS = -x cu -Xcompiler -fPIC\nCGPUFLAGS = -L$(CUDA_HOME)/lib -L$(CUDA_HOME)/lib64 -lcudart -undefined dynamic_lookup\n\nOUT_DIR   = src/ops/build\nPREPROCESSING_SRC = \"src/ops/preprocessing/preprocessing.cc\" \"src/ops/preprocessing/kernels/data_augmentation.cc\"\nGPU_SRC_DATA_AUG  \t= \"src/ops/preprocessing/kernels/data_augmentation.cu.cc\"\nGPU_PROD_DATA_AUG \t= $(OUT_DIR)/data_augmentation.o\nPREPROCESSING_PROD\t= $(OUT_DIR)/preprocessing.so\n\npreprocessing:\n\t$(GPUCC) -g $(CFLAGS) $(GPUCFLAGS) $(GPU_SRC_DATA_AUG) $(GPULFLAGS) $(GPUDEF) -o $(GPU_PROD_DATA_AUG)\n\t$(CXX) -g $(CFLAGS)  $(PREPROCESSING_SRC) $(GPU_PROD_DATA_AUG) $(LFLAGS) $(CGPUFLAGS) -o $(PREPROCESSING_PROD)\n\n\ntest.py\nimport tensorflow as tf\n_preprocessing_ops = tf.load_op_library(\n    tf.resource_loader.get_path_to_datafile(\"./ops/build/preprocessing.so\"))\n\ndata_augmentation.h\n#ifndef FLOWNET_DATA_AUGMENTATION_H_\n#define FLOWNET_DATA_AUGMENTATION_H_\n\nnamespace tensorflow {\ntemplate<typename Device>\nstruct AugmentFunctor {\n  void operator()(const Device& d);\n};\n} // namespace tensorflow\n#endif // FLOWNET_DATA_AUGMENTATION_H_\n\ndata_augmentation.cc\n#define EIGEN_USE_THREADS\n\n#include \"data_augmentation.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nnamespace tensorflow {\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice        GPUDevice;\n\ntemplate<>\nstruct AugmentFunctor<CPUDevice>{\n  void operator()(const CPUDevice& d) {\n    // CPU implementation here\n  }\n};\n\ntemplate<typename Device>\nclass DataAugmentation : public OpKernel {\n  public:\n    explicit DataAugmentation(OpKernelConstruction *ctx) : OpKernel(ctx) {}\n\n    void Compute(OpKernelContext *ctx) override {\n      // Perform augmentation either on CPU or GPU\n      AugmentFunctor<Device>()(ctx->eigen_device<Device>());\n    }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\n                        .Device(DEVICE_CPU),\n                        DataAugmentation<CPUDevice>)\n\n#if GOOGLE_CUDA\n\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\n                        .Device(DEVICE_GPU),\n                        DataAugmentation<GPUDevice>)\n#endif // GOOGLE_CUDA\n} // namespace tensorflow\n\ndata_augmentation.cu.cc\n#if GOOGLE_CUDA\n\n#define EIGEN_USE_GPU\n\n#include \"augmentation_base.h\"\n#include \"data_augmentation.h\"\n#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n\nnamespace tensorflow {\n__global__ void SpatialAugmentation() {\n   // CUDA kernel code goes here\n}\n\ntemplate<>\nstruct AugmentFunctor<GPUDevice>{\n  void operator()(const GPUDevice& d) {\n    // GPU implementation goes here\n    CudaLaunchConfig config = GetCudaLaunchConfig(10, d);\n    SpatialAugmentation<<<config.block_count, config.thread_per_block, 0, d.stream()>>>(config.virtual_thread_count);\n  }\n};\n\ntypedef Eigen::GpuDevice GPUDevice;\ntemplate struct AugmentFunctor<GPUDevice>;\n} // namespace tensorflow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac Sierra\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: python test.py\r\n\r\n### Describe the problem\r\nCreated a custom op, but cannot import it from python. Error at command line:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(src/./ops/build/preprocessing.so, 6): Symbol not found: __ZN10tensorflow14AugmentFunctorIN5Eigen9GpuDeviceEEclERKS2_iiiiiiiPKfPfS7_\r\n  Referenced from: src/./ops/build/preprocessing.so\r\n  Expected in: flat namespace\r\n in src/./ops/build/preprocessing.so\r\n\r\n```\r\n\r\n### Source code / logs\r\nMakefile\r\n```\r\nTF_INC = `python -c \"import tensorflow; print(tensorflow.sysconfig.get_include())\"`\r\n\r\nifndef CUDA_HOME\r\n    CUDA_HOME := /usr/local/cuda\r\nendif\r\n\r\nCC        = gcc -O2 -pthread\r\nCXX       = g++\r\nGPUCC     = nvcc\r\nCFLAGS    = -std=c++11 -I$(TF_INC) -I\"$(CUDA_HOME)/include\" -DGOOGLE_CUDA=1\r\nGPUCFLAGS = -c\r\nLFLAGS    = -pthread -shared -fPIC\r\nGPULFLAGS = -x cu -Xcompiler -fPIC\r\nCGPUFLAGS = -L$(CUDA_HOME)/lib -L$(CUDA_HOME)/lib64 -lcudart -undefined dynamic_lookup\r\n\r\nOUT_DIR   = src/ops/build\r\nPREPROCESSING_SRC = \"src/ops/preprocessing/preprocessing.cc\" \"src/ops/preprocessing/kernels/data_augmentation.cc\"\r\nGPU_SRC_DATA_AUG  \t= \"src/ops/preprocessing/kernels/data_augmentation.cu.cc\"\r\nGPU_PROD_DATA_AUG \t= $(OUT_DIR)/data_augmentation.o\r\nPREPROCESSING_PROD\t= $(OUT_DIR)/preprocessing.so\r\n\r\npreprocessing:\r\n\t$(GPUCC) -g $(CFLAGS) $(GPUCFLAGS) $(GPU_SRC_DATA_AUG) $(GPULFLAGS) $(GPUDEF) -o $(GPU_PROD_DATA_AUG)\r\n\t$(CXX) -g $(CFLAGS)  $(PREPROCESSING_SRC) $(GPU_PROD_DATA_AUG) $(LFLAGS) $(CGPUFLAGS) -o $(PREPROCESSING_PROD)\r\n\r\n```\r\n\r\ntest.py\r\n```\r\nimport tensorflow as tf\r\n_preprocessing_ops = tf.load_op_library(\r\n    tf.resource_loader.get_path_to_datafile(\"./ops/build/preprocessing.so\"))\r\n```\r\n\r\ndata_augmentation.h\r\n```\r\n#ifndef FLOWNET_DATA_AUGMENTATION_H_\r\n#define FLOWNET_DATA_AUGMENTATION_H_\r\n\r\nnamespace tensorflow {\r\ntemplate<typename Device>\r\nstruct AugmentFunctor {\r\n  void operator()(const Device& d);\r\n};\r\n} // namespace tensorflow\r\n#endif // FLOWNET_DATA_AUGMENTATION_H_\r\n```\r\n\r\ndata_augmentation.cc\r\n```\r\n#define EIGEN_USE_THREADS\r\n\r\n#include \"data_augmentation.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nnamespace tensorflow {\r\ntypedef Eigen::ThreadPoolDevice CPUDevice;\r\ntypedef Eigen::GpuDevice        GPUDevice;\r\n\r\ntemplate<>\r\nstruct AugmentFunctor<CPUDevice>{\r\n  void operator()(const CPUDevice& d) {\r\n    // CPU implementation here\r\n  }\r\n};\r\n\r\ntemplate<typename Device>\r\nclass DataAugmentation : public OpKernel {\r\n  public:\r\n    explicit DataAugmentation(OpKernelConstruction *ctx) : OpKernel(ctx) {}\r\n\r\n    void Compute(OpKernelContext *ctx) override {\r\n      // Perform augmentation either on CPU or GPU\r\n      AugmentFunctor<Device>()(ctx->eigen_device<Device>());\r\n    }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\r\n                        .Device(DEVICE_CPU),\r\n                        DataAugmentation<CPUDevice>)\r\n\r\n#if GOOGLE_CUDA\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"DataAugmentation\")\r\n                        .Device(DEVICE_GPU),\r\n                        DataAugmentation<GPUDevice>)\r\n#endif // GOOGLE_CUDA\r\n} // namespace tensorflow\r\n```\r\ndata_augmentation.cu.cc\r\n```\r\n#if GOOGLE_CUDA\r\n\r\n#define EIGEN_USE_GPU\r\n\r\n#include \"augmentation_base.h\"\r\n#include \"data_augmentation.h\"\r\n#include \"tensorflow/core/util/cuda_kernel_helper.h\"\r\n\r\nnamespace tensorflow {\r\n__global__ void SpatialAugmentation() {\r\n   // CUDA kernel code goes here\r\n}\r\n\r\ntemplate<>\r\nstruct AugmentFunctor<GPUDevice>{\r\n  void operator()(const GPUDevice& d) {\r\n    // GPU implementation goes here\r\n    CudaLaunchConfig config = GetCudaLaunchConfig(10, d);\r\n    SpatialAugmentation<<<config.block_count, config.thread_per_block, 0, d.stream()>>>(config.virtual_thread_count);\r\n  }\r\n};\r\n\r\ntypedef Eigen::GpuDevice GPUDevice;\r\ntemplate struct AugmentFunctor<GPUDevice>;\r\n} // namespace tensorflow\r\n```"}