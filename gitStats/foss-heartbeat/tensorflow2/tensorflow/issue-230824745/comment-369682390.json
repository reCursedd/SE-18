{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/369682390", "html_url": "https://github.com/tensorflow/tensorflow/issues/10145#issuecomment-369682390", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10145", "id": 369682390, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTY4MjM5MA==", "user": {"login": "lw394", "id": 15891975, "node_id": "MDQ6VXNlcjE1ODkxOTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/15891975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lw394", "html_url": "https://github.com/lw394", "followers_url": "https://api.github.com/users/lw394/followers", "following_url": "https://api.github.com/users/lw394/following{/other_user}", "gists_url": "https://api.github.com/users/lw394/gists{/gist_id}", "starred_url": "https://api.github.com/users/lw394/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lw394/subscriptions", "organizations_url": "https://api.github.com/users/lw394/orgs", "repos_url": "https://api.github.com/users/lw394/repos", "events_url": "https://api.github.com/users/lw394/events{/privacy}", "received_events_url": "https://api.github.com/users/lw394/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-01T18:18:56Z", "updated_at": "2018-03-01T18:18:56Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11156808\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jppgks\">@jppgks</a> ,  I've used this testing for a 4 Titan X machine.  You can set --distributed=False to compare single GPU, non distributed performance.  With a smaller network, i.e. --hidden-units=128, I see some improvement with 4 GPUs vs 1.  With --hidden_units=2048,  4 gpus distributed is less than half the speed of just using one.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division, absolute_import, print_function, unicode_literals\n\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">from</span> multiprocessing <span class=\"pl-k\">import</span> Process\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib <span class=\"pl-k\">import</span> layers\n<span class=\"pl-k\">from</span> tensorflow <span class=\"pl-k\">import</span> flags\n\ntf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\n\nflags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden_units<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">256</span>,\n                   <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>number hidden units<span class=\"pl-pds\">\"</span></span>)\nflags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">128</span>,\n                   <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch size<span class=\"pl-pds\">\"</span></span>)\nflags.DEFINE_bool(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>distributed<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">True</span>,\n                   <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>set to False for not distributed<span class=\"pl-pds\">\"</span></span>)\n\nflags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output_dir<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>temp_dir<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>path to output_dir<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> tf.flags.<span class=\"pl-c1\">FLAGS</span>\n\n<span class=\"pl-c1\">OUTPUT_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">256</span>\n<span class=\"pl-c1\">INPUT_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">256</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>,<span class=\"pl-smi\">labels</span>):\n\n    outputs <span class=\"pl-k\">=</span> tf.layers.dense(features,<span class=\"pl-c1\">FLAGS</span>.hidden_units)\n    outputs <span class=\"pl-k\">=</span> tf.layers.dense(outputs,<span class=\"pl-c1\">FLAGS</span>.hidden_units)\n    outputs <span class=\"pl-k\">=</span> tf.layers.dense(outputs,<span class=\"pl-c1\">FLAGS</span>.hidden_units)\n    outputs <span class=\"pl-k\">=</span> tf.layers.dense(outputs,<span class=\"pl-c1\">FLAGS</span>.hidden_units)\n    outputs <span class=\"pl-k\">=</span> tf.layers.dense(outputs,<span class=\"pl-c1\">OUTPUT_DIM</span>)\n\n    <span class=\"pl-k\">return</span> outputs\n\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">dumb_input_fn</span>():\n\n    x <span class=\"pl-k\">=</span> tf.random_normal([<span class=\"pl-c1\">FLAGS</span>.batch_size,<span class=\"pl-c1\">INPUT_DIM</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    y <span class=\"pl-k\">=</span> tf.random_normal([<span class=\"pl-c1\">FLAGS</span>.batch_size,<span class=\"pl-c1\">OUTPUT_DIM</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n    <span class=\"pl-k\">return</span> [x,y]\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>(<span class=\"pl-smi\">output_dir</span>, <span class=\"pl-smi\">dist_info</span><span class=\"pl-k\">=</span>{}):\n    \n    cluster <span class=\"pl-k\">=</span> dist_info[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cluster<span class=\"pl-pds\">'</span></span>]\n    job_name <span class=\"pl-k\">=</span> dist_info[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>job_name<span class=\"pl-pds\">'</span></span>]\n    task_index <span class=\"pl-k\">=</span> dist_info[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>task_index<span class=\"pl-pds\">'</span></span>]\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>:<span class=\"pl-c1\">%s</span><span class=\"pl-pds\">'</span></span><span class=\"pl-k\">%</span>(job_name,task_index))\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create and start a server for the local task.</span>\n    server <span class=\"pl-k\">=</span> tf.train.Server(cluster,\n                           <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span>job_name,\n                           <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span>task_index)\n\n    <span class=\"pl-k\">if</span> job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>:\n        server.join()\n    <span class=\"pl-k\">elif</span> job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>:\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n            x,y <span class=\"pl-k\">=</span> dumb_input_fn()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Assigns ops to the local worker by default.</span>\n        <span class=\"pl-k\">with</span> tf.device(tf.train.replica_device_setter(\n            <span class=\"pl-v\">worker_device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> task_index,\n            <span class=\"pl-v\">cluster</span><span class=\"pl-k\">=</span>cluster)):\n    \n            outputs <span class=\"pl-k\">=</span> model_fn(x,y)\n            loss <span class=\"pl-k\">=</span> tf.losses.mean_squared_error(outputs, y)\n     \n            train_op <span class=\"pl-k\">=</span> tf.contrib.layers.optimize_loss(loss, <span class=\"pl-c1\">None</span>, <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Adam<span class=\"pl-pds\">'</span></span>,<span class=\"pl-v\">learning_rate</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1e-3</span>)\n\n\n        global_step <span class=\"pl-k\">=</span> tf.train.get_or_create_global_step()\n\t<span class=\"pl-c\"><span class=\"pl-c\">#</span> session run hooks</span>\n        hooks<span class=\"pl-k\">=</span>[tf.train.StopAtStepHook(<span class=\"pl-v\">last_step</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10000</span>)]\n\n        config <span class=\"pl-k\">=</span> tf.ConfigProto()\n        config.gpu_options.allow_growth <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n        <span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span>server.target,\n                                               <span class=\"pl-v\">is_chief</span><span class=\"pl-k\">=</span>(task_index <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>),\n                                               <span class=\"pl-v\">checkpoint_dir</span><span class=\"pl-k\">=</span>output_dir,\n                                               <span class=\"pl-v\">hooks</span><span class=\"pl-k\">=</span>hooks,\n                                               <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> mon_sess:\n            step <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n            test_interval <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n            start_time <span class=\"pl-k\">=</span> time.time()\n            <span class=\"pl-k\">while</span> <span class=\"pl-k\">not</span> mon_sess.should_stop():\n                \n                \n                _ <span class=\"pl-k\">=</span> mon_sess.run(train_op)\n\n                <span class=\"pl-k\">if</span> step <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">and</span>  step <span class=\"pl-k\">%</span> test_interval <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n                    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Worker:<span class=\"pl-pds\">'</span></span>,task_index,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Step:<span class=\"pl-pds\">\"</span></span>, step,test_interval<span class=\"pl-k\">/</span>(time.time()<span class=\"pl-k\">-</span>start_time),<span class=\"pl-s\"><span class=\"pl-pds\">'</span>steps/sec<span class=\"pl-pds\">'</span></span>)\n                    start_time <span class=\"pl-k\">=</span> time.time()\n\n                step<span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">start_task</span>(<span class=\"pl-smi\">task_info</span>):\n    job_name <span class=\"pl-k\">=</span> task_info[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>job_name<span class=\"pl-pds\">'</span></span>]\n    task_index <span class=\"pl-k\">=</span> task_info[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>task_index<span class=\"pl-pds\">'</span></span>]\n    <span class=\"pl-k\">if</span> job_name<span class=\"pl-k\">==</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> allow each worker to see only 1 of the 4 GPUS</span>\n        os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">\"</span></span>]<span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>(task_index)\n        \n    train(<span class=\"pl-c1\">FLAGS</span>.output_dir, task_info)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">argv</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-k\">if</span> tf.gfile.Exists(<span class=\"pl-c1\">FLAGS</span>.output_dir):\n        tf.gfile.DeleteRecursively(<span class=\"pl-c1\">FLAGS</span>.output_dir)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.distributed:\n        tasks <span class=\"pl-k\">=</span> [\n                [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ps<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">0</span>],\n                [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">0</span>],\n                [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">1</span>],\n                [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">2</span>],\n                [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">3</span>]\n                ]\n        cluster_spec <span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2227<span class=\"pl-pds\">\"</span></span>],\n                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: [\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2223<span class=\"pl-pds\">\"</span></span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2224<span class=\"pl-pds\">\"</span></span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2225<span class=\"pl-pds\">\"</span></span>,\n                            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2226<span class=\"pl-pds\">\"</span></span>\n                            ]\n                        }\n    <span class=\"pl-k\">else</span>:\n        tasks <span class=\"pl-k\">=</span> [[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>,<span class=\"pl-c1\">0</span>]]\n        cluster_spec <span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2223<span class=\"pl-pds\">\"</span></span>]}\n\n    cluster <span class=\"pl-k\">=</span> tf.train.ClusterSpec(cluster_spec)\n    \n    processes <span class=\"pl-k\">=</span> []\n    \n    <span class=\"pl-k\">for</span> t <span class=\"pl-k\">in</span> tasks:\n        task_info <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cluster<span class=\"pl-pds\">'</span></span>:cluster,\n                  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>job_name<span class=\"pl-pds\">'</span></span>:t[<span class=\"pl-c1\">0</span>],\n                  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>task_index<span class=\"pl-pds\">'</span></span>:t[<span class=\"pl-c1\">1</span>]}\n\n        p <span class=\"pl-k\">=</span> Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>start_task, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(task_info,))\n        p.start()\n        processes.append(p)\n    <span class=\"pl-k\">try</span>:\n        <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> processes:\n            p.join()\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">KeyboardInterrupt</span>:\n        <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> processes:\n            p.terminate()\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.app.run()\n</pre></div>", "body_text": "@jppgks ,  I've used this testing for a 4 Titan X machine.  You can set --distributed=False to compare single GPU, non distributed performance.  With a smaller network, i.e. --hidden-units=128, I see some improvement with 4 GPUs vs 1.  With --hidden_units=2048,  4 gpus distributed is less than half the speed of just using one.\nfrom __future__ import division, absolute_import, print_function, unicode_literals\n\nimport os\nimport time\nfrom multiprocessing import Process\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nfrom tensorflow import flags\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\nflags.DEFINE_integer(\"hidden_units\", 256,\n                   \"number hidden units\")\nflags.DEFINE_integer(\"batch_size\", 128,\n                   \"batch size\")\nflags.DEFINE_bool(\"distributed\", True,\n                   \"set to False for not distributed\")\n\nflags.DEFINE_string(\"output_dir\",\"temp_dir\",'path to output_dir')\n\nFLAGS = tf.flags.FLAGS\n\nOUTPUT_DIM = 256\nINPUT_DIM = 256\n\ndef model_fn(features,labels):\n\n    outputs = tf.layers.dense(features,FLAGS.hidden_units)\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\n    outputs = tf.layers.dense(outputs,OUTPUT_DIM)\n\n    return outputs\n\n\n\ndef dumb_input_fn():\n\n    x = tf.random_normal([FLAGS.batch_size,INPUT_DIM], dtype=tf.float32)\n    y = tf.random_normal([FLAGS.batch_size,OUTPUT_DIM], dtype=tf.float32)\n\n    return [x,y]\n\n\ndef train(output_dir, dist_info={}):\n    \n    cluster = dist_info['cluster']\n    job_name = dist_info['job_name']\n    task_index = dist_info['task_index']\n\n    print('%s:%s'%(job_name,task_index))\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster,\n                           job_name=job_name,\n                           task_index=task_index)\n\n    if job_name == \"ps\":\n        server.join()\n    elif job_name == \"worker\":\n        with tf.device('/cpu:0'):\n            x,y = dumb_input_fn()\n        # Assigns ops to the local worker by default.\n        with tf.device(tf.train.replica_device_setter(\n            worker_device=\"/job:worker/task:%d\" % task_index,\n            cluster=cluster)):\n    \n            outputs = model_fn(x,y)\n            loss = tf.losses.mean_squared_error(outputs, y)\n     \n            train_op = tf.contrib.layers.optimize_loss(loss, None, optimizer='Adam',learning_rate = 1e-3)\n\n\n        global_step = tf.train.get_or_create_global_step()\n\t# session run hooks\n        hooks=[tf.train.StopAtStepHook(last_step=10000)]\n\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=(task_index == 0),\n                                               checkpoint_dir=output_dir,\n                                               hooks=hooks,\n                                               config=config) as mon_sess:\n            step = 0\n            test_interval = 100\n            start_time = time.time()\n            while not mon_sess.should_stop():\n                \n                \n                _ = mon_sess.run(train_op)\n\n                if step > 0 and  step % test_interval == 0:\n                    print('Worker:',task_index,\"Step:\", step,test_interval/(time.time()-start_time),'steps/sec')\n                    start_time = time.time()\n\n                step+=1\n\ndef start_task(task_info):\n    job_name = task_info['job_name']\n    task_index = task_info['task_index']\n    if job_name=='worker':\n        # allow each worker to see only 1 of the 4 GPUS\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(task_index)\n        \n    train(FLAGS.output_dir, task_info)\n\ndef main(argv=None):\n    if tf.gfile.Exists(FLAGS.output_dir):\n        tf.gfile.DeleteRecursively(FLAGS.output_dir)\n\n    if FLAGS.distributed:\n        tasks = [\n                ['ps',0],\n                ['worker',0],\n                ['worker',1],\n                ['worker',2],\n                ['worker',3]\n                ]\n        cluster_spec ={\"ps\": [\"localhost:2227\"],\n                        \"worker\": [\n                            \"localhost:2223\",\n                            \"localhost:2224\",\n                            \"localhost:2225\",\n                            \"localhost:2226\"\n                            ]\n                        }\n    else:\n        tasks = [['worker',0]]\n        cluster_spec ={\"worker\": [\"localhost:2223\"]}\n\n    cluster = tf.train.ClusterSpec(cluster_spec)\n    \n    processes = []\n    \n    for t in tasks:\n        task_info = {'cluster':cluster,\n                  'job_name':t[0],\n                  'task_index':t[1]}\n\n        p = Process(target=start_task, args=(task_info,))\n        p.start()\n        processes.append(p)\n    try:\n        for p in processes:\n            p.join()\n    except KeyboardInterrupt:\n        for p in processes:\n            p.terminate()\n\nif __name__ == '__main__':\n    tf.app.run()", "body": "@jppgks ,  I've used this testing for a 4 Titan X machine.  You can set --distributed=False to compare single GPU, non distributed performance.  With a smaller network, i.e. --hidden-units=128, I see some improvement with 4 GPUs vs 1.  With --hidden_units=2048,  4 gpus distributed is less than half the speed of just using one.  \r\n  \r\n```python\r\nfrom __future__ import division, absolute_import, print_function, unicode_literals\r\n\r\nimport os\r\nimport time\r\nfrom multiprocessing import Process\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import layers\r\nfrom tensorflow import flags\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nflags.DEFINE_integer(\"hidden_units\", 256,\r\n                   \"number hidden units\")\r\nflags.DEFINE_integer(\"batch_size\", 128,\r\n                   \"batch size\")\r\nflags.DEFINE_bool(\"distributed\", True,\r\n                   \"set to False for not distributed\")\r\n\r\nflags.DEFINE_string(\"output_dir\",\"temp_dir\",'path to output_dir')\r\n\r\nFLAGS = tf.flags.FLAGS\r\n\r\nOUTPUT_DIM = 256\r\nINPUT_DIM = 256\r\n\r\ndef model_fn(features,labels):\r\n\r\n    outputs = tf.layers.dense(features,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,OUTPUT_DIM)\r\n\r\n    return outputs\r\n\r\n\r\n\r\ndef dumb_input_fn():\r\n\r\n    x = tf.random_normal([FLAGS.batch_size,INPUT_DIM], dtype=tf.float32)\r\n    y = tf.random_normal([FLAGS.batch_size,OUTPUT_DIM], dtype=tf.float32)\r\n\r\n    return [x,y]\r\n\r\n\r\ndef train(output_dir, dist_info={}):\r\n    \r\n    cluster = dist_info['cluster']\r\n    job_name = dist_info['job_name']\r\n    task_index = dist_info['task_index']\r\n\r\n    print('%s:%s'%(job_name,task_index))\r\n\r\n    # Create and start a server for the local task.\r\n    server = tf.train.Server(cluster,\r\n                           job_name=job_name,\r\n                           task_index=task_index)\r\n\r\n    if job_name == \"ps\":\r\n        server.join()\r\n    elif job_name == \"worker\":\r\n        with tf.device('/cpu:0'):\r\n            x,y = dumb_input_fn()\r\n        # Assigns ops to the local worker by default.\r\n        with tf.device(tf.train.replica_device_setter(\r\n            worker_device=\"/job:worker/task:%d\" % task_index,\r\n            cluster=cluster)):\r\n    \r\n            outputs = model_fn(x,y)\r\n            loss = tf.losses.mean_squared_error(outputs, y)\r\n     \r\n            train_op = tf.contrib.layers.optimize_loss(loss, None, optimizer='Adam',learning_rate = 1e-3)\r\n\r\n\r\n        global_step = tf.train.get_or_create_global_step()\r\n\t# session run hooks\r\n        hooks=[tf.train.StopAtStepHook(last_step=10000)]\r\n\r\n        config = tf.ConfigProto()\r\n        config.gpu_options.allow_growth = True\r\n        with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=(task_index == 0),\r\n                                               checkpoint_dir=output_dir,\r\n                                               hooks=hooks,\r\n                                               config=config) as mon_sess:\r\n            step = 0\r\n            test_interval = 100\r\n            start_time = time.time()\r\n            while not mon_sess.should_stop():\r\n                \r\n                \r\n                _ = mon_sess.run(train_op)\r\n\r\n                if step > 0 and  step % test_interval == 0:\r\n                    print('Worker:',task_index,\"Step:\", step,test_interval/(time.time()-start_time),'steps/sec')\r\n                    start_time = time.time()\r\n\r\n                step+=1\r\n\r\ndef start_task(task_info):\r\n    job_name = task_info['job_name']\r\n    task_index = task_info['task_index']\r\n    if job_name=='worker':\r\n        # allow each worker to see only 1 of the 4 GPUS\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(task_index)\r\n        \r\n    train(FLAGS.output_dir, task_info)\r\n\r\ndef main(argv=None):\r\n    if tf.gfile.Exists(FLAGS.output_dir):\r\n        tf.gfile.DeleteRecursively(FLAGS.output_dir)\r\n\r\n    if FLAGS.distributed:\r\n        tasks = [\r\n                ['ps',0],\r\n                ['worker',0],\r\n                ['worker',1],\r\n                ['worker',2],\r\n                ['worker',3]\r\n                ]\r\n        cluster_spec ={\"ps\": [\"localhost:2227\"],\r\n                        \"worker\": [\r\n                            \"localhost:2223\",\r\n                            \"localhost:2224\",\r\n                            \"localhost:2225\",\r\n                            \"localhost:2226\"\r\n                            ]\r\n                        }\r\n    else:\r\n        tasks = [['worker',0]]\r\n        cluster_spec ={\"worker\": [\"localhost:2223\"]}\r\n\r\n    cluster = tf.train.ClusterSpec(cluster_spec)\r\n    \r\n    processes = []\r\n    \r\n    for t in tasks:\r\n        task_info = {'cluster':cluster,\r\n                  'job_name':t[0],\r\n                  'task_index':t[1]}\r\n\r\n        p = Process(target=start_task, args=(task_info,))\r\n        p.start()\r\n        processes.append(p)\r\n    try:\r\n        for p in processes:\r\n            p.join()\r\n    except KeyboardInterrupt:\r\n        for p in processes:\r\n            p.terminate()\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n\r\n```"}