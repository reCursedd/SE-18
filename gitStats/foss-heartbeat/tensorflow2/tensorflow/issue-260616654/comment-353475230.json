{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/353475230", "html_url": "https://github.com/tensorflow/tensorflow/pull/13312#issuecomment-353475230", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13312", "id": 353475230, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzQ3NTIzMA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-21T22:36:17Z", "updated_at": "2017-12-21T22:36:17Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">tf.where(tf.ones_like(beam_ids) &gt; -1)[:,:-1]\n\n\nthat line looks relatively expensive.\n\n\ni guess you can do tf.where(beam_ids &gt; -1)\n\ntruthfully i like range and tile better because it's a much faster\nkernel than tf.where (tf.where is *really* expensive, especially on\ngpu)</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Dec 21, 2017 at 2:29 PM, Steven Ding ***@***.***&gt; wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260616654\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13312\" href=\"https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158392952\">#13312 (comment)</a>&gt;\n :\n\n &gt; +      math_ops.cast(mask, dtypes.bool), x=sorted_beam_ids, y=beam_ids)\n +\n +  # Gather from each tensor in t according to sorted_beam_ids.\n +  def _collect(collector, i):\n +    gathered = _tensor_gather_helper(\n +        gather_indices=sorted_beam_ids[i],\n +        gather_from=t.read(i),\n +        batch_size=batch_size,\n +        range_size=beam_width,\n +        gather_shape=[batch_size * beam_width, -1])\n +    return collector.write(i, gathered), i + 1\n +\n +  collected = tensor_array_ops.TensorArray(\n +      t.dtype, size=t.size(), dynamic_size=False)\n +  collected, _ = control_flow_ops.while_loop(\n +      lambda _, i: i &lt; t.size(),\n\n if i remember the shapes here correctly:\n\n time = 3\n batch = 4\n beam = 5\n depth = 6\n # [time, batch, beam, depth]\n a = tf.constant(np.arange(time * batch * beam * depth), shape=[time, batch, beam, depth], dtype=tf.int64)\n # [time, batch, beam] (reverse beam as example)\n beam_ids = tf.constant(np.flip(np.arange(beam), 0), shape=[1,1,beam], dtype=tf.int64)\n beam_ids = tf.tile(beam_ids, [3,4,1])\n # we need [time, batch, beam, 3]# assume beam_ids &gt; -1\n t_bt_ind = tf.where(tf.ones_like(beam_ids) &gt; -1)[:,:-1]\n t_bt_ind = tf.reshape(t_bt_ind, [time,batch,beam,-1])\n t_bt_be_ind = tf.concat([t_bt_ind, tf.expand_dims(beam_ids, -1)], -1)\n # gather\n tf.gather_nd(a, t_bt_be_ind)\n\n Please double-check. Another way is to combine range and tile; but it is\n hardly readable. We use this method a lot in our code (tf.where(constant)),\n it looks okay. ebrevdo may better comment on this. Thanks!\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260616654\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13312\" href=\"https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158392952\">#13312 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtimwHa50-96kt9b0v8H5obAAtzqlE2ks5tCtvAgaJpZM4PkNmd\">https://github.com/notifications/unsubscribe-auth/ABtimwHa50-96kt9b0v8H5obAAtzqlE2ks5tCtvAgaJpZM4PkNmd</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "tf.where(tf.ones_like(beam_ids) > -1)[:,:-1]\n\n\nthat line looks relatively expensive.\n\n\ni guess you can do tf.where(beam_ids > -1)\n\ntruthfully i like range and tile better because it's a much faster\nkernel than tf.where (tf.where is *really* expensive, especially on\ngpu)\n\u2026\nOn Thu, Dec 21, 2017 at 2:29 PM, Steven Ding ***@***.***> wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n <#13312 (comment)>\n :\n\n > +      math_ops.cast(mask, dtypes.bool), x=sorted_beam_ids, y=beam_ids)\n +\n +  # Gather from each tensor in t according to sorted_beam_ids.\n +  def _collect(collector, i):\n +    gathered = _tensor_gather_helper(\n +        gather_indices=sorted_beam_ids[i],\n +        gather_from=t.read(i),\n +        batch_size=batch_size,\n +        range_size=beam_width,\n +        gather_shape=[batch_size * beam_width, -1])\n +    return collector.write(i, gathered), i + 1\n +\n +  collected = tensor_array_ops.TensorArray(\n +      t.dtype, size=t.size(), dynamic_size=False)\n +  collected, _ = control_flow_ops.while_loop(\n +      lambda _, i: i < t.size(),\n\n if i remember the shapes here correctly:\n\n time = 3\n batch = 4\n beam = 5\n depth = 6\n # [time, batch, beam, depth]\n a = tf.constant(np.arange(time * batch * beam * depth), shape=[time, batch, beam, depth], dtype=tf.int64)\n # [time, batch, beam] (reverse beam as example)\n beam_ids = tf.constant(np.flip(np.arange(beam), 0), shape=[1,1,beam], dtype=tf.int64)\n beam_ids = tf.tile(beam_ids, [3,4,1])\n # we need [time, batch, beam, 3]# assume beam_ids > -1\n t_bt_ind = tf.where(tf.ones_like(beam_ids) > -1)[:,:-1]\n t_bt_ind = tf.reshape(t_bt_ind, [time,batch,beam,-1])\n t_bt_be_ind = tf.concat([t_bt_ind, tf.expand_dims(beam_ids, -1)], -1)\n # gather\n tf.gather_nd(a, t_bt_be_ind)\n\n Please double-check. Another way is to combine range and tile; but it is\n hardly readable. We use this method a lot in our code (tf.where(constant)),\n it looks okay. ebrevdo may better comment on this. Thanks!\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#13312 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtimwHa50-96kt9b0v8H5obAAtzqlE2ks5tCtvAgaJpZM4PkNmd>\n .", "body": "tf.where(tf.ones_like(beam_ids) > -1)[:,:-1]\n\n\nthat line looks relatively expensive.\n\n\ni guess you can do tf.where(beam_ids > -1)\n\ntruthfully i like range and tile better because it's a much faster\nkernel than tf.where (tf.where is *really* expensive, especially on\ngpu)\n\n\nOn Thu, Dec 21, 2017 at 2:29 PM, Steven Ding <notifications@github.com>\nwrote:\n\n> *@steven-hh-ding* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n> <https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158392952>\n> :\n>\n> > +      math_ops.cast(mask, dtypes.bool), x=sorted_beam_ids, y=beam_ids)\n> +\n> +  # Gather from each tensor in t according to sorted_beam_ids.\n> +  def _collect(collector, i):\n> +    gathered = _tensor_gather_helper(\n> +        gather_indices=sorted_beam_ids[i],\n> +        gather_from=t.read(i),\n> +        batch_size=batch_size,\n> +        range_size=beam_width,\n> +        gather_shape=[batch_size * beam_width, -1])\n> +    return collector.write(i, gathered), i + 1\n> +\n> +  collected = tensor_array_ops.TensorArray(\n> +      t.dtype, size=t.size(), dynamic_size=False)\n> +  collected, _ = control_flow_ops.while_loop(\n> +      lambda _, i: i < t.size(),\n>\n> if i remember the shapes here correctly:\n>\n> time = 3\n> batch = 4\n> beam = 5\n> depth = 6\n> # [time, batch, beam, depth]\n> a = tf.constant(np.arange(time * batch * beam * depth), shape=[time, batch, beam, depth], dtype=tf.int64)\n> # [time, batch, beam] (reverse beam as example)\n> beam_ids = tf.constant(np.flip(np.arange(beam), 0), shape=[1,1,beam], dtype=tf.int64)\n> beam_ids = tf.tile(beam_ids, [3,4,1])\n> # we need [time, batch, beam, 3]# assume beam_ids > -1\n> t_bt_ind = tf.where(tf.ones_like(beam_ids) > -1)[:,:-1]\n> t_bt_ind = tf.reshape(t_bt_ind, [time,batch,beam,-1])\n> t_bt_be_ind = tf.concat([t_bt_ind, tf.expand_dims(beam_ids, -1)], -1)\n> # gather\n> tf.gather_nd(a, t_bt_be_ind)\n>\n> Please double-check. Another way is to combine range and tile; but it is\n> hardly readable. We use this method a lot in our code (tf.where(constant)),\n> it looks okay. ebrevdo may better comment on this. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158392952>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimwHa50-96kt9b0v8H5obAAtzqlE2ks5tCtvAgaJpZM4PkNmd>\n> .\n>\n"}