{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/160487776", "pull_request_review_id": 87614037, "id": 160487776, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDQ4Nzc3Ng==", "diff_hunk": "@@ -445,15 +517,55 @@ def _maybe_merge_batch_beams(self, t, s):\n       A reshaped version of t with shape `[batch_size, beam_width] + s`.\n \n     Raises:\n-      TypeError: If `t` is an instance of `TensorArray`.\n       ValueError:  If the rank of `t` is not statically known.\n     \"\"\"\n+    if isinstance(t, tensor_array_ops.TensorArray):\n+      return t\n     _check_maybe(t)\n     if t.shape.ndims >= 2:\n       return self._merge_batch_beams(t, s)\n     else:\n       return t\n \n+  def _maybe_sort_array_beams(self, t, parent_ids, sequence_length):\n+    \"\"\"Maybe sorts beams within a `TensorArray`.\n+\n+    Args:\n+      t: A `TensorArray` of size `max_time` that contains `Tensor`s of shape\n+        `[batch_size, beam_width, s]` or `[batch_size * beam_width, s]` where\n+        `s` is the depth shape.\n+      parent_ids: The parent ids of shape `[max_time, batch_size, beam_width]`.\n+      sequence_length: The sequence length of shape `[batch_size, beam_width]`.\n+\n+    Returns:\n+      A `TensorArray` where beams are sorted in each `Tensor` or `t` itself if it\n+      is not a `TensorArray` or does not meet shape requirements.\n+    \"\"\"\n+    if not isinstance(t, tensor_array_ops.TensorArray):\n+      return t\n+    if (not t._infer_shape or not t._element_shape\n+        or t._element_shape[0].ndims is None or t._element_shape[0].ndims < 1):  # pylint: disable=protected-access\n+      tf.logging.warn(\"The cell state contains a TensorArray that is not \"\n+                      \"amenable to sorting based on the beam search result. \"\n+                      \"For a TensorArray to be sorted, its elements shape \"\n+                      \"must be defined and have at least a rank of 1.\")\n+      return t\n+    shape = t._element_shape[0]  # pylint: disable=protected-access\n+    batch_size = tensor_util.constant_value(self._batch_size)", "path": "tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", "position": null, "original_position": 166, "commit_id": "d3eb228f1db2d60caf380833684944ce12203634", "original_commit_id": "10a222c5c97679995df66c386954d024f039c630", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "not sure how i feel about this.  i think if batch_size is statically known, as are the entries in `shape`, its ok to raise a ValueError here.  however, if they're not, you should probably push down an `Assert` on the shape of the output of `ta.stack()` to compare the run-time batch size and rank at that point.", "created_at": "2018-01-09T18:27:52Z", "updated_at": "2018-03-17T07:09:51Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r160487776", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/160487776"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r160487776"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312"}}, "body_html": "<p>not sure how i feel about this.  i think if batch_size is statically known, as are the entries in <code>shape</code>, its ok to raise a ValueError here.  however, if they're not, you should probably push down an <code>Assert</code> on the shape of the output of <code>ta.stack()</code> to compare the run-time batch size and rank at that point.</p>", "body_text": "not sure how i feel about this.  i think if batch_size is statically known, as are the entries in shape, its ok to raise a ValueError here.  however, if they're not, you should probably push down an Assert on the shape of the output of ta.stack() to compare the run-time batch size and rank at that point."}