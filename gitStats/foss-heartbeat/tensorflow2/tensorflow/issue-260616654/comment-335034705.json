{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335034705", "html_url": "https://github.com/tensorflow/tensorflow/pull/13312#issuecomment-335034705", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13312", "id": 335034705, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTAzNDcwNQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-08T20:13:52Z", "updated_at": "2017-10-08T20:13:52Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">We can also update gathertree to support more input dtypes.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sun, Oct 8, 2017 at 7:51 AM, Steven Ding ***@***.***&gt; wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260616654\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13312\" href=\"https://github.com/tensorflow/tensorflow/pull/13312#discussion_r143356707\">#13312 (comment)</a>&gt;\n :\n\n &gt; @@ -120,13 +120,79 @@ def tile_batch(t, multiplier, name=None):\n      return nest.map_structure(lambda t_: _tile_batch(t_, multiplier), t)\n\n\n -def _check_maybe(t):\n +def _map_function(fn, t):\n +  \"\"\"Maps the function fn on each element of the TensorArray t.\"\"\"\n +  loop_stop = lambda mapped, elems, i: (\n +      i == elems.size())\n +  loop_body = lambda mapped, elems, i: (\n +      mapped.write(i, fn(elems.read(i))), elems, i + 1)\n +  mapped = tensor_array_ops.TensorArray(t.dtype, size=0, dynamic_size=True)\n +  mapped, _, _ = control_flow_ops.while_loop(\n\n Thank you very much for the PR. I am also working on the same problem.\n Instead of picking out the right beams at each time step, we use\n gather_tree to sort out the right beams to avoid a quadratic complexity.\n Unfortunately the gather_tree only supports int32, so we did a dirty cast.\n It is fine for us as the alignments are only used for visualization on\n tensorboard. We update the finalize function and skip tensorarray for\n _merge_batch_beams and _split_batch_beams.\n\n   def finalize(self, outputs, final_state, sequence_lengths):\n     predicted_ids = beam_search_ops.gather_tree(\n         outputs.predicted_ids, outputs.parent_ids,\n         sequence_length=sequence_lengths)\n     def gather_tree_from_array(t):\n         if not isinstance(t, tensor_array_ops.TensorArray):\n             return t\n         history = t.stack()\n         history = rnn._transpose_batch_time(history)\n         history = math_ops.cast(history * 10000, dtypes.int32)\n         history = beam_search_ops.gather_tree(\n             history, outputs.parent_ids,\n             sequence_length=sequence_lengths)\n         history = math_ops.cast(history / 10000, t.dtype)\n         return history\n     final_state = nest.map_structure(gather_tree_from_array, final_state)\n     outputs = FinalBeamSearchDecoderOutput(\n         beam_search_decoder_output=outputs, predicted_ids=predicted_ids)\n     return outputs, final_state\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260616654\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13312\" href=\"https://github.com/tensorflow/tensorflow/pull/13312#discussion_r143356707\">#13312 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim8EkA9QD7lC3xBaNi7yf7LJHYzq0ks5sqOGNgaJpZM4PkNmd\">https://github.com/notifications/unsubscribe-auth/ABtim8EkA9QD7lC3xBaNi7yf7LJHYzq0ks5sqOGNgaJpZM4PkNmd</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "We can also update gathertree to support more input dtypes.\n\u2026\nOn Sun, Oct 8, 2017 at 7:51 AM, Steven Ding ***@***.***> wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n <#13312 (comment)>\n :\n\n > @@ -120,13 +120,79 @@ def tile_batch(t, multiplier, name=None):\n      return nest.map_structure(lambda t_: _tile_batch(t_, multiplier), t)\n\n\n -def _check_maybe(t):\n +def _map_function(fn, t):\n +  \"\"\"Maps the function fn on each element of the TensorArray t.\"\"\"\n +  loop_stop = lambda mapped, elems, i: (\n +      i == elems.size())\n +  loop_body = lambda mapped, elems, i: (\n +      mapped.write(i, fn(elems.read(i))), elems, i + 1)\n +  mapped = tensor_array_ops.TensorArray(t.dtype, size=0, dynamic_size=True)\n +  mapped, _, _ = control_flow_ops.while_loop(\n\n Thank you very much for the PR. I am also working on the same problem.\n Instead of picking out the right beams at each time step, we use\n gather_tree to sort out the right beams to avoid a quadratic complexity.\n Unfortunately the gather_tree only supports int32, so we did a dirty cast.\n It is fine for us as the alignments are only used for visualization on\n tensorboard. We update the finalize function and skip tensorarray for\n _merge_batch_beams and _split_batch_beams.\n\n   def finalize(self, outputs, final_state, sequence_lengths):\n     predicted_ids = beam_search_ops.gather_tree(\n         outputs.predicted_ids, outputs.parent_ids,\n         sequence_length=sequence_lengths)\n     def gather_tree_from_array(t):\n         if not isinstance(t, tensor_array_ops.TensorArray):\n             return t\n         history = t.stack()\n         history = rnn._transpose_batch_time(history)\n         history = math_ops.cast(history * 10000, dtypes.int32)\n         history = beam_search_ops.gather_tree(\n             history, outputs.parent_ids,\n             sequence_length=sequence_lengths)\n         history = math_ops.cast(history / 10000, t.dtype)\n         return history\n     final_state = nest.map_structure(gather_tree_from_array, final_state)\n     outputs = FinalBeamSearchDecoderOutput(\n         beam_search_decoder_output=outputs, predicted_ids=predicted_ids)\n     return outputs, final_state\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n <#13312 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim8EkA9QD7lC3xBaNi7yf7LJHYzq0ks5sqOGNgaJpZM4PkNmd>\n .", "body": "We can also update gathertree to support more input dtypes.\n\nOn Sun, Oct 8, 2017 at 7:51 AM, Steven Ding <notifications@github.com>\nwrote:\n\n> *@steven-hh-ding* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\n> <https://github.com/tensorflow/tensorflow/pull/13312#discussion_r143356707>\n> :\n>\n> > @@ -120,13 +120,79 @@ def tile_batch(t, multiplier, name=None):\n>      return nest.map_structure(lambda t_: _tile_batch(t_, multiplier), t)\n>\n>\n> -def _check_maybe(t):\n> +def _map_function(fn, t):\n> +  \"\"\"Maps the function fn on each element of the TensorArray t.\"\"\"\n> +  loop_stop = lambda mapped, elems, i: (\n> +      i == elems.size())\n> +  loop_body = lambda mapped, elems, i: (\n> +      mapped.write(i, fn(elems.read(i))), elems, i + 1)\n> +  mapped = tensor_array_ops.TensorArray(t.dtype, size=0, dynamic_size=True)\n> +  mapped, _, _ = control_flow_ops.while_loop(\n>\n> Thank you very much for the PR. I am also working on the same problem.\n> Instead of picking out the right beams at each time step, we use\n> gather_tree to sort out the right beams to avoid a quadratic complexity.\n> Unfortunately the gather_tree only supports int32, so we did a dirty cast.\n> It is fine for us as the alignments are only used for visualization on\n> tensorboard. We update the finalize function and skip tensorarray for\n> _merge_batch_beams and _split_batch_beams.\n>\n>   def finalize(self, outputs, final_state, sequence_lengths):\n>     predicted_ids = beam_search_ops.gather_tree(\n>         outputs.predicted_ids, outputs.parent_ids,\n>         sequence_length=sequence_lengths)\n>     def gather_tree_from_array(t):\n>         if not isinstance(t, tensor_array_ops.TensorArray):\n>             return t\n>         history = t.stack()\n>         history = rnn._transpose_batch_time(history)\n>         history = math_ops.cast(history * 10000, dtypes.int32)\n>         history = beam_search_ops.gather_tree(\n>             history, outputs.parent_ids,\n>             sequence_length=sequence_lengths)\n>         history = math_ops.cast(history / 10000, t.dtype)\n>         return history\n>     final_state = nest.map_structure(gather_tree_from_array, final_state)\n>     outputs = FinalBeamSearchDecoderOutput(\n>         beam_search_decoder_output=outputs, predicted_ids=predicted_ids)\n>     return outputs, final_state\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13312#discussion_r143356707>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8EkA9QD7lC3xBaNi7yf7LJHYzq0ks5sqOGNgaJpZM4PkNmd>\n> .\n>\n"}