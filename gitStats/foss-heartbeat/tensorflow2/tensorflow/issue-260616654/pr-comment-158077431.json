{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158077431", "pull_request_review_id": 84827703, "id": 158077431, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1ODA3NzQzMQ==", "diff_hunk": "@@ -806,3 +873,22 @@ def _tensor_gather_helper(gather_indices, gather_from, batch_size,\n     output = array_ops.reshape(output, final_shape, name=\"output\")\n     output.set_shape(final_static_shape)\n     return output\n+\n+\n+def _maybe_sort_array_beams(t, parent_ids, sequence_length):\n+  \"\"\"Maybe sorts beams within a `TensorArray`.\n+\n+  Args:\n+    t: A `TensorArray` of size `max_time` that contains `Tensor`s of shape\n+      `[batch_size, beam_width, depth]`.\n+    parent_ids: The parent ids of shape `[max_time, batch_size, beam_width]`.\n+    sequence_length: The sequence length of shape `[batch_size, beam_width]`.\n+\n+  Returns:\n+    A `TensorArray` where beams are sorted in each `Tensor` or `t` itself if it\n+    is not a `TensorArray`.\n+  \"\"\"\n+  if isinstance(t, tensor_array_ops.TensorArray):", "path": "tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", "position": null, "original_position": 136, "commit_id": "d3eb228f1db2d60caf380833684944ce12203634", "original_commit_id": "1c09f329b8ade55351ed96e1f2951031b599bb87", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "There's no guarantee that the TensorArray has shapes that are amenable to sorting.  what if it contains scalars?  what if the the shape is not `[batch_size, beam_width, depth]` but instead someone is storing previous time steps' state having shape `[?, depth]` where `?` changes from element to element?  This is perfectly valid - you can't stack this TensorArray but you *can* `concat` it.\r\n\r\nIn other words, this function is making some serious assumptions about the fact that only an `AttentionWrapper` might create TensorArrays.  Guard against it; enable by default, but if there's a failure raise a warning message that the user should disable the TensorArray sorting.\r\n\r\nAdditional checks you should use:\r\n\r\n1. Only perform this if `t` has `infer_shape=True`.\r\n2. Only perform this if `t.element_shape` is rank 3 and element_shape[2:3] == [beam_width, depth].", "created_at": "2017-12-20T16:51:42Z", "updated_at": "2018-03-17T07:09:51Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158077431", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158077431"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158077431"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312"}}, "body_html": "<p>There's no guarantee that the TensorArray has shapes that are amenable to sorting.  what if it contains scalars?  what if the the shape is not <code>[batch_size, beam_width, depth]</code> but instead someone is storing previous time steps' state having shape <code>[?, depth]</code> where <code>?</code> changes from element to element?  This is perfectly valid - you can't stack this TensorArray but you <em>can</em> <code>concat</code> it.</p>\n<p>In other words, this function is making some serious assumptions about the fact that only an <code>AttentionWrapper</code> might create TensorArrays.  Guard against it; enable by default, but if there's a failure raise a warning message that the user should disable the TensorArray sorting.</p>\n<p>Additional checks you should use:</p>\n<ol>\n<li>Only perform this if <code>t</code> has <code>infer_shape=True</code>.</li>\n<li>Only perform this if <code>t.element_shape</code> is rank 3 and element_shape[2:3] == [beam_width, depth].</li>\n</ol>", "body_text": "There's no guarantee that the TensorArray has shapes that are amenable to sorting.  what if it contains scalars?  what if the the shape is not [batch_size, beam_width, depth] but instead someone is storing previous time steps' state having shape [?, depth] where ? changes from element to element?  This is perfectly valid - you can't stack this TensorArray but you can concat it.\nIn other words, this function is making some serious assumptions about the fact that only an AttentionWrapper might create TensorArrays.  Guard against it; enable by default, but if there's a failure raise a warning message that the user should disable the TensorArray sorting.\nAdditional checks you should use:\n\nOnly perform this if t has infer_shape=True.\nOnly perform this if t.element_shape is rank 3 and element_shape[2:3] == [beam_width, depth]."}