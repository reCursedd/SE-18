{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158921485", "pull_request_review_id": 85794204, "id": 158921485, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1ODkyMTQ4NQ==", "diff_hunk": "@@ -121,10 +121,73 @@ def tile_batch(t, multiplier, name=None):\n     return nest.map_structure(lambda t_: _tile_batch(t_, multiplier), t)\n \n \n+def gather_tree_from_array(t, parent_ids, sequence_length):\n+  \"\"\"Calculates the full beams for `TensorArray`s.\n+\n+  Args:\n+    t: A `TensorArray` of size `max_time` that contains `Tensor`s of shape\n+      `[batch_size, beam_width, s]` or `[batch_size * beam_width, s]` where\n+      `s` is the depth shape.\n+    parent_ids: The parent ids of shape `[max_time, batch_size, beam_width]`.\n+    sequence_length: The sequence length of shape `[batch_size, beam_width]`.\n+\n+  Returns:\n+    A `TensorArray` of the same size and type as `t` and where beams are sorted\n+    in each `Tensor` according to `parent_ids`.\n+  \"\"\"\n+  max_time = array_ops.shape(parent_ids)[0]\n+  batch_size = array_ops.shape(parent_ids)[1]\n+  beam_width = array_ops.shape(parent_ids)[2]\n+\n+  # Generate beam ids that will be reordered by gather_tree.\n+  beam_ids = array_ops.expand_dims(\n+      array_ops.expand_dims(math_ops.range(beam_width), 0), 0)\n+  beam_ids = array_ops.tile(beam_ids, [max_time, batch_size, 1])\n+\n+  mask = array_ops.sequence_mask(\n+      sequence_length, maxlen=max_time, dtype=dtypes.int32)\n+  mask = array_ops.transpose(mask, perm=[2, 0, 1])\n+\n+  # Use beam_width + 1 to mark the end of beam.\n+  masked_beam_ids = (beam_ids * mask) + (1 - mask) * (beam_width + 1)\n+\n+  max_sequence_lengths = math_ops.to_int32(\n+      math_ops.reduce_max(sequence_length, axis=1))\n+  sorted_beam_ids = beam_search_ops.gather_tree(\n+      step_ids=masked_beam_ids,\n+      parent_ids=parent_ids,\n+      max_sequence_lengths=max_sequence_lengths,\n+      end_token=beam_width + 1)\n+\n+  # For out of range steps, simply copy the same beam.\n+  sorted_beam_ids = array_ops.where(\n+      math_ops.cast(mask, dtypes.bool), x=sorted_beam_ids, y=beam_ids)\n+\n+  # Generate indices for gather_nd.\n+  time_ind = array_ops.tile(array_ops.reshape(\n+      math_ops.range(max_time), [-1, 1, 1]), [1, batch_size, beam_width])\n+  batch_ind = array_ops.tile(array_ops.reshape(\n+      math_ops.range(batch_size), [-1, 1, 1]), [1, max_time, beam_width])\n+  batch_ind = array_ops.transpose(batch_ind, perm=[1, 0, 2])\n+  indices = array_ops.stack([time_ind, batch_ind, sorted_beam_ids], -1)\n+\n+  # Gather from a tensor with collapsed additional dimensions.\n+  gather_from = t.stack()\n+  final_shape = array_ops.shape(gather_from)\n+  gather_from = array_ops.reshape(\n+      gather_from, [max_time, batch_size, beam_width, -1])\n+  ordered = array_ops.gather_nd(gather_from, indices)\n+  ordered = array_ops.reshape(ordered, final_shape)\n+\n+  # Return the result as a TensorArray.\n+  ordered_ta = tensor_array_ops.TensorArray(", "path": "tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", "position": null, "original_position": 63, "commit_id": "d3eb228f1db2d60caf380833684944ce12203634", "original_commit_id": "16da288ad0dd8a191f0bb6b3ee14aca6e0c4f8d8", "user": {"login": "guillaumekln", "id": 4805513, "node_id": "MDQ6VXNlcjQ4MDU1MTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4805513?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guillaumekln", "html_url": "https://github.com/guillaumekln", "followers_url": "https://api.github.com/users/guillaumekln/followers", "following_url": "https://api.github.com/users/guillaumekln/following{/other_user}", "gists_url": "https://api.github.com/users/guillaumekln/gists{/gist_id}", "starred_url": "https://api.github.com/users/guillaumekln/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guillaumekln/subscriptions", "organizations_url": "https://api.github.com/users/guillaumekln/orgs", "repos_url": "https://api.github.com/users/guillaumekln/repos", "events_url": "https://api.github.com/users/guillaumekln/events{/privacy}", "received_events_url": "https://api.github.com/users/guillaumekln/received_events", "type": "User", "site_admin": false}, "body": "We could do that if it is properly documented but it would make the API a bit less consistent. Taking `alignement_history` as an example, the user would first expect the same output type from a `BeamSearchDecoder` or a `BasicDecoder`.\r\n\r\nWhat about stacking all TensorArrays in the cell state in `finalize`? It seems like that is what users do anyway.\r\n\r\nLet me know what you think is best.", "created_at": "2017-12-28T09:57:32Z", "updated_at": "2018-03-17T07:09:51Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158921485", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158921485"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13312#discussion_r158921485"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13312"}}, "body_html": "<p>We could do that if it is properly documented but it would make the API a bit less consistent. Taking <code>alignement_history</code> as an example, the user would first expect the same output type from a <code>BeamSearchDecoder</code> or a <code>BasicDecoder</code>.</p>\n<p>What about stacking all TensorArrays in the cell state in <code>finalize</code>? It seems like that is what users do anyway.</p>\n<p>Let me know what you think is best.</p>", "body_text": "We could do that if it is properly documented but it would make the API a bit less consistent. Taking alignement_history as an example, the user would first expect the same output type from a BeamSearchDecoder or a BasicDecoder.\nWhat about stacking all TensorArrays in the cell state in finalize? It seems like that is what users do anyway.\nLet me know what you think is best.", "in_reply_to_id": 158537603}