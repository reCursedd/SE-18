{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11808", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11808/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11808/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11808/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11808", "id": 245978474, "node_id": "MDU6SXNzdWUyNDU5Nzg0NzQ=", "number": 11808, "title": "tf.contrib.streaming_mean_squared_error returns incorrect result", "user": {"login": "rubenvereecken", "id": 5216553, "node_id": "MDQ6VXNlcjUyMTY1NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5216553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rubenvereecken", "html_url": "https://github.com/rubenvereecken", "followers_url": "https://api.github.com/users/rubenvereecken/followers", "following_url": "https://api.github.com/users/rubenvereecken/following{/other_user}", "gists_url": "https://api.github.com/users/rubenvereecken/gists{/gist_id}", "starred_url": "https://api.github.com/users/rubenvereecken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rubenvereecken/subscriptions", "organizations_url": "https://api.github.com/users/rubenvereecken/orgs", "repos_url": "https://api.github.com/users/rubenvereecken/repos", "events_url": "https://api.github.com/users/rubenvereecken/events{/privacy}", "received_events_url": "https://api.github.com/users/rubenvereecken/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-07-27T09:25:12Z", "updated_at": "2017-08-02T19:53:19Z", "closed_at": "2017-08-01T23:22:28Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Mint 18</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary (pip)</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0.0rc0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><code>tf.contrib.streaming_mean_squared_error</code> returns wonky results. It returns the current mean square error tensor and an update op. According to the documentation their evaluated values should match. They don't, and the values of the latter tend to get weird. A minimal example should demonstrate.</p>\n<h3>Source code / logs</h3>\n<p>Example: mean squared error between two arrays whose difference is an array of ones. The MSE should consistently be 1. It isn't though.</p>\n<div class=\"highlight highlight-source-python\"><pre>sess <span class=\"pl-k\">=</span> tf.InteractiveSession()\na <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">7</span>))\nb <span class=\"pl-k\">=</span> tf.constant(np.arange(<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">6</span>))\ne <span class=\"pl-k\">=</span> tf.contrib.metrics.streaming_mean_squared_error(a,b)\ninit_op <span class=\"pl-k\">=</span> tf.local_variables_initializer(); sess.run(init_op)\nsess.run(e) <span class=\"pl-c\"><span class=\"pl-c\">#</span> (1.0, 1.0)</span>\nsess.run(e) <span class=\"pl-c\"><span class=\"pl-c\">#</span> (1.0, 1.0)</span>\nsess.run(e) <span class=\"pl-c\"><span class=\"pl-c\">#</span> (1.5, 1.0) !!!</span>\nsess.run(e) <span class=\"pl-c\"><span class=\"pl-c\">#</span> (1.0, 1.0)</span></pre></div>\n<p>After having a brief look at the code, I don't see why the returned values don't match. The <a href=\"https://github.com/tensorflow/tensorflow/blob/b10f50ff15944badb7262a207f6628dfa52d6a9d/tensorflow/docs_src/api_guides/python/contrib.metrics.md\">docs</a> speak of <em>finalizing</em> the value but it just looks like <code>total/count</code> is returned.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 18\nTensorFlow installed from (source or binary): Binary (pip)\nTensorFlow version (use command below): v1.3.0.0rc0\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nDescribe the problem\ntf.contrib.streaming_mean_squared_error returns wonky results. It returns the current mean square error tensor and an update op. According to the documentation their evaluated values should match. They don't, and the values of the latter tend to get weird. A minimal example should demonstrate.\nSource code / logs\nExample: mean squared error between two arrays whose difference is an array of ones. The MSE should consistently be 1. It isn't though.\nsess = tf.InteractiveSession()\na = tf.constant(np.arange(3,7))\nb = tf.constant(np.arange(2,6))\ne = tf.contrib.metrics.streaming_mean_squared_error(a,b)\ninit_op = tf.local_variables_initializer(); sess.run(init_op)\nsess.run(e) # (1.0, 1.0)\nsess.run(e) # (1.0, 1.0)\nsess.run(e) # (1.5, 1.0) !!!\nsess.run(e) # (1.0, 1.0)\nAfter having a brief look at the code, I don't see why the returned values don't match. The docs speak of finalizing the value but it just looks like total/count is returned.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18\r\n- **TensorFlow installed from (source or binary)**: Binary (pip)\r\n- **TensorFlow version (use command below)**: v1.3.0.0rc0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n`tf.contrib.streaming_mean_squared_error` returns wonky results. It returns the current mean square error tensor and an update op. According to the documentation their evaluated values should match. They don't, and the values of the latter tend to get weird. A minimal example should demonstrate.\r\n\r\n### Source code / logs\r\nExample: mean squared error between two arrays whose difference is an array of ones. The MSE should consistently be 1. It isn't though.\r\n\r\n```python\r\nsess = tf.InteractiveSession()\r\na = tf.constant(np.arange(3,7))\r\nb = tf.constant(np.arange(2,6))\r\ne = tf.contrib.metrics.streaming_mean_squared_error(a,b)\r\ninit_op = tf.local_variables_initializer(); sess.run(init_op)\r\nsess.run(e) # (1.0, 1.0)\r\nsess.run(e) # (1.0, 1.0)\r\nsess.run(e) # (1.5, 1.0) !!!\r\nsess.run(e) # (1.0, 1.0)\r\n```\r\nAfter having a brief look at the code, I don't see why the returned values don't match. The [docs](https://github.com/tensorflow/tensorflow/blob/b10f50ff15944badb7262a207f6628dfa52d6a9d/tensorflow/docs_src/api_guides/python/contrib.metrics.md) speak of _finalizing_ the value but it just looks like `total/count` is returned.\r\n"}