{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/131025005", "pull_request_review_id": 53963603, "id": 131025005, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzMTAyNTAwNQ==", "diff_hunk": "@@ -20,9 +20,120 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/kernels/bounds_check.h\"\n \n+#ifdef GOOGLE_CUDA\n+#include \"tensorflow/core/kernels/cuda_device_array.h\"\n+#endif // GOOGLE_CUDA\n+\n namespace tensorflow {\n \n-template <class T>\n+typedef Eigen::ThreadPoolDevice CPUDevice;\n+#ifdef GOOGLE_CUDA\n+typedef Eigen::GpuDevice GPUDevice;\n+#endif // GOOGLE_CUDA\n+\n+\n+// Dynamic stitch function for CPUDevice.\n+template <typename T>\n+void DynamicStitchCPU(OpKernelContext* ctx,\n+                const int32 first_dim_size,\n+                const OpInputList& indices_inputs, const OpInputList& data_inputs,\n+                Tensor* merged) {\n+  auto merged_flat = merged->flat_outer_dims<T>();\n+  const int slice_size = merged_flat.dimension(1);\n+  for (int input_num = 0; input_num < indices_inputs.size(); input_num++) {\n+    const Tensor& indices = indices_inputs[input_num];\n+    auto indices_vec = indices.flat<int32>();\n+    const Tensor& data = data_inputs[input_num];\n+    auto data_flat =\n+            data.shaped<T, 2>({indices_vec.dimension(0), slice_size});\n+\n+    if (DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) {\n+      T* merged_base = &merged_flat(0, 0);\n+      const T* data_base = &data_flat(0, 0);\n+      const size_t slice_bytes = slice_size * sizeof(T);\n+      for (int i = 0; i < indices_vec.size(); i++) {\n+        int32 index = internal::SubtleMustCopy(indices_vec(i));\n+        OP_REQUIRES(\n+                ctx, FastBoundsCheck(index, first_dim_size),\n+                errors::InvalidArgument(\"indices[\", i, \"] is out of range\"));\n+        memcpy(merged_base + index * slice_size, data_base + i * slice_size,\n+               slice_bytes);\n+      }\n+    } else {\n+      Eigen::DSizes<Eigen::DenseIndex, 2> sizes(1, slice_size);\n+      for (int i = 0; i < indices_vec.size(); i++) {\n+        // Copy slice data[i] to merged[indices[i]]\n+        Eigen::DSizes<Eigen::DenseIndex, 2> data_indices(i, 0);\n+        int32 index = internal::SubtleMustCopy(indices_vec(i));\n+        OP_REQUIRES(\n+                ctx, FastBoundsCheck(index, first_dim_size),\n+                errors::InvalidArgument(\"indices[\", i, \"] is out of range\"));\n+        Eigen::DSizes<Eigen::DenseIndex, 2> merged_indices(index, 0);\n+        merged_flat.slice(merged_indices, sizes) =\n+                data_flat.slice(data_indices, sizes);\n+      }\n+    }\n+  }\n+}\n+\n+#ifdef GOOGLE_CUDA\n+\n+template <typename T>\n+void DynamicStitchGPUImpl(const Eigen::GpuDevice& gpu_device,\n+                          const int32 slice_size, const int32 first_dim_size,\n+                          const CudaDeviceArrayStruct<int>& input_indices,\n+                          const CudaDeviceArrayStruct<const T*>& input_ptrs,\n+                          T* output);\n+\n+\n+// because the collision requirements, we have to deal with\n+// collion first before send data to gpu kernel.\n+// TODO(ekelsen): This code can be done for more speed.", "path": "tensorflow/core/kernels/dynamic_stitch_op.cc", "position": null, "original_position": 73, "commit_id": "d3e79f9a7da7ec1fb0ae86a7cb317ab8ed544dd6", "original_commit_id": "67b2914ee73a3ad93d33cea42a093d67c5476437", "user": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "body": "How about - \"Instead of doing a serial scan on the CPU to pick the last of duplicated indices, it could instead be done of the GPU implicitly using atomics to make sure the last index is the final write.\"", "created_at": "2017-08-02T23:48:45Z", "updated_at": "2017-08-09T03:37:07Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11940#discussion_r131025005", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11940", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/131025005"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11940#discussion_r131025005"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11940"}}, "body_html": "<p>How about - \"Instead of doing a serial scan on the CPU to pick the last of duplicated indices, it could instead be done of the GPU implicitly using atomics to make sure the last index is the final write.\"</p>", "body_text": "How about - \"Instead of doing a serial scan on the CPU to pick the last of duplicated indices, it could instead be done of the GPU implicitly using atomics to make sure the last index is the final write.\""}