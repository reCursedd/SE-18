{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299521465", "html_url": "https://github.com/tensorflow/tensorflow/issues/9690#issuecomment-299521465", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9690", "id": 299521465, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTUyMTQ2NQ==", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-05T17:08:52Z", "updated_at": "2017-05-05T19:17:38Z", "author_association": "NONE", "body_html": "<p>Cool example <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> , but it has an error. <code>EIGEN_MAX_ALIGN_BYTES</code> depends on the compilation flags. For instance, if I add <code>-march=native</code> to the compiler flags when compiling the op on my AVX compatible box, the op outputs 32 instead of 16. The value from the independently compiled op is more or less independent of the value inside of a given TF binary.</p>\n<p>Any API into this must return the same value used in the core TensorFlow lib, which means it must be compiled with the same relevant flags as the TensorFlow lib, which is easiest done if the functionality is a part of TensorFlow.</p>\n<p>Getting aligned memory from Numpy is harder than it should be: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"50130307\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/numpy/numpy/issues/5312\" data-hovercard-type=\"issue\" data-hovercard-url=\"/numpy/numpy/issues/5312/hovercard\" href=\"https://github.com/numpy/numpy/issues/5312\">numpy/numpy#5312</a> . The only way I know of to get aligned memory from Numpy is to just align it yourself:</p>\n<pre><code>In [14]: a = np.empty(1000, dtype=np.float32)\n\nIn [15]: a.ctypes.data\nOut[15]: 48297584\n\nIn [16]: a.ctypes.data % 16\nOut[16]: 0\n\nIn [17]: a.ctypes.data % 32\nOut[17]: 16\n\nIn [18]: b = a[4:]\n\nIn [19]: b.ctypes.data\nOut[19]: 48297600\n\nIn [20]: b.ctypes.data % 32\nOut[20]: 0\n</code></pre>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">empty_aligned</span>(<span class=\"pl-smi\">n</span>, <span class=\"pl-smi\">align</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>                                                                                                                                     </span>\n<span class=\"pl-s\">    Get n bytes of memory wih alignment align.                                                                                              </span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n\n    a <span class=\"pl-k\">=</span> np.empty(n <span class=\"pl-k\">+</span> (align <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.uint8)\n    data_align <span class=\"pl-k\">=</span> a.ctypes.data <span class=\"pl-k\">%</span> align\n    offset <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">if</span> data_align <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">else</span> (align <span class=\"pl-k\">-</span> data_align)\n    <span class=\"pl-k\">return</span> a[offset : offset <span class=\"pl-k\">+</span> n]</pre></div>", "body_text": "Cool example @yaroslavvb , but it has an error. EIGEN_MAX_ALIGN_BYTES depends on the compilation flags. For instance, if I add -march=native to the compiler flags when compiling the op on my AVX compatible box, the op outputs 32 instead of 16. The value from the independently compiled op is more or less independent of the value inside of a given TF binary.\nAny API into this must return the same value used in the core TensorFlow lib, which means it must be compiled with the same relevant flags as the TensorFlow lib, which is easiest done if the functionality is a part of TensorFlow.\nGetting aligned memory from Numpy is harder than it should be: numpy/numpy#5312 . The only way I know of to get aligned memory from Numpy is to just align it yourself:\nIn [14]: a = np.empty(1000, dtype=np.float32)\n\nIn [15]: a.ctypes.data\nOut[15]: 48297584\n\nIn [16]: a.ctypes.data % 16\nOut[16]: 0\n\nIn [17]: a.ctypes.data % 32\nOut[17]: 16\n\nIn [18]: b = a[4:]\n\nIn [19]: b.ctypes.data\nOut[19]: 48297600\n\nIn [20]: b.ctypes.data % 32\nOut[20]: 0\n\ndef empty_aligned(n, align):\n    \"\"\"                                                                                                                                     \n    Get n bytes of memory wih alignment align.                                                                                              \n    \"\"\"\n\n    a = np.empty(n + (align - 1), dtype=np.uint8)\n    data_align = a.ctypes.data % align\n    offset = 0 if data_align == 0 else (align - data_align)\n    return a[offset : offset + n]", "body": "Cool example @yaroslavvb , but it has an error. ``EIGEN_MAX_ALIGN_BYTES`` depends on the compilation flags. For instance, if I add ``-march=native`` to the compiler flags when compiling the op on my AVX compatible box, the op outputs 32 instead of 16. The value from the independently compiled op is more or less independent of the value inside of a given TF binary.\r\n\r\nAny API into this must return the same value used in the core TensorFlow lib, which means it must be compiled with the same relevant flags as the TensorFlow lib, which is easiest done if the functionality is a part of TensorFlow.\r\n\r\nGetting aligned memory from Numpy is harder than it should be: https://github.com/numpy/numpy/issues/5312 . The only way I know of to get aligned memory from Numpy is to just align it yourself:\r\n```\r\nIn [14]: a = np.empty(1000, dtype=np.float32)\r\n\r\nIn [15]: a.ctypes.data\r\nOut[15]: 48297584\r\n\r\nIn [16]: a.ctypes.data % 16\r\nOut[16]: 0\r\n\r\nIn [17]: a.ctypes.data % 32\r\nOut[17]: 16\r\n\r\nIn [18]: b = a[4:]\r\n\r\nIn [19]: b.ctypes.data\r\nOut[19]: 48297600\r\n\r\nIn [20]: b.ctypes.data % 32\r\nOut[20]: 0\r\n```\r\n\r\n```python\r\ndef empty_aligned(n, align):\r\n    \"\"\"                                                                                                                                     \r\n    Get n bytes of memory wih alignment align.                                                                                              \r\n    \"\"\"\r\n\r\n    a = np.empty(n + (align - 1), dtype=np.uint8)\r\n    data_align = a.ctypes.data % align\r\n    offset = 0 if data_align == 0 else (align - data_align)\r\n    return a[offset : offset + n]\r\n```"}