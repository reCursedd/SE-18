{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/658", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/658/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/658/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/658/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/658", "id": 124483462, "node_id": "MDU6SXNzdWUxMjQ0ODM0NjI=", "number": 658, "title": "zombie process resulting from using many GPUs", "user": {"login": "digitalsword", "id": 12500045, "node_id": "MDQ6VXNlcjEyNTAwMDQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/12500045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/digitalsword", "html_url": "https://github.com/digitalsword", "followers_url": "https://api.github.com/users/digitalsword/followers", "following_url": "https://api.github.com/users/digitalsword/following{/other_user}", "gists_url": "https://api.github.com/users/digitalsword/gists{/gist_id}", "starred_url": "https://api.github.com/users/digitalsword/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/digitalsword/subscriptions", "organizations_url": "https://api.github.com/users/digitalsword/orgs", "repos_url": "https://api.github.com/users/digitalsword/repos", "events_url": "https://api.github.com/users/digitalsword/events{/privacy}", "received_events_url": "https://api.github.com/users/digitalsword/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2015-12-31T16:17:22Z", "updated_at": "2016-06-09T06:11:55Z", "closed_at": "2016-05-16T17:40:30Z", "author_association": "NONE", "body_html": "<p>I run the example cifar10_multi_gpu_train.py on a PC equipped with 4 GPUs. Somehow the program occupies 4 GPUs, but only the first GPU is doing computation.</p>\n<p>When I hit ctrl + c, the python scripts did not terminate, and I found zombie process using htop (the zombie process is associated with command python). After that I have to reboot using \"reboot -nf\" to gain access to GPUs. Tensorflow was installed from source (<a href=\"https://github.com/tensorflow/tensorflow.git\">https://github.com/tensorflow/tensorflow.git</a>).</p>\n<pre><code>  File \"cifar10_multi_gpu_train.py\", line 270, in &lt;module&gt;\n    tf.app.run()\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_multi_gpu_train.py\", line 266, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 236, in train\n    _, loss_value = sess.run([train_op, loss])\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 373, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 433, in _do_run\n    target_list)\nKeyboardInterrupt\n</code></pre>\n<p>However, if I do export CUDA_VISIBLE_DEVICES=0 before running the example to limit it to one GPU, I am able to terminate the python scripts normally using ctrl + c.</p>\n<p>nvidia-smi<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12500045/12065926/a9860536-afad-11e5-8b5d-12fdb343327d.png\"><img src=\"https://cloud.githubusercontent.com/assets/12500045/12065926/a9860536-afad-11e5-8b5d-12fdb343327d.png\" alt=\"screenshot 2015-12-31 10 58 57\" style=\"max-width:100%;\"></a></p>\n<p>htop<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12500045/12065944/da739de8-afad-11e5-937b-dcfe1fc3591d.png\"><img src=\"https://cloud.githubusercontent.com/assets/12500045/12065944/da739de8-afad-11e5-937b-dcfe1fc3591d.png\" alt=\"screenshot 2015-12-31 11 01 15\" style=\"max-width:100%;\"></a></p>", "body_text": "I run the example cifar10_multi_gpu_train.py on a PC equipped with 4 GPUs. Somehow the program occupies 4 GPUs, but only the first GPU is doing computation.\nWhen I hit ctrl + c, the python scripts did not terminate, and I found zombie process using htop (the zombie process is associated with command python). After that I have to reboot using \"reboot -nf\" to gain access to GPUs. Tensorflow was installed from source (https://github.com/tensorflow/tensorflow.git).\n  File \"cifar10_multi_gpu_train.py\", line 270, in <module>\n    tf.app.run()\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_multi_gpu_train.py\", line 266, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 236, in train\n    _, loss_value = sess.run([train_op, loss])\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 373, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 433, in _do_run\n    target_list)\nKeyboardInterrupt\n\nHowever, if I do export CUDA_VISIBLE_DEVICES=0 before running the example to limit it to one GPU, I am able to terminate the python scripts normally using ctrl + c.\nnvidia-smi\n\nhtop", "body": "I run the example cifar10_multi_gpu_train.py on a PC equipped with 4 GPUs. Somehow the program occupies 4 GPUs, but only the first GPU is doing computation.\n\nWhen I hit ctrl + c, the python scripts did not terminate, and I found zombie process using htop (the zombie process is associated with command python). After that I have to reboot using \"reboot -nf\" to gain access to GPUs. Tensorflow was installed from source (https://github.com/tensorflow/tensorflow.git).\n\n```\n  File \"cifar10_multi_gpu_train.py\", line 270, in <module>\n    tf.app.run()\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_multi_gpu_train.py\", line 266, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 236, in train\n    _, loss_value = sess.run([train_op, loss])\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 373, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 433, in _do_run\n    target_list)\nKeyboardInterrupt\n```\n\nHowever, if I do export CUDA_VISIBLE_DEVICES=0 before running the example to limit it to one GPU, I am able to terminate the python scripts normally using ctrl + c.\n\nnvidia-smi\n![screenshot 2015-12-31 10 58 57](https://cloud.githubusercontent.com/assets/12500045/12065926/a9860536-afad-11e5-8b5d-12fdb343327d.png)\n\nhtop\n![screenshot 2015-12-31 11 01 15](https://cloud.githubusercontent.com/assets/12500045/12065944/da739de8-afad-11e5-937b-dcfe1fc3591d.png)\n"}