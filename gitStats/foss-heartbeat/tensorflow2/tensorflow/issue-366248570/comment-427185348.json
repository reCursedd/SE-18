{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/427185348", "html_url": "https://github.com/tensorflow/tensorflow/issues/22692#issuecomment-427185348", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22692", "id": 427185348, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNzE4NTM0OA==", "user": {"login": "kazemSafari", "id": 32110820, "node_id": "MDQ6VXNlcjMyMTEwODIw", "avatar_url": "https://avatars0.githubusercontent.com/u/32110820?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kazemSafari", "html_url": "https://github.com/kazemSafari", "followers_url": "https://api.github.com/users/kazemSafari/followers", "following_url": "https://api.github.com/users/kazemSafari/following{/other_user}", "gists_url": "https://api.github.com/users/kazemSafari/gists{/gist_id}", "starred_url": "https://api.github.com/users/kazemSafari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kazemSafari/subscriptions", "organizations_url": "https://api.github.com/users/kazemSafari/orgs", "repos_url": "https://api.github.com/users/kazemSafari/repos", "events_url": "https://api.github.com/users/kazemSafari/events{/privacy}", "received_events_url": "https://api.github.com/users/kazemSafari/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-04T22:07:14Z", "updated_at": "2018-10-04T22:09:51Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1381301\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ppwwyyxx\">@ppwwyyxx</a> Thank you for sharing the code. Sorry about my comment. I was trying to follow the code you shared on mnist with a simple mlp:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef get_shape(tensor):\n    return tensor.get_shape().as_list()\n\n\n# Source:\n# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\ndef get_available_gpus():\n    \"\"\"\n        Returns a list of the identifiers of all visible GPUs.\n    \"\"\"\n    from tensorflow.python.client import device_lib\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n\n\nPS_OPS = [\n    'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n    'MutableHashTableOfTensors', 'MutableDenseHashTable'\n]\n\n\n# see https://github.com/tensorflow/tensorflow/issues/9517\ndef assign_to_device(device, ps_device):\n    \"\"\"Returns a function to place variables on the ps_device.\n\n    Args:\n        device: Device for everything but variables\n        ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\n\n    If ps_device is not set then the variables will be placed on the default device.\n    The best device for shared varibles depends on the platform as well as the\n    model. Start with CPU:0 and then test GPU:0 to see if there is an\n    improvement.\n    \"\"\"\n    def _assign(op):\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n        if node_def.op in PS_OPS:\n            return ps_device\n        else:\n            return device\n    return _assign\n\n\ndef device_options():\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n    with tf.Session(config=config) as sess:\n        # your code here\n        pass\n\n\n# Source:\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\ndef average_gradients(tower_grads):\n    \"\"\"Calculate the average gradient for each shared variable across all towers.\n    Note that this function provides a synchronization point across all towers.\n    Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\n        over the devices. The inner list ranges over the different variables.\n    Returns:\n            List of pairs of (gradient, variable) where the gradient has been averaged\n            across all towers.\n    \"\"\"\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n\n        # Note that each grad_and_vars looks like the following:\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n        grads = [g for g, _ in grad_and_vars]\n        grad = tf.reduce_mean(grads, 0)\n\n        # Keep in mind that the Variables are redundant because they are shared\n        # across towers. So .. we will just return the first tower's pointer to\n        # the Variable.\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n\n\n# Source\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/utils.py#L140-L170\n#################################\ndef split_grad_list(grad_list):\n    \"\"\"\n    Args:\n        grad_list: K x N x 2\n    Returns:\n        K x N: gradients\n        K x N: variables\n    \"\"\"\n    g = []\n    v = []\n    for tower in grad_list:\n        g.append([x[0] for x in tower])\n        v.append([x[1] for x in tower])\n    print(\"g: \")\n    print(g)\n    print(\"v: \")\n    print(v)\n    return g, v\n\n\ndef merge_grad_list(all_grads, all_vars):\n    \"\"\"\n    Args:\n        all_grads (K x N): gradients\n        all_vars(K x N): variables\n    Return:\n        K x N x 2: list of list of (grad, var) pairs\n    \"\"\"\n    all_towers = [list(zip(gs, vs)) for gs, vs in zip(all_grads, all_vars)]\n    print(\"all_towers: \")\n    print(all_towers)\n    return all_towers\n\n\n**def allreduce_grads(all_grads, average=True):\n    \"\"\"\n    All-reduce average the gradients among K devices. Results are broadcasted to all devices.\n    Args:\n        all_grads (K x N): List of list of gradients. N is the number of variables.\n        average (bool): average gradients or not.\n    Returns:\n        K x N: same as input, but each grad is replaced by the average over K devices.\n    \"\"\"\n    from tensorflow.contrib import nccl\n    nr_tower = len(all_grads)\n    if nr_tower == 1:\n        return all_grads\n    new_all_grads = []  # N x K\n    for grads in zip(*all_grads):\n        print('grads:')\n        print(grads)\n        summed = nccl.all_sum(grads)\n\n        grads_for_devices = []  # K\n        for g in summed:\n            with tf.device(g.device):\n                # tensorflow/benchmarks didn't average gradients\n                if average:\n                    g = tf.multiply(g, 1.0 / nr_tower)\n            grads_for_devices.append(g)\n        new_all_grads.append(grads_for_devices)\n\n    # transpose to K x N\n    ret = list(zip(*new_all_grads))\n    return ret**\n###########################\n\n\n# Source\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/training.py#L240\ndef apply_gradients(opt, grads):\n    devices = get_available_gpus()\n    # num_gpus = len(devices)\n    raw_devices = ['/gpu:{}'.format(k) for k in devices]\n    # optimizer using NCCL\n    train_ops = []\n    with tf.name_scope('apply_gradients'):\n        for idx, grad_and_vars in enumerate(grads):\n            with tf.device(raw_devices[idx]):\n                # apply_gradients may create variables. Make them LOCAL_VARIABLES\n                # with override_to_local_variable(enable=idx &gt; 0):\n                train_ops.append(opt.apply_gradients(\n                    grad_and_vars, name='apply_grad_{}'.format(idx)))\n    train_op = tf.group(*train_ops, name='train_op')\n    return train_op\n\n\ndef create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\"):\n    devices = get_available_gpus()\n    num_gpus = len(devices)\n    # Place all ops on CPU by default\n    # with tf.device('/cpu:0'):\n    tower_grads = []\n    losses = []\n    # tf Graph input\n    # X = tf.placeholder(tf.float32, [None, num_input])\n    # Y = tf.placeholder(tf.float32, [None, num_classes])\n\n    # Split data between GPUs\n    X_s = tf.split(X, num_gpus)\n    Y_s = tf.split(Y, num_gpus)\n    # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    # Get the current variable scope so we can reuse all variables we need once we get\n    # to the second iteration of the loop below\n    with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\n        for i, id in enumerate(devices):\n            name = 'tower_{}'.format(i)\n            # Use the assign_to_device function to ensure that variables are created on the\n            # controller.\n            with tf.device(assign_to_device(id, controller)), tf.name_scope(name):\n\n                _x = X_s[i]\n                _y = Y_s[i]\n\n                logits = mnist_mlp(_x, input_flattened_dim, num_classes)\n\n                # Define loss and optimizer (with train logits, for dropout to take effect)\n                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n                    logits=logits, labels=_y))\n\n                with tf.name_scope(\"compute_gradients\"):\n                    # `compute_gradients` returns a list of (gradient, variable) pairs\n                    grads = optimizer.compute_gradients(loss)\n                    tower_grads.append(grads)\n\n                losses.append(loss)\n                outer_scope.reuse_variables()\n\n    print(tower_grads[0])\n\n    all_grads, all_vars = split_grad_list(tower_grads)\n    all_grads = allreduce_grads(all_grads)\n    tower_grads = merge_grad_list(all_grads, all_vars)\n\n    train_op = apply_gradients(optimizer, tower_grads)\n    # return confusion_mat, equality_op, accuracy_op, train_op\n    return train_op\n\n\ndef mnist_mlp(x, input_flattened_dim, num_classes):\n\n    W = tf.get_variable(name='W1',\n                        shape=[input_flattened_dim, num_classes],\n                        initializer=tf.keras.initializers.glorot_uniform(seed=None),\n                        dtype=tf.float32)\n    b = tf.get_variable(name='b1',\n                        shape=[num_classes],\n                        initializer=tf.zeros_initializer(),\n                        dtype=tf.float32)\n    # Output layer, class prediction\n    logits = tf.nn.relu(tf.matmul(x, W) + b)\n\n    return logits\n\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nprint(x_train.shape)\n\nx_train = np.reshape(x_train, [x_train.shape[0], -1])\nprint(x_train.shape)\nprint(y_train.shape)\n\n\ninput_flattened_dim = 784\nnum_classes = 10\nlearning_rate = .0001\nmax_steps = 100\nbatch_size = 200\nX = tf.placeholder(tf.float32, [None, input_flattened_dim])\nY = tf.placeholder(tf.float32, [None, num_classes])\n\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat(None).batch(batch_size)\nprint(train_dataset)\niterator = train_dataset.make_one_shot_iterator()\n# extract an element\nnext_element = iterator.get_next()\n\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntrain_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(max_steps):\n        batch_x, batch_y = sess.run(next_element)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n</code></pre>\n<p>But I get the following error:</p>\n<pre><code>(60000, 28, 28)\n(60000, 784)\n(60000,)\n&lt;BatchDataset shapes: ((?, 784), (?,)), types: (tf.float64, tf.uint8)&gt;\n2018-10-04 17:02:35.991165: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-10-04 17:02:36.080553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-10-04 17:02:36.080933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\npciBusID: 0000:01:00.0\ntotalMemory: 10.91GiB freeMemory: 10.13GiB\n2018-10-04 17:02:36.154460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-10-04 17:02:36.154821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\npciBusID: 0000:02:00.0\ntotalMemory: 10.92GiB freeMemory: 10.76GiB\n2018-10-04 17:02:36.155558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\n2018-10-04 17:02:36.480714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-04 17:02:36.480738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \n2018-10-04 17:02:36.480743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \n2018-10-04 17:02:36.480746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \n2018-10-04 17:02:36.480964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-10-04 17:02:36.555074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n[(&lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref&gt;), (&lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32&gt;, &lt;tf.Variable 'b1:0' shape=(10,) dtype=float32_ref&gt;)]\ng: \n[[&lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32&gt;], [&lt;tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32&gt;]]\nv: \n[[&lt;tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref&gt;, &lt;tf.Variable 'b1:0' shape=(10,) dtype=float32_ref&gt;], [&lt;tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref&gt;, &lt;tf.Variable 'b1:0' shape=(10,) dtype=float32_ref&gt;]]\ngrads:\n(&lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32&gt;)\ngrads:\n(&lt;tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32&gt;, &lt;tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32&gt;)\nall_towers: \n[[(&lt;tf.Tensor 'Mul:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref&gt;), (&lt;tf.Tensor 'Mul_2:0' shape=(10,) dtype=float32&gt;, &lt;tf.Variable 'b1:0' shape=(10,) dtype=float32_ref&gt;)], [(&lt;tf.Tensor 'Mul_1:0' shape=(784, 10) dtype=float32&gt;, &lt;tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref&gt;), (&lt;tf.Tensor 'Mul_3:0' shape=(10,) dtype=float32&gt;, &lt;tf.Variable 'b1:0' shape=(10,) dtype=float32_ref&gt;)]]\n2018-10-04 17:02:38.038636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\n2018-10-04 17:02:38.038690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-04 17:02:38.038695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \n2018-10-04 17:02:38.038699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \n2018-10-04 17:02:38.038701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \n2018-10-04 17:02:38.038823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-10-04 17:02:38.038988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 270, in &lt;module&gt;\n    train_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 220, in create_parallel_optimization\n    train_op = apply_gradients(optimizer, tower_grads)\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 164, in apply_gradients\n    with tf.device(raw_devices[idx]):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 4085, in device\n    device_function = pydev.merge_device(device_name_or_function)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 284, in merge_device\n    spec = DeviceSpec.from_string(spec or \"\")\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 230, in from_string\n    return DeviceSpec().parse_from_string(spec)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 165, in parse_from_string\n    self.device_index = int(y[1])\n**ValueError: invalid literal for int() with base 10:** ''\n</code></pre>\n<p>Could you provide me with a simple example of using all_reduce. Thanks again.</p>", "body_text": "@ppwwyyxx Thank you for sharing the code. Sorry about my comment. I was trying to follow the code you shared on mnist with a simple mlp:\nimport tensorflow as tf\nimport numpy as np\n\ndef get_shape(tensor):\n    return tensor.get_shape().as_list()\n\n\n# Source:\n# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\ndef get_available_gpus():\n    \"\"\"\n        Returns a list of the identifiers of all visible GPUs.\n    \"\"\"\n    from tensorflow.python.client import device_lib\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n\n\nPS_OPS = [\n    'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n    'MutableHashTableOfTensors', 'MutableDenseHashTable'\n]\n\n\n# see https://github.com/tensorflow/tensorflow/issues/9517\ndef assign_to_device(device, ps_device):\n    \"\"\"Returns a function to place variables on the ps_device.\n\n    Args:\n        device: Device for everything but variables\n        ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\n\n    If ps_device is not set then the variables will be placed on the default device.\n    The best device for shared varibles depends on the platform as well as the\n    model. Start with CPU:0 and then test GPU:0 to see if there is an\n    improvement.\n    \"\"\"\n    def _assign(op):\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n        if node_def.op in PS_OPS:\n            return ps_device\n        else:\n            return device\n    return _assign\n\n\ndef device_options():\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n    with tf.Session(config=config) as sess:\n        # your code here\n        pass\n\n\n# Source:\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\ndef average_gradients(tower_grads):\n    \"\"\"Calculate the average gradient for each shared variable across all towers.\n    Note that this function provides a synchronization point across all towers.\n    Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\n        over the devices. The inner list ranges over the different variables.\n    Returns:\n            List of pairs of (gradient, variable) where the gradient has been averaged\n            across all towers.\n    \"\"\"\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n\n        # Note that each grad_and_vars looks like the following:\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n        grads = [g for g, _ in grad_and_vars]\n        grad = tf.reduce_mean(grads, 0)\n\n        # Keep in mind that the Variables are redundant because they are shared\n        # across towers. So .. we will just return the first tower's pointer to\n        # the Variable.\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n\n\n# Source\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/utils.py#L140-L170\n#################################\ndef split_grad_list(grad_list):\n    \"\"\"\n    Args:\n        grad_list: K x N x 2\n    Returns:\n        K x N: gradients\n        K x N: variables\n    \"\"\"\n    g = []\n    v = []\n    for tower in grad_list:\n        g.append([x[0] for x in tower])\n        v.append([x[1] for x in tower])\n    print(\"g: \")\n    print(g)\n    print(\"v: \")\n    print(v)\n    return g, v\n\n\ndef merge_grad_list(all_grads, all_vars):\n    \"\"\"\n    Args:\n        all_grads (K x N): gradients\n        all_vars(K x N): variables\n    Return:\n        K x N x 2: list of list of (grad, var) pairs\n    \"\"\"\n    all_towers = [list(zip(gs, vs)) for gs, vs in zip(all_grads, all_vars)]\n    print(\"all_towers: \")\n    print(all_towers)\n    return all_towers\n\n\n**def allreduce_grads(all_grads, average=True):\n    \"\"\"\n    All-reduce average the gradients among K devices. Results are broadcasted to all devices.\n    Args:\n        all_grads (K x N): List of list of gradients. N is the number of variables.\n        average (bool): average gradients or not.\n    Returns:\n        K x N: same as input, but each grad is replaced by the average over K devices.\n    \"\"\"\n    from tensorflow.contrib import nccl\n    nr_tower = len(all_grads)\n    if nr_tower == 1:\n        return all_grads\n    new_all_grads = []  # N x K\n    for grads in zip(*all_grads):\n        print('grads:')\n        print(grads)\n        summed = nccl.all_sum(grads)\n\n        grads_for_devices = []  # K\n        for g in summed:\n            with tf.device(g.device):\n                # tensorflow/benchmarks didn't average gradients\n                if average:\n                    g = tf.multiply(g, 1.0 / nr_tower)\n            grads_for_devices.append(g)\n        new_all_grads.append(grads_for_devices)\n\n    # transpose to K x N\n    ret = list(zip(*new_all_grads))\n    return ret**\n###########################\n\n\n# Source\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/training.py#L240\ndef apply_gradients(opt, grads):\n    devices = get_available_gpus()\n    # num_gpus = len(devices)\n    raw_devices = ['/gpu:{}'.format(k) for k in devices]\n    # optimizer using NCCL\n    train_ops = []\n    with tf.name_scope('apply_gradients'):\n        for idx, grad_and_vars in enumerate(grads):\n            with tf.device(raw_devices[idx]):\n                # apply_gradients may create variables. Make them LOCAL_VARIABLES\n                # with override_to_local_variable(enable=idx > 0):\n                train_ops.append(opt.apply_gradients(\n                    grad_and_vars, name='apply_grad_{}'.format(idx)))\n    train_op = tf.group(*train_ops, name='train_op')\n    return train_op\n\n\ndef create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\"):\n    devices = get_available_gpus()\n    num_gpus = len(devices)\n    # Place all ops on CPU by default\n    # with tf.device('/cpu:0'):\n    tower_grads = []\n    losses = []\n    # tf Graph input\n    # X = tf.placeholder(tf.float32, [None, num_input])\n    # Y = tf.placeholder(tf.float32, [None, num_classes])\n\n    # Split data between GPUs\n    X_s = tf.split(X, num_gpus)\n    Y_s = tf.split(Y, num_gpus)\n    # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    # Get the current variable scope so we can reuse all variables we need once we get\n    # to the second iteration of the loop below\n    with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\n        for i, id in enumerate(devices):\n            name = 'tower_{}'.format(i)\n            # Use the assign_to_device function to ensure that variables are created on the\n            # controller.\n            with tf.device(assign_to_device(id, controller)), tf.name_scope(name):\n\n                _x = X_s[i]\n                _y = Y_s[i]\n\n                logits = mnist_mlp(_x, input_flattened_dim, num_classes)\n\n                # Define loss and optimizer (with train logits, for dropout to take effect)\n                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n                    logits=logits, labels=_y))\n\n                with tf.name_scope(\"compute_gradients\"):\n                    # `compute_gradients` returns a list of (gradient, variable) pairs\n                    grads = optimizer.compute_gradients(loss)\n                    tower_grads.append(grads)\n\n                losses.append(loss)\n                outer_scope.reuse_variables()\n\n    print(tower_grads[0])\n\n    all_grads, all_vars = split_grad_list(tower_grads)\n    all_grads = allreduce_grads(all_grads)\n    tower_grads = merge_grad_list(all_grads, all_vars)\n\n    train_op = apply_gradients(optimizer, tower_grads)\n    # return confusion_mat, equality_op, accuracy_op, train_op\n    return train_op\n\n\ndef mnist_mlp(x, input_flattened_dim, num_classes):\n\n    W = tf.get_variable(name='W1',\n                        shape=[input_flattened_dim, num_classes],\n                        initializer=tf.keras.initializers.glorot_uniform(seed=None),\n                        dtype=tf.float32)\n    b = tf.get_variable(name='b1',\n                        shape=[num_classes],\n                        initializer=tf.zeros_initializer(),\n                        dtype=tf.float32)\n    # Output layer, class prediction\n    logits = tf.nn.relu(tf.matmul(x, W) + b)\n\n    return logits\n\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nprint(x_train.shape)\n\nx_train = np.reshape(x_train, [x_train.shape[0], -1])\nprint(x_train.shape)\nprint(y_train.shape)\n\n\ninput_flattened_dim = 784\nnum_classes = 10\nlearning_rate = .0001\nmax_steps = 100\nbatch_size = 200\nX = tf.placeholder(tf.float32, [None, input_flattened_dim])\nY = tf.placeholder(tf.float32, [None, num_classes])\n\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat(None).batch(batch_size)\nprint(train_dataset)\niterator = train_dataset.make_one_shot_iterator()\n# extract an element\nnext_element = iterator.get_next()\n\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntrain_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(max_steps):\n        batch_x, batch_y = sess.run(next_element)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n\nBut I get the following error:\n(60000, 28, 28)\n(60000, 784)\n(60000,)\n<BatchDataset shapes: ((?, 784), (?,)), types: (tf.float64, tf.uint8)>\n2018-10-04 17:02:35.991165: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-10-04 17:02:36.080553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-10-04 17:02:36.080933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\npciBusID: 0000:01:00.0\ntotalMemory: 10.91GiB freeMemory: 10.13GiB\n2018-10-04 17:02:36.154460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-10-04 17:02:36.154821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\npciBusID: 0000:02:00.0\ntotalMemory: 10.92GiB freeMemory: 10.76GiB\n2018-10-04 17:02:36.155558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\n2018-10-04 17:02:36.480714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-04 17:02:36.480738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \n2018-10-04 17:02:36.480743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \n2018-10-04 17:02:36.480746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \n2018-10-04 17:02:36.480964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-10-04 17:02:36.555074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n[(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]\ng: \n[[<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>], [<tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>]]\nv: \n[[<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>], [<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>]]\ngrads:\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>)\ngrads:\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>)\nall_towers: \n[[(<tf.Tensor 'Mul:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_2:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)], [(<tf.Tensor 'Mul_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_3:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]]\n2018-10-04 17:02:38.038636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\n2018-10-04 17:02:38.038690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-04 17:02:38.038695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \n2018-10-04 17:02:38.038699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \n2018-10-04 17:02:38.038701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \n2018-10-04 17:02:38.038823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-10-04 17:02:38.038988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 270, in <module>\n    train_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 220, in create_parallel_optimization\n    train_op = apply_gradients(optimizer, tower_grads)\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 164, in apply_gradients\n    with tf.device(raw_devices[idx]):\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\n    return next(self.gen)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 4085, in device\n    device_function = pydev.merge_device(device_name_or_function)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 284, in merge_device\n    spec = DeviceSpec.from_string(spec or \"\")\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 230, in from_string\n    return DeviceSpec().parse_from_string(spec)\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 165, in parse_from_string\n    self.device_index = int(y[1])\n**ValueError: invalid literal for int() with base 10:** ''\n\nCould you provide me with a simple example of using all_reduce. Thanks again.", "body": "@ppwwyyxx Thank you for sharing the code. Sorry about my comment. I was trying to follow the code you shared on mnist with a simple mlp:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef get_shape(tensor):\r\n    return tensor.get_shape().as_list()\r\n\r\n\r\n# Source:\r\n# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\r\ndef get_available_gpus():\r\n    \"\"\"\r\n        Returns a list of the identifiers of all visible GPUs.\r\n    \"\"\"\r\n    from tensorflow.python.client import device_lib\r\n    local_device_protos = device_lib.list_local_devices()\r\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\r\n\r\n\r\nPS_OPS = [\r\n    'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\r\n    'MutableHashTableOfTensors', 'MutableDenseHashTable'\r\n]\r\n\r\n\r\n# see https://github.com/tensorflow/tensorflow/issues/9517\r\ndef assign_to_device(device, ps_device):\r\n    \"\"\"Returns a function to place variables on the ps_device.\r\n\r\n    Args:\r\n        device: Device for everything but variables\r\n        ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\r\n\r\n    If ps_device is not set then the variables will be placed on the default device.\r\n    The best device for shared varibles depends on the platform as well as the\r\n    model. Start with CPU:0 and then test GPU:0 to see if there is an\r\n    improvement.\r\n    \"\"\"\r\n    def _assign(op):\r\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\r\n        if node_def.op in PS_OPS:\r\n            return ps_device\r\n        else:\r\n            return device\r\n    return _assign\r\n\r\n\r\ndef device_options():\r\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\r\n    with tf.Session(config=config) as sess:\r\n        # your code here\r\n        pass\r\n\r\n\r\n# Source:\r\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\r\ndef average_gradients(tower_grads):\r\n    \"\"\"Calculate the average gradient for each shared variable across all towers.\r\n    Note that this function provides a synchronization point across all towers.\r\n    Args:\r\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\r\n        over the devices. The inner list ranges over the different variables.\r\n    Returns:\r\n            List of pairs of (gradient, variable) where the gradient has been averaged\r\n            across all towers.\r\n    \"\"\"\r\n    average_grads = []\r\n    for grad_and_vars in zip(*tower_grads):\r\n\r\n        # Note that each grad_and_vars looks like the following:\r\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\r\n        grads = [g for g, _ in grad_and_vars]\r\n        grad = tf.reduce_mean(grads, 0)\r\n\r\n        # Keep in mind that the Variables are redundant because they are shared\r\n        # across towers. So .. we will just return the first tower's pointer to\r\n        # the Variable.\r\n        v = grad_and_vars[0][1]\r\n        grad_and_var = (grad, v)\r\n        average_grads.append(grad_and_var)\r\n    return average_grads\r\n\r\n\r\n# Source\r\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/utils.py#L140-L170\r\n#################################\r\ndef split_grad_list(grad_list):\r\n    \"\"\"\r\n    Args:\r\n        grad_list: K x N x 2\r\n    Returns:\r\n        K x N: gradients\r\n        K x N: variables\r\n    \"\"\"\r\n    g = []\r\n    v = []\r\n    for tower in grad_list:\r\n        g.append([x[0] for x in tower])\r\n        v.append([x[1] for x in tower])\r\n    print(\"g: \")\r\n    print(g)\r\n    print(\"v: \")\r\n    print(v)\r\n    return g, v\r\n\r\n\r\ndef merge_grad_list(all_grads, all_vars):\r\n    \"\"\"\r\n    Args:\r\n        all_grads (K x N): gradients\r\n        all_vars(K x N): variables\r\n    Return:\r\n        K x N x 2: list of list of (grad, var) pairs\r\n    \"\"\"\r\n    all_towers = [list(zip(gs, vs)) for gs, vs in zip(all_grads, all_vars)]\r\n    print(\"all_towers: \")\r\n    print(all_towers)\r\n    return all_towers\r\n\r\n\r\n**def allreduce_grads(all_grads, average=True):\r\n    \"\"\"\r\n    All-reduce average the gradients among K devices. Results are broadcasted to all devices.\r\n    Args:\r\n        all_grads (K x N): List of list of gradients. N is the number of variables.\r\n        average (bool): average gradients or not.\r\n    Returns:\r\n        K x N: same as input, but each grad is replaced by the average over K devices.\r\n    \"\"\"\r\n    from tensorflow.contrib import nccl\r\n    nr_tower = len(all_grads)\r\n    if nr_tower == 1:\r\n        return all_grads\r\n    new_all_grads = []  # N x K\r\n    for grads in zip(*all_grads):\r\n        print('grads:')\r\n        print(grads)\r\n        summed = nccl.all_sum(grads)\r\n\r\n        grads_for_devices = []  # K\r\n        for g in summed:\r\n            with tf.device(g.device):\r\n                # tensorflow/benchmarks didn't average gradients\r\n                if average:\r\n                    g = tf.multiply(g, 1.0 / nr_tower)\r\n            grads_for_devices.append(g)\r\n        new_all_grads.append(grads_for_devices)\r\n\r\n    # transpose to K x N\r\n    ret = list(zip(*new_all_grads))\r\n    return ret**\r\n###########################\r\n\r\n\r\n# Source\r\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/training.py#L240\r\ndef apply_gradients(opt, grads):\r\n    devices = get_available_gpus()\r\n    # num_gpus = len(devices)\r\n    raw_devices = ['/gpu:{}'.format(k) for k in devices]\r\n    # optimizer using NCCL\r\n    train_ops = []\r\n    with tf.name_scope('apply_gradients'):\r\n        for idx, grad_and_vars in enumerate(grads):\r\n            with tf.device(raw_devices[idx]):\r\n                # apply_gradients may create variables. Make them LOCAL_VARIABLES\r\n                # with override_to_local_variable(enable=idx > 0):\r\n                train_ops.append(opt.apply_gradients(\r\n                    grad_and_vars, name='apply_grad_{}'.format(idx)))\r\n    train_op = tf.group(*train_ops, name='train_op')\r\n    return train_op\r\n\r\n\r\ndef create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\"):\r\n    devices = get_available_gpus()\r\n    num_gpus = len(devices)\r\n    # Place all ops on CPU by default\r\n    # with tf.device('/cpu:0'):\r\n    tower_grads = []\r\n    losses = []\r\n    # tf Graph input\r\n    # X = tf.placeholder(tf.float32, [None, num_input])\r\n    # Y = tf.placeholder(tf.float32, [None, num_classes])\r\n\r\n    # Split data between GPUs\r\n    X_s = tf.split(X, num_gpus)\r\n    Y_s = tf.split(Y, num_gpus)\r\n    # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\r\n    # Get the current variable scope so we can reuse all variables we need once we get\r\n    # to the second iteration of the loop below\r\n    with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\r\n        for i, id in enumerate(devices):\r\n            name = 'tower_{}'.format(i)\r\n            # Use the assign_to_device function to ensure that variables are created on the\r\n            # controller.\r\n            with tf.device(assign_to_device(id, controller)), tf.name_scope(name):\r\n\r\n                _x = X_s[i]\r\n                _y = Y_s[i]\r\n\r\n                logits = mnist_mlp(_x, input_flattened_dim, num_classes)\r\n\r\n                # Define loss and optimizer (with train logits, for dropout to take effect)\r\n                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\r\n                    logits=logits, labels=_y))\r\n\r\n                with tf.name_scope(\"compute_gradients\"):\r\n                    # `compute_gradients` returns a list of (gradient, variable) pairs\r\n                    grads = optimizer.compute_gradients(loss)\r\n                    tower_grads.append(grads)\r\n\r\n                losses.append(loss)\r\n                outer_scope.reuse_variables()\r\n\r\n    print(tower_grads[0])\r\n\r\n    all_grads, all_vars = split_grad_list(tower_grads)\r\n    all_grads = allreduce_grads(all_grads)\r\n    tower_grads = merge_grad_list(all_grads, all_vars)\r\n\r\n    train_op = apply_gradients(optimizer, tower_grads)\r\n    # return confusion_mat, equality_op, accuracy_op, train_op\r\n    return train_op\r\n\r\n\r\ndef mnist_mlp(x, input_flattened_dim, num_classes):\r\n\r\n    W = tf.get_variable(name='W1',\r\n                        shape=[input_flattened_dim, num_classes],\r\n                        initializer=tf.keras.initializers.glorot_uniform(seed=None),\r\n                        dtype=tf.float32)\r\n    b = tf.get_variable(name='b1',\r\n                        shape=[num_classes],\r\n                        initializer=tf.zeros_initializer(),\r\n                        dtype=tf.float32)\r\n    # Output layer, class prediction\r\n    logits = tf.nn.relu(tf.matmul(x, W) + b)\r\n\r\n    return logits\r\n\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nprint(x_train.shape)\r\n\r\nx_train = np.reshape(x_train, [x_train.shape[0], -1])\r\nprint(x_train.shape)\r\nprint(y_train.shape)\r\n\r\n\r\ninput_flattened_dim = 784\r\nnum_classes = 10\r\nlearning_rate = .0001\r\nmax_steps = 100\r\nbatch_size = 200\r\nX = tf.placeholder(tf.float32, [None, input_flattened_dim])\r\nY = tf.placeholder(tf.float32, [None, num_classes])\r\n\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat(None).batch(batch_size)\r\nprint(train_dataset)\r\niterator = train_dataset.make_one_shot_iterator()\r\n# extract an element\r\nnext_element = iterator.get_next()\r\n\r\n\r\noptimizer = tf.train.AdamOptimizer(learning_rate)\r\ntrain_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for i in range(max_steps):\r\n        batch_x, batch_y = sess.run(next_element)\r\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\r\n```\r\nBut I get the following error:\r\n```\r\n(60000, 28, 28)\r\n(60000, 784)\r\n(60000,)\r\n<BatchDataset shapes: ((?, 784), (?,)), types: (tf.float64, tf.uint8)>\r\n2018-10-04 17:02:35.991165: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-10-04 17:02:36.080553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-10-04 17:02:36.080933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.13GiB\r\n2018-10-04 17:02:36.154460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-10-04 17:02:36.154821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.76GiB\r\n2018-10-04 17:02:36.155558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n2018-10-04 17:02:36.480714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-04 17:02:36.480738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \r\n2018-10-04 17:02:36.480743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \r\n2018-10-04 17:02:36.480746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \r\n2018-10-04 17:02:36.480964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-10-04 17:02:36.555074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n[(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]\r\ng: \r\n[[<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>], [<tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>]]\r\nv: \r\n[[<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>], [<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>]]\r\ngrads:\r\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>)\r\ngrads:\r\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>)\r\nall_towers: \r\n[[(<tf.Tensor 'Mul:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_2:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)], [(<tf.Tensor 'Mul_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_3:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]]\r\n2018-10-04 17:02:38.038636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n2018-10-04 17:02:38.038690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-04 17:02:38.038695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \r\n2018-10-04 17:02:38.038699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \r\n2018-10-04 17:02:38.038701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \r\n2018-10-04 17:02:38.038823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-10-04 17:02:38.038988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 270, in <module>\r\n    train_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 220, in create_parallel_optimization\r\n    train_op = apply_gradients(optimizer, tower_grads)\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 164, in apply_gradients\r\n    with tf.device(raw_devices[idx]):\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 4085, in device\r\n    device_function = pydev.merge_device(device_name_or_function)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 284, in merge_device\r\n    spec = DeviceSpec.from_string(spec or \"\")\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 230, in from_string\r\n    return DeviceSpec().parse_from_string(spec)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 165, in parse_from_string\r\n    self.device_index = int(y[1])\r\n**ValueError: invalid literal for int() with base 10:** ''\r\n```\r\n\r\nCould you provide me with a simple example of using all_reduce. Thanks again."}