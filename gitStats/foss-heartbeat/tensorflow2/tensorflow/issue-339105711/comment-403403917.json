{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/403403917", "html_url": "https://github.com/tensorflow/tensorflow/issues/20605#issuecomment-403403917", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20605", "id": 403403917, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzQwMzkxNw==", "user": {"login": "1icas", "id": 20149552, "node_id": "MDQ6VXNlcjIwMTQ5NTUy", "avatar_url": "https://avatars2.githubusercontent.com/u/20149552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/1icas", "html_url": "https://github.com/1icas", "followers_url": "https://api.github.com/users/1icas/followers", "following_url": "https://api.github.com/users/1icas/following{/other_user}", "gists_url": "https://api.github.com/users/1icas/gists{/gist_id}", "starred_url": "https://api.github.com/users/1icas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/1icas/subscriptions", "organizations_url": "https://api.github.com/users/1icas/orgs", "repos_url": "https://api.github.com/users/1icas/repos", "events_url": "https://api.github.com/users/1icas/events{/privacy}", "received_events_url": "https://api.github.com/users/1icas/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-09T08:38:44Z", "updated_at": "2018-07-09T09:00:04Z", "author_association": "NONE", "body_html": "<p>well,I don't know it's a bug or my fault when i  roughed read the paper (Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference) today . I will describe the problem detailed.</p>\n<p>standard mobilenet-v1 structure:  depthwise conv - bn - relu - pointwise conv - bn - relu</p>\n<p>my model structure: depthwise conv - pointwise conv - bn - relu</p>\n<p>So, i changed my model structure to the standard mobilenet-v1 structure.  Problem solved.</p>\n<p>It looks like that i need the standard mobilenet-v1 structure which i want to quantize the model.</p>\n<p>I read the paper 'Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference' today. The paper said that we can quantize the  conv layer without a bn.</p>\n<p>So it's a bug or that we must add a bn/relu layer after the conv layer which we want to quantize.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suharshs\">@suharshs</a> looking forward to your reply.</p>", "body_text": "well,I don't know it's a bug or my fault when i  roughed read the paper (Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference) today . I will describe the problem detailed.\nstandard mobilenet-v1 structure:  depthwise conv - bn - relu - pointwise conv - bn - relu\nmy model structure: depthwise conv - pointwise conv - bn - relu\nSo, i changed my model structure to the standard mobilenet-v1 structure.  Problem solved.\nIt looks like that i need the standard mobilenet-v1 structure which i want to quantize the model.\nI read the paper 'Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference' today. The paper said that we can quantize the  conv layer without a bn.\nSo it's a bug or that we must add a bn/relu layer after the conv layer which we want to quantize.\n@suharshs looking forward to your reply.", "body": "well,I don't know it's a bug or my fault when i  roughed read the paper (Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference) today . I will describe the problem detailed.\r\n\r\nstandard mobilenet-v1 structure:  depthwise conv - bn - relu - pointwise conv - bn - relu\r\n\r\nmy model structure: depthwise conv - pointwise conv - bn - relu \r\n\r\nSo, i changed my model structure to the standard mobilenet-v1 structure.  Problem solved.\r\n\r\nIt looks like that i need the standard mobilenet-v1 structure which i want to quantize the model.\r\n\r\nI read the paper 'Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference' today. The paper said that we can quantize the  conv layer without a bn. \r\n\r\nSo it's a bug or that we must add a bn/relu layer after the conv layer which we want to quantize.\r\n\r\n@suharshs looking forward to your reply.\r\n"}