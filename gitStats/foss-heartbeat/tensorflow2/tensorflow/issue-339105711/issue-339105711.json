{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20605", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20605/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20605/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20605/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20605", "id": 339105711, "node_id": "MDU6SXNzdWUzMzkxMDU3MTE=", "number": 20605, "title": "Quantize: lacking min/max data, when i transform the quantize graph to tflite", "user": {"login": "1icas", "id": 20149552, "node_id": "MDQ6VXNlcjIwMTQ5NTUy", "avatar_url": "https://avatars2.githubusercontent.com/u/20149552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/1icas", "html_url": "https://github.com/1icas", "followers_url": "https://api.github.com/users/1icas/followers", "following_url": "https://api.github.com/users/1icas/following{/other_user}", "gists_url": "https://api.github.com/users/1icas/gists{/gist_id}", "starred_url": "https://api.github.com/users/1icas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/1icas/subscriptions", "organizations_url": "https://api.github.com/users/1icas/orgs", "repos_url": "https://api.github.com/users/1icas/repos", "events_url": "https://api.github.com/users/1icas/events{/privacy}", "received_events_url": "https://api.github.com/users/1icas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-07-07T01:10:54Z", "updated_at": "2018-07-12T08:39:01Z", "closed_at": "2018-07-07T08:07:58Z", "author_association": "NONE", "body_html": "<p>tensorflow version: 1.8<br>\nmodel: my model structure is very simliar to mobilenet-v1<br>\ndesc: I trained my model use the tf.contrib.quantize.create_training_graph function, and call the tf.contrib.quantize.create_eval_graph() when i generate the eval graph.<br>\nAnd then I use<br>\nbazel-bin/tensorflow/contrib/lite/toco/toco <br>\n--input_file=/home/admin_pc/model_test/output_quant.pb <br>\n--output_file=/home/admin_pc/model_test/mobilenet_qg.tflite <br>\n--input_fromat=TENSORFLOW_GRAPHDEF <br>\n--output_format=TFLITE <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--input_array=image <br>\n--output_array=Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/FusedBatchNorm <br>\n--input_shape=1,224,224,3 <br>\n--change_concat_input_ranges=false <br>\n--std_value=128 --mean_value=128<br>\nto generate the tflite</p>\n<p>but some errores occurs:</p>\n<p>2018-07-07 12:34:56.116401: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 58 operators, 169 arrays (1 quantized)<br>\n2018-07-07 12:34:56.117540: F tensorflow/contrib/lite/toco/tooling_util.cc:1581] Array MobilenetV1/Conv2d_1_depthwise/depthwise, which is an input to the Conv operator producing the output array MobilenetV1/Conv2d_1_pointwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.<br>\nAborted (core dumped)</p>", "body_text": "tensorflow version: 1.8\nmodel: my model structure is very simliar to mobilenet-v1\ndesc: I trained my model use the tf.contrib.quantize.create_training_graph function, and call the tf.contrib.quantize.create_eval_graph() when i generate the eval graph.\nAnd then I use\nbazel-bin/tensorflow/contrib/lite/toco/toco \n--input_file=/home/admin_pc/model_test/output_quant.pb \n--output_file=/home/admin_pc/model_test/mobilenet_qg.tflite \n--input_fromat=TENSORFLOW_GRAPHDEF \n--output_format=TFLITE \n--inference_type=QUANTIZED_UINT8 \n--input_array=image \n--output_array=Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/FusedBatchNorm \n--input_shape=1,224,224,3 \n--change_concat_input_ranges=false \n--std_value=128 --mean_value=128\nto generate the tflite\nbut some errores occurs:\n2018-07-07 12:34:56.116401: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 58 operators, 169 arrays (1 quantized)\n2018-07-07 12:34:56.117540: F tensorflow/contrib/lite/toco/tooling_util.cc:1581] Array MobilenetV1/Conv2d_1_depthwise/depthwise, which is an input to the Conv operator producing the output array MobilenetV1/Conv2d_1_pointwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\nAborted (core dumped)", "body": "tensorflow version: 1.8\r\nmodel: my model structure is very simliar to mobilenet-v1\r\ndesc: I trained my model use the tf.contrib.quantize.create_training_graph function, and call the tf.contrib.quantize.create_eval_graph() when i generate the eval graph.\r\nAnd then I use \r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n--input_file=/home/admin_pc/model_test/output_quant.pb \\\r\n--output_file=/home/admin_pc/model_test/mobilenet_qg.tflite \\\r\n--input_fromat=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_array=image \\\r\n--output_array=Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/FusedBatchNorm \\\r\n--input_shape=1,224,224,3 \\\r\n--change_concat_input_ranges=false \\\r\n--std_value=128 --mean_value=128\r\nto generate the tflite\r\n\r\nbut some errores occurs:\r\n\r\n2018-07-07 12:34:56.116401: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 58 operators, 169 arrays (1 quantized)\r\n2018-07-07 12:34:56.117540: F tensorflow/contrib/lite/toco/tooling_util.cc:1581] Array MobilenetV1/Conv2d_1_depthwise/depthwise, which is an input to the Conv operator producing the output array MobilenetV1/Conv2d_1_pointwise/Relu6, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n"}