{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/115320702", "pull_request_review_id": 36834484, "id": 115320702, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNTMyMDcwMg==", "diff_hunk": "@@ -38,55 +42,178 @@ class FixedLengthRecordReader : public ReaderBase {\n         hop_bytes_(hop_bytes),\n         env_(env),\n         file_pos_limit_(-1),\n-        record_number_(0) {}\n+        record_number_(0),\n+        encoding_(encoding) {}\n \n   // On success:\n-  // * input_buffer_ != nullptr,\n-  // * input_buffer_->Tell() == header_bytes_\n+  // * buffered_input_stream_ != nullptr,\n+  // * buffered_input_stream_->Tell() == header_bytes_\n   // * file_pos_limit_ == file size - footer_bytes_\n   Status OnWorkStartedLocked() override {\n     record_number_ = 0;\n-    uint64 file_size = 0;\n-    TF_RETURN_IF_ERROR(env_->GetFileSize(current_work(), &file_size));\n-    file_pos_limit_ = file_size - footer_bytes_;\n+    if (encoding_ == \"ZLIB\" || encoding_ == \"GZIP\") {\n+      const io::ZlibCompressionOptions zlib_options =\n+          encoding_ == \"ZLIB\" ?\n+          io::ZlibCompressionOptions::DEFAULT() :\n+          io::ZlibCompressionOptions::GZIP();\n \n-    TF_RETURN_IF_ERROR(env_->NewRandomAccessFile(current_work(), &file_));\n+      file_pos_limit_ = -1;\n+      hop_cache_.clear();\n+      footer_cache_.clear();\n+\n+      TF_RETURN_IF_ERROR(env_->NewRandomAccessFile(current_work(), &file_));\n+      file_stream_.reset(new io::RandomAccessInputStream(file_.get()));\n+      buffered_input_stream_.reset(new io::ZlibInputStream(file_stream_.get(),\n+                                                          (size_t)kBufferSize,\n+                                                          (size_t)kBufferSize,\n+                                                          zlib_options));\n+      TF_RETURN_IF_ERROR(buffered_input_stream_->SkipNBytes(header_bytes_));\n+      // The following is similiar to non encoding case except that we also caches\n+      // footer.\n+      // Basically, each read only advances hop_bytes_. However, we have the data\n+      // that is pieced together by\n+      // hop_cache_ + footer_cache_ + read(hop_bytes_)\n+      // Then we use the following to cut data for use:\n+      // value:                     0 --> record_bytes_\n+      // hop_cache_:       hop_bytes_ --> record_bytes_\n+      // footer_cache_: record_bytes_ --> end(record_bytes_ + footer_bytes_)\n+      // Next time we read, we advance hop_bytes_ and append to the end, and\n+      // repeat the same process.\n+      if (0 < hop_bytes_ && hop_bytes_ < record_bytes_) {", "path": "tensorflow/core/kernels/fixed_length_record_reader_op.cc", "position": null, "original_position": 70, "commit_id": "58c7ad730e58a411864bd5b2d24df0a2d2aabc5b", "original_commit_id": "2028de1edc60cc7de1ed4d58afa6c93981126e6d", "user": {"login": "saxenasaurabh", "id": 3967488, "node_id": "MDQ6VXNlcjM5Njc0ODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3967488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saxenasaurabh", "html_url": "https://github.com/saxenasaurabh", "followers_url": "https://api.github.com/users/saxenasaurabh/followers", "following_url": "https://api.github.com/users/saxenasaurabh/following{/other_user}", "gists_url": "https://api.github.com/users/saxenasaurabh/gists{/gist_id}", "starred_url": "https://api.github.com/users/saxenasaurabh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saxenasaurabh/subscriptions", "organizations_url": "https://api.github.com/users/saxenasaurabh/orgs", "repos_url": "https://api.github.com/users/saxenasaurabh/repos", "events_url": "https://api.github.com/users/saxenasaurabh/events{/privacy}", "received_events_url": "https://api.github.com/users/saxenasaurabh/received_events", "type": "User", "site_admin": false}, "body": "Thanks for intricately handling hop_bytes and footer_bytes. It may be cleaner to combine the two caches into a `lookahead_cache_` which could be of size `record_bytes_ + footer_bytes`. You could use the same algorithm as you do now i.e. return record_bytes_ from lookahead_cache_ -> shift cache forward by hop_bytes_.", "created_at": "2017-05-08T18:35:17Z", "updated_at": "2017-06-27T00:11:31Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8901#discussion_r115320702", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8901", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/115320702"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8901#discussion_r115320702"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8901"}}, "body_html": "<p>Thanks for intricately handling hop_bytes and footer_bytes. It may be cleaner to combine the two caches into a <code>lookahead_cache_</code> which could be of size <code>record_bytes_ + footer_bytes</code>. You could use the same algorithm as you do now i.e. return record_bytes_ from lookahead_cache_ -&gt; shift cache forward by hop_bytes_.</p>", "body_text": "Thanks for intricately handling hop_bytes and footer_bytes. It may be cleaner to combine the two caches into a lookahead_cache_ which could be of size record_bytes_ + footer_bytes. You could use the same algorithm as you do now i.e. return record_bytes_ from lookahead_cache_ -> shift cache forward by hop_bytes_."}