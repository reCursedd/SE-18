{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2456", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2456/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2456/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2456/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2456", "id": 156112744, "node_id": "MDU6SXNzdWUxNTYxMTI3NDQ=", "number": 2456, "title": "Problem in distributed parameter server", "user": {"login": "perhapszzy", "id": 7953637, "node_id": "MDQ6VXNlcjc5NTM2Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7953637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/perhapszzy", "html_url": "https://github.com/perhapszzy", "followers_url": "https://api.github.com/users/perhapszzy/followers", "following_url": "https://api.github.com/users/perhapszzy/following{/other_user}", "gists_url": "https://api.github.com/users/perhapszzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/perhapszzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/perhapszzy/subscriptions", "organizations_url": "https://api.github.com/users/perhapszzy/orgs", "repos_url": "https://api.github.com/users/perhapszzy/repos", "events_url": "https://api.github.com/users/perhapszzy/events{/privacy}", "received_events_url": "https://api.github.com/users/perhapszzy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-05-21T17:26:48Z", "updated_at": "2017-01-24T22:23:00Z", "closed_at": "2016-05-23T18:50:27Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Running the distributed tensorflow on GCE kubernetes cluster using the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/dist_mnist_test.sh\">demo</a> with the default images.</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Run the demo with <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69\">hidden_units</a> = 100</li>\n<li>Run the demo with  <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69\">hidden_units</a> = 500</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>Restart all the pods (this worked)</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<pre><code>Traceback (most recent call last):\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 203, in main\n    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 685, in prepare_or_wait_for_session\n    config=config, init_feed_dict=self._init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 163, in prepare_session\n    sess.run(init_op, feed_dict=init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]\n     [[Node: layer2/weights/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@layer2/weights/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:ps/replica:0/task:1/cpu:0\"](layer2/weights/Variable, layer2/weights/truncated_normal_S19)]]\nCaused by op u'layer2/weights/Variable/Assign', defined at:\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 157, in main\n    y = nn_layer(hidden1, FLAGS.hidden_units, 10, 'layer2', act=tf.nn.softmax)\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 115, in nn_layer\n    weights = weight_variable([input_dim, output_dim])\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 85, in weight_variable\n    return tf.Variable(initial)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 308, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 40, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p>The error happened at the init time, and it seems that the log suggests the parameter server didn't clean up the information from previous job:</p>\n<pre><code>tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]\n</code></pre>", "body_text": "Environment info\nRunning the distributed tensorflow on GCE kubernetes cluster using the demo with the default images.\nSteps to reproduce\n\nRun the demo with hidden_units = 100\nRun the demo with  hidden_units = 500\n\nWhat have you tried?\n\nRestart all the pods (this worked)\n\nLogs or other output that would be helpful\nTraceback (most recent call last):\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 203, in main\n    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 685, in prepare_or_wait_for_session\n    config=config, init_feed_dict=self._init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 163, in prepare_session\n    sess.run(init_op, feed_dict=init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]\n     [[Node: layer2/weights/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@layer2/weights/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:ps/replica:0/task:1/cpu:0\"](layer2/weights/Variable, layer2/weights/truncated_normal_S19)]]\nCaused by op u'layer2/weights/Variable/Assign', defined at:\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 157, in main\n    y = nn_layer(hidden1, FLAGS.hidden_units, 10, 'layer2', act=tf.nn.softmax)\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 115, in nn_layer\n    weights = weight_variable([input_dim, output_dim])\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 85, in weight_variable\n    return tf.Variable(initial)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 308, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 40, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\nThe error happened at the init time, and it seems that the log suggests the parameter server didn't clean up the information from previous job:\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]", "body": "### Environment info\n\nRunning the distributed tensorflow on GCE kubernetes cluster using the [demo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/dist_mnist_test.sh) with the default images.\n### Steps to reproduce\n1. Run the demo with [hidden_units](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69) = 100\n2. Run the demo with  [hidden_units](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69) = 500\n### What have you tried?\n1. Restart all the pods (this worked)\n### Logs or other output that would be helpful\n\n```\nTraceback (most recent call last):\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 203, in main\n    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 685, in prepare_or_wait_for_session\n    config=config, init_feed_dict=self._init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 163, in prepare_session\n    sess.run(init_op, feed_dict=init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]\n     [[Node: layer2/weights/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@layer2/weights/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:ps/replica:0/task:1/cpu:0\"](layer2/weights/Variable, layer2/weights/truncated_normal_S19)]]\nCaused by op u'layer2/weights/Variable/Assign', defined at:\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 250, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 157, in main\n    y = nn_layer(hidden1, FLAGS.hidden_units, 10, 'layer2', act=tf.nn.softmax)\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 115, in nn_layer\n    weights = weight_variable([input_dim, output_dim])\n  File \"/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py\", line 85, in weight_variable\n    return tf.Variable(initial)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 308, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 40, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n```\n\nThe error happened at the init time, and it seems that the log suggests the parameter server didn't clean up the information from previous job:\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]\n```\n"}