{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294316615", "html_url": "https://github.com/tensorflow/tensorflow/issues/9239#issuecomment-294316615", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9239", "id": 294316615, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDMxNjYxNQ==", "user": {"login": "amirj", "id": 1645137, "node_id": "MDQ6VXNlcjE2NDUxMzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1645137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amirj", "html_url": "https://github.com/amirj", "followers_url": "https://api.github.com/users/amirj/followers", "following_url": "https://api.github.com/users/amirj/following{/other_user}", "gists_url": "https://api.github.com/users/amirj/gists{/gist_id}", "starred_url": "https://api.github.com/users/amirj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amirj/subscriptions", "organizations_url": "https://api.github.com/users/amirj/orgs", "repos_url": "https://api.github.com/users/amirj/repos", "events_url": "https://api.github.com/users/amirj/events{/privacy}", "received_events_url": "https://api.github.com/users/amirj/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-15T20:39:13Z", "updated_at": "2017-04-15T20:39:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=49262\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jart\">@jart</a>  The latest Bazel (0.4.5). Here is the complete log:</p>\n<pre><code>amir@tyrion:~/projects/tensorflow$ ./configure \nPlease specify the location of python. [Default is /usr/bin/python]: \nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? [Y/n] \njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\n\nUsing python library path: /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] Y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: \nPlease specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: \nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n.........................\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...........\nINFO: Timeout connecting to https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js\namir@tyrion:~/projects/tensorflow$ \n\n</code></pre>", "body_text": "@jart  The latest Bazel (0.4.5). Here is the complete log:\namir@tyrion:~/projects/tensorflow$ ./configure \nPlease specify the location of python. [Default is /usr/bin/python]: \nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? [Y/n] \njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\n\nUsing python library path: /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] Y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: \nPlease specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: \nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.1\n.........................\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...........\nINFO: Timeout connecting to https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js\namir@tyrion:~/projects/tensorflow$", "body": "@jart  The latest Bazel (0.4.5). Here is the complete log:\r\n\r\n```\r\namir@tyrion:~/projects/tensorflow$ ./configure \r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nDo you wish to use jemalloc as the malloc implementation? [Y/n] \r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] Y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: \r\nPlease specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: \r\nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\n.........................\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n...........\r\nINFO: Timeout connecting to https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js\r\namir@tyrion:~/projects/tensorflow$ \r\n\r\n```"}