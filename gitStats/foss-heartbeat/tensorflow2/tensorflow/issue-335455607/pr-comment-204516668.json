{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204516668", "pull_request_review_id": 139608485, "id": 204516668, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDUxNjY2OA==", "diff_hunk": "@@ -52,7 +52,8 @@ load(\n     \"//third_party/mkl:build_defs.bzl\",\n     \"if_mkl\",\n )\n-load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\", \"if_cuda_is_configured\")\n+load(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm\", \"if_rocm_is_configured\")", "path": "tensorflow/core/kernels/BUILD", "position": null, "original_position": 6, "commit_id": "69d3b8faf41791834301a74a05e288964940427d", "original_commit_id": "4885f5e61c204ddc79d2a48cfe91c6c4b7688b18", "user": {"login": "whchung", "id": 1673574, "node_id": "MDQ6VXNlcjE2NzM1NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1673574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whchung", "html_url": "https://github.com/whchung", "followers_url": "https://api.github.com/users/whchung/followers", "following_url": "https://api.github.com/users/whchung/following{/other_user}", "gists_url": "https://api.github.com/users/whchung/gists{/gist_id}", "starred_url": "https://api.github.com/users/whchung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whchung/subscriptions", "organizations_url": "https://api.github.com/users/whchung/orgs", "repos_url": "https://api.github.com/users/whchung/repos", "events_url": "https://api.github.com/users/whchung/events{/privacy}", "received_events_url": "https://api.github.com/users/whchung/received_events", "type": "User", "site_admin": false}, "body": "@jlebar Unfortunately given how GPU common runtime is designed I think it's hard to let TF be configured and built with both CUDA and ROCm at the same time. In `gpu_device.cc`, `EigenCudaStreamDevice` has a compile-time dependency to CUDA constructs. In my current implementation for ROCm, I renamed `EigenCudaStreamDevice` to `EigenGpuStreamDevice` and use `TENSORFLOW_USE_ROCM` macro to switch to ROCm-functional equivalents.\r\n\r\nFor XLA compiler, it's relatively easy to specify a new set of compiler backend and let it target AMDGPU. But for GPU common runtime, a bigger overhaul might be required if the ultimate goal is to get rid of `--config=cuda`.\r\n\r\nThat said, I believe such effort to modularize TF runtime, should be deferred to future PRs, after we have better consensus on how that be achieved?", "created_at": "2018-07-23T18:54:14Z", "updated_at": "2018-09-06T00:48:23Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204516668", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204516668"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204516668"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=150663\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jlebar\">@jlebar</a> Unfortunately given how GPU common runtime is designed I think it's hard to let TF be configured and built with both CUDA and ROCm at the same time. In <code>gpu_device.cc</code>, <code>EigenCudaStreamDevice</code> has a compile-time dependency to CUDA constructs. In my current implementation for ROCm, I renamed <code>EigenCudaStreamDevice</code> to <code>EigenGpuStreamDevice</code> and use <code>TENSORFLOW_USE_ROCM</code> macro to switch to ROCm-functional equivalents.</p>\n<p>For XLA compiler, it's relatively easy to specify a new set of compiler backend and let it target AMDGPU. But for GPU common runtime, a bigger overhaul might be required if the ultimate goal is to get rid of <code>--config=cuda</code>.</p>\n<p>That said, I believe such effort to modularize TF runtime, should be deferred to future PRs, after we have better consensus on how that be achieved?</p>", "body_text": "@jlebar Unfortunately given how GPU common runtime is designed I think it's hard to let TF be configured and built with both CUDA and ROCm at the same time. In gpu_device.cc, EigenCudaStreamDevice has a compile-time dependency to CUDA constructs. In my current implementation for ROCm, I renamed EigenCudaStreamDevice to EigenGpuStreamDevice and use TENSORFLOW_USE_ROCM macro to switch to ROCm-functional equivalents.\nFor XLA compiler, it's relatively easy to specify a new set of compiler backend and let it target AMDGPU. But for GPU common runtime, a bigger overhaul might be required if the ultimate goal is to get rid of --config=cuda.\nThat said, I believe such effort to modularize TF runtime, should be deferred to future PRs, after we have better consensus on how that be achieved?", "in_reply_to_id": 202820055}