{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204511547", "pull_request_review_id": 139602334, "id": 204511547, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDUxMTU0Nw==", "diff_hunk": "@@ -52,7 +52,8 @@ load(\n     \"//third_party/mkl:build_defs.bzl\",\n     \"if_mkl\",\n )\n-load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\", \"if_cuda_is_configured\")\n+load(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm\", \"if_rocm_is_configured\")", "path": "tensorflow/core/kernels/BUILD", "position": null, "original_position": 6, "commit_id": "69d3b8faf41791834301a74a05e288964940427d", "original_commit_id": "4885f5e61c204ddc79d2a48cfe91c6c4b7688b18", "user": {"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}, "body": "> Are we planning to create the internal equivalents of these macros, just like what we have for CUDA?\r\n\r\nIt's @Artem-B and my opinion that `--config=cuda` (and by corollary `if_cuda`) is a harmful hack.  TF uses it as a switch to say \"build for GPU or not\", but it shouldn't: This should be decided by BUILD rules.  (E.g. you depend on `:tensorflow_cpu` or `:tensorflow_gpu`.)\r\n\r\nThe reason we introduced `--config=cuda` is because at the time, Skylark was missing some features we needed in order to make the toolchain work properly.  We think these features are there now.\r\n\r\nUnfortunately the direction of these patches -- including the Eigen patch -- sort of doubles down on the notion of --config=cuda.  If we can't build a TF which includes both cuda and rocm bits, then we'll effectively never be able to get rid of --config=cuda.\r\n\r\nThat's why in XLA we've insisted that we maintain the ability to build for both cuda and rocm, determined by BUILD dependencies.\r\n\r\nThat said, it's unclear to me what is the alternative to these macros for TF, given that the structure of the rocm Eigen patches does not (?) allow us to build for AMDGPU and NVGPU in the same binary.  So TF may need its own versions of them internally; I don't see how else to do it.", "created_at": "2018-07-23T18:37:22Z", "updated_at": "2018-09-06T00:48:23Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204511547", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204511547"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204511547"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277"}}, "body_html": "<blockquote>\n<p>Are we planning to create the internal equivalents of these macros, just like what we have for CUDA?</p>\n</blockquote>\n<p>It's <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=526795\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Artem-B\">@Artem-B</a> and my opinion that <code>--config=cuda</code> (and by corollary <code>if_cuda</code>) is a harmful hack.  TF uses it as a switch to say \"build for GPU or not\", but it shouldn't: This should be decided by BUILD rules.  (E.g. you depend on <code>:tensorflow_cpu</code> or <code>:tensorflow_gpu</code>.)</p>\n<p>The reason we introduced <code>--config=cuda</code> is because at the time, Skylark was missing some features we needed in order to make the toolchain work properly.  We think these features are there now.</p>\n<p>Unfortunately the direction of these patches -- including the Eigen patch -- sort of doubles down on the notion of --config=cuda.  If we can't build a TF which includes both cuda and rocm bits, then we'll effectively never be able to get rid of --config=cuda.</p>\n<p>That's why in XLA we've insisted that we maintain the ability to build for both cuda and rocm, determined by BUILD dependencies.</p>\n<p>That said, it's unclear to me what is the alternative to these macros for TF, given that the structure of the rocm Eigen patches does not (?) allow us to build for AMDGPU and NVGPU in the same binary.  So TF may need its own versions of them internally; I don't see how else to do it.</p>", "body_text": "Are we planning to create the internal equivalents of these macros, just like what we have for CUDA?\n\nIt's @Artem-B and my opinion that --config=cuda (and by corollary if_cuda) is a harmful hack.  TF uses it as a switch to say \"build for GPU or not\", but it shouldn't: This should be decided by BUILD rules.  (E.g. you depend on :tensorflow_cpu or :tensorflow_gpu.)\nThe reason we introduced --config=cuda is because at the time, Skylark was missing some features we needed in order to make the toolchain work properly.  We think these features are there now.\nUnfortunately the direction of these patches -- including the Eigen patch -- sort of doubles down on the notion of --config=cuda.  If we can't build a TF which includes both cuda and rocm bits, then we'll effectively never be able to get rid of --config=cuda.\nThat's why in XLA we've insisted that we maintain the ability to build for both cuda and rocm, determined by BUILD dependencies.\nThat said, it's unclear to me what is the alternative to these macros for TF, given that the structure of the rocm Eigen patches does not (?) allow us to build for AMDGPU and NVGPU in the same binary.  So TF may need its own versions of them internally; I don't see how else to do it.", "in_reply_to_id": 202820055}