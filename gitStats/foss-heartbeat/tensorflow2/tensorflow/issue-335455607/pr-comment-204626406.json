{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204626406", "pull_request_review_id": 139737744, "id": 204626406, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDYyNjQwNg==", "diff_hunk": "@@ -52,7 +52,8 @@ load(\n     \"//third_party/mkl:build_defs.bzl\",\n     \"if_mkl\",\n )\n-load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\", \"if_cuda_is_configured\")\n+load(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm\", \"if_rocm_is_configured\")", "path": "tensorflow/core/kernels/BUILD", "position": null, "original_position": 6, "commit_id": "69d3b8faf41791834301a74a05e288964940427d", "original_commit_id": "4885f5e61c204ddc79d2a48cfe91c6c4b7688b18", "user": {"login": "Artem-B", "id": 526795, "node_id": "MDQ6VXNlcjUyNjc5NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/526795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Artem-B", "html_url": "https://github.com/Artem-B", "followers_url": "https://api.github.com/users/Artem-B/followers", "following_url": "https://api.github.com/users/Artem-B/following{/other_user}", "gists_url": "https://api.github.com/users/Artem-B/gists{/gist_id}", "starred_url": "https://api.github.com/users/Artem-B/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Artem-B/subscriptions", "organizations_url": "https://api.github.com/users/Artem-B/orgs", "repos_url": "https://api.github.com/users/Artem-B/repos", "events_url": "https://api.github.com/users/Artem-B/events{/privacy}", "received_events_url": "https://api.github.com/users/Artem-B/received_events", "type": "User", "site_admin": false}, "body": "Let me try to clarify the way I'd like to see things working.\r\nThe goal is to be able to build any (and all) variants without specifying any extra bazel flags.\r\nI.e. one should be able to say `bazel  //my_project:app_cuda //my_project:app_rocm //my_project:app_cpu` and get all three executables.\r\n\r\nLet's suppose the app consists of main.cpp, kernel.cu (for CUDA and ROCm) and kernel_cpu.cpp (for CPU-only). All three app variants would use the same main.o, app_cuda will use kernel-cuda.o built from kernel.cu using CUDA-specific options/defines, kernel-rocm.o from kernel.cu using ROCm-specific options/defines and kernel-cpu would be compiled form kernel_cpu.cpp. User should be able to build any combination of them simultaneously. When you change anything in the build system, there's only one build configuration to test. If you've built an app there's no confusion about what it supports (or does not). I can't count number of times when someone attemted to run CPU-only TF and complained that it does not sees the GPUS or ran CUDA-enabled GPU on machine without GPUs and complained that it failed. Single build configuration  also saves on overall build time as the objects that don't care about CUDA/ROCm will be built only once, instead of once per build config. Considering that CUDA files constitute relatively small subset of tensorflow,  the difference is substantial. \r\n\r\n--config=cuda was inherited from internal Google build and exists for number of reasons that are not relevant to open-source tensorflow. I understand that it is convenient to continue adding extra dimensions to config parameters, but now that we're adding support for another accelerator is the good time to make sure we do it right. Maintaining and debugging multiple build configurations is a royal pain. Having single set of build rules for everything makes things somewhat easier to deal with.\r\n", "created_at": "2018-07-24T05:20:39Z", "updated_at": "2018-09-06T00:48:23Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204626406", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/204626406"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20277#discussion_r204626406"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20277"}}, "body_html": "<p>Let me try to clarify the way I'd like to see things working.<br>\nThe goal is to be able to build any (and all) variants without specifying any extra bazel flags.<br>\nI.e. one should be able to say <code>bazel  //my_project:app_cuda //my_project:app_rocm //my_project:app_cpu</code> and get all three executables.</p>\n<p>Let's suppose the app consists of main.cpp, kernel.cu (for CUDA and ROCm) and kernel_cpu.cpp (for CPU-only). All three app variants would use the same main.o, app_cuda will use kernel-cuda.o built from kernel.cu using CUDA-specific options/defines, kernel-rocm.o from kernel.cu using ROCm-specific options/defines and kernel-cpu would be compiled form kernel_cpu.cpp. User should be able to build any combination of them simultaneously. When you change anything in the build system, there's only one build configuration to test. If you've built an app there's no confusion about what it supports (or does not). I can't count number of times when someone attemted to run CPU-only TF and complained that it does not sees the GPUS or ran CUDA-enabled GPU on machine without GPUs and complained that it failed. Single build configuration  also saves on overall build time as the objects that don't care about CUDA/ROCm will be built only once, instead of once per build config. Considering that CUDA files constitute relatively small subset of tensorflow,  the difference is substantial.</p>\n<p>--config=cuda was inherited from internal Google build and exists for number of reasons that are not relevant to open-source tensorflow. I understand that it is convenient to continue adding extra dimensions to config parameters, but now that we're adding support for another accelerator is the good time to make sure we do it right. Maintaining and debugging multiple build configurations is a royal pain. Having single set of build rules for everything makes things somewhat easier to deal with.</p>", "body_text": "Let me try to clarify the way I'd like to see things working.\nThe goal is to be able to build any (and all) variants without specifying any extra bazel flags.\nI.e. one should be able to say bazel  //my_project:app_cuda //my_project:app_rocm //my_project:app_cpu and get all three executables.\nLet's suppose the app consists of main.cpp, kernel.cu (for CUDA and ROCm) and kernel_cpu.cpp (for CPU-only). All three app variants would use the same main.o, app_cuda will use kernel-cuda.o built from kernel.cu using CUDA-specific options/defines, kernel-rocm.o from kernel.cu using ROCm-specific options/defines and kernel-cpu would be compiled form kernel_cpu.cpp. User should be able to build any combination of them simultaneously. When you change anything in the build system, there's only one build configuration to test. If you've built an app there's no confusion about what it supports (or does not). I can't count number of times when someone attemted to run CPU-only TF and complained that it does not sees the GPUS or ran CUDA-enabled GPU on machine without GPUs and complained that it failed. Single build configuration  also saves on overall build time as the objects that don't care about CUDA/ROCm will be built only once, instead of once per build config. Considering that CUDA files constitute relatively small subset of tensorflow,  the difference is substantial.\n--config=cuda was inherited from internal Google build and exists for number of reasons that are not relevant to open-source tensorflow. I understand that it is convenient to continue adding extra dimensions to config parameters, but now that we're adding support for another accelerator is the good time to make sure we do it right. Maintaining and debugging multiple build configurations is a royal pain. Having single set of build rules for everything makes things somewhat easier to deal with.", "in_reply_to_id": 202820055}