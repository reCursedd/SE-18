{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/365512970", "html_url": "https://github.com/tensorflow/tensorflow/issues/7407#issuecomment-365512970", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7407", "id": 365512970, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTUxMjk3MA==", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T06:52:24Z", "updated_at": "2018-02-14T06:52:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have a workaround that makes use of a homemade metric. I just wrapped around the homemade metric with <code>tf.metrics.mean</code> like so:</p>\n<p><code>tf.metrics.mean(tf.reduce_mean(tf.cast(tf.equal(predicted_classes, labels), tf.float32)))</code></p>\n<p>It works but I'm not sure if it outputs the same thing as using tf.metrics.accuracy. If it does output the same thing, it would be possible to use homemade metrics.</p>", "body_text": "I have a workaround that makes use of a homemade metric. I just wrapped around the homemade metric with tf.metrics.mean like so:\ntf.metrics.mean(tf.reduce_mean(tf.cast(tf.equal(predicted_classes, labels), tf.float32)))\nIt works but I'm not sure if it outputs the same thing as using tf.metrics.accuracy. If it does output the same thing, it would be possible to use homemade metrics.", "body": "I have a workaround that makes use of a homemade metric. I just wrapped around the homemade metric with `tf.metrics.mean` like so:\r\n\r\n`tf.metrics.mean(tf.reduce_mean(tf.cast(tf.equal(predicted_classes, labels), tf.float32)))`\r\n\r\nIt works but I'm not sure if it outputs the same thing as using tf.metrics.accuracy. If it does output the same thing, it would be possible to use homemade metrics."}