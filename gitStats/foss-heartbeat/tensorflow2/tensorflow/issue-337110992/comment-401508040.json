{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/401508040", "html_url": "https://github.com/tensorflow/tensorflow/issues/20426#issuecomment-401508040", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20426", "id": 401508040, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTUwODA0MA==", "user": {"login": "tanzhenyu", "id": 15220929, "node_id": "MDQ6VXNlcjE1MjIwOTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15220929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanzhenyu", "html_url": "https://github.com/tanzhenyu", "followers_url": "https://api.github.com/users/tanzhenyu/followers", "following_url": "https://api.github.com/users/tanzhenyu/following{/other_user}", "gists_url": "https://api.github.com/users/tanzhenyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanzhenyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanzhenyu/subscriptions", "organizations_url": "https://api.github.com/users/tanzhenyu/orgs", "repos_url": "https://api.github.com/users/tanzhenyu/repos", "events_url": "https://api.github.com/users/tanzhenyu/events{/privacy}", "received_events_url": "https://api.github.com/users/tanzhenyu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-30T01:24:22Z", "updated_at": "2018-06-30T01:24:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>variable scope are used for prefix in tf variables, but here your intention is to name the layer. One workaround I see is to:</p>\n<p>def conv_block(inputs, filters, kernel_size, strides, scope):<br>\nwith tf.variable_scope(scope):<br>\nx = tf.keras.layers.Conv2D(filters, kernel_size, strides, name=scope + '_conv2d')(inputs)<br>\nx = tf.keras.layers.BatchNormalization(name=scope + '_BN')(x)<br>\nx = tf.keras.layers.Activation(tf.nn.relu6, name=scope + '_relu6')(x)<br>\nreturn x</p>\n<p>If you print the layers names, it should be exactly what you hope for. And if you print the variable names, it should be in the format of scope/layer_name/variable_name</p>", "body_text": "variable scope are used for prefix in tf variables, but here your intention is to name the layer. One workaround I see is to:\ndef conv_block(inputs, filters, kernel_size, strides, scope):\nwith tf.variable_scope(scope):\nx = tf.keras.layers.Conv2D(filters, kernel_size, strides, name=scope + '_conv2d')(inputs)\nx = tf.keras.layers.BatchNormalization(name=scope + '_BN')(x)\nx = tf.keras.layers.Activation(tf.nn.relu6, name=scope + '_relu6')(x)\nreturn x\nIf you print the layers names, it should be exactly what you hope for. And if you print the variable names, it should be in the format of scope/layer_name/variable_name", "body": "variable scope are used for prefix in tf variables, but here your intention is to name the layer. One workaround I see is to:\r\n\r\ndef conv_block(inputs, filters, kernel_size, strides, scope):\r\n    with tf.variable_scope(scope):\r\n        x = tf.keras.layers.Conv2D(filters, kernel_size, strides, name=scope + '_conv2d')(inputs)\r\n        x = tf.keras.layers.BatchNormalization(name=scope + '_BN')(x)\r\n        x = tf.keras.layers.Activation(tf.nn.relu6, name=scope + '_relu6')(x)\r\n        return x\r\n\r\nIf you print the layers names, it should be exactly what you hope for. And if you print the variable names, it should be in the format of scope/layer_name/variable_name "}