{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5722", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5722/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5722/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5722/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5722", "id": 190527877, "node_id": "MDU6SXNzdWUxOTA1Mjc4Nzc=", "number": 5722, "title": "Async prefetching queue data on GPU", "user": {"login": "nmiculinic", "id": 3183610, "node_id": "MDQ6VXNlcjMxODM2MTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/3183610?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmiculinic", "html_url": "https://github.com/nmiculinic", "followers_url": "https://api.github.com/users/nmiculinic/followers", "following_url": "https://api.github.com/users/nmiculinic/following{/other_user}", "gists_url": "https://api.github.com/users/nmiculinic/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmiculinic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmiculinic/subscriptions", "organizations_url": "https://api.github.com/users/nmiculinic/orgs", "repos_url": "https://api.github.com/users/nmiculinic/repos", "events_url": "https://api.github.com/users/nmiculinic/events{/privacy}", "received_events_url": "https://api.github.com/users/nmiculinic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 27, "created_at": "2016-11-19T23:29:33Z", "updated_at": "2017-08-08T20:33:06Z", "closed_at": "2017-06-16T21:15:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For example look at te following code:</p>\n<div class=\"highlight highlight-source-python\"><pre>X <span class=\"pl-k\">=</span> fifo_queue.dequeue_many(<span class=\"pl-c1\">100</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Some queue</span>\n<span class=\"pl-c1\">...</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> some processing</span>\nf  <span class=\"pl-c\"><span class=\"pl-c\">#</span> reslut of computation</span></pre></div>\n<p><code>fifo_queue</code> holds all its variable and data in RAM, that is on CPU since there's no GPU kernel for it (nor for any other queue that I'm aware of.</p>\n<p>However upon running:</p>\n<div class=\"highlight highlight-source-python\"><pre>sess.run(f)</pre></div>\n<p>There's a huge bottleneck for dequeuing and copying data from CPU to GPU which could be done async. Here is example of timeline: <a href=\"http://imgur.com/a/1cGHf\" rel=\"nofollow\">http://imgur.com/a/1cGHf</a></p>\n<p>How can I tell tensorflow to async prefetch data on GPU (for example 3xbatch size examples or something like that) so that I avoid waiting for QueueDequeuMany and MEMCPYHtoD operations? Closest I could find for an answer is <a href=\"http://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer\" rel=\"nofollow\">this</a> stackoverflow post, but it didn't shed enough light on the problem.</p>", "body_text": "For example look at te following code:\nX = fifo_queue.dequeue_many(100) # Some queue\n...  # some processing\nf  # reslut of computation\nfifo_queue holds all its variable and data in RAM, that is on CPU since there's no GPU kernel for it (nor for any other queue that I'm aware of.\nHowever upon running:\nsess.run(f)\nThere's a huge bottleneck for dequeuing and copying data from CPU to GPU which could be done async. Here is example of timeline: http://imgur.com/a/1cGHf\nHow can I tell tensorflow to async prefetch data on GPU (for example 3xbatch size examples or something like that) so that I avoid waiting for QueueDequeuMany and MEMCPYHtoD operations? Closest I could find for an answer is this stackoverflow post, but it didn't shed enough light on the problem.", "body": "For example look at te following code:\r\n```python\r\nX = fifo_queue.dequeue_many(100) # Some queue\r\n...  # some processing\r\nf  # reslut of computation\r\n```\r\n\r\n```fifo_queue``` holds all its variable and data in RAM, that is on CPU since there's no GPU kernel for it (nor for any other queue that I'm aware of.\r\n\r\nHowever upon running:\r\n```python\r\nsess.run(f)\r\n```\r\n\r\nThere's a huge bottleneck for dequeuing and copying data from CPU to GPU which could be done async. Here is example of timeline: http://imgur.com/a/1cGHf\r\n\r\nHow can I tell tensorflow to async prefetch data on GPU (for example 3xbatch size examples or something like that) so that I avoid waiting for QueueDequeuMany and MEMCPYHtoD operations? Closest I could find for an answer is [this](http://stackoverflow.com/questions/38751736/understanding-tensorflow-queues-and-cpu-gpu-transfer) stackoverflow post, but it didn't shed enough light on the problem.\r\n"}