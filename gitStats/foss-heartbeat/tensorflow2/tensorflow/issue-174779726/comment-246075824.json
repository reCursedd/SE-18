{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/246075824", "html_url": "https://github.com/tensorflow/tensorflow/issues/4174#issuecomment-246075824", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4174", "id": 246075824, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NjA3NTgyNA==", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-10T00:42:43Z", "updated_at": "2016-09-10T00:43:48Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11247551\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/admcrae\">@admcrae</a> Sounds great!</p>\n<p>We added C++ kernels for them purely for performance, since they appear often in large DL  models and/or their gradients. For example, div(scalar, tensor) would first broadcast scalar to a tensor then divide the two tensors elementwise, whereas inv(tensor) will apply the unary transformation x = 1/x elementswise. The actual division will of course used vectorized/SIMD instructions on most hardware.</p>", "body_text": "@admcrae Sounds great!\nWe added C++ kernels for them purely for performance, since they appear often in large DL  models and/or their gradients. For example, div(scalar, tensor) would first broadcast scalar to a tensor then divide the two tensors elementwise, whereas inv(tensor) will apply the unary transformation x = 1/x elementswise. The actual division will of course used vectorized/SIMD instructions on most hardware.", "body": "@admcrae Sounds great! \n\nWe added C++ kernels for them purely for performance, since they appear often in large DL  models and/or their gradients. For example, div(scalar, tensor) would first broadcast scalar to a tensor then divide the two tensors elementwise, whereas inv(tensor) will apply the unary transformation x = 1/x elementswise. The actual division will of course used vectorized/SIMD instructions on most hardware.\n"}