{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362421243", "html_url": "https://github.com/tensorflow/tensorflow/issues/8535#issuecomment-362421243", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8535", "id": 362421243, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjQyMTI0Mw==", "user": {"login": "aisuni", "id": 35795681, "node_id": "MDQ6VXNlcjM1Nzk1Njgx", "avatar_url": "https://avatars3.githubusercontent.com/u/35795681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aisuni", "html_url": "https://github.com/aisuni", "followers_url": "https://api.github.com/users/aisuni/followers", "following_url": "https://api.github.com/users/aisuni/following{/other_user}", "gists_url": "https://api.github.com/users/aisuni/gists{/gist_id}", "starred_url": "https://api.github.com/users/aisuni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aisuni/subscriptions", "organizations_url": "https://api.github.com/users/aisuni/orgs", "repos_url": "https://api.github.com/users/aisuni/repos", "events_url": "https://api.github.com/users/aisuni/events{/privacy}", "received_events_url": "https://api.github.com/users/aisuni/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-01T22:19:07Z", "updated_at": "2018-02-01T22:50:48Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a><br>\n<code>scale</code> and <code>offset</code> variables are still in float32 DT.  I am not very familiar with this code path, looking for a solution to overcome this as an end user. Pls. suggest.</p>\n<pre><code>&gt; /opt/python3/cerebras-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py(2285)_fused_batch_norm_v2()```\n</code></pre>\n<pre><code>inputs = tf.layers.batch_normalization( inputs=inputs, axis=3, momentum=_BTN_DECAY, epsilon=_BTN_EPSILON, center=True, scale=True, training=is_training, fused=True)\n</code></pre>\n<p>where input tensor is,</p>\n<pre><code>-&gt; def batch_norm_relu(inputs, is_training, data_format):\n(Pdb) inputs\n&lt;tf.Tensor 'initial_max_pool:0' shape=(64, 56, 56, 64) dtype=float16&gt;```\n</code></pre>\n<p>(Pdb)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 754, in batch_normalization<br>\nreturn layer.apply(inputs, training=training)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 729, in apply<br>\nreturn self.<strong>call</strong>(inputs, *args, **kwargs)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 619, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 489, in call<br>\noutputs = self._fused_batch_norm(inputs, training=training)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 380, in _fused_batch_norm<br>\ntraining, _fused_batch_norm_training, _fused_batch_norm_inference)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond<br>\nreturn fn1()<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 366, in _fused_batch_norm_training<br>\ndata_format=self._data_format)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/nn_impl.py\", line 875, in fused_batch_norm<br>\nname=name)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2296, in _fused_batch_norm_v2<br>\nis_training=is_training, name=name)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 609, in _apply_op_helper<br>\nparam_name=input_name)<br>\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint<br>\n\", \".join(dtypes.as_dtype(x).name for x in allowed_list)))</p>\n<p>TypeError: Value passed to parameter 'scale' has DataType float16 not in list of allowed values: float32```</p>", "body_text": "@reedwm @zheng-xq\nscale and offset variables are still in float32 DT.  I am not very familiar with this code path, looking for a solution to overcome this as an end user. Pls. suggest.\n> /opt/python3/cerebras-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py(2285)_fused_batch_norm_v2()```\n\ninputs = tf.layers.batch_normalization( inputs=inputs, axis=3, momentum=_BTN_DECAY, epsilon=_BTN_EPSILON, center=True, scale=True, training=is_training, fused=True)\n\nwhere input tensor is,\n-> def batch_norm_relu(inputs, is_training, data_format):\n(Pdb) inputs\n<tf.Tensor 'initial_max_pool:0' shape=(64, 56, 56, 64) dtype=float16>```\n\n(Pdb)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 754, in batch_normalization\nreturn layer.apply(inputs, training=training)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 729, in apply\nreturn self.call(inputs, *args, **kwargs)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 619, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 489, in call\noutputs = self._fused_batch_norm(inputs, training=training)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 380, in _fused_batch_norm\ntraining, _fused_batch_norm_training, _fused_batch_norm_inference)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\nreturn fn1()\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 366, in _fused_batch_norm_training\ndata_format=self._data_format)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/nn_impl.py\", line 875, in fused_batch_norm\nname=name)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2296, in _fused_batch_norm_v2\nis_training=is_training, name=name)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 609, in _apply_op_helper\nparam_name=input_name)\nFile \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint\n\", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: Value passed to parameter 'scale' has DataType float16 not in list of allowed values: float32```", "body": "@reedwm @zheng-xq \r\n`scale` and `offset` variables are still in float32 DT.  I am not very familiar with this code path, looking for a solution to overcome this as an end user. Pls. suggest.\r\n```\r\n> /opt/python3/cerebras-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py(2285)_fused_batch_norm_v2()```\r\n```\r\n```\r\ninputs = tf.layers.batch_normalization( inputs=inputs, axis=3, momentum=_BTN_DECAY, epsilon=_BTN_EPSILON, center=True, scale=True, training=is_training, fused=True)\r\n```\r\n\r\nwhere input tensor is,\r\n```\r\n-> def batch_norm_relu(inputs, is_training, data_format):\r\n(Pdb) inputs\r\n<tf.Tensor 'initial_max_pool:0' shape=(64, 56, 56, 64) dtype=float16>```\r\n```\r\n\r\n(Pdb) \r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 754, in batch_normalization\r\n    return layer.apply(inputs, training=training)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 729, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/base.py\", line 619, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 489, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 380, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\r\n    return fn1()\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py\", line 366, in _fused_batch_norm_training\r\n    data_format=self._data_format)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/nn_impl.py\", line 875, in fused_batch_norm\r\n    name=name)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2296, in _fused_batch_norm_v2\r\n    is_training=is_training, name=name)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 609, in _apply_op_helper\r\n    param_name=input_name)\r\n  File \"/opt/python3/aisuni-stable/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint\r\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\n\r\nTypeError: Value passed to parameter 'scale' has DataType float16 not in list of allowed values: float32```"}