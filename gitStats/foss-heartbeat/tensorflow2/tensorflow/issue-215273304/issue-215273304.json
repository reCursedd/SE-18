{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8535", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8535/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8535/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8535/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8535", "id": 215273304, "node_id": "MDU6SXNzdWUyMTUyNzMzMDQ=", "number": 8535, "title": "Feature request: add support for float16/float64 to tf.contrib.layers.batch_norm()", "user": {"login": "jakelee8", "id": 19253212, "node_id": "MDQ6VXNlcjE5MjUzMjEy", "avatar_url": "https://avatars3.githubusercontent.com/u/19253212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakelee8", "html_url": "https://github.com/jakelee8", "followers_url": "https://api.github.com/users/jakelee8/followers", "following_url": "https://api.github.com/users/jakelee8/following{/other_user}", "gists_url": "https://api.github.com/users/jakelee8/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakelee8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakelee8/subscriptions", "organizations_url": "https://api.github.com/users/jakelee8/orgs", "repos_url": "https://api.github.com/users/jakelee8/repos", "events_url": "https://api.github.com/users/jakelee8/events{/privacy}", "received_events_url": "https://api.github.com/users/jakelee8/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 23, "created_at": "2017-03-19T15:56:59Z", "updated_at": "2018-09-04T18:17:38Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.</p>\n<p>For general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><code>tf.contrib.layers.batch_norm</code> does not support <code>float16</code> due to defaulting to <code>dtype=tf.float32</code> for <code>get_variable()</code>.</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/067cba5e4b873829f6cdfa61256079d2cfc45d02/tensorflow/python/layers/normalization.py#L141\">tensorflow/tensorflow/python/layers/normalization.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 141\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/067cba5e4b873829f6cdfa61256079d2cfc45d02\">067cba5</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L141\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"141\"></td>\n          <td id=\"LC141\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c1\">self</span>.moving_mean <span class=\"pl-k\">=</span> vs.get_variable( </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<ul>\n<li>Ubuntu 16.04 Docker container</li>\n<li>Ubuntu 16.10 Docker host</li>\n<li>Dockerfile base <code>nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04</code></li>\n<li>CUDA 8.0.61</li>\n<li>CUDNN 5.1.10</li>\n<li>NVidia driver version 378.13</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>$ uname -a\nLinux 97fca57d7bb6 4.8.0-41-generic <span class=\"pl-c\"><span class=\"pl-c\">#</span>44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</span>\n\n$ ls -l /usr/local/cuda/lib64/libcud<span class=\"pl-k\">*</span>\n-rw-r--r-- 1 root root    556000 Jan 26 23:48 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so -<span class=\"pl-k\">&gt;</span> libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so.8.0 -<span class=\"pl-k\">&gt;</span> libcudart.so.8.0.61\n-rw-r--r-- 1 root root    415432 Jan 26 23:48 /usr/local/cuda/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root root    775162 Jan 26 23:48 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 jake users       13 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so -<span class=\"pl-k\">&gt;</span> libcudnn.so.5\nlrwxrwxrwx 1 jake users       18 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so.5 -<span class=\"pl-k\">&gt;</span> libcudnn.so.5.1.10\n-rwxr-xr-x 1 jake users 84163560 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10\n-rw-r--r-- 1 jake users 70364814 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn_static.a\n\n$ conda -V\nconda 4.3.14</pre></div>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>$ python -c <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>import tensorflow; print(tensorflow.__version__)<span class=\"pl-pds\">\"</span></span>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.1</pre></div>\n<p>Conda <code>environment.yml</code>:</p>\n<div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-ent\">name</span>: <span class=\"pl-s\">root</span>\n\n<span class=\"pl-ent\">channels</span>:\n- <span class=\"pl-s\">defaults</span>\n- <span class=\"pl-s\">conda-forge</span>\n- <span class=\"pl-s\">menpo</span>\n\n<span class=\"pl-ent\">dependencies</span>:\n- <span class=\"pl-s\">ipyparallel==5.2.0</span>\n- <span class=\"pl-s\">opencv3=3.1.0</span>\n- <span class=\"pl-ent\">pip</span>:\n  - <span class=\"pl-s\">keras==1.2.2</span>\n  - <span class=\"pl-s\">pydicom==0.9.9</span>\n  - <span class=\"pl-s\">tensorflow-gpu==1.0.1</span>\n  - <span class=\"pl-s\">tflearn==0.3</span></pre></div>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.layers <span class=\"pl-k\">import</span> batch_norm\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> from normalization import batch_norm</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess, tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu<span class=\"pl-pds\">'</span></span>):\n  inputs <span class=\"pl-k\">=</span> tf.convert_to_tensor([<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">2</span>.], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float16)\n  norm <span class=\"pl-k\">=</span> batch_norm(inputs)\n  sess.run(tf.global_variables_initializer())\n  sess.run(norm)</pre></div>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>\n<pre><code>---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-10-f094f32eca33&gt; in &lt;module&gt;()\n      1 a = tf.convert_to_tensor([1., 2.], dtype=tf.float16)\n----&gt; 2 tf.contrib.layers.batch_norm(a).eval()\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n    175       current_args = current_scope[key_func].copy()\n    176       current_args.update(kwargs)\n--&gt; 177     return func(*args, **current_args)\n    178   _add_op(func)\n    179   setattr(func_with_args, '_key_op', _key_op(func))\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\n    516           _scope=sc,\n    517           _reuse=reuse)\n--&gt; 518       outputs = layer.apply(inputs, training=is_training)\n    519 \n    520       # Add variables to collections.\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\n    301       Output tensor(s).\n    302     \"\"\"\n--&gt; 303     return self.__call__(inputs, **kwargs)\n    304 \n    305 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\n    271             self.build(input_shapes)\n    272           self._built = True\n--&gt; 273         outputs = self.call(inputs, **kwargs)\n    274 \n    275         # Apply activity regularization.\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\n    191       if not self.updates:\n    192         mean_update = moving_averages.assign_moving_average(\n--&gt; 193             self.moving_mean, mean, self.momentum, zero_debias=False)\n    194         variance_update = moving_averages.assign_moving_average(\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\n     70         update_delta = _zero_debias(variable, value, decay)\n     71       else:\n---&gt; 72         update_delta = (variable - value) * decay\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\n     74 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\n    675     def _run_op(a, *args):\n    676       # pylint: disable=protected-access\n--&gt; 677       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n    678     # Propagate __doc__ to wrapper\n    679     try:\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\n    791     with ops.name_scope(None, op_name, [x, y]) as name:\n    792       if not isinstance(y, sparse_tensor.SparseTensor):\n--&gt; 793         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\n    794       return func(x, y, name=name)\n    795 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\n    635       name=name,\n    636       preferred_dtype=preferred_dtype,\n--&gt; 637       as_ref=False)\n    638 \n    639 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\n    700 \n    701         if ret is None:\n--&gt; 702           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    703 \n    704         if ret is NotImplemented:\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\n    573     raise ValueError(\n    574         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\n--&gt; 575         % (dtype.name, t.dtype.name, str(t)))\n    576   return t\n    577 \n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm_2/Reshape_1:0\", shape=(2,), dtype=float16)'\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<p>Use a modified <code>tensorflow/python/layers/normalization.py</code> which passes <code>dtype=inputs.dtype.base_dtype</code>.</p>", "body_text": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\ntf.contrib.layers.batch_norm does not support float16 due to defaulting to dtype=tf.float32 for get_variable().\n\n  \n    \n      tensorflow/tensorflow/python/layers/normalization.py\n    \n    \n         Line 141\n      in\n      067cba5\n    \n    \n    \n    \n\n        \n          \n           self.moving_mean = vs.get_variable( \n        \n    \n  \n\n\nEnvironment info\nOperating System:\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n\nUbuntu 16.04 Docker container\nUbuntu 16.10 Docker host\nDockerfile base nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04\nCUDA 8.0.61\nCUDNN 5.1.10\nNVidia driver version 378.13\n\n$ uname -a\nLinux 97fca57d7bb6 4.8.0-41-generic #44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root    556000 Jan 26 23:48 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\n-rw-r--r-- 1 root root    415432 Jan 26 23:48 /usr/local/cuda/lib64/libcudart.so.8.0.61\n-rw-r--r-- 1 root root    775162 Jan 26 23:48 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 jake users       13 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 jake users       18 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\n-rwxr-xr-x 1 jake users 84163560 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10\n-rw-r--r-- 1 jake users 70364814 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn_static.a\n\n$ conda -V\nconda 4.3.14\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\nThe output of bazel version\n\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n1.0.1\nConda environment.yml:\nname: root\n\nchannels:\n- defaults\n- conda-forge\n- menpo\n\ndependencies:\n- ipyparallel==5.2.0\n- opencv3=3.1.0\n- pip:\n  - keras==1.2.2\n  - pydicom==0.9.9\n  - tensorflow-gpu==1.0.1\n  - tflearn==0.3\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport tensorflow as tf\nfrom tensorflow.contrib.layers import batch_norm\n# from normalization import batch_norm\nwith tf.Session() as sess, tf.device('/cpu'):\n  inputs = tf.convert_to_tensor([1., 2.], dtype=tf.float16)\n  norm = batch_norm(inputs)\n  sess.run(tf.global_variables_initializer())\n  sess.run(norm)\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-10-f094f32eca33> in <module>()\n      1 a = tf.convert_to_tensor([1., 2.], dtype=tf.float16)\n----> 2 tf.contrib.layers.batch_norm(a).eval()\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n    175       current_args = current_scope[key_func].copy()\n    176       current_args.update(kwargs)\n--> 177     return func(*args, **current_args)\n    178   _add_op(func)\n    179   setattr(func_with_args, '_key_op', _key_op(func))\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\n    516           _scope=sc,\n    517           _reuse=reuse)\n--> 518       outputs = layer.apply(inputs, training=is_training)\n    519 \n    520       # Add variables to collections.\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\n    301       Output tensor(s).\n    302     \"\"\"\n--> 303     return self.__call__(inputs, **kwargs)\n    304 \n    305 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\n    271             self.build(input_shapes)\n    272           self._built = True\n--> 273         outputs = self.call(inputs, **kwargs)\n    274 \n    275         # Apply activity regularization.\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\n    191       if not self.updates:\n    192         mean_update = moving_averages.assign_moving_average(\n--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)\n    194         variance_update = moving_averages.assign_moving_average(\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\n     70         update_delta = _zero_debias(variable, value, decay)\n     71       else:\n---> 72         update_delta = (variable - value) * decay\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\n     74 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\n    675     def _run_op(a, *args):\n    676       # pylint: disable=protected-access\n--> 677       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n    678     # Propagate __doc__ to wrapper\n    679     try:\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\n    791     with ops.name_scope(None, op_name, [x, y]) as name:\n    792       if not isinstance(y, sparse_tensor.SparseTensor):\n--> 793         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\n    794       return func(x, y, name=name)\n    795 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\n    635       name=name,\n    636       preferred_dtype=preferred_dtype,\n--> 637       as_ref=False)\n    638 \n    639 \n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\n    700 \n    701         if ret is None:\n--> 702           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    703 \n    704         if ret is NotImplemented:\n\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\n    573     raise ValueError(\n    574         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\n--> 575         % (dtype.name, t.dtype.name, str(t)))\n    576   return t\n    577 \n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm_2/Reshape_1:0\", shape=(2,), dtype=float16)'\n\nWhat other attempted solutions have you tried?\nUse a modified tensorflow/python/layers/normalization.py which passes dtype=inputs.dtype.base_dtype.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n`tf.contrib.layers.batch_norm` does not support `float16` due to defaulting to `dtype=tf.float32` for `get_variable()`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/067cba5e4b873829f6cdfa61256079d2cfc45d02/tensorflow/python/layers/normalization.py#L141\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n- Ubuntu 16.04 Docker container\r\n- Ubuntu 16.10 Docker host\r\n- Dockerfile base `nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04`\r\n- CUDA 8.0.61\r\n- CUDNN 5.1.10\r\n- NVidia driver version 378.13\r\n\r\n```sh\r\n$ uname -a\r\nLinux 97fca57d7bb6 4.8.0-41-generic #44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n$ ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root    556000 Jan 26 23:48 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root        16 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root        19 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root    415432 Jan 26 23:48 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root    775162 Jan 26 23:48 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 jake users       13 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 jake users       18 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\r\n-rwxr-xr-x 1 jake users 84163560 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 jake users 70364814 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\n$ conda -V\r\nconda 4.3.14\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n```sh\r\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n1.0.1\r\n```\r\n\r\nConda `environment.yml`:\r\n\r\n```yaml\r\nname: root\r\n\r\nchannels:\r\n- defaults\r\n- conda-forge\r\n- menpo\r\n\r\ndependencies:\r\n- ipyparallel==5.2.0\r\n- opencv3=3.1.0\r\n- pip:\r\n  - keras==1.2.2\r\n  - pydicom==0.9.9\r\n  - tensorflow-gpu==1.0.1\r\n  - tflearn==0.3\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```py\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.layers import batch_norm\r\n# from normalization import batch_norm\r\nwith tf.Session() as sess, tf.device('/cpu'):\r\n  inputs = tf.convert_to_tensor([1., 2.], dtype=tf.float16)\r\n  norm = batch_norm(inputs)\r\n  sess.run(tf.global_variables_initializer())\r\n  sess.run(norm)\r\n```\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-f094f32eca33> in <module>()\r\n      1 a = tf.convert_to_tensor([1., 2.], dtype=tf.float16)\r\n----> 2 tf.contrib.layers.batch_norm(a).eval()\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    175       current_args = current_scope[key_func].copy()\r\n    176       current_args.update(kwargs)\r\n--> 177     return func(*args, **current_args)\r\n    178   _add_op(func)\r\n    179   setattr(func_with_args, '_key_op', _key_op(func))\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\r\n    516           _scope=sc,\r\n    517           _reuse=reuse)\r\n--> 518       outputs = layer.apply(inputs, training=is_training)\r\n    519 \r\n    520       # Add variables to collections.\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\r\n    301       Output tensor(s).\r\n    302     \"\"\"\r\n--> 303     return self.__call__(inputs, **kwargs)\r\n    304 \r\n    305 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\r\n    271             self.build(input_shapes)\r\n    272           self._built = True\r\n--> 273         outputs = self.call(inputs, **kwargs)\r\n    274 \r\n    275         # Apply activity regularization.\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\r\n    191       if not self.updates:\r\n    192         mean_update = moving_averages.assign_moving_average(\r\n--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)\r\n    194         variance_update = moving_averages.assign_moving_average(\r\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\r\n     70         update_delta = _zero_debias(variable, value, decay)\r\n     71       else:\r\n---> 72         update_delta = (variable - value) * decay\r\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\r\n     74 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\r\n    675     def _run_op(a, *args):\r\n    676       # pylint: disable=protected-access\r\n--> 677       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\r\n    678     # Propagate __doc__ to wrapper\r\n    679     try:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    791     with ops.name_scope(None, op_name, [x, y]) as name:\r\n    792       if not isinstance(y, sparse_tensor.SparseTensor):\r\n--> 793         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n    794       return func(x, y, name=name)\r\n    795 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n    635       name=name,\r\n    636       preferred_dtype=preferred_dtype,\r\n--> 637       as_ref=False)\r\n    638 \r\n    639 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\r\n    700 \r\n    701         if ret is None:\r\n--> 702           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    703 \r\n    704         if ret is NotImplemented:\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    573     raise ValueError(\r\n    574         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\r\n--> 575         % (dtype.name, t.dtype.name, str(t)))\r\n    576   return t\r\n    577 \r\n\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm_2/Reshape_1:0\", shape=(2,), dtype=float16)'\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nUse a modified `tensorflow/python/layers/normalization.py` which passes `dtype=inputs.dtype.base_dtype`.\r\n"}