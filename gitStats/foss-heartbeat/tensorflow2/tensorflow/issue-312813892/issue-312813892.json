{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18376", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18376/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18376/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18376/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18376", "id": 312813892, "node_id": "MDU6SXNzdWUzMTI4MTM4OTI=", "number": 18376, "title": "Tensorflow MNIST Estimator: does the training batch size affect the graph expected input?", "user": {"login": "AndRossi", "id": 6909990, "node_id": "MDQ6VXNlcjY5MDk5OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/6909990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndRossi", "html_url": "https://github.com/AndRossi", "followers_url": "https://api.github.com/users/AndRossi/followers", "following_url": "https://api.github.com/users/AndRossi/following{/other_user}", "gists_url": "https://api.github.com/users/AndRossi/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndRossi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndRossi/subscriptions", "organizations_url": "https://api.github.com/users/AndRossi/orgs", "repos_url": "https://api.github.com/users/AndRossi/repos", "events_url": "https://api.github.com/users/AndRossi/events{/privacy}", "received_events_url": "https://api.github.com/users/AndRossi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-04-10T08:05:20Z", "updated_at": "2018-05-16T00:03:46Z", "closed_at": "2018-05-16T00:03:46Z", "author_association": "NONE", "body_html": "<p>Hello Tensorflow team,</p>\n<p>First of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.</p>\n<p>I am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface.<br>\nThe training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.<br>\nI thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:</p>\n<div class=\"highlight highlight-source-python\"><pre>input_layer <span class=\"pl-k\">=</span> tf.reshape(features[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input_layer<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>Here is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png\"><img src=\"https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>At first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.</p>\n<p>First of all I tried to test my model changing the amount of input samples using the Estimator interface:</p>\n<ul>\n<li>I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).</li>\n<li>I tried to use the estimator.predict method passing a single sample at a time.</li>\n</ul>\n<p>In these cases, everything worked fine.</p>\n<p>After that, I have frozen my model using the \"freeze_graph\" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.<br>\nThis is the code I have used:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> cv2\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">with</span> tf.gfile.GFile(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/my/frozen/model.pb<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rb<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> f:\n    graph_def <span class=\"pl-k\">=</span> tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default() <span class=\"pl-k\">as</span> graph:\n    tf.import_graph_def(graph_def, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>prefix<span class=\"pl-pds\">\"</span></span>)\n\n    <span class=\"pl-k\">for</span> op <span class=\"pl-k\">in</span> graph.get_operations():\n        <span class=\"pl-c1\">print</span>(op.name)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> so far it worked: i was able to print the operation of the MNIST model</span>\n\n    x <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>prefix/input_layer:0<span class=\"pl-pds\">'</span></span>)\n    y <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>prefix/softmax_tensor:0<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n        img <span class=\"pl-k\">=</span> cv2.imread(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/a/mnist/like/image.png<span class=\"pl-pds\">\"</span></span>, cv2.<span class=\"pl-c1\">IMREAD_GRAYSCALE</span>)\n        img <span class=\"pl-k\">=</span> np.asarray(<span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>img<span class=\"pl-k\">/</span><span class=\"pl-c1\">255</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n        img <span class=\"pl-k\">=</span> np.reshape(img, (<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>))\n\n        y_out <span class=\"pl-k\">=</span> sess.run(y, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x: [img]})\n        <span class=\"pl-c1\">print</span>(y_out)</pre></div>\n<p>I got this error: <strong>ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'</strong></p>\n<p>So, I feel that I get problems if I try to use this model without passing through the Estimator interface.<br>\nThis worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).</p>\n<h3>Environment</h3>\n<p><strong>Have I written custom code</strong>: Yes, but only for testing purposes. My model was trained with this <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py\">MNIST tutorial code</a><br>\n<strong>OS Platform and Distribution</strong>: MacOS High Sierra 10.13.3<br>\n<strong>TensorFlow installed from</strong>: pip<br>\n<strong>TensorFlow version</strong>: 1.7<br>\n<strong>Bazel version</strong>: N/A<br>\n<strong>CUDA/cuDNN version</strong>: N/A<br>\n<strong>GPU model and memory</strong>: N/A<br>\n<strong>Exact command to reproduce</strong>: N/A</p>", "body_text": "Hello Tensorflow team,\nFirst of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.\nI am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface.\nThe training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.\nI thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:\ninput_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1], name=\"input_layer\")\nHere is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.\n\nAt first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.\nFirst of all I tried to test my model changing the amount of input samples using the Estimator interface:\n\nI tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).\nI tried to use the estimator.predict method passing a single sample at a time.\n\nIn these cases, everything worked fine.\nAfter that, I have frozen my model using the \"freeze_graph\" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.\nThis is the code I have used:\nimport tensorflow as tf\nimport cv2\nimport numpy as np\n\nwith tf.gfile.GFile(\"/path/to/my/frozen/model.pb\", \"rb\") as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\nwith tf.Graph().as_default() as graph:\n    tf.import_graph_def(graph_def, name=\"prefix\")\n\n    for op in graph.get_operations():\n        print(op.name)\n\n    # so far it worked: i was able to print the operation of the MNIST model\n\n    x = graph.get_tensor_by_name('prefix/input_layer:0')\n    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')\n\n    with tf.Session(graph=graph) as sess:\n        img = cv2.imread(\"/path/to/a/mnist/like/image.png\", cv2.IMREAD_GRAYSCALE)\n        img = np.asarray(1-img/255, dtype=np.float32)\n        img = np.reshape(img, (28, 28, 1))\n\n        y_out = sess.run(y, feed_dict={x: [img]})\n        print(y_out)\nI got this error: ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'\nSo, I feel that I get problems if I try to use this model without passing through the Estimator interface.\nThis worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).\nEnvironment\nHave I written custom code: Yes, but only for testing purposes. My model was trained with this MNIST tutorial code\nOS Platform and Distribution: MacOS High Sierra 10.13.3\nTensorFlow installed from: pip\nTensorFlow version: 1.7\nBazel version: N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A", "body": "Hello Tensorflow team, \r\n\r\nFirst of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.\r\n\r\nI am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface. \r\nThe training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.\r\nI thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:\r\n ```python\r\ninput_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1], name=\"input_layer\")\r\n```\r\n\r\nHere is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.\r\n\r\n![image](https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png)\r\n\r\nAt first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.\r\n\r\nFirst of all I tried to test my model changing the amount of input samples using the Estimator interface:\r\n- I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).\r\n- I tried to use the estimator.predict method passing a single sample at a time.  \r\n\r\nIn these cases, everything worked fine.\r\n\r\nAfter that, I have frozen my model using the \"freeze_graph\" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.\r\nThis is the code I have used:\r\n```python\r\nimport tensorflow as tf\r\nimport cv2\r\nimport numpy as np\r\n\r\nwith tf.gfile.GFile(\"/path/to/my/frozen/model.pb\", \"rb\") as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    tf.import_graph_def(graph_def, name=\"prefix\")\r\n\r\n    for op in graph.get_operations():\r\n        print(op.name)\r\n\r\n    # so far it worked: i was able to print the operation of the MNIST model\r\n\r\n    x = graph.get_tensor_by_name('prefix/input_layer:0')\r\n    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        img = cv2.imread(\"/path/to/a/mnist/like/image.png\", cv2.IMREAD_GRAYSCALE)\r\n        img = np.asarray(1-img/255, dtype=np.float32)\r\n        img = np.reshape(img, (28, 28, 1))\r\n\r\n        y_out = sess.run(y, feed_dict={x: [img]})\r\n        print(y_out)\r\n```\r\n\r\nI got this error: **ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'**\r\n\r\nSo, I feel that I get problems if I try to use this model without passing through the Estimator interface.   \r\nThis worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).\r\n\r\n### Environment\r\n**Have I written custom code**: Yes, but only for testing purposes. My model was trained with this [MNIST tutorial code](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py) \r\n**OS Platform and Distribution**: MacOS High Sierra 10.13.3\r\n**TensorFlow installed from**: pip\r\n**TensorFlow version**: 1.7\r\n**Bazel version**: N/A\r\n**CUDA/cuDNN version**: N/A\r\n**GPU model and memory**: N/A\r\n**Exact command to reproduce**: N/A\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"}