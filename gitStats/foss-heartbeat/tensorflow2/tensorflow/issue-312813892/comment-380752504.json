{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/380752504", "html_url": "https://github.com/tensorflow/tensorflow/issues/18376#issuecomment-380752504", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18376", "id": 380752504, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDc1MjUwNA==", "user": {"login": "AndRossi", "id": 6909990, "node_id": "MDQ6VXNlcjY5MDk5OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/6909990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndRossi", "html_url": "https://github.com/AndRossi", "followers_url": "https://api.github.com/users/AndRossi/followers", "following_url": "https://api.github.com/users/AndRossi/following{/other_user}", "gists_url": "https://api.github.com/users/AndRossi/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndRossi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndRossi/subscriptions", "organizations_url": "https://api.github.com/users/AndRossi/orgs", "repos_url": "https://api.github.com/users/AndRossi/repos", "events_url": "https://api.github.com/users/AndRossi/events{/privacy}", "received_events_url": "https://api.github.com/users/AndRossi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-12T10:17:15Z", "updated_at": "2018-04-12T10:17:15Z", "author_association": "NONE", "body_html": "<p>An update on this issue.</p>\n<p>I have asked the same question on StackOverflow too (<a href=\"https://stackoverflow.com/questions/49740247/tensorflow-mnist-estimator-batch-size-affects-the-graph-expected-input/49780607#49780607\" rel=\"nofollow\">here it is</a>), and I got the advice to use <a href=\"https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\" rel=\"nofollow\"><code>tf.placeholder_with_default</code></a> in addition to tf.reshape.</p>\n<p>In fact, tf.reshape does not seem to discard shape information for tensors when using value -1.<br>\nUsing a placeholder there seems to solve my problem :)</p>\n<p>So, firstly, do you suggest me to use a placeholder in this way? Are there any contraindications I should be aware of?</p>\n<p>Secondly, I suggest you to add this to your <a href=\"https://www.tensorflow.org/tutorials/layers\" rel=\"nofollow\">MNIST tutorial</a> :) .<br>\nIn fact, after learning how tf.reshape really works, the description about it in the tutorial is quite misleading:</p>\n<blockquote>\n<p>Note that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features[\"x\"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features[\"x\"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1].</p>\n</blockquote>\n<p>Maybe you can add a more detailed footnote there?</p>\n<p>Thank you :)</p>", "body_text": "An update on this issue.\nI have asked the same question on StackOverflow too (here it is), and I got the advice to use tf.placeholder_with_default in addition to tf.reshape.\nIn fact, tf.reshape does not seem to discard shape information for tensors when using value -1.\nUsing a placeholder there seems to solve my problem :)\nSo, firstly, do you suggest me to use a placeholder in this way? Are there any contraindications I should be aware of?\nSecondly, I suggest you to add this to your MNIST tutorial :) .\nIn fact, after learning how tf.reshape really works, the description about it in the tutorial is quite misleading:\n\nNote that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features[\"x\"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features[\"x\"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1].\n\nMaybe you can add a more detailed footnote there?\nThank you :)", "body": "An update on this issue.\r\n\r\nI have asked the same question on StackOverflow too ([here it is](https://stackoverflow.com/questions/49740247/tensorflow-mnist-estimator-batch-size-affects-the-graph-expected-input/49780607#49780607)), and I got the advice to use [`tf.placeholder_with_default`](https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default) in addition to tf.reshape. \r\n\r\nIn fact, tf.reshape does not seem to discard shape information for tensors when using value -1.\r\nUsing a placeholder there seems to solve my problem :)\r\n\r\nSo, firstly, do you suggest me to use a placeholder in this way? Are there any contraindications I should be aware of?  \r\n  \r\nSecondly, I suggest you to add this to your [MNIST tutorial](https://www.tensorflow.org/tutorials/layers) :) .\r\nIn fact, after learning how tf.reshape really works, the description about it in the tutorial is quite misleading: \r\n\r\n> Note that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features[\"x\"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features[\"x\"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1].\r\n\r\nMaybe you can add a more detailed footnote there?\r\n\r\nThank you :)\r\n"}