{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/247187237", "html_url": "https://github.com/tensorflow/tensorflow/issues/2987#issuecomment-247187237", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2987", "id": 247187237, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzE4NzIzNw==", "user": {"login": "jstaker7", "id": 1364252, "node_id": "MDQ6VXNlcjEzNjQyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1364252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jstaker7", "html_url": "https://github.com/jstaker7", "followers_url": "https://api.github.com/users/jstaker7/followers", "following_url": "https://api.github.com/users/jstaker7/following{/other_user}", "gists_url": "https://api.github.com/users/jstaker7/gists{/gist_id}", "starred_url": "https://api.github.com/users/jstaker7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jstaker7/subscriptions", "organizations_url": "https://api.github.com/users/jstaker7/orgs", "repos_url": "https://api.github.com/users/jstaker7/repos", "events_url": "https://api.github.com/users/jstaker7/events{/privacy}", "received_events_url": "https://api.github.com/users/jstaker7/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-14T23:23:13Z", "updated_at": "2016-09-14T23:23:13Z", "author_association": "NONE", "body_html": "<p>Just to add my 2 cents; I'm running into a similar issue. My setup includes 4 Titan X GPUs and plenty of CPU/RAM. I'm training two models at a time (each using two GPUs). One model has been training for a long time with consistent times per step. I then start up the second model and things look good for about 1500-3000 steps and both models have consistent training times per step. After a while both models slow down considerably with sporadic training times. I then kill my second model and the first one goes back to fast, consistent time per step. Can't figure out what the problem is, and both my CPU and RAM are not fully utilized.</p>", "body_text": "Just to add my 2 cents; I'm running into a similar issue. My setup includes 4 Titan X GPUs and plenty of CPU/RAM. I'm training two models at a time (each using two GPUs). One model has been training for a long time with consistent times per step. I then start up the second model and things look good for about 1500-3000 steps and both models have consistent training times per step. After a while both models slow down considerably with sporadic training times. I then kill my second model and the first one goes back to fast, consistent time per step. Can't figure out what the problem is, and both my CPU and RAM are not fully utilized.", "body": "Just to add my 2 cents; I'm running into a similar issue. My setup includes 4 Titan X GPUs and plenty of CPU/RAM. I'm training two models at a time (each using two GPUs). One model has been training for a long time with consistent times per step. I then start up the second model and things look good for about 1500-3000 steps and both models have consistent training times per step. After a while both models slow down considerably with sporadic training times. I then kill my second model and the first one goes back to fast, consistent time per step. Can't figure out what the problem is, and both my CPU and RAM are not fully utilized.\n"}