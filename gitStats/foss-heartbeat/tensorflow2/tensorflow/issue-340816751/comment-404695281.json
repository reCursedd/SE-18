{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404695281", "html_url": "https://github.com/tensorflow/tensorflow/pull/20752#issuecomment-404695281", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20752", "id": 404695281, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDY5NTI4MQ==", "user": {"login": "whchung", "id": 1673574, "node_id": "MDQ6VXNlcjE2NzM1NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1673574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/whchung", "html_url": "https://github.com/whchung", "followers_url": "https://api.github.com/users/whchung/followers", "following_url": "https://api.github.com/users/whchung/following{/other_user}", "gists_url": "https://api.github.com/users/whchung/gists{/gist_id}", "starred_url": "https://api.github.com/users/whchung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/whchung/subscriptions", "organizations_url": "https://api.github.com/users/whchung/orgs", "repos_url": "https://api.github.com/users/whchung/repos", "events_url": "https://api.github.com/users/whchung/events{/privacy}", "received_events_url": "https://api.github.com/users/whchung/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-13T01:06:34Z", "updated_at": "2018-07-13T01:06:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=150663\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jlebar\">@jlebar</a> ping. There are rationales behind this PR because there would be quite a few differences between NVPTX and AMDGPU paths:</p>\n<ul>\n<li>NVPTXCompiler and to-be-introduced AMDGPUCompiler uses different triple and datalayout string. Also different StreamExecutor platform ID would be used.</li>\n<li>how libdevice on NVPTX and ROCm Device Libs on AMDGPU are located / linked is slightly different</li>\n<li>HLO module optimization pipeline could be different between NVPTX and AMDGPU as some passes may only be applicable for NVPTX for now</li>\n<li>NVPTX has to deal with ptxas and it's not needed for AMDGPU. On the other hand, AMDGPU uses <code>lld</code> to emit ELF</li>\n</ul>", "body_text": "@jlebar ping. There are rationales behind this PR because there would be quite a few differences between NVPTX and AMDGPU paths:\n\nNVPTXCompiler and to-be-introduced AMDGPUCompiler uses different triple and datalayout string. Also different StreamExecutor platform ID would be used.\nhow libdevice on NVPTX and ROCm Device Libs on AMDGPU are located / linked is slightly different\nHLO module optimization pipeline could be different between NVPTX and AMDGPU as some passes may only be applicable for NVPTX for now\nNVPTX has to deal with ptxas and it's not needed for AMDGPU. On the other hand, AMDGPU uses lld to emit ELF", "body": "@jlebar ping. There are rationales behind this PR because there would be quite a few differences between NVPTX and AMDGPU paths:\r\n\r\n- NVPTXCompiler and to-be-introduced AMDGPUCompiler uses different triple and datalayout string. Also different StreamExecutor platform ID would be used.\r\n- how libdevice on NVPTX and ROCm Device Libs on AMDGPU are located / linked is slightly different\r\n- HLO module optimization pipeline could be different between NVPTX and AMDGPU as some passes may only be applicable for NVPTX for now\r\n- NVPTX has to deal with ptxas and it's not needed for AMDGPU. On the other hand, AMDGPU uses `lld` to emit ELF"}