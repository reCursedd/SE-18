{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17221", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17221/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17221/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17221/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17221", "id": 299719976, "node_id": "MDU6SXNzdWUyOTk3MTk5NzY=", "number": 17221, "title": "tf.contrib.signal.stft: Incompatible gradient shape", "user": {"login": "agrinh", "id": 2157859, "node_id": "MDQ6VXNlcjIxNTc4NTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/2157859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agrinh", "html_url": "https://github.com/agrinh", "followers_url": "https://api.github.com/users/agrinh/followers", "following_url": "https://api.github.com/users/agrinh/following{/other_user}", "gists_url": "https://api.github.com/users/agrinh/gists{/gist_id}", "starred_url": "https://api.github.com/users/agrinh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agrinh/subscriptions", "organizations_url": "https://api.github.com/users/agrinh/orgs", "repos_url": "https://api.github.com/users/agrinh/repos", "events_url": "https://api.github.com/users/agrinh/events{/privacy}", "received_events_url": "https://api.github.com/users/agrinh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-02-23T13:59:24Z", "updated_at": "2018-06-17T18:35:46Z", "closed_at": "2018-06-17T18:30:49Z", "author_association": "NONE", "body_html": "<p><strong>Fails on TF 1.5.0 and 1.6.0rc1</strong></p>\n<p>I need to compute gradients of a signal through a STFT with a smaller frame length than FFT length. Assumed this would truncate the window in the gradient computation or fail on some assertion but this fails ungracefully.</p>\n<h3>Sample code</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">test_gradient_computation</span>(<span class=\"pl-smi\">frame_length</span>, <span class=\"pl-smi\">fft_length</span>):\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-k\">with</span> graph.as_default():\n        x <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">16000</span>], tf.float32)\n        x <span class=\"pl-k\">=</span> tf.contrib.signal.stft(\n            x,\n            <span class=\"pl-v\">frame_length</span><span class=\"pl-k\">=</span>frame_length,\n            <span class=\"pl-v\">frame_step</span><span class=\"pl-k\">=</span>frame_length <span class=\"pl-k\">//</span> <span class=\"pl-c1\">2</span>,\n            <span class=\"pl-v\">fft_length</span><span class=\"pl-k\">=</span>fft_length\n        )\n\n        x <span class=\"pl-k\">=</span> tf.abs(x)\n        y <span class=\"pl-k\">=</span> tf.ones_like(x)\n\n        loss <span class=\"pl-k\">=</span> tf.losses.mean_squared_error(x, y)\n\n        optimizer <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">1e-3</span>)\n        train_op <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n            session.run(tf.global_variables_initializer())\n            session.run(train_op)</pre></div>\n<h3>This works:</h3>\n<div class=\"highlight highlight-source-python\"><pre>n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span>\ntest_gradient_computation(<span class=\"pl-v\">frame_length</span><span class=\"pl-k\">=</span>n, <span class=\"pl-v\">fft_length</span><span class=\"pl-k\">=</span>n)\ntest_gradient_computation(<span class=\"pl-v\">frame_length</span><span class=\"pl-k\">=</span>n, <span class=\"pl-v\">fft_length</span><span class=\"pl-k\">=</span>n<span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>)</pre></div>\n<h3>But this fails:</h3>\n<div class=\"highlight highlight-source-python\"><pre>n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span>\ntest_gradient_computation(<span class=\"pl-v\">frame_length</span><span class=\"pl-k\">=</span>n<span class=\"pl-k\">*</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">fft_length</span><span class=\"pl-k\">=</span>n)</pre></div>\n<blockquote>\n<p>ValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: stft/rfft.  Input index: 0. Original input shape: (1, 14, 2048).  Calculated input gradient shape: (1, 14, 1024)</p>\n</blockquote>", "body_text": "Fails on TF 1.5.0 and 1.6.0rc1\nI need to compute gradients of a signal through a STFT with a smaller frame length than FFT length. Assumed this would truncate the window in the gradient computation or fail on some assertion but this fails ungracefully.\nSample code\ndef test_gradient_computation(frame_length, fft_length):\n    graph = tf.Graph()\n    with graph.as_default():\n        x = tf.get_variable('input', [1, 16000], tf.float32)\n        x = tf.contrib.signal.stft(\n            x,\n            frame_length=frame_length,\n            frame_step=frame_length // 2,\n            fft_length=fft_length\n        )\n\n        x = tf.abs(x)\n        y = tf.ones_like(x)\n\n        loss = tf.losses.mean_squared_error(x, y)\n\n        optimizer = tf.train.GradientDescentOptimizer(1e-3)\n        train_op = optimizer.minimize(loss)\n        with tf.Session() as session:\n            session.run(tf.global_variables_initializer())\n            session.run(train_op)\nThis works:\nn = 1024\ntest_gradient_computation(frame_length=n, fft_length=n)\ntest_gradient_computation(frame_length=n, fft_length=n*2)\nBut this fails:\nn = 1024\ntest_gradient_computation(frame_length=n*2, fft_length=n)\n\nValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: stft/rfft.  Input index: 0. Original input shape: (1, 14, 2048).  Calculated input gradient shape: (1, 14, 1024)", "body": "**Fails on TF 1.5.0 and 1.6.0rc1**\r\n\r\nI need to compute gradients of a signal through a STFT with a smaller frame length than FFT length. Assumed this would truncate the window in the gradient computation or fail on some assertion but this fails ungracefully.\r\n\r\n### Sample code\r\n```python\r\ndef test_gradient_computation(frame_length, fft_length):\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        x = tf.get_variable('input', [1, 16000], tf.float32)\r\n        x = tf.contrib.signal.stft(\r\n            x,\r\n            frame_length=frame_length,\r\n            frame_step=frame_length // 2,\r\n            fft_length=fft_length\r\n        )\r\n\r\n        x = tf.abs(x)\r\n        y = tf.ones_like(x)\r\n\r\n        loss = tf.losses.mean_squared_error(x, y)\r\n\r\n        optimizer = tf.train.GradientDescentOptimizer(1e-3)\r\n        train_op = optimizer.minimize(loss)\r\n        with tf.Session() as session:\r\n            session.run(tf.global_variables_initializer())\r\n            session.run(train_op)\r\n```\r\n\r\n### This works:\r\n```python\r\nn = 1024\r\ntest_gradient_computation(frame_length=n, fft_length=n)\r\ntest_gradient_computation(frame_length=n, fft_length=n*2)\r\n```\r\n\r\n### But this fails:\r\n```python\r\nn = 1024\r\ntest_gradient_computation(frame_length=n*2, fft_length=n)\r\n```\r\n> ValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: stft/rfft.  Input index: 0. Original input shape: (1, 14, 2048).  Calculated input gradient shape: (1, 14, 1024)\r\n\r\n"}