{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145485532", "pull_request_review_id": 70293209, "id": 145485532, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NTQ4NTUzMg==", "diff_hunk": "@@ -129,24 +130,38 @@ namespace functor {\n template <typename T>\n struct DiagFunctor<CPUDevice, T> {\n   EIGEN_ALWAYS_INLINE Status\n-  operator() (const CPUDevice& device, const int64 size,\n-                   const T* in, T* out) {\n-    std::fill(out, out + size * size, T());\n-    for (int64 index = 0; index < size; index++) {\n-      out[(1 + size) * index] = in[index];\n-    }\n+  operator() (OpKernelContext* context, const int64 size,\n+              const T* in, T* out) {\n+    auto subDiag = [in, out, size](int64 start, int64 limit) {\n+      std::fill(out + size * start, out + size * limit, T());\n+      for (int64 index = start; index < limit; ++index) {\n+        out[(1 + size) * index] = in[index];\n+      }\n+    };\n+\n+    // Here, 5 is a empirical factor of cost_per_unit.\n+    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n+    Shard(worker_threads.num_threads, worker_threads.workers, size,\n+        5 * size, subDiag);\n     return Status::OK();\n   }\n };\n \n template <typename T>\n struct DiagPartFunctor<CPUDevice, T> {\n   EIGEN_ALWAYS_INLINE Status\n-  operator() (const CPUDevice& device, const int64 size,\n-                   const T* in, T* out) {\n-    for (int64 index = 0; index < size; index++) {\n-      out[index] = in[(1 + size) * index];\n-    }\n+  operator() (OpKernelContext* context, const int64 size,\n+              const T* in, T* out) {\n+    auto subDiagPart = [in, out, size](int64 start, int64 limit) {", "path": "tensorflow/core/kernels/diag_op.cc", "position": null, "original_position": 63, "commit_id": "dc052299c591bd1b71f48bf5efa0585b5a96350c", "original_commit_id": "7d5e1cee1aa3cf6124c4dd0cee225eeba63be8d2", "user": {"login": "cwhipkey", "id": 17578177, "node_id": "MDQ6VXNlcjE3NTc4MTc3", "avatar_url": "https://avatars0.githubusercontent.com/u/17578177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwhipkey", "html_url": "https://github.com/cwhipkey", "followers_url": "https://api.github.com/users/cwhipkey/followers", "following_url": "https://api.github.com/users/cwhipkey/following{/other_user}", "gists_url": "https://api.github.com/users/cwhipkey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwhipkey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwhipkey/subscriptions", "organizations_url": "https://api.github.com/users/cwhipkey/orgs", "repos_url": "https://api.github.com/users/cwhipkey/repos", "events_url": "https://api.github.com/users/cwhipkey/events{/privacy}", "received_events_url": "https://api.github.com/users/cwhipkey/received_events", "type": "User", "site_admin": false}, "body": "perhaps add one line comment here too (although in this case it's more obvious there isn't a different way of sharding).", "created_at": "2017-10-18T17:29:40Z", "updated_at": "2017-10-18T18:12:19Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13666#discussion_r145485532", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13666", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145485532"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13666#discussion_r145485532"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13666"}}, "body_html": "<p>perhaps add one line comment here too (although in this case it's more obvious there isn't a different way of sharding).</p>", "body_text": "perhaps add one line comment here too (although in this case it's more obvious there isn't a different way of sharding)."}