{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145230184", "pull_request_review_id": 69996662, "id": 145230184, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NTIzMDE4NA==", "diff_hunk": "@@ -160,39 +97,138 @@ class DiagPartOp : public OpKernel {\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, out_shape, &output));\n+    functor::DiagPartFunctor<Device, T> diagPartFunc;\n+    diagPartFunc(context->eigen_device<Device>(),\n+                 out_shape.num_elements(),\n+                 tensor.flat<T>().data(),\n+                 output->flat<T>().data());\n+    return;\n+  }\n+};\n+\n+// Implementation of the functor specialization for CPU.\n+// \n+// According to the diagonal definition,\n+// `output[i1,..., ik, i1,..., ik] = input[i1,..., ik]`,\n+//\n+// Let the rank of input is [s1,..., sk], then any offset of input's\n+// pointer can be represent by coordinate [i1,..., ik],\n+// where `index = i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik`\n+//\n+// Let new_index is the offset of output's pointer with coordinate \n+// [i1,..., ik, i1,..., ik], then we have\n+// `new_index = i1*(s2*...sk*s1*...*sk) + i2*(s3*...*sk*s1*...*sk) +... + \\\n+//              ik*(s1*...*sk) + i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik\n+//            = (i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik) * (1 + s1*...*sk)\n+//            = index * (1 + s1*...*sk)\n+//\n+// Let `size = s1*...*sk`, we finally have `new_index = index * (1 + size)`,\n+// which is the transfer function we use below.\n+// This trick make our implementations clear and easy to be parallel.\n+namespace functor {\n+template <typename T>\n+struct DiagFunctor<CPUDevice, T> {\n+  void operator() (const CPUDevice& device, const int64 size,\n+                   const T* in, T* out) {\n+    std::fill(out, out + size * size, T());\n+    for (int64 index = 0; index < size; index++) {\n+      out[(1 + size) * index] = in[index];\n+    }\n+  }\n+};\n \n-    switch (num_dims) {\n-      case 2:\n-        output->tensor<T, 1>() = output->tensor<T, 1>().generate(\n-          DiagonalExtractor<T, 1>(tensor));\n-        break; \n-      case 4:\n-        output->tensor<T, 2>() = output->tensor<T, 2>().generate(\n-          DiagonalExtractor<T, 2>(tensor));\n-        break;\n-      case 6:\n-        output->tensor<T, 3>() = output->tensor<T, 3>().generate(\n-          DiagonalExtractor<T, 3>(tensor));\n-        break;      \n-      default:\n-        context->SetStatus(errors::Unimplemented(\n-          \"Diagonal of rank \", num_dims, \" tensor is not supported yet.\"));\n-        return;\n+template <typename T>\n+struct DiagPartFunctor<CPUDevice, T> {\n+  void operator() (const CPUDevice& device, const int64 size,\n+                   const T* in, T* out) {\n+    for (int64 index = 0; index < size; index++) {\n+      out[index] = in[(1 + size) * index];\n     }\n   }\n };\n+}  // namespace functor\n+\n \n-#define REGISTER_DIAGPARTOP(T) \\\n-  REGISTER_KERNEL_BUILDER( \\\n-      Name(\"DiagPart\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), DiagPartOp<T>)\n+// Register the CPU kernels.\n+#define REGISTER_DIAGOP(T)                                    \\\n+  REGISTER_KERNEL_BUILDER(                                    \\\n+      Name(\"Diag\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n+      DiagOp<CPUDevice, T>)\n+\n+REGISTER_DIAGOP(double);", "path": "tensorflow/core/kernels/diag_op.cc", "position": null, "original_position": 242, "commit_id": "dc052299c591bd1b71f48bf5efa0585b5a96350c", "original_commit_id": "1784839823d340fc74e7ff45f5019257f4d1bf96", "user": {"login": "cwhipkey", "id": 17578177, "node_id": "MDQ6VXNlcjE3NTc4MTc3", "avatar_url": "https://avatars0.githubusercontent.com/u/17578177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwhipkey", "html_url": "https://github.com/cwhipkey", "followers_url": "https://api.github.com/users/cwhipkey/followers", "following_url": "https://api.github.com/users/cwhipkey/following{/other_user}", "gists_url": "https://api.github.com/users/cwhipkey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwhipkey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwhipkey/subscriptions", "organizations_url": "https://api.github.com/users/cwhipkey/orgs", "repos_url": "https://api.github.com/users/cwhipkey/repos", "events_url": "https://api.github.com/users/cwhipkey/events{/privacy}", "received_events_url": "https://api.github.com/users/cwhipkey/received_events", "type": "User", "site_admin": false}, "body": "could you change these to use the macros from core/framework/register_types.h  (TF_CALL_double, TF_CALL_float, etc.)?  Same for the REGISTER_DIAGPARTOP?", "created_at": "2017-10-17T19:23:43Z", "updated_at": "2017-10-18T18:12:19Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13666#discussion_r145230184", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13666", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145230184"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13666#discussion_r145230184"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13666"}}, "body_html": "<p>could you change these to use the macros from core/framework/register_types.h  (TF_CALL_double, TF_CALL_float, etc.)?  Same for the REGISTER_DIAGPARTOP?</p>", "body_text": "could you change these to use the macros from core/framework/register_types.h  (TF_CALL_double, TF_CALL_float, etc.)?  Same for the REGISTER_DIAGPARTOP?"}