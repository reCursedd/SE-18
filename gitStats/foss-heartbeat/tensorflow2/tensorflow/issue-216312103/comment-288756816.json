{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288756816", "html_url": "https://github.com/tensorflow/tensorflow/issues/8647#issuecomment-288756816", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8647", "id": 288756816, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODc1NjgxNg==", "user": {"login": "zehzhang", "id": 22466285, "node_id": "MDQ6VXNlcjIyNDY2Mjg1", "avatar_url": "https://avatars1.githubusercontent.com/u/22466285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zehzhang", "html_url": "https://github.com/zehzhang", "followers_url": "https://api.github.com/users/zehzhang/followers", "following_url": "https://api.github.com/users/zehzhang/following{/other_user}", "gists_url": "https://api.github.com/users/zehzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/zehzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zehzhang/subscriptions", "organizations_url": "https://api.github.com/users/zehzhang/orgs", "repos_url": "https://api.github.com/users/zehzhang/repos", "events_url": "https://api.github.com/users/zehzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/zehzhang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-23T15:29:43Z", "updated_at": "2017-03-23T15:41:34Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25011496\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jubjamie\">@jubjamie</a><br>\nHere it is (still some cleaning work to do, but enough for debugging :) ):</p>\n<pre><code>from keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Lambda\nfrom keras.models import Model, Sequential\nimport numpy as np\nfrom scipy.misc import imresize\nfrom scipy.misc import imsave\nimport tensorflow as tf\nimport keras.backend as K\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import gen_nn_ops\n\n\n@ops.RegisterGradient(\"GuidedRelu\")\ndef _GuidedReluGrad(op, grad):\n    return tf.select(0. &lt; grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()[1:]))\n\n\ndef target_category_loss(x, category_index, nb_classes):\n    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n\n\ndef target_category_loss_output_shape(input_shape):\n    return input_shape\n\n\ndef normalize(x):\n    # utility function to normalize a tensor by its L2 norm\n    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n\ndef backend_reshape(x):\n    shape = (my_batch_size, img_width, img_height, 3)\n    return K.reshape(x, shape)\n\ndef reproduce(x):\n    return x\n\ntuned_vgg_weights_path = './tuned_vgg_model.h5'\nldir = '/N/u/zehzhang/cogsci16/valid/0/'\nname = '01_20150530_16859_sync_frames_parent_img_06600.jpg'\nimg_path = ldir + name\nimg_width = 224\nimg_height = 224\nmy_batch_size = 1\n\n\nnb_classes = 24\ncategory_index = 0\nlayer_name = 'block5_conv3'\n\n\nwith tf.get_default_graph().gradient_override_map({'Relu': 'GuidedRelu'}):\n    model = Sequential()\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dense(24, activation='relu'))\n    model.add(Activation('softmax'))\n    model.load_weights(tuned_vgg_weights_path)\n    print(model.summary())\n\n\n\nconv_output = [l for l in model.layers[-6].layers if l.name is layer_name][0].output\ngrads = K.gradients(model.layers[-2].output[0, 0], model.layers[-6].layers[-2].output)[0]\n\nimg = load_img(img_path, target_size=(img_width, img_height))\nori_w, ori_h = load_img(img_path).size\n\nimg_array = img_to_array(img)\ngradient_function = K.function([model.layers[0].input], [conv_output, grads])\n\noutput, grads_val = gradient_function([preprocess_input(img_array[np.newaxis, :])])\n</code></pre>", "body_text": "@jubjamie\nHere it is (still some cleaning work to do, but enough for debugging :) ):\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Lambda\nfrom keras.models import Model, Sequential\nimport numpy as np\nfrom scipy.misc import imresize\nfrom scipy.misc import imsave\nimport tensorflow as tf\nimport keras.backend as K\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import gen_nn_ops\n\n\n@ops.RegisterGradient(\"GuidedRelu\")\ndef _GuidedReluGrad(op, grad):\n    return tf.select(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()[1:]))\n\n\ndef target_category_loss(x, category_index, nb_classes):\n    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n\n\ndef target_category_loss_output_shape(input_shape):\n    return input_shape\n\n\ndef normalize(x):\n    # utility function to normalize a tensor by its L2 norm\n    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n\ndef backend_reshape(x):\n    shape = (my_batch_size, img_width, img_height, 3)\n    return K.reshape(x, shape)\n\ndef reproduce(x):\n    return x\n\ntuned_vgg_weights_path = './tuned_vgg_model.h5'\nldir = '/N/u/zehzhang/cogsci16/valid/0/'\nname = '01_20150530_16859_sync_frames_parent_img_06600.jpg'\nimg_path = ldir + name\nimg_width = 224\nimg_height = 224\nmy_batch_size = 1\n\n\nnb_classes = 24\ncategory_index = 0\nlayer_name = 'block5_conv3'\n\n\nwith tf.get_default_graph().gradient_override_map({'Relu': 'GuidedRelu'}):\n    model = Sequential()\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dense(24, activation='relu'))\n    model.add(Activation('softmax'))\n    model.load_weights(tuned_vgg_weights_path)\n    print(model.summary())\n\n\n\nconv_output = [l for l in model.layers[-6].layers if l.name is layer_name][0].output\ngrads = K.gradients(model.layers[-2].output[0, 0], model.layers[-6].layers[-2].output)[0]\n\nimg = load_img(img_path, target_size=(img_width, img_height))\nori_w, ori_h = load_img(img_path).size\n\nimg_array = img_to_array(img)\ngradient_function = K.function([model.layers[0].input], [conv_output, grads])\n\noutput, grads_val = gradient_function([preprocess_input(img_array[np.newaxis, :])])", "body": "@jubjamie \r\nHere it is (still some cleaning work to do, but enough for debugging :) ):\r\n```\r\nfrom keras.applications.vgg16 import VGG16, preprocess_input\r\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Lambda\r\nfrom keras.models import Model, Sequential\r\nimport numpy as np\r\nfrom scipy.misc import imresize\r\nfrom scipy.misc import imsave\r\nimport tensorflow as tf\r\nimport keras.backend as K\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import gen_nn_ops\r\n\r\n\r\n@ops.RegisterGradient(\"GuidedRelu\")\r\ndef _GuidedReluGrad(op, grad):\r\n    return tf.select(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()[1:]))\r\n\r\n\r\ndef target_category_loss(x, category_index, nb_classes):\r\n    return tf.multiply(x, K.one_hot([category_index], nb_classes))\r\n\r\n\r\ndef target_category_loss_output_shape(input_shape):\r\n    return input_shape\r\n\r\n\r\ndef normalize(x):\r\n    # utility function to normalize a tensor by its L2 norm\r\n    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\r\n\r\ndef backend_reshape(x):\r\n    shape = (my_batch_size, img_width, img_height, 3)\r\n    return K.reshape(x, shape)\r\n\r\ndef reproduce(x):\r\n    return x\r\n\r\ntuned_vgg_weights_path = './tuned_vgg_model.h5'\r\nldir = '/N/u/zehzhang/cogsci16/valid/0/'\r\nname = '01_20150530_16859_sync_frames_parent_img_06600.jpg'\r\nimg_path = ldir + name\r\nimg_width = 224\r\nimg_height = 224\r\nmy_batch_size = 1\r\n\r\n\r\nnb_classes = 24\r\ncategory_index = 0\r\nlayer_name = 'block5_conv3'\r\n\r\n\r\nwith tf.get_default_graph().gradient_override_map({'Relu': 'GuidedRelu'}):\r\n    model = Sequential()\r\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\r\n    model.add(base_model)\r\n    model.add(Flatten())\r\n    model.add(Dense(4096, activation='relu'))\r\n    model.add(Dense(4096, activation='relu'))\r\n    model.add(Dense(24, activation='relu'))\r\n    model.add(Activation('softmax'))\r\n    model.load_weights(tuned_vgg_weights_path)\r\n    print(model.summary())\r\n\r\n\r\n\r\nconv_output = [l for l in model.layers[-6].layers if l.name is layer_name][0].output\r\ngrads = K.gradients(model.layers[-2].output[0, 0], model.layers[-6].layers[-2].output)[0]\r\n\r\nimg = load_img(img_path, target_size=(img_width, img_height))\r\nori_w, ori_h = load_img(img_path).size\r\n\r\nimg_array = img_to_array(img)\r\ngradient_function = K.function([model.layers[0].input], [conv_output, grads])\r\n\r\noutput, grads_val = gradient_function([preprocess_input(img_array[np.newaxis, :])])\r\n```"}