{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289317899", "html_url": "https://github.com/tensorflow/tensorflow/issues/8696#issuecomment-289317899", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8696", "id": 289317899, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTMxNzg5OQ==", "user": {"login": "mckinziebrandon", "id": 11165945, "node_id": "MDQ6VXNlcjExMTY1OTQ1", "avatar_url": "https://avatars2.githubusercontent.com/u/11165945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mckinziebrandon", "html_url": "https://github.com/mckinziebrandon", "followers_url": "https://api.github.com/users/mckinziebrandon/followers", "following_url": "https://api.github.com/users/mckinziebrandon/following{/other_user}", "gists_url": "https://api.github.com/users/mckinziebrandon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mckinziebrandon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mckinziebrandon/subscriptions", "organizations_url": "https://api.github.com/users/mckinziebrandon/orgs", "repos_url": "https://api.github.com/users/mckinziebrandon/repos", "events_url": "https://api.github.com/users/mckinziebrandon/events{/privacy}", "received_events_url": "https://api.github.com/users/mckinziebrandon/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-26T21:30:25Z", "updated_at": "2017-03-26T21:31:29Z", "author_association": "NONE", "body_html": "<p>A few guesses/checks that might help:</p>\n<ul>\n<li>Checking the list of devices matches what you'd expect. The snippet below will print all the devices seen by TF and their names.</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow.python.client <span class=\"pl-k\">import</span> device_lib\n<span class=\"pl-c1\">print</span>(device_lib.list_local_devices())</pre></div>\n<ul>\n<li>Thread management. Your error message seems to be more related to joining threads/coordinator. Not sure why this only shows with CPU as your device, but perhaps the following might help. I  don't see the use of a coordinator in your snippet. At the very least, it would help with debugging issues arising from coordinator/session. Usually the following is done when using queue runners and parallel threads.</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>coord <span class=\"pl-k\">=</span> tf.train.Coordinator()\nthreads <span class=\"pl-k\">=</span> tf.train.start_queue_runners(<span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess, <span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> . . .  start your training, etc . . . </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> When done training and/or exception is caught:</span>\ncoord.request_stop()\ncoord.join(threads)</pre></div>\n<p><a href=\"https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0#.a64trech2\" rel=\"nofollow\">Further reading on coord/threads</a></p>\n<p>From the <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/batch\" rel=\"nofollow\">tf.train.batch</a> documentation:</p>\n<blockquote>\n<p>A QueueRunner for the queue is added to the current Graph's QUEUE_RUNNER collection.</p>\n</blockquote>\n<p>As far as I know, that means the user should call <code>start_queue_runners</code> for everything to <em>start</em> properly, and then request stop and join when done for everything to <em>end</em> properly.</p>\n<p>If none of this was news to you, then don't mind me. Best of luck!</p>", "body_text": "A few guesses/checks that might help:\n\nChecking the list of devices matches what you'd expect. The snippet below will print all the devices seen by TF and their names.\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\nThread management. Your error message seems to be more related to joining threads/coordinator. Not sure why this only shows with CPU as your device, but perhaps the following might help. I  don't see the use of a coordinator in your snippet. At the very least, it would help with debugging issues arising from coordinator/session. Usually the following is done when using queue runners and parallel threads.\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n# . . .  start your training, etc . . . \n# When done training and/or exception is caught:\ncoord.request_stop()\ncoord.join(threads)\nFurther reading on coord/threads\nFrom the tf.train.batch documentation:\n\nA QueueRunner for the queue is added to the current Graph's QUEUE_RUNNER collection.\n\nAs far as I know, that means the user should call start_queue_runners for everything to start properly, and then request stop and join when done for everything to end properly.\nIf none of this was news to you, then don't mind me. Best of luck!", "body": "A few guesses/checks that might help:\r\n\r\n* Checking the list of devices matches what you'd expect. The snippet below will print all the devices seen by TF and their names.\r\n```python\r\nfrom tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n```\r\n\r\n* Thread management. Your error message seems to be more related to joining threads/coordinator. Not sure why this only shows with CPU as your device, but perhaps the following might help. I  don't see the use of a coordinator in your snippet. At the very least, it would help with debugging issues arising from coordinator/session. Usually the following is done when using queue runners and parallel threads.\r\n\r\n```python\r\ncoord = tf.train.Coordinator()\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n# . . .  start your training, etc . . . \r\n# When done training and/or exception is caught:\r\ncoord.request_stop()\r\ncoord.join(threads)\r\n```\r\n\r\n[Further reading on coord/threads](https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0#.a64trech2)\r\n\r\nFrom the [tf.train.batch](https://www.tensorflow.org/api_docs/python/tf/train/batch) documentation: \r\n\r\n> A QueueRunner for the queue is added to the current Graph's QUEUE_RUNNER collection.\r\n\r\nAs far as I know, that means the user should call ```start_queue_runners``` for everything to *start* properly, and then request stop and join when done for everything to *end* properly.\r\n\r\nIf none of this was news to you, then don't mind me. Best of luck!"}