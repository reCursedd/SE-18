{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252009651", "html_url": "https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-252009651", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4732", "id": 252009651, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjAwOTY1MQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-06T16:06:33Z", "updated_at": "2016-10-06T16:06:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm confused why matmul timing would change unless the shapes changed, or<br>\nperhaps if it for some reason started running on a CPU device where before<br>\nit was running on a GPU device.  Please provide the runmetadata.</p>\n<p>On Wed, Oct 5, 2016 at 8:11 PM, Daniel Schonfeld <a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\nwrote:</p>\n<blockquote>\n<p>Just to add some info, my features tensor is about 32,000 features. So the<br>\nshape of the test set is (3800,32000) and the training data is usually of<br>\nshape (100,32000).</p>\n<p>Like i said, doing the above utilizing feed_dict takes about 80ms per<br>\nsess.run() call and utilizing a QueueRunner with directly fed data items<br>\nfrom numpy array (only for the training data, the test data is a const with<br>\ntf.convert_to_tensor()) takes about 1000ms total with that matmul taking<br>\nmost of the time. And finally utilizing a two tfrecord files, one for the<br>\ntraining data and one for the test data, and feeding with<br>\nparse_single_example for the training data and parse_example for the test<br>\ndata, QueueDequeueMany (&lt;- of the test data, so the one using<br>\nparse_example) and Matmul are the two highest time consumers bringing the<br>\nsess.run() up to around 1800ms.</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"180693989\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4732\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4732/hovercard?comment_id=251856881&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-251856881\">#4732 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim3mQAeLWGCZCOdnkF1K4ylL5ey5sks5qxGbNgaJpZM4KMz--\">https://github.com/notifications/unsubscribe-auth/ABtim3mQAeLWGCZCOdnkF1K4ylL5ey5sks5qxGbNgaJpZM4KMz--</a><br>\n.</p>\n</blockquote>", "body_text": "I'm confused why matmul timing would change unless the shapes changed, or\nperhaps if it for some reason started running on a CPU device where before\nit was running on a GPU device.  Please provide the runmetadata.\nOn Wed, Oct 5, 2016 at 8:11 PM, Daniel Schonfeld notifications@github.com\nwrote:\n\nJust to add some info, my features tensor is about 32,000 features. So the\nshape of the test set is (3800,32000) and the training data is usually of\nshape (100,32000).\nLike i said, doing the above utilizing feed_dict takes about 80ms per\nsess.run() call and utilizing a QueueRunner with directly fed data items\nfrom numpy array (only for the training data, the test data is a const with\ntf.convert_to_tensor()) takes about 1000ms total with that matmul taking\nmost of the time. And finally utilizing a two tfrecord files, one for the\ntraining data and one for the test data, and feeding with\nparse_single_example for the training data and parse_example for the test\ndata, QueueDequeueMany (<- of the test data, so the one using\nparse_example) and Matmul are the two highest time consumers bringing the\nsess.run() up to around 1800ms.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n#4732 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABtim3mQAeLWGCZCOdnkF1K4ylL5ey5sks5qxGbNgaJpZM4KMz--\n.", "body": "I'm confused why matmul timing would change unless the shapes changed, or\nperhaps if it for some reason started running on a CPU device where before\nit was running on a GPU device.  Please provide the runmetadata.\n\nOn Wed, Oct 5, 2016 at 8:11 PM, Daniel Schonfeld notifications@github.com\nwrote:\n\n> Just to add some info, my features tensor is about 32,000 features. So the\n> shape of the test set is (3800,32000) and the training data is usually of\n> shape (100,32000).\n> \n> Like i said, doing the above utilizing feed_dict takes about 80ms per\n> sess.run() call and utilizing a QueueRunner with directly fed data items\n> from numpy array (only for the training data, the test data is a const with\n> tf.convert_to_tensor()) takes about 1000ms total with that matmul taking\n> most of the time. And finally utilizing a two tfrecord files, one for the\n> training data and one for the test data, and feeding with\n> parse_single_example for the training data and parse_example for the test\n> data, QueueDequeueMany (<- of the test data, so the one using\n> parse_example) and Matmul are the two highest time consumers bringing the\n> sess.run() up to around 1800ms.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-251856881,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim3mQAeLWGCZCOdnkF1K4ylL5ey5sks5qxGbNgaJpZM4KMz--\n> .\n"}