{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/251535265", "html_url": "https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-251535265", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4732", "id": 251535265, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MTUzNTI2NQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-04T22:44:29Z", "updated_at": "2016-10-04T22:44:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I looked at some timelines in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"180785242\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4740\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4740/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4740\">#4740</a> and <a href=\"http://stackoverflow.com/questions/39840323/benchmark-of-howto-reading-data\" rel=\"nofollow\">here</a>.</p>\n<p>On official MNIST examples QueueDequeueMany is the bottleneck, whether it's reading using <code>parse_single_example</code> or using <code>slice_input_producer</code>, with or without the GPU, taking 10x longer than entire duration of step when using <code>feed_dict</code> with same data size</p>\n<ul>\n<li>examples/how_tos/reading_data/fully_connected_reader.py</li>\n<li>examples/how_tos/reading_data/fully_connected_preloaded.py</li>\n<li>examples/how_tos/reading_data/fully_connected_preloaded_var.py</li>\n</ul>", "body_text": "I looked at some timelines in #4740 and here.\nOn official MNIST examples QueueDequeueMany is the bottleneck, whether it's reading using parse_single_example or using slice_input_producer, with or without the GPU, taking 10x longer than entire duration of step when using feed_dict with same data size\n\nexamples/how_tos/reading_data/fully_connected_reader.py\nexamples/how_tos/reading_data/fully_connected_preloaded.py\nexamples/how_tos/reading_data/fully_connected_preloaded_var.py", "body": "I looked at some timelines in https://github.com/tensorflow/tensorflow/issues/4740 and [here](http://stackoverflow.com/questions/39840323/benchmark-of-howto-reading-data).\n\nOn official MNIST examples QueueDequeueMany is the bottleneck, whether it's reading using `parse_single_example` or using `slice_input_producer`, with or without the GPU, taking 10x longer than entire duration of step when using `feed_dict` with same data size\n- examples/how_tos/reading_data/fully_connected_reader.py\n- examples/how_tos/reading_data/fully_connected_preloaded.py\n- examples/how_tos/reading_data/fully_connected_preloaded_var.py\n"}