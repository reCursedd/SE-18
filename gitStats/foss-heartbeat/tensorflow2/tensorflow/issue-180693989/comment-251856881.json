{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/251856881", "html_url": "https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-251856881", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4732", "id": 251856881, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MTg1Njg4MQ==", "user": {"login": "danielschonfeld", "id": 522598, "node_id": "MDQ6VXNlcjUyMjU5OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/522598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielschonfeld", "html_url": "https://github.com/danielschonfeld", "followers_url": "https://api.github.com/users/danielschonfeld/followers", "following_url": "https://api.github.com/users/danielschonfeld/following{/other_user}", "gists_url": "https://api.github.com/users/danielschonfeld/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielschonfeld/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielschonfeld/subscriptions", "organizations_url": "https://api.github.com/users/danielschonfeld/orgs", "repos_url": "https://api.github.com/users/danielschonfeld/repos", "events_url": "https://api.github.com/users/danielschonfeld/events{/privacy}", "received_events_url": "https://api.github.com/users/danielschonfeld/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-06T03:10:38Z", "updated_at": "2016-10-06T03:12:05Z", "author_association": "NONE", "body_html": "<p>Just to add some info, my features tensor is about 32,000 features.  So the shape of the test set is (3800,32000) and the training data is a batch of shape (100,32000).</p>\n<p>Like i said, doing the above utilizing <code>feed_dict</code> takes about 80ms per <code>sess.run()</code> call and utilizing a QueueRunner with directly fed data items from numpy array (only for the training data, the test data is a const created by <code>tf.convert_to_tensor()</code>) takes about 1000ms total with <code>MatMul</code> taking most of the time.  And finally utilizing two <code>tfrecord</code> files, one for the training data and one for the test data, and feeding with <code>parse_single_example</code> for the training data and <code>parse_example</code> for the test data, <code>QueueDequeueMany</code> (&lt;- of the test data, so the one using <code>parse_example</code>) and <code>Matmul</code> are the two highest time consumers bringing the <code>sess.run()</code> up to around 1800ms.</p>", "body_text": "Just to add some info, my features tensor is about 32,000 features.  So the shape of the test set is (3800,32000) and the training data is a batch of shape (100,32000).\nLike i said, doing the above utilizing feed_dict takes about 80ms per sess.run() call and utilizing a QueueRunner with directly fed data items from numpy array (only for the training data, the test data is a const created by tf.convert_to_tensor()) takes about 1000ms total with MatMul taking most of the time.  And finally utilizing two tfrecord files, one for the training data and one for the test data, and feeding with parse_single_example for the training data and parse_example for the test data, QueueDequeueMany (<- of the test data, so the one using parse_example) and Matmul are the two highest time consumers bringing the sess.run() up to around 1800ms.", "body": "Just to add some info, my features tensor is about 32,000 features.  So the shape of the test set is (3800,32000) and the training data is a batch of shape (100,32000).\n\nLike i said, doing the above utilizing `feed_dict` takes about 80ms per `sess.run()` call and utilizing a QueueRunner with directly fed data items from numpy array (only for the training data, the test data is a const created by `tf.convert_to_tensor()`) takes about 1000ms total with `MatMul` taking most of the time.  And finally utilizing two `tfrecord` files, one for the training data and one for the test data, and feeding with `parse_single_example` for the training data and `parse_example` for the test data, `QueueDequeueMany` (<- of the test data, so the one using `parse_example`) and `Matmul` are the two highest time consumers bringing the `sess.run()` up to around 1800ms. \n"}