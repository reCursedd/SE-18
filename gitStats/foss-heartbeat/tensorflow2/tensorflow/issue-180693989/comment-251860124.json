{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/251860124", "html_url": "https://github.com/tensorflow/tensorflow/issues/4732#issuecomment-251860124", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4732", "id": 251860124, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MTg2MDEyNA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-06T03:42:34Z", "updated_at": "2016-10-06T03:43:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=522598\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/danielschonfeld\">@danielschonfeld</a><br>\nIt sounds a bit suspicious that matmul itself would take different time depending on <code>feed_dict</code> vs <code>Queue</code>. Are you getting MatMul timing from the Timeline? Are you sure that matmul sizes are the same? Unlike with <code>QueueDequeue</code> many, IO time should not be included in the timeline timing, so if size is the same, the timing should also be the same</p>\n<p>Here's <a href=\"https://github.com/yaroslavvb/stuff/commit/aa886026ca3c48e27f776269548b40a2e2bb89ea\">how</a> you can generate text file with timing information. In that file you can see duration of matmul as well as total output size for sanity checking</p>\n<pre><code>    node_stats {\n      node_name: \"hidden1/MatMul\"\n      all_start_micros: 1475724885315055\n      op_start_rel_micros: 1\n      op_end_rel_micros: 314\n      all_end_rel_micros: 318\n      memory {\n        allocator_name: \"cpu\"\n        total_bytes: 51200\n      }\n\n</code></pre>\n<p>If the this timing information shows same total_bytes but 10x difference in timing, the way to get this triaged would be to provide a minimal self-contained reproducible test case</p>", "body_text": "@danielschonfeld\nIt sounds a bit suspicious that matmul itself would take different time depending on feed_dict vs Queue. Are you getting MatMul timing from the Timeline? Are you sure that matmul sizes are the same? Unlike with QueueDequeue many, IO time should not be included in the timeline timing, so if size is the same, the timing should also be the same\nHere's how you can generate text file with timing information. In that file you can see duration of matmul as well as total output size for sanity checking\n    node_stats {\n      node_name: \"hidden1/MatMul\"\n      all_start_micros: 1475724885315055\n      op_start_rel_micros: 1\n      op_end_rel_micros: 314\n      all_end_rel_micros: 318\n      memory {\n        allocator_name: \"cpu\"\n        total_bytes: 51200\n      }\n\n\nIf the this timing information shows same total_bytes but 10x difference in timing, the way to get this triaged would be to provide a minimal self-contained reproducible test case", "body": "@danielschonfeld \nIt sounds a bit suspicious that matmul itself would take different time depending on `feed_dict` vs `Queue`. Are you getting MatMul timing from the Timeline? Are you sure that matmul sizes are the same? Unlike with `QueueDequeue` many, IO time should not be included in the timeline timing, so if size is the same, the timing should also be the same\n\nHere's [how](https://github.com/yaroslavvb/stuff/commit/aa886026ca3c48e27f776269548b40a2e2bb89ea) you can generate text file with timing information. In that file you can see duration of matmul as well as total output size for sanity checking\n\n```\n    node_stats {\n      node_name: \"hidden1/MatMul\"\n      all_start_micros: 1475724885315055\n      op_start_rel_micros: 1\n      op_end_rel_micros: 314\n      all_end_rel_micros: 318\n      memory {\n        allocator_name: \"cpu\"\n        total_bytes: 51200\n      }\n\n```\n\nIf the this timing information shows same total_bytes but 10x difference in timing, the way to get this triaged would be to provide a minimal self-contained reproducible test case\n"}