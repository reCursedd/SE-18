{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2999", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2999/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2999/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2999/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2999", "id": 161776500, "node_id": "MDU6SXNzdWUxNjE3NzY1MDA=", "number": 2999, "title": "Problem in  restore a previously saved model", "user": {"login": "MammadTavakoli", "id": 12212802, "node_id": "MDQ6VXNlcjEyMjEyODAy", "avatar_url": "https://avatars2.githubusercontent.com/u/12212802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MammadTavakoli", "html_url": "https://github.com/MammadTavakoli", "followers_url": "https://api.github.com/users/MammadTavakoli/followers", "following_url": "https://api.github.com/users/MammadTavakoli/following{/other_user}", "gists_url": "https://api.github.com/users/MammadTavakoli/gists{/gist_id}", "starred_url": "https://api.github.com/users/MammadTavakoli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MammadTavakoli/subscriptions", "organizations_url": "https://api.github.com/users/MammadTavakoli/orgs", "repos_url": "https://api.github.com/users/MammadTavakoli/repos", "events_url": "https://api.github.com/users/MammadTavakoli/events{/privacy}", "received_events_url": "https://api.github.com/users/MammadTavakoli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-06-22T20:22:20Z", "updated_at": "2016-06-29T19:23:19Z", "closed_at": "2016-06-28T22:35:53Z", "author_association": "NONE", "body_html": "<p>I used tensorflow 0.9. I want save my model to be reused with that, I simply add tf.train.save() to save and restore my training variables.</p>\n<p>This is my code:</p>\n<pre><code>`import tensorflow as tf\nimport input_data\nimport os\n\ncheckpoint_dir='./ckpt_dir/'\n\nmnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n\nx = tf.placeholder(tf.float32, shape = [None , 784])\ny_ = tf.placeholder(tf.float32, [None, 10])\n\nsess = tf.InteractiveSession()\n\ndef load_model(sess, saver, checkpoint_dir ):\n\nckpt = tf.train.get_checkpoint_state(checkpoint_dir)\nif ckpt and ckpt.model_checkpoint_path:\nprint(ckpt.model_checkpoint_path)\n\nsaver.restore(sess, ckpt.model_checkpoint_path)\n\nelse:\nif not os.path.exists(checkpoint_dir):\nos.makedirs(checkpoint_dir)\nsess.run(init)\nreturn\n\ndef weight_variable(shape):\ninitial = tf.truncated_normal(shape, stddev = 0.1)\nreturn tf.Variable(initial)\n\ndef bias_variable(shape):\ninitial = tf.constant(0.1, shape= shape)\nreturn tf.Variable(initial)\n\ndef conv2d(x, W):\nreturn tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = \"SAME\")\n\ndef max_pool_2x2(x):\nreturn tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],\npadding = \"SAME\")\n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1, 28, 28, 1])\n\n#\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))\nh_pool1 = max_pool_2x2(h_conv1)\n\n#\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7764, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7764])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n#\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n#\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) +b_fc2)\n\n#\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices = [1]))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\n\nsaver = tf.train.Saver()\n\nload_model(sess, saver, checkpoint_dir)\n\nfor i in range(1):\nbatch = mnist.train.next_batch(50)\nif i%10 == 0:\ntrain_accuracy = accuracy.eval(feed_dict = {x : batch[0] , y_ : batch[1], keep_prob : 1.0})\nprint(\"step %d, training accuracy %g\"%(i, train_accuracy))\n\ntrain_step.run(feed_dict = {x : batch[0], y_ : batch[1], keep_prob : 0.5})\nprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\nx: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\ntf.scalar_summary(\"accuracy\", accuracy)\n\nsaver.save(sess,checkpoint_dir+'model.ckpt')`\n</code></pre>\n<p>When I restore the checkpoint:</p>\n<p><code>saver.restore(sess, ckpt.model_checkpoint_path)</code></p>\n<p>then arises this error:</p>\n<pre><code>Traceback (most recent call last):\n.\n.\n.\nNotFoundError: Tensor name \"global_step_7\" not found in checkpoint files ./ckpt_dir/model.ckpt-0\n[[Node: save_18/restore_slice_438 = RestoreSlicedt=DT_INT32, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op 'save_18/restore_slice_438', defined at:\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/start_ipython_kernel.py\", line 205, in\nipythonkernel.start()\n.\n.\n.\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1224, in __init\nraise TypeError(\"Control input must be an Operation, \"\n</code></pre>\n<p>How can I solve this problem?</p>", "body_text": "I used tensorflow 0.9. I want save my model to be reused with that, I simply add tf.train.save() to save and restore my training variables.\nThis is my code:\n`import tensorflow as tf\nimport input_data\nimport os\n\ncheckpoint_dir='./ckpt_dir/'\n\nmnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n\nx = tf.placeholder(tf.float32, shape = [None , 784])\ny_ = tf.placeholder(tf.float32, [None, 10])\n\nsess = tf.InteractiveSession()\n\ndef load_model(sess, saver, checkpoint_dir ):\n\nckpt = tf.train.get_checkpoint_state(checkpoint_dir)\nif ckpt and ckpt.model_checkpoint_path:\nprint(ckpt.model_checkpoint_path)\n\nsaver.restore(sess, ckpt.model_checkpoint_path)\n\nelse:\nif not os.path.exists(checkpoint_dir):\nos.makedirs(checkpoint_dir)\nsess.run(init)\nreturn\n\ndef weight_variable(shape):\ninitial = tf.truncated_normal(shape, stddev = 0.1)\nreturn tf.Variable(initial)\n\ndef bias_variable(shape):\ninitial = tf.constant(0.1, shape= shape)\nreturn tf.Variable(initial)\n\ndef conv2d(x, W):\nreturn tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = \"SAME\")\n\ndef max_pool_2x2(x):\nreturn tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],\npadding = \"SAME\")\n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1, 28, 28, 1])\n\n#\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))\nh_pool1 = max_pool_2x2(h_conv1)\n\n#\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7764, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7764])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n#\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n#\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) +b_fc2)\n\n#\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices = [1]))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\n\nsaver = tf.train.Saver()\n\nload_model(sess, saver, checkpoint_dir)\n\nfor i in range(1):\nbatch = mnist.train.next_batch(50)\nif i%10 == 0:\ntrain_accuracy = accuracy.eval(feed_dict = {x : batch[0] , y_ : batch[1], keep_prob : 1.0})\nprint(\"step %d, training accuracy %g\"%(i, train_accuracy))\n\ntrain_step.run(feed_dict = {x : batch[0], y_ : batch[1], keep_prob : 0.5})\nprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\nx: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\ntf.scalar_summary(\"accuracy\", accuracy)\n\nsaver.save(sess,checkpoint_dir+'model.ckpt')`\n\nWhen I restore the checkpoint:\nsaver.restore(sess, ckpt.model_checkpoint_path)\nthen arises this error:\nTraceback (most recent call last):\n.\n.\n.\nNotFoundError: Tensor name \"global_step_7\" not found in checkpoint files ./ckpt_dir/model.ckpt-0\n[[Node: save_18/restore_slice_438 = RestoreSlicedt=DT_INT32, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op 'save_18/restore_slice_438', defined at:\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/start_ipython_kernel.py\", line 205, in\nipythonkernel.start()\n.\n.\n.\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1224, in __init\nraise TypeError(\"Control input must be an Operation, \"\n\nHow can I solve this problem?", "body": "I used tensorflow 0.9. I want save my model to be reused with that, I simply add tf.train.save() to save and restore my training variables.\n\nThis is my code:\n\n```\n`import tensorflow as tf\nimport input_data\nimport os\n\ncheckpoint_dir='./ckpt_dir/'\n\nmnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n\nx = tf.placeholder(tf.float32, shape = [None , 784])\ny_ = tf.placeholder(tf.float32, [None, 10])\n\nsess = tf.InteractiveSession()\n\ndef load_model(sess, saver, checkpoint_dir ):\n\nckpt = tf.train.get_checkpoint_state(checkpoint_dir)\nif ckpt and ckpt.model_checkpoint_path:\nprint(ckpt.model_checkpoint_path)\n\nsaver.restore(sess, ckpt.model_checkpoint_path)\n\nelse:\nif not os.path.exists(checkpoint_dir):\nos.makedirs(checkpoint_dir)\nsess.run(init)\nreturn\n\ndef weight_variable(shape):\ninitial = tf.truncated_normal(shape, stddev = 0.1)\nreturn tf.Variable(initial)\n\ndef bias_variable(shape):\ninitial = tf.constant(0.1, shape= shape)\nreturn tf.Variable(initial)\n\ndef conv2d(x, W):\nreturn tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = \"SAME\")\n\ndef max_pool_2x2(x):\nreturn tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],\npadding = \"SAME\")\n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1, 28, 28, 1])\n\n#\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))\nh_pool1 = max_pool_2x2(h_conv1)\n\n#\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7764, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7764])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n#\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n#\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) +b_fc2)\n\n#\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices = [1]))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\n\nsaver = tf.train.Saver()\n\nload_model(sess, saver, checkpoint_dir)\n\nfor i in range(1):\nbatch = mnist.train.next_batch(50)\nif i%10 == 0:\ntrain_accuracy = accuracy.eval(feed_dict = {x : batch[0] , y_ : batch[1], keep_prob : 1.0})\nprint(\"step %d, training accuracy %g\"%(i, train_accuracy))\n\ntrain_step.run(feed_dict = {x : batch[0], y_ : batch[1], keep_prob : 0.5})\nprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\nx: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\ntf.scalar_summary(\"accuracy\", accuracy)\n\nsaver.save(sess,checkpoint_dir+'model.ckpt')`\n```\n\nWhen I restore the checkpoint:\n\n`saver.restore(sess, ckpt.model_checkpoint_path)`\n\nthen arises this error:\n\n```\nTraceback (most recent call last):\n.\n.\n.\nNotFoundError: Tensor name \"global_step_7\" not found in checkpoint files ./ckpt_dir/model.ckpt-0\n[[Node: save_18/restore_slice_438 = RestoreSlicedt=DT_INT32, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op 'save_18/restore_slice_438', defined at:\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/spyderlib/widgets/externalshell/start_ipython_kernel.py\", line 205, in\nipythonkernel.start()\n.\n.\n.\nFile \"/home/m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1224, in __init\nraise TypeError(\"Control input must be an Operation, \"\n```\n\nHow can I solve this problem?\n"}