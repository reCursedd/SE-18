{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/216252913", "html_url": "https://github.com/tensorflow/tensorflow/issues/2193#issuecomment-216252913", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2193", "id": 216252913, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNjI1MjkxMw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-02T14:38:08Z", "updated_at": "2016-05-02T14:38:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Use <code>labels.set_shape(())</code></p>\n<p><code>batch</code> is a kind of FIFOQueue and it needs to know sizes of inputs for memory allocation reasons. It can either get it from <code>shapes</code> argument, or use shape inference to infer it automatically. Since <code>py_func</code> can call arbitrary Python code and give different-shaped argument between invocations, <code>py_func</code> doesn't set static shape and you need to either use <code>shapes</code> argument to <code>batch</code> or <code>set_shape</code> on <code>labels</code> tensor.</p>\n<p>So you either need to</p>\n<p><code>labels.set_shape(())</code></p>\n<p>or do</p>\n<p><code>labels_batch = tf.batch(..., shapes=[()])</code></p>\n<p>Here's an end-to-end example to test this</p>\n<pre><code># Create queue, initialize it with 0,1,2,3,4,5,6,7,8,9\nqueue_size = 10\ntf.reset_default_graph()\nqueue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int64)\nenqueue_placeholder = tf.placeholder(dtype=tf.int64)\nenqueue_op = queue.enqueue(enqueue_placeholder)\ndequeue_op = queue.dequeue()\n\nsess = tf.InteractiveSession()\nfor f in range(queue_size):\n  sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\nsess.run(queue.close())\n\ndef unpackbits(arr):\n    return arr.astype(np.int64)\n\nlabels = dequeue_op\nlabels2, = tf.py_func(unpackbits, [labels], [tf.int64])\n\nlabels2.set_shape(())\nlabels2_batch = tf.batch([labels2], 2, capacity=10)\n\ntf.start_queue_runners()\n\nfor i in range(5):\n  print labels2_batch.eval()\n</code></pre>", "body_text": "Use labels.set_shape(())\nbatch is a kind of FIFOQueue and it needs to know sizes of inputs for memory allocation reasons. It can either get it from shapes argument, or use shape inference to infer it automatically. Since py_func can call arbitrary Python code and give different-shaped argument between invocations, py_func doesn't set static shape and you need to either use shapes argument to batch or set_shape on labels tensor.\nSo you either need to\nlabels.set_shape(())\nor do\nlabels_batch = tf.batch(..., shapes=[()])\nHere's an end-to-end example to test this\n# Create queue, initialize it with 0,1,2,3,4,5,6,7,8,9\nqueue_size = 10\ntf.reset_default_graph()\nqueue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int64)\nenqueue_placeholder = tf.placeholder(dtype=tf.int64)\nenqueue_op = queue.enqueue(enqueue_placeholder)\ndequeue_op = queue.dequeue()\n\nsess = tf.InteractiveSession()\nfor f in range(queue_size):\n  sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\nsess.run(queue.close())\n\ndef unpackbits(arr):\n    return arr.astype(np.int64)\n\nlabels = dequeue_op\nlabels2, = tf.py_func(unpackbits, [labels], [tf.int64])\n\nlabels2.set_shape(())\nlabels2_batch = tf.batch([labels2], 2, capacity=10)\n\ntf.start_queue_runners()\n\nfor i in range(5):\n  print labels2_batch.eval()", "body": "Use `labels.set_shape(())`\n\n`batch` is a kind of FIFOQueue and it needs to know sizes of inputs for memory allocation reasons. It can either get it from `shapes` argument, or use shape inference to infer it automatically. Since `py_func` can call arbitrary Python code and give different-shaped argument between invocations, `py_func` doesn't set static shape and you need to either use `shapes` argument to `batch` or `set_shape` on `labels` tensor.\n\nSo you either need to \n\n`labels.set_shape(())`\n\nor do\n\n`labels_batch = tf.batch(..., shapes=[()])`\n\nHere's an end-to-end example to test this\n\n```\n# Create queue, initialize it with 0,1,2,3,4,5,6,7,8,9\nqueue_size = 10\ntf.reset_default_graph()\nqueue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int64)\nenqueue_placeholder = tf.placeholder(dtype=tf.int64)\nenqueue_op = queue.enqueue(enqueue_placeholder)\ndequeue_op = queue.dequeue()\n\nsess = tf.InteractiveSession()\nfor f in range(queue_size):\n  sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\nsess.run(queue.close())\n\ndef unpackbits(arr):\n    return arr.astype(np.int64)\n\nlabels = dequeue_op\nlabels2, = tf.py_func(unpackbits, [labels], [tf.int64])\n\nlabels2.set_shape(())\nlabels2_batch = tf.batch([labels2], 2, capacity=10)\n\ntf.start_queue_runners()\n\nfor i in range(5):\n  print labels2_batch.eval()\n```\n"}