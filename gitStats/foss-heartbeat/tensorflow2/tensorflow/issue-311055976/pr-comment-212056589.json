{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/212056589", "pull_request_review_id": 148608159, "id": 212056589, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjA1NjU4OQ==", "diff_hunk": "@@ -0,0 +1,2058 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <regex>\n+#include <string>\n+#include <vector>\n+#include <algorithm>\n+#include <iterator>\n+\n+#include <avro.h>\n+\n+#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+namespace tensorflow {\n+\n+using ::tensorflow::shape_inference::ShapeHandle;\n+\n+// As boiler plate for the class I used\n+// tensorflow/core/util/example_proto_helper.h and therein\n+// \"ParseSingleExampleAttrs\".\n+\n+// Checks for valid type for the avro attributes; currently we support bool,\n+// int, long, float, double, string.\n+//\n+// 'dtype' The data type.\n+//\n+// returns OK if any of the supported types; otherwise false.\n+//\n+tensorflow::Status CheckValidType(const tensorflow::DataType& dtype);\n+\n+// Check that all dense shapes are defined. Here, 'defined' means that:\n+// * All shapes have at least one dimension.\n+// * A shape can have an undefined dimension -1, as first dimension.\n+//\n+// 'dense_shape' The dense shapes.\n+//\n+// returns OK if the shapes are defined; otherwise false.\n+//\n+tensorflow::Status CheckDenseShapeToBeDefined(\n+    const std::vector<tensorflow::PartialTensorShape>& dense_shapes);\n+\n+// Struct that holds information about dense tensors that is used during\n+// parsing.\n+struct DenseInformation {\n+  tensorflow::DataType type;             // Type\n+  tensorflow::PartialTensorShape shape;  // Shape\n+  bool variable_length;  // This dense tensor has a variable length in the 2nd\n+                         // dimension\n+  std::size_t elements_per_stride;  // Number of elements per stride\n+};\n+\n+// This class holds the attributes passed into the parse avro record function.\n+// In addition, it builds up information about the 'elements per stride',\n+// 'variable length' for dense tensors, and\n+// 'dense shape' information.\n+class ParseAvroAttrs {\n+ public:\n+  // Initializes the attribute information\n+  template <typename ContextType>\n+  tensorflow::Status Init(ContextType* ctx) {\n+    std::vector<tensorflow::DataType> dense_types;\n+    std::vector<tensorflow::PartialTensorShape> dense_shapes;\n+\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Nsparse\", &num_sparse));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Ndense\", &num_dense));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"sparse_types\", &sparse_types));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Tdense\", &dense_types));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"dense_shapes\", &dense_shapes));\n+\n+    // Check that all dense shapes are defined\n+    TF_RETURN_IF_ERROR(CheckDenseShapeToBeDefined(dense_shapes));\n+\n+    for (int i_dense = 0; i_dense < dense_shapes.size(); ++i_dense) {\n+      DenseInformation dense_info;\n+      tensorflow::TensorShape dense_shape;\n+      // This is the case where we have a fixed len sequence feature, and the\n+      // 1st dimension is undefined.\n+      if (dense_shapes[i_dense].dims() > 0 &&\n+          dense_shapes[i_dense].dim_size(0) == -1) {\n+        dense_info.variable_length = true;\n+        for (int d = 1; d < dense_shapes[i_dense].dims(); ++d) {\n+          dense_shape.AddDim(dense_shapes[i_dense].dim_size(d));\n+        }\n+        // This is the case where all dimensions are defined.\n+      } else {\n+        dense_info.variable_length = false;\n+        dense_shapes[i_dense].AsTensorShape(&dense_shape);\n+      }\n+      // Fill in the remaining information into the dense info and add it to to\n+      // the vector\n+      dense_info.elements_per_stride = dense_shape.num_elements();\n+      dense_info.shape = dense_shapes[i_dense];\n+      dense_info.type = dense_types[i_dense];\n+      dense_infos.push_back(dense_info);\n+    }\n+    return FinishInit();\n+  }\n+\n+  // All these attributes are publicly accessible, hence we did not suffix them\n+  // with '_'.\n+  tensorflow::int64 num_sparse;  // Number of sparse features\n+  tensorflow::int64 num_dense;   // Number of dense features (fixed and variable\n+                                 // length)\n+  std::vector<tensorflow::DataType> sparse_types;  // Types for sparse features\n+  std::vector<DenseInformation> dense_infos;  // Information about each dense\n+                                              // tensor\n+ private:\n+  tensorflow::Status FinishInit();  // for context-independent parts of Init.\n+};\n+\n+// As boiler plate I used tensorflow/core/util/example_proto_helper.cc and\n+// therein \"ParseSingleExampleAttrs\" and\n+Status CheckValidType(const DataType& dtype) {\n+  switch (dtype) {\n+    case DT_BOOL:\n+    case DT_INT32:\n+    case DT_INT64:\n+    case DT_FLOAT:\n+    case DT_DOUBLE:\n+    case DT_STRING:\n+      return Status::OK();\n+    default:\n+      return errors::InvalidArgument(\"Received input dtype: \",\n+                                     DataTypeString(dtype));\n+  }\n+}\n+\n+Status CheckDenseShapeToBeDefined(\n+    const std::vector<PartialTensorShape>& dense_shapes) {\n+  for (int i = 0; i < dense_shapes.size(); ++i) {\n+    const PartialTensorShape& dense_shape = dense_shapes[i];\n+    bool shape_ok = true;\n+    if (dense_shape.dims() == -1) {\n+      shape_ok = false;\n+    } else {\n+      for (int d = 1; d < dense_shape.dims() && shape_ok; ++d) {\n+        if (dense_shape.dim_size(d) == -1) {\n+          shape_ok = false;\n+        }\n+      }\n+    }\n+    if (!shape_ok) {\n+      return errors::InvalidArgument(\n+          \"dense_shapes[\", i,\n+          \"] has unknown rank or unknown inner dimensions: \",\n+          dense_shape.DebugString());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// Finishes the initialization for the attributes, which essentially checks that\n+// the attributes have the correct values.\n+//\n+// returns OK if all attributes are valid; otherwise false.\n+Status ParseAvroAttrs::FinishInit() {\n+  if (static_cast<size_t>(num_sparse) != sparse_types.size()) {\n+    return errors::InvalidArgument(\"len(sparse_keys) != len(sparse_types)\");\n+  }\n+  if (static_cast<size_t>(num_dense) != dense_infos.size()) {\n+    return errors::InvalidArgument(\"len(dense_keys) != len(dense_infos)\");\n+  }\n+  if (num_dense > std::numeric_limits<int32>::max()) {\n+    return errors::InvalidArgument(\"num_dense_ too large\");\n+  }\n+  for (const DenseInformation& dense_info : dense_infos) {\n+    TF_RETURN_IF_ERROR(CheckValidType(dense_info.type));\n+  }\n+  for (const DataType& type : sparse_types) {\n+    TF_RETURN_IF_ERROR(CheckValidType(type));\n+  }\n+  return Status::OK();\n+}\n+\n+// Register the parse function when building the shared library\n+// For the op I used as boiler plate: tensorflow/core/ops/parsing_ops.cc and\n+// there 'ParseExample'\n+// For the op kernel I used as boiler plate:\n+// tensorflow/core/kernels/example_parsing_ops.cc and there 'ExampleParserOp'\n+// For the compute method I used as boiler plate:\n+// tensorflow/core/util/example_proto_fast_parsing.cc and there the\n+//   method 'FastParseExample'\n+\n+REGISTER_OP(\"ParseAvroRecord\")\n+    .Input(\"serialized: string\")\n+    .Input(\"sparse_keys: Nsparse * string\")\n+    .Input(\"dense_keys: Ndense * string\")\n+    .Input(\"dense_defaults: Tdense\")\n+    .Output(\"sparse_indices: Nsparse * int64\")\n+    .Output(\"sparse_values: sparse_types\")\n+    .Output(\"sparse_shapes: Nsparse * int64\")\n+    .Output(\"dense_values: Tdense\")\n+    .Attr(\"Nsparse: int >= 0\")  // Inferred from sparse_keys\n+    .Attr(\"Ndense: int >= 0\")   // Inferred from dense_keys\n+    .Attr(\"sparse_types: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"Tdense: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"dense_shapes: list(shape) >= 0\")\n+    .Attr(\"schema: string\")\n+    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n+\n+       ParseAvroAttrs attrs;\n+       TF_RETURN_IF_ERROR(attrs.Init(c));\n+\n+       // Get the batch size and load it into input\n+       ShapeHandle input;\n+       TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n+\n+       // Get the schema, parse it, and log it\n+       string schema;\n+       TF_RETURN_IF_ERROR(c->GetAttr(\"schema\", &schema));\n+\n+       std::unique_ptr<avro_schema_t, std::function<void(avro_schema_t*)>>\n+           p_reader_schema(new avro_schema_t, [](avro_schema_t* ptr) {\n+             avro_schema_decref(*ptr);\n+           });\n+       if (avro_schema_from_json_length(schema.c_str(), schema.length(),\n+                                        &(*p_reader_schema)) != 0) {\n+         return errors::InvalidArgument(\"The provided json schema is invalid. \",\n+                                        avro_strerror());\n+       }\n+       LOG(INFO) << \"Avro parser with schema\\n\" << schema;", "path": "tensorflow/contrib/avro/ops/parse_avro_record.cc", "position": null, "original_position": 245, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "d1be9e544357e72eb37f6adb626670f745e79a9b", "user": {"login": "galv", "id": 4767568, "node_id": "MDQ6VXNlcjQ3Njc1Njg=", "avatar_url": "https://avatars0.githubusercontent.com/u/4767568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/galv", "html_url": "https://github.com/galv", "followers_url": "https://api.github.com/users/galv/followers", "following_url": "https://api.github.com/users/galv/following{/other_user}", "gists_url": "https://api.github.com/users/galv/gists{/gist_id}", "starred_url": "https://api.github.com/users/galv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/galv/subscriptions", "organizations_url": "https://api.github.com/users/galv/orgs", "repos_url": "https://api.github.com/users/galv/repos", "events_url": "https://api.github.com/users/galv/events{/privacy}", "received_events_url": "https://api.github.com/users/galv/received_events", "type": "User", "site_admin": false}, "body": "This gets output for literally every avro record that gets parsed. I think it would be good to set the log level to something like DEBUG instead.", "created_at": "2018-08-22T18:17:59Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r212056589", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/212056589"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r212056589"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>This gets output for literally every avro record that gets parsed. I think it would be good to set the log level to something like DEBUG instead.</p>", "body_text": "This gets output for literally every avro record that gets parsed. I think it would be good to set the log level to something like DEBUG instead."}