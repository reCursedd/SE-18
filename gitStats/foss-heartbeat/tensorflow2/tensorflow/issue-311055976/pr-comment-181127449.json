{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181127449", "pull_request_review_id": 111647900, "id": 181127449, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTEyNzQ0OQ==", "diff_hunk": "@@ -0,0 +1,1143 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+\n+import logging\n+import collections\n+\n+from tensorflow.python.framework import dtypes as tf_types\n+from tensorflow.python.framework.errors import OpError\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import parsing_ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.platform import test\n+\n+from tensorflow.contrib.avro.python.parse_avro_record import parse_avro_record\n+from tensorflow.contrib.avro.python.utils.avro_record_utilities import get_record_value, serialize, parse_schema\n+from tensorflow.contrib.avro.python.utils.tensor_utilities import fill_in_fixed_len, fill_in_fixed_len_sequence, \\\n+    get_end_indices, get_n_elements_per_batch\n+import tensorflow.contrib.avro.python.utils.numerr as nr\n+\n+\n+class DataForTest(collections.namedtuple('DataForTest', ['schema', 'data', 'features', 'should_pass'])):\n+    \"\"\"\n+    Test data contains a schema, data, features (for parsing), and whether this test is expected to pass or fail.\n+    \"\"\"\n+\n+\n+class ParseAvroRecordTest(test.TestCase):\n+\n+    def __init__(self, *args, **kwargs):\n+        super(ParseAvroRecordTest, self).__init__(*args, **kwargs)\n+\n+    def setUp(self):\n+        \"\"\"\n+        Setup fixture for test cases.\n+        \"\"\"\n+        log_root = logging.getLogger()  # set logging level\n+        log_root.setLevel(logging.INFO)\n+\n+    def run_test(self, test_case):\n+        \"\"\"\n+        Runs a test case.\n+        \"\"\"\n+        # Run over all test cases\n+        schema_object = parse_schema(test_case.schema)\n+        with ops.Graph().as_default() as g, self.test_session(graph=g) as sess:\n+            str_input = array_ops.placeholder(tf_types.string)\n+\n+            parsed = parse_avro_record(str_input, test_case.schema, test_case.features)\n+            records = test_case.data\n+            # To test batch processing summarize all test data points into one batch\n+            serialized = [serialize(record, schema_object) for record in records]\n+            # If this test case should pass ensure that all thresholds are met\n+            if test_case.should_pass:\n+                # Here is where we execute our parser within TensorFlow\n+                tensors = sess.run(parsed, feed_dict={str_input: serialized})\n+                # Go over all key, value pairs in the features; keys are strings and values are TensorFlow type info\n+                for key, value in test_case.features.iteritems():\n+                    # Get all intended tensor values from the test data\n+                    tensor_be = len(records)*[None]\n+                    for i_record, record in enumerate(records):\n+                        record_value = get_record_value(record, key, value.dtype)\n+                        tensor_be[i_record] = record_value\n+                    # Get the actual tensor\n+                    tensor_is = tensors[key]\n+                    # Apply different test for the different tensor types: fixed length, var length, sparse\n+                    if isinstance(value, parsing_ops.FixedLenSequenceFeature):\n+                        logging.info(\"Comparing fixed length feature {0}.\".format(key))\n+                        tensor_be = fill_in_fixed_len_sequence(tensor_be,\n+                                                               end_indices=get_end_indices(tensor_is),\n+                                                               n_elements_per_batch=get_n_elements_per_batch(tensor_is),\n+                                                               default_value=value.default_value)\n+                        assert nr.almost_equal_dense_tensor(tensor_is, tensor_be), \\\n+                            \"Value for field {0} has the relative error of {1} but should be < {2}.\".format(\n+                                key, nr.relative_error_for_dense_tensor(tensor_is, tensor_be),\n+                                nr.ALMOST_EQUALS_THRESHOLD)\n+                    elif isinstance(value, parsing_ops.FixedLenFeature):\n+                        logging.info(\"Comparing fixed length feature {0}.\".format(key))\n+                        tensor_be = fill_in_fixed_len(tensor_be,\n+                                                      end_indices=get_end_indices(tensor_is),\n+                                                      n_elements_per_batch=get_n_elements_per_batch(tensor_is),\n+                                                      default_values=value.default_value)\n+                        assert nr.almost_equal_dense_tensor(tensor_is, tensor_be), \\\n+                            \"Value for field {0} has the relative error of {1} but should be < {2}.\".format(\n+                                key, nr.relative_error_for_dense_tensor(tensor_is, tensor_be),\n+                                nr.ALMOST_EQUALS_THRESHOLD)\n+                    elif isinstance(value, parsing_ops.VarLenFeature):\n+                        logging.info(\"Comparing variable length features {0}.\".format(key))\n+                        assert nr.almost_equal_var_len_tensor(tensor_is, tensor_be), \\\n+                            \"Value for field {0} has the relative error of {1} but should be < {2}.\".format(\n+                                key, nr.relative_error_for_var_len_tensor(tensor_is, tensor_be),\n+                                nr.ALMOST_EQUALS_THRESHOLD)\n+                    elif isinstance(value, parsing_ops.SparseFeature):\n+                        logging.info(\"Comparing sparse tensors {0}.\".format(key))\n+                        assert nr.almost_equal_sparse_tensor(tensor_is, tensor_be, value), \\\n+                            \"Value for field {0} has the relative error of {1} but should be < {2}.\".format(\n+                                key, nr.relative_error_for_sparse_tensor(tensor_is, tensor_be, value),\n+                                nr.ALMOST_EQUALS_THRESHOLD)\n+                    else:\n+                        logging.info(\"Error in feature type\")\n+            else:\n+                # We assume this fails, so the print should not happen\n+                with self.assertRaises(OpError) as error:\n+                    print(sess.run(parsed, feed_dict={str_input: serialized}))\n+                # Log the error message so we can inspect it on the command line\n+                logging.info(error)\n+\n+    def test_primitive_types(self):\n+        \"\"\"\n+        Tests primitive types and the range for the different types of data.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Primitive types.\",\n+                       \"namespace\": \"com.test.primitive\",\n+                       \"type\": \"record\",\n+                       \"name\": \"data_row\",\n+                       \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"},\n+                         {\"name\": \"float_type\", \"type\": \"float\"},\n+                         {\"name\": \"double_type\", \"type\": \"double\"},\n+                         {\"name\": \"long_type\", \"type\": \"long\"},\n+                         {\"name\": \"int_type\", \"type\": \"int\"},\n+                         {\"name\": \"boolean_type\", \"type\": \"boolean\"},\n+                         {\"name\": \"string_type\", \"type\": \"string\"},\n+                         {\"name\": \"bytes_type\", \"type\": \"bytes\"}\n+                       ]}''',\n+            data=[{'index': 0,\n+                   'float_type': 0.0,\n+                   'double_type': 0.0,\n+                   'long_type': 0L,\n+                   'int_type': 0,\n+                   'boolean_type': False,\n+                   'string_type': \"\",\n+                   'bytes_type': \"\"\n+                   },\n+                  {'index': 1,\n+                   'float_type': 3.40282306074e+38,\n+                   'double_type': 1.7976931348623157e+308,\n+                   'long_type': 9223372036854775807L,\n+                   'int_type': 2147483648-1,\n+                   'boolean_type': True,\n+                   'string_type': \"SpecialChars@!#$%^&*()-_=+{}[]|/`~\\\\\\'?\",\n+                   'bytes_type': \"SpecialChars@!#$%^&*()-_=+{}[]|/`~\\\\\\'?\"\n+                   },\n+                  {'index': 2,\n+                   'float_type': -3.40282306074e+38,\n+                   'double_type': -1.7976931348623157e+308,\n+                   'long_type': -9223372036854775807L-1L,\n+                   'int_type': -2147483648,\n+                   'boolean_type': True,\n+                   'string_type': \"ABCDEFGHIJKLMNOPQRSTUVWZabcdefghijklmnopqrstuvwz0123456789\",\n+                   'bytes_type': \"ABCDEFGHIJKLMNOPQRSTUVWZabcdefghijklmnopqrstuvwz0123456789\"\n+                   },\n+                  {'index': 3,\n+                   'float_type': 2342.322,\n+                   'double_type': 2.2250738585072014e-308,\n+                   'long_type': -234829L,\n+                   'int_type': 213648,\n+                   'boolean_type': False,\n+                   'string_type': \"alkdfjiwij2oi2jp\",\n+                   'bytes_type': \"aljk2ijlqn,w\"}],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'float_type': parsing_ops.FixedLenFeature([], tf_types.float32),\n+                      'double_type': parsing_ops.FixedLenFeature([], tf_types.float64),\n+                      'long_type': parsing_ops.FixedLenFeature([], tf_types.int64),\n+                      'int_type': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'boolean_type': parsing_ops.FixedLenFeature([], tf_types.bool),\n+                      'string_type': parsing_ops.FixedLenFeature([], tf_types.string),\n+                      'bytes_type': parsing_ops.FixedLenFeature([], tf_types.string)},\n+            should_pass=True))\n+\n+    def test_fixed_length_lists(self):\n+        \"\"\"\n+        Tests fixed length lists features; where each row has the same number of items in the array.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Fixed length lists.\",\n+                       \"namespace\": \"com.test.lists.fixed\",\n+                       \"type\": \"record\",\n+                       \"name\": \"data_row\",\n+                       \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"},\n+                         {\"name\": \"float_list_type\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n+                         {\"name\": \"double_list_type\", \"type\": {\"type\": \"array\", \"items\": \"double\"}},\n+                         {\"name\": \"long_list_type\", \"type\": {\"type\": \"array\", \"items\": \"long\"}},\n+                         {\"name\": \"int_list_type\", \"type\": {\"type\": \"array\", \"items\": \"int\"}},\n+                         {\"name\": \"boolean_list_type\", \"type\": {\"type\": \"array\", \"items\": \"boolean\"}},\n+                         {\"name\": \"string_list_type\", \"type\": {\"type\": \"array\", \"items\": \"string\"}},\n+                         {\"name\": \"bytes_list_type\", \"type\": {\"type\": \"array\", \"items\": \"bytes\"}}\n+                       ]}''',\n+            data=[{'index': 0,\n+                   'float_list_type': [-1.0001, 0.1, 23.2],\n+                   'double_list_type': [-20.0, 22.33],\n+                   'long_list_type': [-15L, 0L, 3022123019L],\n+                   'int_list_type': [-20, -1, 2934],\n+                   'boolean_list_type': [True],\n+                   'string_list_type': [\"abc\", \"defg\", \"hijkl\"],\n+                   'bytes_list_type': [\"abc\", \"defg\", \"hijkl\"]},\n+                  {'index': 1,\n+                   'float_list_type': [-3.22, 3298.233, 3939.1213],\n+                   'double_list_type': [-2332.324, 2.665439],\n+                   'long_list_type': [-1543L, 233L, 322L],\n+                   'int_list_type': [-5, 342, -3222],\n+                   'boolean_list_type': [False],\n+                   'string_list_type': [\"mnop\", \"qrs\", \"tuvwz\"],\n+                   'bytes_list_type': [\"mnop\", \"qrs\", \"tuvwz\"]\n+                   }],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'float_list_type': parsing_ops.FixedLenFeature([3], tf_types.float32),\n+                      'double_list_type': parsing_ops.FixedLenFeature([2], tf_types.float64),\n+                      'long_list_type': parsing_ops.FixedLenFeature([3], tf_types.int64),\n+                      'int_list_type': parsing_ops.FixedLenFeature([3], tf_types.int32),\n+                      'boolean_list_type': parsing_ops.FixedLenFeature([], tf_types.bool),\n+                      'string_list_type': parsing_ops.FixedLenFeature([3], tf_types.string),\n+                      'bytes_list_type': parsing_ops.FixedLenFeature([3], tf_types.string)},\n+            should_pass=True))\n+\n+    def test_variable_length_lists(self):\n+        \"\"\"\n+        Test variable length features, where each row has a variable number of items in the array.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Variable length lists.\",\n+                       \"namespace\": \"com.test.lists.var\",\n+                       \"type\": \"record\",\n+                       \"name\": \"data_row\",\n+                       \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"},\n+                         {\"name\": \"float_list_type\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n+                         {\"name\": \"double_list_type\", \"type\": {\"type\": \"array\", \"items\": \"double\"}},\n+                         {\"name\": \"long_list_type\", \"type\": {\"type\": \"array\", \"items\": \"long\"}},\n+                         {\"name\": \"int_list_type\", \"type\": {\"type\": \"array\", \"items\": \"int\"}},\n+                         {\"name\": \"boolean_list_type\", \"type\": {\"type\": \"array\", \"items\": \"boolean\"}},\n+                         {\"name\": \"string_list_type\", \"type\": {\"type\": \"array\", \"items\": \"string\"}},\n+                         {\"name\": \"bytes_list_type\", \"type\": {\"type\": \"array\", \"items\": \"bytes\"}}\n+                       ]}''',\n+            data=[{'index': 0,\n+                   'float_list_type': [-1.0001, 0.1],\n+                   'double_list_type': [-20.0, 22.33, 234.32334],\n+                   'long_list_type': [-15L, 0L, 3022123019L],\n+                   'int_list_type': [-20, -1],\n+                   'boolean_list_type': [True, False],\n+                   'string_list_type': [\"abc\", \"defg\"],\n+                   'bytes_list_type': [\"abc\", \"defg\"]},\n+                  {'index': 1,\n+                   'float_list_type': [-3.22, 3298.233, 3939.1213],\n+                   'double_list_type': [-2332.324, 2.665439],\n+                   'long_list_type': [-1543L, 233L, 322L],\n+                   'int_list_type': [-5, 342, -3222],\n+                   'boolean_list_type': [False],\n+                   'string_list_type': [\"mnop\", \"qrs\", \"tuvwz\"],\n+                   'bytes_list_type': [\"mnop\", \"qrs\", \"tuvwz\"]\n+                   }],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'double_list_type': parsing_ops.VarLenFeature(tf_types.float64),\n+                      'long_list_type': parsing_ops.VarLenFeature(tf_types.int64),\n+                      'int_list_type': parsing_ops.VarLenFeature(tf_types.int32),\n+                      'boolean_list_type': parsing_ops.VarLenFeature(tf_types.bool),\n+                      'string_list_type': parsing_ops.VarLenFeature(tf_types.string),\n+                      'bytes_list_type': parsing_ops.VarLenFeature(tf_types.string)},\n+            should_pass=True))\n+\n+    def test_sparse_features(self):\n+        \"\"\"\n+        Test sparse feature. A sparse feature maps an array of records that have data for keys and values.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Sparse features.\",\n+                       \"namespace\": \"com.test.sparse\",\n+                       \"type\": \"record\",\n+                       \"name\": \"sparse_feature\",\n+                       \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"},\n+                         {\"name\": \"sparse_type\",\n+                            \"type\":\n+                            {\n+                                \"type\": \"array\",\n+                                \"items\": {\n+                                    \"type\": \"record\",\n+                                    \"name\": \"sparse_triplet\",\n+                                    \"fields\": [\n+                                        {\"name\": \"index\", \"type\": \"long\"},\n+                                        {\"name\": \"max_index\", \"type\": \"int\"},\n+                                        {\"name\": \"value\", \"type\": \"float\"}\n+                                    ]\n+                                }\n+                            }\n+                        }]}''',\n+            data=[{'index': 0, 'sparse_type': [{'index': 0, 'max_index': 10, 'value': 5.0},\n+                                               {'index': 5, 'max_index': 10, 'value': 7.0},\n+                                               {'index': 3, 'max_index': 10, 'value': 1.0}]},\n+                  {'index': 1, 'sparse_type': [{'index': 0, 'max_index': 10, 'value': 2.0},\n+                                               {'index': 9, 'max_index': 10, 'value': 1.0}]}],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'sparse_type': parsing_ops.SparseFeature(\n+                          index_key='index', value_key='value', dtype=tf_types.float32, size=10)},\n+            should_pass=True))\n+\n+    def test_nesting(self):\n+        \"\"\"\n+        Test nested records.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Nested records, arrays, lists, and link resolution.\",\n+                      \"namespace\": \"com.test.nested\",\n+                      \"type\": \"record\",\n+                      \"name\": \"test_nested_record\",\n+                      \"fields\": [\n+                          {\"name\": \"index\", \"type\": \"int\"},\n+                          {\"name\": \"nested_record\",\n+                           \"type\": {\n+                                \"type\": \"record\",\n+                                \"name\": \"nested_values\",\n+                                \"fields\": [\n+                                    {\"name\": \"nested_int\", \"type\": \"int\"},\n+                                    {\"name\": \"nested_float_list\", \"type\": {\"type\": \"array\", \"items\": \"float\"}}\n+                                    ]}\n+                          },\n+                          {\"name\": \"list_of_records\",\n+                           \"type\": {\n+                                \"type\": \"array\",\n+                                \"items\": {\n+                                    \"type\": \"record\",\n+                                    \"name\": \"person\",\n+                                    \"fields\": [\n+                                        {\"name\": \"first_name\", \"type\": \"string\"},\n+                                        {\"name\": \"age\", \"type\": \"int\"}\n+                                    ]\n+                                }\n+                            }\n+                          },\n+                          {\"name\": \"map_of_records\",\n+                           \"type\": {\n+                                \"type\": \"map\",\n+                                \"values\": {\n+                                    \"type\": \"record\",\n+                                    \"name\": \"secondPerson\",\n+                                    \"fields\": [\n+                                        {\"name\": \"first_name\", \"type\": \"string\"},\n+                                        {\"name\": \"age\", \"type\": \"int\"}\n+                                    ]\n+                                }\n+                            }\n+                          }]}''',\n+            data=[{'index': 0,\n+                   'nested_record': {'nested_int': 0, 'nested_float_list': [0.0, 10.0]},\n+                   'list_of_records': [{'first_name': \"Herbert\", 'age': 70}],\n+                   'map_of_records': {'first': {'first_name': \"Herbert\", 'age': 70},\n+                                      'second': {'first_name': \"Julia\", 'age': 30}}},\n+                  {'index': 1,\n+                   'nested_record': {'nested_int': 0, 'nested_float_list': [0.0, 10.0]},\n+                   'list_of_records': [{'first_name': \"Doug\", 'age': 55},\n+                                       {'first_name': \"Jess\", 'age': 66},\n+                                       {'first_name': \"Julia\", 'age': 30}],\n+                   'map_of_records': {'first': {'first_name': \"Doug\", 'age': 55},\n+                                      'second': {'first_name': \"Jess\", 'age': 66}}},\n+                  {'index': 2,\n+                   'nested_record': {'nested_int': 0, 'nested_float_list': [0.0, 10.0]},\n+                   'list_of_records': [{'first_name': \"Karl\", 'age': 32}],\n+                   'map_of_records': {'first': {'first_name': \"Karl\", 'age': 32},\n+                                      'second': {'first_name': \"Joan\", 'age': 21}}}],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'nested_record/nested_int': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'nested_record/nested_float_list': parsing_ops.FixedLenFeature([2], tf_types.float32),\n+                      'list_of_records/[0]/first_name': parsing_ops.FixedLenFeature([], tf_types.string),\n+                      \"map_of_records/['second']/age\": parsing_ops.FixedLenFeature([], tf_types.int32)},\n+            should_pass=True\n+        ))\n+\n+    def test_nested_with_asterisk(self):\n+        \"\"\"\n+        Test nested records with the asterisk notation. In this case we want all items from an array/map.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Nested records in array to use asterisk.\",\n+                      \"namespace\": \"com.test.nested.records\",\n+                      \"type\": \"record\",\n+                      \"name\": \"test_nested_record\",\n+                      \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"},\n+                         {\"name\": \"sparse_type\",\n+                            \"type\":\n+                            {\n+                                \"type\": \"array\",\n+                                \"items\": {\n+                                    \"type\": \"record\",\n+                                    \"name\": \"sparse_triplet\",\n+                                    \"fields\": [\n+                                        {\"name\": \"index\", \"type\": \"long\"},\n+                                        {\"name\": \"max_index\", \"type\": \"int\"},\n+                                        {\"name\": \"value\", \"type\": \"float\"}\n+                                    ]\n+                                }\n+                            }\n+                        }]}''',\n+            data=[{'index': 0, 'sparse_type': [{'index': 0, 'max_index': 10, 'value': 5.0},\n+                                               {'index': 5, 'max_index': 10, 'value': 7.0},\n+                                               {'index': 3, 'max_index': 10, 'value': 1.0}]},\n+                  {'index': 1, 'sparse_type': [{'index': 0, 'max_index': 10, 'value': 2.0},\n+                                               {'index': 9, 'max_index': 10, 'value': 1.0}]}],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int32),\n+                      'sparse_type/[*]/index': parsing_ops.VarLenFeature(tf_types.int64),\n+                      'sparse_type/[*]/value': parsing_ops.VarLenFeature(tf_types.float32)},\n+            should_pass=True))\n+\n+    def test_parse_int_as_long_fail(self):\n+        \"\"\"\n+        Test a failure case where we want to parse an int as a long value.\n+        \"\"\"\n+        self.run_test(DataForTest(\n+            schema='''{\"doc\": \"Parse int as long (int64) fails.\",\n+                       \"namespace\": \"com.test.int.type.failure\",\n+                       \"type\": \"record\",\n+                       \"name\": \"data_row\",\n+                       \"fields\": [\n+                         {\"name\": \"index\", \"type\": \"int\"}\n+                       ]}''',\n+            data=[{'index': 0}],\n+            features={'index': parsing_ops.FixedLenFeature([], tf_types.int64)},\n+            should_pass=False", "path": "tensorflow/contrib/avro/python/tests/parse_avro_record_test.py", "position": null, "original_position": 421, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "abf605ba22c95f52116b765c90f889b9f17692c1", "user": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "body": "Consider adding an exception type or error message to expect.", "created_at": "2018-04-12T15:38:19Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r181127449", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181127449"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r181127449"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>Consider adding an exception type or error message to expect.</p>", "body_text": "Consider adding an exception type or error message to expect."}