{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/227141563", "pull_request_review_id": 167113622, "id": 227141563, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzE0MTU2Mw==", "diff_hunk": "@@ -0,0 +1,2058 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <regex>\n+#include <string>\n+#include <vector>\n+#include <algorithm>\n+#include <iterator>\n+\n+#include <avro.h>\n+\n+#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+namespace tensorflow {\n+\n+using ::tensorflow::shape_inference::ShapeHandle;\n+\n+// As boiler plate for the class I used\n+// tensorflow/core/util/example_proto_helper.h and therein\n+// \"ParseSingleExampleAttrs\".\n+\n+// Checks for valid type for the avro attributes; currently we support bool,\n+// int, long, float, double, string.\n+//\n+// 'dtype' The data type.\n+//\n+// returns OK if any of the supported types; otherwise false.\n+//\n+tensorflow::Status CheckValidType(const tensorflow::DataType& dtype);\n+\n+// Check that all dense shapes are defined. Here, 'defined' means that:\n+// * All shapes have at least one dimension.\n+// * A shape can have an undefined dimension -1, as first dimension.\n+//\n+// 'dense_shape' The dense shapes.\n+//\n+// returns OK if the shapes are defined; otherwise false.\n+//\n+tensorflow::Status CheckDenseShapeToBeDefined(\n+    const std::vector<tensorflow::PartialTensorShape>& dense_shapes);\n+\n+// Struct that holds information about dense tensors that is used during\n+// parsing.\n+struct DenseInformation {\n+  tensorflow::DataType type;             // Type\n+  tensorflow::PartialTensorShape shape;  // Shape\n+  bool variable_length;  // This dense tensor has a variable length in the 2nd\n+                         // dimension\n+  std::size_t elements_per_stride;  // Number of elements per stride\n+};\n+\n+// This class holds the attributes passed into the parse avro record function.\n+// In addition, it builds up information about the 'elements per stride',\n+// 'variable length' for dense tensors, and\n+// 'dense shape' information.\n+class ParseAvroAttrs {\n+ public:\n+  // Initializes the attribute information\n+  template <typename ContextType>\n+  tensorflow::Status Init(ContextType* ctx) {\n+    std::vector<tensorflow::DataType> dense_types;\n+    std::vector<tensorflow::PartialTensorShape> dense_shapes;\n+\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Nsparse\", &num_sparse));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Ndense\", &num_dense));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"sparse_types\", &sparse_types));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"Tdense\", &dense_types));\n+    TF_RETURN_IF_ERROR(ctx->GetAttr(\"dense_shapes\", &dense_shapes));\n+\n+    // Check that all dense shapes are defined\n+    TF_RETURN_IF_ERROR(CheckDenseShapeToBeDefined(dense_shapes));\n+\n+    for (int i_dense = 0; i_dense < dense_shapes.size(); ++i_dense) {\n+      DenseInformation dense_info;\n+      tensorflow::TensorShape dense_shape;\n+      // This is the case where we have a fixed len sequence feature, and the\n+      // 1st dimension is undefined.\n+      if (dense_shapes[i_dense].dims() > 0 &&\n+          dense_shapes[i_dense].dim_size(0) == -1) {\n+        dense_info.variable_length = true;\n+        for (int d = 1; d < dense_shapes[i_dense].dims(); ++d) {\n+          dense_shape.AddDim(dense_shapes[i_dense].dim_size(d));\n+        }\n+        // This is the case where all dimensions are defined.\n+      } else {\n+        dense_info.variable_length = false;\n+        dense_shapes[i_dense].AsTensorShape(&dense_shape);\n+      }\n+      // Fill in the remaining information into the dense info and add it to to\n+      // the vector\n+      dense_info.elements_per_stride = dense_shape.num_elements();\n+      dense_info.shape = dense_shapes[i_dense];\n+      dense_info.type = dense_types[i_dense];\n+      dense_infos.push_back(dense_info);\n+    }\n+    return FinishInit();\n+  }\n+\n+  // All these attributes are publicly accessible, hence we did not suffix them\n+  // with '_'.\n+  tensorflow::int64 num_sparse;  // Number of sparse features\n+  tensorflow::int64 num_dense;   // Number of dense features (fixed and variable\n+                                 // length)\n+  std::vector<tensorflow::DataType> sparse_types;  // Types for sparse features\n+  std::vector<DenseInformation> dense_infos;  // Information about each dense\n+                                              // tensor\n+ private:\n+  tensorflow::Status FinishInit();  // for context-independent parts of Init.\n+};\n+\n+// As boiler plate I used tensorflow/core/util/example_proto_helper.cc and\n+// therein \"ParseSingleExampleAttrs\" and\n+Status CheckValidType(const DataType& dtype) {\n+  switch (dtype) {\n+    case DT_BOOL:\n+    case DT_INT32:\n+    case DT_INT64:\n+    case DT_FLOAT:\n+    case DT_DOUBLE:\n+    case DT_STRING:\n+      return Status::OK();\n+    default:\n+      return errors::InvalidArgument(\"Received input dtype: \",\n+                                     DataTypeString(dtype));\n+  }\n+}\n+\n+Status CheckDenseShapeToBeDefined(\n+    const std::vector<PartialTensorShape>& dense_shapes) {\n+  for (int i = 0; i < dense_shapes.size(); ++i) {\n+    const PartialTensorShape& dense_shape = dense_shapes[i];\n+    bool shape_ok = true;\n+    if (dense_shape.dims() == -1) {\n+      shape_ok = false;\n+    } else {\n+      for (int d = 1; d < dense_shape.dims() && shape_ok; ++d) {\n+        if (dense_shape.dim_size(d) == -1) {\n+          shape_ok = false;\n+        }\n+      }\n+    }\n+    if (!shape_ok) {\n+      return errors::InvalidArgument(\n+          \"dense_shapes[\", i,\n+          \"] has unknown rank or unknown inner dimensions: \",\n+          dense_shape.DebugString());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// Finishes the initialization for the attributes, which essentially checks that\n+// the attributes have the correct values.\n+//\n+// returns OK if all attributes are valid; otherwise false.\n+Status ParseAvroAttrs::FinishInit() {\n+  if (static_cast<size_t>(num_sparse) != sparse_types.size()) {\n+    return errors::InvalidArgument(\"len(sparse_keys) != len(sparse_types)\");\n+  }\n+  if (static_cast<size_t>(num_dense) != dense_infos.size()) {\n+    return errors::InvalidArgument(\"len(dense_keys) != len(dense_infos)\");\n+  }\n+  if (num_dense > std::numeric_limits<int32>::max()) {\n+    return errors::InvalidArgument(\"num_dense_ too large\");\n+  }\n+  for (const DenseInformation& dense_info : dense_infos) {\n+    TF_RETURN_IF_ERROR(CheckValidType(dense_info.type));\n+  }\n+  for (const DataType& type : sparse_types) {\n+    TF_RETURN_IF_ERROR(CheckValidType(type));\n+  }\n+  return Status::OK();\n+}\n+\n+// Register the parse function when building the shared library\n+// For the op I used as boiler plate: tensorflow/core/ops/parsing_ops.cc and\n+// there 'ParseExample'\n+// For the op kernel I used as boiler plate:\n+// tensorflow/core/kernels/example_parsing_ops.cc and there 'ExampleParserOp'\n+// For the compute method I used as boiler plate:\n+// tensorflow/core/util/example_proto_fast_parsing.cc and there the\n+//   method 'FastParseExample'\n+\n+REGISTER_OP(\"ParseAvroRecord\")\n+    .Input(\"serialized: string\")\n+    .Input(\"sparse_keys: Nsparse * string\")\n+    .Input(\"dense_keys: Ndense * string\")\n+    .Input(\"dense_defaults: Tdense\")\n+    .Output(\"sparse_indices: Nsparse * int64\")\n+    .Output(\"sparse_values: sparse_types\")\n+    .Output(\"sparse_shapes: Nsparse * int64\")\n+    .Output(\"dense_values: Tdense\")\n+    .Attr(\"Nsparse: int >= 0\")  // Inferred from sparse_keys\n+    .Attr(\"Ndense: int >= 0\")   // Inferred from dense_keys\n+    .Attr(\"sparse_types: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"Tdense: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"dense_shapes: list(shape) >= 0\")\n+    .Attr(\"schema: string\")\n+    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n+\n+       ParseAvroAttrs attrs;\n+       TF_RETURN_IF_ERROR(attrs.Init(c));\n+\n+       // Get the batch size and load it into input\n+       ShapeHandle input;\n+       TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n+\n+       // Get the schema, parse it, and log it\n+       string schema;\n+       TF_RETURN_IF_ERROR(c->GetAttr(\"schema\", &schema));\n+\n+       std::unique_ptr<avro_schema_t, std::function<void(avro_schema_t*)>>\n+           p_reader_schema(new avro_schema_t, [](avro_schema_t* ptr) {\n+             avro_schema_decref(*ptr);\n+           });\n+       if (avro_schema_from_json_length(schema.c_str(), schema.length(),\n+                                        &(*p_reader_schema)) != 0) {\n+         return errors::InvalidArgument(\"The provided json schema is invalid. \",\n+                                        avro_strerror());\n+       }\n+       LOG(INFO) << \"Avro parser with schema\\n\" << schema;\n+\n+       int output_idx = 0;\n+\n+       // Output sparse_indices, sparse_values, sparse_shapes\n+       for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+         c->set_output(output_idx++, c->Matrix(c->UnknownDim(), 2));\n+       }\n+       for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+         c->set_output(output_idx++, c->Vector(c->UnknownDim()));\n+       }\n+       for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+         c->set_output(output_idx++, c->Vector(2));\n+       }\n+\n+       // Output dense_values\n+       for (int i_dense = 0; i_dense < attrs.num_dense; ++i_dense) {\n+         ShapeHandle dense;\n+         TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(\n+             attrs.dense_infos[i_dense].shape, &dense));\n+         TF_RETURN_IF_ERROR(c->Concatenate(input, dense, &dense));\n+         c->set_output(output_idx++, dense);\n+       }\n+\n+       return Status::OK();\n+     })\n+    .Doc(R\"doc(\n+      Parses a serialized avro record that follows the supplied schema into typed tensors.\n+      serialized: A vector containing a batch of binary serialized avro records.\n+      dense_keys: A list of Ndense string Tensors.\n+        The keys expected are associated with dense values.\n+      dense_defaults: A list of Ndense Tensors (some may be empty).\n+        These defaults can either be fully defined for all values in the tensor or they\n+        can be defined as padding element that is used whenever the original input data\n+        misses values to fill out the full tensor.\n+      dense_shapes: A list of Ndense shapes; the shapes of the dense tensors.\n+        The number of elements corresponding to dense_key[j]\n+        must always equal dense_shapes[j].NumEntries().\n+        If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output\n+        Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):\n+        The dense outputs are just the inputs row-stacked by batch.\n+        This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case\n+        the shape of the output Tensor dense_values[j] will be\n+        (|serialized|, M, D1, .., DN), where M is the maximum number of blocks\n+        of elements of length D1 * .... * DN, across all minibatch entries\n+        in the input.  Any minibatch entry with less than M blocks of elements of\n+        length D1 * ... * DN will be padded with the corresponding default_value\n+        scalar element along the second dimension.\n+      dense_types: A list of Ndense types; the type of data in each Feature given in dense_keys.\n+      sparse_keys: A list of Ndense string Tensors (scalars).\n+        The keys expected are associated with sparse values.\n+      sparse_types: A list of Nsparse types; the data types of data in each Feature\n+        given in sparse_keys.\n+      schema: A string that describes the avro schema of the underlying serialized avro string.\n+        Currently the parse function supports the primitive types DT_STRING, DT_DOUBLE, DT_FLOAT,\n+        DT_INT64, DT_INT32, and DT_BOOL.\n+        The supported avro version depends on the compiled library avro library linked against\n+        TensorFlow during build. More instructions on avro:\n+        https://avro.apache.org/docs/1.8.1/spec.html\n+    )doc\");\n+\n+template <typename T>\n+using SmallVector = gtl::InlinedVector<T, 4>;  // Up to 4 items are stored\n+                                               // without allocating heap memory\n+\n+// Parses the str into an positive integer number. Does not support '-'.\n+//\n+// 'str' is the string that represents a positive integer, e.g. '32482'.\n+//\n+// returns True if the string can be parsed into a positive integer, otherwise\n+// false.\n+//\n+bool IsNonNegativeInt(const string& str) {\n+  return !str.empty() && std::find_if(str.begin(), str.end(), [](char c) {\n+                           return !std::isdigit(c);\n+                         }) == str.end();\n+}\n+\n+// We use this Avro field representation when parsing user-defined strings to\n+// access types fields, maps, arrays in avro.\n+// An Avro field can be a name, index, key, or asterisk which is used as\n+// wildcard when parsing arrays.\n+// The base class AvroField is an abstract class that defines the avro field\n+// types and general methods.\n+class AvroField {\n+ public:\n+  enum Type {\n+    name,\n+    index,\n+    key,\n+    mapAsterisk,\n+    arrayAsterisk,\n+    arrayFilter\n+  };  // Types for an avro field\n+\n+  // Get the type for an Avro field.\n+  //\n+  // returns The avro type for this field.\n+  //\n+  virtual Type GetType() const = 0;\n+\n+  // Get a human-readable string representation of this Avro field.\n+  //\n+  // returns The string for this field.\n+  //\n+  virtual string ToString() const = 0;\n+\n+  virtual ~AvroField() {}\n+};\n+\n+// Represents a field name which is used to access records' fields.\n+class AvroFieldName : public AvroField {\n+ public:\n+  // Create an Avro field name.\n+  //\n+  // 'name' The name for this Avro field.\n+  //\n+  // returns An instance of 'AvroFieldName'.\n+  //\n+  AvroFieldName(const string& name) : name(name) {}\n+\n+  // Get the name for the Avro field.\n+  //\n+  // returns The name.\n+  //\n+  inline string GetName() const { return name; }\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::name; }\n+\n+  // Get the string representation, see super-class\n+  string ToString() const { return GetName(); }\n+\n+ private:\n+  string name;  // A string to hold the name\n+};\n+\n+// Represents an index which is used to access elements in arrays.\n+class AvroFieldIndex : public AvroField {\n+ public:\n+  // Create an Avro index.\n+  //\n+  // 'index' The index for this Avro field.\n+  //\n+  // returns An instance of 'AvroFieldIndex'.\n+  //\n+  AvroFieldIndex(int index) : index(index) {}\n+\n+  // Get the index of this Avro field.\n+  //\n+  // returns The index.\n+  //\n+  inline int GetIndex() const { return index; }\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::index; }\n+\n+  // Get the string representation, see super-class.\n+  string ToString() const { return std::to_string(GetIndex()); }\n+\n+ private:\n+  int index;  // index to hold\n+};\n+\n+// Represents a key of a map. Side note: We could have used the same type for a\n+// name field in a record and a key in\n+// a map since avro's low level API treats these cases the same way. However, we\n+// choose this cleaner design.\n+class AvroFieldKey : public AvroField {\n+ public:\n+  // Create an Avro field key.\n+  //\n+  // 'key' The key for this Avro field.\n+  //\n+  // returns An instance of 'AvroFieldKey'.\n+  AvroFieldKey(const string& key) : key(key) {}\n+\n+  // Get the key string for this Avro field.\n+  //\n+  // returns The key.\n+  inline string GetKey() const { return key; }\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::key; }\n+\n+  // Get the string representation, see super-class.\n+  string ToString() const { return GetKey(); }\n+\n+ private:\n+  string key;  // the key string\n+};\n+\n+// Used to select all values in a map.\n+class AvroFieldMapAsterisk : public AvroField {\n+ public:\n+  // Creates the Avro field map asterisk.\n+  //\n+  // returns An instance of 'AvroFieldMapAsterisk'.\n+  AvroFieldMapAsterisk() {}\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::mapAsterisk; }\n+\n+  // Get the string representation, see super-class.\n+  string ToString() const { return \"'*'\"; }\n+};\n+\n+// Used to select all items in an array.\n+class AvroFieldArrayAsterisk : public AvroField {\n+ public:\n+  // Creates the Avro field asterisk.\n+  //\n+  // returns An instance of 'AvroFieldAsterisk'.\n+  AvroFieldArrayAsterisk() {}\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::arrayAsterisk; }\n+\n+  // Get the string representation, see super-class.\n+  string ToString() const { return \"*\"; }\n+};\n+\n+// Filters are represented through a key and value pair. The key indicates which\n+// field the\n+// filter will be applied and the value is the criterion for the filter. Only\n+// supported for arrays.\n+class AvroFieldArrayFilter : public AvroField {\n+ public:\n+  // Creates the Avro field filter.\n+  //\n+  // returns An instance of 'AvroFieldFilter'.\n+  AvroFieldArrayFilter(const string& key, const string& value)\n+      : key(key), value(value) {}\n+\n+  // Get the type, see super-class.\n+  AvroField::Type GetType() const { return AvroField::Type::arrayFilter; }\n+\n+  // Get the key of this filter.\n+  inline string GetKey() const { return key; }\n+\n+  // Get the value of this filter.\n+  inline string GetValue() const { return value; }\n+\n+  // Get the string representation, see super-class.\n+  string ToString() const { return GetKey() + \"=\" + GetValue(); }\n+\n+ private:\n+  string key;    // the key of this filter\n+  string value;  // the value of this filter\n+};\n+\n+// The sparse buffer holds a list with primitive data types. This is used when\n+// parsing all tensors.\n+struct SparseBuffer {\n+  // Only the list that corresponds to the data type of the tensor is used\n+  SmallVector<string> string_list;\n+  SmallVector<double> double_list;\n+  SmallVector<float> float_list;\n+  SmallVector<int64> int64_list;\n+  SmallVector<int32> int32_list;\n+  SmallVector<bool> bool_list;      // TODO(fraudies): Change to\n+                                    // util::bitmap::InlinedBitVector<NBITS>\n+  std::vector<size_t> end_indices;  // End indices per row in the batch\n+  size_t n_elements;  // The total number of elements in the batch; required by\n+                      // 'SetValues' to accumulate.\n+};\n+\n+// Template specializations for 'GetListFromBuffer' for the supported types.\n+template <typename T>\n+const SmallVector<T>& GetListFromBuffer(const SparseBuffer& buffer);\n+\n+template <>\n+const SmallVector<int64>& GetListFromBuffer<int64>(const SparseBuffer& buffer) {\n+  return buffer.int64_list;\n+}\n+template <>\n+const SmallVector<int32>& GetListFromBuffer<int32>(const SparseBuffer& buffer) {\n+  return buffer.int32_list;\n+}\n+template <>\n+const SmallVector<float>& GetListFromBuffer<float>(const SparseBuffer& buffer) {\n+  return buffer.float_list;\n+}\n+template <>\n+const SmallVector<double>& GetListFromBuffer<double>(\n+    const SparseBuffer& buffer) {\n+  return buffer.double_list;\n+}\n+template <>\n+const SmallVector<bool>& GetListFromBuffer<bool>(const SparseBuffer& buffer) {\n+  return buffer.bool_list;\n+}\n+template <>\n+const SmallVector<string>& GetListFromBuffer<string>(\n+    const SparseBuffer& buffer) {\n+  return buffer.string_list;\n+}\n+\n+// Template specialization for 'CopyOrMoveBlock'; Note: 'string' values are\n+// moved, others are copied.\n+template <typename InputIterT, typename OutputIterT>\n+void CopyOrMoveBlock(const InputIterT b, const InputIterT e, OutputIterT t) {\n+  std::copy(b, e, t);\n+}\n+\n+template <>\n+void CopyOrMoveBlock(const string* b, const string* e, string* t) {\n+  std::move(b, e, t);\n+}\n+\n+// Checks that default values are available if required for filling in of\n+// values.\n+//\n+// This method is used to check that fixed len sequence features have the\n+// correct default. If any of the rows has less\n+// than 'n_elements_per_batch' values, we check that these can be filled in from\n+// the 'default_value' tensor.\n+//\n+// 'key' Name of the element that is parsed.\n+//\n+// 'n_elements_per_batch'  The number of elements in a batch.\n+//\n+// 'end_indices'  The end indices of the dense tensor as it is.\n+//\n+// 'default_value'  Tensor with default values. If we need to fill in this\n+// tensor must have at least\n+//                  'n_elements_per_batch' many elements.\n+//\n+// returns OK if we can fill in elements or no elements need to be filled in;\n+// otherwise false.\n+//\n+Status CheckDefaultsAvailable(const string& key,\n+                              const size_t n_elements_per_batch,\n+                              const std::vector<size_t>& end_indices,\n+                              const Tensor& default_value) {\n+  const size_t n_batches = end_indices.size();\n+  size_t n_total_elements_is = 0;\n+  const size_t n_default_elements = default_value.NumElements();\n+  const size_t n_elems_be = n_elements_per_batch;  // per row\n+  const bool not_enough_defaults = n_default_elements < n_elements_per_batch;\n+  for (size_t i_batches = 0; i_batches < n_batches; ++i_batches) {\n+    const size_t n_elems_is =\n+        end_indices[i_batches] - n_total_elements_is;  // per row\n+    n_total_elements_is = end_indices[i_batches];\n+    const size_t n_fill = n_elems_be - n_elems_is;\n+    if (n_fill > 0 && not_enough_defaults) {\n+      return errors::InvalidArgument(\"For key '\", key, \"' in batch \", i_batches,\n+                                     \" found \", n_elems_is, \" elements \",\n+                                     \"but for fixed length need \", n_elems_be,\n+                                     \" elements but default provides only \",\n+                                     n_default_elements, \" elements.\");\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// Checks that a default value is supplied.\n+//\n+// This method is used by the fixed len sequence feature.\n+//\n+// 'key' Name of the element that is parsed.\n+//\n+// 'default_value'  Tensor with default value. If we need to fill in this tensor\n+// must have at least 1 element.\n+//\n+// returns OK we have at least one element; otherwise false.\n+//\n+Status CheckDefaultAvailable(const string& key, const Tensor& default_value) {\n+  const bool no_default = default_value.NumElements() <= 0;\n+  if (no_default) {\n+    return errors::InvalidArgument(\"For key '\", key, \"' no default is set in \",\n+                                   default_value.DebugString());\n+  }\n+  return Status::OK();\n+}\n+\n+// Fills in defaults from values in the 'default_tensor'. Note, if there is\n+// nothing to fill in the method leaves\n+// 'values' unchanged.\n+//\n+// 'n_elements' The total number of elements that shall be.\n+//\n+// 'n_elements_per_batch' The number of elements per batch that shall be.\n+//\n+// 'end_indices'  The end indices per batch that are.\n+//\n+// 'values' The result tensor.\n+//\n+template <typename T>\n+void FillInFromValues(const size_t n_elements,\n+                      const size_t n_elements_per_batch,\n+                      const Tensor& default_value,\n+                      const std::vector<size_t>& end_indices, Tensor* values) {\n+  auto tensor_data_ptr = values->flat<T>().data();\n+  const size_t n_batches = end_indices.size();\n+  auto list_ptr = default_value.flat<T>().data();\n+  size_t n_total_elements = 0;\n+  for (size_t i_batches = 0; i_batches < n_batches; ++i_batches) {\n+    const size_t n_elems = end_indices[i_batches] - n_total_elements;\n+    CopyOrMoveBlock(list_ptr + n_elems, list_ptr + n_elements_per_batch,\n+                    tensor_data_ptr + n_elems);\n+    tensor_data_ptr += n_elements_per_batch;\n+    n_total_elements = end_indices[i_batches];\n+  }\n+}\n+\n+// Copy a variable length dense tensor from the 'buffer' into 'values' using the\n+// 'end_indices' to identify the blocks\n+// that shall be copied per batch.\n+//\n+// 'n_elements' The overall number of elements.\n+//\n+// 'n_elements_per_batch' The number of elements in a batch.  Note, that the\n+// 'buffer' may not have that many elements\n+//                        per batch and we have separate methods to fill these\n+// with defaults.\n+//\n+// 'buffer' The buffer that contains the 'end_indices' and a flattened list of\n+// all values for one batch.\n+//\n+// 'values' The result tensor.\n+//\n+template <typename T>\n+void CopyVarLen(const size_t n_elements, const size_t n_elements_per_batch,\n+                const SparseBuffer& buffer, Tensor* values) {\n+\n+  // Data is [batch_size, max_num_elements, data_stride_size]\n+  //   and num_elements_per_minibatch = max_num_elements * data_stride_size\n+  auto tensor_data_ptr = values->flat<T>().data();\n+\n+  // Number of examples being stored in this buffer\n+  const auto& end_indices = buffer.end_indices;\n+  const size_t n_batches = end_indices.size();\n+\n+  const auto& list = GetListFromBuffer<T>(buffer);\n+  auto list_ptr = list.begin();\n+\n+#ifdef DEBUG_LOG_ENABLED\n+  auto list_ptr_ = list.begin();\n+  for (size_t i_elem = 0; i_elem < buffer.n_elements; ++i_elem) {\n+    LOG(INFO) << *list_ptr_ << \", \";\n+    list_ptr_++;\n+  }\n+#endif\n+\n+  size_t n_total_elements = 0;\n+  // Iterate through all the examples stored in this buffer.\n+  for (size_t i_batches = 0; i_batches < n_batches; ++i_batches) {\n+    // Number of elements stored for this example.\n+    const size_t n_elems = end_indices[i_batches] - n_total_elements;\n+    CopyOrMoveBlock(list_ptr, list_ptr + n_elems, tensor_data_ptr);\n+    // Move forward this many elements in the varlen buffer.\n+    list_ptr += n_elems;\n+    // Move forward to the next batch entry in the values output.\n+    tensor_data_ptr += n_elements_per_batch;\n+    n_total_elements = end_indices[i_batches];\n+  }\n+\n+#ifdef DEBUG_LOG_ENABLED\n+  for (size_t i_batches = 0; i_batches < n_batches; ++i_batches) {\n+    LOG(INFO) << \"End [\" << i_batches << \"] = \" << end_indices[i_batches];\n+  }\n+  LOG(INFO) << \"Total \" << n_total_elements << \" elements; counted \"\n+            << list.size() << \" elements.\";\n+  LOG(INFO) << \"Number of \" << n_elements_per_batch << \" per batch.\";\n+#endif\n+\n+  DCHECK(n_total_elements == list.size());\n+}\n+\n+// Fills in from a scalar in 'default_value' and copies from 'buffer' into\n+// 'values'.\n+//\n+// Pre-fills all values with 'default_value' and then copies in the supplied\n+// values from the 'buffer'.\n+// This code is mostly borrowed from\n+// 'tensorflow/core/util/example_proto_fast_parsing.cc' and therein the method\n+// 'FillInFixedLen'.\n+//\n+// 'n_elements' The total number of elements.\n+//\n+// 'n_elements_per_batch' The number of elements in a batch.\n+//\n+// 'buffer' The buffer with the parsed elements.\n+//\n+// 'default_value' The tensor with the scalar default value, which we assume\n+// exists here.\n+//\n+// 'values' The return tensors.\n+//\n+template <typename T>\n+void FillFromScalarAndCopy(const size_t n_elements,\n+                           const size_t n_elements_per_batch,\n+                           const SparseBuffer& buffer,\n+                           const Tensor& default_value, Tensor* values) {\n+\n+  // Fill tensor with default to create padding\n+  std::fill(values->flat<T>().data(), values->flat<T>().data() + n_elements,\n+            default_value.flat<T>()(0));\n+\n+  CopyVarLen<T>(n_elements, n_elements_per_batch, buffer, values);\n+}\n+\n+// Defines a TensorFlow operator that parses an Avro string into TensorFlow\n+// native tensors.\n+// It uses avro c and proto (because of TensorFlow's design).\n+//\n+// When developing this parse function I took inspiration from:\n+// tensorflow/core/util/example_proto_fast_parsing.cc\n+// TODO(fraudies): Run valgrind on this to check for memory leaks\n+class ParseAvroRecordOp : public OpKernel {\n+ public:\n+  // Constructs the parse op. This function does not include the parsing of the\n+  // strings into AvroTypes because these\n+  // strings are considered inputs and might change with each call of the\n+  // 'Compute' function. So, no caching is possible\n+  // for these. This follows the design in\n+  // tensorflow/core/util/example_proto_fast_parsing.cc.\n+  //\n+  // 'ctx' The context to the TensorFlow environment that helps to create\n+  // tensors and error messages.\n+  //\n+  // returns An instance of 'ParseAvroRecordOp'.\n+  //\n+  explicit ParseAvroRecordOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n+    string schema;\n+\n+    // Clear error message for avro\n+    avro_set_error(\"\");\n+\n+    // Get the schema supplied by the user as string and parse it\n+    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"schema\", &schema));\n+    std::unique_ptr<avro_schema_t, std::function<void(avro_schema_t*)>>\n+        p_reader_schema(new avro_schema_t,\n+                        [](avro_schema_t* ptr) { avro_schema_decref(*ptr); });\n+\n+    OP_REQUIRES(ctx,\n+                avro_schema_from_json_length(schema.c_str(), schema.length(),\n+                                             &(*p_reader_schema)) == 0,\n+                errors::InvalidArgument(\"The provided json schema is invalid. \",\n+                                        avro_strerror()));\n+\n+    // Get a generic Avro class and instance of that class\n+    p_iface_ = avro_generic_class_from_schema((*p_reader_schema));\n+    OP_REQUIRES(ctx, p_iface_ != nullptr,\n+                errors::InvalidArgument(\n+                    \"Unable to create class for user-supplied schema. \",\n+                    avro_strerror()));\n+\n+    // Get attributes\n+    OP_REQUIRES_OK(ctx, attrs_.Init(ctx));\n+  }\n+\n+  // Destructor used for clean-up of avro structures.\n+  virtual ~ParseAvroRecordOp() { avro_value_iface_decref(p_iface_); }", "path": "tensorflow/contrib/avro/ops/parse_avro_record.cc", "position": null, "original_position": 799, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "d1be9e544357e72eb37f6adb626670f745e79a9b", "user": {"login": "fraudies", "id": 1770877, "node_id": "MDQ6VXNlcjE3NzA4Nzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1770877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fraudies", "html_url": "https://github.com/fraudies", "followers_url": "https://api.github.com/users/fraudies/followers", "following_url": "https://api.github.com/users/fraudies/following{/other_user}", "gists_url": "https://api.github.com/users/fraudies/gists{/gist_id}", "starred_url": "https://api.github.com/users/fraudies/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fraudies/subscriptions", "organizations_url": "https://api.github.com/users/fraudies/orgs", "repos_url": "https://api.github.com/users/fraudies/repos", "events_url": "https://api.github.com/users/fraudies/events{/privacy}", "received_events_url": "https://api.github.com/users/fraudies/received_events", "type": "User", "site_admin": false}, "body": "Replaced.", "created_at": "2018-10-22T21:16:35Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r227141563", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/227141563"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r227141563"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>Replaced.</p>", "body_text": "Replaced.", "in_reply_to_id": 209789904}