{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226799441", "pull_request_review_id": 166717869, "id": 226799441, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNjc5OTQ0MQ==", "diff_hunk": "@@ -0,0 +1,419 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <avro.h>\n+\n+#include \"tensorflow/core/framework/dataset.h\"\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n+#include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/io/buffered_inputstream.h\"\n+#include \"tensorflow/core/lib/io/inputbuffer.h\"\n+\n+// As boiler plate I used\n+// https://github.com/tensorflow/tensorflow/core/kernels/reader_dataset_ops.cc\n+// https://github.com/tensorflow/tensorflow/blob/v1.4.1/tensorflow/core/ops/dataset_ops.cc\n+// (register op)\n+\n+namespace tensorflow {\n+\n+// Register the avro record dataset operator\n+REGISTER_OP(\"AvroRecordDataset\")\n+    .Input(\"filenames: string\")\n+    .Input(\"schema: string\")\n+    .Input(\"buffer_size: int64\")\n+    .Output(\"handle: variant\")\n+    .SetIsStateful()\n+    .SetShapeFn(shape_inference::ScalarShape)\n+    .Doc(R\"doc(\n+Creates a dataset that emits the avro records from one or more files.\n+filenames: A scalar or vector containing the name(s) of the file(s) to be\n+  read.\n+schema: A string used that is used for schema resolution.\n+)doc\");\n+\n+// This class represents the avro reader options\n+class AvroReaderOptions {\n+ public:\n+  // Creates avro reader options with the given schema and buffer size.\n+  //\n+  static AvroReaderOptions CreateAvroReaderOptions(const string& schema,\n+                                                   int64 buffer_size) {\n+    AvroReaderOptions options;\n+    options.schema = schema;\n+    options.buffer_size = buffer_size;\n+    return options;\n+  }\n+  string schema;\n+  int64 buffer_size =\n+      256 * 1024;  // 256 kB as default but this can be overwritten by the user\n+};\n+\n+void AvroFileReaderDestructor(avro_file_reader_t reader) {\n+  // I don't think we need the CHECK_NOTNULL\n+  CHECK_GE(avro_file_reader_close(reader), 0);\n+}\n+\n+void AvroSchemaDestructor(avro_schema_t schema) {\n+  // Confusingly, it appears that the avro_file_reader_t creates its\n+  // own reference to this schema, so the schema is not really\n+  // \"uniquely\" owned...\n+  CHECK_GE(avro_schema_decref(schema), 0);\n+};\n+\n+void AvroValueInterfaceDestructor(avro_value_iface_t * iface)  {\n+  avro_value_iface_decref(iface);\n+}\n+\n+\n+// This reader is not thread safe\n+class SequentialAvroRecordReader {\n+ public:\n+  // Construct a sequential avro record reader\n+  //\n+  // 'file' is the random access file\n+  //\n+  // 'file_size' is the size of the file\n+  //\n+  // 'filename' is the name of the file\n+  //\n+  // 'options' are avro reader options\n+  //\n+  SequentialAvroRecordReader(RandomAccessFile* file, const uint64 file_size,\n+                             const string& filename,\n+                             const AvroReaderOptions& options =\n+                                 AvroReaderOptions())\n+    : initialized_(false),\n+      filename_(filename),\n+      file_buffer_(file_size, '\\0'),\n+      input_buffer_size_(options.buffer_size),\n+      input_buffer_(new io::InputBuffer(file, options.buffer_size)),\n+      reader_schema_str_(options.schema),\n+      file_reader_(nullptr, AvroFileReaderDestructor),\n+      reader_schema_(nullptr, AvroSchemaDestructor),\n+      writer_schema_(nullptr, AvroSchemaDestructor),\n+      p_reader_iface_(nullptr, AvroValueInterfaceDestructor),\n+      p_writer_iface_(nullptr, AvroValueInterfaceDestructor) { }\n+  virtual ~SequentialAvroRecordReader() {\n+    // Guard against clean-up of non-initialized instances\n+    if (initialized_) {\n+      avro_value_decref(&reader_value_);\n+      avro_value_decref(&writer_value_);\n+    }\n+  }\n+  // Reads the next record into the string record\n+  //\n+  // 'record' pointer to the string where to load the record in\n+  //\n+  // returns Status about this operation\n+  //\n+  Status ReadRecord(string* record) {\n+    bool at_end =\n+      avro_file_reader_read_value(file_reader_.get(), &writer_value_) != 0;\n+    // Are writer_value_ and reader_value_ aliases to the same thing???\n+    size_t len;\n+    if (avro_value_sizeof(&reader_value_, &len)) {\n+      return Status(errors::InvalidArgument(\"Could not find size of value, \",\n+                                            avro_strerror()));\n+    }\n+    record->resize(len);\n+    avro_writer_t mem_writer = avro_writer_memory(record->data(), len);\n+    if (avro_value_write(mem_writer, &reader_value_)) {\n+      avro_writer_free(mem_writer);\n+      return Status(errors::InvalidArgument(\"Unable to write value to memory.\"));\n+    }\n+    avro_writer_free(mem_writer);\n+    return at_end ? errors::OutOfRange(\"eof\") : Status::OK();\n+  }\n+  // Call for startup of work after construction. Loads data into memory and\n+  // sets up the avro file reader\n+  //\n+  // returns Status about this operation\n+  //\n+  Status OnWorkStartup() {\n+    // Clear the error message, so we won't get a wrong message\n+    avro_set_error(\"\");\n+    Status status;\n+\n+    // Read the file into memory via the gfile API so we can accept\n+    // files on S3, HDFS, etc.\n+    TF_RETURN_IF_ERROR(CreateAndLoadFileIntoBuffer(input_buffer_size_));\n+    FILE* fp = fmemopen(static_cast<void*>(const_cast<char*>(file_buffer_.data())),\n+                        file_buffer_.size(), \"r\");\n+    if (fp == nullptr) {\n+      return Status(errors::InvalidArgument(\"Unable to open file \", filename_,\n+                                            \" on memory in avro reader.\"));\n+    }\n+\n+    // Get an avro file reader for that file handle, the 1 indicates to close\n+    // the file handle when done\n+    avro_file_reader_t file_reader_tmp;\n+    if (avro_file_reader_fp(fp, filename_.c_str(), 1, &file_reader_tmp) != 0) {\n+      return Status(errors::InvalidArgument(\"Unable to open file \", filename_,\n+                                            \" in avro reader. \", avro_strerror()));\n+    }\n+    file_reader_.reset(file_reader_tmp);\n+\n+    writer_schema_.reset(avro_file_reader_get_writer_schema(file_reader_.get()));\n+\n+    // The user provided a schema for the reader, check if we need to do schema\n+    // resolution\n+    bool do_resolution = false;\n+    if (reader_schema_str_.length() > 0) {\n+\n+      avro_schema_t reader_schema_tmp;\n+      // Create value to read into using the provided schema\n+      if (avro_schema_from_json_length(reader_schema_str_.data(),\n+                                       reader_schema_str_.length(),\n+                                       &reader_schema_tmp) != 0) {\n+        return Status(errors::InvalidArgument(\n+            \"The provided json schema is invalid. \", avro_strerror()));\n+      }\n+      reader_schema_.reset(reader_schema_tmp);\n+      do_resolution = !avro_schema_equal(writer_schema_.get(), reader_schema_.get());\n+      // We need to do a schema resolution, if the schemas are not the same\n+    }\n+\n+    if (do_resolution) {\n+      // Create reader class\n+      p_reader_iface_.reset(avro_generic_class_from_schema(reader_schema_.get()));\n+      // Create instance for reader class\n+      if (avro_generic_value_new(p_reader_iface_.get(), &reader_value_) != 0) {\n+        return Status(errors::InvalidArgument(\n+            \"Unable to value for user-supplied schema. \", avro_strerror()));\n+      }\n+      // Create resolved writer class\n+      p_writer_iface_.reset(avro_resolved_writer_new(writer_schema_.get(), reader_schema_.get()));\n+      if (p_writer_iface_.get() == nullptr) {\n+        // Cleanup\n+        avro_value_decref(&reader_value_);\n+        return Status(errors::InvalidArgument(\"Schemas are incompatible. \",\n+                                              avro_strerror()));\n+      }\n+      // Create instance for resolved writer class\n+      if (avro_resolved_writer_new_value(p_writer_iface_.get(), &writer_value_) !=\n+          0) {\n+        // Cleanup\n+        avro_value_decref(&reader_value_);\n+        return Status(\n+            errors::InvalidArgument(\"Unable to create resolved writer.\"));\n+      }\n+      avro_resolved_writer_set_dest(&writer_value_, &reader_value_);\n+    } else {\n+      p_writer_iface_.reset(avro_generic_class_from_schema(writer_schema_.get()));\n+      if (avro_generic_value_new(p_writer_iface_.get(), &writer_value_) != 0) {\n+        return Status(errors::InvalidArgument(\n+            \"Unable to create instance for generic class.\"));\n+      }\n+      // The reader_value_ is the same as the writer_value_ in the case we do\n+      // not need to resolve the schema\n+      avro_value_copy_ref(&reader_value_, &writer_value_);\n+    }\n+\n+    // We initialized this avro record reader\n+    initialized_ = true;\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  // Loads file contents into file_buffer_\n+  //\n+  // 'read_buffer_size' buffer size when reading file contents\n+  //\n+  Status CreateAndLoadFileIntoBuffer(int64 read_buffer_size) {\n+    int64 total_bytes_read = 0;\n+    Status status;\n+\n+    // While we still need to read data\n+    char* buffer = const_cast<char*>(file_buffer_.data());\n+    while (total_bytes_read < file_buffer_.size()) {\n+      size_t bytes_read;\n+      status = input_buffer_->ReadNBytes(read_buffer_size, buffer,\n+                                         &bytes_read);", "path": "tensorflow/contrib/avro/ops/avro_record_dataset.cc", "position": null, "original_position": 247, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "d1be9e544357e72eb37f6adb626670f745e79a9b", "user": {"login": "fraudies", "id": 1770877, "node_id": "MDQ6VXNlcjE3NzA4Nzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1770877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fraudies", "html_url": "https://github.com/fraudies", "followers_url": "https://api.github.com/users/fraudies/followers", "following_url": "https://api.github.com/users/fraudies/following{/other_user}", "gists_url": "https://api.github.com/users/fraudies/gists{/gist_id}", "starred_url": "https://api.github.com/users/fraudies/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fraudies/subscriptions", "organizations_url": "https://api.github.com/users/fraudies/orgs", "repos_url": "https://api.github.com/users/fraudies/repos", "events_url": "https://api.github.com/users/fraudies/events{/privacy}", "received_events_url": "https://api.github.com/users/fraudies/received_events", "type": "User", "site_admin": false}, "body": "Agreed. Removed the input buffer and I'm using the Read function directly.", "created_at": "2018-10-19T22:46:29Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r226799441", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/226799441"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r226799441"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>Agreed. Removed the input buffer and I'm using the Read function directly.</p>", "body_text": "Agreed. Removed the input buffer and I'm using the Read function directly.", "in_reply_to_id": 209785301}