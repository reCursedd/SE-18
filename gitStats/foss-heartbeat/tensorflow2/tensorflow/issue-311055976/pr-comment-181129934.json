{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181129934", "pull_request_review_id": 111647900, "id": 181129934, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTEyOTkzNA==", "diff_hunk": "@@ -0,0 +1,222 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import logging\n+import os\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import load_library\n+from tensorflow.core.framework import op_def_pb2 as _op_def_pb2\n+from tensorflow.core.framework import types_pb2 as _types_pb2\n+from tensorflow.python.data.ops.dataset_ops import Dataset\n+from tensorflow.python.framework import tensor_shape\n+from tensorflow.python.eager import context as _context\n+from tensorflow.python.eager import execute as _execute\n+from tensorflow.python.framework import op_def_library as _op_def_library\n+from tensorflow.python.framework import op_def_registry as _registry\n+\n+# Load the native method\n+this_dir = os.path.dirname(os.path.abspath(__file__))\n+lib_name = os.path.join(this_dir, '_avro_record_dataset.so')\n+reader_module = load_library.load_op_library(lib_name)\n+\n+_DEFAULT_READER_BUFFER_SIZE_BYTES = 256 * 1024  # 256 KB\n+\n+\n+def _create_avro_dataset_op_proto():\n+    \"\"\"\n+    Creates the proto definition for the Avro dataset operator.\n+\n+    :return: proto definition for the Avro dataset operator.\n+    \"\"\"\n+\n+    # Create a proto representation for the new op\n+    # op {\n+    #   name: \"AvroRecordDataset\"\n+    #   input_arg {\n+    #     name: \"filenames\"\n+    #     type: DT_STRING\n+    #   }\n+    #   input_arg {\n+    #     name: \"schema\"\n+    #     type: DT_STRING\n+    #   }\n+    #   input_arg {\n+    #     name: \"buffer_size\"\n+    #     type: DT_INT64\n+    #   }\n+    #   output_arg {\n+    #     name: \"handle\"\n+    #     type: DT_VARIANT\n+    #   }\n+    #   is_stateful: true\n+    # }\n+\n+    # Create the operator definition\n+    avro_dataset_op = _op_def_pb2.OpDef()\n+    avro_dataset_op.name = \"AvroRecordDataset\"\n+\n+    # Create and add the input arguments\n+    input_filenames = _op_def_pb2.OpDef.ArgDef()\n+    input_filenames.name = \"filenames\"\n+    input_filenames.type = _types_pb2.DT_STRING\n+    input_schema = _op_def_pb2.OpDef.ArgDef()\n+    input_schema.name = \"schema\"\n+    input_schema.type = _types_pb2.DT_STRING\n+    input_buffer_size = _op_def_pb2.OpDef.ArgDef()\n+    input_buffer_size.name = \"buffer_size\"\n+    input_buffer_size.type = _types_pb2.DT_INT64\n+    avro_dataset_op.input_arg.extend([input_filenames, input_schema, input_buffer_size])\n+\n+    # Create and add the output argument\n+    output_handle = _op_def_pb2.OpDef.ArgDef()\n+    output_handle.name = \"handle\"\n+    output_handle.type = _types_pb2.DT_VARIANT\n+    avro_dataset_op.output_arg.extend([output_handle])\n+\n+    # This method is stateful because it keeps a counter into rows/records\n+    avro_dataset_op.is_stateful = True\n+\n+    return avro_dataset_op\n+\n+\n+def _create_op_def_library(op_proto):\n+    \"\"\"\n+    Creates a customized operator definition library for the given op_proto.\n+\n+    Notice that this method will check that a CC implementation for this method with the SAME signature has been\n+    registered with TensorFlow.  Make sure to load the native code before calling this method.\n+\n+    :return: A operation definition library.\n+    \"\"\"\n+    # Log the proto representation of the operator\n+    logging.info(\"Adding operator {} to the library.\".format(op_proto))\n+\n+    # Register the new op with TF and create an op library for it\n+    # Note: The native cc code will register the operator in _registered_ops, This is for checking\n+    registered_ops = _registry.get_registered_ops()\n+    if op_proto.name not in registered_ops:\n+        raise RuntimeError(\"Could not find native implementation of op '{}'.\".format(op_proto.name))\n+\n+    op_def_lib = _op_def_library.OpDefLibrary()\n+    ops_proto = _op_def_pb2.OpList()\n+    ops_proto.op.extend([op_proto])\n+\n+    # Make sure the registered op matches this one by re-registering it\n+    _registry.register_op_list(ops_proto)  # Will fail if the natively registered op differs\n+\n+    # Add the op to the customized operator library\n+    op_def_lib.add_op_list(ops_proto)\n+\n+    return op_def_lib\n+\n+\n+# Load the customized operator library which contains only our avro dataset operator -- but that is enough here\n+_op_def_lib = _create_op_def_library(_create_avro_dataset_op_proto())\n+\n+\n+def _convert_optional_param_to_tensor(argument_name,", "path": "tensorflow/contrib/avro/python/avro_record_dataset.py", "position": null, "original_position": 121, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "abf605ba22c95f52116b765c90f889b9f17692c1", "user": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "body": "Why not import tensorflow.python.data.util.convert instead of copying?", "created_at": "2018-04-12T15:45:12Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r181129934", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181129934"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r181129934"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>Why not import tensorflow.python.data.util.convert instead of copying?</p>", "body_text": "Why not import tensorflow.python.data.util.convert instead of copying?"}