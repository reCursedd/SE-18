{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/180931787", "pull_request_review_id": 111439622, "id": 180931787, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MDkzMTc4Nw==", "diff_hunk": "@@ -0,0 +1,1630 @@\n+#include <avro.h>\n+#include <vector>\n+#include <algorithm>\n+#include <iterator>\n+#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"avro_helper.h\"\n+\n+using namespace tensorflow;\n+using ::tensorflow::shape_inference::ShapeHandle;\n+\n+template <typename T>\n+using SmallVector = gtl::InlinedVector<T, 4>; // Up to 4 items are stored without allocating heap memory\n+\n+// Register the parse function when building the shared library\n+// For the op I used as boiler plate: tensorflow/core/ops/parsing_ops.cc and there 'ParseExample'\n+// For the op kernel I used as boiler plate: tensorflow/core/kernels/example_parsing_ops.cc and there 'ExampleParserOp'\n+// For the compute method I used as boiler plate: tensorflow/core/util/example_proto_fast_parsing.cc and there the\n+//   method 'FastParseExample'\n+\n+REGISTER_OP(\"ParseAvroRecord\")\n+    .Input(\"serialized: string\")\n+    .Input(\"sparse_keys: Nsparse * string\")\n+    .Input(\"dense_keys: Ndense * string\")\n+    .Input(\"dense_defaults: Tdense\")\n+    .Output(\"sparse_indices: Nsparse * int64\")\n+    .Output(\"sparse_values: sparse_types\")\n+    .Output(\"sparse_shapes: Nsparse * int64\")\n+    .Output(\"dense_values: Tdense\")\n+    .Attr(\"Nsparse: int >= 0\")  // Inferred from sparse_keys\n+    .Attr(\"Ndense: int >= 0\")   // Inferred from dense_keys\n+    .Attr(\"sparse_types: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"Tdense: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"dense_shapes: list(shape) >= 0\")\n+    .Attr(\"schema: string\")\n+    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n+\n+      ParseAvroAttrs attrs;\n+      TF_RETURN_IF_ERROR(attrs.Init(c));\n+\n+      // Get the batch size and load it into input\n+      ShapeHandle input;\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n+\n+      string schema;\n+      avro_schema_t reader_schema;\n+\n+      // Parse schema\n+      TF_RETURN_IF_ERROR(c->GetAttr(\"schema\", &schema));\n+      TF_RETURN_IF_ERROR(avro_schema_from_json_length(schema.c_str(), schema.length(), &reader_schema) == 0 ?\n+        Status::OK() : errors::InvalidArgument(\"The provided json schema is invalid. \", avro_strerror()));\n+\n+      int output_idx = 0;\n+\n+      // Output sparse_indices, sparse_values, sparse_shapes\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Matrix(c->UnknownDim(), 2));\n+      }\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Vector(c->UnknownDim()));\n+      }\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Vector(2));\n+      }\n+\n+      // Output dense_values\n+      for (int i_dense = 0; i_dense < attrs.num_dense; ++i_dense) {\n+        ShapeHandle dense;\n+        TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(attrs.dense_infos[i_dense].shape, &dense));\n+        TF_RETURN_IF_ERROR(c->Concatenate(input, dense, &dense));\n+        c->set_output(output_idx++, dense);\n+      }\n+\n+      // Cleanup of the reader schema\n+      avro_schema_decref(reader_schema);", "path": "tensorflow/contrib/avro/ops/parse_avro_record.cc", "position": null, "original_position": 84, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "abf605ba22c95f52116b765c90f889b9f17692c1", "user": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "body": "This will leak if there's an error above, use unique_ptr with a custom deleter or similar.", "created_at": "2018-04-11T23:56:43Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r180931787", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/180931787"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r180931787"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>This will leak if there's an error above, use unique_ptr with a custom deleter or similar.</p>", "body_text": "This will leak if there's an error above, use unique_ptr with a custom deleter or similar."}