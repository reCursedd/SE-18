{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/180936085", "pull_request_review_id": 111439622, "id": 180936085, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MDkzNjA4NQ==", "diff_hunk": "@@ -0,0 +1,1630 @@\n+#include <avro.h>\n+#include <vector>\n+#include <algorithm>\n+#include <iterator>\n+#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/shape_inference.h\"\n+#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"avro_helper.h\"\n+\n+using namespace tensorflow;\n+using ::tensorflow::shape_inference::ShapeHandle;\n+\n+template <typename T>\n+using SmallVector = gtl::InlinedVector<T, 4>; // Up to 4 items are stored without allocating heap memory\n+\n+// Register the parse function when building the shared library\n+// For the op I used as boiler plate: tensorflow/core/ops/parsing_ops.cc and there 'ParseExample'\n+// For the op kernel I used as boiler plate: tensorflow/core/kernels/example_parsing_ops.cc and there 'ExampleParserOp'\n+// For the compute method I used as boiler plate: tensorflow/core/util/example_proto_fast_parsing.cc and there the\n+//   method 'FastParseExample'\n+\n+REGISTER_OP(\"ParseAvroRecord\")\n+    .Input(\"serialized: string\")\n+    .Input(\"sparse_keys: Nsparse * string\")\n+    .Input(\"dense_keys: Ndense * string\")\n+    .Input(\"dense_defaults: Tdense\")\n+    .Output(\"sparse_indices: Nsparse * int64\")\n+    .Output(\"sparse_values: sparse_types\")\n+    .Output(\"sparse_shapes: Nsparse * int64\")\n+    .Output(\"dense_values: Tdense\")\n+    .Attr(\"Nsparse: int >= 0\")  // Inferred from sparse_keys\n+    .Attr(\"Ndense: int >= 0\")   // Inferred from dense_keys\n+    .Attr(\"sparse_types: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"Tdense: list({float,double,int64,int32,string,bool}) >= 0\")\n+    .Attr(\"dense_shapes: list(shape) >= 0\")\n+    .Attr(\"schema: string\")\n+    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n+\n+      ParseAvroAttrs attrs;\n+      TF_RETURN_IF_ERROR(attrs.Init(c));\n+\n+      // Get the batch size and load it into input\n+      ShapeHandle input;\n+      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input));\n+\n+      string schema;\n+      avro_schema_t reader_schema;\n+\n+      // Parse schema\n+      TF_RETURN_IF_ERROR(c->GetAttr(\"schema\", &schema));\n+      TF_RETURN_IF_ERROR(avro_schema_from_json_length(schema.c_str(), schema.length(), &reader_schema) == 0 ?\n+        Status::OK() : errors::InvalidArgument(\"The provided json schema is invalid. \", avro_strerror()));\n+\n+      int output_idx = 0;\n+\n+      // Output sparse_indices, sparse_values, sparse_shapes\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Matrix(c->UnknownDim(), 2));\n+      }\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Vector(c->UnknownDim()));\n+      }\n+      for (int i_sparse = 0; i_sparse < attrs.num_sparse; ++i_sparse) {\n+        c->set_output(output_idx++, c->Vector(2));\n+      }\n+\n+      // Output dense_values\n+      for (int i_dense = 0; i_dense < attrs.num_dense; ++i_dense) {\n+        ShapeHandle dense;\n+        TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(attrs.dense_infos[i_dense].shape, &dense));\n+        TF_RETURN_IF_ERROR(c->Concatenate(input, dense, &dense));\n+        c->set_output(output_idx++, dense);\n+      }\n+\n+      // Cleanup of the reader schema\n+      avro_schema_decref(reader_schema);\n+\n+      // All ok\n+      return Status::OK();\n+\n+    }).Doc(R\"doc(\n+      Parses a serialized avro record that follows the supplied schema into typed tensors.\n+      serialized: A vector containing a batch of binary serialized avro records.\n+      dense_keys: A list of n_dense string Tensors (scalars).\n+        The keys expected are associated with dense values.\n+      dense_defaults: A list of Ndense Tensors (some may be empty).\n+        dense_defaults[j] provides default values\n+        when the example's feature_map lacks dense_key[j].  If an empty Tensor is\n+        provided for dense_defaults[j], then the Feature dense_keys[j] is required.\n+        The input type is inferred from dense_defaults[j], even when it's empty.\n+        If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,\n+        then the shape of dense_defaults[j] must match that of dense_shapes[j].\n+        If dense_shapes[j] has an undefined major dimension (variable strides dense\n+        feature), dense_defaults[j] must contain a single element:\n+        the padding element.\n+      dense_shapes: A list of Ndense shapes; the shapes of data in each Feature\n+        given in dense_keys.\n+        The number of elements in the Feature corresponding to dense_key[j]\n+        must always equal dense_shapes[j].NumEntries().\n+        If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output\n+        Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):\n+        The dense outputs are just the inputs row-stacked by batch.\n+        This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case\n+        the shape of the output Tensor dense_values[j] will be\n+        (|serialized|, M, D1, .., DN), where M is the maximum number of blocks\n+        of elements of length D1 * .... * DN, across all minibatch entries\n+        in the input.  Any minibatch entry with less than M blocks of elements of\n+        length D1 * ... * DN will be padded with the corresponding default_value\n+        scalar element along the second dimension.\n+      dense_types: A list of n_dense types; the type of data in each Feature given in dense_keys.\n+      sparse_keys: A list of n_sparse string Tensors (scalars).\n+        The keys expected are associated with sparse values.\n+      sparse_types: A list of n_sparse types; the data types of data in each Feature\n+        given in sparse_keys.\n+      schema: A string that describes the avro schema of the underlying serialized avro string.\n+        Currently the parse function supports the primitive types DT_STRING, DT_DOUBLE, DT_FLOAT,\n+        DT_INT64, DT_INT32, and DT_BOOL.\n+    )doc\");\n+\n+// Splits a string into tokens along the separator.\n+// This function is based on: http://stackoverflow.com/questions/236129/split-a-string-in-c.\n+//\n+// 'str' is the string that we split.\n+//\n+// 'spe' is the separator used for the split.\n+//\n+// returns A vector of strings.\n+//\n+std::vector<string> stringSplit(const string& str, char sep) {\n+  std::vector<string> tokens;\n+  size_t start = 0, end = 0;\n+  while ((end = str.find(sep, start)) != string::npos) {\n+    tokens.push_back(str.substr(start, end - start));\n+    start = end + 1;\n+  }\n+  tokens.push_back(str.substr(start));\n+  return tokens;\n+}\n+\n+// Parses the str into an positive integer number. Does not support '-'.\n+//\n+// 'str' is the string that represents a positive integer, e.g. '32482'.\n+//\n+// returns True if the string can be parsed into a positive integer, otherwise false.\n+//\n+bool isNonNegativeInt(const string& str) {", "path": "tensorflow/contrib/avro/ops/parse_avro_record.cc", "position": null, "original_position": 154, "commit_id": "bdf790d5c888e59d593230286edaaf5314daaee5", "original_commit_id": "abf605ba22c95f52116b765c90f889b9f17692c1", "user": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "body": "Please name all functions according to the Google C++ style guide: https://google.github.io/styleguide/cppguide.html#Function_Names\r\n\r\n(I'm personally ok skipping this for now if it's a pain, but this will have to be done if this ever moves out of contrib. Also please use Google style moving forward.)", "created_at": "2018-04-12T00:29:16Z", "updated_at": "2018-10-22T21:28:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r180936085", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/180936085"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18224#discussion_r180936085"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18224"}}, "body_html": "<p>Please name all functions according to the Google C++ style guide: <a href=\"https://google.github.io/styleguide/cppguide.html#Function_Names\" rel=\"nofollow\">https://google.github.io/styleguide/cppguide.html#Function_Names</a></p>\n<p>(I'm personally ok skipping this for now if it's a pain, but this will have to be done if this ever moves out of contrib. Also please use Google style moving forward.)</p>", "body_text": "Please name all functions according to the Google C++ style guide: https://google.github.io/styleguide/cppguide.html#Function_Names\n(I'm personally ok skipping this for now if it's a pain, but this will have to be done if this ever moves out of contrib. Also please use Google style moving forward.)"}