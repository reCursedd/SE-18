{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/355190304", "html_url": "https://github.com/tensorflow/tensorflow/issues/15755#issuecomment-355190304", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15755", "id": 355190304, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTE5MDMwNA==", "user": {"login": "xiaoshenxian", "id": 10596590, "node_id": "MDQ6VXNlcjEwNTk2NTkw", "avatar_url": "https://avatars0.githubusercontent.com/u/10596590?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiaoshenxian", "html_url": "https://github.com/xiaoshenxian", "followers_url": "https://api.github.com/users/xiaoshenxian/followers", "following_url": "https://api.github.com/users/xiaoshenxian/following{/other_user}", "gists_url": "https://api.github.com/users/xiaoshenxian/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiaoshenxian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiaoshenxian/subscriptions", "organizations_url": "https://api.github.com/users/xiaoshenxian/orgs", "repos_url": "https://api.github.com/users/xiaoshenxian/repos", "events_url": "https://api.github.com/users/xiaoshenxian/events{/privacy}", "received_events_url": "https://api.github.com/users/xiaoshenxian/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T03:25:29Z", "updated_at": "2018-01-04T03:25:29Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> I don't think it is a problem to Python generator, because if I change the <code>def task()</code> method as below to using <code>tf.placeholder</code>, then everything goes well:</p>\n<pre><code>def task():\n    with tf.Graph().as_default():\n        sample=tf.placeholder(tf.int32, [1, 8])\n        iter=data_iter()\n        with tf.Session() as sess:\n            while True:\n                try:\n                    result=sess.run(sample, feed_dict={sample:iter.__next__()})\n                    print(result)\n                except:\n                    break\n</code></pre>\n<p>I think it is implausible that the python <code>queue.get()</code> or the <code>generator.__next__()</code> method could block when the queue is not empty within that simple context. As the <code>tf.placeholder</code> version goes well, I think there must be something happened in the <code>Dataset.from_generator</code> method which blocks the <code>generator</code>.</p>\n<p>You mentioned that my code didn't block in both your and your colleague's machine. Could you please tell what your output looked like? Like the first output or the second one provide in my <a href=\"https://stackoverflow.com/questions/47917288/tensorflow-dataset-from-generator-blocks-input\" rel=\"nofollow\">Stack Overflow question</a>? If it looked like the second one, there must be some block. Because I make the main thread wait long enough for the tensorflow thread to process the data. My expectation is the output will come immediately after the main thread put it into the queue, as shown in the first output. In other word, the input log and the output log must shown one by one no matter how many threads is running.</p>\n<p>Would your please help to check again? Thanks a lot.</p>", "body_text": "@mrry I don't think it is a problem to Python generator, because if I change the def task() method as below to using tf.placeholder, then everything goes well:\ndef task():\n    with tf.Graph().as_default():\n        sample=tf.placeholder(tf.int32, [1, 8])\n        iter=data_iter()\n        with tf.Session() as sess:\n            while True:\n                try:\n                    result=sess.run(sample, feed_dict={sample:iter.__next__()})\n                    print(result)\n                except:\n                    break\n\nI think it is implausible that the python queue.get() or the generator.__next__() method could block when the queue is not empty within that simple context. As the tf.placeholder version goes well, I think there must be something happened in the Dataset.from_generator method which blocks the generator.\nYou mentioned that my code didn't block in both your and your colleague's machine. Could you please tell what your output looked like? Like the first output or the second one provide in my Stack Overflow question? If it looked like the second one, there must be some block. Because I make the main thread wait long enough for the tensorflow thread to process the data. My expectation is the output will come immediately after the main thread put it into the queue, as shown in the first output. In other word, the input log and the output log must shown one by one no matter how many threads is running.\nWould your please help to check again? Thanks a lot.", "body": "@mrry I don't think it is a problem to Python generator, because if I change the `def task()` method as below to using `tf.placeholder`, then everything goes well:\r\n\r\n    def task():\r\n        with tf.Graph().as_default():\r\n            sample=tf.placeholder(tf.int32, [1, 8])\r\n            iter=data_iter()\r\n            with tf.Session() as sess:\r\n                while True:\r\n                    try:\r\n                        result=sess.run(sample, feed_dict={sample:iter.__next__()})\r\n                        print(result)\r\n                    except:\r\n                        break\r\n\r\nI think it is implausible that the python `queue.get()` or the `generator.__next__()` method could block when the queue is not empty within that simple context. As the `tf.placeholder` version goes well, I think there must be something happened in the `Dataset.from_generator` method which blocks the `generator`.\r\n\r\nYou mentioned that my code didn't block in both your and your colleague's machine. Could you please tell what your output looked like? Like the first output or the second one provide in my [Stack Overflow question](https://stackoverflow.com/questions/47917288/tensorflow-dataset-from-generator-blocks-input)? If it looked like the second one, there must be some block. Because I make the main thread wait long enough for the tensorflow thread to process the data. My expectation is the output will come immediately after the main thread put it into the queue, as shown in the first output. In other word, the input log and the output log must shown one by one no matter how many threads is running.\r\n\r\nWould your please help to check again? Thanks a lot."}