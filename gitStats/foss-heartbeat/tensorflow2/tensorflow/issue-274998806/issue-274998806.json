{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14670", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14670/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14670/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14670/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14670", "id": 274998806, "node_id": "MDU6SXNzdWUyNzQ5OTg4MDY=", "number": 14670, "title": "Tensorflow Lite toco conversion error on SSD fails", "user": {"login": "dhelleberg", "id": 284093, "node_id": "MDQ6VXNlcjI4NDA5Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/284093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhelleberg", "html_url": "https://github.com/dhelleberg", "followers_url": "https://api.github.com/users/dhelleberg/followers", "following_url": "https://api.github.com/users/dhelleberg/following{/other_user}", "gists_url": "https://api.github.com/users/dhelleberg/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhelleberg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhelleberg/subscriptions", "organizations_url": "https://api.github.com/users/dhelleberg/orgs", "repos_url": "https://api.github.com/users/dhelleberg/repos", "events_url": "https://api.github.com/users/dhelleberg/events{/privacy}", "received_events_url": "https://api.github.com/users/dhelleberg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 26, "created_at": "2017-11-17T21:16:16Z", "updated_at": "2018-07-16T15:22:45Z", "closed_at": "2018-07-16T15:22:45Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOSX 10.12.6</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: master</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.7.0-homebrew</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Apple LLVM version 9.0.0 (clang-900.0.38)</li>\n<li><strong>CUDA/cuDNN version</strong>: -</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>: see below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:</p>\n<p>bazel run --config=opt tensorflow/contrib/lite/toco:toco -- <br>\n--input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb <br>\n--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE <br>\n--output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT <br>\n--input_type=FLOAT --input_arrays=image_tensor <br>\n--output_arrays=detection_boxes --input_shapes=1,320,320,3</p>\n<p>here's the output:</p>\n<p>...<br>\n2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3<br>\n2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice<br>\n2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice<br>\n2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd<br>\n2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model-&gt;flags.drop_control_dependency()) == 2 (3 vs. 2)</p>\n<p>I freezed the model using the python script from the object detection framework:</p>\n<p>python export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3</p>\n<p>Any idea why the conversion fails?<br>\nThanks for any help!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.12.6\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): master\nPython version: 2.7\nBazel version (if compiling from source): 0.7.0-homebrew\nGCC/Compiler version (if compiling from source): Apple LLVM version 9.0.0 (clang-900.0.38)\nCUDA/cuDNN version: -\nGPU model and memory: -\nExact command to reproduce: see below\n\nDescribe the problem\nI'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- \n--input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb \n--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \n--output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \n--input_type=FLOAT --input_arrays=image_tensor \n--output_arrays=detection_boxes --input_shapes=1,320,320,3\nhere's the output:\n...\n2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3\n2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\n2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\n2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd\n2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model->flags.drop_control_dependency()) == 2 (3 vs. 2)\nI freezed the model using the python script from the object detection framework:\npython export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3\nAny idea why the conversion fails?\nThanks for any help!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.12.6\r\n- **TensorFlow installed from (source or binary)**: source \r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nI'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:\r\n\r\n bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \\\r\n                                                         --input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb \\\r\n                                                         --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n                                                         --output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \\\r\n                                                         --input_type=FLOAT --input_arrays=image_tensor \\\r\n                                                         --output_arrays=detection_boxes --input_shapes=1,320,320,3\r\n\r\nhere's the output:\r\n\r\n...\r\n2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3\r\n2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\r\n2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\r\n2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd\r\n2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model->flags.drop_control_dependency()) == 2 (3 vs. 2)\r\n\r\nI freezed the model using the python script from the object detection framework:\r\n\r\npython export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3\r\n\r\nAny idea why the conversion fails?\r\nThanks for any help!"}