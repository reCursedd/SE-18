{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/308628337", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308628337", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 308628337, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODYyODMzNw==", "user": {"login": "winston-li", "id": 10807796, "node_id": "MDQ6VXNlcjEwODA3Nzk2", "avatar_url": "https://avatars0.githubusercontent.com/u/10807796?v=4", "gravatar_id": "", "url": "https://api.github.com/users/winston-li", "html_url": "https://github.com/winston-li", "followers_url": "https://api.github.com/users/winston-li/followers", "following_url": "https://api.github.com/users/winston-li/following{/other_user}", "gists_url": "https://api.github.com/users/winston-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/winston-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/winston-li/subscriptions", "organizations_url": "https://api.github.com/users/winston-li/orgs", "repos_url": "https://api.github.com/users/winston-li/repos", "events_url": "https://api.github.com/users/winston-li/events{/privacy}", "received_events_url": "https://api.github.com/users/winston-li/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-15T04:53:53Z", "updated_at": "2017-06-15T04:53:53Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5758565\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/EdeMeijer\">@EdeMeijer</a>  Thanks. I thought it should work, but after some experiments, I can't make it work as expected. I followed the guidelines of dataset README.md, with pseudo code like following:</p>\n<pre><code>def _parse_function(example_proto):\n    features = {\"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n                \"label\": tf.FixedLenFeature((), tf.int32, default_value=0)}\n    parsed_features = tf.parse_single_example(example_proto, features)\n    return parsed_features[\"image\"], parsed_features[\"label\"]\n\nBATCH_SIZE = 256\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.contrib.data.TFRecordDataset(filenames)\ndataset = dataset.map(_parse_function)\ndataset = dataset.batch(BATCH_SIZE)\ndataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\nimages, labels = next_element\n\n# Training cycles for 100 epochs.\nfor _ in range(100):\n    sess.run(iterator.initializer)\n    while True:\n        try:\n            images_r, labels_r = sess.run([images, labels])\n            print(images_r.shape)\n        except tf.errors.OutOfRangeError:\n            break\n</code></pre>\n<p>After applied the filter, no data available in training cycles. I found the dataset (after batch, prior to filter) was in this form:</p>\n<pre><code>(&lt;tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32&gt;, &lt;tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32&gt;)\n</code></pre>\n<p>Looks like the batch dimension is \"?\" (None?), so the predicate always fails... or I did something wrong?</p>", "body_text": "@EdeMeijer  Thanks. I thought it should work, but after some experiments, I can't make it work as expected. I followed the guidelines of dataset README.md, with pseudo code like following:\ndef _parse_function(example_proto):\n    features = {\"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n                \"label\": tf.FixedLenFeature((), tf.int32, default_value=0)}\n    parsed_features = tf.parse_single_example(example_proto, features)\n    return parsed_features[\"image\"], parsed_features[\"label\"]\n\nBATCH_SIZE = 256\nfilenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\ndataset = tf.contrib.data.TFRecordDataset(filenames)\ndataset = dataset.map(_parse_function)\ndataset = dataset.batch(BATCH_SIZE)\ndataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)\niterator = dataset.make_initializable_iterator()\nnext_element = iterator.get_next()\nimages, labels = next_element\n\n# Training cycles for 100 epochs.\nfor _ in range(100):\n    sess.run(iterator.initializer)\n    while True:\n        try:\n            images_r, labels_r = sess.run([images, labels])\n            print(images_r.shape)\n        except tf.errors.OutOfRangeError:\n            break\n\nAfter applied the filter, no data available in training cycles. I found the dataset (after batch, prior to filter) was in this form:\n(<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)\n\nLooks like the batch dimension is \"?\" (None?), so the predicate always fails... or I did something wrong?", "body": "@EdeMeijer  Thanks. I thought it should work, but after some experiments, I can't make it work as expected. I followed the guidelines of dataset README.md, with pseudo code like following:\r\n\r\n    def _parse_function(example_proto):\r\n        features = {\"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n                    \"label\": tf.FixedLenFeature((), tf.int32, default_value=0)}\r\n        parsed_features = tf.parse_single_example(example_proto, features)\r\n        return parsed_features[\"image\"], parsed_features[\"label\"]\r\n\r\n    BATCH_SIZE = 256\r\n    filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\r\n    dataset = tf.contrib.data.TFRecordDataset(filenames)\r\n    dataset = dataset.map(_parse_function)\r\n    dataset = dataset.batch(BATCH_SIZE)\r\n    dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)\r\n    iterator = dataset.make_initializable_iterator()\r\n    next_element = iterator.get_next()\r\n    images, labels = next_element\r\n\r\n    # Training cycles for 100 epochs.\r\n    for _ in range(100):\r\n        sess.run(iterator.initializer)\r\n        while True:\r\n            try:\r\n                images_r, labels_r = sess.run([images, labels])\r\n                print(images_r.shape)\r\n            except tf.errors.OutOfRangeError:\r\n                break\r\n \r\nAfter applied the filter, no data available in training cycles. I found the dataset (after batch, prior to filter) was in this form: \r\n\r\n    (<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)\r\n\r\nLooks like the batch dimension is \"?\" (None?), so the predicate always fails... or I did something wrong?"}