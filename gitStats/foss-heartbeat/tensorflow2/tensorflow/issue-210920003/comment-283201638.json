{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/283201638", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283201638", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 283201638, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MzIwMTYzOA==", "user": {"login": "22csnyder", "id": 10726729, "node_id": "MDQ6VXNlcjEwNzI2NzI5", "avatar_url": "https://avatars3.githubusercontent.com/u/10726729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/22csnyder", "html_url": "https://github.com/22csnyder", "followers_url": "https://api.github.com/users/22csnyder/followers", "following_url": "https://api.github.com/users/22csnyder/following{/other_user}", "gists_url": "https://api.github.com/users/22csnyder/gists{/gist_id}", "starred_url": "https://api.github.com/users/22csnyder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/22csnyder/subscriptions", "organizations_url": "https://api.github.com/users/22csnyder/orgs", "repos_url": "https://api.github.com/users/22csnyder/repos", "events_url": "https://api.github.com/users/22csnyder/events{/privacy}", "received_events_url": "https://api.github.com/users/22csnyder/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-01T00:04:45Z", "updated_at": "2017-03-01T00:04:45Z", "author_association": "NONE", "body_html": "<p>Oh good timing! Now I can stop writing my own (horrible) dataset class. Many of the things said already resonate with my experience.</p>\n<p>To the extent possible, I would like to code dataset-independent tensorflow computations. I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.</p>\n<p>The use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat]. There are clear problems with queues like you said. A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.</p>\n<p>Some other ideas I jotted down while brainstorming my own class:</p>\n<ul>\n<li>The dataset class (and not the model) should probably the one to have batch_size passed to it. It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.</li>\n<li>A \"verbose\" dataset class should keep track of it's own statistics. It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs. In most use cases I imagine these being restored the same time model parameters are restored.</li>\n</ul>", "body_text": "Oh good timing! Now I can stop writing my own (horrible) dataset class. Many of the things said already resonate with my experience.\nTo the extent possible, I would like to code dataset-independent tensorflow computations. I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.\nThe use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat]. There are clear problems with queues like you said. A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.\nSome other ideas I jotted down while brainstorming my own class:\n\nThe dataset class (and not the model) should probably the one to have batch_size passed to it. It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.\nA \"verbose\" dataset class should keep track of it's own statistics. It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs. In most use cases I imagine these being restored the same time model parameters are restored.", "body": "Oh good timing! Now I can stop writing my own (horrible) dataset class. Many of the things said already resonate with my experience.\r\n\r\nTo the extent possible, I would like to code dataset-independent tensorflow computations. I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.\r\n\r\nThe use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat]. There are clear problems with queues like you said. A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.\r\n\r\nSome other ideas I jotted down while brainstorming my own class:\r\n- The dataset class (and not the model) should probably the one to have batch_size passed to it. It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.\r\n- A \"verbose\" dataset class should keep track of it's own statistics. It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs. In most use cases I imagine these being restored the same time model parameters are restored."}