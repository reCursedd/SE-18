{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/304959321", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-304959321", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 304959321, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNDk1OTMyMQ==", "user": {"login": "drasmuss", "id": 1952220, "node_id": "MDQ6VXNlcjE5NTIyMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1952220?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drasmuss", "html_url": "https://github.com/drasmuss", "followers_url": "https://api.github.com/users/drasmuss/followers", "following_url": "https://api.github.com/users/drasmuss/following{/other_user}", "gists_url": "https://api.github.com/users/drasmuss/gists{/gist_id}", "starred_url": "https://api.github.com/users/drasmuss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drasmuss/subscriptions", "organizations_url": "https://api.github.com/users/drasmuss/orgs", "repos_url": "https://api.github.com/users/drasmuss/repos", "events_url": "https://api.github.com/users/drasmuss/events{/privacy}", "received_events_url": "https://api.github.com/users/drasmuss/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-30T18:00:59Z", "updated_at": "2017-05-30T18:03:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I really like the new Dataset/Iterator API!  Here is a feature that would help my use-case:</p>\n<p>I would like to be able to create iterators that share part of the data pipeline.  As a simple example, something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> np.arange(<span class=\"pl-c1\">12</span>)\n\ndata <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(a)\ndata <span class=\"pl-k\">=</span> data.shuffle(<span class=\"pl-c1\">12</span>)\ndata0 <span class=\"pl-k\">=</span> data.map(my_func0)\ndata1 <span class=\"pl-k\">=</span> data.map(my_func1)\n\niter0 <span class=\"pl-k\">=</span> data0.make_one_shot_iterator()\niter1 <span class=\"pl-k\">=</span> data1.make_one_shot_iterator()\n\nop0 <span class=\"pl-k\">=</span> iter0.get_next()\nop1 <span class=\"pl-k\">=</span> iter1.get_next()</pre></div>\n<p>What I'd like is for <code>op0</code> and <code>op1</code> there to output elements in the same order (because they share the <code>shuffle</code> step), but with different functions (<code>my_func0</code>/<code>my_func1</code>) applied.  That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.</p>", "body_text": "I really like the new Dataset/Iterator API!  Here is a feature that would help my use-case:\nI would like to be able to create iterators that share part of the data pipeline.  As a simple example, something like this:\na = np.arange(12)\n\ndata = tf.contrib.data.Dataset.from_tensor_slices(a)\ndata = data.shuffle(12)\ndata0 = data.map(my_func0)\ndata1 = data.map(my_func1)\n\niter0 = data0.make_one_shot_iterator()\niter1 = data1.make_one_shot_iterator()\n\nop0 = iter0.get_next()\nop1 = iter1.get_next()\nWhat I'd like is for op0 and op1 there to output elements in the same order (because they share the shuffle step), but with different functions (my_func0/my_func1) applied.  That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.", "body": "I really like the new Dataset/Iterator API!  Here is a feature that would help my use-case:\r\n\r\nI would like to be able to create iterators that share part of the data pipeline.  As a simple example, something like this:\r\n``` python\r\na = np.arange(12)\r\n\r\ndata = tf.contrib.data.Dataset.from_tensor_slices(a)\r\ndata = data.shuffle(12)\r\ndata0 = data.map(my_func0)\r\ndata1 = data.map(my_func1)\r\n\r\niter0 = data0.make_one_shot_iterator()\r\niter1 = data1.make_one_shot_iterator()\r\n\r\nop0 = iter0.get_next()\r\nop1 = iter1.get_next()\r\n```\r\nWhat I'd like is for `op0` and `op1` there to output elements in the same order (because they share the `shuffle` step), but with different functions (`my_func0`/`my_func1`) applied.  That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing."}