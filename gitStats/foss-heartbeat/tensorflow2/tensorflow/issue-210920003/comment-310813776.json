{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310813776", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-310813776", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 310813776, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDgxMzc3Ng==", "user": {"login": "c810armyHuan", "id": 19700443, "node_id": "MDQ6VXNlcjE5NzAwNDQz", "avatar_url": "https://avatars2.githubusercontent.com/u/19700443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c810armyHuan", "html_url": "https://github.com/c810armyHuan", "followers_url": "https://api.github.com/users/c810armyHuan/followers", "following_url": "https://api.github.com/users/c810armyHuan/following{/other_user}", "gists_url": "https://api.github.com/users/c810armyHuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/c810armyHuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c810armyHuan/subscriptions", "organizations_url": "https://api.github.com/users/c810armyHuan/orgs", "repos_url": "https://api.github.com/users/c810armyHuan/repos", "events_url": "https://api.github.com/users/c810armyHuan/events{/privacy}", "received_events_url": "https://api.github.com/users/c810armyHuan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-24T04:43:38Z", "updated_at": "2017-06-24T04:43:38Z", "author_association": "NONE", "body_html": "<p>Currently the tutorial says that we can use</p>\n<div class=\"highlight highlight-source-python\"><pre>dataset <span class=\"pl-k\">=</span> dataset.repeat()\ndataset <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10000</span>)</pre></div>\n<p>to get shuffled data. The pattern is also used in <a href=\"https://github.com/tensorflow/tensorflow/blob/1efd7f171ba30421b5d8369a93526395a721c0d9/tensorflow/contrib/data/python/ops/dataset_ops.py#L595\"><code>tf.contrib.data.read_batch_features</code></a></p>\n<p>However calling <code>repeat</code> before <code>shuffle</code> could lead to the shuffle across multiple epochs.<br>\nFor example, the following code</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ndata <span class=\"pl-k\">=</span> tf.contrib.data\n\ndataset <span class=\"pl-k\">=</span> data.Dataset.from_tensor_slices([<span class=\"pl-s\"><span class=\"pl-pds\">'</span>file_0<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>file_1<span class=\"pl-pds\">'</span></span>])\n\nrepeat_count <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\nshuffle_buffer_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n\nrepeat_then_shuffle <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-v\">count</span><span class=\"pl-k\">=</span>repeat_count)\nrepeat_then_shuffle <span class=\"pl-k\">=</span> repeat_then_shuffle.shuffle(\n    <span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span>shuffle_buffer_size)\nrepeat_then_shuffle_iter <span class=\"pl-k\">=</span> repeat_then_shuffle.make_one_shot_iterator()\nget_next <span class=\"pl-k\">=</span> repeat_then_shuffle_iter.get_next()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    result <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">try</span>:\n        <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n            result.append(sess.run(get_next))\n    <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n        <span class=\"pl-k\">pass</span>\n    <span class=\"pl-c1\">print</span>(result) <span class=\"pl-c\"><span class=\"pl-c\">#</span> [b'file_0', b'file_0', b'file_0', b'file_1', b'file_0', b'file_1', b'file_0', b'file_1', b'file_1', b'file_1']</span></pre></div>\n<p>gets 3 <code>file_0</code> before getting a <code>file_1</code>.</p>\n<p>Are there any concerns about calling <code>shuffle</code> before <code>repeat</code>?</p>", "body_text": "Currently the tutorial says that we can use\ndataset = dataset.repeat()\ndataset = dataset.shuffle(buffer_size=10000)\nto get shuffled data. The pattern is also used in tf.contrib.data.read_batch_features\nHowever calling repeat before shuffle could lead to the shuffle across multiple epochs.\nFor example, the following code\nimport tensorflow as tf\n\ndata = tf.contrib.data\n\ndataset = data.Dataset.from_tensor_slices(['file_0', 'file_1'])\n\nrepeat_count = 5\nshuffle_buffer_size = 100\n\nrepeat_then_shuffle = dataset.repeat(count=repeat_count)\nrepeat_then_shuffle = repeat_then_shuffle.shuffle(\n    buffer_size=shuffle_buffer_size)\nrepeat_then_shuffle_iter = repeat_then_shuffle.make_one_shot_iterator()\nget_next = repeat_then_shuffle_iter.get_next()\n\nwith tf.Session() as sess:\n    result = []\n    try:\n        while True:\n            result.append(sess.run(get_next))\n    except tf.errors.OutOfRangeError:\n        pass\n    print(result) # [b'file_0', b'file_0', b'file_0', b'file_1', b'file_0', b'file_1', b'file_0', b'file_1', b'file_1', b'file_1']\ngets 3 file_0 before getting a file_1.\nAre there any concerns about calling shuffle before repeat?", "body": "Currently the tutorial says that we can use \r\n```python\r\ndataset = dataset.repeat()\r\ndataset = dataset.shuffle(buffer_size=10000)\r\n```\r\nto get shuffled data. The pattern is also used in [`tf.contrib.data.read_batch_features`](https://github.com/tensorflow/tensorflow/blob/1efd7f171ba30421b5d8369a93526395a721c0d9/tensorflow/contrib/data/python/ops/dataset_ops.py#L595)\r\n\r\nHowever calling `repeat` before `shuffle` could lead to the shuffle across multiple epochs.\r\nFor example, the following code\r\n```python\r\nimport tensorflow as tf\r\n\r\ndata = tf.contrib.data\r\n\r\ndataset = data.Dataset.from_tensor_slices(['file_0', 'file_1'])\r\n\r\nrepeat_count = 5\r\nshuffle_buffer_size = 100\r\n\r\nrepeat_then_shuffle = dataset.repeat(count=repeat_count)\r\nrepeat_then_shuffle = repeat_then_shuffle.shuffle(\r\n    buffer_size=shuffle_buffer_size)\r\nrepeat_then_shuffle_iter = repeat_then_shuffle.make_one_shot_iterator()\r\nget_next = repeat_then_shuffle_iter.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    result = []\r\n    try:\r\n        while True:\r\n            result.append(sess.run(get_next))\r\n    except tf.errors.OutOfRangeError:\r\n        pass\r\n    print(result) # [b'file_0', b'file_0', b'file_0', b'file_1', b'file_0', b'file_1', b'file_0', b'file_1', b'file_1', b'file_1']\r\n```\r\ngets 3 `file_0` before getting a `file_1`.\r\n\r\nAre there any concerns about calling `shuffle` before `repeat`?\r\n"}