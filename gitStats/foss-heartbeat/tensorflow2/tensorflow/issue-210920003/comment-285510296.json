{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285510296", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-285510296", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 285510296, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTUxMDI5Ng==", "user": {"login": "Mazecreator", "id": 18412448, "node_id": "MDQ6VXNlcjE4NDEyNDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/18412448?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mazecreator", "html_url": "https://github.com/Mazecreator", "followers_url": "https://api.github.com/users/Mazecreator/followers", "following_url": "https://api.github.com/users/Mazecreator/following{/other_user}", "gists_url": "https://api.github.com/users/Mazecreator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mazecreator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mazecreator/subscriptions", "organizations_url": "https://api.github.com/users/Mazecreator/orgs", "repos_url": "https://api.github.com/users/Mazecreator/repos", "events_url": "https://api.github.com/users/Mazecreator/events{/privacy}", "received_events_url": "https://api.github.com/users/Mazecreator/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-09T22:55:01Z", "updated_at": "2017-03-09T22:55:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.</p>\n<p>In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.  Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.</p>\n<p>What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.  So some concept of \"sample age\" would be nice.  I am sure using a circular buffer will work to fix to a number of samples, but \"age\" might be of interest as well, maybe passed as part of the tuple, but in the RL case, simply the sequence of the sample being added might cover the age (FIFO).</p>\n<p>Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.</p>", "body_text": "I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.\nIn dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.  Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.\nWhat I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.  So some concept of \"sample age\" would be nice.  I am sure using a circular buffer will work to fix to a number of samples, but \"age\" might be of interest as well, maybe passed as part of the tuple, but in the RL case, simply the sequence of the sample being added might cover the age (FIFO).\nAgain, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.", "body": "I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.\r\n\r\nIn dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.  Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.\r\n\r\nWhat I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.  So some concept of \"sample age\" would be nice.  I am sure using a circular buffer will work to fix to a number of samples, but \"age\" might be of interest as well, maybe passed as part of the tuple, but in the RL case, simply the sequence of the sample being added might cover the age (FIFO).\r\n\r\nAgain, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice."}