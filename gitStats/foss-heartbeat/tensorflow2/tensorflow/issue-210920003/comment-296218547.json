{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/296218547", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-296218547", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 296218547, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NjIxODU0Nw==", "user": {"login": "kratzert", "id": 13069767, "node_id": "MDQ6VXNlcjEzMDY5NzY3", "avatar_url": "https://avatars0.githubusercontent.com/u/13069767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kratzert", "html_url": "https://github.com/kratzert", "followers_url": "https://api.github.com/users/kratzert/followers", "following_url": "https://api.github.com/users/kratzert/following{/other_user}", "gists_url": "https://api.github.com/users/kratzert/gists{/gist_id}", "starred_url": "https://api.github.com/users/kratzert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kratzert/subscriptions", "organizations_url": "https://api.github.com/users/kratzert/orgs", "repos_url": "https://api.github.com/users/kratzert/repos", "events_url": "https://api.github.com/users/kratzert/events{/privacy}", "received_events_url": "https://api.github.com/users/kratzert/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-21T15:13:08Z", "updated_at": "2017-04-21T15:14:54Z", "author_association": "NONE", "body_html": "<p>Ah okay so maybe a misunderstanding. Thought I made myself clearer.</p>\n<p>I know that data does not appear magically in memory if I use TF. But TF makes it quite easy to place e.g. image loading + preprocessing explicitly on CPU and graph computation on GPU and both is done in parallel. So while GPU calculates ops on some data, CPU is already loading the next data into memory. And since this is done in parallel, we are effectively reducing the computational time by the amount of loading data from disk (since this takes usually less time then one forward + backward pass through the networks graph). But yes this only applies for working with CPU + GPU and has no effect if you use CPU only.</p>\n<p>edit: The maybe only thing I like of TFs input queues is that I the state of the queues (and batch producers) can be observed in Tensorboard. For the rest I fought quite some time to get them running with all the preprocessing I wanted and with queues for testing and validation in the same run.</p>", "body_text": "Ah okay so maybe a misunderstanding. Thought I made myself clearer.\nI know that data does not appear magically in memory if I use TF. But TF makes it quite easy to place e.g. image loading + preprocessing explicitly on CPU and graph computation on GPU and both is done in parallel. So while GPU calculates ops on some data, CPU is already loading the next data into memory. And since this is done in parallel, we are effectively reducing the computational time by the amount of loading data from disk (since this takes usually less time then one forward + backward pass through the networks graph). But yes this only applies for working with CPU + GPU and has no effect if you use CPU only.\nedit: The maybe only thing I like of TFs input queues is that I the state of the queues (and batch producers) can be observed in Tensorboard. For the rest I fought quite some time to get them running with all the preprocessing I wanted and with queues for testing and validation in the same run.", "body": "Ah okay so maybe a misunderstanding. Thought I made myself clearer.\r\n\r\nI know that data does not appear magically in memory if I use TF. But TF makes it quite easy to place e.g. image loading + preprocessing explicitly on CPU and graph computation on GPU and both is done in parallel. So while GPU calculates ops on some data, CPU is already loading the next data into memory. And since this is done in parallel, we are effectively reducing the computational time by the amount of loading data from disk (since this takes usually less time then one forward + backward pass through the networks graph). But yes this only applies for working with CPU + GPU and has no effect if you use CPU only.\r\n\r\nedit: The maybe only thing I like of TFs input queues is that I the state of the queues (and batch producers) can be observed in Tensorboard. For the rest I fought quite some time to get them running with all the preprocessing I wanted and with queues for testing and validation in the same run."}