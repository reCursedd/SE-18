{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/283196884", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283196884", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 283196884, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MzE5Njg4NA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-28T23:37:57Z", "updated_at": "2017-02-28T23:37:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7887138\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kmhofmann\">@kmhofmann</a> We'll certainly support <code>tf.py_func()</code> inside a new-style input pipeline (as well as, in general, compositions of any other TensorFlow ops). I'd like to understand more about your use case, though. How frequently do you move from one outer \"data set\" to the next? Are there any specific operations that you perform at the end of a \"data set\" or can your training loop handle the concatenation of records from different \"data sets\"?</p>\n<p>We're planning to have a few nested iteration primitives, so that you can write a function mapping an element (e.g. a string representing your outer \"data set\") to a <code>Dataset</code> (representing the records in that \"data set\") and then flattening them down to a single <code>Dataset</code>. (Think <code>SelectMany()</code> in C#, <code>flatMap()</code> in Java and Scala.) So I think you could implement your logic for sampling from a \"data set\" in one of these <code>flatMap()</code> functions.</p>\n<p>Let me know if any of this is unclear!</p>", "body_text": "@kmhofmann We'll certainly support tf.py_func() inside a new-style input pipeline (as well as, in general, compositions of any other TensorFlow ops). I'd like to understand more about your use case, though. How frequently do you move from one outer \"data set\" to the next? Are there any specific operations that you perform at the end of a \"data set\" or can your training loop handle the concatenation of records from different \"data sets\"?\nWe're planning to have a few nested iteration primitives, so that you can write a function mapping an element (e.g. a string representing your outer \"data set\") to a Dataset (representing the records in that \"data set\") and then flattening them down to a single Dataset. (Think SelectMany() in C#, flatMap() in Java and Scala.) So I think you could implement your logic for sampling from a \"data set\" in one of these flatMap() functions.\nLet me know if any of this is unclear!", "body": "@kmhofmann We'll certainly support `tf.py_func()` inside a new-style input pipeline (as well as, in general, compositions of any other TensorFlow ops). I'd like to understand more about your use case, though. How frequently do you move from one outer \"data set\" to the next? Are there any specific operations that you perform at the end of a \"data set\" or can your training loop handle the concatenation of records from different \"data sets\"?\r\n\r\nWe're planning to have a few nested iteration primitives, so that you can write a function mapping an element (e.g. a string representing your outer \"data set\") to a `Dataset` (representing the records in that \"data set\") and then flattening them down to a single `Dataset`. (Think `SelectMany()` in C#, `flatMap()` in Java and Scala.) So I think you could implement your logic for sampling from a \"data set\" in one of these `flatMap()` functions.\r\n\r\nLet me know if any of this is unclear!"}