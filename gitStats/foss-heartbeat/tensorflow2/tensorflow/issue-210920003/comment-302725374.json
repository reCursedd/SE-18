{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302725374", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-302725374", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 302725374, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjcyNTM3NA==", "user": {"login": "snnn", "id": 856316, "node_id": "MDQ6VXNlcjg1NjMxNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/856316?v=4", "gravatar_id": "", "url": "https://api.github.com/users/snnn", "html_url": "https://github.com/snnn", "followers_url": "https://api.github.com/users/snnn/followers", "following_url": "https://api.github.com/users/snnn/following{/other_user}", "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}", "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/snnn/subscriptions", "organizations_url": "https://api.github.com/users/snnn/orgs", "repos_url": "https://api.github.com/users/snnn/repos", "events_url": "https://api.github.com/users/snnn/events{/privacy}", "received_events_url": "https://api.github.com/users/snnn/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-19T14:56:00Z", "updated_at": "2017-05-19T14:56:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Any planing for supporting a seek-able file format, which can be started to read from an arbitrary offset?</p>\n<p>Below is why we need it:<br>\nAssume there is a large training data set which is in text format, and we need to convert it into tfrecord format.  Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect! Then we want to run it faster, we would change the worker count to 20, 30, 40, ...  it would be great if we could do this without re-generate the training data.</p>\n<p>Solution:<br>\nFirst, we need to pass an offset and length together with the filename into Dataset 's constructor. Only filename is not enough.</p>\n<p>Second, the file format it self must be seekable(aka. splitable).  it should be one of the following:</p>\n<ol>\n<li>Text format</li>\n<li>Blocked binary format with paddings.</li>\n<li>Has an index file.</li>\n</ol>", "body_text": "Any planing for supporting a seek-able file format, which can be started to read from an arbitrary offset?\nBelow is why we need it:\nAssume there is a large training data set which is in text format, and we need to convert it into tfrecord format.  Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect! Then we want to run it faster, we would change the worker count to 20, 30, 40, ...  it would be great if we could do this without re-generate the training data.\nSolution:\nFirst, we need to pass an offset and length together with the filename into Dataset 's constructor. Only filename is not enough.\nSecond, the file format it self must be seekable(aka. splitable).  it should be one of the following:\n\nText format\nBlocked binary format with paddings.\nHas an index file.", "body": "Any planing for supporting a seek-able file format, which can be started to read from an arbitrary offset?\r\n\r\nBelow is why we need it:\r\nAssume there is a large training data set which is in text format, and we need to convert it into tfrecord format.  Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect! Then we want to run it faster, we would change the worker count to 20, 30, 40, ...  it would be great if we could do this without re-generate the training data.\r\n\r\nSolution:\r\nFirst, we need to pass an offset and length together with the filename into Dataset 's constructor. Only filename is not enough.\r\n\r\nSecond, the file format it self must be seekable(aka. splitable).  it should be one of the following:\r\n 1. Text format\r\n 2. Blocked binary format with paddings. \r\n 3. Has an index file. \r\n\r\n\r\n\r\n\r\n"}