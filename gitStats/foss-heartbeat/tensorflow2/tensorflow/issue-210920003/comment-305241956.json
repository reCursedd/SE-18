{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305241956", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-305241956", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 305241956, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTI0MTk1Ng==", "user": {"login": "vonclites", "id": 4926264, "node_id": "MDQ6VXNlcjQ5MjYyNjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4926264?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vonclites", "html_url": "https://github.com/vonclites", "followers_url": "https://api.github.com/users/vonclites/followers", "following_url": "https://api.github.com/users/vonclites/following{/other_user}", "gists_url": "https://api.github.com/users/vonclites/gists{/gist_id}", "starred_url": "https://api.github.com/users/vonclites/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vonclites/subscriptions", "organizations_url": "https://api.github.com/users/vonclites/orgs", "repos_url": "https://api.github.com/users/vonclites/repos", "events_url": "https://api.github.com/users/vonclites/events{/privacy}", "received_events_url": "https://api.github.com/users/vonclites/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-31T16:28:10Z", "updated_at": "2017-05-31T16:32:10Z", "author_association": "NONE", "body_html": "<ol>\n<li>Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great. For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful. Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.</li>\n<li>I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data. Something that provides similar functionality as the generator feed function in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py</a>  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)</li>\n</ol>\n<p>Thanks for the hard work. I'm digging the new API.</p>", "body_text": "Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great. For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful. Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.\nI think others have mentioned something like this, but a way to create a Dataset from a streaming source of data. Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)\n\nThanks for the hard work. I'm digging the new API.", "body": "1. Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great. For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful. Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.\r\n2. I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data. Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)\r\n\r\nThanks for the hard work. I'm digging the new API.\r\n"}