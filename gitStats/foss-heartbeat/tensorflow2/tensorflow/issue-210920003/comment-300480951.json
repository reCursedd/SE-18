{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300480951", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-300480951", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 300480951, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDQ4MDk1MQ==", "user": {"login": "mirosval", "id": 1315417, "node_id": "MDQ6VXNlcjEzMTU0MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1315417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mirosval", "html_url": "https://github.com/mirosval", "followers_url": "https://api.github.com/users/mirosval/followers", "following_url": "https://api.github.com/users/mirosval/following{/other_user}", "gists_url": "https://api.github.com/users/mirosval/gists{/gist_id}", "starred_url": "https://api.github.com/users/mirosval/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mirosval/subscriptions", "organizations_url": "https://api.github.com/users/mirosval/orgs", "repos_url": "https://api.github.com/users/mirosval/repos", "events_url": "https://api.github.com/users/mirosval/events{/privacy}", "received_events_url": "https://api.github.com/users/mirosval/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-10T13:25:52Z", "updated_at": "2017-05-10T13:25:52Z", "author_association": "NONE", "body_html": "<p>Currently I am worried that my training/prediction preprocessing will diverge over time.</p>\n<p>I would be interested in a pipeline where:</p>\n<ul>\n<li>Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no <code>tf.py_func</code>, but able to provide implementation at runtime)</li>\n<li>There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples</li>\n</ul>\n<p>The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings). It would be ideal to have some <code>Op</code> that can <code>train</code> some values like this during training, carry them over to production within the serialized graph and then I could provide an implementation for this pre/post processing <code>Op</code> in the target production language.</p>", "body_text": "Currently I am worried that my training/prediction preprocessing will diverge over time.\nI would be interested in a pipeline where:\n\nPreprocessing and post processing can be serialized with the inference in a single model and then used from another language (no tf.py_func, but able to provide implementation at runtime)\nThere is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples\n\nThe preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings). It would be ideal to have some Op that can train some values like this during training, carry them over to production within the serialized graph and then I could provide an implementation for this pre/post processing Op in the target production language.", "body": "Currently I am worried that my training/prediction preprocessing will diverge over time.\r\n\r\nI would be interested in a pipeline where:\r\n\r\n* Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no `tf.py_func`, but able to provide implementation at runtime)\r\n* There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples\r\n\r\nThe preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings). It would be ideal to have some `Op` that can `train` some values like this during training, carry them over to production within the serialized graph and then I could provide an implementation for this pre/post processing `Op` in the target production language."}