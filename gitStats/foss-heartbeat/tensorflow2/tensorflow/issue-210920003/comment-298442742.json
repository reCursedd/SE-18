{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/298442742", "html_url": "https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-298442742", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7951", "id": 298442742, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODQ0Mjc0Mg==", "user": {"login": "drcrook1", "id": 6099287, "node_id": "MDQ6VXNlcjYwOTkyODc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6099287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drcrook1", "html_url": "https://github.com/drcrook1", "followers_url": "https://api.github.com/users/drcrook1/followers", "following_url": "https://api.github.com/users/drcrook1/following{/other_user}", "gists_url": "https://api.github.com/users/drcrook1/gists{/gist_id}", "starred_url": "https://api.github.com/users/drcrook1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drcrook1/subscriptions", "organizations_url": "https://api.github.com/users/drcrook1/orgs", "repos_url": "https://api.github.com/users/drcrook1/repos", "events_url": "https://api.github.com/users/drcrook1/events{/privacy}", "received_events_url": "https://api.github.com/users/drcrook1/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-01T21:52:45Z", "updated_at": "2017-05-01T21:52:45Z", "author_association": "NONE", "body_html": "<p>My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.  I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.</p>\n<p>Example: I trained using TFRecords and input queues; I got my weights/model.  I want to perform inference by running my prediction operation; but because the input queue runners etc are part of the graph before that; I am stuck with that mechanism for performing inference.</p>\n<p>See issue here: <a href=\"http://stackoverflow.com/questions/43708616/tensorflow-inference\" rel=\"nofollow\">http://stackoverflow.com/questions/43708616/tensorflow-inference</a></p>\n<p>I like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....</p>", "body_text": "My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.  I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.\nExample: I trained using TFRecords and input queues; I got my weights/model.  I want to perform inference by running my prediction operation; but because the input queue runners etc are part of the graph before that; I am stuck with that mechanism for performing inference.\nSee issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference\nI like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....", "body": "My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.  I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.\r\n\r\nExample: I trained using TFRecords and input queues; I got my weights/model.  I want to perform inference by running my prediction operation; but because the input queue runners etc are part of the graph before that; I am stuck with that mechanism for performing inference.\r\n\r\nSee issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference \r\n\r\nI like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph...."}