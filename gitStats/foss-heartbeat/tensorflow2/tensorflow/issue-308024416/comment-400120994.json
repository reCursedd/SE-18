{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/400120994", "html_url": "https://github.com/tensorflow/tensorflow/issues/17950#issuecomment-400120994", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17950", "id": 400120994, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDEyMDk5NA==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-25T22:53:28Z", "updated_at": "2018-06-25T22:53:28Z", "author_association": "MEMBER", "body_html": "<p>Sorry, I should have elaborated.</p>\n<p>I believe (from the symptoms) that not all updates that are required to be run in the training loop are run by the Estimator returned by <code>model_to_estimator</code>. Hence it only affects batchnorm, which is one of the very few layers that need updates.</p>\n<p>The best workaround IMO is to move the <code>Model</code> definition into the <code>model_fn</code>. An example of this is here: <a href=\"https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py\">https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py</a> (this example could be further simplified by running <code>.compile</code> on the model instead of defining the optimizer in the <code>model_fn</code> directly).</p>", "body_text": "Sorry, I should have elaborated.\nI believe (from the symptoms) that not all updates that are required to be run in the training loop are run by the Estimator returned by model_to_estimator. Hence it only affects batchnorm, which is one of the very few layers that need updates.\nThe best workaround IMO is to move the Model definition into the model_fn. An example of this is here: https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py (this example could be further simplified by running .compile on the model instead of defining the optimizer in the model_fn directly).", "body": "Sorry, I should have elaborated.\r\n\r\nI believe (from the symptoms) that not all updates that are required to be run in the training loop are run by the Estimator returned by `model_to_estimator`. Hence it only affects batchnorm, which is one of the very few layers that need updates.\r\n\r\nThe best workaround IMO is to move the `Model` definition into the `model_fn`. An example of this is here: https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py (this example could be further simplified by running `.compile` on the model instead of defining the optimizer in the `model_fn` directly)."}