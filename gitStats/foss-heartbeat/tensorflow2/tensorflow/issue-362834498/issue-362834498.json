{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22462", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22462/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22462/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22462/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22462", "id": 362834498, "node_id": "MDU6SXNzdWUzNjI4MzQ0OTg=", "number": 22462, "title": "Different behaviors when using  relu activation inside conv2d layer and a standalone ReLU() layer", "user": {"login": "srihari-humbarwadi", "id": 24864163, "node_id": "MDQ6VXNlcjI0ODY0MTYz", "avatar_url": "https://avatars0.githubusercontent.com/u/24864163?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srihari-humbarwadi", "html_url": "https://github.com/srihari-humbarwadi", "followers_url": "https://api.github.com/users/srihari-humbarwadi/followers", "following_url": "https://api.github.com/users/srihari-humbarwadi/following{/other_user}", "gists_url": "https://api.github.com/users/srihari-humbarwadi/gists{/gist_id}", "starred_url": "https://api.github.com/users/srihari-humbarwadi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srihari-humbarwadi/subscriptions", "organizations_url": "https://api.github.com/users/srihari-humbarwadi/orgs", "repos_url": "https://api.github.com/users/srihari-humbarwadi/repos", "events_url": "https://api.github.com/users/srihari-humbarwadi/events{/privacy}", "received_events_url": "https://api.github.com/users/srihari-humbarwadi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-22T07:29:18Z", "updated_at": "2018-10-05T22:06:20Z", "closed_at": "2018-10-05T22:06:20Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1</li>\n<li><strong>Python version</strong>: 3,6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0</li>\n<li><strong>GPU model and memory</strong>: GTX 1080ti 11gb</li>\n<li><strong>Exact command to reproduce</strong>: run the code on mnist dataset</li>\n</ul>\n<pre><code>from tensorflow.python.keras.layers import Conv2D, ReLU, BatchNormalization, Dense, Input, Conv2DTranspose, UpSampling2D, Flatten, Reshape\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.utils import multi_gpu_model\nfrom tensorflow.python.keras.optimizers import Nadam\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras.datasets import mnist\n\n\nimg_height, img_width = 28, 28\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nX = np.expand_dims(x_train, axis=-1)\nprint(X.shape)\n\ninput_image = Input(shape=(img_height, img_width, 1), name='image_imput')\nx = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1', activation='relu')(input_image)\nx = Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv2', activation='relu')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='encoder_conv3', activation='relu')(x)\nx = Flatten()(x)\nencoded = Dense(units=10)(x)\n\ny = Dense(units=1152, activation='relu')(encoded)\ny = Reshape((3, 3, 128))(y)\ny = Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='decoder_deconv1', activation='relu')(y)\ny = Conv2DTranspose(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv2', activation='relu')(y)\ndecoded_image = Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv3', activation='relu')(y)\n\n\nCAE = Model(inputs = input_image, outputs = decoded_image, name = 'CAE')\n\n\ntb = TensorBoard(log_dir='logs', write_graph=True)\nmc = ModelCheckpoint(filepath='models/top_weights.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(monitor='loss', patience=15, verbose=1)\nrlr = ReduceLROnPlateau(monitor='loss')\ncallbacks = [tb, mc, es, rlr]\nCAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n\n\n# CAE.load_weights('models/top_weights.h5')\n# CAE.save('CAE.h5')\nCAE.fit(X, X, epochs=1000, batch_size=256, callbacks=callbacks)\n</code></pre>\n<p>in the above code if i do something like this that is  use a standalone activation layer, the model behaves differently</p>\n<pre><code>x = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1')(input_image)\nx = ReLU()(x)\n</code></pre>\n<p>If i include the activation in the conv2d layer, the model converges at 80% accuracy and when i use a standalone activation layer the model is stuck at 11% accuracy.</p>\n<p>I want to know the reason for different behavior</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.10.1\nPython version: 3,6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0/7.0\nGPU model and memory: GTX 1080ti 11gb\nExact command to reproduce: run the code on mnist dataset\n\nfrom tensorflow.python.keras.layers import Conv2D, ReLU, BatchNormalization, Dense, Input, Conv2DTranspose, UpSampling2D, Flatten, Reshape\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.utils import multi_gpu_model\nfrom tensorflow.python.keras.optimizers import Nadam\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras.datasets import mnist\n\n\nimg_height, img_width = 28, 28\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nX = np.expand_dims(x_train, axis=-1)\nprint(X.shape)\n\ninput_image = Input(shape=(img_height, img_width, 1), name='image_imput')\nx = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1', activation='relu')(input_image)\nx = Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv2', activation='relu')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='encoder_conv3', activation='relu')(x)\nx = Flatten()(x)\nencoded = Dense(units=10)(x)\n\ny = Dense(units=1152, activation='relu')(encoded)\ny = Reshape((3, 3, 128))(y)\ny = Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='decoder_deconv1', activation='relu')(y)\ny = Conv2DTranspose(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv2', activation='relu')(y)\ndecoded_image = Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv3', activation='relu')(y)\n\n\nCAE = Model(inputs = input_image, outputs = decoded_image, name = 'CAE')\n\n\ntb = TensorBoard(log_dir='logs', write_graph=True)\nmc = ModelCheckpoint(filepath='models/top_weights.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(monitor='loss', patience=15, verbose=1)\nrlr = ReduceLROnPlateau(monitor='loss')\ncallbacks = [tb, mc, es, rlr]\nCAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n\n\n# CAE.load_weights('models/top_weights.h5')\n# CAE.save('CAE.h5')\nCAE.fit(X, X, epochs=1000, batch_size=256, callbacks=callbacks)\n\nin the above code if i do something like this that is  use a standalone activation layer, the model behaves differently\nx = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1')(input_image)\nx = ReLU()(x)\n\nIf i include the activation in the conv2d layer, the model converges at 80% accuracy and when i use a standalone activation layer the model is stuck at 11% accuracy.\nI want to know the reason for different behavior", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3,6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GTX 1080ti 11gb\r\n- **Exact command to reproduce**: run the code on mnist dataset\r\n\r\n```\r\nfrom tensorflow.python.keras.layers import Conv2D, ReLU, BatchNormalization, Dense, Input, Conv2DTranspose, UpSampling2D, Flatten, Reshape\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.utils import multi_gpu_model\r\nfrom tensorflow.python.keras.optimizers import Nadam\r\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.python.keras.datasets import mnist\r\n\r\n\r\nimg_height, img_width = 28, 28\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nX = np.expand_dims(x_train, axis=-1)\r\nprint(X.shape)\r\n\r\ninput_image = Input(shape=(img_height, img_width, 1), name='image_imput')\r\nx = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1', activation='relu')(input_image)\r\nx = Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv2', activation='relu')(x)\r\nx = Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='encoder_conv3', activation='relu')(x)\r\nx = Flatten()(x)\r\nencoded = Dense(units=10)(x)\r\n\r\ny = Dense(units=1152, activation='relu')(encoded)\r\ny = Reshape((3, 3, 128))(y)\r\ny = Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='valid', name ='decoder_deconv1', activation='relu')(y)\r\ny = Conv2DTranspose(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv2', activation='relu')(y)\r\ndecoded_image = Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='decoder_deconv3', activation='relu')(y)\r\n\r\n\r\nCAE = Model(inputs = input_image, outputs = decoded_image, name = 'CAE')\r\n\r\n\r\ntb = TensorBoard(log_dir='logs', write_graph=True)\r\nmc = ModelCheckpoint(filepath='models/top_weights.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\r\nes = EarlyStopping(monitor='loss', patience=15, verbose=1)\r\nrlr = ReduceLROnPlateau(monitor='loss')\r\ncallbacks = [tb, mc, es, rlr]\r\nCAE.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\r\n\r\n\r\n# CAE.load_weights('models/top_weights.h5')\r\n# CAE.save('CAE.h5')\r\nCAE.fit(X, X, epochs=1000, batch_size=256, callbacks=callbacks)\r\n ```\r\n\r\nin the above code if i do something like this that is  use a standalone activation layer, the model behaves differently \r\n```\r\nx = Conv2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name ='encoder_conv1')(input_image)\r\nx = ReLU()(x)\r\n```\r\nIf i include the activation in the conv2d layer, the model converges at 80% accuracy and when i use a standalone activation layer the model is stuck at 11% accuracy.\r\n\r\nI want to know the reason for different behavior "}