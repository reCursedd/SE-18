{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/202680730", "html_url": "https://github.com/tensorflow/tensorflow/issues/1686#issuecomment-202680730", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1686", "id": 202680730, "node_id": "MDEyOklzc3VlQ29tbWVudDIwMjY4MDczMA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-29T02:54:27Z", "updated_at": "2016-03-29T02:54:27Z", "author_association": "CONTRIBUTOR", "body_html": "<p>From a quick look at the Slurm docs, it looks like it could well support running TensorFlow, since (i) there's <a href=\"https://support.nesi.org.nz/hc/en-gb/articles/207782537-Python\" rel=\"nofollow\">decent support for running Python jobs</a>. I don't have access to a Slurm cluster, so I'm going to tag this \"Contributions welcome\", but I'd be happy to work with you on this Issue to get your cluster running on Slurm.</p>\n<p>Here's how you could get started:</p>\n<ol>\n<li>Create a Slurm job that sets up a Python virtualenv, installs a recent nightly PIP package, and runs a Python script. (Version 0.8 should include distributed cluster support.)</li>\n<li>In your Python script, parse the <code>$SLURM_NODELIST</code> environment variable to get a list of the hosts involved in the computation.</li>\n<li>Similarly, extract the <a href=\"https://computing.llnl.gov/linux/slurm/mpi_guide.html#open_mpi\" rel=\"nofollow\"><code>$SLURM_STEP_RESV_PORTS</code> environment variable</a> and somehow decide what port to use in that range.</li>\n<li>Create a <code>tf.ClusterSpec</code> based on the information from the environment variables, and use that to create a <code>tf.GrpcServer</code> (documentation coming soon; see <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/server_lib.py\"><code>server_lib.py</code></a>) in each process.</li>\n<li>Define a TensorFlow graph that is distributed across the nodes in your Slurm job.</li>\n</ol>\n<p>Let me know if you have any questions!</p>", "body_text": "From a quick look at the Slurm docs, it looks like it could well support running TensorFlow, since (i) there's decent support for running Python jobs. I don't have access to a Slurm cluster, so I'm going to tag this \"Contributions welcome\", but I'd be happy to work with you on this Issue to get your cluster running on Slurm.\nHere's how you could get started:\n\nCreate a Slurm job that sets up a Python virtualenv, installs a recent nightly PIP package, and runs a Python script. (Version 0.8 should include distributed cluster support.)\nIn your Python script, parse the $SLURM_NODELIST environment variable to get a list of the hosts involved in the computation.\nSimilarly, extract the $SLURM_STEP_RESV_PORTS environment variable and somehow decide what port to use in that range.\nCreate a tf.ClusterSpec based on the information from the environment variables, and use that to create a tf.GrpcServer (documentation coming soon; see server_lib.py) in each process.\nDefine a TensorFlow graph that is distributed across the nodes in your Slurm job.\n\nLet me know if you have any questions!", "body": "From a quick look at the Slurm docs, it looks like it could well support running TensorFlow, since (i) there's [decent support for running Python jobs](https://support.nesi.org.nz/hc/en-gb/articles/207782537-Python). I don't have access to a Slurm cluster, so I'm going to tag this \"Contributions welcome\", but I'd be happy to work with you on this Issue to get your cluster running on Slurm.\n\nHere's how you could get started:\n1. Create a Slurm job that sets up a Python virtualenv, installs a recent nightly PIP package, and runs a Python script. (Version 0.8 should include distributed cluster support.)\n2. In your Python script, parse the `$SLURM_NODELIST` environment variable to get a list of the hosts involved in the computation.\n3. Similarly, extract the [`$SLURM_STEP_RESV_PORTS` environment variable](https://computing.llnl.gov/linux/slurm/mpi_guide.html#open_mpi) and somehow decide what port to use in that range.\n4. Create a `tf.ClusterSpec` based on the information from the environment variables, and use that to create a `tf.GrpcServer` (documentation coming soon; see [`server_lib.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/server_lib.py)) in each process.\n5. Define a TensorFlow graph that is distributed across the nodes in your Slurm job.\n\nLet me know if you have any questions!\n"}