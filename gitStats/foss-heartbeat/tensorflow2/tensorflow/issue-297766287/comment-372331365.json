{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/372331365", "html_url": "https://github.com/tensorflow/tensorflow/issues/17067#issuecomment-372331365", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17067", "id": 372331365, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjMzMTM2NQ==", "user": {"login": "marcionicolau", "id": 1499733, "node_id": "MDQ6VXNlcjE0OTk3MzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1499733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marcionicolau", "html_url": "https://github.com/marcionicolau", "followers_url": "https://api.github.com/users/marcionicolau/followers", "following_url": "https://api.github.com/users/marcionicolau/following{/other_user}", "gists_url": "https://api.github.com/users/marcionicolau/gists{/gist_id}", "starred_url": "https://api.github.com/users/marcionicolau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marcionicolau/subscriptions", "organizations_url": "https://api.github.com/users/marcionicolau/orgs", "repos_url": "https://api.github.com/users/marcionicolau/repos", "events_url": "https://api.github.com/users/marcionicolau/events{/privacy}", "received_events_url": "https://api.github.com/users/marcionicolau/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-12T14:36:44Z", "updated_at": "2018-03-12T14:36:44Z", "author_association": "NONE", "body_html": "<p>Last Updates @dtrebbien :</p>\n<pre><code>sed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) &gt; 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) &gt; 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/split_lib_gpu.cu.cc\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) &gt; 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc\n</code></pre>\n<p>During the compile, I saw this message:</p>\n<pre><code>ld: warning: cannot export hidden symbol std::__1::__vector_base&lt;tensorflow::graph_transforms::OpTypePattern, std::__1::allocator&lt;tensorflow::graph_transforms::OpTypePattern&gt; &gt;::__destruct_at_end(tensorflow::graph_transforms::OpTypePattern*) from bazel-out/darwin-py3-opt/bin/tensorflow/tools/graph_transforms/libtransforms_lib.pic.lo(remove_nodes.pic.o)\n</code></pre>\n<p>Loading results in these messages</p>\n<pre><code>2018-03-12 11:27:54.282823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] OS X does not support NUMA - returning NUMA node zero\n2018-03-12 11:27:54.282993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: GeForce GTX 780M major: 3 minor: 0 memoryClockRate(GHz): 0.784\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 286.09MiB\n2018-03-12 11:27:54.283018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-03-12 11:27:54.639034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\n2018-03-12 11:27:54.649140: I tensorflow/core/common_runtime/direct_session.cc:297] Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\n</code></pre>\n<p>with a simple example</p>\n<pre><code>import tensorflow as tf\nwith tf.device('/gpu:0'):\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\n\nwith tf.Session() as sess:\n    print (sess.run(c))\n</code></pre>\n<p>results</p>\n<pre><code>2018-03-12 11:30:37.822237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-03-12 11:30:37.822477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\n[[22. 28.]\n [49. 64.]]\n</code></pre>\n<p>No more SEGFAULT !</p>", "body_text": "Last Updates @dtrebbien :\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/split_lib_gpu.cu.cc\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc\n\nDuring the compile, I saw this message:\nld: warning: cannot export hidden symbol std::__1::__vector_base<tensorflow::graph_transforms::OpTypePattern, std::__1::allocator<tensorflow::graph_transforms::OpTypePattern> >::__destruct_at_end(tensorflow::graph_transforms::OpTypePattern*) from bazel-out/darwin-py3-opt/bin/tensorflow/tools/graph_transforms/libtransforms_lib.pic.lo(remove_nodes.pic.o)\n\nLoading results in these messages\n2018-03-12 11:27:54.282823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] OS X does not support NUMA - returning NUMA node zero\n2018-03-12 11:27:54.282993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: GeForce GTX 780M major: 3 minor: 0 memoryClockRate(GHz): 0.784\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 286.09MiB\n2018-03-12 11:27:54.283018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-03-12 11:27:54.639034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\n2018-03-12 11:27:54.649140: I tensorflow/core/common_runtime/direct_session.cc:297] Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\n\nwith a simple example\nimport tensorflow as tf\nwith tf.device('/gpu:0'):\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\n\nwith tf.Session() as sess:\n    print (sess.run(c))\n\nresults\n2018-03-12 11:30:37.822237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-03-12 11:30:37.822477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\n[[22. 28.]\n [49. 64.]]\n\nNo more SEGFAULT !", "body": "Last Updates @dtrebbien :\r\n\r\n```\r\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc\r\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/split_lib_gpu.cu.cc\r\nsed -i.bu 's/__align__(sizeof(T)) /__align__(sizeof(T) > 16 ? sizeof(T) : 16) /g' tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc\r\n```\r\n\r\nDuring the compile, I saw this message:\r\n```\r\nld: warning: cannot export hidden symbol std::__1::__vector_base<tensorflow::graph_transforms::OpTypePattern, std::__1::allocator<tensorflow::graph_transforms::OpTypePattern> >::__destruct_at_end(tensorflow::graph_transforms::OpTypePattern*) from bazel-out/darwin-py3-opt/bin/tensorflow/tools/graph_transforms/libtransforms_lib.pic.lo(remove_nodes.pic.o)\r\n```\r\n\r\nLoading results in these messages\r\n\r\n```\r\n2018-03-12 11:27:54.282823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] OS X does not support NUMA - returning NUMA node zero\r\n2018-03-12 11:27:54.282993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\r\nname: GeForce GTX 780M major: 3 minor: 0 memoryClockRate(GHz): 0.784\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 286.09MiB\r\n2018-03-12 11:27:54.283018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-03-12 11:27:54.639034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\r\n2018-03-12 11:27:54.649140: I tensorflow/core/common_runtime/direct_session.cc:297] Device mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\r\n```\r\n\r\nwith a simple example\r\n\r\n```\r\nimport tensorflow as tf\r\nwith tf.device('/gpu:0'):\r\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n    c = tf.matmul(a, b)\r\n\r\nwith tf.Session() as sess:\r\n    print (sess.run(c))\r\n```\r\n\r\nresults\r\n\r\n```\r\n2018-03-12 11:30:37.822237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-03-12 11:30:37.822477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -> physical GPU (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\n[[22. 28.]\r\n [49. 64.]]\r\n```\r\n\r\nNo more SEGFAULT !"}