{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13507", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13507/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13507/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13507/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13507", "id": 263216428, "node_id": "MDU6SXNzdWUyNjMyMTY0Mjg=", "number": 13507, "title": "AttributeError in distributed training", "user": {"login": "Rikorose", "id": 16517898, "node_id": "MDQ6VXNlcjE2NTE3ODk4", "avatar_url": "https://avatars0.githubusercontent.com/u/16517898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rikorose", "html_url": "https://github.com/Rikorose", "followers_url": "https://api.github.com/users/Rikorose/followers", "following_url": "https://api.github.com/users/Rikorose/following{/other_user}", "gists_url": "https://api.github.com/users/Rikorose/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rikorose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rikorose/subscriptions", "organizations_url": "https://api.github.com/users/Rikorose/orgs", "repos_url": "https://api.github.com/users/Rikorose/repos", "events_url": "https://api.github.com/users/Rikorose/events{/privacy}", "received_events_url": "https://api.github.com/users/Rikorose/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-05T18:08:31Z", "updated_at": "2017-10-06T04:24:41Z", "closed_at": "2017-10-06T04:24:41Z", "author_association": "NONE", "body_html": "<p>Im am running tensorflow gpu '0.12.1' installed in a virtualenv on Debian 9.1 with cuda 8 and cudnn 5.1.</p>\n<p>I tried to run the tutorial from <a href=\"https://www.tensorflow.org/versions/r1.2/deploy/distributed\" rel=\"nofollow\">https://www.tensorflow.org/versions/r1.2/deploy/distributed</a></p>\n<p>I started 2 servers and 2 workers like in the tutorial. The servers started as expected.</p>\n<p>I run this command to start a worker:</p>\n<div class=\"highlight highlight-source-shell\"><pre>python cluster_trainer.py \\\n  --ps_hosts=131.188.30.144:2222,131.188.30.142:2222 \\\n  --worker_hosts=131.188.30.134:2222,131.188.30.135:2222 \\\n  --job_name=worker --task_index=1</pre></div>\n<p>The works exited with the error message:</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX 1050 Ti\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.392\npciBusID 0000:02:00.0\nTotal memory: 3.94GiB\nFree memory: 3.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:02:00.0)\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; 131.188.30.144:2222, 1 -&gt; 131.188.30.142:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:2222, 1 -&gt; 131.188.30.135:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:2222\n['131.188.30.144:2222', '131.188.30.142:2222'] ['131.188.30.134:2222', '131.188.30.135:2222'] worker 0\nTraceback (most recent call last):\n  File \"cluster_trainer.py\", line 85, in &lt;module&gt;\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 43, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"cluster_trainer.py\", line 36, in main\n    loss, global_step=global_step)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\n    grad_loss=grad_loss)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 320, in compute_gradients\n    self._assert_valid_dtypes([loss])\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 460, in _assert_valid_dtypes\n    dtype = t.dtype.base_dtype\nAttributeError: 'ellipsis' object has no attribute 'dtype'\n</code></pre>", "body_text": "Im am running tensorflow gpu '0.12.1' installed in a virtualenv on Debian 9.1 with cuda 8 and cudnn 5.1.\nI tried to run the tutorial from https://www.tensorflow.org/versions/r1.2/deploy/distributed\nI started 2 servers and 2 workers like in the tutorial. The servers started as expected.\nI run this command to start a worker:\npython cluster_trainer.py \\\n  --ps_hosts=131.188.30.144:2222,131.188.30.142:2222 \\\n  --worker_hosts=131.188.30.134:2222,131.188.30.135:2222 \\\n  --job_name=worker --task_index=1\nThe works exited with the error message:\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX 1050 Ti\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.392\npciBusID 0000:02:00.0\nTotal memory: 3.94GiB\nFree memory: 3.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:02:00.0)\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -> {0 -> 131.188.30.144:2222, 1 -> 131.188.30.142:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> 131.188.30.135:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:2222\n['131.188.30.144:2222', '131.188.30.142:2222'] ['131.188.30.134:2222', '131.188.30.135:2222'] worker 0\nTraceback (most recent call last):\n  File \"cluster_trainer.py\", line 85, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 43, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"cluster_trainer.py\", line 36, in main\n    loss, global_step=global_step)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\n    grad_loss=grad_loss)\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 320, in compute_gradients\n    self._assert_valid_dtypes([loss])\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 460, in _assert_valid_dtypes\n    dtype = t.dtype.base_dtype\nAttributeError: 'ellipsis' object has no attribute 'dtype'", "body": "Im am running tensorflow gpu '0.12.1' installed in a virtualenv on Debian 9.1 with cuda 8 and cudnn 5.1.\r\n\r\nI tried to run the tutorial from https://www.tensorflow.org/versions/r1.2/deploy/distributed\r\n\r\nI started 2 servers and 2 workers like in the tutorial. The servers started as expected.\r\n\r\nI run this command to start a worker:\r\n```bash\r\npython cluster_trainer.py \\\r\n  --ps_hosts=131.188.30.144:2222,131.188.30.142:2222 \\\r\n  --worker_hosts=131.188.30.134:2222,131.188.30.135:2222 \\\r\n  --job_name=worker --task_index=1\r\n```\r\nThe works exited with the error message:\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.392\r\npciBusID 0000:02:00.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.87GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:02:00.0)\r\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -> {0 -> 131.188.30.144:2222, 1 -> 131.188.30.142:2222}\r\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> 131.188.30.135:2222}\r\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:2222\r\n['131.188.30.144:2222', '131.188.30.142:2222'] ['131.188.30.134:2222', '131.188.30.135:2222'] worker 0\r\nTraceback (most recent call last):\r\n  File \"cluster_trainer.py\", line 85, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"cluster_trainer.py\", line 36, in main\r\n    loss, global_step=global_step)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 320, in compute_gradients\r\n    self._assert_valid_dtypes([loss])\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 460, in _assert_valid_dtypes\r\n    dtype = t.dtype.base_dtype\r\nAttributeError: 'ellipsis' object has no attribute 'dtype'\r\n```\r\n"}