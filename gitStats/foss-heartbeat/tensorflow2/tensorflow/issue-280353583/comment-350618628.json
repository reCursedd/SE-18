{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350618628", "html_url": "https://github.com/tensorflow/tensorflow/issues/15199#issuecomment-350618628", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15199", "id": 350618628, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDYxODYyOA==", "user": {"login": "yanghoonkim", "id": 9985986, "node_id": "MDQ6VXNlcjk5ODU5ODY=", "avatar_url": "https://avatars2.githubusercontent.com/u/9985986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanghoonkim", "html_url": "https://github.com/yanghoonkim", "followers_url": "https://api.github.com/users/yanghoonkim/followers", "following_url": "https://api.github.com/users/yanghoonkim/following{/other_user}", "gists_url": "https://api.github.com/users/yanghoonkim/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanghoonkim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanghoonkim/subscriptions", "organizations_url": "https://api.github.com/users/yanghoonkim/orgs", "repos_url": "https://api.github.com/users/yanghoonkim/repos", "events_url": "https://api.github.com/users/yanghoonkim/events{/privacy}", "received_events_url": "https://api.github.com/users/yanghoonkim/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-11T04:15:34Z", "updated_at": "2017-12-11T08:20:26Z", "author_association": "NONE", "body_html": "<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes, but only with a few lines.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: conda pip install with the instruction on the tensorflow website(binary)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: gtx 1080 ti</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>import tensorflow as tf<br>\nfrom tensorflow.python.ops import rnn_cell_impl</p>\n<p>cell = rnn_cell_impl.GRUCell(5)<br>\nmemory = tf.get_variable('memory', [10, 8, 5])<br>\nattention = tf.contrib.seq2seq.BahdanauAttention(5, memory)<br>\nwrapped_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention)</p>\n<p>rnn_inputs = [tf.get_variable('1', [10, 5]), tf.get_variable('2', [10, 5]), tf.get_variable('3', [10, 5]), tf.get_variable('4', [10, 5])]<br>\nrnn_state = wrapped_cell.zero_state(10, tf.float32)</p>\n<p>outputs, state=  tf.nn.static_rnn(wrapped_cell, rnn_inputs, dtype = tf.float32)</p>\n<p>sess = tf.InteractiveSession()<br>\nsess.run(outputs)</p>\n<p>I think two modules are not compatible because 1. there is a <strong>for loop</strong> inside ststic_rnn  2. there is a variable_scope inside bahdanau attention(or luong attention) whose first argument(name_or_scope) is set None   -&gt;&gt; while name_or_scope is None, each time a variable within the variable scope is created, the name of variable scope will be added '_N'</p>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but only with a few lines.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): conda pip install with the instruction on the tensorflow website(binary)\nTensorFlow version (use command below): 1.4\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 8.0\nGPU model and memory: gtx 1080 ti\nExact command to reproduce:\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import rnn_cell_impl\ncell = rnn_cell_impl.GRUCell(5)\nmemory = tf.get_variable('memory', [10, 8, 5])\nattention = tf.contrib.seq2seq.BahdanauAttention(5, memory)\nwrapped_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention)\nrnn_inputs = [tf.get_variable('1', [10, 5]), tf.get_variable('2', [10, 5]), tf.get_variable('3', [10, 5]), tf.get_variable('4', [10, 5])]\nrnn_state = wrapped_cell.zero_state(10, tf.float32)\noutputs, state=  tf.nn.static_rnn(wrapped_cell, rnn_inputs, dtype = tf.float32)\nsess = tf.InteractiveSession()\nsess.run(outputs)\nI think two modules are not compatible because 1. there is a for loop inside ststic_rnn  2. there is a variable_scope inside bahdanau attention(or luong attention) whose first argument(name_or_scope) is set None   ->> while name_or_scope is None, each time a variable within the variable scope is created, the name of variable scope will be added '_N'", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but only with a few lines.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: conda pip install with the instruction on the tensorflow website(binary)\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: gtx 1080 ti\r\n- **Exact command to reproduce**:\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import rnn_cell_impl\r\n\r\ncell = rnn_cell_impl.GRUCell(5)\r\nmemory = tf.get_variable('memory', [10, 8, 5])\r\nattention = tf.contrib.seq2seq.BahdanauAttention(5, memory)\r\nwrapped_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention)\r\n\r\nrnn_inputs = [tf.get_variable('1', [10, 5]), tf.get_variable('2', [10, 5]), tf.get_variable('3', [10, 5]), tf.get_variable('4', [10, 5])]\r\nrnn_state = wrapped_cell.zero_state(10, tf.float32)\r\n\r\noutputs, state=  tf.nn.static_rnn(wrapped_cell, rnn_inputs, dtype = tf.float32)\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(outputs)\r\n\r\nI think two modules are not compatible because 1. there is a **for loop** inside ststic_rnn  2. there is a variable_scope inside bahdanau attention(or luong attention) whose first argument(name_or_scope) is set None   ->> while name_or_scope is None, each time a variable within the variable scope is created, the name of variable scope will be added '_N'  "}