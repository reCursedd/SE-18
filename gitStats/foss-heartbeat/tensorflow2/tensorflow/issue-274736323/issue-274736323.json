{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14642", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14642/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14642/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14642/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14642", "id": 274736323, "node_id": "MDU6SXNzdWUyNzQ3MzYzMjM=", "number": 14642, "title": "Android tensorflow lite kernel_util.cc:34 input_product_scale < output_scale", "user": {"login": "jasminezz", "id": 16434016, "node_id": "MDQ6VXNlcjE2NDM0MDE2", "avatar_url": "https://avatars0.githubusercontent.com/u/16434016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasminezz", "html_url": "https://github.com/jasminezz", "followers_url": "https://api.github.com/users/jasminezz/followers", "following_url": "https://api.github.com/users/jasminezz/following{/other_user}", "gists_url": "https://api.github.com/users/jasminezz/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasminezz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasminezz/subscriptions", "organizations_url": "https://api.github.com/users/jasminezz/orgs", "repos_url": "https://api.github.com/users/jasminezz/repos", "events_url": "https://api.github.com/users/jasminezz/events{/privacy}", "received_events_url": "https://api.github.com/users/jasminezz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-11-17T02:58:44Z", "updated_at": "2018-06-06T20:47:04Z", "closed_at": "2018-01-24T23:41:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Windows 7.0</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>: 3.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>1.down load Quantilized MobileNet model 0.75_224 from <a href=\"https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.75_224_frozen.tgz\" rel=\"nofollow\">here</a></p>\n<p>2.Transform the frozen .pb model to .tflite file:<br>\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=tmp/mobilenet_v1_0.75_224/frozen_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=tmp/mobilenet_v1_0.75_224/mobilenet_v1_0.75_224.tflite --inference_type=QUANTIZED_UINT8  --input_type=QUANTIZED_UINT8  --input_arrays=input --default_ranges_min=0 --default_ranges_max=6 --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3</p>\n<p>3.Change the \"MODEL_PATH\" in Tensorflow lite Android demo to \"mobilenet_v1_0.75_224.tflite\"</p>\n<h3>logs</h3>\n<p>4.Then run the demo, make the error:<br>\nFATAL EXCEPTION: CameraBackground<br>\nProcess: android.example.com.tflitecamerademo, PID: 13909<br>\njava.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale &lt; output_scale was not true.<br>\nat org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)<br>\nat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)<br>\nat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)<br>\nat org.tensorflow.lite.Interpreter.run(Interpreter.java:93)<br>\nat com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:109)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)<br>\nat android.os.Handler.handleCallback(Handler.java:739)<br>\nat android.os.Handler.dispatchMessage(Handler.java:95)<br>\nat android.os.Looper.loop(Looper.java:135)<br>\nat android.os.HandlerThread.run(HandlerThread.java:61)</p>\n<p>need your help?</p>\n<p>Followed the same steps , transform other mobilenet models, only the  \"mobilenet_v1_1.0_128\" can run successfully.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 7.0\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version: 3.0\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\n1.down load Quantilized MobileNet model 0.75_224 from here\n2.Transform the frozen .pb model to .tflite file:\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=tmp/mobilenet_v1_0.75_224/frozen_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=tmp/mobilenet_v1_0.75_224/mobilenet_v1_0.75_224.tflite --inference_type=QUANTIZED_UINT8  --input_type=QUANTIZED_UINT8  --input_arrays=input --default_ranges_min=0 --default_ranges_max=6 --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3\n3.Change the \"MODEL_PATH\" in Tensorflow lite Android demo to \"mobilenet_v1_0.75_224.tflite\"\nlogs\n4.Then run the demo, make the error:\nFATAL EXCEPTION: CameraBackground\nProcess: android.example.com.tflitecamerademo, PID: 13909\njava.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale < output_scale was not true.\nat org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\nat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)\nat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\nat org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\nat com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:109)\nat com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)\nat com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)\nat com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)\nat android.os.Handler.handleCallback(Handler.java:739)\nat android.os.Handler.dispatchMessage(Handler.java:95)\nat android.os.Looper.loop(Looper.java:135)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nneed your help?\nFollowed the same steps , transform other mobilenet models, only the  \"mobilenet_v1_1.0_128\" can run successfully.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 7.0\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: 3.0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n1.down load Quantilized MobileNet model 0.75_224 from [here](https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.75_224_frozen.tgz\r\n)\r\n\r\n2.Transform the frozen .pb model to .tflite file:\r\n bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=tmp/mobilenet_v1_0.75_224/frozen_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=tmp/mobilenet_v1_0.75_224/mobilenet_v1_0.75_224.tflite --inference_type=QUANTIZED_UINT8  --input_type=QUANTIZED_UINT8  --input_arrays=input --default_ranges_min=0 --default_ranges_max=6 --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3\r\n\r\n3.Change the \"MODEL_PATH\" in Tensorflow lite Android demo to \"mobilenet_v1_0.75_224.tflite\"\r\n\r\n### logs\r\n4.Then run the demo, make the error:\r\nFATAL EXCEPTION: CameraBackground\r\n                                                                                      Process: android.example.com.tflitecamerademo, PID: 13909\r\n                                                                                      java.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale < output_scale was not true.\r\n                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n                                                                                          at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)\r\n                                                                                          at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\r\n                                                                                          at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\r\n                                                                                          at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:109)\r\n                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)\r\n                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)\r\n                                                                                          at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)\r\n                                                                                          at android.os.Handler.handleCallback(Handler.java:739)\r\n                                                                                          at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                                          at android.os.Looper.loop(Looper.java:135)\r\n                                                                                          at android.os.HandlerThread.run(HandlerThread.java:61)\r\n\r\nneed your help?\r\n\r\nFollowed the same steps , transform other mobilenet models, only the  \"mobilenet_v1_1.0_128\" can run successfully.\r\n"}