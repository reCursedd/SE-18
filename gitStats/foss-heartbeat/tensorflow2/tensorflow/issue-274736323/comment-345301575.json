{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345301575", "html_url": "https://github.com/tensorflow/tensorflow/issues/14642#issuecomment-345301575", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14642", "id": 345301575, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTMwMTU3NQ==", "user": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-17T17:00:20Z", "updated_at": "2017-11-17T17:00:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for the detailed description of the error.</p>\n<p>Unfortunately the quantization method used in the models you downloaded are currently incompatible with TF Lite's quantization. (Details: the weights were quantized, and a Dequantize op was introduced post-training, as opposed to retrained the model with quantization in mind). This is why the tensors lack min/max information.</p>\n<p>To make this work you need to use pass:<br>\n'--default_ranges_min=0' '--default_ranges_max=6' '--std_values=128' '--mean_values=128'<br>\nbut bear in mind that this will noticeably affect the accuracy of the model. The alternative is to use the corresponding float model and alter the demo app to provide floating-point input.</p>", "body_text": "Thanks for the detailed description of the error.\nUnfortunately the quantization method used in the models you downloaded are currently incompatible with TF Lite's quantization. (Details: the weights were quantized, and a Dequantize op was introduced post-training, as opposed to retrained the model with quantization in mind). This is why the tensors lack min/max information.\nTo make this work you need to use pass:\n'--default_ranges_min=0' '--default_ranges_max=6' '--std_values=128' '--mean_values=128'\nbut bear in mind that this will noticeably affect the accuracy of the model. The alternative is to use the corresponding float model and alter the demo app to provide floating-point input.", "body": "Thanks for the detailed description of the error.\r\n\r\nUnfortunately the quantization method used in the models you downloaded are currently incompatible with TF Lite's quantization. (Details: the weights were quantized, and a Dequantize op was introduced post-training, as opposed to retrained the model with quantization in mind). This is why the tensors lack min/max information.\r\n\r\nTo make this work you need to use pass:\r\n  '--default_ranges_min=0' '--default_ranges_max=6' '--std_values=128' '--mean_values=128'\r\nbut bear in mind that this will noticeably affect the accuracy of the model. The alternative is to use the corresponding float model and alter the demo app to provide floating-point input."}