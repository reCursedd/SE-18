{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15530", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15530/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15530/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15530/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15530", "id": 283683961, "node_id": "MDU6SXNzdWUyODM2ODM5NjE=", "number": 15530, "title": "Bug?: reading from Google Cloud Storage appears to be accessing cached version", "user": {"login": "cbockman", "id": 4667922, "node_id": "MDQ6VXNlcjQ2Njc5MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/4667922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cbockman", "html_url": "https://github.com/cbockman", "followers_url": "https://api.github.com/users/cbockman/followers", "following_url": "https://api.github.com/users/cbockman/following{/other_user}", "gists_url": "https://api.github.com/users/cbockman/gists{/gist_id}", "starred_url": "https://api.github.com/users/cbockman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cbockman/subscriptions", "organizations_url": "https://api.github.com/users/cbockman/orgs", "repos_url": "https://api.github.com/users/cbockman/repos", "events_url": "https://api.github.com/users/cbockman/events{/privacy}", "received_events_url": "https://api.github.com/users/cbockman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-12-20T20:21:18Z", "updated_at": "2018-11-20T13:26:24Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-rc1-11-g130a514 1.4.0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: observed on CPU &amp; GPU.</li>\n<li><strong>GPU model and memory</strong>: observed on CPU &amp; GPU.</li>\n<li><strong>Exact command to reproduce</strong>: See below.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>How this arose:</p>\n<p>We are trying to set up a basic distributed TF version, where we have separate pods (on Kubernetes) doing validation and training (a simple version, with 1 of each).  GCS is used as the backend to store model output (checkpoints, etc.).</p>\n<p>The validation pod periodically (via Experiment\u2019s continuous_eval <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L564\">tensorflow/tensorflow/contrib/learn/python/learn/experiment.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 564\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e\">f5f2f78</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L564\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"564\"></td>\n          <td id=\"LC564\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">def</span> <span class=\"pl-en\">continuous_eval</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n) periodically polls for new checkpoints to evaluate (<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L517\">tensorflow/tensorflow/contrib/learn/python/learn/experiment.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 517\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e\">f5f2f78</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L517\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"517\"></td>\n          <td id=\"LC517\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> latest_path <span class=\"pl-k\">=</span> saver.latest_checkpoint(<span class=\"pl-c1\">self</span>._estimator.model_dir) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n).</p>\n<p>If it doesn\u2019t find a new checkpoint, it (per the underlying code) echoes out \u201cNo new checkpoint ready for evaluation\u201d and continues to wait for a new one.</p>\n<p>In practice, we found that, even as the training pod produces new checkpoints, the validation pod <em>never</em> picks up a new checkpoint, beyond the first one.  I.e., it collects an initial checkpoint, does evaluation, and then, in all future cycles, echoes out \"No new checkpoint ready for evaluation\".</p>\n<p>In debugging, we found that the checkpoint file the saver tries to load up is always found to be some earlier iteration of the file (<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/python/training/saver.py#L1005\">tensorflow/tensorflow/python/training/saver.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 1005\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e\">f5f2f78</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L1005\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1005\"></td>\n          <td id=\"LC1005\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> file_content <span class=\"pl-k\">=</span> file_io.read_file_to_string( </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n) -- i.e., it seems like the GCS file loader reads the file once, and, from then on out, is continuous accessing a cached version of the data.</p>\n<p>Digging into the code further, this appears to be an issue with how the file reader (file_io.read_file_to_string(...) and downstream methods) loads GCS files.  We were able to replicate this behavior separately, below.</p>\n<p><strong>Help appreciated!</strong></p>\n<ul>\n<li>Is this intended behavior?  Is there, e.g., some sort of GCS setting we have incorrectly set?</li>\n<li>Assuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?  Our next step is going to be to try monkey-patching some of the tf functions to just pull the GCS file local to disk and read it from there...although this is of course not preferred.</li>\n</ul>\n<p>As a side note, Experiment does have a number of references to special handling around using GCS as the backend, although I don't have enough context to say if this is relevant to what we are seeing or not (<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L94\">tensorflow/tensorflow/contrib/learn/python/learn/experiment.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 94\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e\">f5f2f78</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L94\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"94\"></td>\n          <td id=\"LC94\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> searches on GCS.</span> </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n, <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L269\">tensorflow/tensorflow/contrib/learn/python/learn/experiment.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 269\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e\">f5f2f78</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L269\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"269\"></td>\n          <td id=\"LC269\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> fixed holistically later (b/36498507).</span> </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n).</p>\n<h3>Source code / logs</h3>\n<p>Below is a pair of scripts that will replicate this issue.  Run the \u201cBasic Reader\u201d (using the same loading interface from get_checkpoint_state) and the \u201cBasic Writer\u201d simultaneously, and the reader will initially catch whatever is in the file, and then never update, even as the writer continues to write.</p>\n<p>Other things we tried:</p>\n<ul>\n<li>Changing the read/write path to local disk, instead of GCS.  This, unsurprisingly, worked.</li>\n<li>A version of a reader with a context manager (below), to try to reset the reader each loop, and an explicit file.close() (not shown).  Both had the same behavior, i.e., new reads didn't provide the updated file.</li>\n<li>Writing from the same file (process) that we read from: probably unsurprisingly, this <em>does</em> work; i.e., the writing activity either updates the local cache or otherwise convinces the reader to grab a fresh copy from GCS (we didn\u2019t actually test which this might be).</li>\n</ul>\n<p>Basic Reader:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python</span>\n\n<span class=\"pl-k\">from</span> tensorflow.python.lib.io <span class=\"pl-k\">import</span> file_io\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> os\n\n<span class=\"pl-v\">file</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>gs://[MYPATH]<span class=\"pl-pds\">'</span></span>\n\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>GOOGLE_APPLICATION_CREDENTIALS<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/usr/src/app/gcloud/keys/google-auth.json<span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">read</span>():\n    counter<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n    <span class=\"pl-k\">while</span> counter<span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">15</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>reading...<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Contents:<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(file_io.read_file_to_string(<span class=\"pl-v\">file</span>))\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Sleeping for a second...<span class=\"pl-pds\">\"</span></span>)\n        time.sleep(<span class=\"pl-c1\">3</span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        counter <span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\n\nread()</pre></div>\n<p>Basic writer</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python</span>\n\n<span class=\"pl-k\">from</span> tensorflow.python.lib.io <span class=\"pl-k\">import</span> file_io\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> os\n\n<span class=\"pl-v\">file</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>gs://[MYPATH]<span class=\"pl-pds\">'</span></span>\n\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>GOOGLE_APPLICATION_CREDENTIALS<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/usr/src/app/gcloud/keys/google-auth.json<span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">write</span>():\n    counter<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n    <span class=\"pl-k\">while</span> counter<span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">15</span>:\n        <span class=\"pl-k\">with</span> file_io.FileIO(<span class=\"pl-v\">file</span>, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>w<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n            f.write(<span class=\"pl-c1\">str</span>(counter))\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Wrote <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(counter))\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Sleeping for a second...<span class=\"pl-pds\">\"</span></span>)\n        time.sleep(<span class=\"pl-c1\">3</span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        counter <span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\n\nwrite()</pre></div>\n<p>Reader with context manager</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python</span>\n\n<span class=\"pl-k\">from</span> tensorflow.python.lib.io <span class=\"pl-k\">import</span> file_io\n\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> os\n\n<span class=\"pl-v\">file</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>gs://[MYPATH]<span class=\"pl-pds\">'</span></span>\n\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>GOOGLE_APPLICATION_CREDENTIALS<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/usr/src/app/gcloud/keys/google-auth.json<span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">read</span>():\n    counter<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n    <span class=\"pl-k\">while</span> counter<span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">15</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>reading...<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Contents:<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-k\">with</span> file_io.FileIO(<span class=\"pl-v\">file</span>, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>r<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n           <span class=\"pl-c1\">print</span>(f.read())\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Sleeping for a second...<span class=\"pl-pds\">\"</span></span>)\n        time.sleep(<span class=\"pl-c1\">3</span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        counter <span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\n\nread()</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.4.0-rc1-11-g130a514 1.4.0\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: observed on CPU & GPU.\nGPU model and memory: observed on CPU & GPU.\nExact command to reproduce: See below.\n\nDescribe the problem\nHow this arose:\nWe are trying to set up a basic distributed TF version, where we have separate pods (on Kubernetes) doing validation and training (a simple version, with 1 of each).  GCS is used as the backend to store model output (checkpoints, etc.).\nThe validation pod periodically (via Experiment\u2019s continuous_eval \n  \n    \n      tensorflow/tensorflow/contrib/learn/python/learn/experiment.py\n    \n    \n         Line 564\n      in\n      f5f2f78\n    \n    \n    \n    \n\n        \n          \n           def continuous_eval(self, \n        \n    \n  \n\n) periodically polls for new checkpoints to evaluate (\n  \n    \n      tensorflow/tensorflow/contrib/learn/python/learn/experiment.py\n    \n    \n         Line 517\n      in\n      f5f2f78\n    \n    \n    \n    \n\n        \n          \n           latest_path = saver.latest_checkpoint(self._estimator.model_dir) \n        \n    \n  \n\n).\nIf it doesn\u2019t find a new checkpoint, it (per the underlying code) echoes out \u201cNo new checkpoint ready for evaluation\u201d and continues to wait for a new one.\nIn practice, we found that, even as the training pod produces new checkpoints, the validation pod never picks up a new checkpoint, beyond the first one.  I.e., it collects an initial checkpoint, does evaluation, and then, in all future cycles, echoes out \"No new checkpoint ready for evaluation\".\nIn debugging, we found that the checkpoint file the saver tries to load up is always found to be some earlier iteration of the file (\n  \n    \n      tensorflow/tensorflow/python/training/saver.py\n    \n    \n         Line 1005\n      in\n      f5f2f78\n    \n    \n    \n    \n\n        \n          \n           file_content = file_io.read_file_to_string( \n        \n    \n  \n\n) -- i.e., it seems like the GCS file loader reads the file once, and, from then on out, is continuous accessing a cached version of the data.\nDigging into the code further, this appears to be an issue with how the file reader (file_io.read_file_to_string(...) and downstream methods) loads GCS files.  We were able to replicate this behavior separately, below.\nHelp appreciated!\n\nIs this intended behavior?  Is there, e.g., some sort of GCS setting we have incorrectly set?\nAssuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?  Our next step is going to be to try monkey-patching some of the tf functions to just pull the GCS file local to disk and read it from there...although this is of course not preferred.\n\nAs a side note, Experiment does have a number of references to special handling around using GCS as the backend, although I don't have enough context to say if this is relevant to what we are seeing or not (\n  \n    \n      tensorflow/tensorflow/contrib/learn/python/learn/experiment.py\n    \n    \n         Line 94\n      in\n      f5f2f78\n    \n    \n    \n    \n\n        \n          \n           # searches on GCS. \n        \n    \n  \n\n, \n  \n    \n      tensorflow/tensorflow/contrib/learn/python/learn/experiment.py\n    \n    \n         Line 269\n      in\n      f5f2f78\n    \n    \n    \n    \n\n        \n          \n           # fixed holistically later (b/36498507). \n        \n    \n  \n\n).\nSource code / logs\nBelow is a pair of scripts that will replicate this issue.  Run the \u201cBasic Reader\u201d (using the same loading interface from get_checkpoint_state) and the \u201cBasic Writer\u201d simultaneously, and the reader will initially catch whatever is in the file, and then never update, even as the writer continues to write.\nOther things we tried:\n\nChanging the read/write path to local disk, instead of GCS.  This, unsurprisingly, worked.\nA version of a reader with a context manager (below), to try to reset the reader each loop, and an explicit file.close() (not shown).  Both had the same behavior, i.e., new reads didn't provide the updated file.\nWriting from the same file (process) that we read from: probably unsurprisingly, this does work; i.e., the writing activity either updates the local cache or otherwise convinces the reader to grab a fresh copy from GCS (we didn\u2019t actually test which this might be).\n\nBasic Reader:\n#!/usr/bin/env python\n\nfrom tensorflow.python.lib.io import file_io\nimport time\nimport os\n\nfile='gs://[MYPATH]'\n\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\n\ndef read():\n    counter=0\n    while counter<15:\n        print(\"reading...\")\n        print(\"Contents:\")\n        print(file_io.read_file_to_string(file))\n        print(\"\")\n        print(\"Sleeping for a second...\")\n        time.sleep(3)\n        print(\"\")\n        print(\"\")\n        print(\"\")\n        counter +=1\n\nread()\nBasic writer\n#!/usr/bin/env python\n\nfrom tensorflow.python.lib.io import file_io\nimport time\nimport os\n\nfile='gs://[MYPATH]'\n\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\n\ndef write():\n    counter=0\n    while counter<15:\n        with file_io.FileIO(file, mode='w') as f:\n            f.write(str(counter))\n        print(\"Wrote {}\".format(counter))\n        print(\"\")\n        print(\"Sleeping for a second...\")\n        time.sleep(3)\n        print(\"\")\n        print(\"\")\n        print(\"\")\n        counter +=1\n\nwrite()\nReader with context manager\n#!/usr/bin/env python\n\nfrom tensorflow.python.lib.io import file_io\n\nimport time\nimport os\n\nfile='gs://[MYPATH]'\n\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\n\ndef read():\n    counter=0\n    while counter<15:\n        print(\"reading...\")\n        print(\"Contents:\")\n        with file_io.FileIO(file, mode='r') as f:\n           print(f.read())\n        print(\"\")\n        print(\"Sleeping for a second...\")\n        time.sleep(3)\n        print(\"\")\n        print(\"\")\n        print(\"\")\n        counter +=1\n\nread()", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: observed on CPU & GPU.\r\n- **GPU model and memory**: observed on CPU & GPU.\r\n- **Exact command to reproduce**: See below.\r\n\r\n### Describe the problem\r\n\r\nHow this arose:\r\n\r\nWe are trying to set up a basic distributed TF version, where we have separate pods (on Kubernetes) doing validation and training (a simple version, with 1 of each).  GCS is used as the backend to store model output (checkpoints, etc.).\r\n\r\nThe validation pod periodically (via Experiment\u2019s continuous_eval https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L564) periodically polls for new checkpoints to evaluate (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L517).  \r\n\r\nIf it doesn\u2019t find a new checkpoint, it (per the underlying code) echoes out \u201cNo new checkpoint ready for evaluation\u201d and continues to wait for a new one.\r\n\r\nIn practice, we found that, even as the training pod produces new checkpoints, the validation pod *never* picks up a new checkpoint, beyond the first one.  I.e., it collects an initial checkpoint, does evaluation, and then, in all future cycles, echoes out \"No new checkpoint ready for evaluation\".\r\n\r\nIn debugging, we found that the checkpoint file the saver tries to load up is always found to be some earlier iteration of the file (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/python/training/saver.py#L1005) -- i.e., it seems like the GCS file loader reads the file once, and, from then on out, is continuous accessing a cached version of the data.  \r\n\r\nDigging into the code further, this appears to be an issue with how the file reader (file_io.read_file_to_string(...) and downstream methods) loads GCS files.  We were able to replicate this behavior separately, below.\r\n\r\n**Help appreciated!**\r\n\r\n* Is this intended behavior?  Is there, e.g., some sort of GCS setting we have incorrectly set?  \r\n* Assuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?  Our next step is going to be to try monkey-patching some of the tf functions to just pull the GCS file local to disk and read it from there...although this is of course not preferred.\r\n\r\nAs a side note, Experiment does have a number of references to special handling around using GCS as the backend, although I don't have enough context to say if this is relevant to what we are seeing or not (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L94, https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L269).\r\n\r\n### Source code / logs\r\n\r\nBelow is a pair of scripts that will replicate this issue.  Run the \u201cBasic Reader\u201d (using the same loading interface from get_checkpoint_state) and the \u201cBasic Writer\u201d simultaneously, and the reader will initially catch whatever is in the file, and then never update, even as the writer continues to write.\r\n\r\nOther things we tried:\r\n\r\n* Changing the read/write path to local disk, instead of GCS.  This, unsurprisingly, worked.\r\n* A version of a reader with a context manager (below), to try to reset the reader each loop, and an explicit file.close() (not shown).  Both had the same behavior, i.e., new reads didn't provide the updated file.\r\n* Writing from the same file (process) that we read from: probably unsurprisingly, this *does* work; i.e., the writing activity either updates the local cache or otherwise convinces the reader to grab a fresh copy from GCS (we didn\u2019t actually test which this might be).  \r\n\r\nBasic Reader:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nfrom tensorflow.python.lib.io import file_io\r\nimport time\r\nimport os\r\n\r\nfile='gs://[MYPATH]'\r\n\r\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\r\n\r\ndef read():\r\n    counter=0\r\n    while counter<15:\r\n        print(\"reading...\")\r\n        print(\"Contents:\")\r\n        print(file_io.read_file_to_string(file))\r\n        print(\"\")\r\n        print(\"Sleeping for a second...\")\r\n        time.sleep(3)\r\n        print(\"\")\r\n        print(\"\")\r\n        print(\"\")\r\n        counter +=1\r\n\r\nread()\r\n```\r\n\r\nBasic writer\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nfrom tensorflow.python.lib.io import file_io\r\nimport time\r\nimport os\r\n\r\nfile='gs://[MYPATH]'\r\n\r\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\r\n\r\ndef write():\r\n    counter=0\r\n    while counter<15:\r\n        with file_io.FileIO(file, mode='w') as f:\r\n            f.write(str(counter))\r\n        print(\"Wrote {}\".format(counter))\r\n        print(\"\")\r\n        print(\"Sleeping for a second...\")\r\n        time.sleep(3)\r\n        print(\"\")\r\n        print(\"\")\r\n        print(\"\")\r\n        counter +=1\r\n\r\nwrite()\r\n```\r\n\r\nReader with context manager\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nfrom tensorflow.python.lib.io import file_io\r\n\r\nimport time\r\nimport os\r\n\r\nfile='gs://[MYPATH]'\r\n\r\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/usr/src/app/gcloud/keys/google-auth.json'\r\n\r\ndef read():\r\n    counter=0\r\n    while counter<15:\r\n        print(\"reading...\")\r\n        print(\"Contents:\")\r\n        with file_io.FileIO(file, mode='r') as f:\r\n           print(f.read())\r\n        print(\"\")\r\n        print(\"Sleeping for a second...\")\r\n        time.sleep(3)\r\n        print(\"\")\r\n        print(\"\")\r\n        print(\"\")\r\n        counter +=1\r\n\r\nread()\r\n```"}