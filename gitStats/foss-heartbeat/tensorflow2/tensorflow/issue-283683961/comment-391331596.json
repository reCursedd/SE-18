{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391331596", "html_url": "https://github.com/tensorflow/tensorflow/issues/15530#issuecomment-391331596", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15530", "id": 391331596, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTMzMTU5Ng==", "user": {"login": "agrinh", "id": 2157859, "node_id": "MDQ6VXNlcjIxNTc4NTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/2157859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agrinh", "html_url": "https://github.com/agrinh", "followers_url": "https://api.github.com/users/agrinh/followers", "following_url": "https://api.github.com/users/agrinh/following{/other_user}", "gists_url": "https://api.github.com/users/agrinh/gists{/gist_id}", "starred_url": "https://api.github.com/users/agrinh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agrinh/subscriptions", "organizations_url": "https://api.github.com/users/agrinh/orgs", "repos_url": "https://api.github.com/users/agrinh/repos", "events_url": "https://api.github.com/users/agrinh/events{/privacy}", "received_events_url": "https://api.github.com/users/agrinh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-23T12:40:19Z", "updated_at": "2018-05-23T12:40:19Z", "author_association": "NONE", "body_html": "<p>Ran into a similar issue reading data from a GCS bucket with <code>tf.read_file</code>. Without setting <code>GCS_READ_CACHE_MAX_SIZE_MB=0</code> all RAM was consumed by the cache. Not only was this useless (we were caching with tf Dataset anyways), it was also difficult to debug and not documented behaviour.</p>", "body_text": "Ran into a similar issue reading data from a GCS bucket with tf.read_file. Without setting GCS_READ_CACHE_MAX_SIZE_MB=0 all RAM was consumed by the cache. Not only was this useless (we were caching with tf Dataset anyways), it was also difficult to debug and not documented behaviour.", "body": "Ran into a similar issue reading data from a GCS bucket with `tf.read_file`. Without setting `GCS_READ_CACHE_MAX_SIZE_MB=0` all RAM was consumed by the cache. Not only was this useless (we were caching with tf Dataset anyways), it was also difficult to debug and not documented behaviour."}