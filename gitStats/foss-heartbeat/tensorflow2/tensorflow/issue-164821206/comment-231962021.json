{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231962021", "html_url": "https://github.com/tensorflow/tensorflow/issues/3270#issuecomment-231962021", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3270", "id": 231962021, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTk2MjAyMQ==", "user": {"login": "suraj1990", "id": 5551707, "node_id": "MDQ6VXNlcjU1NTE3MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5551707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suraj1990", "html_url": "https://github.com/suraj1990", "followers_url": "https://api.github.com/users/suraj1990/followers", "following_url": "https://api.github.com/users/suraj1990/following{/other_user}", "gists_url": "https://api.github.com/users/suraj1990/gists{/gist_id}", "starred_url": "https://api.github.com/users/suraj1990/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suraj1990/subscriptions", "organizations_url": "https://api.github.com/users/suraj1990/orgs", "repos_url": "https://api.github.com/users/suraj1990/repos", "events_url": "https://api.github.com/users/suraj1990/events{/privacy}", "received_events_url": "https://api.github.com/users/suraj1990/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-12T07:38:45Z", "updated_at": "2016-07-12T07:49:23Z", "author_association": "NONE", "body_html": "<p>I trained two new models with fewer steps. While training the new models, I used with tf.variable_scope(\"en_fr\") for en-fr translator and with tf.variable_scope(\"fr_en\") for fr-en translator.</p>\n<p>For training :</p>\n<pre><code>with tf.variable_scope('fr_en'):\n   model = create_model(sess, False)\n\nwith tf.variable_scope('en_fr'):\n  model = create_model(sess, False)\n</code></pre>\n<p>during decoding : en-fr</p>\n<pre><code>`def en_fr_decode(sentence):\n\n   global en_fr_sess\n\n   if en_fr_sess==None:\n     en_fr_sess = tf.Session()\n\n   global en_fr_model\n   global en_fr_en_vocab_path\n   global en_fr_fr_vocab_path\n\n\n  if en_fr_model==None:\n   with tf.variable_scope('en_fr'):\n      #import pdb; pdb.set_trace()\n      en_fr_model = create_model(en_fr_sess, True)\n      en_fr_model.batch_size = 1` \n</code></pre>\n<p>decoding fr-en :</p>\n<pre><code>`def fr_en_decode(sentence):\n\n  global fr_en_sess\n\n  if fr_en_sess==None:\n    fr_en_sess = tf.Session()\n\n  global fr_en_model\n  global fr_en_en_vocab_path\n  global fr_en_fr_vocab_path\n\n  if fr_en_model==None:\n    with tf.variable_scope('fr_en'):\n      fr_en_model = fr_en_create_model(fr_en_sess, True)\n      fr_en_model.batch_size = 1`\n</code></pre>\n<p>and the create model functions are as below:</p>\n<pre><code>`def create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n  FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n  FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n  FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n  forward_only=forward_only)\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n  else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model\n\ndef fr_en_create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n     380, 380, _buckets,\n     FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n     FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n     forward_only=forward_only)\n ckpt = tf.train.get_checkpoint_state(\"./password_data/train2/\")\n if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model`\n</code></pre>\n<p>Please see the error logs in the file attached. You can see in the logs that the english to french translation is done, after which I am trying to load the french to english model using fr_en_create_model() method. This will give me error as</p>\n<pre><code>`NotFoundError: Tensor name \"en_fr/Variable\" not found in checkpoint files ./password_data/train2/translate.ckpt-400\n [[Node: fr_en/save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_fr_en/save/Const_0, fr_en/save/restore_slice/tensor_name, fr_en/save/restore_slice/shape_and_slice)]]\n [[Node: fr_en/save/restore_slice_46/_58 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_31_fr_en/save/restore_slice_46\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]`\n</code></pre>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/358786/nohup_1.txt\">nohup_1.txt</a></p>", "body_text": "I trained two new models with fewer steps. While training the new models, I used with tf.variable_scope(\"en_fr\") for en-fr translator and with tf.variable_scope(\"fr_en\") for fr-en translator.\nFor training :\nwith tf.variable_scope('fr_en'):\n   model = create_model(sess, False)\n\nwith tf.variable_scope('en_fr'):\n  model = create_model(sess, False)\n\nduring decoding : en-fr\n`def en_fr_decode(sentence):\n\n   global en_fr_sess\n\n   if en_fr_sess==None:\n     en_fr_sess = tf.Session()\n\n   global en_fr_model\n   global en_fr_en_vocab_path\n   global en_fr_fr_vocab_path\n\n\n  if en_fr_model==None:\n   with tf.variable_scope('en_fr'):\n      #import pdb; pdb.set_trace()\n      en_fr_model = create_model(en_fr_sess, True)\n      en_fr_model.batch_size = 1` \n\ndecoding fr-en :\n`def fr_en_decode(sentence):\n\n  global fr_en_sess\n\n  if fr_en_sess==None:\n    fr_en_sess = tf.Session()\n\n  global fr_en_model\n  global fr_en_en_vocab_path\n  global fr_en_fr_vocab_path\n\n  if fr_en_model==None:\n    with tf.variable_scope('fr_en'):\n      fr_en_model = fr_en_create_model(fr_en_sess, True)\n      fr_en_model.batch_size = 1`\n\nand the create model functions are as below:\n`def create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n  FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n  FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n  FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n  forward_only=forward_only)\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n  else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model\n\ndef fr_en_create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n     380, 380, _buckets,\n     FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n     FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n     forward_only=forward_only)\n ckpt = tf.train.get_checkpoint_state(\"./password_data/train2/\")\n if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model`\n\nPlease see the error logs in the file attached. You can see in the logs that the english to french translation is done, after which I am trying to load the french to english model using fr_en_create_model() method. This will give me error as\n`NotFoundError: Tensor name \"en_fr/Variable\" not found in checkpoint files ./password_data/train2/translate.ckpt-400\n [[Node: fr_en/save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_fr_en/save/Const_0, fr_en/save/restore_slice/tensor_name, fr_en/save/restore_slice/shape_and_slice)]]\n [[Node: fr_en/save/restore_slice_46/_58 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_31_fr_en/save/restore_slice_46\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]`\n\nnohup_1.txt", "body": "I trained two new models with fewer steps. While training the new models, I used with tf.variable_scope(\"en_fr\") for en-fr translator and with tf.variable_scope(\"fr_en\") for fr-en translator. \n\nFor training : \n\n```\nwith tf.variable_scope('fr_en'):\n   model = create_model(sess, False)\n\nwith tf.variable_scope('en_fr'):\n  model = create_model(sess, False)\n```\n\nduring decoding : en-fr\n\n```\n`def en_fr_decode(sentence):\n\n   global en_fr_sess\n\n   if en_fr_sess==None:\n     en_fr_sess = tf.Session()\n\n   global en_fr_model\n   global en_fr_en_vocab_path\n   global en_fr_fr_vocab_path\n\n\n  if en_fr_model==None:\n   with tf.variable_scope('en_fr'):\n      #import pdb; pdb.set_trace()\n      en_fr_model = create_model(en_fr_sess, True)\n      en_fr_model.batch_size = 1` \n```\n\ndecoding fr-en : \n\n```\n`def fr_en_decode(sentence):\n\n  global fr_en_sess\n\n  if fr_en_sess==None:\n    fr_en_sess = tf.Session()\n\n  global fr_en_model\n  global fr_en_en_vocab_path\n  global fr_en_fr_vocab_path\n\n  if fr_en_model==None:\n    with tf.variable_scope('fr_en'):\n      fr_en_model = fr_en_create_model(fr_en_sess, True)\n      fr_en_model.batch_size = 1`\n```\n\nand the create model functions are as below:\n\n```\n`def create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n  FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n  FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n  FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n  forward_only=forward_only)\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n  else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model\n\ndef fr_en_create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n     380, 380, _buckets,\n     FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n     FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n     forward_only=forward_only)\n ckpt = tf.train.get_checkpoint_state(\"./password_data/train2/\")\n if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model`\n```\n\nPlease see the error logs in the file attached. You can see in the logs that the english to french translation is done, after which I am trying to load the french to english model using fr_en_create_model() method. This will give me error as \n\n```\n`NotFoundError: Tensor name \"en_fr/Variable\" not found in checkpoint files ./password_data/train2/translate.ckpt-400\n [[Node: fr_en/save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_fr_en/save/Const_0, fr_en/save/restore_slice/tensor_name, fr_en/save/restore_slice/shape_and_slice)]]\n [[Node: fr_en/save/restore_slice_46/_58 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_31_fr_en/save/restore_slice_46\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]`\n```\n\n[nohup_1.txt](https://github.com/tensorflow/tensorflow/files/358786/nohup_1.txt)\n"}