{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16925", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16925/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16925/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16925/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16925", "id": 296143524, "node_id": "MDU6SXNzdWUyOTYxNDM1MjQ=", "number": 16925, "title": "Using bidirectional_dynamic_rnn with Grid3LSTMCell Gives Outputs with Different Shapes", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-02-10T23:23:49Z", "updated_at": "2018-11-22T18:54:08Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nMicrosoft Windows 8.1</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.4 cpu</li>\n<li><strong>Python version</strong>:<br>\n3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nN/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\nN/A</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nN/A</li>\n<li><strong>GPU model and memory</strong>:<br>\nN/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm not sure if that's how using <code>bidirectional_dynamic_rnn</code> with Grid3LSTMCell works but it's giving outputs that are of different shapes: the first one has three dimensions and the second one has four dimensions.</p>\n<h3>Source code / logs</h3>\n<p>Here's the code:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import grid_rnn\n\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell_fw = grid_rnn.Grid3LSTMCell(num_units=8)\n        self.cell_bw = grid_rnn.Grid3LSTMCell(num_units=8)\n\n    def test_bidirectional_dynamic_grid_rnn(self):\n        outputs, output_states = tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\n        print(outputs)\n\n\nif __name__ == '__main__':\n    tf.test.main()\n</code></pre>\n<p>And here's the output of the print statement:</p>\n<p><code>((&lt;tf.Tensor 'bidirectional_rnn/fw/fw/transpose:0' shape=(1, 1, 8) dtype=float32&gt;,), &lt;tf.Tensor 'ReverseV2:0' shape=(1, 1, 1, 8) dtype=float32&gt;)</code></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nMicrosoft Windows 8.1\nTensorFlow installed from (source or binary):\nBinary\nTensorFlow version (use command below):\n1.4 cpu\nPython version:\n3.6\nBazel version (if compiling from source):\nN/A\nGCC/Compiler version (if compiling from source):\nN/A\nCUDA/cuDNN version:\nN/A\nGPU model and memory:\nN/A\n\nDescribe the problem\nI'm not sure if that's how using bidirectional_dynamic_rnn with Grid3LSTMCell works but it's giving outputs that are of different shapes: the first one has three dimensions and the second one has four dimensions.\nSource code / logs\nHere's the code:\nimport tensorflow as tf\nfrom tensorflow.contrib import grid_rnn\n\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\n    def setUp(self):\n        self.num_features = 1\n        self.time_steps = 1\n        self.batch_size = 1\n        tf.reset_default_graph()\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\n        self.cell_fw = grid_rnn.Grid3LSTMCell(num_units=8)\n        self.cell_bw = grid_rnn.Grid3LSTMCell(num_units=8)\n\n    def test_bidirectional_dynamic_grid_rnn(self):\n        outputs, output_states = tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\n        print(outputs)\n\n\nif __name__ == '__main__':\n    tf.test.main()\n\nAnd here's the output of the print statement:\n((<tf.Tensor 'bidirectional_rnn/fw/fw/transpose:0' shape=(1, 1, 8) dtype=float32>,), <tf.Tensor 'ReverseV2:0' shape=(1, 1, 1, 8) dtype=float32>)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMicrosoft Windows 8.1\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.4 cpu\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n\r\n### Describe the problem\r\nI'm not sure if that's how using `bidirectional_dynamic_rnn` with Grid3LSTMCell works but it's giving outputs that are of different shapes: the first one has three dimensions and the second one has four dimensions.\r\n\r\n### Source code / logs\r\nHere's the code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import grid_rnn\r\n\r\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\r\n    def setUp(self):\r\n        self.num_features = 1\r\n        self.time_steps = 1\r\n        self.batch_size = 1\r\n        tf.reset_default_graph()\r\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\r\n        self.cell_fw = grid_rnn.Grid3LSTMCell(num_units=8)\r\n        self.cell_bw = grid_rnn.Grid3LSTMCell(num_units=8)\r\n\r\n    def test_bidirectional_dynamic_grid_rnn(self):\r\n        outputs, output_states = tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\r\n        print(outputs)\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.test.main()\r\n```\r\n\r\nAnd here's the output of the print statement:\r\n\r\n`((<tf.Tensor 'bidirectional_rnn/fw/fw/transpose:0' shape=(1, 1, 8) dtype=float32>,), <tf.Tensor 'ReverseV2:0' shape=(1, 1, 1, 8) dtype=float32>)`"}