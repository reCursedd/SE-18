{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9136", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9136/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9136/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9136/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9136", "id": 220940068, "node_id": "MDU6SXNzdWUyMjA5NDAwNjg=", "number": 9136, "title": "Issues when using Queues + tf.train.Server", "user": {"login": "jdonier", "id": 3336429, "node_id": "MDQ6VXNlcjMzMzY0Mjk=", "avatar_url": "https://avatars2.githubusercontent.com/u/3336429?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdonier", "html_url": "https://github.com/jdonier", "followers_url": "https://api.github.com/users/jdonier/followers", "following_url": "https://api.github.com/users/jdonier/following{/other_user}", "gists_url": "https://api.github.com/users/jdonier/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdonier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdonier/subscriptions", "organizations_url": "https://api.github.com/users/jdonier/orgs", "repos_url": "https://api.github.com/users/jdonier/repos", "events_url": "https://api.github.com/users/jdonier/events{/privacy}", "received_events_url": "https://api.github.com/users/jdonier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-11T12:47:39Z", "updated_at": "2017-04-20T20:42:34Z", "closed_at": "2017-04-20T20:42:34Z", "author_association": "NONE", "body_html": "<p>NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.</p>\n<h3>You must complete this information or else your issue will be closed</h3>\n<ul>\n<li><em>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?</em>: Yes</li>\n<li><em>TensorFlow installed from (source or binary)?</em>: binary</li>\n<li><em>TensorFlow version</em>: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)</li>\n<li><em>Bazel version (if compiling from source)</em>:</li>\n<li><em>CUDA/cuDNN version</em>: N/A</li>\n<li><em>GPU Model and Memory</em>: N/A</li>\n<li><em>Exact command to reproduce</em>: cf below.</li>\n</ul>\n<p>This problem has been reproduced on both Linux and various Mac OS machines.</p>\n<h3>Describe the problem clearly</h3>\n<p>We seem to experience issues when using both queues + <code>tf.train.Server</code>. When executed in a simple python 3.5.3 console, the following script hangs:</p>\n<pre><code>import tensorflow as tf\nimport time\n\ncluster = tf.train.ClusterSpec({\"cpu1\" : ['localhost:2222']})\nserver = tf.train.Server(cluster, job_name=\"cpu1\", task_index=0)\n\nwith tf.Graph().as_default() as graph:\n    # Queue\n    input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))\n\n    # Useless variable\n    variable = tf.Variable(1., dtype=tf.float32, trainable=False, name=\"variable\")\n\n    # Session and queue runners\n    session = tf.Session(target=server.target)\n    session.run(tf.global_variables_initializer())\n    tf.train.start_queue_runners(session)\n\nprint(session.run(variable))  # this works\nprint(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly\n\n# any pause between creating and running the session breaks it\ntime.sleep(1)\n\nprint(session.run(variable))  # retrieving a variable still works, but...\nprint(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.\n</code></pre>\n<p>It outputs:</p>\n<pre><code>1\n2\n2\n</code></pre>\n<p>and then hangs forever. The problem vanishes when either commenting the <code>input_queue=...</code> line, or when writing <code>session = tf.Session()</code> instead of passing the <code>server.target</code>.</p>\n<p>The problems seems to happen not only with variable assignments, but also saving the model using <code>tf.train.Saver().save(session, 'my_model')</code> for instance (and possibly other operations). Note that reading a variable works fine.</p>\n<p>In the example script, the <code>time.sleep</code>command simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.</p>\n<h3>Source Code / Logs</h3>\n<p>The source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/913097/tf-issue-gdb-bt.txt\">tf-issue-gdb-bt.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/913102/tf-issue-gdb-stack-threads.txt\">tf-issue-gdb-stack-threads.txt</a></p>", "body_text": "NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.\nYou must complete this information or else your issue will be closed\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: Yes\nTensorFlow installed from (source or binary)?: binary\nTensorFlow version: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)\nBazel version (if compiling from source):\nCUDA/cuDNN version: N/A\nGPU Model and Memory: N/A\nExact command to reproduce: cf below.\n\nThis problem has been reproduced on both Linux and various Mac OS machines.\nDescribe the problem clearly\nWe seem to experience issues when using both queues + tf.train.Server. When executed in a simple python 3.5.3 console, the following script hangs:\nimport tensorflow as tf\nimport time\n\ncluster = tf.train.ClusterSpec({\"cpu1\" : ['localhost:2222']})\nserver = tf.train.Server(cluster, job_name=\"cpu1\", task_index=0)\n\nwith tf.Graph().as_default() as graph:\n    # Queue\n    input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))\n\n    # Useless variable\n    variable = tf.Variable(1., dtype=tf.float32, trainable=False, name=\"variable\")\n\n    # Session and queue runners\n    session = tf.Session(target=server.target)\n    session.run(tf.global_variables_initializer())\n    tf.train.start_queue_runners(session)\n\nprint(session.run(variable))  # this works\nprint(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly\n\n# any pause between creating and running the session breaks it\ntime.sleep(1)\n\nprint(session.run(variable))  # retrieving a variable still works, but...\nprint(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.\n\nIt outputs:\n1\n2\n2\n\nand then hangs forever. The problem vanishes when either commenting the input_queue=... line, or when writing session = tf.Session() instead of passing the server.target.\nThe problems seems to happen not only with variable assignments, but also saving the model using tf.train.Saver().save(session, 'my_model') for instance (and possibly other operations). Note that reading a variable works fine.\nIn the example script, the time.sleepcommand simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.\nSource Code / Logs\nThe source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.\ntf-issue-gdb-bt.txt\ntf-issue-gdb-stack-threads.txt", "body": "NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.\r\n\r\n### You must complete this information or else your issue will be closed\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes\r\n- *TensorFlow installed from (source or binary)?*: binary\r\n- *TensorFlow version*: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)\r\n- *Bazel version (if compiling from source)*:\r\n- *CUDA/cuDNN version*: N/A\r\n- *GPU Model and Memory*: N/A\r\n- *Exact command to reproduce*: cf below.\r\n\r\nThis problem has been reproduced on both Linux and various Mac OS machines.\r\n\r\n### Describe the problem clearly\r\n\r\nWe seem to experience issues when using both queues + `tf.train.Server`. When executed in a simple python 3.5.3 console, the following script hangs:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\ncluster = tf.train.ClusterSpec({\"cpu1\" : ['localhost:2222']})\r\nserver = tf.train.Server(cluster, job_name=\"cpu1\", task_index=0)\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    # Queue\r\n    input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))\r\n\r\n    # Useless variable\r\n    variable = tf.Variable(1., dtype=tf.float32, trainable=False, name=\"variable\")\r\n\r\n    # Session and queue runners\r\n    session = tf.Session(target=server.target)\r\n    session.run(tf.global_variables_initializer())\r\n    tf.train.start_queue_runners(session)\r\n\r\nprint(session.run(variable))  # this works\r\nprint(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly\r\n\r\n# any pause between creating and running the session breaks it\r\ntime.sleep(1)\r\n\r\nprint(session.run(variable))  # retrieving a variable still works, but...\r\nprint(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.\r\n```\r\n\r\nIt outputs:\r\n\r\n```\r\n1\r\n2\r\n2\r\n```\r\n\r\nand then hangs forever. The problem vanishes when either commenting the `input_queue=...` line, or when writing `session = tf.Session()` instead of passing the `server.target`.\r\n\r\nThe problems seems to happen not only with variable assignments, but also saving the model using `tf.train.Saver().save(session, 'my_model')` for instance (and possibly other operations). Note that reading a variable works fine.\r\n\r\nIn the example script, the `time.sleep`command simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.\r\n\r\n\r\n### Source Code / Logs\r\nThe source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.\r\n\r\n[tf-issue-gdb-bt.txt](https://github.com/tensorflow/tensorflow/files/913097/tf-issue-gdb-bt.txt)\r\n[tf-issue-gdb-stack-threads.txt](https://github.com/tensorflow/tensorflow/files/913102/tf-issue-gdb-stack-threads.txt)\r\n\r\n"}