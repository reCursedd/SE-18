{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/386494731", "html_url": "https://github.com/tensorflow/tensorflow/issues/18971#issuecomment-386494731", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18971", "id": 386494731, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjQ5NDczMQ==", "user": {"login": "gypleon", "id": 22216143, "node_id": "MDQ6VXNlcjIyMjE2MTQz", "avatar_url": "https://avatars1.githubusercontent.com/u/22216143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gypleon", "html_url": "https://github.com/gypleon", "followers_url": "https://api.github.com/users/gypleon/followers", "following_url": "https://api.github.com/users/gypleon/following{/other_user}", "gists_url": "https://api.github.com/users/gypleon/gists{/gist_id}", "starred_url": "https://api.github.com/users/gypleon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gypleon/subscriptions", "organizations_url": "https://api.github.com/users/gypleon/orgs", "repos_url": "https://api.github.com/users/gypleon/repos", "events_url": "https://api.github.com/users/gypleon/events{/privacy}", "received_events_url": "https://api.github.com/users/gypleon/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-04T02:58:27Z", "updated_at": "2018-05-04T07:31:46Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> ,<br>\nThank you for the reply!</p>\n<p>I followed <a href=\"https://www.tensorflow.org/versions/r1.6/install/install_java#using_tensorflow_with_jdk\" rel=\"nofollow\">Installing TensorFlow for Java - Using TensorFlow with JDK</a> with <strong>TF_TYPE=\"gpu\"</strong> and also successfully ran the HelloTF example, of which results are as shown below:</p>\n<div class=\"highlight highlight-source-java\"><pre>$ java <span class=\"pl-smi\">HelloTF</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">01</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">46</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">37.195042</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>platform<span class=\"pl-k\">/</span>cpu_feature_guard<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">140</span>] <span class=\"pl-smi\">Your</span> <span class=\"pl-c1\">CPU</span> supports instructions that <span class=\"pl-c1\">this</span> <span class=\"pl-smi\">TensorFlow</span> binary was not compiled to use<span class=\"pl-k\">:</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">1</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">2</span> <span class=\"pl-c1\">AVX</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">01</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">46</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">37.668711</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1212</span>] <span class=\"pl-smi\">Found</span> device <span class=\"pl-c1\">0</span> with properties<span class=\"pl-k\">:</span>\nname<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span> major<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3</span> minor<span class=\"pl-k\">:</span> <span class=\"pl-c1\">7</span> memoryClockRate(<span class=\"pl-smi\">GHz</span>)<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0.8235</span>\npciBusID<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">88</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>\ntotalMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>17GiB freeMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>10GiB\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">01</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">46</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">37.668869</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1312</span>] <span class=\"pl-smi\">Adding</span> visible gpu devices<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">01</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">46</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">38.096256</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">993</span>] <span class=\"pl-smi\">Creating</span> <span class=\"pl-smi\">TensorFlow</span> device (<span class=\"pl-k\">/</span>job<span class=\"pl-k\">:</span>localhost<span class=\"pl-k\">/</span>replica<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>task<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>device<span class=\"pl-k\">:</span><span class=\"pl-c1\">GPU</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span> with <span class=\"pl-c1\">10764</span> <span class=\"pl-c1\">MB</span> memory) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> physical <span class=\"pl-c1\">GPU</span> (device<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>, name<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span>, pci bus id<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">88</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>, compute capability<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3.7</span>)\n<span class=\"pl-smi\">Hello</span> from <span class=\"pl-c1\">1.6</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span></pre></div>\n<p>Does it mean that I have configure and register the GPU successfully?<br>\nFurthermore, I built the Java program using standard OpenJDK instead of Maven, that is:</p>\n<div class=\"highlight highlight-source-java\"><pre>$ java <span class=\"pl-k\">-</span>version\nopenjdk version <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>1.8.0_162<span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-smi\">OpenJDK</span> <span class=\"pl-smi\">Runtime</span> <span class=\"pl-smi\">Environment</span> (build <span class=\"pl-c1\">1.8</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0_162</span><span class=\"pl-k\">-</span>8u162<span class=\"pl-k\">-</span>b12<span class=\"pl-k\">-</span>0ubuntu0<span class=\"pl-k\">.</span><span class=\"pl-c1\">16.04</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">2</span><span class=\"pl-k\">-</span>b12)\n<span class=\"pl-smi\">OpenJDK</span> <span class=\"pl-c1\">64</span><span class=\"pl-k\">-</span><span class=\"pl-smi\">Bit</span> <span class=\"pl-smi\">Server</span> <span class=\"pl-c1\">VM</span> (build <span class=\"pl-c1\">25.162</span><span class=\"pl-k\">-</span>b12, mixed mode)</pre></div>\n<div class=\"highlight highlight-source-java\"><pre>javac <span class=\"pl-k\">-</span>d <span class=\"pl-c1\">..</span><span class=\"pl-k\">/</span>bin<span class=\"pl-k\">/</span> <span class=\"pl-k\">*</span><span class=\"pl-k\">.</span>java\njava <span class=\"pl-k\">-</span><span class=\"pl-smi\">Djava</span><span class=\"pl-k\">.</span>library<span class=\"pl-k\">.</span>path<span class=\"pl-k\">=</span><span class=\"pl-c1\">..</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">..</span><span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>jni <span class=\"pl-smi\">Main</span></pre></div>\n<p>CLASSPATH has been exported into environment.<br>\nBy the way, would it be better if I develop it under Maven?</p>\n<p>Looking forward to your reply.<br>\nThanks!</p>\n<p><strong>Update 1</strong>: (tested under Maven)<br>\nI also tried to run the programs under Maven but still got the same results.<br>\nHelloTF:</p>\n<div class=\"highlight highlight-source-java\"><pre>$ mvn <span class=\"pl-k\">-</span>q <span class=\"pl-k\">-</span>e compile exec<span class=\"pl-k\">:</span>java\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">03</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">39</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">14.899898</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>platform<span class=\"pl-k\">/</span>cpu_feature_guard<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">140</span>] <span class=\"pl-smi\">Your</span> <span class=\"pl-c1\">CPU</span> supports instructions that <span class=\"pl-c1\">this</span> <span class=\"pl-smi\">TensorFlow</span> binary was not compiled to use<span class=\"pl-k\">:</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">1</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">2</span> <span class=\"pl-c1\">AVX</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">03</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">39</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">15.369079</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1212</span>] <span class=\"pl-smi\">Found</span> device <span class=\"pl-c1\">0</span> with properties<span class=\"pl-k\">:</span>\nname<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span> major<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3</span> minor<span class=\"pl-k\">:</span> <span class=\"pl-c1\">7</span> memoryClockRate(<span class=\"pl-smi\">GHz</span>)<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0.8235</span>\npciBusID<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">44</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>\ntotalMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>17GiB freeMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>10GiB\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">03</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">39</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">15.369201</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1312</span>] <span class=\"pl-smi\">Adding</span> visible gpu devices<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">03</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">39</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">15.809895</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">993</span>] <span class=\"pl-smi\">Creating</span> <span class=\"pl-smi\">TensorFlow</span> device (<span class=\"pl-k\">/</span>job<span class=\"pl-k\">:</span>localhost<span class=\"pl-k\">/</span>replica<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>task<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>device<span class=\"pl-k\">:</span><span class=\"pl-c1\">GPU</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span> with <span class=\"pl-c1\">10764</span> <span class=\"pl-c1\">MB</span> memory) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> physical <span class=\"pl-c1\">GPU</span> (device<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>, name<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span>, pci bus id<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">44</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>, compute capability<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3.7</span>)\n<span class=\"pl-smi\">Hello</span> from <span class=\"pl-c1\">1.6</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span></pre></div>\n<p>My program:</p>\n<div class=\"highlight highlight-source-java\"><pre><span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">31.631928</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>platform<span class=\"pl-k\">/</span>cpu_feature_guard<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">140</span>] <span class=\"pl-smi\">Your</span> <span class=\"pl-c1\">CPU</span> supports instructions that <span class=\"pl-c1\">this</span> <span class=\"pl-smi\">TensorFlow</span> binary was not compiled to use<span class=\"pl-k\">:</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">1</span> <span class=\"pl-c1\">SSE4</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">2</span> <span class=\"pl-c1\">AVX</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">31.646627</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>cc<span class=\"pl-k\">/</span>saved_model<span class=\"pl-k\">/</span>loader<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">240</span>] <span class=\"pl-smi\">Loading</span> <span class=\"pl-smi\">SavedModel</span> with tags<span class=\"pl-k\">:</span> { serve }; from<span class=\"pl-k\">:</span> <span class=\"pl-c1\">..</span><span class=\"pl-k\">/</span>saved_models<span class=\"pl-k\">/</span>updated_model<span class=\"pl-k\">/</span>for_java\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">32.088859</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1212</span>] <span class=\"pl-smi\">Found</span> device <span class=\"pl-c1\">0</span> with properties<span class=\"pl-k\">:</span>\nname<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span> major<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3</span> minor<span class=\"pl-k\">:</span> <span class=\"pl-c1\">7</span> memoryClockRate(<span class=\"pl-smi\">GHz</span>)<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0.8235</span>\npciBusID<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">44</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>\ntotalMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>17GiB freeMemory<span class=\"pl-k\">:</span> 11<span class=\"pl-k\">.</span>10GiB\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">32.089152</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">1312</span>] <span class=\"pl-smi\">Adding</span> visible gpu devices<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">32.490601</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">993</span>] <span class=\"pl-smi\">Creating</span> <span class=\"pl-smi\">TensorFlow</span> device (<span class=\"pl-k\">/</span>job<span class=\"pl-k\">:</span>localhost<span class=\"pl-k\">/</span>replica<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>task<span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>device<span class=\"pl-k\">:</span><span class=\"pl-c1\">GPU</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">0</span> with <span class=\"pl-c1\">10764</span> <span class=\"pl-c1\">MB</span> memory) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> physical <span class=\"pl-c1\">GPU</span> (device<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0</span>, name<span class=\"pl-k\">:</span> <span class=\"pl-smi\">Tesla</span> <span class=\"pl-c1\">K80</span>, pci bus id<span class=\"pl-k\">:</span> <span class=\"pl-c1\">0000</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">44</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">00</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span>, compute capability<span class=\"pl-k\">:</span> <span class=\"pl-c1\">3.7</span>)\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">04</span> <span class=\"pl-c1\">07</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">32.684505</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">I</span> tensorflow<span class=\"pl-k\">/</span>cc<span class=\"pl-k\">/</span>saved_model<span class=\"pl-k\">/</span>loader<span class=\"pl-k\">.</span>cc<span class=\"pl-k\">:</span><span class=\"pl-c1\">289</span>] <span class=\"pl-smi\">SavedModel</span> load <span class=\"pl-k\">for</span> tags { serve }; <span class=\"pl-smi\">Status</span><span class=\"pl-k\">:</span> fail. <span class=\"pl-smi\">Took</span> <span class=\"pl-c1\">1037733</span> microseconds.\n[<span class=\"pl-c1\">WARNING</span>]\n<span class=\"pl-smi\">java.lang<span class=\"pl-k\">.</span>IllegalArgumentException</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">Cannot</span> assign a device <span class=\"pl-k\">for</span> operation <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">Could</span> not satisfy explicit device specification <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:GPU:0<span class=\"pl-pds\">'</span></span> because no supported kernel <span class=\"pl-k\">for</span> <span class=\"pl-c1\">GPU</span> devices is available.\n<span class=\"pl-smi\">Registered</span> kernels<span class=\"pl-k\">:</span>\n  device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>CPU<span class=\"pl-pds\">'</span></span>\n\n         [[<span class=\"pl-smi\">Node</span><span class=\"pl-k\">:</span> gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span> <span class=\"pl-k\">=</span> <span class=\"pl-k\">Assert</span>[<span class=\"pl-smi\">T</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">DT_STRING</span>, <span class=\"pl-c1\">DT_INT32</span>, <span class=\"pl-c1\">DT_STRING</span>, <span class=\"pl-c1\">DT_INT32</span>], summarize<span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, _device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/device:GPU:0<span class=\"pl-pds\">\"</span></span>](gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">All</span>, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span>data_0, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>stack, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span>data_2, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Shape</span>)]]\n    at <span class=\"pl-smi\">org.tensorflow<span class=\"pl-k\">.</span>SavedModelBundle</span><span class=\"pl-k\">.</span>load (<span class=\"pl-smi\">Native</span> <span class=\"pl-smi\">Method</span>)\n    at <span class=\"pl-smi\">org.tensorflow<span class=\"pl-k\">.</span>SavedModelBundle</span><span class=\"pl-k\">.</span>load (<span class=\"pl-smi\">SavedModelBundle</span><span class=\"pl-k\">.</span>java<span class=\"pl-k\">:</span><span class=\"pl-c1\">39</span>)\n    <span class=\"pl-c1\">......</span>\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-k\">------------------------------------------------------------------------</span>\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-c1\">BUILD</span> <span class=\"pl-c1\">FAILURE</span>\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-k\">------------------------------------------------------------------------</span>\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-smi\">Total</span> time<span class=\"pl-k\">:</span> <span class=\"pl-c1\">2.953</span> s\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-smi\">Finished</span> at<span class=\"pl-k\">:</span> <span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">05</span><span class=\"pl-k\">-</span>04T07<span class=\"pl-k\">:</span><span class=\"pl-c1\">16</span><span class=\"pl-k\">:</span>32Z\n[<span class=\"pl-c1\">INFO</span>] <span class=\"pl-k\">------------------------------------------------------------------------</span>\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-smi\">Failed</span> to execute goal org<span class=\"pl-k\">.</span>codehaus<span class=\"pl-k\">.</span>mojo<span class=\"pl-k\">:</span>exec<span class=\"pl-k\">-</span>maven<span class=\"pl-k\">-</span>plugin<span class=\"pl-k\">:</span><span class=\"pl-c1\">1.6</span><span class=\"pl-k\">.</span><span class=\"pl-c1\">0</span><span class=\"pl-k\">:</span>java (<span class=\"pl-k\">default</span><span class=\"pl-k\">-</span>cli) on project <span class=\"pl-c1\">...</span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">An</span> exception occured <span class=\"pl-k\">while</span> executing the <span class=\"pl-smi\">Java</span> class. <span class=\"pl-smi\">Cannot</span> assign a device <span class=\"pl-k\">for</span> operation <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">:</span> <span class=\"pl-smi\">Could</span> not satisfy explicit device specification <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:GPU:0<span class=\"pl-pds\">'</span></span> because no supported kernel <span class=\"pl-k\">for</span> <span class=\"pl-c1\">GPU</span> devices is available.\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-smi\">Registered</span> kernels<span class=\"pl-k\">:</span>\n[<span class=\"pl-c1\">ERROR</span>]   device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>CPU<span class=\"pl-pds\">'</span></span>\n[<span class=\"pl-c1\">ERROR</span>]\n[<span class=\"pl-c1\">ERROR</span>]        [[<span class=\"pl-smi\">Node</span><span class=\"pl-k\">:</span> gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span> <span class=\"pl-k\">=</span> <span class=\"pl-k\">Assert</span>[<span class=\"pl-smi\">T</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">DT_STRING</span>, <span class=\"pl-c1\">DT_INT32</span>, <span class=\"pl-c1\">DT_STRING</span>, <span class=\"pl-c1\">DT_INT32</span>], summarize<span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, _device<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/device:GPU:0<span class=\"pl-pds\">\"</span></span>](gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">All</span>, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span>data_0, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>stack, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span><span class=\"pl-smi\">Assert</span><span class=\"pl-k\">/</span>data_2, gen<span class=\"pl-k\">/</span>seq2seq<span class=\"pl-k\">/</span>encoder<span class=\"pl-k\">/</span>bidirectional_rnn<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span>bw<span class=\"pl-k\">/</span><span class=\"pl-smi\">Shape</span>)]]\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> [<span class=\"pl-smi\">Help</span> <span class=\"pl-c1\">1</span>]\n[<span class=\"pl-c1\">ERROR</span>]\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-smi\">To</span> see the full stack trace of the errors, re<span class=\"pl-k\">-</span>run <span class=\"pl-smi\">Maven</span> with the <span class=\"pl-k\">-</span>e <span class=\"pl-k\">switch</span>.\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-smi\">Re</span><span class=\"pl-k\">-</span>run <span class=\"pl-smi\">Maven</span> using the <span class=\"pl-k\">-</span><span class=\"pl-smi\">X</span> <span class=\"pl-k\">switch</span> to enable full debug logging.\n[<span class=\"pl-c1\">ERROR</span>]\n[<span class=\"pl-c1\">ERROR</span>] <span class=\"pl-smi\">For</span> more information about the errors and possible solutions, please read the following articles<span class=\"pl-k\">:</span>\n[<span class=\"pl-c1\">ERROR</span>] [<span class=\"pl-smi\">Help</span> <span class=\"pl-c1\">1</span>] http<span class=\"pl-k\">:</span><span class=\"pl-c\"><span class=\"pl-c\">//</span>cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</span></pre></div>\n<p><strong>Additional 1</strong>:<br>\nBesides, I could load the load if abandon GPUs by <strong>add_meta_graph_and_variables(clear_devices=True)</strong>. However, in Java, I still cannot retrieve the variables using names I defined in <strong>signature_def_utils.build_signature_def()</strong>. So I really wonder if there is any wrong with my use of <strong>tf.saved_model.signature_def_utils.build_signature_def()</strong>, as shown in my Python code?</p>\n<p>Thank you so much!</p>", "body_text": "Hi @asimshankar ,\nThank you for the reply!\nI followed Installing TensorFlow for Java - Using TensorFlow with JDK with TF_TYPE=\"gpu\" and also successfully ran the HelloTF example, of which results are as shown below:\n$ java HelloTF\n2018-05-04 01:46:37.195042: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n2018-05-04 01:46:37.668711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:88:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-05-04 01:46:37.668869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-05-04 01:46:38.096256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:88:00.0, compute capability: 3.7)\nHello from 1.6.0\nDoes it mean that I have configure and register the GPU successfully?\nFurthermore, I built the Java program using standard OpenJDK instead of Maven, that is:\n$ java -version\nopenjdk version \"1.8.0_162\"\nOpenJDK Runtime Environment (build 1.8.0_162-8u162-b12-0ubuntu0.16.04.2-b12)\nOpenJDK 64-Bit Server VM (build 25.162-b12, mixed mode)\njavac -d ../bin/ *.java\njava -Djava.library.path=../../lib/jni Main\nCLASSPATH has been exported into environment.\nBy the way, would it be better if I develop it under Maven?\nLooking forward to your reply.\nThanks!\nUpdate 1: (tested under Maven)\nI also tried to run the programs under Maven but still got the same results.\nHelloTF:\n$ mvn -q -e compile exec:java\n2018-05-04 03:39:14.899898: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n2018-05-04 03:39:15.369079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:44:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-05-04 03:39:15.369201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-05-04 03:39:15.809895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:44:00.0, compute capability: 3.7)\nHello from 1.6.0\nMy program:\n2018-05-04 07:16:31.631928: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n2018-05-04 07:16:31.646627: I tensorflow/cc/saved_model/loader.cc:240] Loading SavedModel with tags: { serve }; from: ../saved_models/updated_model/for_java\n2018-05-04 07:16:32.088859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:44:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-05-04 07:16:32.089152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-05-04 07:16:32.490601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:44:00.0, compute capability: 3.7)\n2018-05-04 07:16:32.684505: I tensorflow/cc/saved_model/loader.cc:289] SavedModel load for tags { serve }; Status: fail. Took 1037733 microseconds.\n[WARNING]\njava.lang.IllegalArgumentException: Cannot assign a device for operation 'gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='CPU'\n\n         [[Node: gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/device:GPU:0\"](gen/seq2seq/encoder/bidirectional_rnn/bw/bw/All, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_0, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/stack, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_2, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Shape)]]\n    at org.tensorflow.SavedModelBundle.load (Native Method)\n    at org.tensorflow.SavedModelBundle.load (SavedModelBundle.java:39)\n    ......\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 2.953 s\n[INFO] Finished at: 2018-05-04T07:16:32Z\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project ...: An exception occured while executing the Java class. Cannot assign a device for operation 'gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n[ERROR] Registered kernels:\n[ERROR]   device='CPU'\n[ERROR]\n[ERROR]        [[Node: gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/device:GPU:0\"](gen/seq2seq/encoder/bidirectional_rnn/bw/bw/All, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_0, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/stack, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_2, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Shape)]]\n[ERROR] -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\nAdditional 1:\nBesides, I could load the load if abandon GPUs by add_meta_graph_and_variables(clear_devices=True). However, in Java, I still cannot retrieve the variables using names I defined in signature_def_utils.build_signature_def(). So I really wonder if there is any wrong with my use of tf.saved_model.signature_def_utils.build_signature_def(), as shown in my Python code?\nThank you so much!", "body": "Hi @asimshankar ,\r\nThank you for the reply!\r\n\r\nI followed [Installing TensorFlow for Java - Using TensorFlow with JDK](https://www.tensorflow.org/versions/r1.6/install/install_java#using_tensorflow_with_jdk) with **TF_TYPE=\"gpu\"** and also successfully ran the HelloTF example, of which results are as shown below:\r\n\r\n``` java\r\n$ java HelloTF\r\n2018-05-04 01:46:37.195042: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2018-05-04 01:46:37.668711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:88:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-05-04 01:46:37.668869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-05-04 01:46:38.096256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:88:00.0, compute capability: 3.7)\r\nHello from 1.6.0\r\n```\r\n\r\nDoes it mean that I have configure and register the GPU successfully? \r\nFurthermore, I built the Java program using standard OpenJDK instead of Maven, that is:\r\n``` java\r\n$ java -version\r\nopenjdk version \"1.8.0_162\"\r\nOpenJDK Runtime Environment (build 1.8.0_162-8u162-b12-0ubuntu0.16.04.2-b12)\r\nOpenJDK 64-Bit Server VM (build 25.162-b12, mixed mode)\r\n```\r\n``` java\r\njavac -d ../bin/ *.java\r\njava -Djava.library.path=../../lib/jni Main\r\n```\r\nCLASSPATH has been exported into environment.\r\nBy the way, would it be better if I develop it under Maven?\r\n\r\nLooking forward to your reply.\r\nThanks!\r\n\r\n**Update 1**: (tested under Maven)\r\nI also tried to run the programs under Maven but still got the same results.\r\nHelloTF:\r\n``` java\r\n$ mvn -q -e compile exec:java\r\n2018-05-04 03:39:14.899898: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2018-05-04 03:39:15.369079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:44:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-05-04 03:39:15.369201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-05-04 03:39:15.809895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:44:00.0, compute capability: 3.7)\r\nHello from 1.6.0\r\n```\r\nMy program:\r\n``` java\r\n2018-05-04 07:16:31.631928: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2018-05-04 07:16:31.646627: I tensorflow/cc/saved_model/loader.cc:240] Loading SavedModel with tags: { serve }; from: ../saved_models/updated_model/for_java\r\n2018-05-04 07:16:32.088859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:44:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-05-04 07:16:32.089152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-05-04 07:16:32.490601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:44:00.0, compute capability: 3.7)\r\n2018-05-04 07:16:32.684505: I tensorflow/cc/saved_model/loader.cc:289] SavedModel load for tags { serve }; Status: fail. Took 1037733 microseconds.\r\n[WARNING]\r\njava.lang.IllegalArgumentException: Cannot assign a device for operation 'gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='CPU'\r\n\r\n         [[Node: gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/device:GPU:0\"](gen/seq2seq/encoder/bidirectional_rnn/bw/bw/All, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_0, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/stack, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_2, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Shape)]]\r\n    at org.tensorflow.SavedModelBundle.load (Native Method)\r\n    at org.tensorflow.SavedModelBundle.load (SavedModelBundle.java:39)\r\n    ......\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 2.953 s\r\n[INFO] Finished at: 2018-05-04T07:16:32Z\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project ...: An exception occured while executing the Java class. Cannot assign a device for operation 'gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\n[ERROR] Registered kernels:\r\n[ERROR]   device='CPU'\r\n[ERROR]\r\n[ERROR]        [[Node: gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device=\"/device:GPU:0\"](gen/seq2seq/encoder/bidirectional_rnn/bw/bw/All, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_0, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/stack, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Assert/Assert/data_2, gen/seq2seq/encoder/bidirectional_rnn/bw/bw/Shape)]]\r\n[ERROR] -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n```\r\n\r\n**Additional 1**:\r\nBesides, I could load the load if abandon GPUs by **add_meta_graph_and_variables(clear_devices=True)**. However, in Java, I still cannot retrieve the variables using names I defined in **signature_def_utils.build_signature_def()**. So I really wonder if there is any wrong with my use of **tf.saved_model.signature_def_utils.build_signature_def()**, as shown in my Python code? \r\n\r\nThank you so much!"}