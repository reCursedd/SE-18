{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313224040", "html_url": "https://github.com/tensorflow/tensorflow/issues/9527#issuecomment-313224040", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9527", "id": 313224040, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzIyNDA0MA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-05T20:54:55Z", "updated_at": "2017-07-05T20:54:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Can you provide examples/gists of your manual unrolling code, how you're calling static_rnn, and also your custom dynamic_rnn which doesn't use TensorArrays?</p>\n<p>It's true that if you don't care about the final state or properly zeroing out your outputs (both require using tf.where) then you can get faster performance.  You disable this by passing sequence_length=None to dynamic_rnn.  You can also use tf.contrib.cudnn_rnn if you've got very performance critical code.  I'm trying to understand if tf.where isthe only source of slowdown compared to your streamlined versions.</p>", "body_text": "Can you provide examples/gists of your manual unrolling code, how you're calling static_rnn, and also your custom dynamic_rnn which doesn't use TensorArrays?\nIt's true that if you don't care about the final state or properly zeroing out your outputs (both require using tf.where) then you can get faster performance.  You disable this by passing sequence_length=None to dynamic_rnn.  You can also use tf.contrib.cudnn_rnn if you've got very performance critical code.  I'm trying to understand if tf.where isthe only source of slowdown compared to your streamlined versions.", "body": "Can you provide examples/gists of your manual unrolling code, how you're calling static_rnn, and also your custom dynamic_rnn which doesn't use TensorArrays?\r\n\r\nIt's true that if you don't care about the final state or properly zeroing out your outputs (both require using tf.where) then you can get faster performance.  You disable this by passing sequence_length=None to dynamic_rnn.  You can also use tf.contrib.cudnn_rnn if you've got very performance critical code.  I'm trying to understand if tf.where isthe only source of slowdown compared to your streamlined versions."}