{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17059", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17059/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17059/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17059/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17059", "id": 297698225, "node_id": "MDU6SXNzdWUyOTc2OTgyMjU=", "number": 17059, "title": "Dataset API does not pass dimensionality information for its output tensor", "user": {"login": "Lancerchiang", "id": 35952525, "node_id": "MDQ6VXNlcjM1OTUyNTI1", "avatar_url": "https://avatars2.githubusercontent.com/u/35952525?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lancerchiang", "html_url": "https://github.com/Lancerchiang", "followers_url": "https://api.github.com/users/Lancerchiang/followers", "following_url": "https://api.github.com/users/Lancerchiang/following{/other_user}", "gists_url": "https://api.github.com/users/Lancerchiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lancerchiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lancerchiang/subscriptions", "organizations_url": "https://api.github.com/users/Lancerchiang/orgs", "repos_url": "https://api.github.com/users/Lancerchiang/repos", "events_url": "https://api.github.com/users/Lancerchiang/events{/privacy}", "received_events_url": "https://api.github.com/users/Lancerchiang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-16T07:09:31Z", "updated_at": "2018-02-17T12:03:43Z", "closed_at": "2018-02-17T12:03:43Z", "author_association": "NONE", "body_html": "<p>SYSTEM INFO<br>\npython version: Python 2.7.12<br>\ntensorflow version: 1.4.0<br>\nCUDA version: 8.0<br>\nUbuntu version: Ubuntu 16.04 LTS</p>\n<p>----------------------------------------------------------------UPDATE-------------------------------------------------------------------</p>\n<p>Please directly go to my third post which reproduces my issue with the minimum amount of code</p>\n<p>----------------------------------------------------------UPDATE FINISHED----------------------------------------------------------</p>\n<p><a href=\"url\">https://github.com/tensorflow/tensorflow/issues/13348</a></p>\n<p>My problem is very similar to the issue above but I did not find solution in that post.</p>\n<pre><code>def image_parser(image_name):\n    im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n    im = cv2.imread(im_file)\n    blobs, im_scales = _get_blobs(im)\n    assert len(im_scales) == 1, \"Only single-image batch implemented\"\n    im_blob = blobs['data']\n    blobs['im_info'] = np.array([im_blob.shape[1], im_blob.shape[2], im_scales[0]], dtype=np.float32)\n    return blobs['data'], blobs['im_info'], im_scales, im\n\ndef _get_blobs(im):\n  \"\"\"Convert an image and RoIs within that image into network inputs.\"\"\"\n  blobs = {}\n  blobs['data'], im_scale_factors = _get_image_blob(im)\n\n  return blobs, im_scale_factors\n\ndef _get_image_blob(im):\n  \"\"\"Converts an image into a network input.\n  Arguments:\n    im (ndarray): a color image in BGR order\n  Returns:\n    blob (ndarray): a data blob holding an image pyramid\n    im_scale_factors (list): list of image scales (relative to im) used\n      in the image pyramid\n  \"\"\"\n  im_orig = im.astype(np.float32, copy=True)\n  im_orig -= cfg.PIXEL_MEANS\n\n  im_shape = im_orig.shape\n  im_size_min = np.min(im_shape[0:2])\n  im_size_max = np.max(im_shape[0:2])\n\n  processed_ims = []\n  im_scale_factors = []\n\n  for target_size in cfg.TEST.SCALES:\n    im_scale = float(target_size) / float(im_size_min)\n    # Prevent the biggest axis from being more than MAX_SIZE\n    if np.round(im_scale * im_size_max) &gt; cfg.TEST.MAX_SIZE:\n      im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)\n    im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\n            interpolation=cv2.INTER_LINEAR)\n    im_scale_factors.append(im_scale)\n    processed_ims.append(im)\n\n  # Create a blob to hold the input images\n  blob = im_list_to_blob(processed_ims)\n  return blob, np.array(im_scale_factors)\n\n\ndef im_list_to_blob(ims):\n  \"\"\"Convert a list of images into a network input.\n\n  Assumes images are already prepared (means subtracted, BGR order, ...).\n  \"\"\"\n  max_shape = np.array([im.shape for im in ims]).max(axis=0)\n  num_images = len(ims)\n  blob = np.zeros((num_images, max_shape[0], max_shape[1], 3),\n                  dtype=np.float32)\n  for i in range(num_images):\n    im = ims[i]\n    blob[i, 0:im.shape[0], 0:im.shape[1], :] = im\n\n  return blob\n</code></pre>\n<p>I defined a function <code>image_parser</code> which will parse image file name into 4 numpy arrays (it has three subsequent function calls,  <code> _get_blobs</code>, <code> _get_image_blob</code>,  <code>im_list_to_blob</code>)</p>\n<p>Then I construct a dataset with <code>py_func</code> mapping to form the input pipeline:</p>\n<pre><code> images = []\n for root, dirs, files in os.walk('./data/demo/'):\n     for file in files:\n         if file.endswith('jpg'):\n             images.append(file)\n\n # dataset construction\n im_dataset = tf.data.Dataset.from_tensor_slices(images)\n im_dataset = im_dataset.map(lambda image:\n                             tuple(tf.py_func(image_parser, [image], [tf.float32, tf.float32, tf.float64, tf.uint8])),\n                             num_parallel_calls = 2)\n im_dataset = im_dataset.prefetch(4)\n print(\"output data type is \", im_dataset.output_types)\n print(\"output data shape is \", im_dataset.output_shapes)\n iterator = im_dataset.make_initializable_iterator()\n with tf.Session() as sess:\n     sess.run(iterator.initializer)\n     a = sess.run(iterator.get_next())\n print(\"shape of the run results are: \")\n print(a[0].shape)\n print(a[1].shape)\n print(a[2].shape)\n print(a[3].shape)\n</code></pre>\n<p>When I print the shape of my output tensors from dataset right after my dataset construction, the print is:</p>\n<pre><code>output data type is  (tf.float32, tf.float32, tf.float64, tf.uint8)\noutput data shape is  (TensorShape(None), TensorShape(None), TensorShape(None), TensorShape(None))\n</code></pre>\n<p>the shape of tensors is None.</p>\n<p>However I could print out the output tensor shape after my sess.run.</p>\n<pre><code>shape of the run results are: \n(1, 600, 800, 3)\n(3,)\n(1,)\n(375, 500, 3)\n</code></pre>\n<p>I need the shape of the output tensor from dataset to be defined to feed into my graph. Thanks!</p>", "body_text": "SYSTEM INFO\npython version: Python 2.7.12\ntensorflow version: 1.4.0\nCUDA version: 8.0\nUbuntu version: Ubuntu 16.04 LTS\n----------------------------------------------------------------UPDATE-------------------------------------------------------------------\nPlease directly go to my third post which reproduces my issue with the minimum amount of code\n----------------------------------------------------------UPDATE FINISHED----------------------------------------------------------\nhttps://github.com/tensorflow/tensorflow/issues/13348\nMy problem is very similar to the issue above but I did not find solution in that post.\ndef image_parser(image_name):\n    im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n    im = cv2.imread(im_file)\n    blobs, im_scales = _get_blobs(im)\n    assert len(im_scales) == 1, \"Only single-image batch implemented\"\n    im_blob = blobs['data']\n    blobs['im_info'] = np.array([im_blob.shape[1], im_blob.shape[2], im_scales[0]], dtype=np.float32)\n    return blobs['data'], blobs['im_info'], im_scales, im\n\ndef _get_blobs(im):\n  \"\"\"Convert an image and RoIs within that image into network inputs.\"\"\"\n  blobs = {}\n  blobs['data'], im_scale_factors = _get_image_blob(im)\n\n  return blobs, im_scale_factors\n\ndef _get_image_blob(im):\n  \"\"\"Converts an image into a network input.\n  Arguments:\n    im (ndarray): a color image in BGR order\n  Returns:\n    blob (ndarray): a data blob holding an image pyramid\n    im_scale_factors (list): list of image scales (relative to im) used\n      in the image pyramid\n  \"\"\"\n  im_orig = im.astype(np.float32, copy=True)\n  im_orig -= cfg.PIXEL_MEANS\n\n  im_shape = im_orig.shape\n  im_size_min = np.min(im_shape[0:2])\n  im_size_max = np.max(im_shape[0:2])\n\n  processed_ims = []\n  im_scale_factors = []\n\n  for target_size in cfg.TEST.SCALES:\n    im_scale = float(target_size) / float(im_size_min)\n    # Prevent the biggest axis from being more than MAX_SIZE\n    if np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:\n      im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)\n    im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\n            interpolation=cv2.INTER_LINEAR)\n    im_scale_factors.append(im_scale)\n    processed_ims.append(im)\n\n  # Create a blob to hold the input images\n  blob = im_list_to_blob(processed_ims)\n  return blob, np.array(im_scale_factors)\n\n\ndef im_list_to_blob(ims):\n  \"\"\"Convert a list of images into a network input.\n\n  Assumes images are already prepared (means subtracted, BGR order, ...).\n  \"\"\"\n  max_shape = np.array([im.shape for im in ims]).max(axis=0)\n  num_images = len(ims)\n  blob = np.zeros((num_images, max_shape[0], max_shape[1], 3),\n                  dtype=np.float32)\n  for i in range(num_images):\n    im = ims[i]\n    blob[i, 0:im.shape[0], 0:im.shape[1], :] = im\n\n  return blob\n\nI defined a function image_parser which will parse image file name into 4 numpy arrays (it has three subsequent function calls,   _get_blobs,  _get_image_blob,  im_list_to_blob)\nThen I construct a dataset with py_func mapping to form the input pipeline:\n images = []\n for root, dirs, files in os.walk('./data/demo/'):\n     for file in files:\n         if file.endswith('jpg'):\n             images.append(file)\n\n # dataset construction\n im_dataset = tf.data.Dataset.from_tensor_slices(images)\n im_dataset = im_dataset.map(lambda image:\n                             tuple(tf.py_func(image_parser, [image], [tf.float32, tf.float32, tf.float64, tf.uint8])),\n                             num_parallel_calls = 2)\n im_dataset = im_dataset.prefetch(4)\n print(\"output data type is \", im_dataset.output_types)\n print(\"output data shape is \", im_dataset.output_shapes)\n iterator = im_dataset.make_initializable_iterator()\n with tf.Session() as sess:\n     sess.run(iterator.initializer)\n     a = sess.run(iterator.get_next())\n print(\"shape of the run results are: \")\n print(a[0].shape)\n print(a[1].shape)\n print(a[2].shape)\n print(a[3].shape)\n\nWhen I print the shape of my output tensors from dataset right after my dataset construction, the print is:\noutput data type is  (tf.float32, tf.float32, tf.float64, tf.uint8)\noutput data shape is  (TensorShape(None), TensorShape(None), TensorShape(None), TensorShape(None))\n\nthe shape of tensors is None.\nHowever I could print out the output tensor shape after my sess.run.\nshape of the run results are: \n(1, 600, 800, 3)\n(3,)\n(1,)\n(375, 500, 3)\n\nI need the shape of the output tensor from dataset to be defined to feed into my graph. Thanks!", "body": "SYSTEM INFO\r\npython version: Python 2.7.12\r\ntensorflow version: 1.4.0\r\nCUDA version: 8.0\r\nUbuntu version: Ubuntu 16.04 LTS\r\n\r\n----------------------------------------------------------------UPDATE-------------------------------------------------------------------\r\n\r\nPlease directly go to my third post which reproduces my issue with the minimum amount of code\r\n\r\n----------------------------------------------------------UPDATE FINISHED----------------------------------------------------------\r\n\r\n[https://github.com/tensorflow/tensorflow/issues/13348](url)\r\n\r\nMy problem is very similar to the issue above but I did not find solution in that post.\r\n\r\n```\r\ndef image_parser(image_name):\r\n    im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\r\n    im = cv2.imread(im_file)\r\n    blobs, im_scales = _get_blobs(im)\r\n    assert len(im_scales) == 1, \"Only single-image batch implemented\"\r\n    im_blob = blobs['data']\r\n    blobs['im_info'] = np.array([im_blob.shape[1], im_blob.shape[2], im_scales[0]], dtype=np.float32)\r\n    return blobs['data'], blobs['im_info'], im_scales, im\r\n\r\ndef _get_blobs(im):\r\n  \"\"\"Convert an image and RoIs within that image into network inputs.\"\"\"\r\n  blobs = {}\r\n  blobs['data'], im_scale_factors = _get_image_blob(im)\r\n\r\n  return blobs, im_scale_factors\r\n\r\ndef _get_image_blob(im):\r\n  \"\"\"Converts an image into a network input.\r\n  Arguments:\r\n    im (ndarray): a color image in BGR order\r\n  Returns:\r\n    blob (ndarray): a data blob holding an image pyramid\r\n    im_scale_factors (list): list of image scales (relative to im) used\r\n      in the image pyramid\r\n  \"\"\"\r\n  im_orig = im.astype(np.float32, copy=True)\r\n  im_orig -= cfg.PIXEL_MEANS\r\n\r\n  im_shape = im_orig.shape\r\n  im_size_min = np.min(im_shape[0:2])\r\n  im_size_max = np.max(im_shape[0:2])\r\n\r\n  processed_ims = []\r\n  im_scale_factors = []\r\n\r\n  for target_size in cfg.TEST.SCALES:\r\n    im_scale = float(target_size) / float(im_size_min)\r\n    # Prevent the biggest axis from being more than MAX_SIZE\r\n    if np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:\r\n      im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)\r\n    im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\r\n            interpolation=cv2.INTER_LINEAR)\r\n    im_scale_factors.append(im_scale)\r\n    processed_ims.append(im)\r\n\r\n  # Create a blob to hold the input images\r\n  blob = im_list_to_blob(processed_ims)\r\n  return blob, np.array(im_scale_factors)\r\n\r\n\r\ndef im_list_to_blob(ims):\r\n  \"\"\"Convert a list of images into a network input.\r\n\r\n  Assumes images are already prepared (means subtracted, BGR order, ...).\r\n  \"\"\"\r\n  max_shape = np.array([im.shape for im in ims]).max(axis=0)\r\n  num_images = len(ims)\r\n  blob = np.zeros((num_images, max_shape[0], max_shape[1], 3),\r\n                  dtype=np.float32)\r\n  for i in range(num_images):\r\n    im = ims[i]\r\n    blob[i, 0:im.shape[0], 0:im.shape[1], :] = im\r\n\r\n  return blob\r\n```\r\n\r\nI defined a function `image_parser` which will parse image file name into 4 numpy arrays (it has three subsequent function calls,  ` _get_blobs`, ` _get_image_blob`,  `im_list_to_blob`)\r\n\r\nThen I construct a dataset with `py_func` mapping to form the input pipeline:\r\n\r\n   ```\r\n    images = []\r\n    for root, dirs, files in os.walk('./data/demo/'):\r\n        for file in files:\r\n            if file.endswith('jpg'):\r\n                images.append(file)\r\n\r\n    # dataset construction\r\n    im_dataset = tf.data.Dataset.from_tensor_slices(images)\r\n    im_dataset = im_dataset.map(lambda image:\r\n                                tuple(tf.py_func(image_parser, [image], [tf.float32, tf.float32, tf.float64, tf.uint8])),\r\n                                num_parallel_calls = 2)\r\n    im_dataset = im_dataset.prefetch(4)\r\n    print(\"output data type is \", im_dataset.output_types)\r\n    print(\"output data shape is \", im_dataset.output_shapes)\r\n    iterator = im_dataset.make_initializable_iterator()\r\n    with tf.Session() as sess:\r\n        sess.run(iterator.initializer)\r\n        a = sess.run(iterator.get_next())\r\n    print(\"shape of the run results are: \")\r\n    print(a[0].shape)\r\n    print(a[1].shape)\r\n    print(a[2].shape)\r\n    print(a[3].shape)\r\n```\r\n\r\nWhen I print the shape of my output tensors from dataset right after my dataset construction, the print is:\r\n```\r\noutput data type is  (tf.float32, tf.float32, tf.float64, tf.uint8)\r\noutput data shape is  (TensorShape(None), TensorShape(None), TensorShape(None), TensorShape(None))\r\n```\r\nthe shape of tensors is None.\r\n\r\nHowever I could print out the output tensor shape after my sess.run. \r\n```\r\nshape of the run results are: \r\n(1, 600, 800, 3)\r\n(3,)\r\n(1,)\r\n(375, 500, 3)\r\n```\r\n\r\nI need the shape of the output tensor from dataset to be defined to feed into my graph. Thanks!"}