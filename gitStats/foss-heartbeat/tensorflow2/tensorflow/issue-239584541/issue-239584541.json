{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11148", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11148/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11148/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11148/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11148", "id": 239584541, "node_id": "MDU6SXNzdWUyMzk1ODQ1NDE=", "number": 11148, "title": "TFDBG Crashing on Windows 10; 'Causality Violated in Timing Relations of Debug Dumps'", "user": {"login": "CJMenart", "id": 16726571, "node_id": "MDQ6VXNlcjE2NzI2NTcx", "avatar_url": "https://avatars3.githubusercontent.com/u/16726571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CJMenart", "html_url": "https://github.com/CJMenart", "followers_url": "https://api.github.com/users/CJMenart/followers", "following_url": "https://api.github.com/users/CJMenart/following{/other_user}", "gists_url": "https://api.github.com/users/CJMenart/gists{/gist_id}", "starred_url": "https://api.github.com/users/CJMenart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CJMenart/subscriptions", "organizations_url": "https://api.github.com/users/CJMenart/orgs", "repos_url": "https://api.github.com/users/CJMenart/repos", "events_url": "https://api.github.com/users/CJMenart/events{/privacy}", "received_events_url": "https://api.github.com/users/CJMenart/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-06-29T19:20:06Z", "updated_at": "2018-09-28T21:15:06Z", "closed_at": "2018-09-28T21:15:06Z", "author_association": "NONE", "body_html": "<p>I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd.</p>\n<p>But when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'</p>\n<hr>\n<p>-Windows 10, up to date<br>\n-Python 3.5<br>\n-TensorFlow 1.2.0, compiled in CPU-only mode</p>\n<p>Source Code:<br>\nI have one script to define the network and one to run the actual test. I will include both.</p>\n<p>sameDiffNet:</p>\n<pre><code>import tensorflow as tf\n\nclass SameDiffNet:\n\t# class is a siamese FC network for classifying vectors as same/different\n\t\n\tdef __init__(self,inputLen):\n\t\t# settings\n\t\tself.NUM_BRANCHES = 2\n\t\tself.LAYER_SIZES = [100,100]\n\t\tself.DATA_TYPE = tf.float32\n\t\t\n\t\t# input\n\t\tself.inputs = []\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\n\n\t\t# network branches\n\t\tself.branches = []\n\t\tself.branchWeights = self.branch_weights(inputLen)\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.branches.append(self.network_branch(branch))\n\t\t\t\t\n\t\t# combination layer and loss\n\t\tself.out = self.distance_layer_euclidean()\n\t\tself.target = tf.placeholder(self.DATA_TYPE,None)\n\t\tself.loss = self.cross_entropy_loss()\n\t\t\n\tdef branch_weights(self,inputLen):\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=\"weights\"))\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias\"))\n\t\t\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=\"weights\"))\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=\"bias\"))\n\t\t\n\t\treturn netWeights\n\t\t\n\tdef network_branch(self,branch):\n\t\tfc = self.inputs[branch]\n\t\tfor layer in range(len(self.LAYER_SIZES)):\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\n\t\treturn fc\n\t\t\t\n\tdef distance_layer_euclidean(self):\n\t\tassert self.NUM_BRANCHES == 2\n\t\tdist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))\n\t\treturn dist\n\t\t\n\tdef cross_entropy_loss(self):\n\t\tloss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))\n\t\treturn loss`\n</code></pre>\n<p>toyTestTraining:</p>\n<pre><code>''' A simple test where we train our siamese network on toy examples\nOur training data consists of a pair of 0's and 1's, and our truth output will\nsimply be the XOR of these two values'''\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\nfrom sameDiffNet import SameDiffNet\n\nnumTraining = 1000\nnumIter = 1000\n\nsess = tf.InteractiveSession()\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\nsess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\nnetwork = SameDiffNet(2)\noptimizer = tf.train.AdamOptimizer().minimize(network.loss)\n\ndata = np.random.randint(0,2,(numTraining,2))\ntruth = data[:,0] == data[:,1]\ntruth = [float(not truth[b]) for b in range(numTraining)]\ndata = data.astype(float)\n\ninit = tf.global_variables_initializer().run()\nfor iter in range(numIter):\n\tpermutationL = np.random.permutation(numTraining)\n\tpermutationR = np.random.permutation(numTraining)\n\ttarget = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]\n\n\ttotalLoss = 0.0\n\tfor v in range(numTraining):\n\t\t_, loss = sess.run([optimizer,network.loss], feed_dict={\n\t\t\t\t\t\tnetwork.inputs[0]:[data[permutationL[v],:]],\n\t\t\t\t\t\tnetwork.inputs[1]:[data[permutationR[v],:]],\n\t\t\t\t\t\tnetwork.target: target[v]})\n\t\ttotalLoss += loss\n\t\t\n\tif np.isnan(totalLoss):\n\t\tprint('Model diverged with loss = NaN')\n\t\tquit()\n\n\tif iter % 10 == 0:\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\n</code></pre>\n<p>import toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:<br>\nTraceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nFile \"D:\\Computer Vision\\Siamese Same-Different Network\\toyTestTraining.py\", line 35, in <br>\nnetwork.target: target[v]})<br>\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 495, in run<br>\nrun_end_resp = self.on_run_end(run_end_req)<br>\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 312, in on_run_end<br>\nself._dump_root, partition_graphs=partition_graphs)<br>\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 551, in <strong>init</strong><br>\nself._load_partition_graphs(partition_graphs, validate)<br>\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 809, in _load_partition_graphs<br>\nself._validate_dump_with_graphs()<br>\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 985, in _validate_dump_with_graphs<br>\n(node, datum.timestamp, repr(pending_inputs[node])))<br>\nValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]</p>\n<p>This error happens 100% of the time I run these commands.<br>\nI apologize in advance if I'm overlooking something obvious. Thank you.</p>", "body_text": "I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd.\nBut when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'\n\n-Windows 10, up to date\n-Python 3.5\n-TensorFlow 1.2.0, compiled in CPU-only mode\nSource Code:\nI have one script to define the network and one to run the actual test. I will include both.\nsameDiffNet:\nimport tensorflow as tf\n\nclass SameDiffNet:\n\t# class is a siamese FC network for classifying vectors as same/different\n\t\n\tdef __init__(self,inputLen):\n\t\t# settings\n\t\tself.NUM_BRANCHES = 2\n\t\tself.LAYER_SIZES = [100,100]\n\t\tself.DATA_TYPE = tf.float32\n\t\t\n\t\t# input\n\t\tself.inputs = []\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\n\n\t\t# network branches\n\t\tself.branches = []\n\t\tself.branchWeights = self.branch_weights(inputLen)\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.branches.append(self.network_branch(branch))\n\t\t\t\t\n\t\t# combination layer and loss\n\t\tself.out = self.distance_layer_euclidean()\n\t\tself.target = tf.placeholder(self.DATA_TYPE,None)\n\t\tself.loss = self.cross_entropy_loss()\n\t\t\n\tdef branch_weights(self,inputLen):\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=\"weights\"))\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias\"))\n\t\t\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=\"weights\"))\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=\"bias\"))\n\t\t\n\t\treturn netWeights\n\t\t\n\tdef network_branch(self,branch):\n\t\tfc = self.inputs[branch]\n\t\tfor layer in range(len(self.LAYER_SIZES)):\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\n\t\treturn fc\n\t\t\t\n\tdef distance_layer_euclidean(self):\n\t\tassert self.NUM_BRANCHES == 2\n\t\tdist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))\n\t\treturn dist\n\t\t\n\tdef cross_entropy_loss(self):\n\t\tloss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))\n\t\treturn loss`\n\ntoyTestTraining:\n''' A simple test where we train our siamese network on toy examples\nOur training data consists of a pair of 0's and 1's, and our truth output will\nsimply be the XOR of these two values'''\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import debug as tf_debug\nfrom sameDiffNet import SameDiffNet\n\nnumTraining = 1000\nnumIter = 1000\n\nsess = tf.InteractiveSession()\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\nsess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\nnetwork = SameDiffNet(2)\noptimizer = tf.train.AdamOptimizer().minimize(network.loss)\n\ndata = np.random.randint(0,2,(numTraining,2))\ntruth = data[:,0] == data[:,1]\ntruth = [float(not truth[b]) for b in range(numTraining)]\ndata = data.astype(float)\n\ninit = tf.global_variables_initializer().run()\nfor iter in range(numIter):\n\tpermutationL = np.random.permutation(numTraining)\n\tpermutationR = np.random.permutation(numTraining)\n\ttarget = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]\n\n\ttotalLoss = 0.0\n\tfor v in range(numTraining):\n\t\t_, loss = sess.run([optimizer,network.loss], feed_dict={\n\t\t\t\t\t\tnetwork.inputs[0]:[data[permutationL[v],:]],\n\t\t\t\t\t\tnetwork.inputs[1]:[data[permutationR[v],:]],\n\t\t\t\t\t\tnetwork.target: target[v]})\n\t\ttotalLoss += loss\n\t\t\n\tif np.isnan(totalLoss):\n\t\tprint('Model diverged with loss = NaN')\n\t\tquit()\n\n\tif iter % 10 == 0:\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\n\nimport toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:\nTraceback (most recent call last):\nFile \"\", line 1, in \nFile \"D:\\Computer Vision\\Siamese Same-Different Network\\toyTestTraining.py\", line 35, in \nnetwork.target: target[v]})\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 495, in run\nrun_end_resp = self.on_run_end(run_end_req)\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 312, in on_run_end\nself._dump_root, partition_graphs=partition_graphs)\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 551, in init\nself._load_partition_graphs(partition_graphs, validate)\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 809, in _load_partition_graphs\nself._validate_dump_with_graphs()\nFile \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 985, in _validate_dump_with_graphs\n(node, datum.timestamp, repr(pending_inputs[node])))\nValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]\nThis error happens 100% of the time I run these commands.\nI apologize in advance if I'm overlooking something obvious. Thank you.", "body": "I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd. \r\n\r\nBut when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'\r\n\r\n------------------------\r\n\r\n-Windows 10, up to date\r\n-Python 3.5\r\n-TensorFlow 1.2.0, compiled in CPU-only mode\r\n\r\nSource Code:\r\nI have one script to define the network and one to run the actual test. I will include both.\r\n\r\nsameDiffNet:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass SameDiffNet:\r\n\t# class is a siamese FC network for classifying vectors as same/different\r\n\t\r\n\tdef __init__(self,inputLen):\r\n\t\t# settings\r\n\t\tself.NUM_BRANCHES = 2\r\n\t\tself.LAYER_SIZES = [100,100]\r\n\t\tself.DATA_TYPE = tf.float32\r\n\t\t\r\n\t\t# input\r\n\t\tself.inputs = []\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\r\n\r\n\t\t# network branches\r\n\t\tself.branches = []\r\n\t\tself.branchWeights = self.branch_weights(inputLen)\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.branches.append(self.network_branch(branch))\r\n\t\t\t\t\r\n\t\t# combination layer and loss\r\n\t\tself.out = self.distance_layer_euclidean()\r\n\t\tself.target = tf.placeholder(self.DATA_TYPE,None)\r\n\t\tself.loss = self.cross_entropy_loss()\r\n\t\t\r\n\tdef branch_weights(self,inputLen):\r\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\r\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\r\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\r\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=\"weights\"))\r\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias\"))\r\n\t\t\r\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\r\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=\"weights\"))\r\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=\"bias\"))\r\n\t\t\r\n\t\treturn netWeights\r\n\t\t\r\n\tdef network_branch(self,branch):\r\n\t\tfc = self.inputs[branch]\r\n\t\tfor layer in range(len(self.LAYER_SIZES)):\r\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\r\n\t\treturn fc\r\n\t\t\t\r\n\tdef distance_layer_euclidean(self):\r\n\t\tassert self.NUM_BRANCHES == 2\r\n\t\tdist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))\r\n\t\treturn dist\r\n\t\t\r\n\tdef cross_entropy_loss(self):\r\n\t\tloss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))\r\n\t\treturn loss`\r\n```\r\n\r\ntoyTestTraining:\r\n```\r\n''' A simple test where we train our siamese network on toy examples\r\nOur training data consists of a pair of 0's and 1's, and our truth output will\r\nsimply be the XOR of these two values'''\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import debug as tf_debug\r\nfrom sameDiffNet import SameDiffNet\r\n\r\nnumTraining = 1000\r\nnumIter = 1000\r\n\r\nsess = tf.InteractiveSession()\r\nsess = tf_debug.LocalCLIDebugWrapperSession(sess)\r\nsess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\r\nnetwork = SameDiffNet(2)\r\noptimizer = tf.train.AdamOptimizer().minimize(network.loss)\r\n\r\ndata = np.random.randint(0,2,(numTraining,2))\r\ntruth = data[:,0] == data[:,1]\r\ntruth = [float(not truth[b]) for b in range(numTraining)]\r\ndata = data.astype(float)\r\n\r\ninit = tf.global_variables_initializer().run()\r\nfor iter in range(numIter):\r\n\tpermutationL = np.random.permutation(numTraining)\r\n\tpermutationR = np.random.permutation(numTraining)\r\n\ttarget = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]\r\n\r\n\ttotalLoss = 0.0\r\n\tfor v in range(numTraining):\r\n\t\t_, loss = sess.run([optimizer,network.loss], feed_dict={\r\n\t\t\t\t\t\tnetwork.inputs[0]:[data[permutationL[v],:]],\r\n\t\t\t\t\t\tnetwork.inputs[1]:[data[permutationR[v],:]],\r\n\t\t\t\t\t\tnetwork.target: target[v]})\r\n\t\ttotalLoss += loss\r\n\t\t\r\n\tif np.isnan(totalLoss):\r\n\t\tprint('Model diverged with loss = NaN')\r\n\t\tquit()\r\n\r\n\tif iter % 10 == 0:\r\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\r\n```\r\n\r\n\r\nimport toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Computer Vision\\Siamese Same-Different Network\\toyTestTraining.py\", line 35, in <module>\r\n    network.target: target[v]})\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 495, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 312, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 551, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 809, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"C:\\Users\\Christopher\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\debug\\lib\\debug_data.py\", line 985, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]\r\n\r\n\r\nThis error happens 100% of the time I run these commands.\r\nI apologize in advance if I'm overlooking something obvious. Thank you."}