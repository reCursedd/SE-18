{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316235210", "html_url": "https://github.com/tensorflow/tensorflow/issues/11416#issuecomment-316235210", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11416", "id": 316235210, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjIzNTIxMA==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-19T00:14:33Z", "updated_at": "2017-07-19T00:14:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1696340\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bobzhuyb\">@bobzhuyb</a> And I think I have checked with TF people before, and they have made it pretty clear that TF is not designed to utilize UVM nor support this feature. See relevant discussion in <a href=\"https://github.com/tensorflow/tensorflow/issues/3678#issuecomment-238064949\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3678/hovercard\">here</a>. I also tend to believe neither IB driver or CUDA driver should alter memory mappings managed by the other one, as we are not doing peer memory access for NIC and GPU.</p>\n<p>On the other hand I have worked with TF memory allocation subsystem and they are doing a pretty good job on keeping track of CUDA host/device memory allocation. See relevant details for <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc#L241\">host</a> and <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc#L113\">device</a> memory. And if you adjust those parameters (like the initial memory allocation or <code>allow_growth=False</code>), you could force it to allocate all CUDA memory at very early stage (before the whole distributed runtime is even initialized). After that, the virtual memory mappings of these memory regions should not be altered. If you do that, the step 2 of your speculation is rather unlikely to happen.</p>\n<p>Being said that, the is a possibility that something is wrong in either CUDA or IB driver, but our chances are small. cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a> any comments on this?</p>", "body_text": "@bobzhuyb And I think I have checked with TF people before, and they have made it pretty clear that TF is not designed to utilize UVM nor support this feature. See relevant discussion in here. I also tend to believe neither IB driver or CUDA driver should alter memory mappings managed by the other one, as we are not doing peer memory access for NIC and GPU.\nOn the other hand I have worked with TF memory allocation subsystem and they are doing a pretty good job on keeping track of CUDA host/device memory allocation. See relevant details for host and device memory. And if you adjust those parameters (like the initial memory allocation or allow_growth=False), you could force it to allocate all CUDA memory at very early stage (before the whole distributed runtime is even initialized). After that, the virtual memory mappings of these memory regions should not be altered. If you do that, the step 2 of your speculation is rather unlikely to happen.\nBeing said that, the is a possibility that something is wrong in either CUDA or IB driver, but our chances are small. cc @zheng-xq @poxvoculi any comments on this?", "body": "@bobzhuyb And I think I have checked with TF people before, and they have made it pretty clear that TF is not designed to utilize UVM nor support this feature. See relevant discussion in [here](https://github.com/tensorflow/tensorflow/issues/3678#issuecomment-238064949). I also tend to believe neither IB driver or CUDA driver should alter memory mappings managed by the other one, as we are not doing peer memory access for NIC and GPU.\r\n\r\nOn the other hand I have worked with TF memory allocation subsystem and they are doing a pretty good job on keeping track of CUDA host/device memory allocation. See relevant details for [host](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc#L241) and [device](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc#L113) memory. And if you adjust those parameters (like the initial memory allocation or `allow_growth=False`), you could force it to allocate all CUDA memory at very early stage (before the whole distributed runtime is even initialized). After that, the virtual memory mappings of these memory regions should not be altered. If you do that, the step 2 of your speculation is rather unlikely to happen.\r\n\r\nBeing said that, the is a possibility that something is wrong in either CUDA or IB driver, but our chances are small. cc @zheng-xq @poxvoculi any comments on this?"}