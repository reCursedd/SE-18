{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163122540", "pull_request_review_id": 90684940, "id": 163122540, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzEyMjU0MA==", "diff_hunk": "@@ -45,6 +45,42 @@ const char* const kXlaOutsideCompilationAttr = \"_XlaOutsideCompilation\";\n \n namespace {\n \n+// An node will not be processed by XLA even it has the XLA kernel:\n+// 1, In Tensorflow, conventionally, INT32 ops are regarded as shape or control ops, and\n+// are registered on CPU only. XLA should follow the same rule, to avoid the potential\n+// redundant memcopy in GPU_XLA case.\n+// 2, Any OpKernel with more than 500 inputs is excluded. This is a temp workaround to avoid an", "path": "tensorflow/compiler/jit/mark_for_compilation_pass.cc", "position": 8, "original_position": 8, "commit_id": "1014b797bdb3a036da8d011e86f99f347580f948", "original_commit_id": "1014b797bdb3a036da8d011e86f99f347580f948", "user": {"login": "hawkinsp", "id": 348932, "node_id": "MDQ6VXNlcjM0ODkzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/348932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hawkinsp", "html_url": "https://github.com/hawkinsp", "followers_url": "https://api.github.com/users/hawkinsp/followers", "following_url": "https://api.github.com/users/hawkinsp/following{/other_user}", "gists_url": "https://api.github.com/users/hawkinsp/gists{/gist_id}", "starred_url": "https://api.github.com/users/hawkinsp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hawkinsp/subscriptions", "organizations_url": "https://api.github.com/users/hawkinsp/orgs", "repos_url": "https://api.github.com/users/hawkinsp/repos", "events_url": "https://api.github.com/users/hawkinsp/events{/privacy}", "received_events_url": "https://api.github.com/users/hawkinsp/received_events", "type": "User", "site_admin": false}, "body": "I have no strong objection to this part.\r\n\r\nThat said it feels a bit like this is the wrong fix: whether or not the original TensorFlow operator has many inputs does not necessarily imply generated kernel has that many inputs, although I agree it is likely to lead to that for an operator such as a concatenation.\r\n\r\nPerhaps give a concrete example as to a situation where this arises? What would need to happen before we could declare this issue fixed and remove the special case again?\r\n\r\nAdded Justin as a reviewer to comment on this part.", "created_at": "2018-01-23T01:35:57Z", "updated_at": "2018-01-23T01:36:26Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16259#discussion_r163122540", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16259", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163122540"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16259#discussion_r163122540"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16259"}}, "body_html": "<p>I have no strong objection to this part.</p>\n<p>That said it feels a bit like this is the wrong fix: whether or not the original TensorFlow operator has many inputs does not necessarily imply generated kernel has that many inputs, although I agree it is likely to lead to that for an operator such as a concatenation.</p>\n<p>Perhaps give a concrete example as to a situation where this arises? What would need to happen before we could declare this issue fixed and remove the special case again?</p>\n<p>Added Justin as a reviewer to comment on this part.</p>", "body_text": "I have no strong objection to this part.\nThat said it feels a bit like this is the wrong fix: whether or not the original TensorFlow operator has many inputs does not necessarily imply generated kernel has that many inputs, although I agree it is likely to lead to that for an operator such as a concatenation.\nPerhaps give a concrete example as to a situation where this arises? What would need to happen before we could declare this issue fixed and remove the special case again?\nAdded Justin as a reviewer to comment on this part."}