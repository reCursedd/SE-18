{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425597445", "html_url": "https://github.com/tensorflow/tensorflow/issues/22551#issuecomment-425597445", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22551", "id": 425597445, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTU5NzQ0NQ==", "user": {"login": "meereeum", "id": 7970350, "node_id": "MDQ6VXNlcjc5NzAzNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/7970350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meereeum", "html_url": "https://github.com/meereeum", "followers_url": "https://api.github.com/users/meereeum/followers", "following_url": "https://api.github.com/users/meereeum/following{/other_user}", "gists_url": "https://api.github.com/users/meereeum/gists{/gist_id}", "starred_url": "https://api.github.com/users/meereeum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meereeum/subscriptions", "organizations_url": "https://api.github.com/users/meereeum/orgs", "repos_url": "https://api.github.com/users/meereeum/repos", "events_url": "https://api.github.com/users/meereeum/events{/privacy}", "received_events_url": "https://api.github.com/users/meereeum/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-29T00:01:38Z", "updated_at": "2018-09-29T00:05:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=233710\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/axch\">@axch</a> interesting, and great catch - thanks for the thorough response.<br>\nalso, I hadn't realized it was possible to generate 64-bit uniforms by modifying the default params.</p>\n<p>for posterity, the chance of having at least 1 collision with 10,000 samples &amp; 2^23 slots - as per default TF uniform sampling on [0,1) - is:</p>\n<pre><code>from scipy.special import gammaln\n\nlog_factorial = lambda x: gammaln(x+1)\nlogprob_unique = lambda n, k: log_factorial(n) - (k * np.log(n) + log_factorial(n-k))\n\n1 - np.exp(logprob_unique(2**23, 10**4)) # 0.997425855296802\n</code></pre>", "body_text": "@axch interesting, and great catch - thanks for the thorough response.\nalso, I hadn't realized it was possible to generate 64-bit uniforms by modifying the default params.\nfor posterity, the chance of having at least 1 collision with 10,000 samples & 2^23 slots - as per default TF uniform sampling on [0,1) - is:\nfrom scipy.special import gammaln\n\nlog_factorial = lambda x: gammaln(x+1)\nlogprob_unique = lambda n, k: log_factorial(n) - (k * np.log(n) + log_factorial(n-k))\n\n1 - np.exp(logprob_unique(2**23, 10**4)) # 0.997425855296802", "body": "@axch interesting, and great catch - thanks for the thorough response.\r\nalso, I hadn't realized it was possible to generate 64-bit uniforms by modifying the default params.\r\n\r\nfor posterity, the chance of having at least 1 collision with 10,000 samples & 2^23 slots - as per default TF uniform sampling on [0,1) - is:\r\n```\r\nfrom scipy.special import gammaln\r\n\r\nlog_factorial = lambda x: gammaln(x+1)\r\nlogprob_unique = lambda n, k: log_factorial(n) - (k * np.log(n) + log_factorial(n-k))\r\n\r\n1 - np.exp(logprob_unique(2**23, 10**4)) # 0.997425855296802\r\n```"}