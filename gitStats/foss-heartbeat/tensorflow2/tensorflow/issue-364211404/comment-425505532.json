{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425505532", "html_url": "https://github.com/tensorflow/tensorflow/issues/22551#issuecomment-425505532", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22551", "id": 425505532, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTUwNTUzMg==", "user": {"login": "axch", "id": 233710, "node_id": "MDQ6VXNlcjIzMzcxMA==", "avatar_url": "https://avatars3.githubusercontent.com/u/233710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/axch", "html_url": "https://github.com/axch", "followers_url": "https://api.github.com/users/axch/followers", "following_url": "https://api.github.com/users/axch/following{/other_user}", "gists_url": "https://api.github.com/users/axch/gists{/gist_id}", "starred_url": "https://api.github.com/users/axch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/axch/subscriptions", "organizations_url": "https://api.github.com/users/axch/orgs", "repos_url": "https://api.github.com/users/axch/repos", "events_url": "https://api.github.com/users/axch/events{/privacy}", "received_events_url": "https://api.github.com/users/axch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-28T17:16:39Z", "updated_at": "2018-09-28T17:16:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If uniqueness is important in your application, you could increase precision to 64 bits:</p>\n<pre><code>for _ in range(10):\n  print(len(np.unique(tf.distributions.Uniform(\n    low=np.float64(0.), high=np.float64(1.)).sample(N).eval())))\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n</code></pre>\n<p>or, of course, detect duplicates explicitly.</p>\n<p>If you really need a floating-point uniform distribution in TensorFlow with high precision near 0, please file a feature request for that.  It's likely to be enough slower to be a separate code path, and probably is a better fit for <a href=\"https://github.com/tensorflow/probability\">TensorFlow Probability</a> than for TensorFlow proper. Closing this issue as \"intended behavior\".</p>", "body_text": "If uniqueness is important in your application, you could increase precision to 64 bits:\nfor _ in range(10):\n  print(len(np.unique(tf.distributions.Uniform(\n    low=np.float64(0.), high=np.float64(1.)).sample(N).eval())))\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n10000\n\nor, of course, detect duplicates explicitly.\nIf you really need a floating-point uniform distribution in TensorFlow with high precision near 0, please file a feature request for that.  It's likely to be enough slower to be a separate code path, and probably is a better fit for TensorFlow Probability than for TensorFlow proper. Closing this issue as \"intended behavior\".", "body": "If uniqueness is important in your application, you could increase precision to 64 bits:\r\n```\r\nfor _ in range(10):\r\n  print(len(np.unique(tf.distributions.Uniform(\r\n    low=np.float64(0.), high=np.float64(1.)).sample(N).eval())))\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n10000\r\n```\r\nor, of course, detect duplicates explicitly.\r\n\r\nIf you really need a floating-point uniform distribution in TensorFlow with high precision near 0, please file a feature request for that.  It's likely to be enough slower to be a separate code path, and probably is a better fit for [TensorFlow Probability](https://github.com/tensorflow/probability) than for TensorFlow proper. Closing this issue as \"intended behavior\"."}