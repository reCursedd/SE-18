{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/380599426", "html_url": "https://github.com/tensorflow/tensorflow/issues/18323#issuecomment-380599426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18323", "id": 380599426, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDU5OTQyNg==", "user": {"login": "VanitarNordic", "id": 18719591, "node_id": "MDQ6VXNlcjE4NzE5NTkx", "avatar_url": "https://avatars0.githubusercontent.com/u/18719591?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VanitarNordic", "html_url": "https://github.com/VanitarNordic", "followers_url": "https://api.github.com/users/VanitarNordic/followers", "following_url": "https://api.github.com/users/VanitarNordic/following{/other_user}", "gists_url": "https://api.github.com/users/VanitarNordic/gists{/gist_id}", "starred_url": "https://api.github.com/users/VanitarNordic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VanitarNordic/subscriptions", "organizations_url": "https://api.github.com/users/VanitarNordic/orgs", "repos_url": "https://api.github.com/users/VanitarNordic/repos", "events_url": "https://api.github.com/users/VanitarNordic/events{/privacy}", "received_events_url": "https://api.github.com/users/VanitarNordic/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-11T21:20:47Z", "updated_at": "2018-04-11T21:26:34Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a></p>\n<p>I trained both LSTM and GRU, each 10 times in a loop. both for 5 epochs. everything is identical for both.</p>\n<p><strong>GRU:</strong></p>\n<p>All 10 runs handle the same results as below and all are identical:</p>\n<pre><code>Epoch 1/5\n - 2s - loss: 0.0085 - val_loss: 0.0011\nEpoch 2/5\n - 1s - loss: 0.0087 - val_loss: 1.4272e-04\nEpoch 3/5\n - 1s - loss: 0.0049 - val_loss: 5.7577e-05\nEpoch 4/5\n - 1s - loss: 0.0025 - val_loss: 7.7277e-04\nEpoch 5/5\n - 1s - loss: 0.0013 - val_loss: 0.0019\n</code></pre>\n<p><strong>LSTM:</strong></p>\n<p>Within 10 runs, sometimes it delivers the results like A and sometimes like B. it is something like a rotary switch that randomly goes to A or B.</p>\n<p>A:</p>\n<pre><code>Epoch 1/5\n - 2s - loss: 0.0146 - val_loss: 6.0151e-04\nEpoch 2/5\n - 1s - loss: 0.0111 - val_loss: 1.2672e-04\nEpoch 3/5\n - 1s - loss: 0.0071 - val_loss: 2.7325e-04\nEpoch 4/5\n - 1s - loss: 0.0041 - val_loss: 6.2337e-04\nEpoch 5/5\n - 1s - loss: 0.0021 - val_loss: 8.3224e-04  \n</code></pre>\n<p>B:</p>\n<pre><code>Epoch 1/5\n - 2s - loss: 0.0146 - val_loss: 6.0327e-04\nEpoch 2/5\n - 1s - loss: 0.0111 - val_loss: 1.2939e-04\nEpoch 3/5\n - 1s - loss: 0.0071 - val_loss: 2.7630e-04\nEpoch 4/5\n - 1s - loss: 0.0041 - val_loss: 6.2675e-04\nEpoch 5/5\n - 2s - loss: 0.0021 - val_loss: 8.3687e-04\n</code></pre>\n<blockquote>\n<p>Can you use tf.reset_default_graph() between iterations?</p>\n</blockquote>\n<p>I tried it. unfortunately it did not change the situation.</p>\n<blockquote>\n<p>Can you compare the graphdefs generated for each entry of the loop and ensure the ops are created in the same order?</p>\n</blockquote>\n<p>I could not get the point. Would you please explain it more?</p>", "body_text": "@ebrevdo\nI trained both LSTM and GRU, each 10 times in a loop. both for 5 epochs. everything is identical for both.\nGRU:\nAll 10 runs handle the same results as below and all are identical:\nEpoch 1/5\n - 2s - loss: 0.0085 - val_loss: 0.0011\nEpoch 2/5\n - 1s - loss: 0.0087 - val_loss: 1.4272e-04\nEpoch 3/5\n - 1s - loss: 0.0049 - val_loss: 5.7577e-05\nEpoch 4/5\n - 1s - loss: 0.0025 - val_loss: 7.7277e-04\nEpoch 5/5\n - 1s - loss: 0.0013 - val_loss: 0.0019\n\nLSTM:\nWithin 10 runs, sometimes it delivers the results like A and sometimes like B. it is something like a rotary switch that randomly goes to A or B.\nA:\nEpoch 1/5\n - 2s - loss: 0.0146 - val_loss: 6.0151e-04\nEpoch 2/5\n - 1s - loss: 0.0111 - val_loss: 1.2672e-04\nEpoch 3/5\n - 1s - loss: 0.0071 - val_loss: 2.7325e-04\nEpoch 4/5\n - 1s - loss: 0.0041 - val_loss: 6.2337e-04\nEpoch 5/5\n - 1s - loss: 0.0021 - val_loss: 8.3224e-04  \n\nB:\nEpoch 1/5\n - 2s - loss: 0.0146 - val_loss: 6.0327e-04\nEpoch 2/5\n - 1s - loss: 0.0111 - val_loss: 1.2939e-04\nEpoch 3/5\n - 1s - loss: 0.0071 - val_loss: 2.7630e-04\nEpoch 4/5\n - 1s - loss: 0.0041 - val_loss: 6.2675e-04\nEpoch 5/5\n - 2s - loss: 0.0021 - val_loss: 8.3687e-04\n\n\nCan you use tf.reset_default_graph() between iterations?\n\nI tried it. unfortunately it did not change the situation.\n\nCan you compare the graphdefs generated for each entry of the loop and ensure the ops are created in the same order?\n\nI could not get the point. Would you please explain it more?", "body": "@ebrevdo \r\n\r\nI trained both LSTM and GRU, each 10 times in a loop. both for 5 epochs. everything is identical for both.\r\n\r\n**GRU:**\r\n\r\nAll 10 runs handle the same results as below and all are identical:\r\n\r\n```\r\nEpoch 1/5\r\n - 2s - loss: 0.0085 - val_loss: 0.0011\r\nEpoch 2/5\r\n - 1s - loss: 0.0087 - val_loss: 1.4272e-04\r\nEpoch 3/5\r\n - 1s - loss: 0.0049 - val_loss: 5.7577e-05\r\nEpoch 4/5\r\n - 1s - loss: 0.0025 - val_loss: 7.7277e-04\r\nEpoch 5/5\r\n - 1s - loss: 0.0013 - val_loss: 0.0019\r\n```\r\n\r\n**LSTM:**\r\n\r\nWithin 10 runs, sometimes it delivers the results like A and sometimes like B. it is something like a rotary switch that randomly goes to A or B.\r\n\r\nA:\r\n```\r\nEpoch 1/5\r\n - 2s - loss: 0.0146 - val_loss: 6.0151e-04\r\nEpoch 2/5\r\n - 1s - loss: 0.0111 - val_loss: 1.2672e-04\r\nEpoch 3/5\r\n - 1s - loss: 0.0071 - val_loss: 2.7325e-04\r\nEpoch 4/5\r\n - 1s - loss: 0.0041 - val_loss: 6.2337e-04\r\nEpoch 5/5\r\n - 1s - loss: 0.0021 - val_loss: 8.3224e-04  \r\n```\r\n\r\nB:\r\n```\r\nEpoch 1/5\r\n - 2s - loss: 0.0146 - val_loss: 6.0327e-04\r\nEpoch 2/5\r\n - 1s - loss: 0.0111 - val_loss: 1.2939e-04\r\nEpoch 3/5\r\n - 1s - loss: 0.0071 - val_loss: 2.7630e-04\r\nEpoch 4/5\r\n - 1s - loss: 0.0041 - val_loss: 6.2675e-04\r\nEpoch 5/5\r\n - 2s - loss: 0.0021 - val_loss: 8.3687e-04\r\n```\r\n\r\n> Can you use tf.reset_default_graph() between iterations?\r\n\r\nI tried it. unfortunately it did not change the situation.\r\n\r\n> Can you compare the graphdefs generated for each entry of the loop and ensure the ops are created in the same order?\r\n\r\nI could not get the point. Would you please explain it more?"}