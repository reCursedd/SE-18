{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234005072", "html_url": "https://github.com/tensorflow/tensorflow/issues/3373#issuecomment-234005072", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3373", "id": 234005072, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDAwNTA3Mg==", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-20T16:33:49Z", "updated_at": "2016-07-20T16:42:44Z", "author_association": "NONE", "body_html": "<p><code>1350 * (1 &lt;&lt; 20)</code> (5.27GiB) works while <code>1360 * (1 &lt;&lt; 20)</code> (5.31GiB) does not. This confirms the cutoff is half of 10.57GiB mentioned by log (I'm assuming this the BFC allocator's memory pool size).</p>\n<p>A fix or at least a documented workaround for this bug (only being able to use 50% of GPU memory for a single variable) would be very nice.<br>\nUsing full GPU memory for data enables efficient batch gradient descent as well as work on very large single training examples (such as a 2 hour video) without getting bottlenecked by PCI-e transfer speeds.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> mentioned that variable initialization is a tf.Assign. Is it possible to do Assign across device boundaries (such as assigning a GPU variable lhs to a CPU tensor rhs)? This seems like it could take nearly identical code paths to whatever mechanism TF uses to move tensors between devices (in this case just a <code>cudaMemcpy</code>, no need for custom \"in-place initialization kernel\").</p>\n<p>I'm not familiar with how the code actually looks, but if there's a \"receive\" node directly feeding into an \"assign\" node, maybe the \"receive\"'s data pointer can be initialized with the array underlying the variable for \"assign\", and then the \"assign\" can become a no-op as the \"receive\" tensor and the variable's data are aliased?</p>", "body_text": "1350 * (1 << 20) (5.27GiB) works while 1360 * (1 << 20) (5.31GiB) does not. This confirms the cutoff is half of 10.57GiB mentioned by log (I'm assuming this the BFC allocator's memory pool size).\nA fix or at least a documented workaround for this bug (only being able to use 50% of GPU memory for a single variable) would be very nice.\nUsing full GPU memory for data enables efficient batch gradient descent as well as work on very large single training examples (such as a 2 hour video) without getting bottlenecked by PCI-e transfer speeds.\n@zheng-xq mentioned that variable initialization is a tf.Assign. Is it possible to do Assign across device boundaries (such as assigning a GPU variable lhs to a CPU tensor rhs)? This seems like it could take nearly identical code paths to whatever mechanism TF uses to move tensors between devices (in this case just a cudaMemcpy, no need for custom \"in-place initialization kernel\").\nI'm not familiar with how the code actually looks, but if there's a \"receive\" node directly feeding into an \"assign\" node, maybe the \"receive\"'s data pointer can be initialized with the array underlying the variable for \"assign\", and then the \"assign\" can become a no-op as the \"receive\" tensor and the variable's data are aliased?", "body": "`1350 * (1 << 20)` (5.27GiB) works while `1360 * (1 << 20)` (5.31GiB) does not. This confirms the cutoff is half of 10.57GiB mentioned by log (I'm assuming this the BFC allocator's memory pool size).\n\nA fix or at least a documented workaround for this bug (only being able to use 50% of GPU memory for a single variable) would be very nice. \nUsing full GPU memory for data enables efficient batch gradient descent as well as work on very large single training examples (such as a 2 hour video) without getting bottlenecked by PCI-e transfer speeds.\n\n@zheng-xq mentioned that variable initialization is a tf.Assign. Is it possible to do Assign across device boundaries (such as assigning a GPU variable lhs to a CPU tensor rhs)? This seems like it could take nearly identical code paths to whatever mechanism TF uses to move tensors between devices (in this case just a `cudaMemcpy`, no need for custom \"in-place initialization kernel\"). \n\nI'm not familiar with how the code actually looks, but if there's a \"receive\" node directly feeding into an \"assign\" node, maybe the \"receive\"'s data pointer can be initialized with the array underlying the variable for \"assign\", and then the \"assign\" can become a no-op as the \"receive\" tensor and the variable's data are aliased?\n"}