{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397440771", "html_url": "https://github.com/tensorflow/tensorflow/issues/20022#issuecomment-397440771", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20022", "id": 397440771, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzQ0MDc3MQ==", "user": {"login": "sebamlu", "id": 39166555, "node_id": "MDQ6VXNlcjM5MTY2NTU1", "avatar_url": "https://avatars2.githubusercontent.com/u/39166555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sebamlu", "html_url": "https://github.com/sebamlu", "followers_url": "https://api.github.com/users/sebamlu/followers", "following_url": "https://api.github.com/users/sebamlu/following{/other_user}", "gists_url": "https://api.github.com/users/sebamlu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sebamlu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sebamlu/subscriptions", "organizations_url": "https://api.github.com/users/sebamlu/orgs", "repos_url": "https://api.github.com/users/sebamlu/repos", "events_url": "https://api.github.com/users/sebamlu/events{/privacy}", "received_events_url": "https://api.github.com/users/sebamlu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-14T21:15:25Z", "updated_at": "2018-06-14T21:17:11Z", "author_association": "NONE", "body_html": "<p>Sure, I'm using TFRecordDataset instead of tf.contrib.data.make_csv_dataset, but should make no difference.</p>\n<pre><code>    with tf.variable_scope('feeding_data'):\n        train_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*train*.tfrecord'))\n        train_set = train_set.repeat(epochs)\n        train_set = train_set.shuffle(1000)\n        train_set = train_set.map(decode_data, num_parallel_calls=num_map_threads)\n        train_set = train_set.batch(batch_size)\n\n        test_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*test*.tfrecord'))\n        test_set = test_set.shuffle(buffer_size=1000)  # Enables stochastic batch validation\n        test_set = test_set.map(decode_data, num_parallel_calls=num_map_threads)\n        test_set = test_set.batch(batch_size)\n\n        training_iterator = train_set.make_one_shot_iterator()\n        validation_iterator = test_set.make_initializable_iterator()  \n\n    model = BaseCnnModel(num_classes=n_classes)\n    model.compile(\n        optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9),\n        loss='categorical_crossentropy',\n        metrics=['accuracy'],\n    )\n\n    model.fit(\n        x=training_iterator,\n        validation_data=validation_iterator,\n        steps_per_epoch=40,\n        epochs=epochs,\n        validation_steps=2,\n    )\n\n</code></pre>\n<p>and the model</p>\n<blockquote>\n<p>class BaseCnnModel(keras.Model):</p>\n<pre><code>def __init__(self, num_classes, dropout_rate=0.5):\n    super(BaseCnnModel, self).__init__(name='bcnn')\n\n    self.cnn1 = keras.layers.Conv2D(12, 3, activation=tf.nn.relu)\n    self.maxp1 = keras.layers.MaxPooling2D((2, 2))\n    self.cnn2 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\n    self.maxpl2 = keras.layers.MaxPooling2D((2, 2))\n    self.cnn3 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\n    self.maxpl3 = keras.layers.MaxPooling2D((2, 2))\n    self.flat = keras.layers.Flatten()\n    self.dense1 = keras.layers.Dense(512, activation=tf.nn.relu)\n    self.drop1 = keras.layers.Dropout(dropout_rate)\n    self.dense2 = keras.layers.Dense(num_classes, activation=None)\n\ndef call(self, inputs):\n    x = self.cnn1(inputs)\n    x = self.maxp1(x)\n    x = self.cnn2(x)\n    x = self.maxpl2(x)\n    x = self.cnn3(x)\n    x = self.maxpl3(x)\n    x = self.flat(x)\n    x = self.dense1(x)\n    x = self.drop1(x) # I assume that keras makes this work properly on evaluation..\n    return self.dense2(x)\n</code></pre>\n</blockquote>\n<p>As you can see i never defined an input shape for the model</p>", "body_text": "Sure, I'm using TFRecordDataset instead of tf.contrib.data.make_csv_dataset, but should make no difference.\n    with tf.variable_scope('feeding_data'):\n        train_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*train*.tfrecord'))\n        train_set = train_set.repeat(epochs)\n        train_set = train_set.shuffle(1000)\n        train_set = train_set.map(decode_data, num_parallel_calls=num_map_threads)\n        train_set = train_set.batch(batch_size)\n\n        test_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*test*.tfrecord'))\n        test_set = test_set.shuffle(buffer_size=1000)  # Enables stochastic batch validation\n        test_set = test_set.map(decode_data, num_parallel_calls=num_map_threads)\n        test_set = test_set.batch(batch_size)\n\n        training_iterator = train_set.make_one_shot_iterator()\n        validation_iterator = test_set.make_initializable_iterator()  \n\n    model = BaseCnnModel(num_classes=n_classes)\n    model.compile(\n        optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9),\n        loss='categorical_crossentropy',\n        metrics=['accuracy'],\n    )\n\n    model.fit(\n        x=training_iterator,\n        validation_data=validation_iterator,\n        steps_per_epoch=40,\n        epochs=epochs,\n        validation_steps=2,\n    )\n\n\nand the model\n\nclass BaseCnnModel(keras.Model):\ndef __init__(self, num_classes, dropout_rate=0.5):\n    super(BaseCnnModel, self).__init__(name='bcnn')\n\n    self.cnn1 = keras.layers.Conv2D(12, 3, activation=tf.nn.relu)\n    self.maxp1 = keras.layers.MaxPooling2D((2, 2))\n    self.cnn2 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\n    self.maxpl2 = keras.layers.MaxPooling2D((2, 2))\n    self.cnn3 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\n    self.maxpl3 = keras.layers.MaxPooling2D((2, 2))\n    self.flat = keras.layers.Flatten()\n    self.dense1 = keras.layers.Dense(512, activation=tf.nn.relu)\n    self.drop1 = keras.layers.Dropout(dropout_rate)\n    self.dense2 = keras.layers.Dense(num_classes, activation=None)\n\ndef call(self, inputs):\n    x = self.cnn1(inputs)\n    x = self.maxp1(x)\n    x = self.cnn2(x)\n    x = self.maxpl2(x)\n    x = self.cnn3(x)\n    x = self.maxpl3(x)\n    x = self.flat(x)\n    x = self.dense1(x)\n    x = self.drop1(x) # I assume that keras makes this work properly on evaluation..\n    return self.dense2(x)\n\n\nAs you can see i never defined an input shape for the model", "body": "Sure, I'm using TFRecordDataset instead of tf.contrib.data.make_csv_dataset, but should make no difference.\r\n\r\n\r\n```\r\n    with tf.variable_scope('feeding_data'):\r\n        train_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*train*.tfrecord'))\r\n        train_set = train_set.repeat(epochs)\r\n        train_set = train_set.shuffle(1000)\r\n        train_set = train_set.map(decode_data, num_parallel_calls=num_map_threads)\r\n        train_set = train_set.batch(batch_size)\r\n\r\n        test_set = tf.data.TFRecordDataset(glob(DATA_DIR + '/*test*.tfrecord'))\r\n        test_set = test_set.shuffle(buffer_size=1000)  # Enables stochastic batch validation\r\n        test_set = test_set.map(decode_data, num_parallel_calls=num_map_threads)\r\n        test_set = test_set.batch(batch_size)\r\n\r\n        training_iterator = train_set.make_one_shot_iterator()\r\n        validation_iterator = test_set.make_initializable_iterator()  \r\n\r\n    model = BaseCnnModel(num_classes=n_classes)\r\n    model.compile(\r\n        optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9),\r\n        loss='categorical_crossentropy',\r\n        metrics=['accuracy'],\r\n    )\r\n\r\n    model.fit(\r\n        x=training_iterator,\r\n        validation_data=validation_iterator,\r\n        steps_per_epoch=40,\r\n        epochs=epochs,\r\n        validation_steps=2,\r\n    )\r\n\r\n```\r\n\r\nand the model\r\n\r\n> class BaseCnnModel(keras.Model):\r\n> \r\n>     def __init__(self, num_classes, dropout_rate=0.5):\r\n>         super(BaseCnnModel, self).__init__(name='bcnn')\r\n> \r\n>         self.cnn1 = keras.layers.Conv2D(12, 3, activation=tf.nn.relu)\r\n>         self.maxp1 = keras.layers.MaxPooling2D((2, 2))\r\n>         self.cnn2 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\r\n>         self.maxpl2 = keras.layers.MaxPooling2D((2, 2))\r\n>         self.cnn3 = keras.layers.Conv2D(16, 3, activation=tf.nn.relu)\r\n>         self.maxpl3 = keras.layers.MaxPooling2D((2, 2))\r\n>         self.flat = keras.layers.Flatten()\r\n>         self.dense1 = keras.layers.Dense(512, activation=tf.nn.relu)\r\n>         self.drop1 = keras.layers.Dropout(dropout_rate)\r\n>         self.dense2 = keras.layers.Dense(num_classes, activation=None)\r\n> \r\n>     def call(self, inputs):\r\n>         x = self.cnn1(inputs)\r\n>         x = self.maxp1(x)\r\n>         x = self.cnn2(x)\r\n>         x = self.maxpl2(x)\r\n>         x = self.cnn3(x)\r\n>         x = self.maxpl3(x)\r\n>         x = self.flat(x)\r\n>         x = self.dense1(x)\r\n>         x = self.drop1(x) # I assume that keras makes this work properly on evaluation..\r\n>         return self.dense2(x)\r\n> \r\n\r\n\r\nAs you can see i never defined an input shape for the model\r\n"}