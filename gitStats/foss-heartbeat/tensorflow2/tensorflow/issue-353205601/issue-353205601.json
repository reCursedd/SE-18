{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21817", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21817/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21817/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21817/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21817", "id": 353205601, "node_id": "MDU6SXNzdWUzNTMyMDU2MDE=", "number": 21817, "title": "tflite conv bug", "user": {"login": "zgxnet", "id": 9656617, "node_id": "MDQ6VXNlcjk2NTY2MTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/9656617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zgxnet", "html_url": "https://github.com/zgxnet", "followers_url": "https://api.github.com/users/zgxnet/followers", "following_url": "https://api.github.com/users/zgxnet/following{/other_user}", "gists_url": "https://api.github.com/users/zgxnet/gists{/gist_id}", "starred_url": "https://api.github.com/users/zgxnet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zgxnet/subscriptions", "organizations_url": "https://api.github.com/users/zgxnet/orgs", "repos_url": "https://api.github.com/users/zgxnet/repos", "events_url": "https://api.github.com/users/zgxnet/events{/privacy}", "received_events_url": "https://api.github.com/users/zgxnet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-08-23T03:14:20Z", "updated_at": "2018-09-12T15:52:12Z", "closed_at": "2018-09-12T15:52:12Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:N/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.10.0</li>\n<li><strong>Python version</strong>:3.6.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:7.3.0</li>\n<li><strong>CUDA/cuDNN version</strong>:N/A</li>\n<li><strong>GPU model and memory</strong>:N/A</li>\n<li><strong>Exact command to reproduce</strong>:N/A</li>\n</ul>\n<p>There is a bug in the multithreaded implementation of conv2d.  In certain cases when batch_size &gt; 1, only the first image are considered while others ignored. For the reason see file contrib/lite/kernels/internal/optimized/multithreaded_conv.h</p>\n<div class=\"highlight highlight-source-c++\"><pre> } <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span> (filter_height == input_height &amp;&amp; filter_width == input_width &amp;&amp;\n               pad_width == <span class=\"pl-c1\">0</span> &amp;&amp; pad_height == <span class=\"pl-c1\">0</span>) {\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> If the input data and filter have the same height/width,</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> the 2D convolution is reduced to matrix multiplication.</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> k =  <span class=\"pl-c\"><span class=\"pl-c\">//</span> Length of reduction dimension.</span>\n          filter_width * filter_height * input_depth;\n      Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, <span class=\"pl-c1\">1</span>&gt; dim_pair;\n      dim_pair[<span class=\"pl-c1\">0</span>] = Eigen::IndexPair&lt;Eigen::DenseIndex&gt;(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>);\n      EigenMatrix <span class=\"pl-smi\">output</span>(output_data, <span class=\"pl-c1\">1</span>, filter_count);\n      ConstEigenMatrix <span class=\"pl-smi\">input</span>(input_data, <span class=\"pl-c1\">1</span>, k);\n      ConstEigenMatrix <span class=\"pl-smi\">filter</span>(filter_data, k, filter_count);\n      MatMulConvFunctor&lt;Eigen::ThreadPoolDevice, T&gt;()(device, output, input,\n                                                      filter, dim_pair);\n    } <span class=\"pl-k\">else</span> {</pre></div>\n<p>In the above code, the input_batches are ignored.<br>\nI have also verified a quick fix:</p>\n<div class=\"highlight highlight-source-c++\"><pre>    } <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span> (filter_height == input_height &amp;&amp; filter_width == input_width &amp;&amp;\n               pad_width == <span class=\"pl-c1\">0</span> &amp;&amp; pad_height == <span class=\"pl-c1\">0</span>) {\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> If the input data and filter have the same height/width,</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> the 2D convolution is reduced to matrix multiplication.</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> k =  <span class=\"pl-c\"><span class=\"pl-c\">//</span> Length of reduction dimension.</span>\n          filter_width * filter_height * input_depth;\n\t  Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, <span class=\"pl-c1\">1</span>&gt; dim_pair;\n      dim_pair[<span class=\"pl-c1\">0</span>] = Eigen::IndexPair&lt;Eigen::DenseIndex&gt;(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>);\n      EigenMatrix <span class=\"pl-smi\">output</span>(output_data, input_batches, filter_count);\n      ConstEigenMatrix <span class=\"pl-smi\">input</span>(input_data, input_batches, k);\n      ConstEigenMatrix <span class=\"pl-smi\">filter</span>(filter_data, k, filter_count);\n      MatMulConvFunctor&lt;Eigen::ThreadPoolDevice, T&gt;()(device, output, input,\n\t\t  filter, dim_pair);\n    } <span class=\"pl-k\">else</span> {</pre></div>\n<p>Just change 1 to input_batches.<br>\nMy code works well based on my experiments.<br>\nIt is a simple and quick fix, please merge it into the master if possible.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):N/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below):1.10.0\nPython version:3.6.0\nBazel version (if compiling from source):0.16.1\nGCC/Compiler version (if compiling from source):7.3.0\nCUDA/cuDNN version:N/A\nGPU model and memory:N/A\nExact command to reproduce:N/A\n\nThere is a bug in the multithreaded implementation of conv2d.  In certain cases when batch_size > 1, only the first image are considered while others ignored. For the reason see file contrib/lite/kernels/internal/optimized/multithreaded_conv.h\n } else if (filter_height == input_height && filter_width == input_width &&\n               pad_width == 0 && pad_height == 0) {\n      // If the input data and filter have the same height/width,\n      // the 2D convolution is reduced to matrix multiplication.\n      const int k =  // Length of reduction dimension.\n          filter_width * filter_height * input_depth;\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 0);\n      EigenMatrix output(output_data, 1, filter_count);\n      ConstEigenMatrix input(input_data, 1, k);\n      ConstEigenMatrix filter(filter_data, k, filter_count);\n      MatMulConvFunctor<Eigen::ThreadPoolDevice, T>()(device, output, input,\n                                                      filter, dim_pair);\n    } else {\nIn the above code, the input_batches are ignored.\nI have also verified a quick fix:\n    } else if (filter_height == input_height && filter_width == input_width &&\n               pad_width == 0 && pad_height == 0) {\n      // If the input data and filter have the same height/width,\n      // the 2D convolution is reduced to matrix multiplication.\n      const int k =  // Length of reduction dimension.\n          filter_width * filter_height * input_depth;\n\t  Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 0);\n      EigenMatrix output(output_data, input_batches, filter_count);\n      ConstEigenMatrix input(input_data, input_batches, k);\n      ConstEigenMatrix filter(filter_data, k, filter_count);\n      MatMulConvFunctor<Eigen::ThreadPoolDevice, T>()(device, output, input,\n\t\t  filter, dim_pair);\n    } else {\nJust change 1 to input_batches.\nMy code works well based on my experiments.\nIt is a simple and quick fix, please merge it into the master if possible.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:N/A\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.10.0\r\n- **Python version**:3.6.0\r\n- **Bazel version (if compiling from source)**:0.16.1\r\n- **GCC/Compiler version (if compiling from source)**:7.3.0\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:N/A\r\n\r\nThere is a bug in the multithreaded implementation of conv2d.  In certain cases when batch_size > 1, only the first image are considered while others ignored. For the reason see file contrib/lite/kernels/internal/optimized/multithreaded_conv.h\r\n```C++\r\n } else if (filter_height == input_height && filter_width == input_width &&\r\n               pad_width == 0 && pad_height == 0) {\r\n      // If the input data and filter have the same height/width,\r\n      // the 2D convolution is reduced to matrix multiplication.\r\n      const int k =  // Length of reduction dimension.\r\n          filter_width * filter_height * input_depth;\r\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\r\n      dim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 0);\r\n      EigenMatrix output(output_data, 1, filter_count);\r\n      ConstEigenMatrix input(input_data, 1, k);\r\n      ConstEigenMatrix filter(filter_data, k, filter_count);\r\n      MatMulConvFunctor<Eigen::ThreadPoolDevice, T>()(device, output, input,\r\n                                                      filter, dim_pair);\r\n    } else {\r\n```\r\nIn the above code, the input_batches are ignored.\r\nI have also verified a quick fix:\r\n```C++\r\n    } else if (filter_height == input_height && filter_width == input_width &&\r\n               pad_width == 0 && pad_height == 0) {\r\n      // If the input data and filter have the same height/width,\r\n      // the 2D convolution is reduced to matrix multiplication.\r\n      const int k =  // Length of reduction dimension.\r\n          filter_width * filter_height * input_depth;\r\n\t  Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\r\n      dim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 0);\r\n      EigenMatrix output(output_data, input_batches, filter_count);\r\n      ConstEigenMatrix input(input_data, input_batches, k);\r\n      ConstEigenMatrix filter(filter_data, k, filter_count);\r\n      MatMulConvFunctor<Eigen::ThreadPoolDevice, T>()(device, output, input,\r\n\t\t  filter, dim_pair);\r\n    } else {\r\n```\r\nJust change 1 to input_batches.\r\nMy code works well based on my experiments.\r\nIt is a simple and quick fix, please merge it into the master if possible.\r\n"}