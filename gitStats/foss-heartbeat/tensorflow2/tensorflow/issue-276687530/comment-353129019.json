{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/353129019", "html_url": "https://github.com/tensorflow/tensorflow/issues/14868#issuecomment-353129019", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868", "id": 353129019, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzEyOTAxOQ==", "user": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-20T17:29:10Z", "updated_at": "2017-12-20T17:29:10Z", "author_association": "MEMBER", "body_html": "<p>Creating an iterator in a loop (every epoch) will keep adding nodes to the graph, so the slowdown you are seeing is expected. I am not aware of any use case where creating an iterator in a loop would be the right thing to do.</p>\n<p>What is the reason you do not want to create a batch using data from different epochs? In any case, you can always do dataset.shuffle().batch().repeat() instead of dataset.shuffle().repeat().batch() in case you would prefer to have the last batch of each epoch to be possibly smaller (in the case the batch size does not divide the size of the epoch, which seems to be your case).</p>", "body_text": "Creating an iterator in a loop (every epoch) will keep adding nodes to the graph, so the slowdown you are seeing is expected. I am not aware of any use case where creating an iterator in a loop would be the right thing to do.\nWhat is the reason you do not want to create a batch using data from different epochs? In any case, you can always do dataset.shuffle().batch().repeat() instead of dataset.shuffle().repeat().batch() in case you would prefer to have the last batch of each epoch to be possibly smaller (in the case the batch size does not divide the size of the epoch, which seems to be your case).", "body": "Creating an iterator in a loop (every epoch) will keep adding nodes to the graph, so the slowdown you are seeing is expected. I am not aware of any use case where creating an iterator in a loop would be the right thing to do.\r\n\r\nWhat is the reason you do not want to create a batch using data from different epochs? In any case, you can always do dataset.shuffle().batch().repeat() instead of dataset.shuffle().repeat().batch() in case you would prefer to have the last batch of each epoch to be possibly smaller (in the case the batch size does not divide the size of the epoch, which seems to be your case)."}