{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/435440663", "html_url": "https://github.com/tensorflow/tensorflow/issues/14868#issuecomment-435440663", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868", "id": 435440663, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTQ0MDY2Mw==", "user": {"login": "Nithanaroy", "id": 670556, "node_id": "MDQ6VXNlcjY3MDU1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/670556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nithanaroy", "html_url": "https://github.com/Nithanaroy", "followers_url": "https://api.github.com/users/Nithanaroy/followers", "following_url": "https://api.github.com/users/Nithanaroy/following{/other_user}", "gists_url": "https://api.github.com/users/Nithanaroy/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nithanaroy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nithanaroy/subscriptions", "organizations_url": "https://api.github.com/users/Nithanaroy/orgs", "repos_url": "https://api.github.com/users/Nithanaroy/repos", "events_url": "https://api.github.com/users/Nithanaroy/events{/privacy}", "received_events_url": "https://api.github.com/users/Nithanaroy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-02T16:44:25Z", "updated_at": "2018-11-02T16:44:25Z", "author_association": "NONE", "body_html": "<p>I see a similar slow down though I dont add new nodes to the graph,</p>\n<div class=\"highlight highlight-source-python\"><pre>    dataset <span class=\"pl-k\">=</span> tf.data.TFRecordDataset(data_files, <span class=\"pl-v\">num_parallel_reads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">79</span>)\n\n<span class=\"pl-k\">if</span> is_training:\n    dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.shuffle_and_repeat(<span class=\"pl-c1\">1743</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">42</span>))\n\ndataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.map_and_batch(decode, <span class=\"pl-c1\">128</span>,\n                                                        <span class=\"pl-v\">num_parallel_batches</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">58</span>,\n                                                        <span class=\"pl-v\">drop_remainder</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n                        )\ndataset <span class=\"pl-k\">=</span> dataset.prefetch(<span class=\"pl-c1\">1064</span>)</pre></div>\n<p>and fit a tf.keras model like so,</p>\n<div class=\"highlight highlight-source-python\"><pre>model.fit(\n    dataset.make_one_shot_iterator(),\n    <span class=\"pl-v\">steps_per_epoch</span><span class=\"pl-k\">=</span>model_meta.train_records <span class=\"pl-k\">//</span> <span class=\"pl-c1\">128</span>,\n    <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,\n    <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>test_dataset.make_one_shot_iterator(),\n    <span class=\"pl-v\">validation_steps</span><span class=\"pl-k\">=</span>test_records <span class=\"pl-k\">//</span> <span class=\"pl-c1\">128</span>,\n    <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\n)</pre></div>\n<p>I'm using for a 1 GPU 7GB RAM training. What am I missing?</p>", "body_text": "I see a similar slow down though I dont add new nodes to the graph,\n    dataset = tf.data.TFRecordDataset(data_files, num_parallel_reads=79)\n\nif is_training:\n    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(1743, -1, 42))\n\ndataset = dataset.apply(tf.contrib.data.map_and_batch(decode, 128,\n                                                        num_parallel_batches=58,\n                                                        drop_remainder=False)\n                        )\ndataset = dataset.prefetch(1064)\nand fit a tf.keras model like so,\nmodel.fit(\n    dataset.make_one_shot_iterator(),\n    steps_per_epoch=model_meta.train_records // 128,\n    epochs=2,\n    validation_data=test_dataset.make_one_shot_iterator(),\n    validation_steps=test_records // 128,\n    verbose=0\n)\nI'm using for a 1 GPU 7GB RAM training. What am I missing?", "body": "I see a similar slow down though I dont add new nodes to the graph,\r\n\r\n```python\r\n    dataset = tf.data.TFRecordDataset(data_files, num_parallel_reads=79)\r\n\r\nif is_training:\r\n    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(1743, -1, 42))\r\n\r\ndataset = dataset.apply(tf.contrib.data.map_and_batch(decode, 128,\r\n                                                        num_parallel_batches=58,\r\n                                                        drop_remainder=False)\r\n                        )\r\ndataset = dataset.prefetch(1064)\r\n```\r\nand fit a tf.keras model like so,\r\n```python\r\nmodel.fit(\r\n    dataset.make_one_shot_iterator(),\r\n    steps_per_epoch=model_meta.train_records // 128,\r\n    epochs=2,\r\n    validation_data=test_dataset.make_one_shot_iterator(),\r\n    validation_steps=test_records // 128,\r\n    verbose=0\r\n)\r\n```\r\nI'm using for a 1 GPU 7GB RAM training. What am I missing?\r\n"}