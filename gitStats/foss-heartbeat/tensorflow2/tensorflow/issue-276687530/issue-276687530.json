{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14868/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14868", "id": 276687530, "node_id": "MDU6SXNzdWUyNzY2ODc1MzA=", "number": 14868, "title": "consuming Dataset becomes slower and slower, if make_one_shot_iterator each epoch ", "user": {"login": "qixiang109", "id": 19428642, "node_id": "MDQ6VXNlcjE5NDI4NjQy", "avatar_url": "https://avatars3.githubusercontent.com/u/19428642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qixiang109", "html_url": "https://github.com/qixiang109", "followers_url": "https://api.github.com/users/qixiang109/followers", "following_url": "https://api.github.com/users/qixiang109/following{/other_user}", "gists_url": "https://api.github.com/users/qixiang109/gists{/gist_id}", "starred_url": "https://api.github.com/users/qixiang109/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qixiang109/subscriptions", "organizations_url": "https://api.github.com/users/qixiang109/orgs", "repos_url": "https://api.github.com/users/qixiang109/repos", "events_url": "https://api.github.com/users/qixiang109/events{/privacy}", "received_events_url": "https://api.github.com/users/qixiang109/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2017-11-24T19:27:25Z", "updated_at": "2018-11-02T18:13:01Z", "closed_at": "2018-01-05T18:02:00Z", "author_association": "NONE", "body_html": "<h3>Problem</h3>\n<p>I run make_one_shot_iterator() each epoch because  I want re-shuffle the dataset each epoch. I Know that the dataset.shuffle().repeat().batch() pipeline can do almost the same thing, but when data_num can not be divided exactly by batch_size, the pipeline merges two epochs at their boundary to construct a complete batch,  which I HATE.</p>\n<p>So, I choose to run dataset.shuffle().batch() and make_one_shot_iterator() before each epoch. But I find that the speed of consuming dataset becomes slower and slower, significantly. I tried different settings to find out that it is make_one_shot_iterator() which makes consuming slow.</p>\n<p>By the way, I build tensorflow 1.4 from source on OS X with support of GPU, some hacky workaround.</p>\n<h3>Code</h3>\n<pre><code>num_data = 1000\nnum_epoch = 50\nbatch_size = 32\ndataset = tf.data.Dataset.range(num_data)\n\nmode=3 \n# model = 1,2,or 3\n# 1: re-shuffle, re-batch and re-make-iterator each epoch\n# 2: re-batch and re-make-iterator\n# 3: only re-make-iterator\n\nwith tf.Session() as sess:\n    for epoch in xrange(num_epoch):\n        t1 = time.time()\n        if mode==1: \n            _dataset = dataset.shuffle(num_data).batch(batch_size)\n            iterator = _dataset.make_one_shot_iterator()\n        elif mode==2:\n            _dataset = dataset.batch(batch_size)\n            iterator = _dataset.make_one_shot_iterator()\n        elif mode==3: \n            iterator = dataset.make_one_shot_iterator()\n        t2 = time.time()\n        for i in xrange(num_data/batch_size):\n            a = sess.run(iterator.get_next())\n        t3 =time.time()\n        print 'epoch %d make_iterator_time %.4f comsuming_time %.4f'%(epoch,t2-t1,t3-t2)\n</code></pre>\n<p>and the outputs:</p>\n<pre><code>epoch 0 make_iterator_time 0.0181 comsuming_time 0.1366\nepoch 1 make_iterator_time 0.0036 comsuming_time 0.1444\nepoch 2 make_iterator_time 0.0040 comsuming_time 0.1559\nepoch 3 make_iterator_time 0.0036 comsuming_time 0.1695\nepoch 4 make_iterator_time 0.0036 comsuming_time 0.1899\nepoch 5 make_iterator_time 0.0036 comsuming_time 0.1955\nepoch 6 make_iterator_time 0.0036 comsuming_time 0.2082\nepoch 7 make_iterator_time 0.0037 comsuming_time 0.2191\nepoch 8 make_iterator_time 0.0036 comsuming_time 0.2334\nepoch 9 make_iterator_time 0.0040 comsuming_time 0.2461\nepoch 10 make_iterator_time 0.0036 comsuming_time 0.2621\nepoch 11 make_iterator_time 0.0036 comsuming_time 0.2720\nepoch 12 make_iterator_time 0.0036 comsuming_time 0.2886\nepoch 13 make_iterator_time 0.0036 comsuming_time 0.3006\nepoch 14 make_iterator_time 0.0037 comsuming_time 0.3134\nepoch 15 make_iterator_time 0.0039 comsuming_time 0.3260\nepoch 16 make_iterator_time 0.0445 comsuming_time 0.3438\nepoch 17 make_iterator_time 0.0037 comsuming_time 0.3576\nepoch 18 make_iterator_time 0.0037 comsuming_time 0.3678\nepoch 19 make_iterator_time 0.0040 comsuming_time 0.3827\nepoch 20 make_iterator_time 0.0037 comsuming_time 0.3937\nepoch 21 make_iterator_time 0.0038 comsuming_time 0.4172\nepoch 22 make_iterator_time 0.0036 comsuming_time 0.4222\n...\n</code></pre>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: OS X 10.12.5</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4</li>\n<li><strong>Python version</strong>:  2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.7.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: clang-802.0.42</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7</li>\n<li><strong>GPU model and memory</strong>: GTX1080 8G</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>", "body_text": "Problem\nI run make_one_shot_iterator() each epoch because  I want re-shuffle the dataset each epoch. I Know that the dataset.shuffle().repeat().batch() pipeline can do almost the same thing, but when data_num can not be divided exactly by batch_size, the pipeline merges two epochs at their boundary to construct a complete batch,  which I HATE.\nSo, I choose to run dataset.shuffle().batch() and make_one_shot_iterator() before each epoch. But I find that the speed of consuming dataset becomes slower and slower, significantly. I tried different settings to find out that it is make_one_shot_iterator() which makes consuming slow.\nBy the way, I build tensorflow 1.4 from source on OS X with support of GPU, some hacky workaround.\nCode\nnum_data = 1000\nnum_epoch = 50\nbatch_size = 32\ndataset = tf.data.Dataset.range(num_data)\n\nmode=3 \n# model = 1,2,or 3\n# 1: re-shuffle, re-batch and re-make-iterator each epoch\n# 2: re-batch and re-make-iterator\n# 3: only re-make-iterator\n\nwith tf.Session() as sess:\n    for epoch in xrange(num_epoch):\n        t1 = time.time()\n        if mode==1: \n            _dataset = dataset.shuffle(num_data).batch(batch_size)\n            iterator = _dataset.make_one_shot_iterator()\n        elif mode==2:\n            _dataset = dataset.batch(batch_size)\n            iterator = _dataset.make_one_shot_iterator()\n        elif mode==3: \n            iterator = dataset.make_one_shot_iterator()\n        t2 = time.time()\n        for i in xrange(num_data/batch_size):\n            a = sess.run(iterator.get_next())\n        t3 =time.time()\n        print 'epoch %d make_iterator_time %.4f comsuming_time %.4f'%(epoch,t2-t1,t3-t2)\n\nand the outputs:\nepoch 0 make_iterator_time 0.0181 comsuming_time 0.1366\nepoch 1 make_iterator_time 0.0036 comsuming_time 0.1444\nepoch 2 make_iterator_time 0.0040 comsuming_time 0.1559\nepoch 3 make_iterator_time 0.0036 comsuming_time 0.1695\nepoch 4 make_iterator_time 0.0036 comsuming_time 0.1899\nepoch 5 make_iterator_time 0.0036 comsuming_time 0.1955\nepoch 6 make_iterator_time 0.0036 comsuming_time 0.2082\nepoch 7 make_iterator_time 0.0037 comsuming_time 0.2191\nepoch 8 make_iterator_time 0.0036 comsuming_time 0.2334\nepoch 9 make_iterator_time 0.0040 comsuming_time 0.2461\nepoch 10 make_iterator_time 0.0036 comsuming_time 0.2621\nepoch 11 make_iterator_time 0.0036 comsuming_time 0.2720\nepoch 12 make_iterator_time 0.0036 comsuming_time 0.2886\nepoch 13 make_iterator_time 0.0036 comsuming_time 0.3006\nepoch 14 make_iterator_time 0.0037 comsuming_time 0.3134\nepoch 15 make_iterator_time 0.0039 comsuming_time 0.3260\nepoch 16 make_iterator_time 0.0445 comsuming_time 0.3438\nepoch 17 make_iterator_time 0.0037 comsuming_time 0.3576\nepoch 18 make_iterator_time 0.0037 comsuming_time 0.3678\nepoch 19 make_iterator_time 0.0040 comsuming_time 0.3827\nepoch 20 make_iterator_time 0.0037 comsuming_time 0.3937\nepoch 21 make_iterator_time 0.0038 comsuming_time 0.4172\nepoch 22 make_iterator_time 0.0036 comsuming_time 0.4222\n...\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS X 10.12.5\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.4\nPython version:  2.7\nBazel version (if compiling from source): 0.7.0\nGCC/Compiler version (if compiling from source): clang-802.0.42\nCUDA/cuDNN version: 9.0/7\nGPU model and memory: GTX1080 8G\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"", "body": "### Problem\r\n\r\nI run make_one_shot_iterator() each epoch because  I want re-shuffle the dataset each epoch. I Know that the dataset.shuffle().repeat().batch() pipeline can do almost the same thing, but when data_num can not be divided exactly by batch_size, the pipeline merges two epochs at their boundary to construct a complete batch,  which I HATE.\r\n\r\nSo, I choose to run dataset.shuffle().batch() and make_one_shot_iterator() before each epoch. But I find that the speed of consuming dataset becomes slower and slower, significantly. I tried different settings to find out that it is make_one_shot_iterator() which makes consuming slow. \r\n\r\nBy the way, I build tensorflow 1.4 from source on OS X with support of GPU, some hacky workaround. \r\n\r\n### Code\r\n\r\n```\r\nnum_data = 1000\r\nnum_epoch = 50\r\nbatch_size = 32\r\ndataset = tf.data.Dataset.range(num_data)\r\n\r\nmode=3 \r\n# model = 1,2,or 3\r\n# 1: re-shuffle, re-batch and re-make-iterator each epoch\r\n# 2: re-batch and re-make-iterator\r\n# 3: only re-make-iterator\r\n\r\nwith tf.Session() as sess:\r\n    for epoch in xrange(num_epoch):\r\n        t1 = time.time()\r\n        if mode==1: \r\n            _dataset = dataset.shuffle(num_data).batch(batch_size)\r\n            iterator = _dataset.make_one_shot_iterator()\r\n        elif mode==2:\r\n            _dataset = dataset.batch(batch_size)\r\n            iterator = _dataset.make_one_shot_iterator()\r\n        elif mode==3: \r\n            iterator = dataset.make_one_shot_iterator()\r\n        t2 = time.time()\r\n        for i in xrange(num_data/batch_size):\r\n            a = sess.run(iterator.get_next())\r\n        t3 =time.time()\r\n        print 'epoch %d make_iterator_time %.4f comsuming_time %.4f'%(epoch,t2-t1,t3-t2)\r\n```\r\n\r\nand the outputs:\r\n\r\n```\r\nepoch 0 make_iterator_time 0.0181 comsuming_time 0.1366\r\nepoch 1 make_iterator_time 0.0036 comsuming_time 0.1444\r\nepoch 2 make_iterator_time 0.0040 comsuming_time 0.1559\r\nepoch 3 make_iterator_time 0.0036 comsuming_time 0.1695\r\nepoch 4 make_iterator_time 0.0036 comsuming_time 0.1899\r\nepoch 5 make_iterator_time 0.0036 comsuming_time 0.1955\r\nepoch 6 make_iterator_time 0.0036 comsuming_time 0.2082\r\nepoch 7 make_iterator_time 0.0037 comsuming_time 0.2191\r\nepoch 8 make_iterator_time 0.0036 comsuming_time 0.2334\r\nepoch 9 make_iterator_time 0.0040 comsuming_time 0.2461\r\nepoch 10 make_iterator_time 0.0036 comsuming_time 0.2621\r\nepoch 11 make_iterator_time 0.0036 comsuming_time 0.2720\r\nepoch 12 make_iterator_time 0.0036 comsuming_time 0.2886\r\nepoch 13 make_iterator_time 0.0036 comsuming_time 0.3006\r\nepoch 14 make_iterator_time 0.0037 comsuming_time 0.3134\r\nepoch 15 make_iterator_time 0.0039 comsuming_time 0.3260\r\nepoch 16 make_iterator_time 0.0445 comsuming_time 0.3438\r\nepoch 17 make_iterator_time 0.0037 comsuming_time 0.3576\r\nepoch 18 make_iterator_time 0.0037 comsuming_time 0.3678\r\nepoch 19 make_iterator_time 0.0040 comsuming_time 0.3827\r\nepoch 20 make_iterator_time 0.0037 comsuming_time 0.3937\r\nepoch 21 make_iterator_time 0.0038 comsuming_time 0.4172\r\nepoch 22 make_iterator_time 0.0036 comsuming_time 0.4222\r\n...\r\n ```\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.5\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: clang-802.0.42\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**: GTX1080 8G\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\""}