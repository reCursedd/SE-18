{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11583", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11583/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11583/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11583/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11583", "id": 243790385, "node_id": "MDU6SXNzdWUyNDM3OTAzODU=", "number": 11583, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)", "user": {"login": "Loohaze", "id": 18029266, "node_id": "MDQ6VXNlcjE4MDI5MjY2", "avatar_url": "https://avatars3.githubusercontent.com/u/18029266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Loohaze", "html_url": "https://github.com/Loohaze", "followers_url": "https://api.github.com/users/Loohaze/followers", "following_url": "https://api.github.com/users/Loohaze/following{/other_user}", "gists_url": "https://api.github.com/users/Loohaze/gists{/gist_id}", "starred_url": "https://api.github.com/users/Loohaze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Loohaze/subscriptions", "organizations_url": "https://api.github.com/users/Loohaze/orgs", "repos_url": "https://api.github.com/users/Loohaze/repos", "events_url": "https://api.github.com/users/Loohaze/events{/privacy}", "received_events_url": "https://api.github.com/users/Loohaze/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-07-18T17:22:30Z", "updated_at": "2017-12-11T21:41:52Z", "closed_at": "2017-12-11T21:40:27Z", "author_association": "NONE", "body_html": "<p>I try to run the Sequence-to-Sequence Models with tensorflow, but when I run the training set, I have the problem like this</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call<br>\nreturn fn(*args)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1004, in _run_fn<br>\nstatus, run_metadata)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/contextlib.py\", line 89, in <strong>exit</strong><br>\nnext(self.gen)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status<br>\npywrap_tensorflow.TF_GetCode(status))<br>\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)<br>\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"translate.py\", line 322, in <br>\ntf.app.run()<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run<br>\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))<br>\nFile \"translate.py\", line 319, in main<br>\ntrain()<br>\nFile \"translate.py\", line 210, in train<br>\ntarget_weights, bucket_id, False)<br>\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 251, in step<br>\noutputs = session.run(output_feed, input_feed)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run<br>\nrun_metadata_ptr)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)<br>\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]</p>\n<p>Caused by op 'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15', defined at:<br>\nFile \"translate.py\", line 322, in <br>\ntf.app.run()<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run<br>\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))<br>\nFile \"translate.py\", line 319, in main<br>\ntrain()<br>\nFile \"translate.py\", line 178, in train<br>\nmodel = create_model(sess, False)<br>\nFile \"translate.py\", line 136, in create_model<br>\ndtype=dtype)<br>\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 179, in <strong>init</strong><br>\nsoftmax_loss_function=softmax_loss_function)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1180, in model_with_buckets<br>\ndecoder_inputs[:bucket[1]])<br>\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 178, in <br>\nlambda x, y: seq2seq_f(x, y, False),<br>\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 142, in seq2seq_f<br>\ndtype=dtype)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 876, in embedding_attention_seq2seq<br>\ninitial_state_attention=initial_state_attention)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in embedding_attention_decoder<br>\nembedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in <br>\nembedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 111, in embedding_lookup<br>\nvalidate_indices=validate_indices)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1359, in gather<br>\nvalidate_indices=validate_indices, name=name)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op<br>\nop_def=op_def)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<p>InvalidArgumentError (see above for traceback): indices[49] = 60000 is not in [0, 60000)<br>\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]</p>\n</blockquote>\n<p>It seems the problem happens randomly when running training set. It means when I have this problem,I can continue and this may not happen in next steps.<br>\nI checked this problem on previous issues, but I am sure that I have set the parameter of vocabulary size<br>\nHere are my input commands:</p>\n<blockquote>\n<p>python translate.py --data_dir /private/tmp/ch-en  --train_dir /private/tmp/ch-en/train_result --size=256 --num_layers=2 --steps_per_checkpoint=200 --from_vocab_size=60000 --to_vocab_size=60000</p>\n</blockquote>\n<p>So how to solve this problem?</p>", "body_text": "I try to run the Sequence-to-Sequence Models with tensorflow, but when I run the training set, I have the problem like this\n\nTraceback (most recent call last):\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\nreturn fn(*args)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1004, in _run_fn\nstatus, run_metadata)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/contextlib.py\", line 89, in exit\nnext(self.gen)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\npywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"translate.py\", line 322, in \ntf.app.run()\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile \"translate.py\", line 319, in main\ntrain()\nFile \"translate.py\", line 210, in train\ntarget_weights, bucket_id, False)\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 251, in step\noutputs = session.run(output_feed, input_feed)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run\nrun_metadata_ptr)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\ntarget_list, options, run_metadata)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\nCaused by op 'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15', defined at:\nFile \"translate.py\", line 322, in \ntf.app.run()\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile \"translate.py\", line 319, in main\ntrain()\nFile \"translate.py\", line 178, in train\nmodel = create_model(sess, False)\nFile \"translate.py\", line 136, in create_model\ndtype=dtype)\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 179, in init\nsoftmax_loss_function=softmax_loss_function)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1180, in model_with_buckets\ndecoder_inputs[:bucket[1]])\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 178, in \nlambda x, y: seq2seq_f(x, y, False),\nFile \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 142, in seq2seq_f\ndtype=dtype)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 876, in embedding_attention_seq2seq\ninitial_state_attention=initial_state_attention)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in embedding_attention_decoder\nembedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in \nembedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 111, in embedding_lookup\nvalidate_indices=validate_indices)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1359, in gather\nvalidate_indices=validate_indices, name=name)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\nop_def=op_def)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in init\nself._traceback = _extract_stack()\nInvalidArgumentError (see above for traceback): indices[49] = 60000 is not in [0, 60000)\n[[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\n\nIt seems the problem happens randomly when running training set. It means when I have this problem,I can continue and this may not happen in next steps.\nI checked this problem on previous issues, but I am sure that I have set the parameter of vocabulary size\nHere are my input commands:\n\npython translate.py --data_dir /private/tmp/ch-en  --train_dir /private/tmp/ch-en/train_result --size=256 --num_layers=2 --steps_per_checkpoint=200 --from_vocab_size=60000 --to_vocab_size=60000\n\nSo how to solve this problem?", "body": "I try to run the Sequence-to-Sequence Models with tensorflow, but when I run the training set, I have the problem like this\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\r\n>     return fn(*args)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1004, in _run_fn\r\n>     status, run_metadata)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n>     next(self.gen)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n>     pywrap_tensorflow.TF_GetCode(status))\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)\r\n> \t [[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"translate.py\", line 322, in <module>\r\n>     tf.app.run()\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n>   File \"translate.py\", line 319, in main\r\n>     train()\r\n>   File \"translate.py\", line 210, in train\r\n>     target_weights, bucket_id, False)\r\n>   File \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 251, in step\r\n>     outputs = session.run(output_feed, input_feed)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n>     run_metadata_ptr)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n>     feed_dict_string, options, run_metadata)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n>     target_list, options, run_metadata)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[49] = 60000 is not in [0, 60000)\r\n> \t [[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\r\n> \r\n> Caused by op 'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15', defined at:\r\n>   File \"translate.py\", line 322, in <module>\r\n>     tf.app.run()\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n>   File \"translate.py\", line 319, in main\r\n>     train()\r\n>   File \"translate.py\", line 178, in train\r\n>     model = create_model(sess, False)\r\n>   File \"translate.py\", line 136, in create_model\r\n>     dtype=dtype)\r\n>   File \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 179, in __init__\r\n>     softmax_loss_function=softmax_loss_function)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1180, in model_with_buckets\r\n>     decoder_inputs[:bucket[1]])\r\n>   File \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 178, in <lambda>\r\n>     lambda x, y: seq2seq_f(x, y, False),\r\n>   File \"/Users/loohaze/Documents/models/tutorials/rnn/translate/seq2seq_model.py\", line 142, in seq2seq_f\r\n>     dtype=dtype)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 876, in embedding_attention_seq2seq\r\n>     initial_state_attention=initial_state_attention)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in embedding_attention_decoder\r\n>     embedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 772, in <listcomp>\r\n>     embedding_ops.embedding_lookup(embedding, i) for i in decoder_inputs\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 111, in embedding_lookup\r\n>     validate_indices=validate_indices)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1359, in gather\r\n>     validate_indices=validate_indices, name=name)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n>     op_def=op_def)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n>     original_op=self._default_original_op, op_def=op_def)\r\n>   File \"/Users/loohaze/anaconda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n>     self._traceback = _extract_stack()\r\n> \r\n> InvalidArgumentError (see above for traceback): indices[49] = 60000 is not in [0, 60000)\r\n> \t [[Node: model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/embedding_lookup_15 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_attention_seq2seq/embedding_attention_decoder/embedding/read, _recv_decoder15_0)]]\r\n> \r\n\r\nIt seems the problem happens randomly when running training set. It means when I have this problem,I can continue and this may not happen in next steps.\r\nI checked this problem on previous issues, but I am sure that I have set the parameter of vocabulary size\r\nHere are my input commands:\r\n\r\n> python translate.py --data_dir /private/tmp/ch-en  --train_dir /private/tmp/ch-en/train_result --size=256 --num_layers=2 --steps_per_checkpoint=200 --from_vocab_size=60000 --to_vocab_size=60000\r\n\r\nSo how to solve this problem?\r\n"}