{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299797456", "html_url": "https://github.com/tensorflow/tensorflow/pull/9477#issuecomment-299797456", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9477", "id": 299797456, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTc5NzQ1Ng==", "user": {"login": "xcyan", "id": 8760875, "node_id": "MDQ6VXNlcjg3NjA4NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/8760875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xcyan", "html_url": "https://github.com/xcyan", "followers_url": "https://api.github.com/users/xcyan/followers", "following_url": "https://api.github.com/users/xcyan/following{/other_user}", "gists_url": "https://api.github.com/users/xcyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/xcyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xcyan/subscriptions", "organizations_url": "https://api.github.com/users/xcyan/orgs", "repos_url": "https://api.github.com/users/xcyan/repos", "events_url": "https://api.github.com/users/xcyan/events{/privacy}", "received_events_url": "https://api.github.com/users/xcyan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-08T07:50:36Z", "updated_at": "2017-05-08T07:50:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=577277\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinwicke\">@martinwicke</a>  Thank you for your comments! However, the comment seems not fair.</p>\n<blockquote>\n<p>For some definition of \"many\" --only 200k or so people have touched TF, far fewer use 3d convolutions (500-1000?), fewer use transposed 3D convolutions (100-200?), and far fewer use Slim. If we total ~5-10 people that's already a stretch.</p>\n</blockquote>\n<p>In fact, conv3d/conv3d_transpose has become really popular these days: please check out the latest CVPR/NIPS/ICML papers that use 3d convolution:<br>\n[1] Unsupervised Learning of 3D Structure from Images In NIPS 16 from Deepmind<br>\n[2] Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling In NIPS 2016 from Facebook &amp; MIT<br>\n[3] Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision In NIPS 2016 from UM, Adobe &amp; Google Brain<br>\n[4] Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis In CVPR 2017 from Stanford<br>\n[5] Learning a Predictable and Generative Vector Representation for Objects In ECCV 2016 from CMU &amp; Google Research<br>\nand so on.</p>\n<p>We really appreciate if the conv3d/conv3d_transpose can be added to slim, which may benefit people working on 3D generation.<br>\nAs far as I know, Torch has provided the conv3d/conv3d_transpose and that is one reason some researchers tend to avoid using TF for 3D generation.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4168984\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Kongsea\">@Kongsea</a><br>\nIs it possible to make any modification on your side? As far as I can see, it will cause TF developers to do some extra work (~20 breakages according to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a> ) which might not be the high priority for them. Thank you very much!</p>", "body_text": "@fchollet @martinwicke  Thank you for your comments! However, the comment seems not fair.\n\nFor some definition of \"many\" --only 200k or so people have touched TF, far fewer use 3d convolutions (500-1000?), fewer use transposed 3D convolutions (100-200?), and far fewer use Slim. If we total ~5-10 people that's already a stretch.\n\nIn fact, conv3d/conv3d_transpose has become really popular these days: please check out the latest CVPR/NIPS/ICML papers that use 3d convolution:\n[1] Unsupervised Learning of 3D Structure from Images In NIPS 16 from Deepmind\n[2] Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling In NIPS 2016 from Facebook & MIT\n[3] Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision In NIPS 2016 from UM, Adobe & Google Brain\n[4] Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis In CVPR 2017 from Stanford\n[5] Learning a Predictable and Generative Vector Representation for Objects In ECCV 2016 from CMU & Google Research\nand so on.\nWe really appreciate if the conv3d/conv3d_transpose can be added to slim, which may benefit people working on 3D generation.\nAs far as I know, Torch has provided the conv3d/conv3d_transpose and that is one reason some researchers tend to avoid using TF for 3D generation.\n@Kongsea\nIs it possible to make any modification on your side? As far as I can see, it will cause TF developers to do some extra work (~20 breakages according to @fchollet ) which might not be the high priority for them. Thank you very much!", "body": "@fchollet @martinwicke  Thank you for your comments! However, the comment seems not fair.\r\n\r\n> For some definition of \"many\" --only 200k or so people have touched TF, far fewer use 3d convolutions (500-1000?), fewer use transposed 3D convolutions (100-200?), and far fewer use Slim. If we total ~5-10 people that's already a stretch.\r\n\r\nIn fact, conv3d/conv3d_transpose has become really popular these days: please check out the latest CVPR/NIPS/ICML papers that use 3d convolution:\r\n[1] Unsupervised Learning of 3D Structure from Images In NIPS 16 from Deepmind\r\n[2] Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling In NIPS 2016 from Facebook & MIT\r\n[3] Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision In NIPS 2016 from UM, Adobe & Google Brain\r\n[4] Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis In CVPR 2017 from Stanford\r\n[5] Learning a Predictable and Generative Vector Representation for Objects In ECCV 2016 from CMU & Google Research\r\nand so on.\r\n\r\nWe really appreciate if the conv3d/conv3d_transpose can be added to slim, which may benefit people working on 3D generation.\r\nAs far as I know, Torch has provided the conv3d/conv3d_transpose and that is one reason some researchers tend to avoid using TF for 3D generation.\r\n\r\n@Kongsea \r\nIs it possible to make any modification on your side? As far as I can see, it will cause TF developers to do some extra work (~20 breakages according to @fchollet ) which might not be the high priority for them. Thank you very much!"}