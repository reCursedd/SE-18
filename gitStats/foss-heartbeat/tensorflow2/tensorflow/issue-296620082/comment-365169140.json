{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/365169140", "html_url": "https://github.com/tensorflow/tensorflow/issues/16965#issuecomment-365169140", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16965", "id": 365169140, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTE2OTE0MA==", "user": {"login": "sagarbhathwar", "id": 21982231, "node_id": "MDQ6VXNlcjIxOTgyMjMx", "avatar_url": "https://avatars3.githubusercontent.com/u/21982231?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sagarbhathwar", "html_url": "https://github.com/sagarbhathwar", "followers_url": "https://api.github.com/users/sagarbhathwar/followers", "following_url": "https://api.github.com/users/sagarbhathwar/following{/other_user}", "gists_url": "https://api.github.com/users/sagarbhathwar/gists{/gist_id}", "starred_url": "https://api.github.com/users/sagarbhathwar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sagarbhathwar/subscriptions", "organizations_url": "https://api.github.com/users/sagarbhathwar/orgs", "repos_url": "https://api.github.com/users/sagarbhathwar/repos", "events_url": "https://api.github.com/users/sagarbhathwar/events{/privacy}", "received_events_url": "https://api.github.com/users/sagarbhathwar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-13T07:00:17Z", "updated_at": "2018-02-13T07:00:41Z", "author_association": "NONE", "body_html": "<p>This bug is still present with Keras program:</p>\n<pre><code>import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\n\nx_train = np.random.random((100,100,100,3))\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\nx_test = np.random.random((20,100,100,3))\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(20,1)), num_classes=10)\n\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(100,100,3)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=10)\n\n</code></pre>\n<p>The below snipped from stackoverflow fixes it in MNIST example</p>\n<pre><code>config = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config, ...)\n</code></pre>\n<p>This fix from <a href=\"https://stackoverflow.com/questions/41117740/tensorflow-crashes-with-cublas-status-alloc-failed\" rel=\"nofollow\">https://stackoverflow.com/questions/41117740/tensorflow-crashes-with-cublas-status-alloc-failed</a></p>\n<p>What's the problem here?</p>", "body_text": "This bug is still present with Keras program:\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\n\nx_train = np.random.random((100,100,100,3))\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\nx_test = np.random.random((20,100,100,3))\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(20,1)), num_classes=10)\n\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(100,100,3)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=10)\n\n\nThe below snipped from stackoverflow fixes it in MNIST example\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config, ...)\n\nThis fix from https://stackoverflow.com/questions/41117740/tensorflow-crashes-with-cublas-status-alloc-failed\nWhat's the problem here?", "body": "This bug is still present with Keras program:\r\n```\r\nimport numpy as np\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Dropout, Flatten\r\nfrom keras.layers import Conv2D, MaxPooling2D\r\nfrom keras.optimizers import SGD\r\n\r\n\r\nx_train = np.random.random((100,100,100,3))\r\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\r\nx_test = np.random.random((20,100,100,3))\r\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(20,1)), num_classes=10)\r\n\r\n\r\nmodel = Sequential()\r\n\r\n\r\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(100,100,3)))\r\nmodel.add(Conv2D(32, (3,3), activation='relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.25))\r\n\r\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.25))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(256, activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(10, activation='softmax'))\r\n\r\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\r\n\r\nmodel.fit(x_train, y_train, batch_size=32, epochs=10)\r\n\r\n```\r\nThe below snipped from stackoverflow fixes it in MNIST example\r\n```\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = tf.Session(config=config, ...)\r\n```\r\n\r\nThis fix from https://stackoverflow.com/questions/41117740/tensorflow-crashes-with-cublas-status-alloc-failed\r\n\r\nWhat's the problem here?"}