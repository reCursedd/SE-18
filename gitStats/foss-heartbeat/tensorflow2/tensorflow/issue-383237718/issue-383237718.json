{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23904", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23904/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23904/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23904/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23904", "id": 383237718, "node_id": "MDU6SXNzdWUzODMyMzc3MTg=", "number": 23904, "title": "New instances of iterator.make_initializer do not release previously allocated memory", "user": {"login": "artsobolev", "id": 434122, "node_id": "MDQ6VXNlcjQzNDEyMg==", "avatar_url": "https://avatars1.githubusercontent.com/u/434122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/artsobolev", "html_url": "https://github.com/artsobolev", "followers_url": "https://api.github.com/users/artsobolev/followers", "following_url": "https://api.github.com/users/artsobolev/following{/other_user}", "gists_url": "https://api.github.com/users/artsobolev/gists{/gist_id}", "starred_url": "https://api.github.com/users/artsobolev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/artsobolev/subscriptions", "organizations_url": "https://api.github.com/users/artsobolev/orgs", "repos_url": "https://api.github.com/users/artsobolev/repos", "events_url": "https://api.github.com/users/artsobolev/events{/privacy}", "received_events_url": "https://api.github.com/users/artsobolev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T18:05:43Z", "updated_at": "2018-11-21T18:05:43Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0</li>\n<li>Python version: 3.5.2</li>\n<li>Bazel version (if compiling from source): NA</li>\n<li>GCC/Compiler version (if compiling from source): NA</li>\n<li>CUDA/cuDNN version: 9.0.176 / 7.3.0.29</li>\n<li>GPU model and memory: GeForce GTX 1080 Ti</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nConsider the following setup (see the code below)</p>\n<ol>\n<li>Create a dataset using <code>tf.data.Dataset.from_tensor_slices</code></li>\n<li>Use it to initialize a <code>tf.data.Iterator.from_structure</code> iterator</li>\n<li>Repeat the previous step several times in a single session</li>\n</ol>\n<p>Observed behavior: memory consumption grows linearly with number of iterations</p>\n<p><strong>Describe the expected behavior</strong><br>\nMemory consumption should be bounded for any number of iterations.</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> psutil\n\nn_samples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">1000</span>\ndim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">50</span>\n\nraw_data <span class=\"pl-k\">=</span> np.zeros((n_samples, dim)).astype(np.float32)\ndataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(raw_data).batch(batch_size)\niterator <span class=\"pl-k\">=</span> tf.data.Iterator.from_structure(tf.float32, [<span class=\"pl-c1\">None</span>, dim])\n\nprocess <span class=\"pl-k\">=</span> psutil.Process(os.getpid())\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">mem</span>():\n    <span class=\"pl-k\">return</span> process.memory_info().rss <span class=\"pl-k\">/</span> <span class=\"pl-c1\">1024</span> <span class=\"pl-k\">**</span> <span class=\"pl-c1\">3</span>.\n\nsess <span class=\"pl-k\">=</span> tf.Session()\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">20</span>):\n    sess.run(iterator.make_initializer(dataset))\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Epoch <span class=\"pl-c1\">{}</span>, mem.: <span class=\"pl-c1\">{<span class=\"pl-k\">:.2f</span>}</span>Gb<span class=\"pl-pds\">'</span></span>.format( i, mem() ))</pre></div>\n<p>Output:</p>\n<pre><code>Epoch 0, mem.: 1.34Gb\nEpoch 1, mem.: 1.71Gb\nEpoch 2, mem.: 2.09Gb\nEpoch 3, mem.: 2.46Gb\nEpoch 4, mem.: 2.83Gb\nEpoch 5, mem.: 3.20Gb\nEpoch 6, mem.: 3.58Gb\nEpoch 7, mem.: 3.95Gb\nEpoch 8, mem.: 4.32Gb\nEpoch 9, mem.: 4.69Gb\nEpoch 10, mem.: 5.07Gb\nEpoch 11, mem.: 5.44Gb\nEpoch 12, mem.: 5.81Gb\nEpoch 13, mem.: 6.18Gb\nEpoch 14, mem.: 6.56Gb\nEpoch 15, mem.: 6.93Gb\nEpoch 16, mem.: 7.30Gb\nEpoch 17, mem.: 7.67Gb\nEpoch 18, mem.: 8.05Gb\nEpoch 19, mem.: 8.42Gb\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\nPython version: 3.5.2\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: 9.0.176 / 7.3.0.29\nGPU model and memory: GeForce GTX 1080 Ti\n\nDescribe the current behavior\nConsider the following setup (see the code below)\n\nCreate a dataset using tf.data.Dataset.from_tensor_slices\nUse it to initialize a tf.data.Iterator.from_structure iterator\nRepeat the previous step several times in a single session\n\nObserved behavior: memory consumption grows linearly with number of iterations\nDescribe the expected behavior\nMemory consumption should be bounded for any number of iterations.\nCode to reproduce the issue\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport psutil\n\nn_samples = 1000*1000\ndim = 100\nbatch_size = 50\n\nraw_data = np.zeros((n_samples, dim)).astype(np.float32)\ndataset = tf.data.Dataset.from_tensor_slices(raw_data).batch(batch_size)\niterator = tf.data.Iterator.from_structure(tf.float32, [None, dim])\n\nprocess = psutil.Process(os.getpid())\ndef mem():\n    return process.memory_info().rss / 1024 ** 3.\n\nsess = tf.Session()\nfor i in range(20):\n    sess.run(iterator.make_initializer(dataset))\n    print('Epoch {}, mem.: {:.2f}Gb'.format( i, mem() ))\nOutput:\nEpoch 0, mem.: 1.34Gb\nEpoch 1, mem.: 1.71Gb\nEpoch 2, mem.: 2.09Gb\nEpoch 3, mem.: 2.46Gb\nEpoch 4, mem.: 2.83Gb\nEpoch 5, mem.: 3.20Gb\nEpoch 6, mem.: 3.58Gb\nEpoch 7, mem.: 3.95Gb\nEpoch 8, mem.: 4.32Gb\nEpoch 9, mem.: 4.69Gb\nEpoch 10, mem.: 5.07Gb\nEpoch 11, mem.: 5.44Gb\nEpoch 12, mem.: 5.81Gb\nEpoch 13, mem.: 6.18Gb\nEpoch 14, mem.: 6.56Gb\nEpoch 15, mem.: 6.93Gb\nEpoch 16, mem.: 7.30Gb\nEpoch 17, mem.: 7.67Gb\nEpoch 18, mem.: 8.05Gb\nEpoch 19, mem.: 8.42Gb", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 9.0.176 / 7.3.0.29\r\n- GPU model and memory: GeForce GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nConsider the following setup (see the code below)\r\n1. Create a dataset using `tf.data.Dataset.from_tensor_slices`\r\n2. Use it to initialize a `tf.data.Iterator.from_structure` iterator\r\n3. Repeat the previous step several times in a single session\r\n\r\nObserved behavior: memory consumption grows linearly with number of iterations\r\n\r\n**Describe the expected behavior**\r\nMemory consumption should be bounded for any number of iterations.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\nimport psutil\r\n\r\nn_samples = 1000*1000\r\ndim = 100\r\nbatch_size = 50\r\n\r\nraw_data = np.zeros((n_samples, dim)).astype(np.float32)\r\ndataset = tf.data.Dataset.from_tensor_slices(raw_data).batch(batch_size)\r\niterator = tf.data.Iterator.from_structure(tf.float32, [None, dim])\r\n\r\nprocess = psutil.Process(os.getpid())\r\ndef mem():\r\n    return process.memory_info().rss / 1024 ** 3.\r\n\r\nsess = tf.Session()\r\nfor i in range(20):\r\n    sess.run(iterator.make_initializer(dataset))\r\n    print('Epoch {}, mem.: {:.2f}Gb'.format( i, mem() ))\r\n```\r\n\r\nOutput:\r\n```\r\nEpoch 0, mem.: 1.34Gb\r\nEpoch 1, mem.: 1.71Gb\r\nEpoch 2, mem.: 2.09Gb\r\nEpoch 3, mem.: 2.46Gb\r\nEpoch 4, mem.: 2.83Gb\r\nEpoch 5, mem.: 3.20Gb\r\nEpoch 6, mem.: 3.58Gb\r\nEpoch 7, mem.: 3.95Gb\r\nEpoch 8, mem.: 4.32Gb\r\nEpoch 9, mem.: 4.69Gb\r\nEpoch 10, mem.: 5.07Gb\r\nEpoch 11, mem.: 5.44Gb\r\nEpoch 12, mem.: 5.81Gb\r\nEpoch 13, mem.: 6.18Gb\r\nEpoch 14, mem.: 6.56Gb\r\nEpoch 15, mem.: 6.93Gb\r\nEpoch 16, mem.: 7.30Gb\r\nEpoch 17, mem.: 7.67Gb\r\nEpoch 18, mem.: 8.05Gb\r\nEpoch 19, mem.: 8.42Gb\r\n```"}