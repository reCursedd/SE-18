{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13213", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13213/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13213/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13213/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13213", "id": 259537007, "node_id": "MDU6SXNzdWUyNTk1MzcwMDc=", "number": 13213, "title": "GRPC causes training to pause in individual worker (distributed tensorflow, synchronised)", "user": {"login": "utkrist", "id": 3055617, "node_id": "MDQ6VXNlcjMwNTU2MTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/3055617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/utkrist", "html_url": "https://github.com/utkrist", "followers_url": "https://api.github.com/users/utkrist/followers", "following_url": "https://api.github.com/users/utkrist/following{/other_user}", "gists_url": "https://api.github.com/users/utkrist/gists{/gist_id}", "starred_url": "https://api.github.com/users/utkrist/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/utkrist/subscriptions", "organizations_url": "https://api.github.com/users/utkrist/orgs", "repos_url": "https://api.github.com/users/utkrist/repos", "events_url": "https://api.github.com/users/utkrist/events{/privacy}", "received_events_url": "https://api.github.com/users/utkrist/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2017-09-21T15:27:50Z", "updated_at": "2017-09-25T12:23:23Z", "closed_at": "2017-09-25T12:21:26Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Debian GNU/Linux 8.9 (jessie)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.2.0-5-g435cdfc 1.2.1</li>\n<li><strong>Python version</strong>: 3.6.2</li>\n<li><strong>CUDA/cuDNN version</strong>: cuda-8.0 / cudnn-5.1.5</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX Titan X, 12 GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The distributed synchronized ( between graph replication, 4 workers, 3 ps ) training works fine until one of the ps tasks reports following error. After that, one of the worker processes just stops, and the rest of the workers may also stop later with same error.</p>\n<pre><code>2017-09-21 16:45:55.606842: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:2000, 1 -&gt; localhost:2001, 2 -&gt; localhost:2002}\n 2017-09-21 16:45:55.606877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:2003, 1 -&gt; localhost:2004, 2 -&gt; localhost:2005, 3 -&gt; localhost:2006}\n 2017-09-21 16:45:55.608066: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2002\n E0921 16:48:52.596846076    3037 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=12325, new grpc_chttp2_stream id=12317\n 2017-09-21 16:48:57.497244: W tensorflow/core/framework/op_kernel.cc:1158] Out of range: End of sequence\n      [[Node: data_source_task_index_0/IteratorGetNext = IteratorGetNext[output_shapes=[[-1,-1], [-1,-1], [-1,-1], [-1,-1], [-1,-1]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64], _device=\"/job:ps/replica:0/task:0/cpu:0\"](data_source_task_index_0/Iterator)]]\n      [[Node: data_source_task_index_0/cond/Merge_2_S341 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:2/cpu:0\", send_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device_incarnation=-6450759800525444137, tensor_name=\"edge_359_data_source_task_index_0/cond/Merge_2\", tensor_type=DT_INT64, _device=\"/job:ps/replica:0/task:2/cpu:0\"]()]]\n E0921 16:49:58.462749643    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24769\n E0921 16:49:58.462780714    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24773\n E0921 16:49:58.463260203    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24777\n E0921 16:49:58.463277333    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24779\n E0921 16:49:58.463283953    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24781\n E0921 16:49:58.463289625    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24783\n E0921 16:49:58.463295275    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24785\n</code></pre>\n<p>For more detail see the stackoverflow post:<br>\n<a href=\"https://stackoverflow.com/questions/46322337/frozen-training-in-distributed-tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/46322337/frozen-training-in-distributed-tensorflow</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 8.9 (jessie)\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.2.0-5-g435cdfc 1.2.1\nPython version: 3.6.2\nCUDA/cuDNN version: cuda-8.0 / cudnn-5.1.5\nGPU model and memory: GeForce GTX Titan X, 12 GB\nExact command to reproduce:\n\nDescribe the problem\nThe distributed synchronized ( between graph replication, 4 workers, 3 ps ) training works fine until one of the ps tasks reports following error. After that, one of the worker processes just stops, and the rest of the workers may also stop later with same error.\n2017-09-21 16:45:55.606842: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2000, 1 -> localhost:2001, 2 -> localhost:2002}\n 2017-09-21 16:45:55.606877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2003, 1 -> localhost:2004, 2 -> localhost:2005, 3 -> localhost:2006}\n 2017-09-21 16:45:55.608066: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2002\n E0921 16:48:52.596846076    3037 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=12325, new grpc_chttp2_stream id=12317\n 2017-09-21 16:48:57.497244: W tensorflow/core/framework/op_kernel.cc:1158] Out of range: End of sequence\n      [[Node: data_source_task_index_0/IteratorGetNext = IteratorGetNext[output_shapes=[[-1,-1], [-1,-1], [-1,-1], [-1,-1], [-1,-1]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64], _device=\"/job:ps/replica:0/task:0/cpu:0\"](data_source_task_index_0/Iterator)]]\n      [[Node: data_source_task_index_0/cond/Merge_2_S341 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:2/cpu:0\", send_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device_incarnation=-6450759800525444137, tensor_name=\"edge_359_data_source_task_index_0/cond/Merge_2\", tensor_type=DT_INT64, _device=\"/job:ps/replica:0/task:2/cpu:0\"]()]]\n E0921 16:49:58.462749643    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24769\n E0921 16:49:58.462780714    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24773\n E0921 16:49:58.463260203    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24777\n E0921 16:49:58.463277333    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24779\n E0921 16:49:58.463283953    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24781\n E0921 16:49:58.463289625    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24783\n E0921 16:49:58.463295275    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24785\n\nFor more detail see the stackoverflow post:\nhttps://stackoverflow.com/questions/46322337/frozen-training-in-distributed-tensorflow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8.9 (jessie)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.2.0-5-g435cdfc 1.2.1\r\n- **Python version**: 3.6.2\r\n- **CUDA/cuDNN version**: cuda-8.0 / cudnn-5.1.5\r\n- **GPU model and memory**: GeForce GTX Titan X, 12 GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nThe distributed synchronized ( between graph replication, 4 workers, 3 ps ) training works fine until one of the ps tasks reports following error. After that, one of the worker processes just stops, and the rest of the workers may also stop later with same error. \r\n\r\n   ```\r\n 2017-09-21 16:45:55.606842: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2000, 1 -> localhost:2001, 2 -> localhost:2002}\r\n    2017-09-21 16:45:55.606877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2003, 1 -> localhost:2004, 2 -> localhost:2005, 3 -> localhost:2006}\r\n    2017-09-21 16:45:55.608066: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2002\r\n    E0921 16:48:52.596846076    3037 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=12325, new grpc_chttp2_stream id=12317\r\n    2017-09-21 16:48:57.497244: W tensorflow/core/framework/op_kernel.cc:1158] Out of range: End of sequence\r\n         [[Node: data_source_task_index_0/IteratorGetNext = IteratorGetNext[output_shapes=[[-1,-1], [-1,-1], [-1,-1], [-1,-1], [-1,-1]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64], _device=\"/job:ps/replica:0/task:0/cpu:0\"](data_source_task_index_0/Iterator)]]\r\n         [[Node: data_source_task_index_0/cond/Merge_2_S341 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:2/cpu:0\", send_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device_incarnation=-6450759800525444137, tensor_name=\"edge_359_data_source_task_index_0/cond/Merge_2\", tensor_type=DT_INT64, _device=\"/job:ps/replica:0/task:2/cpu:0\"]()]]\r\n    E0921 16:49:58.462749643    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24769\r\n    E0921 16:49:58.462780714    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24775, new grpc_chttp2_stream id=24773\r\n    E0921 16:49:58.463260203    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24777\r\n    E0921 16:49:58.463277333    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24779\r\n    E0921 16:49:58.463283953    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24781\r\n    E0921 16:49:58.463289625    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24783\r\n    E0921 16:49:58.463295275    3036 parsing.c:801]              ignoring out of order new grpc_chttp2_stream request on server; last grpc_chttp2_stream id=24793, new grpc_chttp2_stream id=24785\r\n```\r\n\r\n\r\nFor more detail see the stackoverflow post: \r\nhttps://stackoverflow.com/questions/46322337/frozen-training-in-distributed-tensorflow  "}