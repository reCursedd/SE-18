{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/337662966", "html_url": "https://github.com/tensorflow/tensorflow/issues/13537#issuecomment-337662966", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13537", "id": 337662966, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzY2Mjk2Ng==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-18T17:17:36Z", "updated_at": "2017-10-18T17:17:36Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">The current merged tensor behavior is broken since even though you can\nassign a merged tensor to a variable, but then you have to slice it back up\nwhen you want to read the states back out again; and in the meantime you've\nlost the structure and shape of the intermediate states.\n\nHaving tf.assign support tuples may make sense; we'll look into it.  In the\nmeantime, you should be able to get pretty far using nest:\n\nupdated_variables = tf.contrib.framework.nest.map_structure(lambda v, s:\nv.assign(s), variables, states)\n\nwhere variables are created via map_structure using the rnn_cell's\nstate_size property or by looping over the zero_state tensors.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Wed, Oct 18, 2017 at 10:06 AM, Greg Peatfield ***@***.***&gt; wrote:\n I would like to still request either tf.assign() be updated to support\n Tuples to drastically reduce the complexity of updating the LSTM Tuple (as\n well as any future changes) or that the current merged tensor remain as\n supported.\n\n For cases where the network is copied for parallel Reinforcement Learning\n threads where the global network is copied, the complexity is going to\n increase due to the unique nature or handling Tuple Named Tensors.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"263573460\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13537\" href=\"https://github.com/tensorflow/tensorflow/issues/13537#issuecomment-337659615\">#13537 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim7gQ0A7m_4sjIO5tMMTtd9SjExDfks5stjAIgaJpZM4PxCmq\">https://github.com/notifications/unsubscribe-auth/ABtim7gQ0A7m_4sjIO5tMMTtd9SjExDfks5stjAIgaJpZM4PxCmq</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "The current merged tensor behavior is broken since even though you can\nassign a merged tensor to a variable, but then you have to slice it back up\nwhen you want to read the states back out again; and in the meantime you've\nlost the structure and shape of the intermediate states.\n\nHaving tf.assign support tuples may make sense; we'll look into it.  In the\nmeantime, you should be able to get pretty far using nest:\n\nupdated_variables = tf.contrib.framework.nest.map_structure(lambda v, s:\nv.assign(s), variables, states)\n\nwhere variables are created via map_structure using the rnn_cell's\nstate_size property or by looping over the zero_state tensors.\n\u2026\nOn Wed, Oct 18, 2017 at 10:06 AM, Greg Peatfield ***@***.***> wrote:\n I would like to still request either tf.assign() be updated to support\n Tuples to drastically reduce the complexity of updating the LSTM Tuple (as\n well as any future changes) or that the current merged tensor remain as\n supported.\n\n For cases where the network is copied for parallel Reinforcement Learning\n threads where the global network is copied, the complexity is going to\n increase due to the unique nature or handling Tuple Named Tensors.\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n <#13537 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim7gQ0A7m_4sjIO5tMMTtd9SjExDfks5stjAIgaJpZM4PxCmq>\n .", "body": "The current merged tensor behavior is broken since even though you can\nassign a merged tensor to a variable, but then you have to slice it back up\nwhen you want to read the states back out again; and in the meantime you've\nlost the structure and shape of the intermediate states.\n\nHaving tf.assign support tuples may make sense; we'll look into it.  In the\nmeantime, you should be able to get pretty far using nest:\n\nupdated_variables = tf.contrib.framework.nest.map_structure(lambda v, s:\nv.assign(s), variables, states)\n\nwhere variables are created via map_structure using the rnn_cell's\nstate_size property or by looping over the zero_state tensors.\n\nOn Wed, Oct 18, 2017 at 10:06 AM, Greg Peatfield <notifications@github.com>\nwrote:\n\n> I would like to still request either tf.assign() be updated to support\n> Tuples to drastically reduce the complexity of updating the LSTM Tuple (as\n> well as any future changes) or that the current merged tensor remain as\n> supported.\n>\n> For cases where the network is copied for parallel Reinforcement Learning\n> threads where the global network is copied, the complexity is going to\n> increase due to the unique nature or handling Tuple Named Tensors.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13537#issuecomment-337659615>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim7gQ0A7m_4sjIO5tMMTtd9SjExDfks5stjAIgaJpZM4PxCmq>\n> .\n>\n"}