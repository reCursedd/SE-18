{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336317687", "html_url": "https://github.com/tensorflow/tensorflow/issues/13537#issuecomment-336317687", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13537", "id": 336317687, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjMxNzY4Nw==", "user": {"login": "Mazecreator", "id": 18412448, "node_id": "MDQ6VXNlcjE4NDEyNDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/18412448?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mazecreator", "html_url": "https://github.com/Mazecreator", "followers_url": "https://api.github.com/users/Mazecreator/followers", "following_url": "https://api.github.com/users/Mazecreator/following{/other_user}", "gists_url": "https://api.github.com/users/Mazecreator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mazecreator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mazecreator/subscriptions", "organizations_url": "https://api.github.com/users/Mazecreator/orgs", "repos_url": "https://api.github.com/users/Mazecreator/repos", "events_url": "https://api.github.com/users/Mazecreator/events{/privacy}", "received_events_url": "https://api.github.com/users/Mazecreator/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-13T00:31:13Z", "updated_at": "2017-10-13T00:31:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think I understand the approach although I have yet to code the solution.  It seems like the more an more I dig into this approach the more complexity and issue the rise.  I may need to wait for the actual support for assign() with Tuples.  I ran into another issue as I was trying to prototype this and it was initializing a variable with a Tuple only returns a single combined tensor.  Hopefully if Assign() supports tuples the \"variable()\" will support Tuples as well to initialize.  I find the biggest problem is the complexity of other libraries by manually copying like this.  Also, I need to figure out how to screen for a tuple so when I \"assign()\" the variables I don't collapse the tuple into a single tensor variable as this was tough to find even in a short segment of code.</p>\n<p>So I think I might be able to do a short-term solution if needed based upon the comments from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> , but I really think if the RNN training is going to force the state to be a tuple then the rest of TensorFlow should help support this new requirement.  Another option is to remove the warning statement and just document that Tuples are handled faster and support both formats moving forward.  I am sure this is an easier solution for now, not sure about the long term support issues as I am sure the team will need to think through.</p>\n<p>Here is what I am talking about when the RNN cells are \"state_is_tuple=True\"</p>\n<pre><code>        self.init_state = self.cell_L1.zero_state(batch_size, tf.float32)\n        self.state = tf.Variable(self.init_state, trainable=False)\n</code></pre>\n<p>In the code above, this silently functions as you would expect.  The self.state is initialized with the Tuple value from self.init_state, but what you get for self.state is actually a single Tensor variable with the Tuple collapsed.  This causes the RNN functions to fail later as they are expecting a Tuple for the state.</p>", "body_text": "I think I understand the approach although I have yet to code the solution.  It seems like the more an more I dig into this approach the more complexity and issue the rise.  I may need to wait for the actual support for assign() with Tuples.  I ran into another issue as I was trying to prototype this and it was initializing a variable with a Tuple only returns a single combined tensor.  Hopefully if Assign() supports tuples the \"variable()\" will support Tuples as well to initialize.  I find the biggest problem is the complexity of other libraries by manually copying like this.  Also, I need to figure out how to screen for a tuple so when I \"assign()\" the variables I don't collapse the tuple into a single tensor variable as this was tough to find even in a short segment of code.\nSo I think I might be able to do a short-term solution if needed based upon the comments from @ebrevdo , but I really think if the RNN training is going to force the state to be a tuple then the rest of TensorFlow should help support this new requirement.  Another option is to remove the warning statement and just document that Tuples are handled faster and support both formats moving forward.  I am sure this is an easier solution for now, not sure about the long term support issues as I am sure the team will need to think through.\nHere is what I am talking about when the RNN cells are \"state_is_tuple=True\"\n        self.init_state = self.cell_L1.zero_state(batch_size, tf.float32)\n        self.state = tf.Variable(self.init_state, trainable=False)\n\nIn the code above, this silently functions as you would expect.  The self.state is initialized with the Tuple value from self.init_state, but what you get for self.state is actually a single Tensor variable with the Tuple collapsed.  This causes the RNN functions to fail later as they are expecting a Tuple for the state.", "body": "I think I understand the approach although I have yet to code the solution.  It seems like the more an more I dig into this approach the more complexity and issue the rise.  I may need to wait for the actual support for assign() with Tuples.  I ran into another issue as I was trying to prototype this and it was initializing a variable with a Tuple only returns a single combined tensor.  Hopefully if Assign() supports tuples the \"variable()\" will support Tuples as well to initialize.  I find the biggest problem is the complexity of other libraries by manually copying like this.  Also, I need to figure out how to screen for a tuple so when I \"assign()\" the variables I don't collapse the tuple into a single tensor variable as this was tough to find even in a short segment of code.\r\n\r\nSo I think I might be able to do a short-term solution if needed based upon the comments from @ebrevdo , but I really think if the RNN training is going to force the state to be a tuple then the rest of TensorFlow should help support this new requirement.  Another option is to remove the warning statement and just document that Tuples are handled faster and support both formats moving forward.  I am sure this is an easier solution for now, not sure about the long term support issues as I am sure the team will need to think through.\r\n\r\nHere is what I am talking about when the RNN cells are \"state_is_tuple=True\"\r\n\r\n            self.init_state = self.cell_L1.zero_state(batch_size, tf.float32)\r\n            self.state = tf.Variable(self.init_state, trainable=False)\r\n\r\nIn the code above, this silently functions as you would expect.  The self.state is initialized with the Tuple value from self.init_state, but what you get for self.state is actually a single Tensor variable with the Tuple collapsed.  This causes the RNN functions to fail later as they are expecting a Tuple for the state.\r\n"}