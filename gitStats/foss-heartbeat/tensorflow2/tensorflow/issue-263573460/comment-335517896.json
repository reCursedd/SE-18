{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335517896", "html_url": "https://github.com/tensorflow/tensorflow/issues/13537#issuecomment-335517896", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13537", "id": 335517896, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTUxNzg5Ng==", "user": {"login": "Mazecreator", "id": 18412448, "node_id": "MDQ6VXNlcjE4NDEyNDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/18412448?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mazecreator", "html_url": "https://github.com/Mazecreator", "followers_url": "https://api.github.com/users/Mazecreator/followers", "following_url": "https://api.github.com/users/Mazecreator/following{/other_user}", "gists_url": "https://api.github.com/users/Mazecreator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mazecreator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mazecreator/subscriptions", "organizations_url": "https://api.github.com/users/Mazecreator/orgs", "repos_url": "https://api.github.com/users/Mazecreator/repos", "events_url": "https://api.github.com/users/Mazecreator/events{/privacy}", "received_events_url": "https://api.github.com/users/Mazecreator/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-10T15:47:54Z", "updated_at": "2017-10-10T15:51:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=29663194\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cy89\">@cy89</a> this might do it but it doesn't seem like \"tf.contrib.framework.nest.map_structure()\" exists.  I am using TF1.3 but checked the HEAD and didn't see that \"nest\" folder.  I tried to find if it moved to another location but couldn't find it.</p>\n<p>I am sure this is a good short term solution within the active LSTM graph but will greatly complicate copying variables from one Net to another as the transparency of the .assign() would be appreciated.</p>\n<p>Once we have a short-term solution I will post it on Stack Overflow in response to my open issue.</p>\n<p>Here was my interpretation of the implementation for the LSTM State:</p>\n<pre><code>        output, self.new_state = tf.nn.dynamic_rnn(self.cell_L1,hidden_input,time_major=True,\\\n                initial_state=self.state,  dtype=tf.float32, swap_memory=True)\n\n        self.state = tf.contrib.framework.nest.map_structure(\n                lambda state, var: tf.assign(var, state),\n                self.new_state,\n                #variable_tuple,\n                check_types=False)\n\n        with tf.control_dependencies([self.state]):\n            outputs = tf.identity(output)       \n</code></pre>", "body_text": "@cy89 this might do it but it doesn't seem like \"tf.contrib.framework.nest.map_structure()\" exists.  I am using TF1.3 but checked the HEAD and didn't see that \"nest\" folder.  I tried to find if it moved to another location but couldn't find it.\nI am sure this is a good short term solution within the active LSTM graph but will greatly complicate copying variables from one Net to another as the transparency of the .assign() would be appreciated.\nOnce we have a short-term solution I will post it on Stack Overflow in response to my open issue.\nHere was my interpretation of the implementation for the LSTM State:\n        output, self.new_state = tf.nn.dynamic_rnn(self.cell_L1,hidden_input,time_major=True,\\\n                initial_state=self.state,  dtype=tf.float32, swap_memory=True)\n\n        self.state = tf.contrib.framework.nest.map_structure(\n                lambda state, var: tf.assign(var, state),\n                self.new_state,\n                #variable_tuple,\n                check_types=False)\n\n        with tf.control_dependencies([self.state]):\n            outputs = tf.identity(output)", "body": "@cy89 this might do it but it doesn't seem like \"tf.contrib.framework.nest.map_structure()\" exists.  I am using TF1.3 but checked the HEAD and didn't see that \"nest\" folder.  I tried to find if it moved to another location but couldn't find it.\r\n\r\nI am sure this is a good short term solution within the active LSTM graph but will greatly complicate copying variables from one Net to another as the transparency of the .assign() would be appreciated.\r\n\r\nOnce we have a short-term solution I will post it on Stack Overflow in response to my open issue.\r\n\r\nHere was my interpretation of the implementation for the LSTM State:\r\n\r\n            output, self.new_state = tf.nn.dynamic_rnn(self.cell_L1,hidden_input,time_major=True,\\\r\n                    initial_state=self.state,  dtype=tf.float32, swap_memory=True)\r\n\r\n            self.state = tf.contrib.framework.nest.map_structure(\r\n                    lambda state, var: tf.assign(var, state),\r\n                    self.new_state,\r\n                    #variable_tuple,\r\n                    check_types=False)\r\n\r\n            with tf.control_dependencies([self.state]):\r\n                outputs = tf.identity(output)       "}