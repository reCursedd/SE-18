{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309375713", "html_url": "https://github.com/tensorflow/tensorflow/issues/8181#issuecomment-309375713", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8181", "id": 309375713, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTM3NTcxMw==", "user": {"login": "xiusir", "id": 23228998, "node_id": "MDQ6VXNlcjIzMjI4OTk4", "avatar_url": "https://avatars2.githubusercontent.com/u/23228998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiusir", "html_url": "https://github.com/xiusir", "followers_url": "https://api.github.com/users/xiusir/followers", "following_url": "https://api.github.com/users/xiusir/following{/other_user}", "gists_url": "https://api.github.com/users/xiusir/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiusir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiusir/subscriptions", "organizations_url": "https://api.github.com/users/xiusir/orgs", "repos_url": "https://api.github.com/users/xiusir/repos", "events_url": "https://api.github.com/users/xiusir/events{/privacy}", "received_events_url": "https://api.github.com/users/xiusir/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-19T08:39:42Z", "updated_at": "2017-06-19T08:39:42Z", "author_association": "NONE", "body_html": "<p>Maybe I have the same problem. TensorFlow VERSION  1.1.0<br>\nHas it been fixed in 1.1.0?</p>\n<p>I specifed [\"input\", \"output\"] as the input and output nodes of my model  by tf.identity.<br>\nAfter frozen,  I can found \"input\", \"output\" in graph_def.node.<br>\nAfter optimized, \"input\" is still there, but \"output\" is lost.</p>\n<h1>train.py</h1>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">inference</span>(<span class=\"pl-smi\">images</span>):\n  images <span class=\"pl-k\">=</span> tf.identity(images, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">...</span> <span class=\"pl-c1\">...</span>\n  softmax_linear <span class=\"pl-k\">=</span> tf.identity(softmax_linear, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>)\n  <span class=\"pl-k\">return</span> softmax_linear</pre></div>\n<h1>package.py -- Generate model file</h1>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> -*- coding: utf-8 -*-</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Preparing a TF model for usage in Android</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=missing-docstring</span>\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.tools <span class=\"pl-k\">import</span> freeze_graph\n<span class=\"pl-k\">from</span> tensorflow.python.tools <span class=\"pl-k\">import</span> optimize_for_inference_lib\n\n<span class=\"pl-c1\">MODEL_NAME</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>carc34<span class=\"pl-pds\">'</span></span>\npath<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>\ninput_graph_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>/graph.pbtxt<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> path\ncheckpoint_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>/model.ckpt-100000<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> path\ninput_saver_def_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\ninput_binary <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\ninput_node_names <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>\noutput_node_names <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output,softmax_linear/softmax_linear<span class=\"pl-pds\">\"</span></span>\nrestore_op_name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>save/restore_all<span class=\"pl-pds\">\"</span></span>\nfilename_tensor_name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>save/Const:0<span class=\"pl-pds\">\"</span></span>\noutput_frozen_graph_name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>frozen_<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">MODEL_NAME</span><span class=\"pl-k\">+</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>.pb<span class=\"pl-pds\">'</span></span>\noutput_optimized_graph_name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>optimized_<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">+</span><span class=\"pl-c1\">MODEL_NAME</span><span class=\"pl-k\">+</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>.pb<span class=\"pl-pds\">'</span></span>\nclear_devices <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Freeze the graph</span>\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n                          input_binary, checkpoint_path, output_node_names,\n                          restore_op_name, filename_tensor_name,\n                          output_frozen_graph_name, clear_devices, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Optimize for inference</span>\ninput_graph_def <span class=\"pl-k\">=</span> tf.GraphDef()\n<span class=\"pl-k\">with</span> tf.gfile.Open(output_frozen_graph_name, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>rb<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> f:\n    data <span class=\"pl-k\">=</span> f.read()\n    input_graph_def.ParseFromString(data)\n    output_graph_def <span class=\"pl-k\">=</span> optimize_for_inference_lib.optimize_for_inference(\n                input_graph_def,\n                input_node_names.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>),  <span class=\"pl-c\"><span class=\"pl-c\">#</span> an array of the input node(s)</span>\n                output_node_names.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c\"><span class=\"pl-c\">#</span> an array of the output nodes</span>\n                tf.float32.as_datatype_enum)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Save the optimized graph</span>\nf <span class=\"pl-k\">=</span> tf.gfile.FastGFile(output_optimized_graph_name, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>w<span class=\"pl-pds\">\"</span></span>)\nf.write(output_graph_def.SerializeToString())\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>#tf.train.write_graph(output_graph_def, './', output_optimized_graph_name)   #</span>\n</pre></div>\n<h1>show_nodes.py -- Print all nodes in frozen and optimized</h1>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n<span class=\"pl-k\">import</span> os.path\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.framework <span class=\"pl-k\">import</span> graph_util\n<span class=\"pl-k\">from</span> tensorflow.python.framework <span class=\"pl-k\">import</span> tensor_shape\n<span class=\"pl-k\">from</span> tensorflow.python.platform <span class=\"pl-k\">import</span> gfile\n<span class=\"pl-k\">from</span> tensorflow.python.util <span class=\"pl-k\">import</span> compat\n\n<span class=\"pl-c1\">MODEL_OUTPUT_TENSOR_NAME</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>\n<span class=\"pl-k\">with</span> tf.Graph().as_default() <span class=\"pl-k\">as</span> graph:\n    model_filename <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>frozen_carc34.pb<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">with</span> gfile.FastGFile(model_filename, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n      graph_def <span class=\"pl-k\">=</span> tf.GraphDef()\n      graph_def.ParseFromString(f.read())\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span>#for n in graph_def.node:</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span>#  print (n.name)</span>\n      output_tensor <span class=\"pl-k\">=</span> tf.import_graph_def(graph_def, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">return_elements</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">MODEL_OUTPUT_TENSOR_NAME</span>])\n      <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Found in frozen<span class=\"pl-pds\">\"</span></span>)\n\n    model_filename <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>optimized_carc34.pb<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">with</span> gfile.FastGFile(model_filename, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n      graph_def <span class=\"pl-k\">=</span> tf.GraphDef()\n      graph_def.ParseFromString(f.read())\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span>#for n in graph_def.node:</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span>#  print (n.name)</span>\n      output_tensor <span class=\"pl-k\">=</span> tf.import_graph_def(graph_def, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">return_elements</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">MODEL_OUTPUT_TENSOR_NAME</span>])\n      <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Found in optimized<span class=\"pl-pds\">\"</span></span>)</pre></div>", "body_text": "Maybe I have the same problem. TensorFlow VERSION  1.1.0\nHas it been fixed in 1.1.0?\nI specifed [\"input\", \"output\"] as the input and output nodes of my model  by tf.identity.\nAfter frozen,  I can found \"input\", \"output\" in graph_def.node.\nAfter optimized, \"input\" is still there, but \"output\" is lost.\ntrain.py\ndef inference(images):\n  images = tf.identity(images, 'input')\n... ...\n  softmax_linear = tf.identity(softmax_linear, 'output')\n  return softmax_linear\npackage.py -- Generate model file\n# -*- coding: utf-8 -*-\n# Preparing a TF model for usage in Android\n# pylint: disable=missing-docstring\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport sys\nimport tensorflow as tf\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\nMODEL_NAME = 'carc34'\npath='.'\ninput_graph_path = '%s/graph.pbtxt' % path\ncheckpoint_path = '%s/model.ckpt-100000' % path\ninput_saver_def_path = \"\"\ninput_binary = False\ninput_node_names = \"input\"\noutput_node_names = \"output,softmax_linear/softmax_linear\"\nrestore_op_name = \"save/restore_all\"\nfilename_tensor_name = \"save/Const:0\"\noutput_frozen_graph_name = 'frozen_'+MODEL_NAME+'.pb'\noutput_optimized_graph_name = 'optimized_'+MODEL_NAME+'.pb'\nclear_devices = True\n\n# Freeze the graph\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n                          input_binary, checkpoint_path, output_node_names,\n                          restore_op_name, filename_tensor_name,\n                          output_frozen_graph_name, clear_devices, \"\")\n\n# Optimize for inference\ninput_graph_def = tf.GraphDef()\nwith tf.gfile.Open(output_frozen_graph_name, \"rb\") as f:\n    data = f.read()\n    input_graph_def.ParseFromString(data)\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n                input_graph_def,\n                input_node_names.split(\",\"),  # an array of the input node(s)\n                output_node_names.split(\",\"), # an array of the output nodes\n                tf.float32.as_datatype_enum)\n\n# Save the optimized graph\nf = tf.gfile.FastGFile(output_optimized_graph_name, \"w\")\nf.write(output_graph_def.SerializeToString())\n##tf.train.write_graph(output_graph_def, './', output_optimized_graph_name)   #\n\nshow_nodes.py -- Print all nodes in frozen and optimized\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os.path\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.util import compat\n\nMODEL_OUTPUT_TENSOR_NAME = 'output'\nwith tf.Graph().as_default() as graph:\n    model_filename = os.path.join('.', 'frozen_carc34.pb')\n    with gfile.FastGFile(model_filename, 'rb') as f:\n      graph_def = tf.GraphDef()\n      graph_def.ParseFromString(f.read())\n      ##for n in graph_def.node:\n      ##  print (n.name)\n      output_tensor = tf.import_graph_def(graph_def, name='', return_elements=[MODEL_OUTPUT_TENSOR_NAME])\n      print (\"Found in frozen\")\n\n    model_filename = os.path.join('.', 'optimized_carc34.pb')\n    with gfile.FastGFile(model_filename, 'rb') as f:\n      graph_def = tf.GraphDef()\n      graph_def.ParseFromString(f.read())\n      ##for n in graph_def.node:\n      ##  print (n.name)\n      output_tensor = tf.import_graph_def(graph_def, name='', return_elements=[MODEL_OUTPUT_TENSOR_NAME])\n      print (\"Found in optimized\")", "body": "Maybe I have the same problem. TensorFlow VERSION  1.1.0\r\nHas it been fixed in 1.1.0?\r\n\r\nI specifed [\"input\", \"output\"] as the input and output nodes of my model  by tf.identity.\r\nAfter frozen,  I can found \"input\", \"output\" in graph_def.node.\r\nAfter optimized, \"input\" is still there, but \"output\" is lost.\r\n\r\n# train.py\r\n```python\r\ndef inference(images):\r\n  images = tf.identity(images, 'input')\r\n... ...\r\n  softmax_linear = tf.identity(softmax_linear, 'output')\r\n  return softmax_linear\r\n```\r\n\r\n# package.py -- Generate model file\r\n```python\r\n# -*- coding: utf-8 -*-\r\n# Preparing a TF model for usage in Android\r\n# pylint: disable=missing-docstring\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport sys\r\nimport tensorflow as tf\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\n\r\nMODEL_NAME = 'carc34'\r\npath='.'\r\ninput_graph_path = '%s/graph.pbtxt' % path\r\ncheckpoint_path = '%s/model.ckpt-100000' % path\r\ninput_saver_def_path = \"\"\r\ninput_binary = False\r\ninput_node_names = \"input\"\r\noutput_node_names = \"output,softmax_linear/softmax_linear\"\r\nrestore_op_name = \"save/restore_all\"\r\nfilename_tensor_name = \"save/Const:0\"\r\noutput_frozen_graph_name = 'frozen_'+MODEL_NAME+'.pb'\r\noutput_optimized_graph_name = 'optimized_'+MODEL_NAME+'.pb'\r\nclear_devices = True\r\n\r\n# Freeze the graph\r\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                          input_binary, checkpoint_path, output_node_names,\r\n                          restore_op_name, filename_tensor_name,\r\n                          output_frozen_graph_name, clear_devices, \"\")\r\n\r\n# Optimize for inference\r\ninput_graph_def = tf.GraphDef()\r\nwith tf.gfile.Open(output_frozen_graph_name, \"rb\") as f:\r\n    data = f.read()\r\n    input_graph_def.ParseFromString(data)\r\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n                input_graph_def,\r\n                input_node_names.split(\",\"),  # an array of the input node(s)\r\n                output_node_names.split(\",\"), # an array of the output nodes\r\n                tf.float32.as_datatype_enum)\r\n\r\n# Save the optimized graph\r\nf = tf.gfile.FastGFile(output_optimized_graph_name, \"w\")\r\nf.write(output_graph_def.SerializeToString())\r\n##tf.train.write_graph(output_graph_def, './', output_optimized_graph_name)   #\r\n\r\n```\r\n\r\n# show_nodes.py -- Print all nodes in frozen and optimized\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport os.path\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import graph_util\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.platform import gfile\r\nfrom tensorflow.python.util import compat\r\n\r\nMODEL_OUTPUT_TENSOR_NAME = 'output'\r\nwith tf.Graph().as_default() as graph:\r\n    model_filename = os.path.join('.', 'frozen_carc34.pb')\r\n    with gfile.FastGFile(model_filename, 'rb') as f:\r\n      graph_def = tf.GraphDef()\r\n      graph_def.ParseFromString(f.read())\r\n      ##for n in graph_def.node:\r\n      ##  print (n.name)\r\n      output_tensor = tf.import_graph_def(graph_def, name='', return_elements=[MODEL_OUTPUT_TENSOR_NAME])\r\n      print (\"Found in frozen\")\r\n\r\n    model_filename = os.path.join('.', 'optimized_carc34.pb')\r\n    with gfile.FastGFile(model_filename, 'rb') as f:\r\n      graph_def = tf.GraphDef()\r\n      graph_def.ParseFromString(f.read())\r\n      ##for n in graph_def.node:\r\n      ##  print (n.name)\r\n      output_tensor = tf.import_graph_def(graph_def, name='', return_elements=[MODEL_OUTPUT_TENSOR_NAME])\r\n      print (\"Found in optimized\")\r\n```\r\n"}