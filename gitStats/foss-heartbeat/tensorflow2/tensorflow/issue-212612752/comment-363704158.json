{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363704158", "html_url": "https://github.com/tensorflow/tensorflow/issues/8181#issuecomment-363704158", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8181", "id": 363704158, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzcwNDE1OA==", "user": {"login": "arun-kumark", "id": 13482732, "node_id": "MDQ6VXNlcjEzNDgyNzMy", "avatar_url": "https://avatars1.githubusercontent.com/u/13482732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arun-kumark", "html_url": "https://github.com/arun-kumark", "followers_url": "https://api.github.com/users/arun-kumark/followers", "following_url": "https://api.github.com/users/arun-kumark/following{/other_user}", "gists_url": "https://api.github.com/users/arun-kumark/gists{/gist_id}", "starred_url": "https://api.github.com/users/arun-kumark/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arun-kumark/subscriptions", "organizations_url": "https://api.github.com/users/arun-kumark/orgs", "repos_url": "https://api.github.com/users/arun-kumark/repos", "events_url": "https://api.github.com/users/arun-kumark/events{/privacy}", "received_events_url": "https://api.github.com/users/arun-kumark/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-07T09:11:02Z", "updated_at": "2018-02-07T09:11:39Z", "author_association": "NONE", "body_html": "<p>Hi Xiusir<br>\nI need you help, I am facing the same issue while running the optimize_for_inference.py script.<br>\nMy arguments are as below:</p>\n<p>python optimize_for_inference.py --input=res101_faster_rcnn_iter_5600.pb --output=optimized_graph.pb --input_names=\"input\" --output_names=\"final_result\"</p>\n<p>My pb file is based on Resnet-101. I am sharing my res101_faster_rcnn_iter_5600.ckpt.custom file below to see it's contents:</p>\n<p>`node {<br>\nname: \"Placeholder\"<br>\nop: \"Placeholder\"<br>\nattr {<br>\nkey: \"dtype\"<br>\nvalue {<br>\ntype: DT_FLOAT<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"shape\"<br>\nvalue {<br>\nshape {<br>\ndim {<br>\nsize: 1<br>\n}<br>\ndim {<br>\nsize: -1<br>\n}<br>\ndim {<br>\nsize: -1<br>\n}<br>\ndim {<br>\nsize: 3<br>\n}<br>\n}<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"Placeholder_1\"<br>\nop: \"Placeholder\"<br>\nattr {<br>\nkey: \"dtype\"<br>\nvalue {<br>\ntype: DT_FLOAT<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"shape\"<br>\nvalue {<br>\nshape {<br>\ndim {<br>\nsize: 1<br>\n}<br>\ndim {<br>\nsize: 3<br>\n}<br>\n}<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"Placeholder_2\"<br>\nop: \"Placeholder\"<br>\nattr {<br>\nkey: \"dtype\"<br>\nvalue {<br>\ntype: DT_FLOAT<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"shape\"<br>\nvalue {<br>\nshape {<br>\ndim {<br>\nsize: -1<br>\n}<br>\ndim {<br>\nsize: 5<br>\n}<br>\n}<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"resnet_v1_101/Pad/paddings\"<br>\nop: \"Const\"<br>\nattr {<br>\nkey: \"dtype\"<br>\nvalue {<br>\ntype: DT_INT32<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"value\"<br>\nvalue {<br>\ntensor {<br>\ndtype: DT_INT32<br>\ntensor_shape {<br>\ndim {<br>\nsize: 4<br>\n}<br>\ndim {<br>\nsize: 2<br>\n}<br>\n}<br>\ntensor_content: \"\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"<br>\n}<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"resnet_v1_101/Pad\"<br>\nop: \"Pad\"<br>\ninput: \"Placeholder\"<br>\ninput: \"resnet_v1_101/Pad/paddings\"<br>\nattr {<br>\nkey: \"T\"<br>\nvalue {<br>\ntype: DT_FLOAT<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"Tpaddings\"<br>\nvalue {<br>\ntype: DT_INT32<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/shape\"<br>\nop: \"Const\"<br>\nattr {<br>\nkey: \"_class\"<br>\nvalue {<br>\nlist {<br>\ns: \"loc:@resnet_v1_101/conv1/weights\"<br>\n}<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"dtype\"<br>\nvalue {<br>\ntype: DT_INT32<br>\n}<br>\n}<br>\nattr {<br>\nkey: \"value\"<br>\nvalue {<br>\ntensor {<br>\ndtype: DT_INT32<br>\ntensor_shape {<br>\ndim {<br>\nsize: 4<br>\n}<br>\n}<br>\ntensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\"<br>\n}<br>\n}<br>\n}<br>\n}<br>\nnode {<br>\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/mean\"<br>\nop: \"Const\"<br>\nattr {<br>\nkey: \"_class\"<br>\nvalue {<br>\nlist {<br>\ns: \"loc:@resnet_v1_101/conv1/weights\"<br>\n}<br>\n}<br>\n}</p>\n<p>I am getting tyhe below error :</p>\n<p>__result\" /home/arun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6 return f(*args, **kwds) /home/arun/anaconda3/lib/python3.6/site-packages/h5py/<strong>init</strong>.py:34: FutureWarning: Conversion of the second argument of issubdtype fromfloattonp.floatingis deprecated. In future, it will be treated asnp.float64 == np.dtype(float).type. from ._conv import register_converters as _register_converters Traceback (most recent call last): File \"optimize_for_inference.py\", line 146, in  app.run(main=main, argv=[sys.argv[0]] + unparsed) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run _sys.exit(main(<em>sys.argv[:1] + flags_passthrough)) File \"optimize_for_inference.py\", line 90, in main FLAGS.output_names.split(\",\"), FLAGS.placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py\", line 109, in optimize_for_inference placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py\", line 83, in strip_unused raise KeyError(\"The following input nodes were not found: %s\\n\" % not_found) KeyError: \"The following input nodes were not found: {'input'}\\n\"</em><br>\nPlease help me identifying what arguments you passed to run the script.</p>\n<p>python touch.py -m res101_faster_rcnn_iter_5600.ckpt.meta -o res101_faster_rcnn_iter_5600.pb -b</p>\n<p>and my touch.py has following contents, which I took from some repository:</p>\n<pre><code>#! /usr/bin/python3\n#generate a pb file !\nfrom __future__ import print_function\nimport tensorflow as tf\nimport argparse\nimport os\n\nif __name__ == '__main__':\n\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-m','--model',required=True, type=str, metavar='' ,help=\"model meta graph AKA .ckpt.meta file to start with\")\n    parser.add_argument('-o', '--output_file', type=str, required=True, metavar='',help=\"Where to save the output file \")\n    parser.add_argument('-b','--bin',dest='binary_file',action='store_true', help=\"saves file as binary instead of default text file\")\n    parser.add_argument('-v','--verbose',dest='verbosity',action='store_true',help=\"trigger the verbose output (show tensorflow debug info)\")\n    args = parser.parse_args()\n    #get output dir from output file name\n    output_dir = os.path.dirname(args.output_file)\n    if output_dir == \"\":\n        output_dir=\".\"\n    output_file_name = os.path.basename(args.output_file)\n    #setting verbosity    \n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n    if args.verbosity:\n        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n    print (\"Welcome to tensorflow graph saver\")\n    print (\"loading \",os.path.basename(args.model))\n    #opening a new session\n    with tf.Session() as sess:\n        new_saver = tf.train.import_meta_graph(args.model)\n        new_saver.restore(sess,args.model.replace(\".meta\",\"\") )\n        print (\"model\",os.path.basename(args.model),\"loaded correctly... converting it to graph\")\n        tf.train.write_graph(sess.graph, output_dir ,output_file_name, as_text=not args.binary_file)\n        print(\"conversion done, output file saved as\",args.output_file)\n</code></pre>", "body_text": "Hi Xiusir\nI need you help, I am facing the same issue while running the optimize_for_inference.py script.\nMy arguments are as below:\npython optimize_for_inference.py --input=res101_faster_rcnn_iter_5600.pb --output=optimized_graph.pb --input_names=\"input\" --output_names=\"final_result\"\nMy pb file is based on Resnet-101. I am sharing my res101_faster_rcnn_iter_5600.ckpt.custom file below to see it's contents:\n`node {\nname: \"Placeholder\"\nop: \"Placeholder\"\nattr {\nkey: \"dtype\"\nvalue {\ntype: DT_FLOAT\n}\n}\nattr {\nkey: \"shape\"\nvalue {\nshape {\ndim {\nsize: 1\n}\ndim {\nsize: -1\n}\ndim {\nsize: -1\n}\ndim {\nsize: 3\n}\n}\n}\n}\n}\nnode {\nname: \"Placeholder_1\"\nop: \"Placeholder\"\nattr {\nkey: \"dtype\"\nvalue {\ntype: DT_FLOAT\n}\n}\nattr {\nkey: \"shape\"\nvalue {\nshape {\ndim {\nsize: 1\n}\ndim {\nsize: 3\n}\n}\n}\n}\n}\nnode {\nname: \"Placeholder_2\"\nop: \"Placeholder\"\nattr {\nkey: \"dtype\"\nvalue {\ntype: DT_FLOAT\n}\n}\nattr {\nkey: \"shape\"\nvalue {\nshape {\ndim {\nsize: -1\n}\ndim {\nsize: 5\n}\n}\n}\n}\n}\nnode {\nname: \"resnet_v1_101/Pad/paddings\"\nop: \"Const\"\nattr {\nkey: \"dtype\"\nvalue {\ntype: DT_INT32\n}\n}\nattr {\nkey: \"value\"\nvalue {\ntensor {\ndtype: DT_INT32\ntensor_shape {\ndim {\nsize: 4\n}\ndim {\nsize: 2\n}\n}\ntensor_content: \"\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n}\n}\n}\n}\nnode {\nname: \"resnet_v1_101/Pad\"\nop: \"Pad\"\ninput: \"Placeholder\"\ninput: \"resnet_v1_101/Pad/paddings\"\nattr {\nkey: \"T\"\nvalue {\ntype: DT_FLOAT\n}\n}\nattr {\nkey: \"Tpaddings\"\nvalue {\ntype: DT_INT32\n}\n}\n}\nnode {\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/shape\"\nop: \"Const\"\nattr {\nkey: \"_class\"\nvalue {\nlist {\ns: \"loc:@resnet_v1_101/conv1/weights\"\n}\n}\n}\nattr {\nkey: \"dtype\"\nvalue {\ntype: DT_INT32\n}\n}\nattr {\nkey: \"value\"\nvalue {\ntensor {\ndtype: DT_INT32\ntensor_shape {\ndim {\nsize: 4\n}\n}\ntensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\"\n}\n}\n}\n}\nnode {\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/mean\"\nop: \"Const\"\nattr {\nkey: \"_class\"\nvalue {\nlist {\ns: \"loc:@resnet_v1_101/conv1/weights\"\n}\n}\n}\nI am getting tyhe below error :\n__result\" /home/arun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6 return f(*args, **kwds) /home/arun/anaconda3/lib/python3.6/site-packages/h5py/init.py:34: FutureWarning: Conversion of the second argument of issubdtype fromfloattonp.floatingis deprecated. In future, it will be treated asnp.float64 == np.dtype(float).type. from ._conv import register_converters as _register_converters Traceback (most recent call last): File \"optimize_for_inference.py\", line 146, in  app.run(main=main, argv=[sys.argv[0]] + unparsed) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run _sys.exit(main(sys.argv[:1] + flags_passthrough)) File \"optimize_for_inference.py\", line 90, in main FLAGS.output_names.split(\",\"), FLAGS.placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py\", line 109, in optimize_for_inference placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py\", line 83, in strip_unused raise KeyError(\"The following input nodes were not found: %s\\n\" % not_found) KeyError: \"The following input nodes were not found: {'input'}\\n\"\nPlease help me identifying what arguments you passed to run the script.\npython touch.py -m res101_faster_rcnn_iter_5600.ckpt.meta -o res101_faster_rcnn_iter_5600.pb -b\nand my touch.py has following contents, which I took from some repository:\n#! /usr/bin/python3\n#generate a pb file !\nfrom __future__ import print_function\nimport tensorflow as tf\nimport argparse\nimport os\n\nif __name__ == '__main__':\n\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-m','--model',required=True, type=str, metavar='' ,help=\"model meta graph AKA .ckpt.meta file to start with\")\n    parser.add_argument('-o', '--output_file', type=str, required=True, metavar='',help=\"Where to save the output file \")\n    parser.add_argument('-b','--bin',dest='binary_file',action='store_true', help=\"saves file as binary instead of default text file\")\n    parser.add_argument('-v','--verbose',dest='verbosity',action='store_true',help=\"trigger the verbose output (show tensorflow debug info)\")\n    args = parser.parse_args()\n    #get output dir from output file name\n    output_dir = os.path.dirname(args.output_file)\n    if output_dir == \"\":\n        output_dir=\".\"\n    output_file_name = os.path.basename(args.output_file)\n    #setting verbosity    \n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n    if args.verbosity:\n        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n    print (\"Welcome to tensorflow graph saver\")\n    print (\"loading \",os.path.basename(args.model))\n    #opening a new session\n    with tf.Session() as sess:\n        new_saver = tf.train.import_meta_graph(args.model)\n        new_saver.restore(sess,args.model.replace(\".meta\",\"\") )\n        print (\"model\",os.path.basename(args.model),\"loaded correctly... converting it to graph\")\n        tf.train.write_graph(sess.graph, output_dir ,output_file_name, as_text=not args.binary_file)\n        print(\"conversion done, output file saved as\",args.output_file)", "body": "Hi Xiusir\r\nI need you help, I am facing the same issue while running the optimize_for_inference.py script.\r\nMy arguments are as below:\r\n\r\npython optimize_for_inference.py --input=res101_faster_rcnn_iter_5600.pb --output=optimized_graph.pb --input_names=\"input\" --output_names=\"final_result\"\r\n\r\nMy pb file is based on Resnet-101. I am sharing my res101_faster_rcnn_iter_5600.ckpt.custom file below to see it's contents:\r\n\r\n`node {\r\nname: \"Placeholder\"\r\nop: \"Placeholder\"\r\nattr {\r\nkey: \"dtype\"\r\nvalue {\r\ntype: DT_FLOAT\r\n}\r\n}\r\nattr {\r\nkey: \"shape\"\r\nvalue {\r\nshape {\r\ndim {\r\nsize: 1\r\n}\r\ndim {\r\nsize: -1\r\n}\r\ndim {\r\nsize: -1\r\n}\r\ndim {\r\nsize: 3\r\n}\r\n}\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"Placeholder_1\"\r\nop: \"Placeholder\"\r\nattr {\r\nkey: \"dtype\"\r\nvalue {\r\ntype: DT_FLOAT\r\n}\r\n}\r\nattr {\r\nkey: \"shape\"\r\nvalue {\r\nshape {\r\ndim {\r\nsize: 1\r\n}\r\ndim {\r\nsize: 3\r\n}\r\n}\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"Placeholder_2\"\r\nop: \"Placeholder\"\r\nattr {\r\nkey: \"dtype\"\r\nvalue {\r\ntype: DT_FLOAT\r\n}\r\n}\r\nattr {\r\nkey: \"shape\"\r\nvalue {\r\nshape {\r\ndim {\r\nsize: -1\r\n}\r\ndim {\r\nsize: 5\r\n}\r\n}\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"resnet_v1_101/Pad/paddings\"\r\nop: \"Const\"\r\nattr {\r\nkey: \"dtype\"\r\nvalue {\r\ntype: DT_INT32\r\n}\r\n}\r\nattr {\r\nkey: \"value\"\r\nvalue {\r\ntensor {\r\ndtype: DT_INT32\r\ntensor_shape {\r\ndim {\r\nsize: 4\r\n}\r\ndim {\r\nsize: 2\r\n}\r\n}\r\ntensor_content: \"\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\r\n}\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"resnet_v1_101/Pad\"\r\nop: \"Pad\"\r\ninput: \"Placeholder\"\r\ninput: \"resnet_v1_101/Pad/paddings\"\r\nattr {\r\nkey: \"T\"\r\nvalue {\r\ntype: DT_FLOAT\r\n}\r\n}\r\nattr {\r\nkey: \"Tpaddings\"\r\nvalue {\r\ntype: DT_INT32\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/shape\"\r\nop: \"Const\"\r\nattr {\r\nkey: \"_class\"\r\nvalue {\r\nlist {\r\ns: \"loc:@resnet_v1_101/conv1/weights\"\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"dtype\"\r\nvalue {\r\ntype: DT_INT32\r\n}\r\n}\r\nattr {\r\nkey: \"value\"\r\nvalue {\r\ntensor {\r\ndtype: DT_INT32\r\ntensor_shape {\r\ndim {\r\nsize: 4\r\n}\r\n}\r\ntensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\\003\\000\\000\\000@\\000\\000\\000\"\r\n}\r\n}\r\n}\r\n}\r\nnode {\r\nname: \"resnet_v1_101/conv1/weights/Initializer/truncated_normal/mean\"\r\nop: \"Const\"\r\nattr {\r\nkey: \"_class\"\r\nvalue {\r\nlist {\r\ns: \"loc:@resnet_v1_101/conv1/weights\"\r\n}\r\n}\r\n}\r\n\r\nI am getting tyhe below error :\r\n\r\n__result\" /home/arun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6 return f(*args, **kwds) /home/arun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype fromfloattonp.floatingis deprecated. In future, it will be treated asnp.float64 == np.dtype(float).type. from ._conv import register_converters as _register_converters Traceback (most recent call last): File \"optimize_for_inference.py\", line 146, in <module> app.run(main=main, argv=[sys.argv[0]] + unparsed) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File \"optimize_for_inference.py\", line 90, in main FLAGS.output_names.split(\",\"), FLAGS.placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py\", line 109, in optimize_for_inference placeholder_type_enum) File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py\", line 83, in strip_unused raise KeyError(\"The following input nodes were not found: %s\\n\" % not_found) KeyError: \"The following input nodes were not found: {'input'}\\n\"_\r\nPlease help me identifying what arguments you passed to run the script.\r\n\r\npython touch.py -m res101_faster_rcnn_iter_5600.ckpt.meta -o res101_faster_rcnn_iter_5600.pb -b\r\n\r\nand my touch.py has following contents, which I took from some repository:\r\n\r\n```\r\n#! /usr/bin/python3\r\n#generate a pb file !\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\nimport argparse\r\nimport os\r\n\r\nif __name__ == '__main__':\r\n\r\n\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('-m','--model',required=True, type=str, metavar='' ,help=\"model meta graph AKA .ckpt.meta file to start with\")\r\n    parser.add_argument('-o', '--output_file', type=str, required=True, metavar='',help=\"Where to save the output file \")\r\n    parser.add_argument('-b','--bin',dest='binary_file',action='store_true', help=\"saves file as binary instead of default text file\")\r\n    parser.add_argument('-v','--verbose',dest='verbosity',action='store_true',help=\"trigger the verbose output (show tensorflow debug info)\")\r\n    args = parser.parse_args()\r\n    #get output dir from output file name\r\n    output_dir = os.path.dirname(args.output_file)\r\n    if output_dir == \"\":\r\n        output_dir=\".\"\r\n    output_file_name = os.path.basename(args.output_file)\r\n    #setting verbosity    \r\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n    if args.verbosity:\r\n        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\r\n    print (\"Welcome to tensorflow graph saver\")\r\n    print (\"loading \",os.path.basename(args.model))\r\n    #opening a new session\r\n    with tf.Session() as sess:\r\n        new_saver = tf.train.import_meta_graph(args.model)\r\n        new_saver.restore(sess,args.model.replace(\".meta\",\"\") )\r\n        print (\"model\",os.path.basename(args.model),\"loaded correctly... converting it to graph\")\r\n        tf.train.write_graph(sess.graph, output_dir ,output_file_name, as_text=not args.binary_file)\r\n        print(\"conversion done, output file saved as\",args.output_file)\r\n```"}