{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8529", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8529/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8529/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8529/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8529", "id": 215253598, "node_id": "MDU6SXNzdWUyMTUyNTM1OTg=", "number": 8529, "title": "Compile Tensorflow 1.0 with GPU on RHEL6 / SL6", "user": {"login": "albenoit", "id": 2619976, "node_id": "MDQ6VXNlcjI2MTk5NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2619976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albenoit", "html_url": "https://github.com/albenoit", "followers_url": "https://api.github.com/users/albenoit/followers", "following_url": "https://api.github.com/users/albenoit/following{/other_user}", "gists_url": "https://api.github.com/users/albenoit/gists{/gist_id}", "starred_url": "https://api.github.com/users/albenoit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albenoit/subscriptions", "organizations_url": "https://api.github.com/users/albenoit/orgs", "repos_url": "https://api.github.com/users/albenoit/repos", "events_url": "https://api.github.com/users/albenoit/events{/privacy}", "received_events_url": "https://api.github.com/users/albenoit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2017-03-19T10:03:06Z", "updated_at": "2018-04-02T15:40:45Z", "closed_at": "2017-03-31T18:31:44Z", "author_association": "NONE", "body_html": "<p>Dear all,<br>\ni managed to compile Tensorflow 0.12.1 with GPU option few months ago on our computational grid based on SL6 but moving to version 1.0 is still an issue with trying to activate the GPU support.<br>\nI tried to merge all the advise i could find here but still no success.<br>\nSo here is a summary:</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>This issue is actually close to the ones as <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"203763687\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7118\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7118/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7118\">#7118</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"151104976\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2109\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2109/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2109\">#2109</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"155416689\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2413\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2413/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2413\">#2413</a>, etc.<br>\nMy compilation attempts always show similar error but dealing with different packages. Here is the last example:<br>\n<code>ERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr': this rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/thd_windows.c': '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'. Target //tensorflow/tools/pip_package:build_pip_package failed to build INFO: Elapsed time: 20.467s, Critical Path: 9.90s </code></p>\n<p><strong>Please note that Tensorflow compiles fine if GPU support is not activated. Then, i suspect a missing include option in third_party/gpus/crosstool/CROOSTOOL.tpl or third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl since such options disappeared from version 0.12 such as <code>cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\" </code>but i need some detailled information to fix it.</strong></p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\n<code>RedHat Scientific Linux 6 with kernel 2.6.32-642.13.1.el6.x86_64 </code><br>\nRegarding libc , gcc versions, i rely on the devtoolsets-4.<br>\nUsing the following gcc version:</p>\n<pre><code> gcc -v\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/var/opt/rh/devtoolset-4/root/usr/bin/../libexec/gcc/x86_64-redhat-linux/5.3.1/lto-wrapper\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/opt/rh/devtoolset-4/root/usr --mandir=/opt/rh/devtoolset-4/root/usr/share/man --infodir=/opt/rh/devtoolset-4/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --enable-plugin --with-linker-hash-style=gnu --enable-initfini-array --disable-libgcj --with-default-libstdcxx-abi=gcc4-compatible --with-isl=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/isl-install --enable-libmpx --with-mpc=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/mpc-install --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 5.3.1 20160406 (Red Hat 5.3.1-6) (GCC) \n</code></pre>\n<p>Regarding system variables, here are the specific tunings:</p>\n<pre><code>set path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\nset path=(/usr/local/cuda-8.0/bin $path)\nset path=(/uds_data/listic/install/bazel/output $path)\nset path=(/opt/rh/devtoolset-4/root/usr/bin $path)\nsetenv CC /opt/rh/devtoolset-4/root/usr/bin/gcc\n\nsetenv JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/\nsetenv GRPC_JAVA_PLUGIN /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\n\nsetenv CUDA_HOME /usr/local/cuda-8.0\nsetenv INCLUDE_PATH /usr/local/cuda-8.0/include\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\n\nsetenv LD_LIBRARY_PATH /gpfs/MUST-DATA/listic/install/caffe_must/cudnn_51/cuda/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\n#set path=(/uds_data/listic/install/gcc/build6.2/bin $path)\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'\n\n\n</code></pre>\n<p>Installed version of CUDA and cuDNN: Cuda 8.0 and CuDNN 5.1</p>\n<pre><code>ls /usr/local/cuda-8.0/lib64/libcud*\n/usr/local/cuda-8.0/lib64/libcudadevrt.a\n/usr/local/cuda-8.0/lib64/libcudart.so\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n\n\nls /univ_home/UNIVSOFT/COMMON/cudnn/lib64\nlibcudnn.so  libcudnn.so.5  libcudnn.so.5.1.5  libcudnn_static.a  libm.so\n\n</code></pre>\n<p>Tensorflow is being compiled from source</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n</ol>\n<pre><code>git rev-parse HEAD\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\n</code></pre>\n<ol start=\"2\">\n<li>The output of <code>bazel version</code><br>\nI actually tried with the following bazel versions : 0.4.3, 0.4.4 and 0.4.5 and always got the same errors.</li>\n</ol>\n<pre><code>bazel version\nBuild label: 0.4.3-2017-03-18 (@1d2fb1f)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Sat Mar 18 15:58:41 2017 (1489852721)\nBuild timestamp: 1489852721\nBuild timestamp as int: 1489852721\n\n</code></pre>\n<p>Here are my local code changes to target devtoolsets-4 compiling tools:</p>\n<pre><code>git diff\ndiff --git a/tensorflow/core/platform/default/build_config.bzl b/tensorflow/core\nindex 48ef8df..be831d5 100644\n--- a/tensorflow/core/platform/default/build_config.bzl\n+++ b/tensorflow/core/platform/default/build_config.bzl\n@@ -8,7 +8,7 @@ load(\"//tensorflow:tensorflow.bzl\", \"if_not_mobile\")\n WITH_GCP_SUPPORT = False\n WITH_HDFS_SUPPORT = False\n WITH_XLA_SUPPORT = False\n-WITH_JEMALLOC = True\n+WITH_JEMALLOC = False\n \n # Appends a suffix to a list of deps.\n def tf_deps(deps, suffix):\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\nindex 3788eed..fa5b670 100644\n--- a/tensorflow/tensorflow.bzl\n+++ b/tensorflow/tensorflow.bzl\n@@ -751,7 +751,7 @@ def tf_custom_op_library(name, srcs=[], gpu_srcs=[], deps=[]\n   )\n \n def tf_extension_linkopts():\n-  return []  # No extension link opts\n+  return [\"-lrt\"]  # No extension link opts\n \n def tf_extension_copts():\n   return []  # No extension c opts\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL.tpl b/third_party/gpus/crossto\nindex b77a45c..746817f 100644\n--- a/third_party/gpus/crosstool/CROSSTOOL.tpl\n+++ b/third_party/gpus/crosstool/CROSSTOOL.tpl\n@@ -42,10 +42,10 @@ toolchain {\n   target_system_name: \"local\"\n   toolchain_identifier: \"local_linux\"\n \n-  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\n-  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\n-  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\n-  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\n+  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\n+  tool_path { name: \"compat-ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n+  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\n+  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\n   # As part of the TensorFlow release, we place some cuda-related compilation\n   # files in @local_config_cuda//crosstool/clang/bin, and this relative\n   # path, combined with the rest of our Bazel configuration causes our\n@@ -56,21 +56,23 @@ toolchain {\n   cxx_flag: \"-std=c++11\"\n   linker_flag: \"-Wl,-no-as-needed\"\n   linker_flag: \"-lstdc++\"\n-  linker_flag: \"-B/usr/bin/\"\n+  linker_flag: \"-lm\"\n+  linker_flag: \"-lrt\"\n+  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\n \n %{gcc_host_compiler_includes}\n-  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\n+  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\" }\n \n   # C(++) compiles invoke the compiler (as that is the one knowing where\n   # to find libraries), but we provide LD so other rules can invoke the linker.\n-  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\n+  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n \n-  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\n-  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\n+  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\n+  tool_path { name: \"objcopy\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\"\n   objcopy_embed_flag: \"-I\"\n   objcopy_embed_flag: \"binary\"\n-  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\n-  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\n+  tool_path { name: \"objdump\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objdump\"\n+  tool_path { name: \"strip\" path: \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\n \n   # Anticipated future default.\n   unfiltered_cxx_flag: \"-no-canonical-prefixes\"\ndiff --git a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_no\nindex b7d6cc6..e78b70c 100755\n--- a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\n+++ b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\n@@ -51,7 +51,7 @@ GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n \n CURRENT_DIR = os.path.dirname(sys.argv[0])\n NVCC_PATH = CURRENT_DIR + '/../../../cuda/bin/nvcc'\n-LLVM_HOST_COMPILER_PATH = ('/usr/bin/gcc')\n+LLVM_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\n PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\n NVCC_VERSION = '%{cuda_version}'\n \n(END) \n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Here is my configuration step:</p>\n<pre><code>./configure\nPlease specify the location of python. [Default is /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]: \nPlease specify optimization flags to use during compilation [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] n\njemalloc disabled on Linux\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\n\nUsing python library path: /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]: \nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]: /univ_home/UNIVSOFT/COMMON/cudnn/\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: \n.\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...............\nINFO: All external dependencies fetched successfully.\nConfiguration finished\n</code></pre>\n<p>Next, compiling:</p>\n<pre><code>bazel build --linkopt='-lrt' -c opt --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nINFO: Found 1 target...\nERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr':\nthis rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/tmpfile_windows.c':\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 12.842s, Critical Path: 3.24s\n\n</code></pre>\n<p>This time the error highlights grpc inclusion errors, it used to be related to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9922696\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nasm\">@nasm</a> or others. depending on the trials.</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>Tried bazel version 0.4.3, 0.4.4, 0.4.5 with the same results.<br>\nTried Tensorflow R1.0, v1.0.1, same results</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "Dear all,\ni managed to compile Tensorflow 0.12.1 with GPU option few months ago on our computational grid based on SL6 but moving to version 1.0 is still an issue with trying to activate the GPU support.\nI tried to merge all the advise i could find here but still no success.\nSo here is a summary:\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nThis issue is actually close to the ones as #7118, #2109, #2413, etc.\nMy compilation attempts always show similar error but dealing with different packages. Here is the last example:\nERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr': this rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/thd_windows.c': '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'. Target //tensorflow/tools/pip_package:build_pip_package failed to build INFO: Elapsed time: 20.467s, Critical Path: 9.90s \nPlease note that Tensorflow compiles fine if GPU support is not activated. Then, i suspect a missing include option in third_party/gpus/crosstool/CROOSTOOL.tpl or third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl since such options disappeared from version 0.12 such as cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\" but i need some detailled information to fix it.\nEnvironment info\nOperating System:\nRedHat Scientific Linux 6 with kernel 2.6.32-642.13.1.el6.x86_64 \nRegarding libc , gcc versions, i rely on the devtoolsets-4.\nUsing the following gcc version:\n gcc -v\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/var/opt/rh/devtoolset-4/root/usr/bin/../libexec/gcc/x86_64-redhat-linux/5.3.1/lto-wrapper\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/opt/rh/devtoolset-4/root/usr --mandir=/opt/rh/devtoolset-4/root/usr/share/man --infodir=/opt/rh/devtoolset-4/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --enable-plugin --with-linker-hash-style=gnu --enable-initfini-array --disable-libgcj --with-default-libstdcxx-abi=gcc4-compatible --with-isl=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/isl-install --enable-libmpx --with-mpc=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/mpc-install --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 5.3.1 20160406 (Red Hat 5.3.1-6) (GCC) \n\nRegarding system variables, here are the specific tunings:\nset path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\nset path=(/usr/local/cuda-8.0/bin $path)\nset path=(/uds_data/listic/install/bazel/output $path)\nset path=(/opt/rh/devtoolset-4/root/usr/bin $path)\nsetenv CC /opt/rh/devtoolset-4/root/usr/bin/gcc\n\nsetenv JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/\nsetenv GRPC_JAVA_PLUGIN /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\n\nsetenv CUDA_HOME /usr/local/cuda-8.0\nsetenv INCLUDE_PATH /usr/local/cuda-8.0/include\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\n\nsetenv LD_LIBRARY_PATH /gpfs/MUST-DATA/listic/install/caffe_must/cudnn_51/cuda/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\n#set path=(/uds_data/listic/install/gcc/build6.2/bin $path)\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'\n\n\n\nInstalled version of CUDA and cuDNN: Cuda 8.0 and CuDNN 5.1\nls /usr/local/cuda-8.0/lib64/libcud*\n/usr/local/cuda-8.0/lib64/libcudadevrt.a\n/usr/local/cuda-8.0/lib64/libcudart.so\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n\n\nls /univ_home/UNIVSOFT/COMMON/cudnn/lib64\nlibcudnn.so  libcudnn.so.5  libcudnn.so.5.1.5  libcudnn_static.a  libm.so\n\n\nTensorflow is being compiled from source\n\nThe commit hash (git rev-parse HEAD)\n\ngit rev-parse HEAD\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\n\n\nThe output of bazel version\nI actually tried with the following bazel versions : 0.4.3, 0.4.4 and 0.4.5 and always got the same errors.\n\nbazel version\nBuild label: 0.4.3-2017-03-18 (@1d2fb1f)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Sat Mar 18 15:58:41 2017 (1489852721)\nBuild timestamp: 1489852721\nBuild timestamp as int: 1489852721\n\n\nHere are my local code changes to target devtoolsets-4 compiling tools:\ngit diff\ndiff --git a/tensorflow/core/platform/default/build_config.bzl b/tensorflow/core\nindex 48ef8df..be831d5 100644\n--- a/tensorflow/core/platform/default/build_config.bzl\n+++ b/tensorflow/core/platform/default/build_config.bzl\n@@ -8,7 +8,7 @@ load(\"//tensorflow:tensorflow.bzl\", \"if_not_mobile\")\n WITH_GCP_SUPPORT = False\n WITH_HDFS_SUPPORT = False\n WITH_XLA_SUPPORT = False\n-WITH_JEMALLOC = True\n+WITH_JEMALLOC = False\n \n # Appends a suffix to a list of deps.\n def tf_deps(deps, suffix):\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\nindex 3788eed..fa5b670 100644\n--- a/tensorflow/tensorflow.bzl\n+++ b/tensorflow/tensorflow.bzl\n@@ -751,7 +751,7 @@ def tf_custom_op_library(name, srcs=[], gpu_srcs=[], deps=[]\n   )\n \n def tf_extension_linkopts():\n-  return []  # No extension link opts\n+  return [\"-lrt\"]  # No extension link opts\n \n def tf_extension_copts():\n   return []  # No extension c opts\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL.tpl b/third_party/gpus/crossto\nindex b77a45c..746817f 100644\n--- a/third_party/gpus/crosstool/CROSSTOOL.tpl\n+++ b/third_party/gpus/crosstool/CROSSTOOL.tpl\n@@ -42,10 +42,10 @@ toolchain {\n   target_system_name: \"local\"\n   toolchain_identifier: \"local_linux\"\n \n-  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\n-  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\n-  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\n-  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\n+  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\n+  tool_path { name: \"compat-ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n+  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\n+  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\n   # As part of the TensorFlow release, we place some cuda-related compilation\n   # files in @local_config_cuda//crosstool/clang/bin, and this relative\n   # path, combined with the rest of our Bazel configuration causes our\n@@ -56,21 +56,23 @@ toolchain {\n   cxx_flag: \"-std=c++11\"\n   linker_flag: \"-Wl,-no-as-needed\"\n   linker_flag: \"-lstdc++\"\n-  linker_flag: \"-B/usr/bin/\"\n+  linker_flag: \"-lm\"\n+  linker_flag: \"-lrt\"\n+  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\n \n %{gcc_host_compiler_includes}\n-  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\n+  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\" }\n \n   # C(++) compiles invoke the compiler (as that is the one knowing where\n   # to find libraries), but we provide LD so other rules can invoke the linker.\n-  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\n+  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n \n-  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\n-  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\n+  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\n+  tool_path { name: \"objcopy\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\"\n   objcopy_embed_flag: \"-I\"\n   objcopy_embed_flag: \"binary\"\n-  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\n-  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\n+  tool_path { name: \"objdump\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objdump\"\n+  tool_path { name: \"strip\" path: \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\n \n   # Anticipated future default.\n   unfiltered_cxx_flag: \"-no-canonical-prefixes\"\ndiff --git a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_no\nindex b7d6cc6..e78b70c 100755\n--- a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\n+++ b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\n@@ -51,7 +51,7 @@ GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n \n CURRENT_DIR = os.path.dirname(sys.argv[0])\n NVCC_PATH = CURRENT_DIR + '/../../../cuda/bin/nvcc'\n-LLVM_HOST_COMPILER_PATH = ('/usr/bin/gcc')\n+LLVM_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\n PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\n NVCC_VERSION = '%{cuda_version}'\n \n(END) \n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nHere is my configuration step:\n./configure\nPlease specify the location of python. [Default is /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]: \nPlease specify optimization flags to use during compilation [Default is -march=native]: \nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] n\njemalloc disabled on Linux\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\n\nUsing python library path: /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]: \nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]: /univ_home/UNIVSOFT/COMMON/cudnn/\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: \n.\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...............\nINFO: All external dependencies fetched successfully.\nConfiguration finished\n\nNext, compiling:\nbazel build --linkopt='-lrt' -c opt --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nINFO: Found 1 target...\nERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr':\nthis rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/tmpfile_windows.c':\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 12.842s, Critical Path: 3.24s\n\n\nThis time the error highlights grpc inclusion errors, it used to be related to @nasm or others. depending on the trials.\nWhat other attempted solutions have you tried?\nTried bazel version 0.4.3, 0.4.4, 0.4.5 with the same results.\nTried Tensorflow R1.0, v1.0.1, same results\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "Dear all,\r\ni managed to compile Tensorflow 0.12.1 with GPU option few months ago on our computational grid based on SL6 but moving to version 1.0 is still an issue with trying to activate the GPU support.\r\nI tried to merge all the advise i could find here but still no success.\r\nSo here is a summary:\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nThis issue is actually close to the ones as #7118, #2109, #2413, etc.\r\nMy compilation attempts always show similar error but dealing with different packages. Here is the last example:\r\n`ERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr':\r\nthis rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/thd_windows.c':\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 20.467s, Critical Path: 9.90s\r\n`\r\n\r\n**Please note that Tensorflow compiles fine if GPU support is not activated. Then, i suspect a missing include option in third_party/gpus/crosstool/CROOSTOOL.tpl or third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl since such options disappeared from version 0.12 such as `cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\" `but i need some detailled information to fix it.**\r\n\r\n \r\n### Environment info\r\nOperating System: \r\n`RedHat Scientific Linux 6 with kernel 2.6.32-642.13.1.el6.x86_64\r\n`\r\nRegarding libc , gcc versions, i rely on the devtoolsets-4.\r\nUsing the following gcc version:\r\n```\r\n gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/var/opt/rh/devtoolset-4/root/usr/bin/../libexec/gcc/x86_64-redhat-linux/5.3.1/lto-wrapper\r\nTarget: x86_64-redhat-linux\r\nConfigured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/opt/rh/devtoolset-4/root/usr --mandir=/opt/rh/devtoolset-4/root/usr/share/man --infodir=/opt/rh/devtoolset-4/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --enable-plugin --with-linker-hash-style=gnu --enable-initfini-array --disable-libgcj --with-default-libstdcxx-abi=gcc4-compatible --with-isl=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/isl-install --enable-libmpx --with-mpc=/builddir/build/BUILD/gcc-5.3.1-20160406/obj-x86_64-redhat-linux/mpc-install --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\r\nThread model: posix\r\ngcc version 5.3.1 20160406 (Red Hat 5.3.1-6) (GCC) \r\n```\r\nRegarding system variables, here are the specific tunings:\r\n```\r\nset path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\r\nset path=(/usr/local/cuda-8.0/bin $path)\r\nset path=(/uds_data/listic/install/bazel/output $path)\r\nset path=(/opt/rh/devtoolset-4/root/usr/bin $path)\r\nsetenv CC /opt/rh/devtoolset-4/root/usr/bin/gcc\r\n\r\nsetenv JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/\r\nsetenv GRPC_JAVA_PLUGIN /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\r\n\r\nsetenv CUDA_HOME /usr/local/cuda-8.0\r\nsetenv INCLUDE_PATH /usr/local/cuda-8.0/include\r\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\r\n\r\nsetenv LD_LIBRARY_PATH /gpfs/MUST-DATA/listic/install/caffe_must/cudnn_51/cuda/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\r\n#set path=(/uds_data/listic/install/gcc/build6.2/bin $path)\r\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'\r\n\r\n\r\n```\r\nInstalled version of CUDA and cuDNN: Cuda 8.0 and CuDNN 5.1\r\n```\r\nls /usr/local/cuda-8.0/lib64/libcud*\r\n/usr/local/cuda-8.0/lib64/libcudadevrt.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n\r\n\r\nls /univ_home/UNIVSOFT/COMMON/cudnn/lib64\r\nlibcudnn.so  libcudnn.so.5  libcudnn.so.5.1.5  libcudnn_static.a  libm.so\r\n\r\n```\r\nTensorflow is being compiled from source \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n```\r\ngit rev-parse HEAD\r\ne895d5ca395c2362df4f5c8f08b68501b41f8a98\r\n```\r\n2. The output of `bazel version`\r\nI actually tried with the following bazel versions : 0.4.3, 0.4.4 and 0.4.5 and always got the same errors.\r\n```\r\nbazel version\r\nBuild label: 0.4.3-2017-03-18 (@1d2fb1f)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Sat Mar 18 15:58:41 2017 (1489852721)\r\nBuild timestamp: 1489852721\r\nBuild timestamp as int: 1489852721\r\n\r\n```\r\n\r\nHere are my local code changes to target devtoolsets-4 compiling tools:\r\n\r\n```\r\ngit diff\r\ndiff --git a/tensorflow/core/platform/default/build_config.bzl b/tensorflow/core\r\nindex 48ef8df..be831d5 100644\r\n--- a/tensorflow/core/platform/default/build_config.bzl\r\n+++ b/tensorflow/core/platform/default/build_config.bzl\r\n@@ -8,7 +8,7 @@ load(\"//tensorflow:tensorflow.bzl\", \"if_not_mobile\")\r\n WITH_GCP_SUPPORT = False\r\n WITH_HDFS_SUPPORT = False\r\n WITH_XLA_SUPPORT = False\r\n-WITH_JEMALLOC = True\r\n+WITH_JEMALLOC = False\r\n \r\n # Appends a suffix to a list of deps.\r\n def tf_deps(deps, suffix):\r\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex 3788eed..fa5b670 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -751,7 +751,7 @@ def tf_custom_op_library(name, srcs=[], gpu_srcs=[], deps=[]\r\n   )\r\n \r\n def tf_extension_linkopts():\r\n-  return []  # No extension link opts\r\n+  return [\"-lrt\"]  # No extension link opts\r\n \r\n def tf_extension_copts():\r\n   return []  # No extension c opts\r\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL.tpl b/third_party/gpus/crossto\r\nindex b77a45c..746817f 100644\r\n--- a/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n+++ b/third_party/gpus/crosstool/CROSSTOOL.tpl\r\n@@ -42,10 +42,10 @@ toolchain {\r\n   target_system_name: \"local\"\r\n   toolchain_identifier: \"local_linux\"\r\n \r\n-  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\r\n-  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\r\n-  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\r\n-  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\r\n+  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\r\n+  tool_path { name: \"compat-ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\r\n+  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\r\n+  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\r\n   # As part of the TensorFlow release, we place some cuda-related compilation\r\n   # files in @local_config_cuda//crosstool/clang/bin, and this relative\r\n   # path, combined with the rest of our Bazel configuration causes our\r\n@@ -56,21 +56,23 @@ toolchain {\r\n   cxx_flag: \"-std=c++11\"\r\n   linker_flag: \"-Wl,-no-as-needed\"\r\n   linker_flag: \"-lstdc++\"\r\n-  linker_flag: \"-B/usr/bin/\"\r\n+  linker_flag: \"-lm\"\r\n+  linker_flag: \"-lrt\"\r\n+  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\r\n \r\n %{gcc_host_compiler_includes}\r\n-  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\r\n+  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\" }\r\n \r\n   # C(++) compiles invoke the compiler (as that is the one knowing where\r\n   # to find libraries), but we provide LD so other rules can invoke the linker.\r\n-  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\r\n+  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\r\n \r\n-  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\r\n-  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\r\n+  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\r\n+  tool_path { name: \"objcopy\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\"\r\n   objcopy_embed_flag: \"-I\"\r\n   objcopy_embed_flag: \"binary\"\r\n-  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\r\n-  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\r\n+  tool_path { name: \"objdump\" path: \"/opt/rh/devtoolset-4/root/usr/bin/objdump\"\r\n+  tool_path { name: \"strip\" path: \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\r\n \r\n   # Anticipated future default.\r\n   unfiltered_cxx_flag: \"-no-canonical-prefixes\"\r\ndiff --git a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_no\r\nindex b7d6cc6..e78b70c 100755\r\n--- a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\r\n+++ b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.t\r\n@@ -51,7 +51,7 @@ GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\r\n \r\n CURRENT_DIR = os.path.dirname(sys.argv[0])\r\n NVCC_PATH = CURRENT_DIR + '/../../../cuda/bin/nvcc'\r\n-LLVM_HOST_COMPILER_PATH = ('/usr/bin/gcc')\r\n+LLVM_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\r\n PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\r\n NVCC_VERSION = '%{cuda_version}'\r\n \r\n(END) \r\n```\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nHere is my configuration step:\r\n```\r\n./configure\r\nPlease specify the location of python. [Default is /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]: \r\nPlease specify optimization flags to use during compilation [Default is -march=native]: \r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] n\r\njemalloc disabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\r\n\r\nUsing python library path: /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]: \r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-8.0]: /univ_home/UNIVSOFT/COMMON/cudnn/\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: \r\n.\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n...............\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n```\r\n\r\nNext, compiling:\r\n\r\n```\r\nbazel build --linkopt='-lrt' -c opt --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nINFO: Found 1 target...\r\nERROR: /gpfs/MUST-SHARE/univ_home/alben/.cache/bazel/_bazel_alben/07a9bf809031fe756469f64b1512dee9/external/grpc/BUILD:71:1: undeclared inclusion(s) in rule '@grpc//:gpr':\r\nthis rule is missing dependency declarations for the following files included by 'external/grpc/src/core/lib/support/tmpfile_windows.c':\r\n  '/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 12.842s, Critical Path: 3.24s\r\n\r\n```\r\nThis time the error highlights grpc inclusion errors, it used to be related to @nasm or others. depending on the trials.\r\n\r\n\r\n### What other attempted solutions have you tried?\r\nTried bazel version 0.4.3, 0.4.4, 0.4.5 with the same results.\r\nTried Tensorflow R1.0, v1.0.1, same results\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}