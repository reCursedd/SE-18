{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364652166", "html_url": "https://github.com/tensorflow/tensorflow/issues/8529#issuecomment-364652166", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8529", "id": 364652166, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDY1MjE2Ng==", "user": {"login": "albenoit", "id": 2619976, "node_id": "MDQ6VXNlcjI2MTk5NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2619976?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albenoit", "html_url": "https://github.com/albenoit", "followers_url": "https://api.github.com/users/albenoit/followers", "following_url": "https://api.github.com/users/albenoit/following{/other_user}", "gists_url": "https://api.github.com/users/albenoit/gists{/gist_id}", "starred_url": "https://api.github.com/users/albenoit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albenoit/subscriptions", "organizations_url": "https://api.github.com/users/albenoit/orgs", "repos_url": "https://api.github.com/users/albenoit/repos", "events_url": "https://api.github.com/users/albenoit/events{/privacy}", "received_events_url": "https://api.github.com/users/albenoit/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-10T13:13:52Z", "updated_at": "2018-03-23T17:08:40Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Hi,\nnice to know it helps.\n\nHowever, despite the fact that compilation and installation succeeded, i\nhave trouble when running a tensorflow graph because of a conflict between\ncudnn versions. The error message appears when Tensorflow 1.5 session starts:</div>\n<div class=\"email-quoted-reply\"> 2018-02-08 18:17:27.719349: E\n tensorflow/stream_executor/cuda/cuda_dnn.cc:378] Loaded runtime CuDNN\n library: 7004 (compatibility version 7000) but source was compiled with\n 5105 (compatibility version 5100).  If using a binary install, upgrade your\n CuDNN library to match.  If building from sources, make sure the library\n loaded at runtime matches a compatible version specified during compile\n configuration.</div>\n<div class=\"email-fragment\">But, when running ldd on the tensorflow so file, it points to cudnn7.0.4\nand the trouble seems to come from a link between an old cudnn5.1 and the\ncuda8.0 installation. Strange but our grid maintainers are looking at this\npoint.\n\n*** UPDATE, the problem no more exists with Tensorflow 1.6 !!! ***\n\nThe compilation of Tensorflow 1.6 on REHL SL6 with cuda8.0 and\ncudnn7.0.5 was done this way:\n\nTo make tensorflow build possible  i had to get the devtoolset-4 pakage to\nget an appropriate version of gcc and related build tools.\nThat done, my variables are the following. Some redundancies exist but are\nexplained by requirements of various modules that all need their specific\nkeywords...\nTake care, since bazel requires a lot of space for caching, i had to set\nvariable to a folder with large available space:\nmy .cshrc file (some line being of interest for other topics but may also\nhelp :\n\nsetenv LD_LIBRARY_PATH</div>\n<div class=\"email-quoted-reply\"> /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/#:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/Boost/boost_1_57_0/lib:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/OpenCV/opencv-2.4.10/lib:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/gdal/2.0.0/lib:$LD_LIBRARY_PATH\n set path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\n set path=(/usr/local/cuda-8.0/bin $path)\n set path=(/uds_data/listic/install/bazel/bazel-0.8.0-dist/output/ $path)\n set path=(/opt/rh/devtoolset-4/root/usr/bin $path)\n setenv PYTHONPATH\n \"/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\"\n #:/uds_data/listic/install/caffe_must/caffe_GPU/python/\"\n setenv JAVA_HOME\n /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre\n setenv GRPC_JAVA_PLUGIN\n /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\n #/gpfs/MUST-DATA/listic/install/grpc-java/precompiled/p\n</div>\n<div class=\"email-fragment\">setenv TEST_TMPDIR /tmp/\nsetenv CUDA_HOME /usr/local/cuda-8.0\nsetenv INCLUDE_PATH\n/usr/local/cuda-8.0/include#:/gpfs/MUST-DATA/listic/install/nccl/build/include#:$INCLUDE_PATH\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\nsetenv LD_LIBRARY_PATH\n/gpfs/MUST-DATA/listic/install/mkl-dnn/build/lib:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures\n--ignore_unsupported_sandboxing --genrule_strategy=standalone\n--spawn_strategy=standalone --jobs 8'\n\n\n\nRegarding Bazel, the only way i got it work was to get the 0.9.0-dist\npackage and compile it.</div>\n<div class=\"email-quoted-reply\">    --&gt; get to <a href=\"https://github.com/bazelbuild/bazel/releases\">https://github.com/bazelbuild/bazel/releases</a> and get a\n *-dist version\n    353    14:27    wget\n <a href=\"https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-dist.zip\">https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-dist.zip</a>\n    354    14:28    unzip bazel-0.9.0-dist.zip\n    355    14:28    mkdir bazel-0.9.0-dist\n    356    14:28    cd bazel-0.9.0-dist\n    357    14:28    unzip ../bazel-0.9.0-dist.zip\n    361    14:34    ./compile.sh\n\n    --&gt; once compiled, add bazel to path:\n set path=(//uds_data/listic/install/bazel/bazel-0.9.0-dist/output/bazel\n $path)\n</div>\n<div class=\"email-fragment\">In addition, update/create a .bazelrc file in your home dir with (you\ncertainly need to update your java path)\nbuild --verbose_failures\n--linkopt=-Wl,-rpath,/opt/rh/devtoolset-4/root/usr/lib64\n--linkopt=-Wl,-rpath,/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre/lib/\n--linkopt=-lz --linkopt=-lrt --linkopt=-lm --genrule_strategy=standalone\n--spawn_strategy=standalone --linkopt=-Wl,-rpath,/usr/local/cuda-8.0/lib64/\n\n\n\n\n\nRegarding Tensorflow 1.5, here are my local changes on Tensorflow 1.5 :</div>\n<div class=\"email-quoted-reply\"> diff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\n index bafb562..5d5d554 100644\n --- a/tensorflow/tensorflow.bzl\n +++ b/tensorflow/tensorflow.bzl\n @@ -1264,7 +1264,7 @@ register_extension_info(\n  )\n\n  def tf_extension_linkopts():\n -  return []  # No extension link opts\n +  return [\"-lrt\"]  # No extension link opts\n\n  def tf_extension_copts():\n    return []  # No extension c opts\n diff --git a/tensorflow/tools/git/gen/branch_ref\n b/tensorflow/tools/git/gen/branch_ref\n deleted file mode 100644\n index 8b13789..0000000\n --- a/tensorflow/tools/git/gen/branch_ref\n +++ /dev/null\n @@ -1 +0,0 @@\n -\n diff --git a/tensorflow/tools/git/gen/branch_ref\n b/tensorflow/tools/git/gen/branch_ref\n new file mode 120000\n index 0000000..70ed0ba\n --- /dev/null\n +++ b/tensorflow/tools/git/gen/branch_ref\n @@ -0,0 +1 @@\n\n +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/refs/heads/r1.5\n \\ No newline at end of file\n diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\n deleted file mode 100644\n index 8b13789..0000000\n --- a/tensorflow/tools/git/gen/head\n +++ /dev/null\n @@ -1 +0,0 @@\n -\n diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\n new file mode 120000\n index 0000000..28074d9\n --- /dev/null\n +++ b/tensorflow/tools/git/gen/head\n @@ -0,0 +1 @@\n +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/HEAD\n \\ No newline at end of file\n diff --git a/tensorflow/tools/git/gen/spec.json\n b/tensorflow/tools/git/gen/spec.json\n index 176bbc2..2dbb36c 100644\n --- a/tensorflow/tools/git/gen/spec.json\n +++ b/tensorflow/tools/git/gen/spec.json\n @@ -1,3 +1,5 @@\n  {\n -  \"git\": false\n -}\n +  \"path\": \"/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow\",\n +  \"git\": true,\n +  \"branch\": \"refs/heads/r1.5\"\n +}\n \\ No newline at end of file\n diff --git a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n index 05290d6..7b2e448 100644\n --- a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n +++ b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n @@ -42,10 +42,10 @@ toolchain {\n    target_system_name: \"local\"\n    toolchain_identifier: \"local_linux\"\n\n -  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\n -  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\n -  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\n -  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\n +  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\n +  tool_path { name: \"compat-ld\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n +  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\n +  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\n    # As part of the TensorFlow release, we place some cuda-related\n compilation\n    # files in @local_config_cuda//crosstool/clang/bin, and this relative\n    # path, combined with the rest of our Bazel configuration causes our\n @@ -56,21 +56,23 @@ toolchain {\n    cxx_flag: \"-std=c++11\"\n    linker_flag: \"-Wl,-no-as-needed\"\n    linker_flag: \"-lstdc++\"\n -  linker_flag: \"-B/usr/bin/\"\n +  linker_flag: \"-lm\"\n +  linker_flag: \"-lrt\"\n +  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\n\n  %{host_compiler_includes}\n -  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\n +  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\"\n }\n\n    # C(++) compiles invoke the compiler (as that is the one knowing where\n    # to find libraries), but we provide LD so other rules can invoke the\n linker.\n -  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\n +  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n\n -  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\n -  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\n +  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\n +  tool_path { name: \"objcopy\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\" }\n    objcopy_embed_flag: \"-I\"\n    objcopy_embed_flag: \"binary\"\n -  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\n -  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\n +  tool_path { name: \"objdump\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/objdump\" }\n +  tool_path { name: \"strip\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\n\n    # Anticipated future default.\n    unfiltered_cxx_flag: \"-no-canonical-prefixes\"\n @@ -122,6 +124,11 @@ toolchain {\n\n    # Include directory for cuda headers.\n  %{cuda_include_path}\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include\"\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/include/c++/5.3.1/include\"\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/local/include\"\n +cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/include\"\n +cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\"\n\n    compilation_mode_flags {\n      mode: DBG\n diff --git\n a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n index 2558f46..2d7ff15 100755\n ---\n a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n +++\n b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n @@ -47,7 +47,8 @@ import pipes\n\n  # Template values set by cuda_autoconf.\n  CPU_COMPILER = ('%{cpu_compiler}')\n -GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n +#GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n +GCC_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\n\n  NVCC_PATH = '%{nvcc_path}'\n  PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\n diff --git a/third_party/gpus/cuda_configure.bzl\n b/third_party/gpus/cuda_configure.bzl\n index 31a4bfa..2f8dc81 100644\n --- a/third_party/gpus/cuda_configure.bzl\n +++ b/third_party/gpus/cuda_configure.bzl\n @@ -89,8 +89,7 @@ def _get_cxx_inc_directories_impl(repository_ctx, cc,\n lang_is_cpp):\n    # TODO: We pass -no-canonical-prefixes here to match the compiler flags,\n    #       but in cuda_clang CROSSTOOL file that is a `feature` and we\n should\n    #       handle the case when it's disabled and no flag is passed\n -  result = repository_ctx.execute([cc, \"-no-canonical-prefixes\",\n -                                   \"-E\", \"-x\" + lang, \"-\", \"-v\"])\n +  result = repository_ctx.execute([cc,\"-E\", \"-x\" + lang, \"-\", \"-v\"])\n    index1 = result.stderr.find(_INC_DIR_MARKER_BEGIN)\n    if index1 == -1:\n      return []\n</div>\n<div class=\"email-fragment\">Regarding configure setup:</div>\n<div class=\"email-quoted-reply\"> ***@***.*** tensorflow]$ ./configure\n INFO: $TEST_TMPDIR defined: output root default is '/tmp/'.\n You have bazel 0.8.0- ***@***.***) installed.\n Please specify the location of python. [Default is\n /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]:\n\n\n Found possible Python library paths:\n   /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\n Please input the desired Python library path to use.  Default is\n [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\n\n Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n\n No jemalloc as malloc support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]:\n n\n No Google Cloud Platform support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\n No Hadoop File System support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]:\n n\n No Amazon S3 File System support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with XLA JIT support? [y/N]: y\n XLA JIT support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with GDR support? [y/N]: n\n No GDR support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with VERBS support? [y/N]: n\n No VERBS support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\n No OpenCL SYCL support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with CUDA support? [y/N]: y\n CUDA support will be enabled for TensorFlow.\n\n Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave\n empty to default to CUDA 9.0]: 8.0\n\n\n Please specify the location where CUDA 8.0 toolkit is installed. Refer to\n README.md for more details. [Default is /usr/local/cuda]:\n /usr/local/cuda-8.0\n\n\n Please specify the cuDNN version you want to use. [Leave empty to default\n to cuDNN 7.0]: 7\n\n\n Please specify the location where cuDNN 7 library is installed. Refer to\n README.md for more details. [Default is\n /usr/local/cuda-8.0]:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5\n\n\n Please specify a list of comma-separated Cuda compute capabilities you\n want to build with.\n You can find the compute capability of your device at:\n <a href=\"https://developer.nvidia.com/cuda-gpus\">https://developer.nvidia.com/cuda-gpus</a>.\n Please note that each additional compute capability significantly\n increases your build time and binary size. [Default is: 3.7,3.7]\n\n\n Do you want to use clang as CUDA compiler? [y/N]:\n nvcc will be used as CUDA compiler.\n\n Please specify which gcc should be used by nvcc as the host compiler.\n [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]:\n\n\n Do you wish to build TensorFlow with MPI support? [y/N]:\n No MPI support will be enabled for TensorFlow.\n\n Please specify optimization flags to use during compilation when bazel\n option \"--config=opt\" is specified [Default is -march=native]:\n\n\n Add \"--config=mkl\" to your bazel command to build with MKL support.\n Please note that MKL on MacOS or windows is still not supported.\n If you would like to use a local MKL instead of downloading, please set\n the environment variable \"TF_MKL_ROOT\" every time before build.\n\n Would you like to interactively configure ./WORKSPACE for Android builds?\n [y/N]:\n Not configuring the WORKSPACE for Android builds.\n\n Configuration finished\n</div>\n<div class=\"email-fragment\">Now the build command:</div>\n<div class=\"email-quoted-reply\"> bazel build --config=mkl --linkopt='-lrt' -c opt --copt=-mavx\n --copt=-mavx2 --copt=-msse4.2 --copt=-msse4.1 --copt=-mfma --copt=-msse3\n --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone\n //tensorflow/tools/pip_package:build_pip_package\n</div>\n<div class=\"email-fragment\">And the final package creation:</div>\n<div class=\"email-quoted-reply\">  bazel-bin/tensorflow/tools/pip_package/build_pip_package\n /tmp/tensorflow_pkg\n</div>\n<div class=\"email-fragment\">UPDATE : adding graph update capabilities:</div>\n<div class=\"email-quoted-reply\"> bazel build tensorflow/tools/graph_transforms:transform_graph\n I really hope it helps.</div>\n<div class=\"email-fragment\">Alex\n\n2018-02-10 13:44 GMT+01:00 lucy-itjob &lt;notifications@github.com&gt;:</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\"> Alex,\n\n Thank you for all this information.\n\n I am new in this area. To me, you are the first one land on the moon in\n this area, I am still on the earth, and pulling my hair to get this\n Tensorflow working on RHEL6, hoping some day I can land on the moon just\n like you did.\n\n Can you do me a favor? I know you had listed your local customized files\n which modified by you in previously email chain, could you please sent all\n the your local customized files (Bazel and Tensorflow) which modified by\n you to me directly, my email is ***@***.*** could you please\n include Crosstool files for current and previous version (give me the\n current version name and download url) too ? So that I can use the code to\n compare my environment based on your files.\n\n You know, to be able to walk on the moon, it is not easy since there are\n no Tensorflow vendor support on RHEL6.\n\n Alex, I attach an picture for you to enjoy! Thanks a lot\n [image: image]\n &lt;<a href=\"https://user-images.githubusercontent.com/25250352/36062221-4b206a64-0e2d-11e8-87bc-ec48874097a9.png\">https://user-images.githubusercontent.com/25250352/36062221-4b206a64-0e2d-11e8-87bc-ec48874097a9.png</a>&gt;\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"215253598\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8529\" href=\"https://github.com/tensorflow/tensorflow/issues/8529#issuecomment-364649132\">#8529 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ACf6SPNswb4TaN4ozMc6FfsbQDu_nXFDks5tTY9JgaJpZM4Mhr7n\">https://github.com/notifications/unsubscribe-auth/ACf6SPNswb4TaN4ozMc6FfsbQDu_nXFDks5tTY9JgaJpZM4Mhr7n</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nAlexandre BENOIT,\nAssociate Professor / Ma\u00eetre de Conf\u00e9rence\nImage processing and visual scene classification,\nLISTIC Lab / IUT Annecy\n<a href=\"https://sites.google.com/site/benoitalexandrevision/\">https://sites.google.com/site/benoitalexandrevision/</a>\n</div>\n</div>", "body_text": "Hi,\nnice to know it helps.\n\nHowever, despite the fact that compilation and installation succeeded, i\nhave trouble when running a tensorflow graph because of a conflict between\ncudnn versions. The error message appears when Tensorflow 1.5 session starts:\n 2018-02-08 18:17:27.719349: E\n tensorflow/stream_executor/cuda/cuda_dnn.cc:378] Loaded runtime CuDNN\n library: 7004 (compatibility version 7000) but source was compiled with\n 5105 (compatibility version 5100).  If using a binary install, upgrade your\n CuDNN library to match.  If building from sources, make sure the library\n loaded at runtime matches a compatible version specified during compile\n configuration.\nBut, when running ldd on the tensorflow so file, it points to cudnn7.0.4\nand the trouble seems to come from a link between an old cudnn5.1 and the\ncuda8.0 installation. Strange but our grid maintainers are looking at this\npoint.\n\n*** UPDATE, the problem no more exists with Tensorflow 1.6 !!! ***\n\nThe compilation of Tensorflow 1.6 on REHL SL6 with cuda8.0 and\ncudnn7.0.5 was done this way:\n\nTo make tensorflow build possible  i had to get the devtoolset-4 pakage to\nget an appropriate version of gcc and related build tools.\nThat done, my variables are the following. Some redundancies exist but are\nexplained by requirements of various modules that all need their specific\nkeywords...\nTake care, since bazel requires a lot of space for caching, i had to set\nvariable to a folder with large available space:\nmy .cshrc file (some line being of interest for other topics but may also\nhelp :\n\nsetenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/#:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/Boost/boost_1_57_0/lib:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/OpenCV/opencv-2.4.10/lib:$LD_LIBRARY_PATH\n setenv LD_LIBRARY_PATH\n /univ_home/UNIVSOFT/COMMON/gdal/2.0.0/lib:$LD_LIBRARY_PATH\n set path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\n set path=(/usr/local/cuda-8.0/bin $path)\n set path=(/uds_data/listic/install/bazel/bazel-0.8.0-dist/output/ $path)\n set path=(/opt/rh/devtoolset-4/root/usr/bin $path)\n setenv PYTHONPATH\n \"/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\"\n #:/uds_data/listic/install/caffe_must/caffe_GPU/python/\"\n setenv JAVA_HOME\n /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre\n setenv GRPC_JAVA_PLUGIN\n /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\n #/gpfs/MUST-DATA/listic/install/grpc-java/precompiled/p\n\nsetenv TEST_TMPDIR /tmp/\nsetenv CUDA_HOME /usr/local/cuda-8.0\nsetenv INCLUDE_PATH\n/usr/local/cuda-8.0/include#:/gpfs/MUST-DATA/listic/install/nccl/build/include#:$INCLUDE_PATH\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\nsetenv LD_LIBRARY_PATH\n/gpfs/MUST-DATA/listic/install/mkl-dnn/build/lib:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures\n--ignore_unsupported_sandboxing --genrule_strategy=standalone\n--spawn_strategy=standalone --jobs 8'\n\n\n\nRegarding Bazel, the only way i got it work was to get the 0.9.0-dist\npackage and compile it.\n    --> get to https://github.com/bazelbuild/bazel/releases and get a\n *-dist version\n    353    14:27    wget\n https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-dist.zip\n    354    14:28    unzip bazel-0.9.0-dist.zip\n    355    14:28    mkdir bazel-0.9.0-dist\n    356    14:28    cd bazel-0.9.0-dist\n    357    14:28    unzip ../bazel-0.9.0-dist.zip\n    361    14:34    ./compile.sh\n\n    --> once compiled, add bazel to path:\n set path=(//uds_data/listic/install/bazel/bazel-0.9.0-dist/output/bazel\n $path)\n\nIn addition, update/create a .bazelrc file in your home dir with (you\ncertainly need to update your java path)\nbuild --verbose_failures\n--linkopt=-Wl,-rpath,/opt/rh/devtoolset-4/root/usr/lib64\n--linkopt=-Wl,-rpath,/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre/lib/\n--linkopt=-lz --linkopt=-lrt --linkopt=-lm --genrule_strategy=standalone\n--spawn_strategy=standalone --linkopt=-Wl,-rpath,/usr/local/cuda-8.0/lib64/\n\n\n\n\n\nRegarding Tensorflow 1.5, here are my local changes on Tensorflow 1.5 :\n diff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\n index bafb562..5d5d554 100644\n --- a/tensorflow/tensorflow.bzl\n +++ b/tensorflow/tensorflow.bzl\n @@ -1264,7 +1264,7 @@ register_extension_info(\n  )\n\n  def tf_extension_linkopts():\n -  return []  # No extension link opts\n +  return [\"-lrt\"]  # No extension link opts\n\n  def tf_extension_copts():\n    return []  # No extension c opts\n diff --git a/tensorflow/tools/git/gen/branch_ref\n b/tensorflow/tools/git/gen/branch_ref\n deleted file mode 100644\n index 8b13789..0000000\n --- a/tensorflow/tools/git/gen/branch_ref\n +++ /dev/null\n @@ -1 +0,0 @@\n -\n diff --git a/tensorflow/tools/git/gen/branch_ref\n b/tensorflow/tools/git/gen/branch_ref\n new file mode 120000\n index 0000000..70ed0ba\n --- /dev/null\n +++ b/tensorflow/tools/git/gen/branch_ref\n @@ -0,0 +1 @@\n\n +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/refs/heads/r1.5\n \\ No newline at end of file\n diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\n deleted file mode 100644\n index 8b13789..0000000\n --- a/tensorflow/tools/git/gen/head\n +++ /dev/null\n @@ -1 +0,0 @@\n -\n diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\n new file mode 120000\n index 0000000..28074d9\n --- /dev/null\n +++ b/tensorflow/tools/git/gen/head\n @@ -0,0 +1 @@\n +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/HEAD\n \\ No newline at end of file\n diff --git a/tensorflow/tools/git/gen/spec.json\n b/tensorflow/tools/git/gen/spec.json\n index 176bbc2..2dbb36c 100644\n --- a/tensorflow/tools/git/gen/spec.json\n +++ b/tensorflow/tools/git/gen/spec.json\n @@ -1,3 +1,5 @@\n  {\n -  \"git\": false\n -}\n +  \"path\": \"/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow\",\n +  \"git\": true,\n +  \"branch\": \"refs/heads/r1.5\"\n +}\n \\ No newline at end of file\n diff --git a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n index 05290d6..7b2e448 100644\n --- a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n +++ b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\n @@ -42,10 +42,10 @@ toolchain {\n    target_system_name: \"local\"\n    toolchain_identifier: \"local_linux\"\n\n -  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\n -  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\n -  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\n -  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\n +  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\n +  tool_path { name: \"compat-ld\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n +  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\n +  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\n    # As part of the TensorFlow release, we place some cuda-related\n compilation\n    # files in @local_config_cuda//crosstool/clang/bin, and this relative\n    # path, combined with the rest of our Bazel configuration causes our\n @@ -56,21 +56,23 @@ toolchain {\n    cxx_flag: \"-std=c++11\"\n    linker_flag: \"-Wl,-no-as-needed\"\n    linker_flag: \"-lstdc++\"\n -  linker_flag: \"-B/usr/bin/\"\n +  linker_flag: \"-lm\"\n +  linker_flag: \"-lrt\"\n +  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\n\n  %{host_compiler_includes}\n -  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\n +  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\"\n }\n\n    # C(++) compiles invoke the compiler (as that is the one knowing where\n    # to find libraries), but we provide LD so other rules can invoke the\n linker.\n -  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\n +  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\n\n -  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\n -  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\n +  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\n +  tool_path { name: \"objcopy\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\" }\n    objcopy_embed_flag: \"-I\"\n    objcopy_embed_flag: \"binary\"\n -  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\n -  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\n +  tool_path { name: \"objdump\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/objdump\" }\n +  tool_path { name: \"strip\" path:\n \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\n\n    # Anticipated future default.\n    unfiltered_cxx_flag: \"-no-canonical-prefixes\"\n @@ -122,6 +124,11 @@ toolchain {\n\n    # Include directory for cuda headers.\n  %{cuda_include_path}\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include\"\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/include/c++/5.3.1/include\"\n +cxx_builtin_include_directory:\n \"/opt/rh/devtoolset-4/root/usr/local/include\"\n +cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/include\"\n +cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\"\n\n    compilation_mode_flags {\n      mode: DBG\n diff --git\n a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n index 2558f46..2d7ff15 100755\n ---\n a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n +++\n b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\n @@ -47,7 +47,8 @@ import pipes\n\n  # Template values set by cuda_autoconf.\n  CPU_COMPILER = ('%{cpu_compiler}')\n -GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n +#GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\n +GCC_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\n\n  NVCC_PATH = '%{nvcc_path}'\n  PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\n diff --git a/third_party/gpus/cuda_configure.bzl\n b/third_party/gpus/cuda_configure.bzl\n index 31a4bfa..2f8dc81 100644\n --- a/third_party/gpus/cuda_configure.bzl\n +++ b/third_party/gpus/cuda_configure.bzl\n @@ -89,8 +89,7 @@ def _get_cxx_inc_directories_impl(repository_ctx, cc,\n lang_is_cpp):\n    # TODO: We pass -no-canonical-prefixes here to match the compiler flags,\n    #       but in cuda_clang CROSSTOOL file that is a `feature` and we\n should\n    #       handle the case when it's disabled and no flag is passed\n -  result = repository_ctx.execute([cc, \"-no-canonical-prefixes\",\n -                                   \"-E\", \"-x\" + lang, \"-\", \"-v\"])\n +  result = repository_ctx.execute([cc,\"-E\", \"-x\" + lang, \"-\", \"-v\"])\n    index1 = result.stderr.find(_INC_DIR_MARKER_BEGIN)\n    if index1 == -1:\n      return []\n\nRegarding configure setup:\n ***@***.*** tensorflow]$ ./configure\n INFO: $TEST_TMPDIR defined: output root default is '/tmp/'.\n You have bazel 0.8.0- ***@***.***) installed.\n Please specify the location of python. [Default is\n /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]:\n\n\n Found possible Python library paths:\n   /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\n Please input the desired Python library path to use.  Default is\n [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\n\n Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n\n No jemalloc as malloc support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]:\n n\n No Google Cloud Platform support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\n No Hadoop File System support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]:\n n\n No Amazon S3 File System support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with XLA JIT support? [y/N]: y\n XLA JIT support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with GDR support? [y/N]: n\n No GDR support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with VERBS support? [y/N]: n\n No VERBS support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\n No OpenCL SYCL support will be enabled for TensorFlow.\n\n Do you wish to build TensorFlow with CUDA support? [y/N]: y\n CUDA support will be enabled for TensorFlow.\n\n Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave\n empty to default to CUDA 9.0]: 8.0\n\n\n Please specify the location where CUDA 8.0 toolkit is installed. Refer to\n README.md for more details. [Default is /usr/local/cuda]:\n /usr/local/cuda-8.0\n\n\n Please specify the cuDNN version you want to use. [Leave empty to default\n to cuDNN 7.0]: 7\n\n\n Please specify the location where cuDNN 7 library is installed. Refer to\n README.md for more details. [Default is\n /usr/local/cuda-8.0]:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5\n\n\n Please specify a list of comma-separated Cuda compute capabilities you\n want to build with.\n You can find the compute capability of your device at:\n https://developer.nvidia.com/cuda-gpus.\n Please note that each additional compute capability significantly\n increases your build time and binary size. [Default is: 3.7,3.7]\n\n\n Do you want to use clang as CUDA compiler? [y/N]:\n nvcc will be used as CUDA compiler.\n\n Please specify which gcc should be used by nvcc as the host compiler.\n [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]:\n\n\n Do you wish to build TensorFlow with MPI support? [y/N]:\n No MPI support will be enabled for TensorFlow.\n\n Please specify optimization flags to use during compilation when bazel\n option \"--config=opt\" is specified [Default is -march=native]:\n\n\n Add \"--config=mkl\" to your bazel command to build with MKL support.\n Please note that MKL on MacOS or windows is still not supported.\n If you would like to use a local MKL instead of downloading, please set\n the environment variable \"TF_MKL_ROOT\" every time before build.\n\n Would you like to interactively configure ./WORKSPACE for Android builds?\n [y/N]:\n Not configuring the WORKSPACE for Android builds.\n\n Configuration finished\n\nNow the build command:\n bazel build --config=mkl --linkopt='-lrt' -c opt --copt=-mavx\n --copt=-mavx2 --copt=-msse4.2 --copt=-msse4.1 --copt=-mfma --copt=-msse3\n --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone\n //tensorflow/tools/pip_package:build_pip_package\n\nAnd the final package creation:\n  bazel-bin/tensorflow/tools/pip_package/build_pip_package\n /tmp/tensorflow_pkg\n\nUPDATE : adding graph update capabilities:\n bazel build tensorflow/tools/graph_transforms:transform_graph\n I really hope it helps.\nAlex\n\n2018-02-10 13:44 GMT+01:00 lucy-itjob <notifications@github.com>:\n\u2026\n Alex,\n\n Thank you for all this information.\n\n I am new in this area. To me, you are the first one land on the moon in\n this area, I am still on the earth, and pulling my hair to get this\n Tensorflow working on RHEL6, hoping some day I can land on the moon just\n like you did.\n\n Can you do me a favor? I know you had listed your local customized files\n which modified by you in previously email chain, could you please sent all\n the your local customized files (Bazel and Tensorflow) which modified by\n you to me directly, my email is ***@***.*** could you please\n include Crosstool files for current and previous version (give me the\n current version name and download url) too ? So that I can use the code to\n compare my environment based on your files.\n\n You know, to be able to walk on the moon, it is not easy since there are\n no Tensorflow vendor support on RHEL6.\n\n Alex, I attach an picture for you to enjoy! Thanks a lot\n [image: image]\n <https://user-images.githubusercontent.com/25250352/36062221-4b206a64-0e2d-11e8-87bc-ec48874097a9.png>\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#8529 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ACf6SPNswb4TaN4ozMc6FfsbQDu_nXFDks5tTY9JgaJpZM4Mhr7n>\n .\n\n\n-- \nAlexandre BENOIT,\nAssociate Professor / Ma\u00eetre de Conf\u00e9rence\nImage processing and visual scene classification,\nLISTIC Lab / IUT Annecy\nhttps://sites.google.com/site/benoitalexandrevision/", "body": "Hi,\r\nnice to know it helps.\r\n\r\nHowever, despite the fact that compilation and installation succeeded, i\r\nhave trouble when running a tensorflow graph because of a conflict between\r\ncudnn versions. The error message appears when Tensorflow 1.5 session starts:\r\n\r\n> 2018-02-08 18:17:27.719349: E\r\n> tensorflow/stream_executor/cuda/cuda_dnn.cc:378] Loaded runtime CuDNN\r\n> library: 7004 (compatibility version 7000) but source was compiled with\r\n> 5105 (compatibility version 5100).  If using a binary install, upgrade your\r\n> CuDNN library to match.  If building from sources, make sure the library\r\n> loaded at runtime matches a compatible version specified during compile\r\n> configuration.\r\n\r\nBut, when running ldd on the tensorflow so file, it points to cudnn7.0.4\r\nand the trouble seems to come from a link between an old cudnn5.1 and the\r\ncuda8.0 installation. Strange but our grid maintainers are looking at this\r\npoint.\r\n\r\n*** UPDATE, the problem no more exists with Tensorflow 1.6 !!! ***\r\n\r\nThe compilation of Tensorflow 1.6 on REHL SL6 with cuda8.0 and\r\ncudnn7.0.5 was done this way:\r\n\r\nTo make tensorflow build possible  i had to get the devtoolset-4 pakage to\r\nget an appropriate version of gcc and related build tools.\r\nThat done, my variables are the following. Some redundancies exist but are\r\nexplained by requirements of various modules that all need their specific\r\nkeywords...\r\nTake care, since bazel requires a lot of space for caching, i had to set\r\nvariable to a folder with large available space:\r\nmy .cshrc file (some line being of interest for other topics but may also\r\nhelp :\r\n\r\nsetenv LD_LIBRARY_PATH\r\n> /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/#:$LD_LIBRARY_PATH\r\n> setenv LD_LIBRARY_PATH\r\n> /univ_home/UNIVSOFT/COMMON/Boost/boost_1_57_0/lib:$LD_LIBRARY_PATH\r\n> setenv LD_LIBRARY_PATH\r\n> /univ_home/UNIVSOFT/COMMON/OpenCV/opencv-2.4.10/lib:$LD_LIBRARY_PATH\r\n> setenv LD_LIBRARY_PATH\r\n> /univ_home/UNIVSOFT/COMMON/gdal/2.0.0/lib:$LD_LIBRARY_PATH\r\n> set path=(/univ_home/UNIVSOFT/COMMON/python/2.7.6/bin $path)\r\n> set path=(/usr/local/cuda-8.0/bin $path)\r\n> set path=(/uds_data/listic/install/bazel/bazel-0.8.0-dist/output/ $path)\r\n> set path=(/opt/rh/devtoolset-4/root/usr/bin $path)\r\n> setenv PYTHONPATH\r\n> \"/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\"\r\n> #:/uds_data/listic/install/caffe_must/caffe_GPU/python/\"\r\n> setenv JAVA_HOME\r\n> /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre\r\n> setenv GRPC_JAVA_PLUGIN\r\n> /gpfs/MUST-DATA/listic/install/grpc/protoc-gen-grpc-java-0.15.0-linux-x86_64.exe\r\n> #/gpfs/MUST-DATA/listic/install/grpc-java/precompiled/p\r\n>\r\nsetenv TEST_TMPDIR /tmp/\r\nsetenv CUDA_HOME /usr/local/cuda-8.0\r\nsetenv INCLUDE_PATH\r\n/usr/local/cuda-8.0/include#:/gpfs/MUST-DATA/listic/install/nccl/build/include#:$INCLUDE_PATH\r\nsetenv LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\r\nsetenv LD_LIBRARY_PATH\r\n/gpfs/MUST-DATA/listic/install/mkl-dnn/build/lib:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/opt/rh/devtoolset-4/root/usr/lib:$LD_LIBRARY_PATH\r\nsetenv EXTRA_BAZEL_ARGS '-s --verbose_failures\r\n--ignore_unsupported_sandboxing --genrule_strategy=standalone\r\n--spawn_strategy=standalone --jobs 8'\r\n\r\n\r\n\r\nRegarding Bazel, the only way i got it work was to get the 0.9.0-dist\r\npackage and compile it.\r\n\r\n>    --> get to https://github.com/bazelbuild/bazel/releases and get a\r\n> *-dist version\r\n>    353    14:27    wget\r\n> https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-dist.zip\r\n>    354    14:28    unzip bazel-0.9.0-dist.zip\r\n>    355    14:28    mkdir bazel-0.9.0-dist\r\n>    356    14:28    cd bazel-0.9.0-dist\r\n>    357    14:28    unzip ../bazel-0.9.0-dist.zip\r\n>    361    14:34    ./compile.sh\r\n>\r\n>    --> once compiled, add bazel to path:\r\n> set path=(//uds_data/listic/install/bazel/bazel-0.9.0-dist/output/bazel\r\n> $path)\r\n>\r\nIn addition, update/create a .bazelrc file in your home dir with (you\r\ncertainly need to update your java path)\r\nbuild --verbose_failures\r\n--linkopt=-Wl,-rpath,/opt/rh/devtoolset-4/root/usr/lib64\r\n--linkopt=-Wl,-rpath,/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-0.b15.el6_8.x86_64/jre/lib/\r\n--linkopt=-lz --linkopt=-lrt --linkopt=-lm --genrule_strategy=standalone\r\n--spawn_strategy=standalone --linkopt=-Wl,-rpath,/usr/local/cuda-8.0/lib64/\r\n\r\n\r\n\r\n\r\n\r\nRegarding Tensorflow 1.5, here are my local changes on Tensorflow 1.5 :\r\n\r\n> diff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\n> index bafb562..5d5d554 100644\r\n> --- a/tensorflow/tensorflow.bzl\r\n> +++ b/tensorflow/tensorflow.bzl\r\n> @@ -1264,7 +1264,7 @@ register_extension_info(\r\n>  )\r\n>\r\n>  def tf_extension_linkopts():\r\n> -  return []  # No extension link opts\r\n> +  return [\"-lrt\"]  # No extension link opts\r\n>\r\n>  def tf_extension_copts():\r\n>    return []  # No extension c opts\r\n> diff --git a/tensorflow/tools/git/gen/branch_ref\r\n> b/tensorflow/tools/git/gen/branch_ref\r\n> deleted file mode 100644\r\n> index 8b13789..0000000\r\n> --- a/tensorflow/tools/git/gen/branch_ref\r\n> +++ /dev/null\r\n> @@ -1 +0,0 @@\r\n> -\r\n> diff --git a/tensorflow/tools/git/gen/branch_ref\r\n> b/tensorflow/tools/git/gen/branch_ref\r\n> new file mode 120000\r\n> index 0000000..70ed0ba\r\n> --- /dev/null\r\n> +++ b/tensorflow/tools/git/gen/branch_ref\r\n> @@ -0,0 +1 @@\r\n>\r\n> +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/refs/heads/r1.5\r\n> \\ No newline at end of file\r\n> diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\r\n> deleted file mode 100644\r\n> index 8b13789..0000000\r\n> --- a/tensorflow/tools/git/gen/head\r\n> +++ /dev/null\r\n> @@ -1 +0,0 @@\r\n> -\r\n> diff --git a/tensorflow/tools/git/gen/head b/tensorflow/tools/git/gen/head\r\n> new file mode 120000\r\n> index 0000000..28074d9\r\n> --- /dev/null\r\n> +++ b/tensorflow/tools/git/gen/head\r\n> @@ -0,0 +1 @@\r\n> +/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow/.git/HEAD\r\n> \\ No newline at end of file\r\n> diff --git a/tensorflow/tools/git/gen/spec.json\r\n> b/tensorflow/tools/git/gen/spec.json\r\n> index 176bbc2..2dbb36c 100644\r\n> --- a/tensorflow/tools/git/gen/spec.json\r\n> +++ b/tensorflow/tools/git/gen/spec.json\r\n> @@ -1,3 +1,5 @@\r\n>  {\r\n> -  \"git\": false\r\n> -}\r\n> +  \"path\": \"/gpfs/MUST-DATA/listic/install/tensorflow.1.5/tensorflow\",\r\n> +  \"git\": true,\r\n> +  \"branch\": \"refs/heads/r1.5\"\r\n> +}\r\n> \\ No newline at end of file\r\n> diff --git a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n> b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n> index 05290d6..7b2e448 100644\r\n> --- a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n> +++ b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n> @@ -42,10 +42,10 @@ toolchain {\r\n>    target_system_name: \"local\"\r\n>    toolchain_identifier: \"local_linux\"\r\n>\r\n> -  tool_path { name: \"ar\" path: \"/usr/bin/ar\" }\r\n> -  tool_path { name: \"compat-ld\" path: \"/usr/bin/ld\" }\r\n> -  tool_path { name: \"cpp\" path: \"/usr/bin/cpp\" }\r\n> -  tool_path { name: \"dwp\" path: \"/usr/bin/dwp\" }\r\n> +  tool_path { name: \"ar\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ar\" }\r\n> +  tool_path { name: \"compat-ld\" path:\r\n> \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\r\n> +  tool_path { name: \"cpp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/cpp\" }\r\n> +  tool_path { name: \"dwp\" path: \"/opt/rh/devtoolset-4/root/usr/bin/dwp\" }\r\n>    # As part of the TensorFlow release, we place some cuda-related\r\n> compilation\r\n>    # files in @local_config_cuda//crosstool/clang/bin, and this relative\r\n>    # path, combined with the rest of our Bazel configuration causes our\r\n> @@ -56,21 +56,23 @@ toolchain {\r\n>    cxx_flag: \"-std=c++11\"\r\n>    linker_flag: \"-Wl,-no-as-needed\"\r\n>    linker_flag: \"-lstdc++\"\r\n> -  linker_flag: \"-B/usr/bin/\"\r\n> +  linker_flag: \"-lm\"\r\n> +  linker_flag: \"-lrt\"\r\n> +  linker_flag: \"-B/opt/rh/devtoolset-4/root/usr/bin/\"\r\n>\r\n>  %{host_compiler_includes}\r\n> -  tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\r\n> +  tool_path { name: \"gcov\" path: \"/opt/rh/devtoolset-4/root/usr/bin/gcov\"\r\n> }\r\n>\r\n>    # C(++) compiles invoke the compiler (as that is the one knowing where\r\n>    # to find libraries), but we provide LD so other rules can invoke the\r\n> linker.\r\n> -  tool_path { name: \"ld\" path: \"/usr/bin/ld\" }\r\n> +  tool_path { name: \"ld\" path: \"/opt/rh/devtoolset-4/root/usr/bin/ld\" }\r\n>\r\n> -  tool_path { name: \"nm\" path: \"/usr/bin/nm\" }\r\n> -  tool_path { name: \"objcopy\" path: \"/usr/bin/objcopy\" }\r\n> +  tool_path { name: \"nm\" path: \"/opt/rh/devtoolset-4/root/usr/bin/nm\" }\r\n> +  tool_path { name: \"objcopy\" path:\r\n> \"/opt/rh/devtoolset-4/root/usr/bin/objcopy\" }\r\n>    objcopy_embed_flag: \"-I\"\r\n>    objcopy_embed_flag: \"binary\"\r\n> -  tool_path { name: \"objdump\" path: \"/usr/bin/objdump\" }\r\n> -  tool_path { name: \"strip\" path: \"/usr/bin/strip\" }\r\n> +  tool_path { name: \"objdump\" path:\r\n> \"/opt/rh/devtoolset-4/root/usr/bin/objdump\" }\r\n> +  tool_path { name: \"strip\" path:\r\n> \"/opt/rh/devtoolset-4/root/usr/bin/strip\" }\r\n>\r\n>    # Anticipated future default.\r\n>    unfiltered_cxx_flag: \"-no-canonical-prefixes\"\r\n> @@ -122,6 +124,11 @@ toolchain {\r\n>\r\n>    # Include directory for cuda headers.\r\n>  %{cuda_include_path}\r\n> +cxx_builtin_include_directory:\r\n> \"/opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.3.1/include\"\r\n> +cxx_builtin_include_directory:\r\n> \"/opt/rh/devtoolset-4/root/usr/include/c++/5.3.1/include\"\r\n> +cxx_builtin_include_directory:\r\n> \"/opt/rh/devtoolset-4/root/usr/local/include\"\r\n> +cxx_builtin_include_directory: \"/opt/rh/devtoolset-4/root/usr/include\"\r\n> +cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include/\"\r\n>\r\n>    compilation_mode_flags {\r\n>      mode: DBG\r\n> diff --git\r\n> a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n> b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n> index 2558f46..2d7ff15 100755\r\n> ---\r\n> a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n> +++\r\n> b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n> @@ -47,7 +47,8 @@ import pipes\r\n>\r\n>  # Template values set by cuda_autoconf.\r\n>  CPU_COMPILER = ('%{cpu_compiler}')\r\n> -GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\r\n> +#GCC_HOST_COMPILER_PATH = ('%{gcc_host_compiler_path}')\r\n> +GCC_HOST_COMPILER_PATH = ('/opt/rh/devtoolset-4/root/usr/bin/gcc')\r\n>\r\n>  NVCC_PATH = '%{nvcc_path}'\r\n>  PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\r\n> diff --git a/third_party/gpus/cuda_configure.bzl\r\n> b/third_party/gpus/cuda_configure.bzl\r\n> index 31a4bfa..2f8dc81 100644\r\n> --- a/third_party/gpus/cuda_configure.bzl\r\n> +++ b/third_party/gpus/cuda_configure.bzl\r\n> @@ -89,8 +89,7 @@ def _get_cxx_inc_directories_impl(repository_ctx, cc,\r\n> lang_is_cpp):\r\n>    # TODO: We pass -no-canonical-prefixes here to match the compiler flags,\r\n>    #       but in cuda_clang CROSSTOOL file that is a `feature` and we\r\n> should\r\n>    #       handle the case when it's disabled and no flag is passed\r\n> -  result = repository_ctx.execute([cc, \"-no-canonical-prefixes\",\r\n> -                                   \"-E\", \"-x\" + lang, \"-\", \"-v\"])\r\n> +  result = repository_ctx.execute([cc,\"-E\", \"-x\" + lang, \"-\", \"-v\"])\r\n>    index1 = result.stderr.find(_INC_DIR_MARKER_BEGIN)\r\n>    if index1 == -1:\r\n>      return []\r\n>\r\n\r\nRegarding configure setup:\r\n\r\n> [alben@lapp-wngpu002 tensorflow]$ ./configure\r\n> INFO: $TEST_TMPDIR defined: output root default is '/tmp/'.\r\n> You have bazel 0.8.0- (@non-git) installed.\r\n> Please specify the location of python. [Default is\r\n> /univ_home/UNIVSOFT/COMMON/python/2.7.6/bin/python]:\r\n>\r\n>\r\n> Found possible Python library paths:\r\n>   /univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages\r\n> Please input the desired Python library path to use.  Default is\r\n> [/univ_home/UNIVSOFT/COMMON/python/2.7.6/lib/python2.7/site-packages]\r\n>\r\n> Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n\r\n> No jemalloc as malloc support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]:\r\n> n\r\n> No Google Cloud Platform support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\n> No Hadoop File System support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]:\r\n> n\r\n> No Amazon S3 File System support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with XLA JIT support? [y/N]: y\r\n> XLA JIT support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with GDR support? [y/N]: n\r\n> No GDR support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with VERBS support? [y/N]: n\r\n> No VERBS support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\n> No OpenCL SYCL support will be enabled for TensorFlow.\r\n>\r\n> Do you wish to build TensorFlow with CUDA support? [y/N]: y\r\n> CUDA support will be enabled for TensorFlow.\r\n>\r\n> Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave\r\n> empty to default to CUDA 9.0]: 8.0\r\n>\r\n>\r\n> Please specify the location where CUDA 8.0 toolkit is installed. Refer to\r\n> README.md for more details. [Default is /usr/local/cuda]:\r\n> /usr/local/cuda-8.0\r\n>\r\n>\r\n> Please specify the cuDNN version you want to use. [Leave empty to default\r\n> to cuDNN 7.0]: 7\r\n>\r\n>\r\n> Please specify the location where cuDNN 7 library is installed. Refer to\r\n> README.md for more details. [Default is\r\n> /usr/local/cuda-8.0]:/uds_data/listic/install/cuda/cudnn-cuda8-v7.0.5\r\n>\r\n>\r\n> Please specify a list of comma-separated Cuda compute capabilities you\r\n> want to build with.\r\n> You can find the compute capability of your device at:\r\n> https://developer.nvidia.com/cuda-gpus.\r\n> Please note that each additional compute capability significantly\r\n> increases your build time and binary size. [Default is: 3.7,3.7]\r\n>\r\n>\r\n> Do you want to use clang as CUDA compiler? [y/N]:\r\n> nvcc will be used as CUDA compiler.\r\n>\r\n> Please specify which gcc should be used by nvcc as the host compiler.\r\n> [Default is /opt/rh/devtoolset-4/root/usr/bin/gcc]:\r\n>\r\n>\r\n> Do you wish to build TensorFlow with MPI support? [y/N]:\r\n> No MPI support will be enabled for TensorFlow.\r\n>\r\n> Please specify optimization flags to use during compilation when bazel\r\n> option \"--config=opt\" is specified [Default is -march=native]:\r\n>\r\n>\r\n> Add \"--config=mkl\" to your bazel command to build with MKL support.\r\n> Please note that MKL on MacOS or windows is still not supported.\r\n> If you would like to use a local MKL instead of downloading, please set\r\n> the environment variable \"TF_MKL_ROOT\" every time before build.\r\n>\r\n> Would you like to interactively configure ./WORKSPACE for Android builds?\r\n> [y/N]:\r\n> Not configuring the WORKSPACE for Android builds.\r\n>\r\n> Configuration finished\r\n>\r\n\r\nNow the build command:\r\n\r\n> bazel build --config=mkl --linkopt='-lrt' -c opt --copt=-mavx\r\n> --copt=-mavx2 --copt=-msse4.2 --copt=-msse4.1 --copt=-mfma --copt=-msse3\r\n> --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone\r\n> //tensorflow/tools/pip_package:build_pip_package\r\n>\r\n\r\nAnd the final package creation:\r\n\r\n\r\n>  bazel-bin/tensorflow/tools/pip_package/build_pip_package\r\n> /tmp/tensorflow_pkg\r\n>\r\n\r\nUPDATE : adding graph update capabilities:\r\n\r\n> bazel build tensorflow/tools/graph_transforms:transform_graph\r\n\r\n\r\n\r\n> I really hope it helps.\r\n   Alex\r\n\r\n2018-02-10 13:44 GMT+01:00 lucy-itjob <notifications@github.com>:\r\n\r\n> Alex,\r\n>\r\n> Thank you for all this information.\r\n>\r\n> I am new in this area. To me, you are the first one land on the moon in\r\n> this area, I am still on the earth, and pulling my hair to get this\r\n> Tensorflow working on RHEL6, hoping some day I can land on the moon just\r\n> like you did.\r\n>\r\n> Can you do me a favor? I know you had listed your local customized files\r\n> which modified by you in previously email chain, could you please sent all\r\n> the your local customized files (Bazel and Tensorflow) which modified by\r\n> you to me directly, my email is lucy_itjob@comcat.net. could you please\r\n> include Crosstool files for current and previous version (give me the\r\n> current version name and download url) too ? So that I can use the code to\r\n> compare my environment based on your files.\r\n>\r\n> You know, to be able to walk on the moon, it is not easy since there are\r\n> no Tensorflow vendor support on RHEL6.\r\n>\r\n> Alex, I attach an picture for you to enjoy! Thanks a lot\r\n> [image: image]\r\n> <https://user-images.githubusercontent.com/25250352/36062221-4b206a64-0e2d-11e8-87bc-ec48874097a9.png>\r\n>\r\n> \u2014\r\n> You are receiving this because you authored the thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/8529#issuecomment-364649132>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/ACf6SPNswb4TaN4ozMc6FfsbQDu_nXFDks5tTY9JgaJpZM4Mhr7n>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nAlexandre BENOIT,\r\nAssociate Professor / Ma\u00eetre de Conf\u00e9rence\r\nImage processing and visual scene classification,\r\nLISTIC Lab / IUT Annecy\r\nhttps://sites.google.com/site/benoitalexandrevision/\r\n"}