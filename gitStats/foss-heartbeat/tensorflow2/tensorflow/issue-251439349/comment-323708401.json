{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323708401", "html_url": "https://github.com/tensorflow/tensorflow/issues/12418#issuecomment-323708401", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12418", "id": 323708401, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzcwODQwMQ==", "user": {"login": "bpiel", "id": 662053, "node_id": "MDQ6VXNlcjY2MjA1Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/662053?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpiel", "html_url": "https://github.com/bpiel", "followers_url": "https://api.github.com/users/bpiel/followers", "following_url": "https://api.github.com/users/bpiel/following{/other_user}", "gists_url": "https://api.github.com/users/bpiel/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpiel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpiel/subscriptions", "organizations_url": "https://api.github.com/users/bpiel/orgs", "repos_url": "https://api.github.com/users/bpiel/repos", "events_url": "https://api.github.com/users/bpiel/events{/privacy}", "received_events_url": "https://api.github.com/users/bpiel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-21T10:30:05Z", "updated_at": "2017-08-21T10:30:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5977844\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dguerra\">@dguerra</a> <code>BiasAddGrad</code> already exists as an op, which means the math is already implemented (the hard part). But, <code>BiasAddGrad</code> can't be used by <code>AddSymbolicGradients</code> without a bit of wrapper logic and then being registered as the gradient of <code>BiasAdd</code>.</p>", "body_text": "@dguerra BiasAddGrad already exists as an op, which means the math is already implemented (the hard part). But, BiasAddGrad can't be used by AddSymbolicGradients without a bit of wrapper logic and then being registered as the gradient of BiasAdd.", "body": "@dguerra `BiasAddGrad` already exists as an op, which means the math is already implemented (the hard part). But, `BiasAddGrad` can't be used by `AddSymbolicGradients` without a bit of wrapper logic and then being registered as the gradient of `BiasAdd`."}