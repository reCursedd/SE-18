{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312354348", "html_url": "https://github.com/tensorflow/tensorflow/issues/11122#issuecomment-312354348", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11122", "id": 312354348, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjM1NDM0OA==", "user": {"login": "ramanishka", "id": 12480405, "node_id": "MDQ6VXNlcjEyNDgwNDA1", "avatar_url": "https://avatars3.githubusercontent.com/u/12480405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramanishka", "html_url": "https://github.com/ramanishka", "followers_url": "https://api.github.com/users/ramanishka/followers", "following_url": "https://api.github.com/users/ramanishka/following{/other_user}", "gists_url": "https://api.github.com/users/ramanishka/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramanishka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramanishka/subscriptions", "organizations_url": "https://api.github.com/users/ramanishka/orgs", "repos_url": "https://api.github.com/users/ramanishka/repos", "events_url": "https://api.github.com/users/ramanishka/events{/privacy}", "received_events_url": "https://api.github.com/users/ramanishka/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-30T19:29:50Z", "updated_at": "2017-06-30T19:30:18Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5105569\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suiyuan2009\">@suiyuan2009</a> No need to \"try cpu version\". The snippet <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1331470\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mikowals\">@mikowals</a> provided works fine without the explicit specification of the device if gpus are available. But if they are not available for some reason (e.g. CUDA_VISIBLE_DEVICES='') - the code requires such explicit specification. Interesting, that this breaks cifar10 code.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=184424\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ali01\">@ali01</a></p>\n<pre><code>$ cat tf_env.txt\n== cat /etc/issue ===============================================\nLinux sv 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\n\n== uname -a =====================================================\nLinux sv800478lx 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.0)\nprotobuf (3.3.0)\ntensorflow (1.2.0)\ntensorflow-tensorboard (0.1.2)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.0\ntf.GIT_VERSION = b'v1.2.0-1367-g270a3e8'\ntf.COMPILER_VERSION = b'v1.2.0-1367-g270a3e8'\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Jun 30 12:01:38 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    On   | 0000:03:00.0      On |                  N/A |\n| 27%   49C    P0    59W / 250W |   1017MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    On   | 0000:04:00.0     Off |                  N/A |\n| 23%   39C    P0    56W / 250W |      1MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n</code></pre>\n<pre><code>$ cat .tf_configure.bazelrc\n................\nbuild --define with_jemalloc=true\nbuild --define with_xla_support=true\nbuild:opt --cxxopt=-march=native --copt=-march=native\nbuild --action_env TF_NEED_CUDA=\"1\"\nbuild --action_env TF_NEED_OPENCL=\"0\"\nbuild --action_env TF_CUDA_CLANG=\"0\"\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\nbuild --action_env TF_CUDA_VERSION=\"8.0\"\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\nbuild --action_env TF_CUDNN_VERSION=\"\"\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-8.0\"\nbuild --action_env TF_CUDNN_VERSION=\"6\"\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\nbuild --config=cuda\ntest --config=cuda\n</code></pre>\n<p>Without explicit device specification, example.py:</p>\n<pre><code>import tensorflow as tf\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\nwith tf.Session() as sess: \n    res = sess.run(x)\n</code></pre>\n<p><code>CUDA_VISIBLE_DEVICES='' python example.py</code> crashes with <code>Attempting to fetch value instead of handling error Not found: could not find registered computation placer for platform Executor -- check target linkage Aborted (core dumped)</code></p>\n<p>At the same time the version from <a href=\"https://github.com/yaroslavvb/tensorflow-community-wheels/issues/21\" data-hovercard-type=\"issue\" data-hovercard-url=\"/yaroslavvb/tensorflow-community-wheels/issues/21/hovercard\">g8bbec0b</a> works.</p>\n<p>I would assume that something happened in between.</p>", "body_text": "@suiyuan2009 No need to \"try cpu version\". The snippet @mikowals provided works fine without the explicit specification of the device if gpus are available. But if they are not available for some reason (e.g. CUDA_VISIBLE_DEVICES='') - the code requires such explicit specification. Interesting, that this breaks cifar10 code.\n@ali01\n$ cat tf_env.txt\n== cat /etc/issue ===============================================\nLinux sv 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\n\n== uname -a =====================================================\nLinux sv800478lx 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.0)\nprotobuf (3.3.0)\ntensorflow (1.2.0)\ntensorflow-tensorboard (0.1.2)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.0\ntf.GIT_VERSION = b'v1.2.0-1367-g270a3e8'\ntf.COMPILER_VERSION = b'v1.2.0-1367-g270a3e8'\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nFri Jun 30 12:01:38 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    On   | 0000:03:00.0      On |                  N/A |\n| 27%   49C    P0    59W / 250W |   1017MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    On   | 0000:04:00.0     Off |                  N/A |\n| 23%   39C    P0    56W / 250W |      1MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n\n$ cat .tf_configure.bazelrc\n................\nbuild --define with_jemalloc=true\nbuild --define with_xla_support=true\nbuild:opt --cxxopt=-march=native --copt=-march=native\nbuild --action_env TF_NEED_CUDA=\"1\"\nbuild --action_env TF_NEED_OPENCL=\"0\"\nbuild --action_env TF_CUDA_CLANG=\"0\"\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\nbuild --action_env TF_CUDA_VERSION=\"8.0\"\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\nbuild --action_env TF_CUDNN_VERSION=\"\"\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-8.0\"\nbuild --action_env TF_CUDNN_VERSION=\"6\"\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\nbuild --config=cuda\ntest --config=cuda\n\nWithout explicit device specification, example.py:\nimport tensorflow as tf\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\nwith tf.Session() as sess: \n    res = sess.run(x)\n\nCUDA_VISIBLE_DEVICES='' python example.py crashes with Attempting to fetch value instead of handling error Not found: could not find registered computation placer for platform Executor -- check target linkage Aborted (core dumped)\nAt the same time the version from g8bbec0b works.\nI would assume that something happened in between.", "body": "@suiyuan2009 No need to \"try cpu version\". The snippet @mikowals provided works fine without the explicit specification of the device if gpus are available. But if they are not available for some reason (e.g. CUDA_VISIBLE_DEVICES='') - the code requires such explicit specification. Interesting, that this breaks cifar10 code. \r\n\r\n@ali01\r\n```\r\n$ cat tf_env.txt\r\n== cat /etc/issue ===============================================\r\nLinux sv 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n\r\n== uname -a =====================================================\r\nLinux sv800478lx 4.8.0-56-generic #61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.0)\r\ntensorflow-tensorboard (0.1.2)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.0\r\ntf.GIT_VERSION = b'v1.2.0-1367-g270a3e8'\r\ntf.COMPILER_VERSION = b'v1.2.0-1367-g270a3e8'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Jun 30 12:01:38 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    On   | 0000:03:00.0      On |                  N/A |\r\n| 27%   49C    P0    59W / 250W |   1017MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN X (Pascal)    On   | 0000:04:00.0     Off |                  N/A |\r\n| 23%   39C    P0    56W / 250W |      1MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n```\r\n```\r\n$ cat .tf_configure.bazelrc\r\n................\r\nbuild --define with_jemalloc=true\r\nbuild --define with_xla_support=true\r\nbuild:opt --cxxopt=-march=native --copt=-march=native\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env TF_NEED_OPENCL=\"0\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"8.0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --action_env TF_CUDNN_VERSION=\"\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-8.0\"\r\nbuild --action_env TF_CUDNN_VERSION=\"6\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\n```\r\n\r\nWithout explicit device specification, example.py:\r\n```\r\nimport tensorflow as tf\r\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\r\nwith tf.Session() as sess: \r\n    res = sess.run(x)\r\n```\r\n`CUDA_VISIBLE_DEVICES='' python example.py` crashes with `Attempting to fetch value instead of handling error Not found: could not find registered computation placer for platform Executor -- check target linkage\r\nAborted (core dumped)`\r\n\r\nAt the same time the version from [g8bbec0b](https://github.com/yaroslavvb/tensorflow-community-wheels/issues/21) works. \r\n\r\nI would assume that something happened in between. "}