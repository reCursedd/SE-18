{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313250574", "html_url": "https://github.com/tensorflow/tensorflow/issues/11122#issuecomment-313250574", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11122", "id": 313250574, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzI1MDU3NA==", "user": {"login": "darrengarvey", "id": 260360, "node_id": "MDQ6VXNlcjI2MDM2MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/260360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darrengarvey", "html_url": "https://github.com/darrengarvey", "followers_url": "https://api.github.com/users/darrengarvey/followers", "following_url": "https://api.github.com/users/darrengarvey/following{/other_user}", "gists_url": "https://api.github.com/users/darrengarvey/gists{/gist_id}", "starred_url": "https://api.github.com/users/darrengarvey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darrengarvey/subscriptions", "organizations_url": "https://api.github.com/users/darrengarvey/orgs", "repos_url": "https://api.github.com/users/darrengarvey/repos", "events_url": "https://api.github.com/users/darrengarvey/events{/privacy}", "received_events_url": "https://api.github.com/users/darrengarvey/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-05T23:05:56Z", "updated_at": "2017-07-05T23:05:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Looks like this came in with the <code>ComputationPlacer</code> in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/7d3497a639670d9c31d09185ff97b852f0fbe101/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/7d3497a639670d9c31d09185ff97b852f0fbe101\"><tt>7d3497a</tt></a>. Although it might have just been exposed by that commit.</p>\n<p>Specifically, <a href=\"https://github.com/tensorflow/tensorflow/commit/7d3497a639670d9c31d09185ff97b852f0fbe101#diff-91c1769c96df8265caf0c5f0ea83666fR99\">this check</a> fails for the Executor plugin. The <code>TransferManager</code> registers  itself in the executor plugin (<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/plugin/executor/transfer_manager.cc#L183\">like this</a>) so bodging in a similar thing for <code>ComputationPlacer</code> fixes the network I see the reported error on. eg:</p>\n<pre><code>diff --git a/tensorflow/compiler/plugin/executor/transfer_manager.cc b/tensorflow/compiler/plugin/executor/transfer_manager.cc\nindex 51c5dee..39d443e 100644\n--- a/tensorflow/compiler/plugin/executor/transfer_manager.cc\n+++ b/tensorflow/compiler/plugin/executor/transfer_manager.cc\n@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/compiler/xla/types.h\"\n #include \"tensorflow/compiler/xla/util.h\"\n #include \"tensorflow/compiler/xla/xla_data.pb.h\"\n+#include \"tensorflow/compiler/xla/service/computation_placer.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/stream_executor_no_cuda.h\"\n@@ -179,9 +180,15 @@ static std::unique_ptr&lt;xla::TransferManager&gt; CreateExecutorTransferManager() {\n   return xla::MakeUnique&lt;xla::executorplugin::ExecutorTransferManager&gt;();\n }\n\n+static std::unique_ptr&lt;xla::ComputationPlacer&gt; CreateExecutorComputationPlacer() {\n+  return xla::MakeUnique&lt;xla::ComputationPlacer&gt;();\n+}\n+\n static bool InitModule() {\n   xla::TransferManager::RegisterTransferManager(sep::kExecutorPlatformId,\n                                                 &amp;CreateExecutorTransferManager);\n+  xla::ComputationPlacer::RegisterComputationPlacer(sep::kExecutorPlatformId,\n+                                                &amp;CreateExecutorComputationPlacer);\n   return true;\n }\n static bool module_initialized = InitModule();\n</code></pre>\n<p>However unsurprisingly this bodge doesn't fix the other test cases in this ticket. For instance the simple test case:</p>\n<pre><code>import tensorflow as tf\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\nwith tf.Session() as sess: \n    res = sess.run(x)\n</code></pre>\n<p>Now provokes:</p>\n<pre><code>tensorflow.python.framework.errors_impl.UnimplementedError: unhandled HLO ops for HloEvaluator: rng.\n\t [[Node: cluster_0/_0/_1 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_0[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\"]()]]\n\t [[Node: cluster_0/_0/_1/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\", send_device_incarnation=1, tensor_name=\"edge_6_cluster_0/_0/_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]```\n</code></pre>", "body_text": "Looks like this came in with the ComputationPlacer in 7d3497a. Although it might have just been exposed by that commit.\nSpecifically, this check fails for the Executor plugin. The TransferManager registers  itself in the executor plugin (like this) so bodging in a similar thing for ComputationPlacer fixes the network I see the reported error on. eg:\ndiff --git a/tensorflow/compiler/plugin/executor/transfer_manager.cc b/tensorflow/compiler/plugin/executor/transfer_manager.cc\nindex 51c5dee..39d443e 100644\n--- a/tensorflow/compiler/plugin/executor/transfer_manager.cc\n+++ b/tensorflow/compiler/plugin/executor/transfer_manager.cc\n@@ -23,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/compiler/xla/types.h\"\n #include \"tensorflow/compiler/xla/util.h\"\n #include \"tensorflow/compiler/xla/xla_data.pb.h\"\n+#include \"tensorflow/compiler/xla/service/computation_placer.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/stream_executor_no_cuda.h\"\n@@ -179,9 +180,15 @@ static std::unique_ptr<xla::TransferManager> CreateExecutorTransferManager() {\n   return xla::MakeUnique<xla::executorplugin::ExecutorTransferManager>();\n }\n\n+static std::unique_ptr<xla::ComputationPlacer> CreateExecutorComputationPlacer() {\n+  return xla::MakeUnique<xla::ComputationPlacer>();\n+}\n+\n static bool InitModule() {\n   xla::TransferManager::RegisterTransferManager(sep::kExecutorPlatformId,\n                                                 &CreateExecutorTransferManager);\n+  xla::ComputationPlacer::RegisterComputationPlacer(sep::kExecutorPlatformId,\n+                                                &CreateExecutorComputationPlacer);\n   return true;\n }\n static bool module_initialized = InitModule();\n\nHowever unsurprisingly this bodge doesn't fix the other test cases in this ticket. For instance the simple test case:\nimport tensorflow as tf\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\nwith tf.Session() as sess: \n    res = sess.run(x)\n\nNow provokes:\ntensorflow.python.framework.errors_impl.UnimplementedError: unhandled HLO ops for HloEvaluator: rng.\n\t [[Node: cluster_0/_0/_1 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_0[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\"]()]]\n\t [[Node: cluster_0/_0/_1/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\", send_device_incarnation=1, tensor_name=\"edge_6_cluster_0/_0/_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]```", "body": "Looks like this came in with the `ComputationPlacer` in 7d3497a6. Although it might have just been exposed by that commit.\r\n\r\nSpecifically, [this check](https://github.com/tensorflow/tensorflow/commit/7d3497a639670d9c31d09185ff97b852f0fbe101#diff-91c1769c96df8265caf0c5f0ea83666fR99) fails for the Executor plugin. The `TransferManager` registers  itself in the executor plugin ([like this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/plugin/executor/transfer_manager.cc#L183)) so bodging in a similar thing for `ComputationPlacer` fixes the network I see the reported error on. eg:\r\n\r\n```\r\ndiff --git a/tensorflow/compiler/plugin/executor/transfer_manager.cc b/tensorflow/compiler/plugin/executor/transfer_manager.cc\r\nindex 51c5dee..39d443e 100644\r\n--- a/tensorflow/compiler/plugin/executor/transfer_manager.cc\r\n+++ b/tensorflow/compiler/plugin/executor/transfer_manager.cc\r\n@@ -23,6 +23,7 @@ limitations under the License.\r\n #include \"tensorflow/compiler/xla/types.h\"\r\n #include \"tensorflow/compiler/xla/util.h\"\r\n #include \"tensorflow/compiler/xla/xla_data.pb.h\"\r\n+#include \"tensorflow/compiler/xla/service/computation_placer.h\"\r\n #include \"tensorflow/core/lib/core/errors.h\"\r\n #include \"tensorflow/core/platform/logging.h\"\r\n #include \"tensorflow/core/platform/stream_executor_no_cuda.h\"\r\n@@ -179,9 +180,15 @@ static std::unique_ptr<xla::TransferManager> CreateExecutorTransferManager() {\r\n   return xla::MakeUnique<xla::executorplugin::ExecutorTransferManager>();\r\n }\r\n\r\n+static std::unique_ptr<xla::ComputationPlacer> CreateExecutorComputationPlacer() {\r\n+  return xla::MakeUnique<xla::ComputationPlacer>();\r\n+}\r\n+\r\n static bool InitModule() {\r\n   xla::TransferManager::RegisterTransferManager(sep::kExecutorPlatformId,\r\n                                                 &CreateExecutorTransferManager);\r\n+  xla::ComputationPlacer::RegisterComputationPlacer(sep::kExecutorPlatformId,\r\n+                                                &CreateExecutorComputationPlacer);\r\n   return true;\r\n }\r\n static bool module_initialized = InitModule();\r\n```\r\n\r\nHowever unsurprisingly this bodge doesn't fix the other test cases in this ticket. For instance the simple test case:\r\n\r\n```\r\nimport tensorflow as tf\r\nx = tf.random_normal(shape=[64, 64, 32, 32], seed=1.)\r\nwith tf.Session() as sess: \r\n    res = sess.run(x)\r\n```\r\nNow provokes:\r\n```\r\ntensorflow.python.framework.errors_impl.UnimplementedError: unhandled HLO ops for HloEvaluator: rng.\r\n\t [[Node: cluster_0/_0/_1 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_0[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\"]()]]\r\n\t [[Node: cluster_0/_0/_1/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:XLA_EXEC:0\", send_device_incarnation=1, tensor_name=\"edge_6_cluster_0/_0/_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]```"}