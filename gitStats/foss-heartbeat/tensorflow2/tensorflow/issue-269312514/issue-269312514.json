{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14056", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14056/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14056/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14056/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/14056", "id": 269312514, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ5MzMyNzQ4", "number": 14056, "title": "Half Normal Distribution (and inverse error function)", "user": {"login": "cshenton", "id": 14693516, "node_id": "MDQ6VXNlcjE0NjkzNTE2", "avatar_url": "https://avatars0.githubusercontent.com/u/14693516?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cshenton", "html_url": "https://github.com/cshenton", "followers_url": "https://api.github.com/users/cshenton/followers", "following_url": "https://api.github.com/users/cshenton/following{/other_user}", "gists_url": "https://api.github.com/users/cshenton/gists{/gist_id}", "starred_url": "https://api.github.com/users/cshenton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cshenton/subscriptions", "organizations_url": "https://api.github.com/users/cshenton/orgs", "repos_url": "https://api.github.com/users/cshenton/repos", "events_url": "https://api.github.com/users/cshenton/events{/privacy}", "received_events_url": "https://api.github.com/users/cshenton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-10-28T12:08:47Z", "updated_at": "2017-11-29T21:15:39Z", "closed_at": "2017-11-29T21:15:39Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14056", "html_url": "https://github.com/tensorflow/tensorflow/pull/14056", "diff_url": "https://github.com/tensorflow/tensorflow/pull/14056.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/14056.patch"}, "body_html": "<h2>Inverse Error Function</h2>\n<p>Added <code>erfinv</code> as a simple function of <code>ndtri</code> (the api mirrors the approach taken in <code>scipy.special</code>. Mainly to prevent distributions with methods in terms of the inverse error function reimplementing their own wrappers around <code>ndtri</code>.</p>\n<h2>Half Normal Distribution</h2>\n<div class=\"highlight highlight-source-python\"><pre>X <span class=\"pl-k\">~</span> Normal(<span class=\"pl-c1\">0.0</span>, scale)\nY <span class=\"pl-k\">=</span> <span class=\"pl-k\">|</span>X<span class=\"pl-k\">|</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> then Y ~ HalfNormal(scale)</span></pre></div>\n<p>Added the Half Normal distribution to <code>contrib.distributions</code>. Main things to look at is how I'm dealing with the pdf discontinuity.</p>\n<p>A discontinuity in the pdf that sends values to 0.0 is easy to represent in <code>prob</code>, (by multiplying my a tensor with 0.0s at the relevant positions) than <code>log_prob</code> (which requires masking -inf wherever x &lt; 0). I'd be interested if anyone has any suggestions for correct ways to implement the latter, as I think this is a case where <code>log_prob</code> is more numerically stable (along the support of the distribution that is).</p>", "body_text": "Inverse Error Function\nAdded erfinv as a simple function of ndtri (the api mirrors the approach taken in scipy.special. Mainly to prevent distributions with methods in terms of the inverse error function reimplementing their own wrappers around ndtri.\nHalf Normal Distribution\nX ~ Normal(0.0, scale)\nY = |X|\n# then Y ~ HalfNormal(scale)\nAdded the Half Normal distribution to contrib.distributions. Main things to look at is how I'm dealing with the pdf discontinuity.\nA discontinuity in the pdf that sends values to 0.0 is easy to represent in prob, (by multiplying my a tensor with 0.0s at the relevant positions) than log_prob (which requires masking -inf wherever x < 0). I'd be interested if anyone has any suggestions for correct ways to implement the latter, as I think this is a case where log_prob is more numerically stable (along the support of the distribution that is).", "body": "## Inverse Error Function\r\n\r\nAdded `erfinv` as a simple function of `ndtri` (the api mirrors the approach taken in `scipy.special`. Mainly to prevent distributions with methods in terms of the inverse error function reimplementing their own wrappers around `ndtri`.\r\n\r\n## Half Normal Distribution\r\n```python\r\nX ~ Normal(0.0, scale)\r\nY = |X|\r\n# then Y ~ HalfNormal(scale)\r\n```\r\n\r\nAdded the Half Normal distribution to `contrib.distributions`. Main things to look at is how I'm dealing with the pdf discontinuity.\r\n\r\nA discontinuity in the pdf that sends values to 0.0 is easy to represent in `prob`, (by multiplying my a tensor with 0.0s at the relevant positions) than `log_prob` (which requires masking -inf wherever x < 0). I'd be interested if anyone has any suggestions for correct ways to implement the latter, as I think this is a case where `log_prob` is more numerically stable (along the support of the distribution that is)."}