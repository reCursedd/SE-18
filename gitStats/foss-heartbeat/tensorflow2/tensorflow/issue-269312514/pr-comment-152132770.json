{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/152132770", "pull_request_review_id": 77948066, "id": 152132770, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MjEzMjc3MA==", "diff_hunk": "@@ -0,0 +1,318 @@\n+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for initializers.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import importlib\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import ops\n+from tensorflow.python.framework import tensor_shape\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gradients_impl\n+from tensorflow.python.ops import variables\n+from tensorflow.contrib.distributions.python.ops import half_normal as hn_lib\n+from tensorflow.python.platform import test\n+from tensorflow.python.platform import tf_logging\n+\n+\n+def try_import(name):  # pylint: disable=invalid-name\n+  module = None\n+  try:\n+    module = importlib.import_module(name)\n+  except ImportError as e:\n+    tf_logging.warning(\"Could not import %s: %s\" % (name, str(e)))\n+  return module\n+\n+stats = try_import(\"scipy.stats\")\n+\n+\n+class HalfNormalTest(test.TestCase):\n+\n+  def setUp(self):\n+    self._rng = np.random.RandomState(123)\n+\n+  def assertAllFinite(self, tensor):\n+    is_finite = np.isfinite(tensor.eval())\n+    all_true = np.ones_like(is_finite, dtype=np.bool)\n+    self.assertAllEqual(all_true, is_finite)\n+\n+  def _testParamShapes(self, sample_shape, expected):\n+    with self.test_session():\n+      param_shapes = hn_lib.HalfNormal.param_shapes(sample_shape)\n+      scale_shape = param_shapes[\"scale\"]\n+      self.assertAllEqual(expected, scale_shape.eval())\n+      scale = array_ops.ones(scale_shape)\n+      self.assertAllEqual(\n+          expected,\n+          array_ops.shape(hn_lib.HalfNormal(scale).sample()).eval())\n+\n+  def _testParamStaticShapes(self, sample_shape, expected):\n+    param_shapes = hn_lib.HalfNormal.param_static_shapes(sample_shape)\n+    scale_shape = param_shapes[\"scale\"]\n+    self.assertEqual(expected, scale_shape)\n+\n+  def _testBatchShapes(self, dist, tensor):\n+    self.assertAllEqual(dist.batch_shape_tensor().eval(), tensor.shape)\n+    self.assertAllEqual(dist.batch_shape_tensor().eval(), tensor.eval().shape)\n+    self.assertAllEqual(dist.batch_shape, tensor.shape)\n+    self.assertAllEqual(dist.batch_shape, tensor.eval().shape)\n+\n+  def testParamShapes(self):\n+    sample_shape = [10, 3, 4]\n+    self._testParamShapes(sample_shape, sample_shape)\n+    self._testParamShapes(constant_op.constant(sample_shape), sample_shape)\n+\n+  def testParamStaticShapes(self):\n+    sample_shape = [10, 3, 4]\n+    self._testParamStaticShapes(sample_shape, sample_shape)\n+    self._testParamStaticShapes(\n+        tensor_shape.TensorShape(sample_shape), sample_shape)\n+\n+  def testHalfNormalLogPDF(self):\n+    with self.test_session():\n+      batch_size = 6\n+      scale = constant_op.constant([3.0] * batch_size)\n+      x = np.array([-2.5, 2.5, 4.0, 0.0, -1.0, 2.0], dtype=np.float32)\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+\n+      log_pdf = halfnorm.log_prob(x)\n+      self._testBatchShapes(halfnorm, log_pdf)\n+\n+      pdf = halfnorm.prob(x)\n+      self._testBatchShapes(halfnorm, pdf)\n+\n+      if not stats:\n+        return\n+      expected_log_pdf = stats.halfnorm(scale=scale.eval()).logpdf(x)\n+      self.assertAllClose(expected_log_pdf, log_pdf.eval())\n+      self.assertAllClose(np.exp(expected_log_pdf), pdf.eval())\n+\n+  def testHalfNormalLogPDFMultidimensional(self):\n+    with self.test_session():\n+      batch_size = 6\n+      scale = constant_op.constant([[3.0, 1.0]] * batch_size)\n+      x = np.array([[-2.5, 2.5, 4.0, 0.0, -1.0, 2.0]], dtype=np.float32).T\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+\n+      log_pdf = halfnorm.log_prob(x)\n+      self._testBatchShapes(halfnorm, log_pdf)\n+\n+      pdf = halfnorm.prob(x)\n+      self._testBatchShapes(halfnorm, pdf)\n+\n+      if not stats:\n+        return\n+      expected_log_pdf = stats.halfnorm(scale=scale.eval()).logpdf(x)\n+      self.assertAllClose(expected_log_pdf, log_pdf.eval())\n+      self.assertAllClose(np.exp(expected_log_pdf), pdf.eval())\n+\n+  def testHalfNormalCDF(self):\n+    with self.test_session():\n+      batch_size = 50\n+      scale = self._rng.rand(batch_size) + 1.0\n+      x = np.linspace(-8.0, 8.0, batch_size).astype(np.float64)\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+\n+      cdf = halfnorm.cdf(x)\n+      self._testBatchShapes(halfnorm, cdf)\n+\n+      log_cdf = halfnorm.log_cdf(x)\n+      self._testBatchShapes(halfnorm, log_cdf)\n+\n+      if not stats:\n+        return\n+      expected_logcdf = stats.halfnorm(scale=scale).logcdf(x)\n+      self.assertAllClose(expected_logcdf, log_cdf.eval(), atol=0)\n+      self.assertAllClose(np.exp(expected_logcdf), cdf.eval(), atol=0)\n+\n+  def testHalfNormalSurvivalFunction(self):\n+    with self.test_session():\n+      batch_size = 50\n+      scale = self._rng.rand(batch_size) + 1.0\n+      x = np.linspace(-8.0, 8.0, batch_size).astype(np.float64)\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+\n+      sf = halfnorm.survival_function(x)\n+      self._testBatchShapes(halfnorm, sf)\n+\n+      log_sf = halfnorm.log_survival_function(x)\n+      self._testBatchShapes(halfnorm, log_sf)\n+\n+      if not stats:\n+        return\n+      expected_logsf = stats.halfnorm(scale=scale).logsf(x)\n+      self.assertAllClose(expected_logsf, log_sf.eval(), atol=0)\n+      self.assertAllClose(np.exp(expected_logsf), sf.eval(), atol=0)\n+\n+  def testHalfNormalQuantile(self):\n+    with self.test_session():\n+      batch_size = 50\n+      scale = self._rng.rand(batch_size) + 1.0\n+      p = np.linspace(0., 1.0, batch_size).astype(np.float64)\n+\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+      x = halfnorm.quantile(p)\n+      self._testBatchShapes(halfnorm, x)\n+\n+      if not stats:\n+        return\n+      expected_x = stats.halfnorm(scale=scale).ppf(p)\n+      self.assertAllClose(expected_x, x.eval(), atol=0)\n+\n+  def testFiniteGradients(self):\n+    for dtype in [np.float32, np.float64]:\n+      g = ops.Graph()\n+      with g.as_default():\n+        scale = variables.Variable(dtype(3.0))\n+        dist = hn_lib.HalfNormal(scale=scale)\n+        x = np.array([0.01, 0.1, 1., 5., 10.]).astype(dtype)\n+        for func in [\n+            dist.cdf, dist.log_cdf, dist.survival_function,\n+            dist.log_prob, dist.prob, dist.log_survival_function,\n+        ]:\n+          print(func.__name__)\n+          value = func(x)\n+          grads = gradients_impl.gradients(value, [scale])\n+          with self.test_session(graph=g):\n+            variables.global_variables_initializer().run()\n+            self.assertAllFinite(value)\n+            self.assertAllFinite(grads[0])\n+\n+  def testHalfNormalEntropy(self):\n+    with self.test_session():\n+      scale = np.array([[1.0, 2.0, 3.0]])\n+      halfnorm = hn_lib.HalfNormal(scale=scale)\n+\n+      expected_entropy = 0.5 * np.log(np.pi * scale ** 2.0 / 2.0) + 0.5", "path": "tensorflow/contrib/distributions/python/kernel_tests/half_normal_test.py", "position": null, "original_position": 204, "commit_id": "f474884a7c6269c5b945ec6f558a42f5af3b3871", "original_commit_id": "6cffa2e77a4ce3c13ee19dcdb45b80f4b098676a", "user": {"login": "cshenton", "id": 14693516, "node_id": "MDQ6VXNlcjE0NjkzNTE2", "avatar_url": "https://avatars0.githubusercontent.com/u/14693516?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cshenton", "html_url": "https://github.com/cshenton", "followers_url": "https://api.github.com/users/cshenton/followers", "following_url": "https://api.github.com/users/cshenton/following{/other_user}", "gists_url": "https://api.github.com/users/cshenton/gists{/gist_id}", "starred_url": "https://api.github.com/users/cshenton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cshenton/subscriptions", "organizations_url": "https://api.github.com/users/cshenton/orgs", "repos_url": "https://api.github.com/users/cshenton/repos", "events_url": "https://api.github.com/users/cshenton/events{/privacy}", "received_events_url": "https://api.github.com/users/cshenton/received_events", "type": "User", "site_admin": false}, "body": "Will do. Is a link to wikipedia fine? There's the 1961 paper on the folded normal distributions but that's paywalled so less easy to check.", "created_at": "2017-11-20T22:43:34Z", "updated_at": "2017-11-21T02:39:21Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14056#discussion_r152132770", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14056", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/152132770"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14056#discussion_r152132770"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14056"}}, "body_html": "<p>Will do. Is a link to wikipedia fine? There's the 1961 paper on the folded normal distributions but that's paywalled so less easy to check.</p>", "body_text": "Will do. Is a link to wikipedia fine? There's the 1961 paper on the folded normal distributions but that's paywalled so less easy to check.", "in_reply_to_id": 152072573}