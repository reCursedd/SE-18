{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/319427272", "html_url": "https://github.com/tensorflow/tensorflow/issues/11909#issuecomment-319427272", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11909", "id": 319427272, "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTQyNzI3Mg==", "user": {"login": "emsi", "id": 433383, "node_id": "MDQ6VXNlcjQzMzM4Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/433383?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emsi", "html_url": "https://github.com/emsi", "followers_url": "https://api.github.com/users/emsi/followers", "following_url": "https://api.github.com/users/emsi/following{/other_user}", "gists_url": "https://api.github.com/users/emsi/gists{/gist_id}", "starred_url": "https://api.github.com/users/emsi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emsi/subscriptions", "organizations_url": "https://api.github.com/users/emsi/orgs", "repos_url": "https://api.github.com/users/emsi/repos", "events_url": "https://api.github.com/users/emsi/events{/privacy}", "received_events_url": "https://api.github.com/users/emsi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-01T16:41:52Z", "updated_at": "2017-08-01T16:41:52Z", "author_association": "NONE", "body_html": "<p>Yes. NaNs are undoubtedly handled differently between GPU and CPU. [There's another possibility, see the last paragraph of this post].</p>\n<p>By correct results I mean that I have a model that I trained on GPU and it works correctly on GPU. It produces desired results and is surprisingly numerically stable. It's most probably due to the fact that those NaNs are handled on GPU much like -Inf. At least while evaluating.</p>\n<p>On the other hand I'm absolutely certain that if the model was trained on CPU there would be no NaNs in the weights.</p>\n<p>There's yet another possibility that those NaNs are not NaNs in the first place. It might be conversion error when the weights are obtained from the GPU memory which is reversed when the weights are applied there hence the problem surfaces only when the model is computed on CPU. The argument that supports this claim is that when I change the NaNs to minus infinity the model produces the same results. So both: NaN and -Inf are represented as equal in the GPU memory (at least when sourced from model weights as it's probably not a general case for GPU).</p>", "body_text": "Yes. NaNs are undoubtedly handled differently between GPU and CPU. [There's another possibility, see the last paragraph of this post].\nBy correct results I mean that I have a model that I trained on GPU and it works correctly on GPU. It produces desired results and is surprisingly numerically stable. It's most probably due to the fact that those NaNs are handled on GPU much like -Inf. At least while evaluating.\nOn the other hand I'm absolutely certain that if the model was trained on CPU there would be no NaNs in the weights.\nThere's yet another possibility that those NaNs are not NaNs in the first place. It might be conversion error when the weights are obtained from the GPU memory which is reversed when the weights are applied there hence the problem surfaces only when the model is computed on CPU. The argument that supports this claim is that when I change the NaNs to minus infinity the model produces the same results. So both: NaN and -Inf are represented as equal in the GPU memory (at least when sourced from model weights as it's probably not a general case for GPU).", "body": "Yes. NaNs are undoubtedly handled differently between GPU and CPU. [There's another possibility, see the last paragraph of this post].\r\n\r\nBy correct results I mean that I have a model that I trained on GPU and it works correctly on GPU. It produces desired results and is surprisingly numerically stable. It's most probably due to the fact that those NaNs are handled on GPU much like -Inf. At least while evaluating.\r\n\r\nOn the other hand I'm absolutely certain that if the model was trained on CPU there would be no NaNs in the weights. \r\n\r\nThere's yet another possibility that those NaNs are not NaNs in the first place. It might be conversion error when the weights are obtained from the GPU memory which is reversed when the weights are applied there hence the problem surfaces only when the model is computed on CPU. The argument that supports this claim is that when I change the NaNs to minus infinity the model produces the same results. So both: NaN and -Inf are represented as equal in the GPU memory (at least when sourced from model weights as it's probably not a general case for GPU). "}