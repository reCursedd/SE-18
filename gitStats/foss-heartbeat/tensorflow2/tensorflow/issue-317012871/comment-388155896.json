{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388155896", "html_url": "https://github.com/tensorflow/tensorflow/issues/18813#issuecomment-388155896", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18813", "id": 388155896, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODE1NTg5Ng==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-10T19:14:18Z", "updated_at": "2018-05-10T19:14:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>That sounds like it could be useful, although I don't believe anybody is working on it right now. IIUC, it would be equivalent to range-partitioning rather than round-robin partitioning the dataset, right? If you knew the number of elements in each file, you could probably build something workable using <code>Dataset.skip()</code> and <code>Dataset.take()</code>.</p>\n<p>I'll open this up to contributions in case anybody wants to add an interface for doing this more efficiently.</p>", "body_text": "That sounds like it could be useful, although I don't believe anybody is working on it right now. IIUC, it would be equivalent to range-partitioning rather than round-robin partitioning the dataset, right? If you knew the number of elements in each file, you could probably build something workable using Dataset.skip() and Dataset.take().\nI'll open this up to contributions in case anybody wants to add an interface for doing this more efficiently.", "body": "That sounds like it could be useful, although I don't believe anybody is working on it right now. IIUC, it would be equivalent to range-partitioning rather than round-robin partitioning the dataset, right? If you knew the number of elements in each file, you could probably build something workable using `Dataset.skip()` and `Dataset.take()`.\r\n\r\nI'll open this up to contributions in case anybody wants to add an interface for doing this more efficiently."}