{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318373681", "html_url": "https://github.com/tensorflow/tensorflow/issues/11690#issuecomment-318373681", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11690", "id": 318373681, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODM3MzY4MQ==", "user": {"login": "the-moliver", "id": 144949, "node_id": "MDQ6VXNlcjE0NDk0OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/144949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/the-moliver", "html_url": "https://github.com/the-moliver", "followers_url": "https://api.github.com/users/the-moliver/followers", "following_url": "https://api.github.com/users/the-moliver/following{/other_user}", "gists_url": "https://api.github.com/users/the-moliver/gists{/gist_id}", "starred_url": "https://api.github.com/users/the-moliver/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/the-moliver/subscriptions", "organizations_url": "https://api.github.com/users/the-moliver/orgs", "repos_url": "https://api.github.com/users/the-moliver/repos", "events_url": "https://api.github.com/users/the-moliver/events{/privacy}", "received_events_url": "https://api.github.com/users/the-moliver/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-27T14:10:46Z", "updated_at": "2017-07-27T14:10:46Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19834515\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lllyasviel\">@lllyasviel</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1634862\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/StefanoD\">@StefanoD</a>  The instance normalization paper says: \"The key idea is to replace batch normalization layers in the generator architecture with instance normalization layers, and to keep them at test time (as opposed to freeze and simplify them out as done for batch normalization)\". I believe the running_mean and running_var in the lua implementations are being used to hack the batch normalization implementation to do instance normalization. Instance normalization is just contrast normalization and the keras-contrib implementation looks right to me. Please point out specific bugs if you identify them.</p>", "body_text": "@lllyasviel @StefanoD  The instance normalization paper says: \"The key idea is to replace batch normalization layers in the generator architecture with instance normalization layers, and to keep them at test time (as opposed to freeze and simplify them out as done for batch normalization)\". I believe the running_mean and running_var in the lua implementations are being used to hack the batch normalization implementation to do instance normalization. Instance normalization is just contrast normalization and the keras-contrib implementation looks right to me. Please point out specific bugs if you identify them.", "body": "@lllyasviel @StefanoD  The instance normalization paper says: \"The key idea is to replace batch normalization layers in the generator architecture with instance normalization layers, and to keep them at test time (as opposed to freeze and simplify them out as done for batch normalization)\". I believe the running_mean and running_var in the lua implementations are being used to hack the batch normalization implementation to do instance normalization. Instance normalization is just contrast normalization and the keras-contrib implementation looks right to me. Please point out specific bugs if you identify them."}