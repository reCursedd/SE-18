{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3481", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3481/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3481/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3481/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3481", "id": 167231145, "node_id": "MDU6SXNzdWUxNjcyMzExNDU=", "number": 3481, "title": "Failed to do 8-bit quantization following the tutorial: Op type not registered 'Dequantize'", "user": {"login": "MingSun-Tse", "id": 16812048, "node_id": "MDQ6VXNlcjE2ODEyMDQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/16812048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MingSun-Tse", "html_url": "https://github.com/MingSun-Tse", "followers_url": "https://api.github.com/users/MingSun-Tse/followers", "following_url": "https://api.github.com/users/MingSun-Tse/following{/other_user}", "gists_url": "https://api.github.com/users/MingSun-Tse/gists{/gist_id}", "starred_url": "https://api.github.com/users/MingSun-Tse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MingSun-Tse/subscriptions", "organizations_url": "https://api.github.com/users/MingSun-Tse/orgs", "repos_url": "https://api.github.com/users/MingSun-Tse/repos", "events_url": "https://api.github.com/users/MingSun-Tse/events{/privacy}", "received_events_url": "https://api.github.com/users/MingSun-Tse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2016-07-24T12:23:07Z", "updated_at": "2016-08-11T06:50:39Z", "closed_at": "2016-08-11T06:50:39Z", "author_association": "NONE", "body_html": "<p>hello, I'm learning to do 8-bit quantization following the <a href=\"https://www.tensorflow.org/versions/master/how_tos/quantization/index.html\" rel=\"nofollow\">How-to-tutorial</a> step-by-step, after I managed to output the <code>quantized_graph.pb</code>, then I was trying to test it, just like the tutorial:</p>\n<pre><code>&gt;&gt; bazel build tensorflow/examples/label_image:label_image\n&gt;&gt; bazel-bin/tensorflow/examples/label_image/label_image \\\n--input_graph=/tmp/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--mean_value=128 \\\n--std_value=128 \\\n--input_layer_name=\"Mul:0\" \\\n--output_layer_name=\"softmax:0\"\n</code></pre>\n<p>( a not-so-important change is, in fact, I found the script above didn't work, so I changed some parameter names as below: )</p>\n<pre><code>&gt;&gt; bazel-bin/tensorflow/examples/label_image/label_image \n--graph=/tmp/imagenet/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--input_mean=128 \\\n--input_std=128 \\\n--input_layer=\"Mul:0\"\\\n--output_layer=\"softmax:0\"\n</code></pre>\n<p>However, I got the error:</p>\n<pre><code>E tensorflow/examples/label_image/main.cc:281] Not found: Op type not registered 'Dequantize'\n</code></pre>\n<p>Do anyone know how to fix this? thanks a lot in advance :)</p>", "body_text": "hello, I'm learning to do 8-bit quantization following the How-to-tutorial step-by-step, after I managed to output the quantized_graph.pb, then I was trying to test it, just like the tutorial:\n>> bazel build tensorflow/examples/label_image:label_image\n>> bazel-bin/tensorflow/examples/label_image/label_image \\\n--input_graph=/tmp/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--mean_value=128 \\\n--std_value=128 \\\n--input_layer_name=\"Mul:0\" \\\n--output_layer_name=\"softmax:0\"\n\n( a not-so-important change is, in fact, I found the script above didn't work, so I changed some parameter names as below: )\n>> bazel-bin/tensorflow/examples/label_image/label_image \n--graph=/tmp/imagenet/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--input_mean=128 \\\n--input_std=128 \\\n--input_layer=\"Mul:0\"\\\n--output_layer=\"softmax:0\"\n\nHowever, I got the error:\nE tensorflow/examples/label_image/main.cc:281] Not found: Op type not registered 'Dequantize'\n\nDo anyone know how to fix this? thanks a lot in advance :)", "body": "hello, I'm learning to do 8-bit quantization following the [How-to-tutorial](https://www.tensorflow.org/versions/master/how_tos/quantization/index.html) step-by-step, after I managed to output the `quantized_graph.pb`, then I was trying to test it, just like the tutorial:\n\n```\n>> bazel build tensorflow/examples/label_image:label_image\n>> bazel-bin/tensorflow/examples/label_image/label_image \\\n--input_graph=/tmp/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--mean_value=128 \\\n--std_value=128 \\\n--input_layer_name=\"Mul:0\" \\\n--output_layer_name=\"softmax:0\"\n```\n\n( a not-so-important change is, in fact, I found the script above didn't work, so I changed some parameter names as below: )\n\n```\n>> bazel-bin/tensorflow/examples/label_image/label_image \n--graph=/tmp/imagenet/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--input_mean=128 \\\n--input_std=128 \\\n--input_layer=\"Mul:0\"\\\n--output_layer=\"softmax:0\"\n```\n\nHowever, I got the error:\n\n```\nE tensorflow/examples/label_image/main.cc:281] Not found: Op type not registered 'Dequantize'\n```\n\nDo anyone know how to fix this? thanks a lot in advance :)\n"}