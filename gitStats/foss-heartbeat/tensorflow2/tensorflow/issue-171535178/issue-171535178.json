{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3864", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3864/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3864/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3864/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3864", "id": 171535178, "node_id": "MDU6SXNzdWUxNzE1MzUxNzg=", "number": 3864, "title": "Tensorflow r.0.10, CUDA 8.0, cuDNN 5.1 core dumped, CUDA_ERROR_OUT_OF_MEMORY", "user": {"login": "iNLyze", "id": 8356146, "node_id": "MDQ6VXNlcjgzNTYxNDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8356146?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iNLyze", "html_url": "https://github.com/iNLyze", "followers_url": "https://api.github.com/users/iNLyze/followers", "following_url": "https://api.github.com/users/iNLyze/following{/other_user}", "gists_url": "https://api.github.com/users/iNLyze/gists{/gist_id}", "starred_url": "https://api.github.com/users/iNLyze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iNLyze/subscriptions", "organizations_url": "https://api.github.com/users/iNLyze/orgs", "repos_url": "https://api.github.com/users/iNLyze/repos", "events_url": "https://api.github.com/users/iNLyze/events{/privacy}", "received_events_url": "https://api.github.com/users/iNLyze/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-08-16T22:42:25Z", "updated_at": "2017-02-04T04:03:43Z", "closed_at": "2016-08-18T23:07:14Z", "author_association": "NONE", "body_html": "<p>On running a benchmark with MNIST data on a CNN (source below) tensorflow first complains about memory allocation and then appears to have trouble using cuDNN 5.1<br>\nDetailed script and output at the bottom.<br>\nProblem appears to affect cuDNN specifically as I could run CUDA examples as well as matmul on tensorflow without problems.</p>\n<h3>Environment info</h3>\n<p>Operating System: ubuntu 16.04<br>\nuname -a<br>\nLinux  4.4.0-34-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115998800\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/53\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/53/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/53\">#53</a>-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>Installed version of CUDA and cuDNN:<br>\nls -l $CUDA_HOME/lib64/libcud*<br>\n-rw-r--r-- 1 root root   560184 Aug 15 22:51 /usr/local/cuda/lib64/libcudadevrt.a<br>\nlrwxrwxrwx 1 root root       16 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0<br>\nlrwxrwxrwx 1 root root       19 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27<br>\n-rwxr-xr-x 1 root root   394472 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0.27<br>\n-rw-r--r-- 1 root root   737516 Aug 15 22:51 /usr/local/cuda/lib64/libcudart_static.a<br>\nlrwxrwxrwx 1 root root       13 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5<br>\nlrwxrwxrwx 1 root root       17 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.5<br>\n-rwxr-xr-x 1 root root 79337624 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5.1.5<br>\n-rw-r--r-- 1 root root 69756172 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn_static.a</p>\n<h3>Environment variables</h3>\n<p>echo $LD_LIBRARY_PATH<br>\n/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64<br>\necho $CUDA_HOME<br>\n/usr/local/cuda<br>\necho $PATH<br>\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin/:/usr/local/cuda/bin/</p>\n<h3>Tensorflow version</h3>\n<p>Compiled from source, r0.10, built into pip package and installed this pip wheel<br>\nConfigured with cuDNN path and version set to system default</p>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\nsee /// OUTPUT /// at the end</li>\n</ol>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)<br>\nn.a.<br>\nversion r0.10</li>\n<li>The output of <code>bazel version</code><br>\nbazel version<br>\nBuild label: 0.3.1-2016-08-15 (@936c2c2)<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Sun Aug 14 23:07:32 2016 (1471216052)<br>\nBuild timestamp: 1471216052<br>\nBuild timestamp as int: 1471216052</li>\n</ol>\n<h3>Steps to reproduce: run this script</h3>\n<p>import numpy<br>\nfrom keras.datasets import mnist<br>\nfrom keras.models import Sequential<br>\nfrom keras.layers import Dense<br>\nfrom keras.layers import Dropout<br>\nfrom keras.layers import Flatten<br>\nfrom keras.layers.convolutional import Convolution2D<br>\nfrom keras.layers.convolutional import MaxPooling2D<br>\nfrom keras.utils import np_utils</p>\n<h5>fix random seed for reproducibility</h5>\n<p>seed = 7<br>\nnumpy.random.seed(seed)</p>\n<h5>load data</h5>\n<p>(X_train, y_train), (X_test, y_test) = mnist.load_data()</p>\n<h5>reshape to be [samples][channels][width][height]</h5>\n<p>X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')<br>\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')</p>\n<h5>normalize inputs from 0-255 to 0-1</h5>\n<p>X_train = X_train / 255<br>\nX_test = X_test / 255</p>\n<h5>one hot encode outputs</h5>\n<p>y_train = np_utils.to_categorical(y_train)<br>\ny_test = np_utils.to_categorical(y_test)<br>\nnum_classes = y_test.shape[1]</p>\n<h5>define a simple CNN model</h5>\n<p>def baseline_model():<br>\n##### create model<br>\nmodel = Sequential()<br>\nmodel.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))<br>\nmodel.add(MaxPooling2D(pool_size=(2, 2)))<br>\nmodel.add(Dropout(0.2))<br>\nmodel.add(Flatten())<br>\nmodel.add(Dense(128, activation='relu'))<br>\nmodel.add(Dense(num_classes, activation='softmax'))<br>\n##### Compile model<br>\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br>\nreturn model</p>\n<h5>build the model</h5>\n<p>model = baseline_model()</p>\n<h5>Fit the model</h5>\n<p>model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)</p>\n<h5>Final evaluation of the model</h5>\n<p>scores = model.evaluate(X_test, y_test, verbose=0)<br>\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))</p>\n<h3>///////////// OUTPUT /////////////////</h3>\n<p>Using TensorFlow backend.<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 1070<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.683<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 7.91GiB<br>\nFree memory: 148.69MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)<br>\nE tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 148.69M (155910144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY<br>\nTrain on 60000 samples, validate on 10000 samples<br>\nEpoch 1/10<br>\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR<br>\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM<br>\nF tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms)<br>\nAborted (core dumped)</p>", "body_text": "On running a benchmark with MNIST data on a CNN (source below) tensorflow first complains about memory allocation and then appears to have trouble using cuDNN 5.1\nDetailed script and output at the bottom.\nProblem appears to affect cuDNN specifically as I could run CUDA examples as well as matmul on tensorflow without problems.\nEnvironment info\nOperating System: ubuntu 16.04\nuname -a\nLinux  4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nInstalled version of CUDA and cuDNN:\nls -l $CUDA_HOME/lib64/libcud*\n-rw-r--r-- 1 root root   560184 Aug 15 22:51 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Aug 15 22:51 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn_static.a\nEnvironment variables\necho $LD_LIBRARY_PATH\n/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\necho $CUDA_HOME\n/usr/local/cuda\necho $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin/:/usr/local/cuda/bin/\nTensorflow version\nCompiled from source, r0.10, built into pip package and installed this pip wheel\nConfigured with cuDNN path and version set to system default\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\nsee /// OUTPUT /// at the end\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\nn.a.\nversion r0.10\nThe output of bazel version\nbazel version\nBuild label: 0.3.1-2016-08-15 (@936c2c2)\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Sun Aug 14 23:07:32 2016 (1471216052)\nBuild timestamp: 1471216052\nBuild timestamp as int: 1471216052\n\nSteps to reproduce: run this script\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\nload data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nreshape to be [samples][channels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\nnormalize inputs from 0-255 to 0-1\nX_train = X_train / 255\nX_test = X_test / 255\none hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\ndefine a simple CNN model\ndef baseline_model():\n##### create model\nmodel = Sequential()\nmodel.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n##### Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nreturn model\nbuild the model\nmodel = baseline_model()\nFit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\nFinal evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n///////////// OUTPUT /////////////////\nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.683\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 148.69MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 148.69M (155910144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\nF tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)\nAborted (core dumped)", "body": "On running a benchmark with MNIST data on a CNN (source below) tensorflow first complains about memory allocation and then appears to have trouble using cuDNN 5.1\nDetailed script and output at the bottom. \nProblem appears to affect cuDNN specifically as I could run CUDA examples as well as matmul on tensorflow without problems. \n### Environment info\n\nOperating System: ubuntu 16.04\nuname -a\nLinux <Name> 4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nInstalled version of CUDA and cuDNN: \nls -l $CUDA_HOME/lib64/libcud*\n-rw-r--r-- 1 root root   560184 Aug 15 22:51 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Aug 15 22:51 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn_static.a\n### Environment variables\n\necho $LD_LIBRARY_PATH\n/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\necho $CUDA_HOME\n/usr/local/cuda\necho $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin/:/usr/local/cuda/bin/\n### Tensorflow version\n\nCompiled from source, r0.10, built into pip package and installed this pip wheel\nConfigured with cuDNN path and version set to system default\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   see /// OUTPUT /// at the end\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   n.a.\n   version r0.10\n2. The output of `bazel version`\n   bazel version\n   Build label: 0.3.1-2016-08-15 (@936c2c2)\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Sun Aug 14 23:07:32 2016 (1471216052)\n   Build timestamp: 1471216052\n   Build timestamp as int: 1471216052\n### Steps to reproduce: run this script\n\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\n##### fix random seed for reproducibility\n\nseed = 7\nnumpy.random.seed(seed)\n##### load data\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n##### reshape to be [samples][channels][width][height]\n\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n##### normalize inputs from 0-255 to 0-1\n\nX_train = X_train / 255\nX_test = X_test / 255\n##### one hot encode outputs\n\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\n##### define a simple CNN model\n\ndef baseline_model():\n    ##### create model\n    model = Sequential()\n    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    ##### Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n##### build the model\n\nmodel = baseline_model()\n##### Fit the model\n\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n##### Final evaluation of the model\n\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n### ///////////// OUTPUT /////////////////\n\nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.683\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 148.69MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 148.69M (155910144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\nF tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \nAborted (core dumped)\n"}