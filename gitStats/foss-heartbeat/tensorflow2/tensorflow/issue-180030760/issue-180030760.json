{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4655", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4655/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4655/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4655/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4655", "id": 180030760, "node_id": "MDU6SXNzdWUxODAwMzA3NjA=", "number": 4655, "title": "expend the output of CNN", "user": {"login": "chamas14", "id": 7315508, "node_id": "MDQ6VXNlcjczMTU1MDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/7315508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chamas14", "html_url": "https://github.com/chamas14", "followers_url": "https://api.github.com/users/chamas14/followers", "following_url": "https://api.github.com/users/chamas14/following{/other_user}", "gists_url": "https://api.github.com/users/chamas14/gists{/gist_id}", "starred_url": "https://api.github.com/users/chamas14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chamas14/subscriptions", "organizations_url": "https://api.github.com/users/chamas14/orgs", "repos_url": "https://api.github.com/users/chamas14/repos", "events_url": "https://api.github.com/users/chamas14/events{/privacy}", "received_events_url": "https://api.github.com/users/chamas14/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-09-29T12:07:43Z", "updated_at": "2016-10-01T20:25:09Z", "closed_at": "2016-10-01T20:25:09Z", "author_association": "NONE", "body_html": "<p>I am trying to expend the outputs of my network from 11 to 12 outputs, i have restored the previous checkpoint that is already retrained in 11 outputs. I got the answer from  here <a href=\"http://stackoverflow.com/questions/34913762/how-to-expand-a-tensorflow-variable\" rel=\"nofollow\">http://stackoverflow.com/questions/34913762/how-to-expand-a-tensorflow-variable</a> in This question told me how to change the shape of the variable, to expand it to fit another row of weights, but I don't know if i initialize the weight and biases in the right way. Actually i don't have error but the the test accuracy is decreased from 95% to 9%. may be there is somewhere wrong issue in the code. that's the code:</p>\n<pre><code> w_b_not = {\n  'weight_4': tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1)),\n  'bias_4'  : tf.Variable(tf.constant(1.0, shape=[num_labels])),}\n\n w_b = {\n  'wc1_0': tf.Variable(tf.random_normal([patch_size_1, patch_size_1, num_channels, depth],stddev=0.1)),\n   .....\n  'bc1_0' : tf.Variable(tf.zeros([depth]))}\n\n .... #here is the networks model\n\n num_steps = 1001 \n with tf.Session(graph=graph) as sess:\n    ckpt = ('path_of_checkpoint.ckpt')\n    if os.path.isfile(ckpt) :\n       layer6_weights = tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1))\n       layer6_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n  n_w_b = {\n  'new_layer_weights' : tf.concat(0,[w_b_not['weight_4'], layer6_weights]),\n  'new_layer_biases' : tf.concat(0,[w_b_not['bias_4'], layer6_biases])}\n  resize_var_1 = tf.assign(w_b_not['weight_4'], n_w_b['new_layer_weights'], validate_shape=False)\n  resize_var_2 = tf.assign(w_b_not['bias_4'], n_w_b['new_layer_biases'], validate_shape=False)\n  logits = tf.get_collection('logits')[0]\n  w_b_new_saver = tf.train.Saver()\n  init_op = tf.initialize_all_variables()        \n  w_b_saver.restore(sess, ckpt)\n  print(\"restore complete\")\n  for step in xrange(num_steps):\n    sess.run(init_op)\n  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval() , test_labels,  force = False ))  \n</code></pre>", "body_text": "I am trying to expend the outputs of my network from 11 to 12 outputs, i have restored the previous checkpoint that is already retrained in 11 outputs. I got the answer from  here http://stackoverflow.com/questions/34913762/how-to-expand-a-tensorflow-variable in This question told me how to change the shape of the variable, to expand it to fit another row of weights, but I don't know if i initialize the weight and biases in the right way. Actually i don't have error but the the test accuracy is decreased from 95% to 9%. may be there is somewhere wrong issue in the code. that's the code:\n w_b_not = {\n  'weight_4': tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1)),\n  'bias_4'  : tf.Variable(tf.constant(1.0, shape=[num_labels])),}\n\n w_b = {\n  'wc1_0': tf.Variable(tf.random_normal([patch_size_1, patch_size_1, num_channels, depth],stddev=0.1)),\n   .....\n  'bc1_0' : tf.Variable(tf.zeros([depth]))}\n\n .... #here is the networks model\n\n num_steps = 1001 \n with tf.Session(graph=graph) as sess:\n    ckpt = ('path_of_checkpoint.ckpt')\n    if os.path.isfile(ckpt) :\n       layer6_weights = tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1))\n       layer6_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n  n_w_b = {\n  'new_layer_weights' : tf.concat(0,[w_b_not['weight_4'], layer6_weights]),\n  'new_layer_biases' : tf.concat(0,[w_b_not['bias_4'], layer6_biases])}\n  resize_var_1 = tf.assign(w_b_not['weight_4'], n_w_b['new_layer_weights'], validate_shape=False)\n  resize_var_2 = tf.assign(w_b_not['bias_4'], n_w_b['new_layer_biases'], validate_shape=False)\n  logits = tf.get_collection('logits')[0]\n  w_b_new_saver = tf.train.Saver()\n  init_op = tf.initialize_all_variables()        \n  w_b_saver.restore(sess, ckpt)\n  print(\"restore complete\")\n  for step in xrange(num_steps):\n    sess.run(init_op)\n  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval() , test_labels,  force = False ))", "body": "I am trying to expend the outputs of my network from 11 to 12 outputs, i have restored the previous checkpoint that is already retrained in 11 outputs. I got the answer from  here http://stackoverflow.com/questions/34913762/how-to-expand-a-tensorflow-variable in This question told me how to change the shape of the variable, to expand it to fit another row of weights, but I don't know if i initialize the weight and biases in the right way. Actually i don't have error but the the test accuracy is decreased from 95% to 9%. may be there is somewhere wrong issue in the code. that's the code:\n\n```\n w_b_not = {\n  'weight_4': tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1)),\n  'bias_4'  : tf.Variable(tf.constant(1.0, shape=[num_labels])),}\n\n w_b = {\n  'wc1_0': tf.Variable(tf.random_normal([patch_size_1, patch_size_1, num_channels, depth],stddev=0.1)),\n   .....\n  'bc1_0' : tf.Variable(tf.zeros([depth]))}\n\n .... #here is the networks model\n\n num_steps = 1001 \n with tf.Session(graph=graph) as sess:\n    ckpt = ('path_of_checkpoint.ckpt')\n    if os.path.isfile(ckpt) :\n       layer6_weights = tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1))\n       layer6_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n  n_w_b = {\n  'new_layer_weights' : tf.concat(0,[w_b_not['weight_4'], layer6_weights]),\n  'new_layer_biases' : tf.concat(0,[w_b_not['bias_4'], layer6_biases])}\n  resize_var_1 = tf.assign(w_b_not['weight_4'], n_w_b['new_layer_weights'], validate_shape=False)\n  resize_var_2 = tf.assign(w_b_not['bias_4'], n_w_b['new_layer_biases'], validate_shape=False)\n  logits = tf.get_collection('logits')[0]\n  w_b_new_saver = tf.train.Saver()\n  init_op = tf.initialize_all_variables()        \n  w_b_saver.restore(sess, ckpt)\n  print(\"restore complete\")\n  for step in xrange(num_steps):\n    sess.run(init_op)\n  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval() , test_labels,  force = False ))  \n```\n"}