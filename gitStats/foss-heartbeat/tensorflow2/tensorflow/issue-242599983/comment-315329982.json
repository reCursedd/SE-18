{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315329982", "html_url": "https://github.com/tensorflow/tensorflow/issues/11470#issuecomment-315329982", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11470", "id": 315329982, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTMyOTk4Mg==", "user": {"login": "josemlopez", "id": 4112135, "node_id": "MDQ6VXNlcjQxMTIxMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/4112135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josemlopez", "html_url": "https://github.com/josemlopez", "followers_url": "https://api.github.com/users/josemlopez/followers", "following_url": "https://api.github.com/users/josemlopez/following{/other_user}", "gists_url": "https://api.github.com/users/josemlopez/gists{/gist_id}", "starred_url": "https://api.github.com/users/josemlopez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josemlopez/subscriptions", "organizations_url": "https://api.github.com/users/josemlopez/orgs", "repos_url": "https://api.github.com/users/josemlopez/repos", "events_url": "https://api.github.com/users/josemlopez/events{/privacy}", "received_events_url": "https://api.github.com/users/josemlopez/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-14T10:43:37Z", "updated_at": "2017-07-14T10:43:37Z", "author_association": "NONE", "body_html": "<p>Hi asimshankar,</p>\n<p>This is my python side:</p>\n<pre><code>#!/usr/bin/env python\n\ntry:\n    import cPickle as pickle\n    from urllib2 import urlopen\nexcept ImportError:\n    import pickle\n    from urllib.request import urlopen\n\nimport logging\n\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.losses.python.losses import loss_ops\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.saved_model import builder as saved_model_builder\n\nFILE_SEED = 42\nIMG_SIZE = 128\n\npathToSaveModel = './tmpTestNewX/model'\n\n\ndef loadFeatures(files):\n    data = np.ndarray((len(files), IMG_SIZE * IMG_SIZE * 3))\n    for n, f in enumerate(files):\n        logging.debug('loading file #%d' % n)\n        img = cv2.imread(f)\n        h, w, _ = img.shape\n        if w &gt; h:\n            diff = w - h\n            img = img[:, diff / 2: diff / 2 + h]\n        elif w &lt; h:\n            diff = h - w\n            img = img[diff / 2: diff / 2 + w, :]\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        data[n] = img.ravel()\n\n    return data\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\nxavier = tf.contrib.layers.xavier_initializer\n\nif __name__ == '__main__':\n    with tf.Session(graph=tf.Graph()) as session:\n        x = tf.placeholder(tf.float32, shape=[None, IMG_SIZE * IMG_SIZE * 3], name=\"input_jm\")\n        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=\"y_\")\n\n        x_image = tf.reshape(x, [-1, IMG_SIZE, IMG_SIZE, 3])  # 128\n\n        W_conv1 = tf.get_variable(\"W_conv1\", shape=[3, 3, 3, 6], initializer=xavier())\n        b_conv1 = tf.get_variable('b_conv1', [1, 1, 1, 6])\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n        h_pool1 = max_pool_2x2(h_conv1)  # 64\n\n        W_conv2 = tf.get_variable(\"W_conv2\", shape=[3, 3, 6, 6], initializer=xavier())\n        b_conv2 = tf.get_variable('b_conv2', [1, 1, 1, 6])\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n        h_pool2 = max_pool_2x2(h_conv2)  # 32\n\n        W_conv3 = tf.get_variable(\"W_conv3\", shape=[3, 3, 6, 12], initializer=xavier())\n        b_conv3 = tf.get_variable('b_conv3', [1, 1, 1, 12])\n        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n        h_pool3 = max_pool_2x2(h_conv3)  # 16\n\n        W_conv4 = tf.get_variable(\"W_conv4\", shape=[3, 3, 12, 24], initializer=xavier())\n        b_conv4 = tf.get_variable('b_conv4', [1, 1, 1, 24])\n        h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n        h_pool4 = max_pool_2x2(h_conv4)  # 8\n\n        h_pool4_flat = tf.reshape(h_pool4, [-1, 8 * 8 * 24])\n\n        W_fc1 = tf.get_variable(\"W_fc1\", shape=[8 * 8 * 24, 1024], initializer=xavier())\n        b_fc1 = tf.get_variable('b_fc1', [1024], initializer=init_ops.zeros_initializer)\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\n\n        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n        W_fcO = tf.get_variable(\"W_fcO\", shape=[1024, 2], initializer=xavier())\n        b_fcO = tf.get_variable('b_fcO', [2], initializer=init_ops.zeros_initializer)\n\n        logits = tf.matmul(h_fc1_drop, W_fcO) + b_fcO\n        y_conv = tf.nn.softmax(logits)\n\n        cross_entropy = loss_ops.softmax_cross_entropy(logits, y_)\n\n        train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)\n\n        predictions = predictions = tf.argmax(y_conv, 1, name=\"predictions\")\n\n        #Load\n        saver = tf.train.Saver()\n        saver.restore(session, \"./newModel.ckpt\")\n\n        collection_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\n        r1 = session.run(W_conv1)\n        path = \"./\"\n        classS = [\"girl1.jpg\"]\n        classS_1 = [\"car1.jpg\", \"cat1.jpg\", \"girlOk1.jpg\"]\n        classNS_running = [\"manRunning.jpg\", \"manRunning1.jpg\", \"girlRunning.jpg\"]\n        classS_other = [\"baby-shower-cap.jpg\", \"Bottle.jpg\"]\n        images = classS + classS_1 + classNS_running + classS_other\n        images2 = [path + i for i in images]\n        for image in images2:\n            features = loadFeatures([image])\n            res = predictions.eval(\n                 feed_dict={\n                     x: features,\n                     keep_prob: 1.0, }\n            )\n            print('Image {} has a prob {} '.format(image, res))\n\n\n        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n        b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\n        b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING]) #, legacy_init_op=legacy_init_op)\n        b.save()\n</code></pre>\n<p>And this is my Java side:</p>\n<pre><code>import org.tensorflow.*;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.List;\n\npublic class LoadModelSample {\n\n    // In the fullness of time, equivalents of the methods of this class should be auto-generated from\n    // the OpDefs linked into libtensorflow_jni.so. That would match what is done in other languages\n    // like Python, C++ and Go.\n    static class GraphBuilder {\n        GraphBuilder(Graph g) {\n            this.g = g;\n        }\n\n        Output div(Output x, Output y) {\n            return binaryOp(\"Div\", x, y);\n        }\n\n        Output sub(Output x, Output y) {\n            return binaryOp(\"Sub\", x, y);\n        }\n\n        Output resizeBilinear(Output images, Output size) {\n            return binaryOp(\"ResizeArea\", images, size);\n        }\n\n        Output expandDims(Output input, Output dim) {\n            return binaryOp(\"ExpandDims\", input, dim);\n        }\n\n        Output cast(Output value, DataType dtype) {\n            return g.opBuilder(\"Cast\", \"Cast\").addInput(value).setAttr(\"DstT\", dtype).build().output(0);\n        }\n\n        Output decodeJpeg(Output contents, long channels) {\n            return g.opBuilder(\"DecodeJpeg\", \"DecodeJpeg\")\n                    .addInput(contents)\n                    .setAttr(\"channels\", channels)\n                    .build()\n                    .output(0);\n        }\n\n        Output constant(String name, Object value) {\n            try (Tensor t = Tensor.create(value)) {\n                return g.opBuilder(\"Const\", name)\n                        .setAttr(\"dtype\", t.dataType())\n                        .setAttr(\"value\", t)\n                        .build()\n                        .output(0);\n            }\n        }\n\n        private Output binaryOp(String type, Output in1, Output in2) {\n            return g.opBuilder(type, type).addInput(in1).addInput(in2).build().output(0);\n        }\n\n        private Graph g;\n    }\n\n    private static byte[] readAllBytesOrExit(Path path) {\n        try {\n            return Files.readAllBytes(path);\n        } catch (IOException e) {\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\n            System.exit(1);\n        }\n        return null;\n    }\n\n    private static Tensor constructAndExecuteGraphToNormalizeImage(int img_size, byte[] imageBytes) {\n        try (Graph g = new Graph()) {\n            GraphBuilder b = new GraphBuilder(g);\n            // Some constants specific to the pre-trained model at:\n            // https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n            //\n            // - The model was trained with images scaled to img_sizeXimg_size pixels.\n            // - The colors, represented as R, G, B in 1-byte each were converted to\n            //   float using (value - Mean)/Scale.\n            final int H = img_size; //224;\n            final int W = img_size; //224;\n            final float mean = 117f;\n            final float scale = 1f;\n\n            // Since the graph is being constructed once per execution here, we can use a constant for the\n            // input image. If the graph were to be re-used for multiple input images, a placeholder would\n            // have been more appropriate.\n            final Output input = b.constant(\"input\", imageBytes);\n            final Output output =\n                    b.div(\n                            //b.sub(\n                            b.resizeBilinear(\n                                    b.expandDims(\n                                            b.cast(b.decodeJpeg(input, 3), DataType.FLOAT),\n                                            b.constant(\"make_batch\", 0)\n                                    ),\n                                    b.constant(\"size\", new int[] {H, W})),\n                            //       b.constant(\"mean\", mean)),\n                            b.constant(\"scale\", scale));\n            try (Session s = new Session(g)) {\n                Tensor result = s.runner().fetch(output.op().name()).run().get(0);\n                return result;\n            }\n        }\n    }\n\n    private static List&lt;String&gt; readAllLinesOrExit(Path path) {\n        try {\n            return Files.readAllLines(path, Charset.forName(\"UTF-8\"));\n        } catch (IOException e) {\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\n            System.exit(0);\n        }\n        return null;\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        final int IMG_SIZE = 128;\n        final String value = \"Hello from \" + TensorFlow.version();\n        System.out.print(value+\"\\\\n\");\n\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNewX/model\", \"train\");\n\n        long[] sitio2;\n        try (Graph g = load.graph()) {\n            try (Session s = load.session();)\n            {\n                String[] images = new String[] { \"./cat1.jpg\", \"./girl1.jpg\", \"./bottle.jpg\" };\n                for (String imgName : images) {\n                    byte[] imageBytes = readAllBytesOrExit(Paths.get(imgName));\n                    Tensor image = constructAndExecuteGraphToNormalizeImage(IMG_SIZE, imageBytes); //constructImage(IMG_SIZE, imageBytes);\n                    Tensor result = s.runner()\n                            .feed(\"keep_prob\", Tensor.create(1.0F))\n                            .feed(\"input_jm\", image)\n                            .fetch(\"predictions\").run().get(0);\n                    sitio2 = result.copyTo(new long[1]);\n                    System.out.print(imgName+\" -&gt; \"+sitio2[0]+\"\\n\");\n                }\n\n            }\n        }\n        load.close();\n    }\n}\n</code></pre>\n<p>My example is pretty simple, I think. Maybe is a problem with versions or something I'm missing?</p>", "body_text": "Hi asimshankar,\nThis is my python side:\n#!/usr/bin/env python\n\ntry:\n    import cPickle as pickle\n    from urllib2 import urlopen\nexcept ImportError:\n    import pickle\n    from urllib.request import urlopen\n\nimport logging\n\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.losses.python.losses import loss_ops\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.saved_model import builder as saved_model_builder\n\nFILE_SEED = 42\nIMG_SIZE = 128\n\npathToSaveModel = './tmpTestNewX/model'\n\n\ndef loadFeatures(files):\n    data = np.ndarray((len(files), IMG_SIZE * IMG_SIZE * 3))\n    for n, f in enumerate(files):\n        logging.debug('loading file #%d' % n)\n        img = cv2.imread(f)\n        h, w, _ = img.shape\n        if w > h:\n            diff = w - h\n            img = img[:, diff / 2: diff / 2 + h]\n        elif w < h:\n            diff = h - w\n            img = img[diff / 2: diff / 2 + w, :]\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        data[n] = img.ravel()\n\n    return data\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\nxavier = tf.contrib.layers.xavier_initializer\n\nif __name__ == '__main__':\n    with tf.Session(graph=tf.Graph()) as session:\n        x = tf.placeholder(tf.float32, shape=[None, IMG_SIZE * IMG_SIZE * 3], name=\"input_jm\")\n        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=\"y_\")\n\n        x_image = tf.reshape(x, [-1, IMG_SIZE, IMG_SIZE, 3])  # 128\n\n        W_conv1 = tf.get_variable(\"W_conv1\", shape=[3, 3, 3, 6], initializer=xavier())\n        b_conv1 = tf.get_variable('b_conv1', [1, 1, 1, 6])\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n        h_pool1 = max_pool_2x2(h_conv1)  # 64\n\n        W_conv2 = tf.get_variable(\"W_conv2\", shape=[3, 3, 6, 6], initializer=xavier())\n        b_conv2 = tf.get_variable('b_conv2', [1, 1, 1, 6])\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n        h_pool2 = max_pool_2x2(h_conv2)  # 32\n\n        W_conv3 = tf.get_variable(\"W_conv3\", shape=[3, 3, 6, 12], initializer=xavier())\n        b_conv3 = tf.get_variable('b_conv3', [1, 1, 1, 12])\n        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n        h_pool3 = max_pool_2x2(h_conv3)  # 16\n\n        W_conv4 = tf.get_variable(\"W_conv4\", shape=[3, 3, 12, 24], initializer=xavier())\n        b_conv4 = tf.get_variable('b_conv4', [1, 1, 1, 24])\n        h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n        h_pool4 = max_pool_2x2(h_conv4)  # 8\n\n        h_pool4_flat = tf.reshape(h_pool4, [-1, 8 * 8 * 24])\n\n        W_fc1 = tf.get_variable(\"W_fc1\", shape=[8 * 8 * 24, 1024], initializer=xavier())\n        b_fc1 = tf.get_variable('b_fc1', [1024], initializer=init_ops.zeros_initializer)\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\n\n        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n        W_fcO = tf.get_variable(\"W_fcO\", shape=[1024, 2], initializer=xavier())\n        b_fcO = tf.get_variable('b_fcO', [2], initializer=init_ops.zeros_initializer)\n\n        logits = tf.matmul(h_fc1_drop, W_fcO) + b_fcO\n        y_conv = tf.nn.softmax(logits)\n\n        cross_entropy = loss_ops.softmax_cross_entropy(logits, y_)\n\n        train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)\n\n        predictions = predictions = tf.argmax(y_conv, 1, name=\"predictions\")\n\n        #Load\n        saver = tf.train.Saver()\n        saver.restore(session, \"./newModel.ckpt\")\n\n        collection_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\n        r1 = session.run(W_conv1)\n        path = \"./\"\n        classS = [\"girl1.jpg\"]\n        classS_1 = [\"car1.jpg\", \"cat1.jpg\", \"girlOk1.jpg\"]\n        classNS_running = [\"manRunning.jpg\", \"manRunning1.jpg\", \"girlRunning.jpg\"]\n        classS_other = [\"baby-shower-cap.jpg\", \"Bottle.jpg\"]\n        images = classS + classS_1 + classNS_running + classS_other\n        images2 = [path + i for i in images]\n        for image in images2:\n            features = loadFeatures([image])\n            res = predictions.eval(\n                 feed_dict={\n                     x: features,\n                     keep_prob: 1.0, }\n            )\n            print('Image {} has a prob {} '.format(image, res))\n\n\n        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n        b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\n        b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING]) #, legacy_init_op=legacy_init_op)\n        b.save()\n\nAnd this is my Java side:\nimport org.tensorflow.*;\n\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.List;\n\npublic class LoadModelSample {\n\n    // In the fullness of time, equivalents of the methods of this class should be auto-generated from\n    // the OpDefs linked into libtensorflow_jni.so. That would match what is done in other languages\n    // like Python, C++ and Go.\n    static class GraphBuilder {\n        GraphBuilder(Graph g) {\n            this.g = g;\n        }\n\n        Output div(Output x, Output y) {\n            return binaryOp(\"Div\", x, y);\n        }\n\n        Output sub(Output x, Output y) {\n            return binaryOp(\"Sub\", x, y);\n        }\n\n        Output resizeBilinear(Output images, Output size) {\n            return binaryOp(\"ResizeArea\", images, size);\n        }\n\n        Output expandDims(Output input, Output dim) {\n            return binaryOp(\"ExpandDims\", input, dim);\n        }\n\n        Output cast(Output value, DataType dtype) {\n            return g.opBuilder(\"Cast\", \"Cast\").addInput(value).setAttr(\"DstT\", dtype).build().output(0);\n        }\n\n        Output decodeJpeg(Output contents, long channels) {\n            return g.opBuilder(\"DecodeJpeg\", \"DecodeJpeg\")\n                    .addInput(contents)\n                    .setAttr(\"channels\", channels)\n                    .build()\n                    .output(0);\n        }\n\n        Output constant(String name, Object value) {\n            try (Tensor t = Tensor.create(value)) {\n                return g.opBuilder(\"Const\", name)\n                        .setAttr(\"dtype\", t.dataType())\n                        .setAttr(\"value\", t)\n                        .build()\n                        .output(0);\n            }\n        }\n\n        private Output binaryOp(String type, Output in1, Output in2) {\n            return g.opBuilder(type, type).addInput(in1).addInput(in2).build().output(0);\n        }\n\n        private Graph g;\n    }\n\n    private static byte[] readAllBytesOrExit(Path path) {\n        try {\n            return Files.readAllBytes(path);\n        } catch (IOException e) {\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\n            System.exit(1);\n        }\n        return null;\n    }\n\n    private static Tensor constructAndExecuteGraphToNormalizeImage(int img_size, byte[] imageBytes) {\n        try (Graph g = new Graph()) {\n            GraphBuilder b = new GraphBuilder(g);\n            // Some constants specific to the pre-trained model at:\n            // https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n            //\n            // - The model was trained with images scaled to img_sizeXimg_size pixels.\n            // - The colors, represented as R, G, B in 1-byte each were converted to\n            //   float using (value - Mean)/Scale.\n            final int H = img_size; //224;\n            final int W = img_size; //224;\n            final float mean = 117f;\n            final float scale = 1f;\n\n            // Since the graph is being constructed once per execution here, we can use a constant for the\n            // input image. If the graph were to be re-used for multiple input images, a placeholder would\n            // have been more appropriate.\n            final Output input = b.constant(\"input\", imageBytes);\n            final Output output =\n                    b.div(\n                            //b.sub(\n                            b.resizeBilinear(\n                                    b.expandDims(\n                                            b.cast(b.decodeJpeg(input, 3), DataType.FLOAT),\n                                            b.constant(\"make_batch\", 0)\n                                    ),\n                                    b.constant(\"size\", new int[] {H, W})),\n                            //       b.constant(\"mean\", mean)),\n                            b.constant(\"scale\", scale));\n            try (Session s = new Session(g)) {\n                Tensor result = s.runner().fetch(output.op().name()).run().get(0);\n                return result;\n            }\n        }\n    }\n\n    private static List<String> readAllLinesOrExit(Path path) {\n        try {\n            return Files.readAllLines(path, Charset.forName(\"UTF-8\"));\n        } catch (IOException e) {\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\n            System.exit(0);\n        }\n        return null;\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        final int IMG_SIZE = 128;\n        final String value = \"Hello from \" + TensorFlow.version();\n        System.out.print(value+\"\\\\n\");\n\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNewX/model\", \"train\");\n\n        long[] sitio2;\n        try (Graph g = load.graph()) {\n            try (Session s = load.session();)\n            {\n                String[] images = new String[] { \"./cat1.jpg\", \"./girl1.jpg\", \"./bottle.jpg\" };\n                for (String imgName : images) {\n                    byte[] imageBytes = readAllBytesOrExit(Paths.get(imgName));\n                    Tensor image = constructAndExecuteGraphToNormalizeImage(IMG_SIZE, imageBytes); //constructImage(IMG_SIZE, imageBytes);\n                    Tensor result = s.runner()\n                            .feed(\"keep_prob\", Tensor.create(1.0F))\n                            .feed(\"input_jm\", image)\n                            .fetch(\"predictions\").run().get(0);\n                    sitio2 = result.copyTo(new long[1]);\n                    System.out.print(imgName+\" -> \"+sitio2[0]+\"\\n\");\n                }\n\n            }\n        }\n        load.close();\n    }\n}\n\nMy example is pretty simple, I think. Maybe is a problem with versions or something I'm missing?", "body": "Hi asimshankar, \r\n\r\nThis is my python side:\r\n```\r\n#!/usr/bin/env python\r\n\r\ntry:\r\n    import cPickle as pickle\r\n    from urllib2 import urlopen\r\nexcept ImportError:\r\n    import pickle\r\n    from urllib.request import urlopen\r\n\r\nimport logging\r\n\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.losses.python.losses import loss_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.saved_model import builder as saved_model_builder\r\n\r\nFILE_SEED = 42\r\nIMG_SIZE = 128\r\n\r\npathToSaveModel = './tmpTestNewX/model'\r\n\r\n\r\ndef loadFeatures(files):\r\n    data = np.ndarray((len(files), IMG_SIZE * IMG_SIZE * 3))\r\n    for n, f in enumerate(files):\r\n        logging.debug('loading file #%d' % n)\r\n        img = cv2.imread(f)\r\n        h, w, _ = img.shape\r\n        if w > h:\r\n            diff = w - h\r\n            img = img[:, diff / 2: diff / 2 + h]\r\n        elif w < h:\r\n            diff = h - w\r\n            img = img[diff / 2: diff / 2 + w, :]\r\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\r\n        data[n] = img.ravel()\r\n\r\n    return data\r\n\r\ndef conv2d(x, W):\r\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\ndef max_pool_2x2(x):\r\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\nxavier = tf.contrib.layers.xavier_initializer\r\n\r\nif __name__ == '__main__':\r\n    with tf.Session(graph=tf.Graph()) as session:\r\n        x = tf.placeholder(tf.float32, shape=[None, IMG_SIZE * IMG_SIZE * 3], name=\"input_jm\")\r\n        y_ = tf.placeholder(tf.float32, shape=[None, 2], name=\"y_\")\r\n\r\n        x_image = tf.reshape(x, [-1, IMG_SIZE, IMG_SIZE, 3])  # 128\r\n\r\n        W_conv1 = tf.get_variable(\"W_conv1\", shape=[3, 3, 3, 6], initializer=xavier())\r\n        b_conv1 = tf.get_variable('b_conv1', [1, 1, 1, 6])\r\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n        h_pool1 = max_pool_2x2(h_conv1)  # 64\r\n\r\n        W_conv2 = tf.get_variable(\"W_conv2\", shape=[3, 3, 6, 6], initializer=xavier())\r\n        b_conv2 = tf.get_variable('b_conv2', [1, 1, 1, 6])\r\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n        h_pool2 = max_pool_2x2(h_conv2)  # 32\r\n\r\n        W_conv3 = tf.get_variable(\"W_conv3\", shape=[3, 3, 6, 12], initializer=xavier())\r\n        b_conv3 = tf.get_variable('b_conv3', [1, 1, 1, 12])\r\n        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\r\n        h_pool3 = max_pool_2x2(h_conv3)  # 16\r\n\r\n        W_conv4 = tf.get_variable(\"W_conv4\", shape=[3, 3, 12, 24], initializer=xavier())\r\n        b_conv4 = tf.get_variable('b_conv4', [1, 1, 1, 24])\r\n        h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\r\n        h_pool4 = max_pool_2x2(h_conv4)  # 8\r\n\r\n        h_pool4_flat = tf.reshape(h_pool4, [-1, 8 * 8 * 24])\r\n\r\n        W_fc1 = tf.get_variable(\"W_fc1\", shape=[8 * 8 * 24, 1024], initializer=xavier())\r\n        b_fc1 = tf.get_variable('b_fc1', [1024], initializer=init_ops.zeros_initializer)\r\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\r\n\r\n        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\r\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n\r\n        W_fcO = tf.get_variable(\"W_fcO\", shape=[1024, 2], initializer=xavier())\r\n        b_fcO = tf.get_variable('b_fcO', [2], initializer=init_ops.zeros_initializer)\r\n\r\n        logits = tf.matmul(h_fc1_drop, W_fcO) + b_fcO\r\n        y_conv = tf.nn.softmax(logits)\r\n\r\n        cross_entropy = loss_ops.softmax_cross_entropy(logits, y_)\r\n\r\n        train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)\r\n\r\n        predictions = predictions = tf.argmax(y_conv, 1, name=\"predictions\")\r\n\r\n        #Load\r\n        saver = tf.train.Saver()\r\n        saver.restore(session, \"./newModel.ckpt\")\r\n\r\n        collection_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\n\r\n        r1 = session.run(W_conv1)\r\n        path = \"./\"\r\n        classS = [\"girl1.jpg\"]\r\n        classS_1 = [\"car1.jpg\", \"cat1.jpg\", \"girlOk1.jpg\"]\r\n        classNS_running = [\"manRunning.jpg\", \"manRunning1.jpg\", \"girlRunning.jpg\"]\r\n        classS_other = [\"baby-shower-cap.jpg\", \"Bottle.jpg\"]\r\n        images = classS + classS_1 + classNS_running + classS_other\r\n        images2 = [path + i for i in images]\r\n        for image in images2:\r\n            features = loadFeatures([image])\r\n            res = predictions.eval(\r\n                 feed_dict={\r\n                     x: features,\r\n                     keep_prob: 1.0, }\r\n            )\r\n            print('Image {} has a prob {} '.format(image, res))\r\n\r\n\r\n        legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n        b = saved_model_builder.SavedModelBuilder(pathToSaveModel)\r\n        b.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.TRAINING]) #, legacy_init_op=legacy_init_op)\r\n        b.save()\r\n```\r\n\r\n\r\nAnd this is my Java side:\r\n\r\n```\r\nimport org.tensorflow.*;\r\n\r\nimport java.io.IOException;\r\nimport java.nio.charset.Charset;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\nimport java.util.List;\r\n\r\npublic class LoadModelSample {\r\n\r\n    // In the fullness of time, equivalents of the methods of this class should be auto-generated from\r\n    // the OpDefs linked into libtensorflow_jni.so. That would match what is done in other languages\r\n    // like Python, C++ and Go.\r\n    static class GraphBuilder {\r\n        GraphBuilder(Graph g) {\r\n            this.g = g;\r\n        }\r\n\r\n        Output div(Output x, Output y) {\r\n            return binaryOp(\"Div\", x, y);\r\n        }\r\n\r\n        Output sub(Output x, Output y) {\r\n            return binaryOp(\"Sub\", x, y);\r\n        }\r\n\r\n        Output resizeBilinear(Output images, Output size) {\r\n            return binaryOp(\"ResizeArea\", images, size);\r\n        }\r\n\r\n        Output expandDims(Output input, Output dim) {\r\n            return binaryOp(\"ExpandDims\", input, dim);\r\n        }\r\n\r\n        Output cast(Output value, DataType dtype) {\r\n            return g.opBuilder(\"Cast\", \"Cast\").addInput(value).setAttr(\"DstT\", dtype).build().output(0);\r\n        }\r\n\r\n        Output decodeJpeg(Output contents, long channels) {\r\n            return g.opBuilder(\"DecodeJpeg\", \"DecodeJpeg\")\r\n                    .addInput(contents)\r\n                    .setAttr(\"channels\", channels)\r\n                    .build()\r\n                    .output(0);\r\n        }\r\n\r\n        Output constant(String name, Object value) {\r\n            try (Tensor t = Tensor.create(value)) {\r\n                return g.opBuilder(\"Const\", name)\r\n                        .setAttr(\"dtype\", t.dataType())\r\n                        .setAttr(\"value\", t)\r\n                        .build()\r\n                        .output(0);\r\n            }\r\n        }\r\n\r\n        private Output binaryOp(String type, Output in1, Output in2) {\r\n            return g.opBuilder(type, type).addInput(in1).addInput(in2).build().output(0);\r\n        }\r\n\r\n        private Graph g;\r\n    }\r\n\r\n    private static byte[] readAllBytesOrExit(Path path) {\r\n        try {\r\n            return Files.readAllBytes(path);\r\n        } catch (IOException e) {\r\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\r\n            System.exit(1);\r\n        }\r\n        return null;\r\n    }\r\n\r\n    private static Tensor constructAndExecuteGraphToNormalizeImage(int img_size, byte[] imageBytes) {\r\n        try (Graph g = new Graph()) {\r\n            GraphBuilder b = new GraphBuilder(g);\r\n            // Some constants specific to the pre-trained model at:\r\n            // https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\r\n            //\r\n            // - The model was trained with images scaled to img_sizeXimg_size pixels.\r\n            // - The colors, represented as R, G, B in 1-byte each were converted to\r\n            //   float using (value - Mean)/Scale.\r\n            final int H = img_size; //224;\r\n            final int W = img_size; //224;\r\n            final float mean = 117f;\r\n            final float scale = 1f;\r\n\r\n            // Since the graph is being constructed once per execution here, we can use a constant for the\r\n            // input image. If the graph were to be re-used for multiple input images, a placeholder would\r\n            // have been more appropriate.\r\n            final Output input = b.constant(\"input\", imageBytes);\r\n            final Output output =\r\n                    b.div(\r\n                            //b.sub(\r\n                            b.resizeBilinear(\r\n                                    b.expandDims(\r\n                                            b.cast(b.decodeJpeg(input, 3), DataType.FLOAT),\r\n                                            b.constant(\"make_batch\", 0)\r\n                                    ),\r\n                                    b.constant(\"size\", new int[] {H, W})),\r\n                            //       b.constant(\"mean\", mean)),\r\n                            b.constant(\"scale\", scale));\r\n            try (Session s = new Session(g)) {\r\n                Tensor result = s.runner().fetch(output.op().name()).run().get(0);\r\n                return result;\r\n            }\r\n        }\r\n    }\r\n\r\n    private static List<String> readAllLinesOrExit(Path path) {\r\n        try {\r\n            return Files.readAllLines(path, Charset.forName(\"UTF-8\"));\r\n        } catch (IOException e) {\r\n            System.err.println(\"Failed to read [\" + path + \"]: \" + e.getMessage());\r\n            System.exit(0);\r\n        }\r\n        return null;\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n\r\n        final int IMG_SIZE = 128;\r\n        final String value = \"Hello from \" + TensorFlow.version();\r\n        System.out.print(value+\"\\\\n\");\r\n\r\n        SavedModelBundle load = SavedModelBundle.load(\"./tmpTestNewX/model\", \"train\");\r\n\r\n        long[] sitio2;\r\n        try (Graph g = load.graph()) {\r\n            try (Session s = load.session();)\r\n            {\r\n                String[] images = new String[] { \"./cat1.jpg\", \"./girl1.jpg\", \"./bottle.jpg\" };\r\n                for (String imgName : images) {\r\n                    byte[] imageBytes = readAllBytesOrExit(Paths.get(imgName));\r\n                    Tensor image = constructAndExecuteGraphToNormalizeImage(IMG_SIZE, imageBytes); //constructImage(IMG_SIZE, imageBytes);\r\n                    Tensor result = s.runner()\r\n                            .feed(\"keep_prob\", Tensor.create(1.0F))\r\n                            .feed(\"input_jm\", image)\r\n                            .fetch(\"predictions\").run().get(0);\r\n                    sitio2 = result.copyTo(new long[1]);\r\n                    System.out.print(imgName+\" -> \"+sitio2[0]+\"\\n\");\r\n                }\r\n\r\n            }\r\n        }\r\n        load.close();\r\n    }\r\n}\r\n```\r\n\r\nMy example is pretty simple, I think. Maybe is a problem with versions or something I'm missing?"}