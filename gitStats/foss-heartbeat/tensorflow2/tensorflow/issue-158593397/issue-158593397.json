{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2680", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2680/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2680/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2680/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2680", "id": 158593397, "node_id": "MDU6SXNzdWUxNTg1OTMzOTc=", "number": 2680, "title": "Loading model in Android and No OpKernel was registered to support Op error", "user": {"login": "TianweiXing", "id": 17885178, "node_id": "MDQ6VXNlcjE3ODg1MTc4", "avatar_url": "https://avatars1.githubusercontent.com/u/17885178?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TianweiXing", "html_url": "https://github.com/TianweiXing", "followers_url": "https://api.github.com/users/TianweiXing/followers", "following_url": "https://api.github.com/users/TianweiXing/following{/other_user}", "gists_url": "https://api.github.com/users/TianweiXing/gists{/gist_id}", "starred_url": "https://api.github.com/users/TianweiXing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TianweiXing/subscriptions", "organizations_url": "https://api.github.com/users/TianweiXing/orgs", "repos_url": "https://api.github.com/users/TianweiXing/repos", "events_url": "https://api.github.com/users/TianweiXing/events{/privacy}", "received_events_url": "https://api.github.com/users/TianweiXing/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 28, "created_at": "2016-06-06T03:08:52Z", "updated_at": "2017-10-18T05:48:50Z", "closed_at": "2016-06-24T18:12:23Z", "author_association": "NONE", "body_html": "<p>I encountered a problem when using a self-trained face-recognition model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:</p>\n<pre><code>06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:196 End computing.\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:199 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs\n                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/divisor = Inv[T=DT_FLOAT](incept5b/in4_conv1x1_55/batch_norm/moments/moments/Const)]]\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 28605 (tensorflowmnist)\n06-05 16:25:11.423 186-186/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** \n</code></pre>\n<p>It is similar to the issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"135957980\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1269\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1269/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1269\">#1269</a></p>\n<p>I don't understand why it causes an error?<br>\nAll the other layers ( from incept3a  to incept5a) have almost the same structures, but there's no error....</p>\n<p>Could anyone give me some advice?<br>\nThanks a lot!</p>\n<p>The structure of the model I use is like this:</p>\n<pre><code>\ndef inference_nn4_max_pool_96(images, pool_type, use_lrn, keep_probability, phase_train=True):\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  if use_lrn:\n    lrn1 = tf.nn.local_response_normalization(pool1, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn1 = pool1\n  conv2 = _conv(lrn1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  if use_lrn:\n    lrn2 = tf.nn.local_response_normalization(conv3, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn2 = conv3\n  pool3 = _mpool(lrn2,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'MAX', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, pool_type, 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'MAX', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, pool_type, 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, pool_type, 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, pool_type, 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, pool_type, 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'MAX', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, pool_type, 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'MAX', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if keep_probability&lt;1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n</code></pre>", "body_text": "I encountered a problem when using a self-trained face-recognition model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:196 End computing.\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:199 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs\n                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/divisor = Inv[T=DT_FLOAT](incept5b/in4_conv1x1_55/batch_norm/moments/moments/Const)]]\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 28605 (tensorflowmnist)\n06-05 16:25:11.423 186-186/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** \n\nIt is similar to the issue #1269\nI don't understand why it causes an error?\nAll the other layers ( from incept3a  to incept5a) have almost the same structures, but there's no error....\nCould anyone give me some advice?\nThanks a lot!\nThe structure of the model I use is like this:\n\ndef inference_nn4_max_pool_96(images, pool_type, use_lrn, keep_probability, phase_train=True):\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  if use_lrn:\n    lrn1 = tf.nn.local_response_normalization(pool1, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn1 = pool1\n  conv2 = _conv(lrn1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  if use_lrn:\n    lrn2 = tf.nn.local_response_normalization(conv3, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn2 = conv3\n  pool3 = _mpool(lrn2,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'MAX', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, pool_type, 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'MAX', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, pool_type, 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, pool_type, 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, pool_type, 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, pool_type, 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'MAX', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, pool_type, 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'MAX', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if keep_probability<1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm", "body": "I encountered a problem when using a self-trained face-recognition model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:\n\n```\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:196 End computing.\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:199 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs\n                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/divisor = Inv[T=DT_FLOAT](incept5b/in4_conv1x1_55/batch_norm/moments/moments/Const)]]\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 28605 (tensorflowmnist)\n06-05 16:25:11.423 186-186/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** \n```\n\nIt is similar to the issue #1269 \n\nI don't understand why it causes an error? \nAll the other layers ( from incept3a  to incept5a) have almost the same structures, but there's no error....\n\nCould anyone give me some advice?\nThanks a lot!\n\nThe structure of the model I use is like this:\n\n```\n\ndef inference_nn4_max_pool_96(images, pool_type, use_lrn, keep_probability, phase_train=True):\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  if use_lrn:\n    lrn1 = tf.nn.local_response_normalization(pool1, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn1 = pool1\n  conv2 = _conv(lrn1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  if use_lrn:\n    lrn2 = tf.nn.local_response_normalization(conv3, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn2 = conv3\n  pool3 = _mpool(lrn2,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'MAX', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, pool_type, 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'MAX', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, pool_type, 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, pool_type, 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, pool_type, 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, pool_type, 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'MAX', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, pool_type, 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'MAX', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if keep_probability<1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n```\n"}