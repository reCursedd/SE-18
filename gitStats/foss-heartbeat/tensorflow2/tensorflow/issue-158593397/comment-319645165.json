{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/319645165", "html_url": "https://github.com/tensorflow/tensorflow/issues/2680#issuecomment-319645165", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2680", "id": 319645165, "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTY0NTE2NQ==", "user": {"login": "Lucky94", "id": 8686388, "node_id": "MDQ6VXNlcjg2ODYzODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/8686388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lucky94", "html_url": "https://github.com/Lucky94", "followers_url": "https://api.github.com/users/Lucky94/followers", "following_url": "https://api.github.com/users/Lucky94/following{/other_user}", "gists_url": "https://api.github.com/users/Lucky94/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lucky94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lucky94/subscriptions", "organizations_url": "https://api.github.com/users/Lucky94/orgs", "repos_url": "https://api.github.com/users/Lucky94/repos", "events_url": "https://api.github.com/users/Lucky94/events{/privacy}", "received_events_url": "https://api.github.com/users/Lucky94/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-02T11:26:51Z", "updated_at": "2017-08-02T11:26:51Z", "author_association": "NONE", "body_html": "<p>Hey, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19175336\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Mr-Grieves\">@Mr-Grieves</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15935629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nesadiankemo\">@nesadiankemo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11816941\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/leftstone2015\">@leftstone2015</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3376817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewharp\">@andrewharp</a><br>\nThat error is gone . I did change only the TF_CALL_bool macros at lines L#98 and L#125 only and not at any other places. Also i didn't change the TF_CALL_string macro. So it worked for me but now I'm getting error at the later stage when i am running the benchmark for \"frozen_inference_graph.pb\" as provided for object detection model.</p>\n<blockquote>\n<p>adb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/frozen_inference_graph.pb --input_layer=image_tensor:0 --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"detection_scores/detection_scores:0\"<br>\nnative : benchmark_model.cc:404 Graph: [/data/local/tmp/frozen_inference_graph.pb]<br>\nnative : benchmark_model.cc:405 Input layers: [image_tensor:0]<br>\nnative : benchmark_model.cc:406 Input shapes: [1,224,224,3]<br>\nnative : benchmark_model.cc:407 Input types: [float]<br>\nnative : benchmark_model.cc:408 Output layers: [detection_scores/detection_scores:0]<br>\nnative : benchmark_model.cc:409 Num runs: [50]<br>\nnative : benchmark_model.cc:410 Inter-run delay (seconds): [-1.0]<br>\nnative : benchmark_model.cc:411 Num threads: [-1]<br>\nnative : benchmark_model.cc:412 Benchmark name: []<br>\nnative : benchmark_model.cc:413 Output prefix: []<br>\nnative : benchmark_model.cc:414 Show sizes: [0]<br>\nnative : benchmark_model.cc:415 Warmup runs: [2]<br>\nnative : benchmark_model.cc:54 Loading TensorFlow.<br>\nnative : benchmark_model.cc:61 Got config, 0 devices<br>\ncan't determine number of CPU cores: assuming 4<br>\ncan't determine number of CPU cores: assuming 4<br>\nnative : benchmark_model.cc:74 Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:<br>\ndevice='GPU'; T in [DT_STRING]<br>\ndevice='GPU'; T in [DT_BOOL]<br>\ndevice='GPU'; T in [DT_INT32]<br>\ndevice='GPU'; T in [DT_FLOAT]<br>\ndevice='CPU'; T in [DT_FLOAT]<br>\ndevice='CPU'; T in [DT_INT32]</p>\n<p>[[Node: Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/cond_2/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2, Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2)]]</p>\n</blockquote>\n<p>One workout mentioned here <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"214164574\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8404\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8404/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8404\">#8404</a> is that \" to freeze the graph without phase_train\"<br>\nIs there any other fix without re-freezing the graph?<br>\n*Note: And also my error mentioned above (after [[Node: ...........]]) is bit different from the one mentioned at <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"214164574\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8404\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8404/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8404\">#8404</a></p>", "body_text": "Hey, @Mr-Grieves @nesadiankemo @leftstone2015 @andrewharp\nThat error is gone . I did change only the TF_CALL_bool macros at lines L#98 and L#125 only and not at any other places. Also i didn't change the TF_CALL_string macro. So it worked for me but now I'm getting error at the later stage when i am running the benchmark for \"frozen_inference_graph.pb\" as provided for object detection model.\n\nadb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/frozen_inference_graph.pb --input_layer=image_tensor:0 --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"detection_scores/detection_scores:0\"\nnative : benchmark_model.cc:404 Graph: [/data/local/tmp/frozen_inference_graph.pb]\nnative : benchmark_model.cc:405 Input layers: [image_tensor:0]\nnative : benchmark_model.cc:406 Input shapes: [1,224,224,3]\nnative : benchmark_model.cc:407 Input types: [float]\nnative : benchmark_model.cc:408 Output layers: [detection_scores/detection_scores:0]\nnative : benchmark_model.cc:409 Num runs: [50]\nnative : benchmark_model.cc:410 Inter-run delay (seconds): [-1.0]\nnative : benchmark_model.cc:411 Num threads: [-1]\nnative : benchmark_model.cc:412 Benchmark name: []\nnative : benchmark_model.cc:413 Output prefix: []\nnative : benchmark_model.cc:414 Show sizes: [0]\nnative : benchmark_model.cc:415 Warmup runs: [2]\nnative : benchmark_model.cc:54 Loading TensorFlow.\nnative : benchmark_model.cc:61 Got config, 0 devices\ncan't determine number of CPU cores: assuming 4\ncan't determine number of CPU cores: assuming 4\nnative : benchmark_model.cc:74 Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\ndevice='GPU'; T in [DT_STRING]\ndevice='GPU'; T in [DT_BOOL]\ndevice='GPU'; T in [DT_INT32]\ndevice='GPU'; T in [DT_FLOAT]\ndevice='CPU'; T in [DT_FLOAT]\ndevice='CPU'; T in [DT_INT32]\n[[Node: Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/cond_2/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2, Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2)]]\n\nOne workout mentioned here #8404 is that \" to freeze the graph without phase_train\"\nIs there any other fix without re-freezing the graph?\n*Note: And also my error mentioned above (after [[Node: ...........]]) is bit different from the one mentioned at #8404", "body": "Hey, @Mr-Grieves @nesadiankemo @leftstone2015 @andrewharp \r\nThat error is gone . I did change only the TF_CALL_bool macros at lines L#98 and L#125 only and not at any other places. Also i didn't change the TF_CALL_string macro. So it worked for me but now I'm getting error at the later stage when i am running the benchmark for \"frozen_inference_graph.pb\" as provided for object detection model. \r\n\r\n>  adb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/frozen_inference_graph.pb --input_layer=image_tensor:0 --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"detection_scores/detection_scores:0\"\r\n> native : benchmark_model.cc:404 Graph: [/data/local/tmp/frozen_inference_graph.pb]\r\n> native : benchmark_model.cc:405 Input layers: [image_tensor:0]\r\n> native : benchmark_model.cc:406 Input shapes: [1,224,224,3]\r\n> native : benchmark_model.cc:407 Input types: [float]\r\n> native : benchmark_model.cc:408 Output layers: [detection_scores/detection_scores:0]\r\n> native : benchmark_model.cc:409 Num runs: [50]\r\n> native : benchmark_model.cc:410 Inter-run delay (seconds): [-1.0]\r\n> native : benchmark_model.cc:411 Num threads: [-1]\r\n> native : benchmark_model.cc:412 Benchmark name: []\r\n> native : benchmark_model.cc:413 Output prefix: []\r\n> native : benchmark_model.cc:414 Show sizes: [0]\r\n> native : benchmark_model.cc:415 Warmup runs: [2]\r\n> native : benchmark_model.cc:54 Loading TensorFlow.\r\n> native : benchmark_model.cc:61 Got config, 0 devices\r\n> can't determine number of CPU cores: assuming 4\r\n> can't determine number of CPU cores: assuming 4\r\n> native : benchmark_model.cc:74 Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n>   device='GPU'; T in [DT_STRING]\r\n>   device='GPU'; T in [DT_BOOL]\r\n>   device='GPU'; T in [DT_INT32]\r\n>   device='GPU'; T in [DT_FLOAT]\r\n>   device='CPU'; T in [DT_FLOAT]\r\n>   device='CPU'; T in [DT_INT32]\r\n> \r\n> \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/cond_2/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2, Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2)]]\r\n\r\nOne workout mentioned here #8404 is that \" to freeze the graph without phase_train\"\r\nIs there any other fix without re-freezing the graph? \r\n*Note: And also my error mentioned above (after [[Node: ...........]]) is bit different from the one mentioned at #8404 "}