{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242881692", "html_url": "https://github.com/tensorflow/tensorflow/issues/4047#issuecomment-242881692", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4047", "id": 242881692, "node_id": "MDEyOklzc3VlQ29tbWVudDI0Mjg4MTY5Mg==", "user": {"login": "perhapszzy", "id": 7953637, "node_id": "MDQ6VXNlcjc5NTM2Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7953637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/perhapszzy", "html_url": "https://github.com/perhapszzy", "followers_url": "https://api.github.com/users/perhapszzy/followers", "following_url": "https://api.github.com/users/perhapszzy/following{/other_user}", "gists_url": "https://api.github.com/users/perhapszzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/perhapszzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/perhapszzy/subscriptions", "organizations_url": "https://api.github.com/users/perhapszzy/orgs", "repos_url": "https://api.github.com/users/perhapszzy/repos", "events_url": "https://api.github.com/users/perhapszzy/events{/privacy}", "received_events_url": "https://api.github.com/users/perhapszzy/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-27T00:11:59Z", "updated_at": "2016-08-27T00:11:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Still have trouble installing the gperftools ... But I found if I don't run cifar10_eval with the training, the slow down became less severe. It only slows down from time to time</p>\n<pre><code>2016-08-27 00:06:55.565748: step 16220 (global_step 16220), loss = 0.92 (409.7 examples/sec; 0.312 sec/batch)\n2016-08-27 00:06:59.056398: step 16230 (global_step 16230), loss = 0.86 (336.3 examples/sec; 0.381 sec/batch)\n2016-08-27 00:07:03.097942: step 16240 (global_step 16240), loss = 0.82 (366.3 examples/sec; 0.349 sec/batch)\n2016-08-27 00:07:08.687517: step 16250 (global_step 16250), loss = 0.97 (52.4 examples/sec; 2.443 sec/batch)\n2016-08-27 00:07:12.856141: step 16260 (global_step 16260), loss = 1.05 (354.0 examples/sec; 0.362 sec/batch)\n2016-08-27 00:07:17.285705: step 16270 (global_step 16270), loss = 0.79 (101.0 examples/sec; 1.268 sec/batch)\n2016-08-27 00:07:22.531608: step 16280 (global_step 16280), loss = 0.83 (156.5 examples/sec; 0.818 sec/batch)\n2016-08-27 00:07:26.008164: step 16290 (global_step 16290), loss = 0.79 (380.7 examples/sec; 0.336 sec/batch)\n2016-08-27 00:07:31.529857: step 16300 (global_step 16300), loss = 0.92 (379.1 examples/sec; 0.338 sec/batch)\n2016-08-27 00:07:35.004310: step 16310 (global_step 16310), loss = 1.10 (358.1 examples/sec; 0.357 sec/batch)\n2016-08-27 00:07:39.766474: step 16320 (global_step 16320), loss = 0.85 (368.9 examples/sec; 0.347 sec/batch)\n2016-08-27 00:07:44.046154: step 16330 (global_step 16330), loss = 0.90 (413.7 examples/sec; 0.309 sec/batch)\n2016-08-27 00:07:49.655521: step 16340 (global_step 16340), loss = 0.71 (170.9 examples/sec; 0.749 sec/batch)\n2016-08-27 00:07:54.041737: step 16350 (global_step 16350), loss = 0.85 (171.1 examples/sec; 0.748 sec/batch)\n2016-08-27 00:07:57.530356: step 16360 (global_step 16360), loss = 0.88 (382.9 examples/sec; 0.334 sec/batch)\n</code></pre>", "body_text": "Still have trouble installing the gperftools ... But I found if I don't run cifar10_eval with the training, the slow down became less severe. It only slows down from time to time\n2016-08-27 00:06:55.565748: step 16220 (global_step 16220), loss = 0.92 (409.7 examples/sec; 0.312 sec/batch)\n2016-08-27 00:06:59.056398: step 16230 (global_step 16230), loss = 0.86 (336.3 examples/sec; 0.381 sec/batch)\n2016-08-27 00:07:03.097942: step 16240 (global_step 16240), loss = 0.82 (366.3 examples/sec; 0.349 sec/batch)\n2016-08-27 00:07:08.687517: step 16250 (global_step 16250), loss = 0.97 (52.4 examples/sec; 2.443 sec/batch)\n2016-08-27 00:07:12.856141: step 16260 (global_step 16260), loss = 1.05 (354.0 examples/sec; 0.362 sec/batch)\n2016-08-27 00:07:17.285705: step 16270 (global_step 16270), loss = 0.79 (101.0 examples/sec; 1.268 sec/batch)\n2016-08-27 00:07:22.531608: step 16280 (global_step 16280), loss = 0.83 (156.5 examples/sec; 0.818 sec/batch)\n2016-08-27 00:07:26.008164: step 16290 (global_step 16290), loss = 0.79 (380.7 examples/sec; 0.336 sec/batch)\n2016-08-27 00:07:31.529857: step 16300 (global_step 16300), loss = 0.92 (379.1 examples/sec; 0.338 sec/batch)\n2016-08-27 00:07:35.004310: step 16310 (global_step 16310), loss = 1.10 (358.1 examples/sec; 0.357 sec/batch)\n2016-08-27 00:07:39.766474: step 16320 (global_step 16320), loss = 0.85 (368.9 examples/sec; 0.347 sec/batch)\n2016-08-27 00:07:44.046154: step 16330 (global_step 16330), loss = 0.90 (413.7 examples/sec; 0.309 sec/batch)\n2016-08-27 00:07:49.655521: step 16340 (global_step 16340), loss = 0.71 (170.9 examples/sec; 0.749 sec/batch)\n2016-08-27 00:07:54.041737: step 16350 (global_step 16350), loss = 0.85 (171.1 examples/sec; 0.748 sec/batch)\n2016-08-27 00:07:57.530356: step 16360 (global_step 16360), loss = 0.88 (382.9 examples/sec; 0.334 sec/batch)", "body": "Still have trouble installing the gperftools ... But I found if I don't run cifar10_eval with the training, the slow down became less severe. It only slows down from time to time\n\n```\n2016-08-27 00:06:55.565748: step 16220 (global_step 16220), loss = 0.92 (409.7 examples/sec; 0.312 sec/batch)\n2016-08-27 00:06:59.056398: step 16230 (global_step 16230), loss = 0.86 (336.3 examples/sec; 0.381 sec/batch)\n2016-08-27 00:07:03.097942: step 16240 (global_step 16240), loss = 0.82 (366.3 examples/sec; 0.349 sec/batch)\n2016-08-27 00:07:08.687517: step 16250 (global_step 16250), loss = 0.97 (52.4 examples/sec; 2.443 sec/batch)\n2016-08-27 00:07:12.856141: step 16260 (global_step 16260), loss = 1.05 (354.0 examples/sec; 0.362 sec/batch)\n2016-08-27 00:07:17.285705: step 16270 (global_step 16270), loss = 0.79 (101.0 examples/sec; 1.268 sec/batch)\n2016-08-27 00:07:22.531608: step 16280 (global_step 16280), loss = 0.83 (156.5 examples/sec; 0.818 sec/batch)\n2016-08-27 00:07:26.008164: step 16290 (global_step 16290), loss = 0.79 (380.7 examples/sec; 0.336 sec/batch)\n2016-08-27 00:07:31.529857: step 16300 (global_step 16300), loss = 0.92 (379.1 examples/sec; 0.338 sec/batch)\n2016-08-27 00:07:35.004310: step 16310 (global_step 16310), loss = 1.10 (358.1 examples/sec; 0.357 sec/batch)\n2016-08-27 00:07:39.766474: step 16320 (global_step 16320), loss = 0.85 (368.9 examples/sec; 0.347 sec/batch)\n2016-08-27 00:07:44.046154: step 16330 (global_step 16330), loss = 0.90 (413.7 examples/sec; 0.309 sec/batch)\n2016-08-27 00:07:49.655521: step 16340 (global_step 16340), loss = 0.71 (170.9 examples/sec; 0.749 sec/batch)\n2016-08-27 00:07:54.041737: step 16350 (global_step 16350), loss = 0.85 (171.1 examples/sec; 0.748 sec/batch)\n2016-08-27 00:07:57.530356: step 16360 (global_step 16360), loss = 0.88 (382.9 examples/sec; 0.334 sec/batch)\n```\n"}