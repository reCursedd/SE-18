{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242778668", "html_url": "https://github.com/tensorflow/tensorflow/issues/4047#issuecomment-242778668", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4047", "id": 242778668, "node_id": "MDEyOklzc3VlQ29tbWVudDI0Mjc3ODY2OA==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-26T16:09:33Z", "updated_at": "2016-08-26T16:13:40Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7953637\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/perhapszzy\">@perhapszzy</a>  I presume you're following the tutorial code from <a href=\"https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html\" rel=\"nofollow\">here</a>?</p>\n<p>It looks like you have mistyped several of the command lines, especially the <code>worker_hosts</code> and <code>ps_hosts</code> args:<br>\n<code>--worker_hosts='machine2:2222,machine2:2222'</code></p>\n<ul>\n<li>It's unclear what machine the PS is running on (is there a <code>machine0</code> or <code>machine3</code>?)</li>\n<li>You start 'worker' processes on <code>machine1</code> and <code>machine2</code></li>\n<li>You tell the workers that the PS is on <code>machine1</code> so they connect to the first worker instead!</li>\n<li>You tell each worker about the process on <code>machine2</code> twice, but don't mention <code>machine1</code></li>\n</ul>\n<p>I'm not 100% sure what would happen in this case, i.e. using the same worker twice (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> Any ideas?) ...but it's unlikely you are going to scale well, since<br>\na) The parameter service is unused<br>\nb) You are either using just one worker, or trying to run two training steps simultaneously on the same worker.</p>\n<p>Please can you double check these command lines and let me know if it fixes the problem.<br>\nIt's very unlikely that there is a bug/issue here, though we could arguably add some argument sanity checking to spot this sort of configuration mistake.</p>", "body_text": "@perhapszzy  I presume you're following the tutorial code from here?\nIt looks like you have mistyped several of the command lines, especially the worker_hosts and ps_hosts args:\n--worker_hosts='machine2:2222,machine2:2222'\n\nIt's unclear what machine the PS is running on (is there a machine0 or machine3?)\nYou start 'worker' processes on machine1 and machine2\nYou tell the workers that the PS is on machine1 so they connect to the first worker instead!\nYou tell each worker about the process on machine2 twice, but don't mention machine1\n\nI'm not 100% sure what would happen in this case, i.e. using the same worker twice (@mrry Any ideas?) ...but it's unlikely you are going to scale well, since\na) The parameter service is unused\nb) You are either using just one worker, or trying to run two training steps simultaneously on the same worker.\nPlease can you double check these command lines and let me know if it fixes the problem.\nIt's very unlikely that there is a bug/issue here, though we could arguably add some argument sanity checking to spot this sort of configuration mistake.", "body": "@perhapszzy  I presume you're following the tutorial code from [here](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html)?\n\nIt looks like you have mistyped several of the command lines, especially the `worker_hosts` and `ps_hosts` args:\n`--worker_hosts='machine2:2222,machine2:2222'`\n- It's unclear what machine the PS is running on (is there a `machine0` or `machine3`?)\n- You start 'worker' processes on `machine1` and `machine2`\n- You tell the workers that the PS is on `machine1` so they connect to the first worker instead!\n- You tell each worker about the process on `machine2` twice, but don't mention `machine1`\n\nI'm not 100% sure what would happen in this case, i.e. using the same worker twice (@mrry Any ideas?) ...but it's unlikely you are going to scale well, since \na) The parameter service is unused\nb) You are either using just one worker, or trying to run two training steps simultaneously on the same worker.\n\nPlease can you double check these command lines and let me know if it fixes the problem.\nIt's very unlikely that there is a bug/issue here, though we could arguably add some argument sanity checking to spot this sort of configuration mistake.\n"}