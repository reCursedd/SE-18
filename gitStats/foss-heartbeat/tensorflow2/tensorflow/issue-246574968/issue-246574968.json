{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11882", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11882/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11882/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11882/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11882", "id": 246574968, "node_id": "MDU6SXNzdWUyNDY1NzQ5Njg=", "number": 11882, "title": "conv2d_transpose produce different results on GPU", "user": {"login": "jnjaby", "id": 16274959, "node_id": "MDQ6VXNlcjE2Mjc0OTU5", "avatar_url": "https://avatars3.githubusercontent.com/u/16274959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jnjaby", "html_url": "https://github.com/jnjaby", "followers_url": "https://api.github.com/users/jnjaby/followers", "following_url": "https://api.github.com/users/jnjaby/following{/other_user}", "gists_url": "https://api.github.com/users/jnjaby/gists{/gist_id}", "starred_url": "https://api.github.com/users/jnjaby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jnjaby/subscriptions", "organizations_url": "https://api.github.com/users/jnjaby/orgs", "repos_url": "https://api.github.com/users/jnjaby/repos", "events_url": "https://api.github.com/users/jnjaby/events{/privacy}", "received_events_url": "https://api.github.com/users/jnjaby/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-07-30T10:11:36Z", "updated_at": "2018-11-14T19:13:09Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p>== cat /etc/issue ===============================================<br>\nLinux ST 4.2.0-42-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115994238\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/49\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/49/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/49\">#49</a>~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"14.04.4 LTS, Trusty Tahr\"<br>\nVERSION_ID=\"14.04\"</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux ST 4.2.0-42-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115994238\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/49\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/49/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/49\">#49</a>~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nmsgpack-numpy (0.4.1)<br>\nnumpy (1.13.1)<br>\nprotobuf (3.2.0)<br>\ntensorflow (0.10.0)<br>\ntensorflow-gpu (1.0.0)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.0.0<br>\ntf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty<br>\ntf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty<br>\nSanity check: array([1], dtype=int32)<br>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /home/abc/torch/install/lib:/usr/lib/x86_64-linux-gnu:/home/abc/torch/install/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:/usr/local/cuda/lib64::/usr/local/computecpp/lib:/data/software/gurobi652/linux64/lib<br>\nDYLD_LIBRARY_PATH /home/abc/torch/install/lib:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:</p>\n<p>== nvidia-smi ===================================================<br>\nSun Jul 30 17:45:45 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |<br>\n|  0%   53C    P2    47W / 260W |   7909MiB /  8112MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|    0      1308    G   /usr/bin/X                                     357MiB |<br>\n|    0      2590    G   compiz                                         229MiB |<br>\n|    0      3254    G   ...el-token=CBAE43C38254E155E78826C3F38F0092    99MiB |<br>\n|    0      9480    C   python                                        1039MiB |<br>\n|    0     10432    C   /usr/bin/python                               5895MiB |<br>\n|    0     20408    C   /usr/bin/python                                283MiB |<br>\n|    0     28024    G   /usr/local/MATLAB/R2015a/bin/glnxa64/MATLAB      2MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so.8.0<br>\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44<br>\n/usr/local/MATLAB/R2015a/bin/glnxa64/libcudart.so.6.5.14</p>\n<h3>Describe the problem</h3>\n<p>I am trying to use <code>tf.nn.conv2d_transpose</code> but it produces different results every time on GPU. However, the result would be the same when switching the device to CPU. It seems like a bug. Please check the toy model below for more details.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nnp.random.seed(<span class=\"pl-c1\">1234</span>)\nconv_ <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">56</span>)\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    bottom <span class=\"pl-k\">=</span> tf.constant(conv_, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    weight <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weight<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">56</span>], <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0.001</span>))\n    bias <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bias<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>np.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32))\t\n\n    conv <span class=\"pl-k\">=</span> tf.nn.conv2d_transpose(bottom, weight, [<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">1</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n    conv <span class=\"pl-k\">=</span> tf.nn.bias_add(conv, bias)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.global_variables_initializer())\nnp.array_equal(sess.run(conv), sess.run(conv))</pre></div>\n<p><code>Out[2]: False</code></p>", "body_text": "System information\n== cat /etc/issue ===============================================\nLinux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"14.04.4 LTS, Trusty Tahr\"\nVERSION_ID=\"14.04\"\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nmsgpack-numpy (0.4.1)\nnumpy (1.13.1)\nprotobuf (3.2.0)\ntensorflow (0.10.0)\ntensorflow-gpu (1.0.0)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.0.0\ntf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty\ntf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty\nSanity check: array([1], dtype=int32)\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n== env ==========================================================\nLD_LIBRARY_PATH /home/abc/torch/install/lib:/usr/lib/x86_64-linux-gnu:/home/abc/torch/install/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:/usr/local/cuda/lib64::/usr/local/computecpp/lib:/data/software/gurobi652/linux64/lib\nDYLD_LIBRARY_PATH /home/abc/torch/install/lib:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:\n== nvidia-smi ===================================================\nSun Jul 30 17:45:45 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |\n|  0%   53C    P2    47W / 260W |   7909MiB /  8112MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1308    G   /usr/bin/X                                     357MiB |\n|    0      2590    G   compiz                                         229MiB |\n|    0      3254    G   ...el-token=CBAE43C38254E155E78826C3F38F0092    99MiB |\n|    0      9480    C   python                                        1039MiB |\n|    0     10432    C   /usr/bin/python                               5895MiB |\n|    0     20408    C   /usr/bin/python                                283MiB |\n|    0     28024    G   /usr/local/MATLAB/R2015a/bin/glnxa64/MATLAB      2MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so.8.0\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44\n/usr/local/MATLAB/R2015a/bin/glnxa64/libcudart.so.6.5.14\nDescribe the problem\nI am trying to use tf.nn.conv2d_transpose but it produces different results every time on GPU. However, the result would be the same when switching the device to CPU. It seems like a bug. Please check the toy model below for more details.\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(1234)\nconv_ = np.random.randn(10, 7, 7, 56)\n\nwith tf.device('/gpu:0'):\n    bottom = tf.constant(conv_, dtype=tf.float32)\n    weight = tf.get_variable(\"weight\", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))\n    bias = tf.get_variable(\"bias\", initializer=np.zeros(1, dtype=np.float32))\t\n\n    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')\n    conv = tf.nn.bias_add(conv, bias)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nnp.array_equal(sess.run(conv), sess.run(conv))\nOut[2]: False", "body": "### System information\r\n== cat /etc/issue ===============================================\r\nLinux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"14.04.4 LTS, Trusty Tahr\"\r\nVERSION_ID=\"14.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nmsgpack-numpy (0.4.1)\r\nnumpy (1.13.1)\r\nprotobuf (3.2.0)\r\ntensorflow (0.10.0)\r\ntensorflow-gpu (1.0.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.0.0\r\ntf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty\r\ntf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty\r\nSanity check: array([1], dtype=int32)\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /home/abc/torch/install/lib:/usr/lib/x86_64-linux-gnu:/home/abc/torch/install/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:/usr/local/cuda/lib64::/usr/local/computecpp/lib:/data/software/gurobi652/linux64/lib\r\nDYLD_LIBRARY_PATH /home/abc/torch/install/lib:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:\r\n\r\n== nvidia-smi ===================================================\r\nSun Jul 30 17:45:45 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |\r\n|  0%   53C    P2    47W / 260W |   7909MiB /  8112MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1308    G   /usr/bin/X                                     357MiB |\r\n|    0      2590    G   compiz                                         229MiB |\r\n|    0      3254    G   ...el-token=CBAE43C38254E155E78826C3F38F0092    99MiB |\r\n|    0      9480    C   python                                        1039MiB |\r\n|    0     10432    C   /usr/bin/python                               5895MiB |\r\n|    0     20408    C   /usr/bin/python                                283MiB |\r\n|    0     28024    G   /usr/local/MATLAB/R2015a/bin/glnxa64/MATLAB      2MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so.8.0\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44\r\n/usr/local/MATLAB/R2015a/bin/glnxa64/libcudart.so.6.5.14\r\n### Describe the problem\r\nI am trying to use `tf.nn.conv2d_transpose` but it produces different results every time on GPU. However, the result would be the same when switching the device to CPU. It seems like a bug. Please check the toy model below for more details.\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnp.random.seed(1234)\r\nconv_ = np.random.randn(10, 7, 7, 56)\r\n\r\nwith tf.device('/gpu:0'):\r\n    bottom = tf.constant(conv_, dtype=tf.float32)\r\n    weight = tf.get_variable(\"weight\", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))\r\n    bias = tf.get_variable(\"bias\", initializer=np.zeros(1, dtype=np.float32))\t\r\n\r\n    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')\r\n    conv = tf.nn.bias_add(conv, bias)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nnp.array_equal(sess.run(conv), sess.run(conv))\r\n```\r\n`Out[2]: False`"}