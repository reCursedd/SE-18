{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/319245560", "html_url": "https://github.com/tensorflow/tensorflow/issues/11882#issuecomment-319245560", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11882", "id": 319245560, "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTI0NTU2MA==", "user": {"login": "jnjaby", "id": 16274959, "node_id": "MDQ6VXNlcjE2Mjc0OTU5", "avatar_url": "https://avatars3.githubusercontent.com/u/16274959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jnjaby", "html_url": "https://github.com/jnjaby", "followers_url": "https://api.github.com/users/jnjaby/followers", "following_url": "https://api.github.com/users/jnjaby/following{/other_user}", "gists_url": "https://api.github.com/users/jnjaby/gists{/gist_id}", "starred_url": "https://api.github.com/users/jnjaby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jnjaby/subscriptions", "organizations_url": "https://api.github.com/users/jnjaby/orgs", "repos_url": "https://api.github.com/users/jnjaby/repos", "events_url": "https://api.github.com/users/jnjaby/events{/privacy}", "received_events_url": "https://api.github.com/users/jnjaby/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-01T01:55:33Z", "updated_at": "2017-08-02T02:00:51Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a> The last case is consistent. I make another test case output <code>True</code> and <code>False</code> respectively, showing different result between <code>tf.constant</code> and <code>tf.Variables</code>. Commonly, however, the weights should remain the same after initialization. So let's clarify the questions:</p>\n<ul>\n<li>Where is the non-determinism produced, Tensorflow or other libraries of GPU?</li>\n<li>What is the difference between <code>constant</code> Tensor and <code>variable</code> Tensor?</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nnp.random.seed(<span class=\"pl-c1\">1234</span>)\nconv_ <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">56</span>)\nweight <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>.,<span class=\"pl-c1\">1</span>., (<span class=\"pl-c1\">9</span>,<span class=\"pl-c1\">9</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">56</span>)).astype(np.float32)\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    bottom <span class=\"pl-k\">=</span> tf.constant(conv_, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    biases <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bias_gpu<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>np.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32))\n\n    weight_con <span class=\"pl-k\">=</span> tf.constant(weight, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    weight_var <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weight_gpu<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">56</span>], <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0.001</span>))\n\n    conv_con <span class=\"pl-k\">=</span> tf.nn.conv2d_transpose(bottom, weight_con, [<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">1</span>],[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>],<span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n    conv_var <span class=\"pl-k\">=</span> tf.nn.conv2d_transpose(bottom, weight_var, [<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">19</span>, <span class=\"pl-c1\">1</span>],[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>],<span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>)\n\n    conv_con <span class=\"pl-k\">=</span> tf.nn.bias_add(conv_con, biases)\n    conv_var <span class=\"pl-k\">=</span> tf.nn.bias_add(conv_var, biases)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.global_variables_initializer())\n\n<span class=\"pl-c1\">print</span> (np.array_equal(sess.run(conv_con), sess.run(conv_con)))\n<span class=\"pl-c1\">print</span> (np.array_equal(sess.run(conv_var), sess.run(conv_var)))</pre></div>", "body_text": "@aselle The last case is consistent. I make another test case output True and False respectively, showing different result between tf.constant and tf.Variables. Commonly, however, the weights should remain the same after initialization. So let's clarify the questions:\n\nWhere is the non-determinism produced, Tensorflow or other libraries of GPU?\nWhat is the difference between constant Tensor and variable Tensor?\n\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(1234)\nconv_ = np.random.randn(10, 7, 7, 56)\nweight = np.random.uniform(-1.,1., (9,9,1,56)).astype(np.float32)\n\nwith tf.device('/gpu:0'):\n    bottom = tf.constant(conv_, dtype=tf.float32)\n    biases = tf.get_variable(\"bias_gpu\", initializer=np.zeros(1, dtype=np.float32))\n\n    weight_con = tf.constant(weight, dtype=tf.float32)\n    weight_var = tf.get_variable(\"weight_gpu\", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))\n\n    conv_con = tf.nn.conv2d_transpose(bottom, weight_con, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')\n    conv_var = tf.nn.conv2d_transpose(bottom, weight_var, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')\n\n    conv_con = tf.nn.bias_add(conv_con, biases)\n    conv_var = tf.nn.bias_add(conv_var, biases)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint (np.array_equal(sess.run(conv_con), sess.run(conv_con)))\nprint (np.array_equal(sess.run(conv_var), sess.run(conv_var)))", "body": "@aselle The last case is consistent. I make another test case output `True` and `False` respectively, showing different result between `tf.constant` and `tf.Variables`. Commonly, however, the weights should remain the same after initialization. So let's clarify the questions:\r\n- Where is the non-determinism produced, Tensorflow or other libraries of GPU?\r\n- What is the difference between `constant` Tensor and `variable` Tensor?\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnp.random.seed(1234)\r\nconv_ = np.random.randn(10, 7, 7, 56)\r\nweight = np.random.uniform(-1.,1., (9,9,1,56)).astype(np.float32)\r\n\r\nwith tf.device('/gpu:0'):\r\n    bottom = tf.constant(conv_, dtype=tf.float32)\r\n    biases = tf.get_variable(\"bias_gpu\", initializer=np.zeros(1, dtype=np.float32))\r\n\r\n    weight_con = tf.constant(weight, dtype=tf.float32)\r\n    weight_var = tf.get_variable(\"weight_gpu\", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))\r\n\r\n    conv_con = tf.nn.conv2d_transpose(bottom, weight_con, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')\r\n    conv_var = tf.nn.conv2d_transpose(bottom, weight_var, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')\r\n\r\n    conv_con = tf.nn.bias_add(conv_con, biases)\r\n    conv_var = tf.nn.bias_add(conv_var, biases)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nprint (np.array_equal(sess.run(conv_con), sess.run(conv_con)))\r\nprint (np.array_equal(sess.run(conv_var), sess.run(conv_var)))\r\n```"}