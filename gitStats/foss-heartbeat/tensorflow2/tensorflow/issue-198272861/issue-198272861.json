{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6593", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6593/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6593/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6593/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6593", "id": 198272861, "node_id": "MDU6SXNzdWUxOTgyNzI4NjE=", "number": 6593, "title": "MonitoredSession Implementation [awaiting response]", "user": {"login": "chaitanya2692", "id": 8254695, "node_id": "MDQ6VXNlcjgyNTQ2OTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8254695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chaitanya2692", "html_url": "https://github.com/chaitanya2692", "followers_url": "https://api.github.com/users/chaitanya2692/followers", "following_url": "https://api.github.com/users/chaitanya2692/following{/other_user}", "gists_url": "https://api.github.com/users/chaitanya2692/gists{/gist_id}", "starred_url": "https://api.github.com/users/chaitanya2692/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chaitanya2692/subscriptions", "organizations_url": "https://api.github.com/users/chaitanya2692/orgs", "repos_url": "https://api.github.com/users/chaitanya2692/repos", "events_url": "https://api.github.com/users/chaitanya2692/events{/privacy}", "received_events_url": "https://api.github.com/users/chaitanya2692/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-01-01T16:26:07Z", "updated_at": "2017-01-06T00:55:28Z", "closed_at": "2017-01-06T00:55:28Z", "author_association": "NONE", "body_html": "<p>I am trying to solve simple arithmetic operations on 4 separate devices which I was successful in doing. Now, I want to implement fault tolerance in my program in the event that one of the node fails. I am using the tf.train.MonitoredTrainingSession class to achieve the desired results. I am not confident about the implementation in my program as I am not getting a favorable output. Below is the program as far as I could get:-</p>\n<p>Please help</p>\n<pre><code>import tensorflow as tf\n\nglobal_step_tensor = tf.Variable(10, trainable=False, name='global_step')\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\nx = tf.constant(2)\n\nwith tf.device(\"/job:local/task:0\"):\n    y1 = x + 300\n\nwith tf.device(\"/job:local/task:1\"):\n    y2 = x**2\n\nwith tf.device(\"/job:local/task:2\"):\n    y3 = 5*x\n\nwith tf.device(\"/job:local/task:3\"):\n    y0 = x - 66\n    y = y0 + y1 + y2 + y3\n\nChiefSessionCreator = tf.train.ChiefSessionCreator(scaffold=None, master='localhost:2222', config='grpc://localhost:2222', checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints')\nsaver_hook = tf.train.CheckpointSaverHook(checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', save_secs=10, save_steps=None, saver=y, checkpoint_basename='model.ckpt', scaffold=None)\nsummary_hook = tf.train.SummarySaverHook(save_steps=None, save_secs=10, output_dir='/home/chaitanya/tensorflow/codes/savepoints', summary_writer=None, scaffold=None, summary_op=y)\n\nwith tf.train.MonitoredTrainingSession(master='localhost:2222', is_chief=True, checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', \n    scaffold=None, hooks=[saver_hook, summary_hook], chief_only_hooks=None, save_checkpoint_secs=10, save_summaries_steps=None, config='grpc://localhost:2222') as sess:\n\n    while not sess.should_stop():\n        sess.run(model)\n\n    while not sess.should_stop():\n        print(sess.run(y0))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y1))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y2))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y3))\n        print('\\n')\n\n    while not sess.should_stop():\n        result = sess.run(y)\n        print(result)\n</code></pre>\n<p>I have also posted this on stackoverflow:-</p>\n<p><a href=\"https://stackoverflow.com/questions/41478027/tf-train-monitoredtrainingsession-arguments\" rel=\"nofollow\">https://stackoverflow.com/questions/41478027/tf-train-monitoredtrainingsession-arguments</a></p>", "body_text": "I am trying to solve simple arithmetic operations on 4 separate devices which I was successful in doing. Now, I want to implement fault tolerance in my program in the event that one of the node fails. I am using the tf.train.MonitoredTrainingSession class to achieve the desired results. I am not confident about the implementation in my program as I am not getting a favorable output. Below is the program as far as I could get:-\nPlease help\nimport tensorflow as tf\n\nglobal_step_tensor = tf.Variable(10, trainable=False, name='global_step')\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\nx = tf.constant(2)\n\nwith tf.device(\"/job:local/task:0\"):\n    y1 = x + 300\n\nwith tf.device(\"/job:local/task:1\"):\n    y2 = x**2\n\nwith tf.device(\"/job:local/task:2\"):\n    y3 = 5*x\n\nwith tf.device(\"/job:local/task:3\"):\n    y0 = x - 66\n    y = y0 + y1 + y2 + y3\n\nChiefSessionCreator = tf.train.ChiefSessionCreator(scaffold=None, master='localhost:2222', config='grpc://localhost:2222', checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints')\nsaver_hook = tf.train.CheckpointSaverHook(checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', save_secs=10, save_steps=None, saver=y, checkpoint_basename='model.ckpt', scaffold=None)\nsummary_hook = tf.train.SummarySaverHook(save_steps=None, save_secs=10, output_dir='/home/chaitanya/tensorflow/codes/savepoints', summary_writer=None, scaffold=None, summary_op=y)\n\nwith tf.train.MonitoredTrainingSession(master='localhost:2222', is_chief=True, checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', \n    scaffold=None, hooks=[saver_hook, summary_hook], chief_only_hooks=None, save_checkpoint_secs=10, save_summaries_steps=None, config='grpc://localhost:2222') as sess:\n\n    while not sess.should_stop():\n        sess.run(model)\n\n    while not sess.should_stop():\n        print(sess.run(y0))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y1))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y2))\n        print('\\n')\n\n    while not sess.should_stop():\n        print(sess.run(y3))\n        print('\\n')\n\n    while not sess.should_stop():\n        result = sess.run(y)\n        print(result)\n\nI have also posted this on stackoverflow:-\nhttps://stackoverflow.com/questions/41478027/tf-train-monitoredtrainingsession-arguments", "body": "I am trying to solve simple arithmetic operations on 4 separate devices which I was successful in doing. Now, I want to implement fault tolerance in my program in the event that one of the node fails. I am using the tf.train.MonitoredTrainingSession class to achieve the desired results. I am not confident about the implementation in my program as I am not getting a favorable output. Below is the program as far as I could get:-\r\n\r\nPlease help\r\n```\r\nimport tensorflow as tf\r\n\r\nglobal_step_tensor = tf.Variable(10, trainable=False, name='global_step')\r\n\r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\",\"localhost:2224\", \"localhost:2225\"]})\r\nx = tf.constant(2)\r\n\r\nwith tf.device(\"/job:local/task:0\"):\r\n    y1 = x + 300\r\n\r\nwith tf.device(\"/job:local/task:1\"):\r\n    y2 = x**2\r\n\r\nwith tf.device(\"/job:local/task:2\"):\r\n    y3 = 5*x\r\n\r\nwith tf.device(\"/job:local/task:3\"):\r\n    y0 = x - 66\r\n    y = y0 + y1 + y2 + y3\r\n\r\nChiefSessionCreator = tf.train.ChiefSessionCreator(scaffold=None, master='localhost:2222', config='grpc://localhost:2222', checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints')\r\nsaver_hook = tf.train.CheckpointSaverHook(checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', save_secs=10, save_steps=None, saver=y, checkpoint_basename='model.ckpt', scaffold=None)\r\nsummary_hook = tf.train.SummarySaverHook(save_steps=None, save_secs=10, output_dir='/home/chaitanya/tensorflow/codes/savepoints', summary_writer=None, scaffold=None, summary_op=y)\r\n\r\nwith tf.train.MonitoredTrainingSession(master='localhost:2222', is_chief=True, checkpoint_dir='/home/chaitanya/tensorflow/codes/checkpoints', \r\n    scaffold=None, hooks=[saver_hook, summary_hook], chief_only_hooks=None, save_checkpoint_secs=10, save_summaries_steps=None, config='grpc://localhost:2222') as sess:\r\n\r\n    while not sess.should_stop():\r\n        sess.run(model)\r\n\r\n    while not sess.should_stop():\r\n        print(sess.run(y0))\r\n        print('\\n')\r\n\r\n    while not sess.should_stop():\r\n        print(sess.run(y1))\r\n        print('\\n')\r\n\r\n    while not sess.should_stop():\r\n        print(sess.run(y2))\r\n        print('\\n')\r\n\r\n    while not sess.should_stop():\r\n        print(sess.run(y3))\r\n        print('\\n')\r\n\r\n    while not sess.should_stop():\r\n        result = sess.run(y)\r\n        print(result)\r\n```\r\nI have also posted this on stackoverflow:-\r\n\r\nhttps://stackoverflow.com/questions/41478027/tf-train-monitoredtrainingsession-arguments"}