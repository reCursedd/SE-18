{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265135672", "html_url": "https://github.com/tensorflow/tensorflow/issues/6116#issuecomment-265135672", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6116", "id": 265135672, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTEzNTY3Mg==", "user": {"login": "llhe", "id": 192829, "node_id": "MDQ6VXNlcjE5MjgyOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/192829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/llhe", "html_url": "https://github.com/llhe", "followers_url": "https://api.github.com/users/llhe/followers", "following_url": "https://api.github.com/users/llhe/following{/other_user}", "gists_url": "https://api.github.com/users/llhe/gists{/gist_id}", "starred_url": "https://api.github.com/users/llhe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/llhe/subscriptions", "organizations_url": "https://api.github.com/users/llhe/orgs", "repos_url": "https://api.github.com/users/llhe/repos", "events_url": "https://api.github.com/users/llhe/events{/privacy}", "received_events_url": "https://api.github.com/users/llhe/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-06T12:14:13Z", "updated_at": "2016-12-10T01:36:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>To make things more clear, I collected more detailed data for <a href=\"https://github.com/grpc/grpc/blob/d7ff4ff40071d2b486a052183e3e9f9382afb745/src/core/lib/support/slice_buffer.c#L278\">memmove</a>:</p>\n<div class=\"highlight highlight-source-c\"><pre>  <span class=\"pl-c\"><span class=\"pl-c\">//</span> int move_size = (sb-&gt;count - 1) * sizeof(gpr_slice);</span>\n  <span class=\"pl-en\">memmove</span>(&amp;sb-&gt;slices[<span class=\"pl-c1\">0</span>], &amp;sb-&gt;slices[<span class=\"pl-c1\">1</span>], (sb-&gt;count - <span class=\"pl-c1\">1</span>) * sizeof(gpr_slice));\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> int data_size = GPR_SLICE_LENGTH(slice);</span></pre></div>\n<p>A typical <code>move_size</code>, <code>slice_size</code> sequence,</p>\n<ul>\n<li>move_size: 6096, slice_size: 608</li>\n<li>move_size: 6072, slice_size: 8192</li>\n<li>move_size: 6048, slice_size: 7583</li>\n<li>move_size: 6024, slice_size: 600</li>\n<li>move_size: 6000, slice_size: 8192</li>\n<li>move_size: 5976, slice_size: 7591</li>\n<li>move_size: 5952, slice_size: 592</li>\n<li>move_size: 5928, slice_size: 8192</li>\n<li>move_size: 5904, slice_size: 7599</li>\n<li>move_size: 5880, slice_size: 584</li>\n<li>move_size: 5856, slice_size: 8192</li>\n<li>move_size: 5832, slice_size: 7607</li>\n<li>move_size: 5808, slice_size: 576</li>\n<li>move_size: 5784, slice_size: 8192</li>\n<li>move_size: 5760, slice_size: 7615</li>\n<li>move_size: 5736, slice_size: 568</li>\n<li>move_size: 5712, slice_size: 8192</li>\n<li>move_size: 5688, slice_size: 7623</li>\n<li>move_size: 5664, slice_size: 560</li>\n<li>move_size: 5640, slice_size: 8192</li>\n<li>move_size: 5616, slice_size: 7631</li>\n<li>move_size: 5592, slice_size: 552</li>\n<li>move_size: 5568, slice_size: 8192</li>\n<li>move_size: 5544, slice_size: 7639</li>\n<li>move_size: 5520, slice_size: 544</li>\n<li>move_size: 5496, slice_size: 8192</li>\n<li>move_size: 5472, slice_size: 7647</li>\n<li>move_size: 5448, slice_size: 536</li>\n<li>move_size: 5424, slice_size: 8192</li>\n<li>move_size: 5400, slice_size: 7655</li>\n<li>move_size: 5376, slice_size: 528</li>\n<li>move_size: 5352, slice_size: 8192</li>\n<li>move_size: 5328, slice_size: 7663</li>\n<li>move_size: 5304, slice_size: 520</li>\n</ul>\n<p>So the problem is obvious (the slice_size will sum to 100MB per run). The root cause should be the grpc buffer management does not work well for large message. This also explains why the throughput will decrease with the increase of the tensor size.</p>\n<p>Not quite familiar with the grpc code, adding an grpc option to change 'gpr_slice_buffer_take_first' to 'gpr_slice_buffer_take_all' can remove the unnecessary memory copy? Tuning the slice size can also help reducing the overhead but can't eliminate it.</p>", "body_text": "To make things more clear, I collected more detailed data for memmove:\n  // int move_size = (sb->count - 1) * sizeof(gpr_slice);\n  memmove(&sb->slices[0], &sb->slices[1], (sb->count - 1) * sizeof(gpr_slice));\n  // int data_size = GPR_SLICE_LENGTH(slice);\nA typical move_size, slice_size sequence,\n\nmove_size: 6096, slice_size: 608\nmove_size: 6072, slice_size: 8192\nmove_size: 6048, slice_size: 7583\nmove_size: 6024, slice_size: 600\nmove_size: 6000, slice_size: 8192\nmove_size: 5976, slice_size: 7591\nmove_size: 5952, slice_size: 592\nmove_size: 5928, slice_size: 8192\nmove_size: 5904, slice_size: 7599\nmove_size: 5880, slice_size: 584\nmove_size: 5856, slice_size: 8192\nmove_size: 5832, slice_size: 7607\nmove_size: 5808, slice_size: 576\nmove_size: 5784, slice_size: 8192\nmove_size: 5760, slice_size: 7615\nmove_size: 5736, slice_size: 568\nmove_size: 5712, slice_size: 8192\nmove_size: 5688, slice_size: 7623\nmove_size: 5664, slice_size: 560\nmove_size: 5640, slice_size: 8192\nmove_size: 5616, slice_size: 7631\nmove_size: 5592, slice_size: 552\nmove_size: 5568, slice_size: 8192\nmove_size: 5544, slice_size: 7639\nmove_size: 5520, slice_size: 544\nmove_size: 5496, slice_size: 8192\nmove_size: 5472, slice_size: 7647\nmove_size: 5448, slice_size: 536\nmove_size: 5424, slice_size: 8192\nmove_size: 5400, slice_size: 7655\nmove_size: 5376, slice_size: 528\nmove_size: 5352, slice_size: 8192\nmove_size: 5328, slice_size: 7663\nmove_size: 5304, slice_size: 520\n\nSo the problem is obvious (the slice_size will sum to 100MB per run). The root cause should be the grpc buffer management does not work well for large message. This also explains why the throughput will decrease with the increase of the tensor size.\nNot quite familiar with the grpc code, adding an grpc option to change 'gpr_slice_buffer_take_first' to 'gpr_slice_buffer_take_all' can remove the unnecessary memory copy? Tuning the slice size can also help reducing the overhead but can't eliminate it.", "body": "To make things more clear, I collected more detailed data for [memmove](https://github.com/grpc/grpc/blob/d7ff4ff40071d2b486a052183e3e9f9382afb745/src/core/lib/support/slice_buffer.c#L278):\r\n```c\r\n  // int move_size = (sb->count - 1) * sizeof(gpr_slice);\r\n  memmove(&sb->slices[0], &sb->slices[1], (sb->count - 1) * sizeof(gpr_slice));\r\n  // int data_size = GPR_SLICE_LENGTH(slice);\r\n```\r\nA typical `move_size`, `slice_size` sequence,\r\n* move_size: 6096, slice_size: 608\r\n* move_size: 6072, slice_size: 8192\r\n* move_size: 6048, slice_size: 7583\r\n* move_size: 6024, slice_size: 600\r\n* move_size: 6000, slice_size: 8192\r\n* move_size: 5976, slice_size: 7591\r\n* move_size: 5952, slice_size: 592\r\n* move_size: 5928, slice_size: 8192\r\n* move_size: 5904, slice_size: 7599\r\n* move_size: 5880, slice_size: 584\r\n* move_size: 5856, slice_size: 8192\r\n* move_size: 5832, slice_size: 7607\r\n* move_size: 5808, slice_size: 576\r\n* move_size: 5784, slice_size: 8192\r\n* move_size: 5760, slice_size: 7615\r\n* move_size: 5736, slice_size: 568\r\n* move_size: 5712, slice_size: 8192\r\n* move_size: 5688, slice_size: 7623\r\n* move_size: 5664, slice_size: 560\r\n* move_size: 5640, slice_size: 8192\r\n* move_size: 5616, slice_size: 7631\r\n* move_size: 5592, slice_size: 552\r\n* move_size: 5568, slice_size: 8192\r\n* move_size: 5544, slice_size: 7639\r\n* move_size: 5520, slice_size: 544\r\n* move_size: 5496, slice_size: 8192\r\n* move_size: 5472, slice_size: 7647\r\n* move_size: 5448, slice_size: 536\r\n* move_size: 5424, slice_size: 8192\r\n* move_size: 5400, slice_size: 7655\r\n* move_size: 5376, slice_size: 528\r\n* move_size: 5352, slice_size: 8192\r\n* move_size: 5328, slice_size: 7663\r\n* move_size: 5304, slice_size: 520\r\n\r\nSo the problem is obvious (the slice_size will sum to 100MB per run). The root cause should be the grpc buffer management does not work well for large message. This also explains why the throughput will decrease with the increase of the tensor size.\r\n\r\nNot quite familiar with the grpc code, adding an grpc option to change 'gpr_slice_buffer_take_first' to 'gpr_slice_buffer_take_all' can remove the unnecessary memory copy? Tuning the slice size can also help reducing the overhead but can't eliminate it."}