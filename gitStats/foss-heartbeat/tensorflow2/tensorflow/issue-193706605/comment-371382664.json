{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/371382664", "html_url": "https://github.com/tensorflow/tensorflow/issues/6116#issuecomment-371382664", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6116", "id": 371382664, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTM4MjY2NA==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-08T05:23:00Z", "updated_at": "2018-03-08T05:23:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> Well I do agree more optimisations could be done with gRPC to eliminate memcpy even with current TCP/IP stack. The loopback performance in my DigitalOcean box is around 20 Gbps:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ sudo perf record netperf -t TCP_STREAM -H 127.0.0.1\nMIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to <span class=\"pl-en\">127.0.0.1</span> () port 0 AF_INET <span class=\"pl-c1\">:</span> demo\nRecv   Send    Send\nSocket Socket  Message  Elapsed\nSize   Size    Size     Time     Throughput\nbytes  bytes   bytes    secs.    10^6bits/sec\n\n 87380  16384  16384    10.00    18905.90\n[ perf record: Woken up 6 <span class=\"pl-c1\">times</span> to write data ]\n[ perf record: Captured and wrote 1.338 MB perf.data (30386 samples) ]</pre></div>\n<p>But I don't think it is really about memcpy, as the kernel also memcpy and it seems doing it pretty fast:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ sudo perf report --header\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ========</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> captured on: Thu Mar  8 05:09:45 2018</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> hostname : localhost</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> os release : 4.15.0-1-amd64</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> perf version : 4.15.4</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> arch : x86_64</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> nrcpus online : 4</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> nrcpus avail : 4</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> cpudesc : Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> cpuid : GenuineIntel,6,79,1</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> total memory : 8172116 kB</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> cmdline : /usr/bin/perf_4.15 record netperf -t TCP_STREAM -H 127.0.0.1</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> event : name = cycles, , size = 112, { sample_period, sample_freq } = 1500, sample_type = IP|TID|TIME|PERIOD, disabled = 1, inherit = 1, mmap = 1, comm = 1,</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> CPU_TOPOLOGY info available, use -I to display</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> NUMA_TOPOLOGY info available, use -I to display</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> pmu mappings: breakpoint = 5, cpu = 4, software = 1, tracepoint = 2, msr = 6</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> CACHE info available, use -I to display</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> missing features: TRACING_DATA BRANCH_STACK GROUP_DESC AUXTRACE STAT</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ========</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Total Lost Samples: 0</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Samples: 13K of event 'cycles'</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Event count (approx.): 19061735130</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Overhead  Command  Shared Object      Symbol</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ........  .......  .................  ..............................................</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n    34.79%  netperf  [kernel.kallsyms]  [k] copy_user_enhanced_fast_string\n     4.40%  netperf  [kernel.kallsyms]  [k] tcp_sendmsg_locked\n     3.08%  netperf  [kernel.kallsyms]  [k] __tcp_ack_snd_check\n     2.55%  netperf  [kernel.kallsyms]  [k] __pv_queued_spin_lock_slowpath\n     2.29%  netperf  [kernel.kallsyms]  [k] syscall_return_via_sysret\n     1.77%  netperf  [kernel.kallsyms]  [k] pvclock_clocksource_read\n     1.49%  netperf  [unknown]          [k] 0xfffffe000003201e\n     1.38%  netperf  [kernel.kallsyms]  [k] __raw_callee_save___pv_queued_spin_unlock\n     1.23%  netperf  [kernel.kallsyms]  [k] get_page_from_freelist</pre></div>", "body_text": "@yaroslavvb Well I do agree more optimisations could be done with gRPC to eliminate memcpy even with current TCP/IP stack. The loopback performance in my DigitalOcean box is around 20 Gbps:\n$ sudo perf record netperf -t TCP_STREAM -H 127.0.0.1\nMIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 127.0.0.1 () port 0 AF_INET : demo\nRecv   Send    Send\nSocket Socket  Message  Elapsed\nSize   Size    Size     Time     Throughput\nbytes  bytes   bytes    secs.    10^6bits/sec\n\n 87380  16384  16384    10.00    18905.90\n[ perf record: Woken up 6 times to write data ]\n[ perf record: Captured and wrote 1.338 MB perf.data (30386 samples) ]\nBut I don't think it is really about memcpy, as the kernel also memcpy and it seems doing it pretty fast:\n$ sudo perf report --header\n# ========\n# captured on: Thu Mar  8 05:09:45 2018\n# hostname : localhost\n# os release : 4.15.0-1-amd64\n# perf version : 4.15.4\n# arch : x86_64\n# nrcpus online : 4\n# nrcpus avail : 4\n# cpudesc : Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n# cpuid : GenuineIntel,6,79,1\n# total memory : 8172116 kB\n# cmdline : /usr/bin/perf_4.15 record netperf -t TCP_STREAM -H 127.0.0.1\n# event : name = cycles, , size = 112, { sample_period, sample_freq } = 1500, sample_type = IP|TID|TIME|PERIOD, disabled = 1, inherit = 1, mmap = 1, comm = 1,\n# CPU_TOPOLOGY info available, use -I to display\n# NUMA_TOPOLOGY info available, use -I to display\n# pmu mappings: breakpoint = 5, cpu = 4, software = 1, tracepoint = 2, msr = 6\n# CACHE info available, use -I to display\n# missing features: TRACING_DATA BRANCH_STACK GROUP_DESC AUXTRACE STAT\n# ========\n#\n#\n# Total Lost Samples: 0\n#\n# Samples: 13K of event 'cycles'\n# Event count (approx.): 19061735130\n#\n# Overhead  Command  Shared Object      Symbol\n# ........  .......  .................  ..............................................\n#\n    34.79%  netperf  [kernel.kallsyms]  [k] copy_user_enhanced_fast_string\n     4.40%  netperf  [kernel.kallsyms]  [k] tcp_sendmsg_locked\n     3.08%  netperf  [kernel.kallsyms]  [k] __tcp_ack_snd_check\n     2.55%  netperf  [kernel.kallsyms]  [k] __pv_queued_spin_lock_slowpath\n     2.29%  netperf  [kernel.kallsyms]  [k] syscall_return_via_sysret\n     1.77%  netperf  [kernel.kallsyms]  [k] pvclock_clocksource_read\n     1.49%  netperf  [unknown]          [k] 0xfffffe000003201e\n     1.38%  netperf  [kernel.kallsyms]  [k] __raw_callee_save___pv_queued_spin_unlock\n     1.23%  netperf  [kernel.kallsyms]  [k] get_page_from_freelist", "body": "@yaroslavvb Well I do agree more optimisations could be done with gRPC to eliminate memcpy even with current TCP/IP stack. The loopback performance in my DigitalOcean box is around 20 Gbps:\r\n\r\n```shell\r\n$ sudo perf record netperf -t TCP_STREAM -H 127.0.0.1\r\nMIGRATED TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 127.0.0.1 () port 0 AF_INET : demo\r\nRecv   Send    Send\r\nSocket Socket  Message  Elapsed\r\nSize   Size    Size     Time     Throughput\r\nbytes  bytes   bytes    secs.    10^6bits/sec\r\n\r\n 87380  16384  16384    10.00    18905.90\r\n[ perf record: Woken up 6 times to write data ]\r\n[ perf record: Captured and wrote 1.338 MB perf.data (30386 samples) ]\r\n```\r\n\r\nBut I don't think it is really about memcpy, as the kernel also memcpy and it seems doing it pretty fast:\r\n```shell\r\n$ sudo perf report --header\r\n# ========\r\n# captured on: Thu Mar  8 05:09:45 2018\r\n# hostname : localhost\r\n# os release : 4.15.0-1-amd64\r\n# perf version : 4.15.4\r\n# arch : x86_64\r\n# nrcpus online : 4\r\n# nrcpus avail : 4\r\n# cpudesc : Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\r\n# cpuid : GenuineIntel,6,79,1\r\n# total memory : 8172116 kB\r\n# cmdline : /usr/bin/perf_4.15 record netperf -t TCP_STREAM -H 127.0.0.1\r\n# event : name = cycles, , size = 112, { sample_period, sample_freq } = 1500, sample_type = IP|TID|TIME|PERIOD, disabled = 1, inherit = 1, mmap = 1, comm = 1,\r\n# CPU_TOPOLOGY info available, use -I to display\r\n# NUMA_TOPOLOGY info available, use -I to display\r\n# pmu mappings: breakpoint = 5, cpu = 4, software = 1, tracepoint = 2, msr = 6\r\n# CACHE info available, use -I to display\r\n# missing features: TRACING_DATA BRANCH_STACK GROUP_DESC AUXTRACE STAT\r\n# ========\r\n#\r\n#\r\n# Total Lost Samples: 0\r\n#\r\n# Samples: 13K of event 'cycles'\r\n# Event count (approx.): 19061735130\r\n#\r\n# Overhead  Command  Shared Object      Symbol\r\n# ........  .......  .................  ..............................................\r\n#\r\n    34.79%  netperf  [kernel.kallsyms]  [k] copy_user_enhanced_fast_string\r\n     4.40%  netperf  [kernel.kallsyms]  [k] tcp_sendmsg_locked\r\n     3.08%  netperf  [kernel.kallsyms]  [k] __tcp_ack_snd_check\r\n     2.55%  netperf  [kernel.kallsyms]  [k] __pv_queued_spin_lock_slowpath\r\n     2.29%  netperf  [kernel.kallsyms]  [k] syscall_return_via_sysret\r\n     1.77%  netperf  [kernel.kallsyms]  [k] pvclock_clocksource_read\r\n     1.49%  netperf  [unknown]          [k] 0xfffffe000003201e\r\n     1.38%  netperf  [kernel.kallsyms]  [k] __raw_callee_save___pv_queued_spin_unlock\r\n     1.23%  netperf  [kernel.kallsyms]  [k] get_page_from_freelist\r\n```"}