{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2323", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2323/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2323/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2323/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2323", "id": 154251234, "node_id": "MDU6SXNzdWUxNTQyNTEyMzQ=", "number": 2323, "title": "the process wil be so slow when reading batch data from csv files in tensorflow", "user": {"login": "liumilan", "id": 5533901, "node_id": "MDQ6VXNlcjU1MzM5MDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5533901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liumilan", "html_url": "https://github.com/liumilan", "followers_url": "https://api.github.com/users/liumilan/followers", "following_url": "https://api.github.com/users/liumilan/following{/other_user}", "gists_url": "https://api.github.com/users/liumilan/gists{/gist_id}", "starred_url": "https://api.github.com/users/liumilan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liumilan/subscriptions", "organizations_url": "https://api.github.com/users/liumilan/orgs", "repos_url": "https://api.github.com/users/liumilan/repos", "events_url": "https://api.github.com/users/liumilan/events{/privacy}", "received_events_url": "https://api.github.com/users/liumilan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2016-05-11T14:01:17Z", "updated_at": "2016-05-13T03:19:17Z", "closed_at": "2016-05-12T21:40:08Z", "author_association": "NONE", "body_html": "<p>def read_data(filename):</p>\n<pre><code>    filename_queue = tf.train.string_input_producer([filename])\n    reader = tf.TextLineReader()\n    key, value = reader.read(filename_queue)\n    record_defaults = [[1.0 for col in range(1)] for row in range(280)]\n    record_defaults[279][0] = 1\n    a = tf.decode_csv(value, record_defaults=record_defaults)\n    data = tf.pack(a[0:278])\n    label = a[-1]\n    min_after_dequeue = 10000\n    capacity = min_after_dequeue + 3 * batch_size\n    data_batch, label_batch = tf.train.shuffle_batch([data, label], batch_size=batch_size, capacity=capacity,min_after_dequeue=min_after_dequeue)\n    return data_batch, label_batch\n</code></pre>\n<p>def main(argv=None):</p>\n<pre><code>    data,label = read_data(FLAGS.train_file)\n\n    tf.initialize_all_variables()\n    with tf.Session() as sess:\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n            example, label = sess.run([data, label])\n            print (example)\n</code></pre>\n<p>Here is my code above ,why it take 10 minutes to print example data?How can I optimise my code? I have only set batchsize is 2</p>", "body_text": "def read_data(filename):\n    filename_queue = tf.train.string_input_producer([filename])\n    reader = tf.TextLineReader()\n    key, value = reader.read(filename_queue)\n    record_defaults = [[1.0 for col in range(1)] for row in range(280)]\n    record_defaults[279][0] = 1\n    a = tf.decode_csv(value, record_defaults=record_defaults)\n    data = tf.pack(a[0:278])\n    label = a[-1]\n    min_after_dequeue = 10000\n    capacity = min_after_dequeue + 3 * batch_size\n    data_batch, label_batch = tf.train.shuffle_batch([data, label], batch_size=batch_size, capacity=capacity,min_after_dequeue=min_after_dequeue)\n    return data_batch, label_batch\n\ndef main(argv=None):\n    data,label = read_data(FLAGS.train_file)\n\n    tf.initialize_all_variables()\n    with tf.Session() as sess:\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n            example, label = sess.run([data, label])\n            print (example)\n\nHere is my code above ,why it take 10 minutes to print example data?How can I optimise my code? I have only set batchsize is 2", "body": "def read_data(filename):\n\n```\n    filename_queue = tf.train.string_input_producer([filename])\n    reader = tf.TextLineReader()\n    key, value = reader.read(filename_queue)\n    record_defaults = [[1.0 for col in range(1)] for row in range(280)]\n    record_defaults[279][0] = 1\n    a = tf.decode_csv(value, record_defaults=record_defaults)\n    data = tf.pack(a[0:278])\n    label = a[-1]\n    min_after_dequeue = 10000\n    capacity = min_after_dequeue + 3 * batch_size\n    data_batch, label_batch = tf.train.shuffle_batch([data, label], batch_size=batch_size, capacity=capacity,min_after_dequeue=min_after_dequeue)\n    return data_batch, label_batch\n```\n\ndef main(argv=None):  \n\n```\n    data,label = read_data(FLAGS.train_file)\n\n    tf.initialize_all_variables()\n    with tf.Session() as sess:\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n            example, label = sess.run([data, label])\n            print (example)\n```\n\nHere is my code above ,why it take 10 minutes to print example data?How can I optimise my code? I have only set batchsize is 2\n"}