{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/218773210", "html_url": "https://github.com/tensorflow/tensorflow/issues/2323#issuecomment-218773210", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2323", "id": 218773210, "node_id": "MDEyOklzc3VlQ29tbWVudDIxODc3MzIxMA==", "user": {"login": "beopst", "id": 10264378, "node_id": "MDQ6VXNlcjEwMjY0Mzc4", "avatar_url": "https://avatars2.githubusercontent.com/u/10264378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beopst", "html_url": "https://github.com/beopst", "followers_url": "https://api.github.com/users/beopst/followers", "following_url": "https://api.github.com/users/beopst/following{/other_user}", "gists_url": "https://api.github.com/users/beopst/gists{/gist_id}", "starred_url": "https://api.github.com/users/beopst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beopst/subscriptions", "organizations_url": "https://api.github.com/users/beopst/orgs", "repos_url": "https://api.github.com/users/beopst/repos", "events_url": "https://api.github.com/users/beopst/events{/privacy}", "received_events_url": "https://api.github.com/users/beopst/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-12T14:24:30Z", "updated_at": "2016-05-12T14:24:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes, it is because of batch_size. In this case, the queue should still block until it has a sufficient amount of elements for the first single batch.</p>\n<p>tf.train.shuffle_batch needs some time only for the first dequeue operation. Once it has elements more than min_after_queue, it consumes much little time since tf.train.shuffle_batch runs in a separate thread. You can see if you call <code>example, label = sess.run([data, label])</code> in a loop.</p>", "body_text": "Yes, it is because of batch_size. In this case, the queue should still block until it has a sufficient amount of elements for the first single batch.\ntf.train.shuffle_batch needs some time only for the first dequeue operation. Once it has elements more than min_after_queue, it consumes much little time since tf.train.shuffle_batch runs in a separate thread. You can see if you call example, label = sess.run([data, label]) in a loop.", "body": "Yes, it is because of batch_size. In this case, the queue should still block until it has a sufficient amount of elements for the first single batch. \n\ntf.train.shuffle_batch needs some time only for the first dequeue operation. Once it has elements more than min_after_queue, it consumes much little time since tf.train.shuffle_batch runs in a separate thread. You can see if you call `example, label = sess.run([data, label])` in a loop.\n"}