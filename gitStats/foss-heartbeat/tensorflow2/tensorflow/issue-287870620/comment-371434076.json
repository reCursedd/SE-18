{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/371434076", "html_url": "https://github.com/tensorflow/tensorflow/issues/16045#issuecomment-371434076", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16045", "id": 371434076, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTQzNDA3Ng==", "user": {"login": "rapatel0", "id": 18704704, "node_id": "MDQ6VXNlcjE4NzA0NzA0", "avatar_url": "https://avatars3.githubusercontent.com/u/18704704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rapatel0", "html_url": "https://github.com/rapatel0", "followers_url": "https://api.github.com/users/rapatel0/followers", "following_url": "https://api.github.com/users/rapatel0/following{/other_user}", "gists_url": "https://api.github.com/users/rapatel0/gists{/gist_id}", "starred_url": "https://api.github.com/users/rapatel0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rapatel0/subscriptions", "organizations_url": "https://api.github.com/users/rapatel0/orgs", "repos_url": "https://api.github.com/users/rapatel0/repos", "events_url": "https://api.github.com/users/rapatel0/events{/privacy}", "received_events_url": "https://api.github.com/users/rapatel0/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-08T09:40:12Z", "updated_at": "2018-03-08T09:40:24Z", "author_association": "NONE", "body_html": "<p>I added the cuda patches to my existing docker container and ran the test with the XLA streamexecutor running on CPU+GPU, GPU only, and a model without XLA as a baseline. We set the global seed in all cases and all image sizes and batch sizes are the same.</p>\n<ul>\n<li>After 70,000 iterations the noXLA model reaches a loss of 0.19  and is still trending downward.</li>\n<li>After 120,000 iterations both XLA models oscillate between losses of 0.3-0.4 and continue to oscillate until a limit of 200,000 iterations.</li>\n</ul>\n<p>I still need to try a test with patches applied before compiling tensorflow. Not sure if this will make a difference.</p>", "body_text": "I added the cuda patches to my existing docker container and ran the test with the XLA streamexecutor running on CPU+GPU, GPU only, and a model without XLA as a baseline. We set the global seed in all cases and all image sizes and batch sizes are the same.\n\nAfter 70,000 iterations the noXLA model reaches a loss of 0.19  and is still trending downward.\nAfter 120,000 iterations both XLA models oscillate between losses of 0.3-0.4 and continue to oscillate until a limit of 200,000 iterations.\n\nI still need to try a test with patches applied before compiling tensorflow. Not sure if this will make a difference.", "body": "I added the cuda patches to my existing docker container and ran the test with the XLA streamexecutor running on CPU+GPU, GPU only, and a model without XLA as a baseline. We set the global seed in all cases and all image sizes and batch sizes are the same.\r\n \r\n- After 70,000 iterations the noXLA model reaches a loss of 0.19  and is still trending downward.\r\n- After 120,000 iterations both XLA models oscillate between losses of 0.3-0.4 and continue to oscillate until a limit of 200,000 iterations. \r\n\r\nI still need to try a test with patches applied before compiling tensorflow. Not sure if this will make a difference. "}