{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357123894", "html_url": "https://github.com/tensorflow/tensorflow/issues/16045#issuecomment-357123894", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16045", "id": 357123894, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzEyMzg5NA==", "user": {"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-12T02:18:31Z", "updated_at": "2018-01-12T02:18:31Z", "author_association": "MEMBER", "body_html": "<p>(For future reference, it's a lot better to file two separate issues if you have two problems.  Otherwise when the bug becomes long, it's hard to track the problems.)</p>\n<p>I use CUDA_VISIBLE_DEVICES with XLA all the time and it works fine.  I'm pretty surprised to hear that it's not working for you, because it takes effect in an nvidia library that's much lower-level than TF or XLA.  That is, because neither TF nor XLA is responsible for respecting this env var, I suspect the environment variable is getting stripped out somewhere in your setup.  Without steps to reproduce, I can't say more.</p>\n<p>I'm not a TF person, so I can't speak to the TF config options not working, but again, I think a TF person would need additional information, probably concrete steps to reproduce, in order to assist.</p>\n<p>With respect to your model not converging, that's very concerning.  But again I'd need concrete steps to reproduce in order to debug this.</p>", "body_text": "(For future reference, it's a lot better to file two separate issues if you have two problems.  Otherwise when the bug becomes long, it's hard to track the problems.)\nI use CUDA_VISIBLE_DEVICES with XLA all the time and it works fine.  I'm pretty surprised to hear that it's not working for you, because it takes effect in an nvidia library that's much lower-level than TF or XLA.  That is, because neither TF nor XLA is responsible for respecting this env var, I suspect the environment variable is getting stripped out somewhere in your setup.  Without steps to reproduce, I can't say more.\nI'm not a TF person, so I can't speak to the TF config options not working, but again, I think a TF person would need additional information, probably concrete steps to reproduce, in order to assist.\nWith respect to your model not converging, that's very concerning.  But again I'd need concrete steps to reproduce in order to debug this.", "body": "(For future reference, it's a lot better to file two separate issues if you have two problems.  Otherwise when the bug becomes long, it's hard to track the problems.)\r\n\r\nI use CUDA_VISIBLE_DEVICES with XLA all the time and it works fine.  I'm pretty surprised to hear that it's not working for you, because it takes effect in an nvidia library that's much lower-level than TF or XLA.  That is, because neither TF nor XLA is responsible for respecting this env var, I suspect the environment variable is getting stripped out somewhere in your setup.  Without steps to reproduce, I can't say more.\r\n\r\nI'm not a TF person, so I can't speak to the TF config options not working, but again, I think a TF person would need additional information, probably concrete steps to reproduce, in order to assist.\r\n\r\nWith respect to your model not converging, that's very concerning.  But again I'd need concrete steps to reproduce in order to debug this."}