{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7551", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7551/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7551/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7551/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7551", "id": 208010826, "node_id": "MDU6SXNzdWUyMDgwMTA4MjY=", "number": 7551, "title": "Addition is much slower on non-last axis (non-fused batch norm with NCHW)", "user": {"login": "taion", "id": 3112159, "node_id": "MDQ6VXNlcjMxMTIxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3112159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taion", "html_url": "https://github.com/taion", "followers_url": "https://api.github.com/users/taion/followers", "following_url": "https://api.github.com/users/taion/following{/other_user}", "gists_url": "https://api.github.com/users/taion/gists{/gist_id}", "starred_url": "https://api.github.com/users/taion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taion/subscriptions", "organizations_url": "https://api.github.com/users/taion/orgs", "repos_url": "https://api.github.com/users/taion/repos", "events_url": "https://api.github.com/users/taion/events{/privacy}", "received_events_url": "https://api.github.com/users/taion/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}, {"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-02-16T04:13:10Z", "updated_at": "2017-06-17T03:06:57Z", "closed_at": "2017-06-17T03:06:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I noticed this from observing my models training many times slower when using non-fused batch norm and the NCHW data format. When looking at the timeline, it's dominated by addition (and multiplication) operations.</p>\n<p>I can mostly work around this by using the fused batch norm, but DenseNet models in principle (and in practice when using NHWC here) benefit from splitting up the learned beta/gamma and the normalization steps from batch normalization, and using a straightforward implementation (included below) makes my model run significantly slower when using NCHW.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I did a quick search on the issue tracker and SO, and couldn't find anything similar reported.</p>\n<h3>Environment info</h3>\n<p>gcr.io/tensorflow/tensorflow:1.0.0-devel-gpu on AWS p2.xlarge</p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Compare:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">%%</span>time\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default(), tf.Session() <span class=\"pl-k\">as</span> sess:\n    zeros <span class=\"pl-k\">=</span> tf.zeros((<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">256</span>))\n    beta <span class=\"pl-k\">=</span> tf.get_variable(\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>beta<span class=\"pl-pds\">'</span></span>,\n        (<span class=\"pl-c1\">256</span>,),\n        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.ones_initializer(),\n        <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    )\n\n    loss <span class=\"pl-k\">=</span> tf.reduce_mean((zeros <span class=\"pl-k\">+</span> beta) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>)\n    optimizer <span class=\"pl-k\">=</span> tf.train.MomentumOptimizer(<span class=\"pl-c1\">0.1</span>, <span class=\"pl-c1\">0.9</span>)\n    train_op <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n\n    sess.run(tf.global_variables_initializer())\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">500</span>):\n        sess.run(train_op)</pre></div>\n<pre><code>CPU times: user 7.8 s, sys: 868 ms, total: 8.67 s\nWall time: 9.69 s\n</code></pre>\n<p>v.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">%%</span>time\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default(), tf.Session() <span class=\"pl-k\">as</span> sess:\n    zeros <span class=\"pl-k\">=</span> tf.zeros((<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>))\n    beta <span class=\"pl-k\">=</span> tf.get_variable(\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>beta<span class=\"pl-pds\">'</span></span>,\n        (<span class=\"pl-c1\">256</span>,),\n        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.ones_initializer(),\n        <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    )\n    beta <span class=\"pl-k\">=</span> tf.reshape(beta, (<span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>))\n\n    loss <span class=\"pl-k\">=</span> tf.reduce_mean((zeros <span class=\"pl-k\">+</span> beta) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>)\n    optimizer <span class=\"pl-k\">=</span> tf.train.MomentumOptimizer(<span class=\"pl-c1\">0.1</span>, <span class=\"pl-c1\">0.9</span>)\n    train_op <span class=\"pl-k\">=</span> optimizer.minimize(loss)\n\n    sess.run(tf.global_variables_initializer())\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">500</span>):\n        sess.run(train_op)</pre></div>\n<pre><code>CPU times: user 14.6 s, sys: 2.81 s, total: 17.4 s\nWall time: 18.9 s\n</code></pre>\n<p>This is the scale/bias transform that triggers the problem for me in practice:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">affine_transformation</span>(\n    <span class=\"pl-smi\">inputs</span>,\n    <span class=\"pl-smi\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,\n    <span class=\"pl-smi\">beta_initializer</span><span class=\"pl-k\">=</span>tf.zeros_initializer(),\n    <span class=\"pl-smi\">gamma_initializer</span><span class=\"pl-k\">=</span>tf.ones_initializer(),\n    <span class=\"pl-smi\">beta_regularizer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-smi\">gamma_regularizer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n):\n    inputs_shape <span class=\"pl-k\">=</span> inputs.get_shape()\n    params_dim <span class=\"pl-k\">=</span> inputs_shape[axis]\n\n    beta <span class=\"pl-k\">=</span> tf.get_variable(\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>beta<span class=\"pl-pds\">'</span></span>,\n        (params_dim,),\n        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>beta_initializer,\n        <span class=\"pl-v\">regularizer</span><span class=\"pl-k\">=</span>beta_regularizer,\n        <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    )\n    gamma <span class=\"pl-k\">=</span> tf.get_variable(\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gamma<span class=\"pl-pds\">'</span></span>,\n        (params_dim,),\n        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>gamma_initializer,\n        <span class=\"pl-v\">regularizer</span><span class=\"pl-k\">=</span>gamma_regularizer,\n        <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    )\n\n    <span class=\"pl-k\">if</span> axis <span class=\"pl-k\">!=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>:\n        params_shape <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> <span class=\"pl-c1\">len</span>(inputs_shape)\n        params_shape[axis] <span class=\"pl-k\">=</span> params_dim.value\n\n        beta <span class=\"pl-k\">=</span> tf.reshape(beta, params_shape)\n        gamma <span class=\"pl-k\">=</span> tf.reshape(gamma, params_shape)\n\n    <span class=\"pl-k\">return</span> gamma <span class=\"pl-k\">*</span> inputs <span class=\"pl-k\">+</span> beta</pre></div>", "body_text": "I noticed this from observing my models training many times slower when using non-fused batch norm and the NCHW data format. When looking at the timeline, it's dominated by addition (and multiplication) operations.\nI can mostly work around this by using the fused batch norm, but DenseNet models in principle (and in practice when using NHWC here) benefit from splitting up the learned beta/gamma and the normalization steps from batch normalization, and using a straightforward implementation (included below) makes my model run significantly slower when using NCHW.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI did a quick search on the issue tracker and SO, and couldn't find anything similar reported.\nEnvironment info\ngcr.io/tensorflow/tensorflow:1.0.0-devel-gpu on AWS p2.xlarge\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nCompare:\n%%time\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    zeros = tf.zeros((64, 32, 32, 256))\n    beta = tf.get_variable(\n        'beta',\n        (256,),\n        initializer=tf.ones_initializer(),\n        trainable=True,\n    )\n\n    loss = tf.reduce_mean((zeros + beta) ** 2)\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\n    train_op = optimizer.minimize(loss)\n\n    sess.run(tf.global_variables_initializer())\n\n    for i in range(500):\n        sess.run(train_op)\nCPU times: user 7.8 s, sys: 868 ms, total: 8.67 s\nWall time: 9.69 s\n\nv.\n%%time\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    zeros = tf.zeros((64, 256, 32, 32))\n    beta = tf.get_variable(\n        'beta',\n        (256,),\n        initializer=tf.ones_initializer(),\n        trainable=True,\n    )\n    beta = tf.reshape(beta, (256, 1, 1))\n\n    loss = tf.reduce_mean((zeros + beta) ** 2)\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\n    train_op = optimizer.minimize(loss)\n\n    sess.run(tf.global_variables_initializer())\n\n    for i in range(500):\n        sess.run(train_op)\nCPU times: user 14.6 s, sys: 2.81 s, total: 17.4 s\nWall time: 18.9 s\n\nThis is the scale/bias transform that triggers the problem for me in practice:\ndef affine_transformation(\n    inputs,\n    axis=-1,\n    beta_initializer=tf.zeros_initializer(),\n    gamma_initializer=tf.ones_initializer(),\n    beta_regularizer=None,\n    gamma_regularizer=None,\n):\n    inputs_shape = inputs.get_shape()\n    params_dim = inputs_shape[axis]\n\n    beta = tf.get_variable(\n        'beta',\n        (params_dim,),\n        initializer=beta_initializer,\n        regularizer=beta_regularizer,\n        trainable=True,\n    )\n    gamma = tf.get_variable(\n        'gamma',\n        (params_dim,),\n        initializer=gamma_initializer,\n        regularizer=gamma_regularizer,\n        trainable=True,\n    )\n\n    if axis != -1:\n        params_shape = [1] * len(inputs_shape)\n        params_shape[axis] = params_dim.value\n\n        beta = tf.reshape(beta, params_shape)\n        gamma = tf.reshape(gamma, params_shape)\n\n    return gamma * inputs + beta", "body": "I noticed this from observing my models training many times slower when using non-fused batch norm and the NCHW data format. When looking at the timeline, it's dominated by addition (and multiplication) operations.\r\n\r\nI can mostly work around this by using the fused batch norm, but DenseNet models in principle (and in practice when using NHWC here) benefit from splitting up the learned beta/gamma and the normalization steps from batch normalization, and using a straightforward implementation (included below) makes my model run significantly slower when using NCHW.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI did a quick search on the issue tracker and SO, and couldn't find anything similar reported.\r\n\r\n### Environment info\r\n\r\ngcr.io/tensorflow/tensorflow:1.0.0-devel-gpu on AWS p2.xlarge\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nCompare:\r\n\r\n```python\r\n%%time\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    zeros = tf.zeros((64, 32, 32, 256))\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (256,),\r\n        initializer=tf.ones_initializer(),\r\n        trainable=True,\r\n    )\r\n\r\n    loss = tf.reduce_mean((zeros + beta) ** 2)\r\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\r\n    train_op = optimizer.minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(500):\r\n        sess.run(train_op)\r\n```\r\n\r\n```\r\nCPU times: user 7.8 s, sys: 868 ms, total: 8.67 s\r\nWall time: 9.69 s\r\n```\r\n\r\nv.\r\n\r\n```python\r\n%%time\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    zeros = tf.zeros((64, 256, 32, 32))\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (256,),\r\n        initializer=tf.ones_initializer(),\r\n        trainable=True,\r\n    )\r\n    beta = tf.reshape(beta, (256, 1, 1))\r\n\r\n    loss = tf.reduce_mean((zeros + beta) ** 2)\r\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\r\n    train_op = optimizer.minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(500):\r\n        sess.run(train_op)\r\n```\r\n\r\n```\r\nCPU times: user 14.6 s, sys: 2.81 s, total: 17.4 s\r\nWall time: 18.9 s\r\n```\r\n\r\nThis is the scale/bias transform that triggers the problem for me in practice:\r\n\r\n```python\r\ndef affine_transformation(\r\n    inputs,\r\n    axis=-1,\r\n    beta_initializer=tf.zeros_initializer(),\r\n    gamma_initializer=tf.ones_initializer(),\r\n    beta_regularizer=None,\r\n    gamma_regularizer=None,\r\n):\r\n    inputs_shape = inputs.get_shape()\r\n    params_dim = inputs_shape[axis]\r\n\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (params_dim,),\r\n        initializer=beta_initializer,\r\n        regularizer=beta_regularizer,\r\n        trainable=True,\r\n    )\r\n    gamma = tf.get_variable(\r\n        'gamma',\r\n        (params_dim,),\r\n        initializer=gamma_initializer,\r\n        regularizer=gamma_regularizer,\r\n        trainable=True,\r\n    )\r\n\r\n    if axis != -1:\r\n        params_shape = [1] * len(inputs_shape)\r\n        params_shape[axis] = params_dim.value\r\n\r\n        beta = tf.reshape(beta, params_shape)\r\n        gamma = tf.reshape(gamma, params_shape)\r\n\r\n    return gamma * inputs + beta\r\n```"}