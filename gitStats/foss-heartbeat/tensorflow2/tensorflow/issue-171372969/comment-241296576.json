{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241296576", "html_url": "https://github.com/tensorflow/tensorflow/issues/3843#issuecomment-241296576", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3843", "id": 241296576, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTI5NjU3Ng==", "user": {"login": "1051824353", "id": 11565200, "node_id": "MDQ6VXNlcjExNTY1MjAw", "avatar_url": "https://avatars0.githubusercontent.com/u/11565200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/1051824353", "html_url": "https://github.com/1051824353", "followers_url": "https://api.github.com/users/1051824353/followers", "following_url": "https://api.github.com/users/1051824353/following{/other_user}", "gists_url": "https://api.github.com/users/1051824353/gists{/gist_id}", "starred_url": "https://api.github.com/users/1051824353/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/1051824353/subscriptions", "organizations_url": "https://api.github.com/users/1051824353/orgs", "repos_url": "https://api.github.com/users/1051824353/repos", "events_url": "https://api.github.com/users/1051824353/events{/privacy}", "received_events_url": "https://api.github.com/users/1051824353/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-22T01:30:15Z", "updated_at": "2016-08-22T01:30:15Z", "author_association": "NONE", "body_html": "<p>c_api_test.cc src:<br>\n#include \"./c_api.h\"<br>\n#include&lt;stdio.h&gt;<br>\n#include&lt;string.h&gt;</p>\n<p>int main(int argc, char <em>argv[]){<br>\nprintf(\"---- -------start\");<br>\nTF_Status</em> s = TF_NewStatus();<br>\nTF_SessionOptions* opt = TF_NewSessionOptions();<br>\nTF_Session* session = TF_NewSession(opt, s);<br>\nTF_DeleteSessionOptions(opt);<br>\nTF_CloseSession(session,s);<br>\nTF_DeleteStatus(s);</p>\n<p>printf(\"---- -------end\");<br>\nreturn 1;<br>\n}</p>\n<p>c_api.h file is within tensorflow/c directory :<br>\n/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.</p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\");<br>\nyou may not use this file except in compliance with the License.<br>\nYou may obtain a copy of the License at</p>\n<pre><code>http://www.apache.org/licenses/LICENSE-2.0\n</code></pre>\n<p>Unless required by applicable law or agreed to in writing, software<br>\ndistributed under the License is distributed on an \"AS IS\" BASIS,<br>\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>\nSee the License for the specific language governing permissions and<br>\nlimitations under the License.<br>\n==============================================================================*/</p>\n<p>#ifndef TENSORFLOW_C_C_API_H_<br>\n#define TENSORFLOW_C_C_API_H_</p>\n<p>#include &lt;stddef.h&gt;<br>\n#include &lt;stdint.h&gt;</p>\n<p>// --------------------------------------------------------------------------<br>\n// C API for TensorFlow.<br>\n//<br>\n// The API leans towards simplicity and uniformity instead of convenience<br>\n// since most usage will be by language specific wrappers.<br>\n//<br>\n// Conventions:<br>\n// * We use the prefix TF_ for everything in the API.<br>\n// * Objects are always passed around as pointers to opaque structs<br>\n//   and these structs are allocated/deallocated via the API.<br>\n// * TF_Status holds error information.  It is an object type<br>\n//   and therefore is passed around as a pointer to an opaque<br>\n//   struct as mentioned above.<br>\n// * Every call that has a TF_Status* argument clears it on success<br>\n//   and fills it with error info on failure.<br>\n//<br>\n// Questions left to address:<br>\n// * Might at some point need a way for callers to provide their own Env.<br>\n// * Maybe add TF_TensorShape that encapsulates dimension info.<br>\n//<br>\n// Design decisions made:<br>\n// * Backing store for tensor memory has an associated deallocation<br>\n//   function.  This deallocation function will point to client code<br>\n//   for tensors populated by the client.  So the client can do things<br>\n//   like shadowing a numpy array.<br>\n// * We do not provide TF_OK since it is not strictly necessary and we<br>\n//   are not optimizing for convenience.<br>\n// * We make assumption that one session has one graph.  This should be<br>\n//   fine since we have the ability to run sub-graphs.<br>\n// * We could allow NULL for some arguments (e.g., NULL options arg).<br>\n//   However since convenience is not a primary goal, we don't do this.<br>\n// * Devices are not in this API.  Instead, they are created/used internally<br>\n//   and the API just provides high level controls over the number of<br>\n//   devices of each type.</p>\n<p>#ifdef __cplusplus<br>\nextern \"C\" {<br>\n#endif</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.<br>\n// The enum values here are identical to corresponding values in types.proto.<br>\ntypedef enum {<br>\nTF_FLOAT = 1,<br>\nTF_DOUBLE = 2,<br>\nTF_INT32 = 3,  // Int32 tensors are always in 'host' memory.<br>\nTF_UINT8 = 4,<br>\nTF_INT16 = 5,<br>\nTF_INT8 = 6,<br>\nTF_STRING = 7,<br>\nTF_COMPLEX64 = 8,  // Single-precision complex<br>\nTF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility<br>\nTF_INT64 = 9,<br>\nTF_BOOL = 10,<br>\nTF_QINT8 = 11,     // Quantized int8<br>\nTF_QUINT8 = 12,    // Quantized uint8<br>\nTF_QINT32 = 13,    // Quantized int32<br>\nTF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.<br>\nTF_QINT16 = 15,    // Quantized int16<br>\nTF_QUINT16 = 16,   // Quantized uint16<br>\nTF_UINT16 = 17,<br>\nTF_COMPLEX128 = 18,  // Double-precision complex<br>\nTF_HALF = 19,<br>\n} TF_DataType;</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_Code holds an error code.  The enum values here are identical to<br>\n// corresponding values in error_codes.proto.<br>\ntypedef enum {<br>\nTF_OK = 0,<br>\nTF_CANCELLED = 1,<br>\nTF_UNKNOWN = 2,<br>\nTF_INVALID_ARGUMENT = 3,<br>\nTF_DEADLINE_EXCEEDED = 4,<br>\nTF_NOT_FOUND = 5,<br>\nTF_ALREADY_EXISTS = 6,<br>\nTF_PERMISSION_DENIED = 7,<br>\nTF_UNAUTHENTICATED = 16,<br>\nTF_RESOURCE_EXHAUSTED = 8,<br>\nTF_FAILED_PRECONDITION = 9,<br>\nTF_ABORTED = 10,<br>\nTF_OUT_OF_RANGE = 11,<br>\nTF_UNIMPLEMENTED = 12,<br>\nTF_INTERNAL = 13,<br>\nTF_UNAVAILABLE = 14,<br>\nTF_DATA_LOSS = 15,<br>\n} TF_Code;</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_Status holds error information.  It either has an OK code, or<br>\n// else an error code with an associated error message.<br>\ntypedef struct TF_Status TF_Status;</p>\n<p>// Return a new status object.<br>\nextern TF_Status* TF_NewStatus();</p>\n<p>// Delete a previously created status object.<br>\nextern void TF_DeleteStatus(TF_Status*);</p>\n<p>// Record &lt;code, msg&gt; in <em>s.  Any previous information is lost.<br>\n// A common use is to clear a status: TF_SetStatus(s, TF_OK, \"\");<br>\nextern void TF_SetStatus(TF_Status</em> s, TF_Code code, const char* msg);</p>\n<p>// Return the code record in <em>s.<br>\nextern TF_Code TF_GetCode(const TF_Status</em> s);</p>\n<p>// Return a pointer to the (null-terminated) error message in <em>s.  The<br>\n// return value points to memory that is only usable until the next<br>\n// mutation to *s.  Always returns an empty string if TF_GetCode(s) is<br>\n// TF_OK.<br>\nextern const char</em> TF_Message(const TF_Status* s);</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_Buffer holds a pointer to a block of data and its associated length.<br>\n// Typically, the data consists of a serialized protocol buffer, but other data<br>\n// may also be held in a buffer.<br>\n//<br>\n// By default, TF_Buffer itself does not do any memory management of the<br>\n// pointed-to block.  If need be, users of this struct should specify how to<br>\n// deallocate the block by setting the <code>data_deallocator</code> function pointer.<br>\ntypedef struct {<br>\nconst void* data;<br>\nsize_t length;<br>\nvoid (<em>data_deallocator)(void</em> data, size_t length);<br>\n} TF_Buffer;</p>\n<p>// Makes a copy of the input and sets an appropriate deallocator.  Useful for<br>\n// passing in read-only, input protobufs.<br>\nextern TF_Buffer* TF_NewBufferFromString(const void* proto, size_t proto_len);</p>\n<p>// Useful for passing <em>out</em> a protobuf.<br>\nextern TF_Buffer* TF_NewBuffer();</p>\n<p>extern void TF_DeleteBuffer(TF_Buffer*);</p>\n<p>extern TF_Buffer TF_GetBuffer(TF_Buffer* buffer);</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_Tensor holds a multi-dimensional array of elements of a single data type.<br>\n// For all types other than TF_STRING, the data buffer stores elements<br>\n// in row major order.  E.g. if data is treated as a vector of TF_DataType:<br>\n//<br>\n//   element 0:   index (0, ..., 0)<br>\n//   element 1:   index (0, ..., 1)<br>\n//   ...<br>\n//<br>\n// The format for TF_STRING tensors is:<br>\n//   start_offset: array[uint64]<br>\n//   data:         byte[...]<br>\n//<br>\n//   String length is encoded (varint?) starting at data[start_offset[i]]<br>\n//   String contents follow immediately after string length.</p>\n<p>typedef struct TF_Tensor TF_Tensor;</p>\n<p>// Return a new tensor that holds the bytes data[0,len-1].<br>\n//<br>\n// The data will be deallocated by a subsequent call to TF_DeleteTensor via:<br>\n//      (<em>deallocator)(data, len, deallocator_arg)<br>\n// Clients must provide a custom deallocator function so they can pass in<br>\n// memory managed by something like numpy.<br>\nextern TF_Tensor</em> TF_NewTensor(TF_DataType, const int64_t* dims, int num_dims,<br>\nvoid* data, size_t len,<br>\nvoid (<em>deallocator)(void</em> data, size_t len,<br>\nvoid* arg),<br>\nvoid* deallocator_arg);</p>\n<p>// Destroy a tensor.<br>\nextern void TF_DeleteTensor(TF_Tensor*);</p>\n<p>// Return the type of a tensor element.<br>\nextern TF_DataType TF_TensorType(const TF_Tensor*);</p>\n<p>// Return the number of dimensions that the tensor has.<br>\nextern int TF_NumDims(const TF_Tensor*);</p>\n<p>// Return the length of the tensor in the \"dim_index\" dimension.<br>\n// REQUIRES: 0 &lt;= dim_index &lt; TF_NumDims(tensor)<br>\nextern int64_t TF_Dim(const TF_Tensor* tensor, int dim_index);</p>\n<p>// Return the size of the underlying data in bytes.<br>\nextern size_t TF_TensorByteSize(const TF_Tensor*);</p>\n<p>// Return a pointer to the underlying data buffer.<br>\nextern void* TF_TensorData(const TF_Tensor*);</p>\n<p>// --------------------------------------------------------------------------<br>\n// TF_SessionOptions holds options that can be passed during session creation.<br>\ntypedef struct TF_SessionOptions TF_SessionOptions;</p>\n<p>// Return a new options object.<br>\nextern TF_SessionOptions* TF_NewSessionOptions();</p>\n<p>// Set the target in TF_SessionOptions.options.<br>\n// target can be empty, a single entry, or a comma separated list of entries.<br>\n// Each entry is in one of the following formats :<br>\n// \"local\"<br>\n// ip:port<br>\n// host:port<br>\nextern void TF_SetTarget(TF_SessionOptions* options, const char* target);</p>\n<p>// Set the config in TF_SessionOptions.options.<br>\n// config should be a serialized tensorflow.ConfigProto proto.<br>\n// If config was not parsed successfully as a ConfigProto, record the<br>\n// error information in <em>status.<br>\nextern void TF_SetConfig(TF_SessionOptions</em> options, const void* proto,<br>\nsize_t proto_len, TF_Status* status);</p>\n<p>// Destroy an options object.<br>\nextern void TF_DeleteSessionOptions(TF_SessionOptions*);</p>\n<p>// TODO(jeff,sanjay):<br>\n// - export functions to set Config fields</p>\n<p>// --------------------------------------------------------------------------<br>\n// The new graph construction API, still under development.</p>\n<p>// Represents a computation graph.  Graphs may be shared between sessions.<br>\n// Graphs are thread-safe when used as directed below.<br>\ntypedef struct TF_Graph TF_Graph;</p>\n<p>// Return a new graph object.<br>\nextern TF_Graph* TF_NewGraph();</p>\n<p>// Destroy an options object.  Graph will be deleted once no more<br>\n// TFSessionWithGraph's are referencing it.<br>\nextern void TF_DeleteGraph(TF_Graph*);</p>\n<p>// Node being built. The underlying graph must outlive this.<br>\ntypedef struct TF_NodeDescription TF_NodeDescription;</p>\n<p>// Node that has been added to the graph. Valid until the graph is<br>\n// deleted -- in particular adding a new node to the graph does not<br>\n// invalidate old TF_Node* pointers.<br>\ntypedef struct TF_Node TF_Node;</p>\n<p>// Represents a specific input or output of a node, e.g. to specify the<br>\n// specific output to pass as an input to an op.<br>\ntypedef struct TF_Port {<br>\nTF_Node* node;<br>\nint index;  // Specifies the index of the input or output within node.<br>\n} TF_Port;</p>\n<p>// Node will only be added to <em>graph when TF_FinishNode() is called<br>\n// (assuming TF_FinishNode() does not return an error).  *graph must<br>\n// not be deleted until after TF_FinishNode() is called.<br>\nextern TF_NodeDescription</em> TF_NewNode(TF_Graph* graph, const char* op_type,<br>\nconst char* node_name);</p>\n<p>// Specify the device for <code>desc</code>.  Defaults to empty, meaning unconstrained.<br>\nextern void TF_SetDevice(TF_NodeDescription* desc, const char* device);</p>\n<p>// The calls to TF_AddInput and TF_AddInputList must match (in number,<br>\n// order, and type) the op declaration.  For example, the \"Concat\" op<br>\n// has registration:<br>\n//   REGISTER_OP(\"Concat\")<br>\n//       .Input(\"concat_dim: int32\")<br>\n//       .Input(\"values: N * T\")<br>\n//       .Output(\"output: T\")<br>\n//       .Attr(\"N: int &gt;= 2\")<br>\n//       .Attr(\"T: type\");<br>\n// that defines two inputs, \"concat_dim\" and \"values\" (in that order).<br>\n// You must use TF_AddInput() for the first input (since it takes a<br>\n// single tensor), and TF_AddInputList() for the second input (since<br>\n// it takes a list, even if you were to pass a list with a single<br>\n// tensor), as in:<br>\n//   TF_NodeDescription* desc = TF_NewNode(graph, \"Concat\", \"c\");<br>\n//   TF_Port concat_dim_input = {...};<br>\n//   TF_AddInput(desc, concat_dim_input);<br>\n//   TF_Port values_inputs[5] = {{...}, ..., {...}};<br>\n//   TF_AddInputList(desc, 5, values_inputs);</p>\n<p>// For inputs that take a single tensor.<br>\nextern void TF_AddInput(TF_NodeDescription* desc, TF_Port input);</p>\n<p>// For inputs that take a list of tensors.<br>\n// inputs must point to TF_Port[num_inputs].<br>\nextern void TF_AddInputList(TF_NodeDescription* desc, const TF_Port* inputs,<br>\nint num_inputs);</p>\n<p>// Call once per control input to <code>desc</code>.<br>\nextern void TF_AddControlInput(TF_NodeDescription* desc, TF_Node* input);</p>\n<p>// Call some TF_SetAttr*() function for every attr that is not<br>\n// inferred from an input and doesn't have a default value you wish to<br>\n// keep.</p>\n<p>// <code>value</code> must point to a string of length <code>length</code> bytes.<br>\nextern void TF_SetAttrString(TF_NodeDescription* desc, const char* attr_name,<br>\nconst void* value, int length);<br>\n// <code>values</code> and <code>lengths</code> both must have lengths <code>num_values</code>.<br>\n// <code>values[i]</code> must point to a string of length <code>lengths[i]</code> bytes.<br>\nextern void TF_SetAttrStringList(TF_NodeDescription* desc,<br>\nconst char* attr_name,<br>\nconst void* const* values, const int* lengths,<br>\nint num_values);<br>\nextern void TF_SetAttrInt(TF_NodeDescription* desc, const char* attr_name,<br>\nint64_t value);<br>\nextern void TF_SetAttrIntList(TF_NodeDescription* desc, const char* attr_name,<br>\nconst int64_t* values, int num_values);<br>\nextern void TF_SetAttrFloat(TF_NodeDescription* desc, const char* attr_name,<br>\nfloat value);<br>\nextern void TF_SetAttrFloatList(TF_NodeDescription* desc, const char* attr_name,<br>\nconst float* values, int num_values);<br>\nextern void TF_SetAttrBool(TF_NodeDescription* desc, const char* attr_name,<br>\nunsigned char value);<br>\nextern void TF_SetAttrBoolList(TF_NodeDescription* desc, const char* attr_name,<br>\nconst unsigned char* values, int num_values);<br>\nextern void TF_SetAttrType(TF_NodeDescription* desc, const char* attr_name,<br>\nTF_DataType value);<br>\nextern void TF_SetAttrTypeList(TF_NodeDescription* desc, const char* attr_name,<br>\nconst TF_DataType* values, int num_values);</p>\n<p>// Set <code>num_dims</code> to -1 to represent \"unknown rank\".  Otherwise,<br>\n// <code>dims</code> points to an array of length <code>num_dims</code>.  <code>dims[i]</code> must be<br>\n// &gt;= -1, with -1 meaning \"unknown dimension\".<br>\nextern void TF_SetAttrShape(TF_NodeDescription* desc, const char* attr_name,<br>\nconst int64_t* dims, int num_dims);<br>\n// <code>dims</code> and <code>num_dims</code> must point to arrays of length <code>num_shapes</code>.<br>\n// Set <code>num_dims[i]</code> to -1 to represent \"unknown rank\".  Otherwise,<br>\n// <code>dims[i]</code> points to an array of length <code>num_dims[i]</code>.  <code>dims[i][j]</code><br>\n// must be &gt;= -1, with -1 meaning \"unknown dimension\".<br>\nextern void TF_SetAttrShapeList(TF_NodeDescription* desc, const char* attr_name,<br>\nconst int64_t* const* dims, const int* num_dims,<br>\nint num_shapes);<br>\n// <code>proto</code> must point to an array of <code>proto_len</code> bytes representing a<br>\n// binary-serialized TensorShapeProto.<br>\nextern void TF_SetAttrTensorShapeProto(TF_NodeDescription* desc,<br>\nconst char* attr_name, void* proto,<br>\nint proto_len, TF_Status* status);<br>\n// <code>protos</code> and <code>proto_lens</code> must point to arrays of length <code>num_shapes</code>.<br>\n// <code>protos[i]</code> must point to an array of <code>proto_lens[i]</code> bytes<br>\n// representing a binary-serialized TensorShapeProto.<br>\nextern void TF_SetAttrTensorShapeProtoList(TF_NodeDescription* desc,<br>\nconst char* attr_name,<br>\nconst void* const* protos,<br>\nconst int* proto_lens,<br>\nint num_shapes, TF_Status* status);</p>\n<p>// This functions takes ownership of <em>value (the<br>\n// implementation will eventually call TF_DeleteTensor).<br>\nextern void TF_SetAttrTensor(TF_NodeDescription</em> desc, const char* attr_name,<br>\nTF_Tensor* value, TF_Status* status);<br>\n// This functions takes ownership of values[0]..values[num_values-1](the<br>\n// implementation will eventually call TF_DeleteTensor on each).<br>\nextern void TF_SetAttrTensorList(TF_NodeDescription* desc,<br>\nconst char* attr_name,<br>\nTF_Tensor* const* values, int num_values,<br>\nTF_Status* status);</p>\n<p>// <code>proto</code> should point to a sequence of bytes of length <code>proto_len</code><br>\n// representing a binary serialization of an AttrValue protocol<br>\n// buffer.<br>\nextern void TF_SetAttrToAttrValueProto(TF_NodeDescription* desc,<br>\nconst char* attr_name, const void* proto,<br>\nsize_t proto_len, TF_Status* status);</p>\n<p>// If this function succeeds:<br>\n//   * <em>status is set to an OK value,<br>\n//   * a TF_Node is added to the graph,<br>\n//   * a non-null value pointing to the added node is returned --<br>\n//     this value is valid until the underlying graph is deleted.<br>\n// Otherwise:<br>\n//   * *status is set to a non-OK value,<br>\n//   * the graph is not modified,<br>\n//   * a null value is returned.<br>\n// In either case, it deletes <code>desc</code>.<br>\nextern TF_Node</em> TF_FinishNode(TF_NodeDescription* desc, TF_Status* status);</p>\n<p>// TF_Node functions.  Nodes are immutable once created, so these are all<br>\n// query functions.</p>\n<p>extern const char* TF_NodeName(TF_Node* node);<br>\nextern const char* TF_NodeOpType(TF_Node* node);<br>\nextern const char* TF_NodeDevice(TF_Node* node);</p>\n<p>extern int TF_NodeNumOutputs(TF_Node* node);<br>\nextern TF_DataType TF_NodeOutputType(TF_Port node_out);<br>\nextern int TF_NodeOutputListLength(TF_Node* node, const char* arg_name,<br>\nTF_Status* status);</p>\n<p>extern int TF_NodeNumInputs(TF_Node* node);<br>\nextern TF_DataType TF_NodeInputType(TF_Port node_in);<br>\nextern int TF_NodeInputListLength(TF_Node* node, const char* arg_name,<br>\nTF_Status* status);</p>\n<p>// In this code:<br>\n//   TF_Port producer = TF_NodeInput(consumer);<br>\n// There is an edge from producer.node's output (given by<br>\n// producer.index) to consumer.node's input (given by consumer.index).<br>\nextern TF_Port TF_NodeInput(TF_Port node_in);</p>\n<p>// Get the number of current consumers of a node's output.  Note that<br>\n// this number can change when new nodes are added to the graph.<br>\nextern int TF_NodeOutputNumConsumers(TF_Port node_out);</p>\n<p>// Get list of all current consumers of a node's output.  consumers<br>\n// must point to an array of length at least max_consumers (ideally<br>\n// set to TF_NodeOutputNumConsumer(node_out)).  Beware that a<br>\n// concurrent modification of the graph can increase the number of<br>\n// consumers of a node.  Returns the number of output consumers<br>\n// (should match TF_NodeOutputNumConsumers(node_out)).<br>\nextern int TF_NodeOutputConsumers(TF_Port node_out, TF_Port* consumers,<br>\nint max_consumers);</p>\n<p>// Get the number of control inputs to a node.<br>\nextern int TF_NodeNumControlInputs(TF_Node* node);</p>\n<p>// Get list of all control inputs to a node.  control_inputs must<br>\n// point to an array of length max_control_inputs (ideally set to<br>\n// TF_NodeNumControlInputs(node)).  Returns the number of control<br>\n// inputs (should match TF_NodeNumControlInputs(node)).<br>\nextern int TF_NodeGetControlInputs(TF_Node* node, TF_Node** control_inputs,<br>\nint max_control_inputs);</p>\n<p>// Get the number of nodes that have <em>node as a control inputs.<br>\n// Note that this number can change when new nodes are added to the<br>\n// graph.<br>\nextern int TF_NodeNumControlOutputs(TF_Node</em> node);</p>\n<p>// Get the list of nodes that have <em>node as a control input.<br>\n// control_outputs must point to an array of length at least<br>\n// max_control_outputs (ideally set to<br>\n// TF_NodeNumControlOutputs(node)). Beware that a concurrent<br>\n// modification of the graph can increase the number of control<br>\n// outputs.  Returns the number of control outputs (should match<br>\n// TF_NodeNumControlOutputs(node)).<br>\nextern int TF_NodeGetControlOutputs(TF_Node</em> node, TF_Node** control_outputs,<br>\nint max_control_outputs);</p>\n<p>// Sets <code>output_attr_value</code> to the binary-serialized AttrValue proto<br>\n// representation of the value of the <code>attr_name</code> attr of <code>node</code>.<br>\nextern void TF_NodeGetAttrValueProto(TF_Node* node, const char* attr_name,<br>\nTF_Buffer* output_attr_value,<br>\nTF_Status* status);</p>\n<p>// Returns the node in the graph with <code>node_name</code>. Returns nullptr if<br>\n// no node found.<br>\nextern TF_Node* TF_GraphNodeByName(TF_Graph* graph, const char* node_name);</p>\n<p>// Iterate through the nodes of a graph.  To use:<br>\n// size_t pos = 0;<br>\n// TF_Node* node;<br>\n// while ((node = TF_GraphNextNode(graph, &amp;pos)) != nullptr) {<br>\n//   DoSomethingWithNode(node);<br>\n// }<br>\nextern TF_Node* TF_GraphNextNode(TF_Graph* graph, size_t* pos);</p>\n<p>// Note: The following two functions may fail on very large protos in the<br>\n// future.</p>\n<p>extern void TF_GraphToGraphDef(TF_Graph* graph, TF_Buffer* output_graph_def,<br>\nTF_Status* status);</p>\n<p>extern void TF_NodeToNodeDef(TF_Node* node, TF_Buffer* output_node_def,<br>\nTF_Status* status);</p>\n<p>// TODO(josh11b): Query attrs for a Node.</p>\n<p>// TODO(cwhipkey): Query shape for node outputs.</p>\n<p>// TODO(josh11b,mrry): Import GraphDef into TF_Graph.</p>\n<p>// TODO(andydavis): Function to add gradients to a graph.</p>\n<p>// TODO(josh11b): Register OpDef, available to all nodes added<br>\n// to this graph.</p>\n<p>// The following two may both benefit from a subgraph-definition API<br>\n// that re-uses most of the graph-definition API.<br>\n// TODO(andydavis): Add functions to a graph.<br>\n// TODO(yuanbyu): Add while loop to graph.</p>\n<p>// --------------------------------------------------------------------------<br>\n// The new session API that uses TF_Graph*.  The intent is this will<br>\n// replace the TF_ExtendGraph() API.</p>\n<p>// TODO(josh11b): Rename this TF_Session once we delete the old API.<br>\ntypedef struct TF_SessionWithGraph TF_SessionWithGraph;</p>\n<p>// Return a new execution session with the associated graph, or NULL<br>\n// on error.  <em>graph must be a valid graph (not deleted or nullptr).<br>\n// This function will prevent the graph from being deleted until<br>\n// TF_DeleteSessionWithGraph() is called.  Does not take ownership of opts.<br>\n// TODO(josh11b): Rename this TF_NewSession() once we delete the old API.<br>\nextern TF_SessionWithGraph</em> TF_NewSessionWithGraph(<br>\nTF_Graph* graph, const TF_SessionOptions* opts, TF_Status* status);</p>\n<p>// Close a session. This contacts any other processes associated with this<br>\n// session, if applicable. This may not be called after<br>\n// TF_DeleteSessionWithGraph().<br>\n// TODO(josh11b): Rename this TF_CloseSession() once we delete the old API.<br>\nextern void TF_CloseSessionWithGraph(TF_SessionWithGraph_, TF_Status_ status);</p>\n<p>// Destroy a session object.  Even if error information is recorded in<br>\n// <em>status, this call discards all local resources associated with the<br>\n// session.  The session may not be used during or after this call<br>\n// (and the session drops its reference to the corresponding graph).<br>\n// TODO(josh11b): Rename this TF_DeleteSession() once we delete the old API.<br>\nextern void TF_DeleteSessionWithGraph(TF_SessionWithGraph</em>, TF_Status* status);</p>\n<p>// See TF_Run() below.<br>\nextern void TF_SessionRun(TF_SessionWithGraph* session,<br>\n// RunOptions<br>\nconst TF_Buffer* run_options,<br>\n// Input tensors<br>\nconst TF_Port* inputs, TF_Tensor* const* input_values,<br>\nint ninputs,<br>\n// Output tensors<br>\nconst TF_Port* outputs, TF_Tensor** output_values,<br>\nint noutputs,<br>\n// Target nodes<br>\nconst TF_Node* const* target_nodes, int ntargets,<br>\n// RunMetadata<br>\nTF_Buffer* run_metadata,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// See TF_PRunSetup() below.<br>\nextern void TF_SessionPRunSetup(TF_SessionWithGraph_,<br>\n// Input names<br>\nconst TF_Port_ inputs, int ninputs,<br>\n// Output names<br>\nconst TF_Port* outputs, int noutputs,<br>\n// Target nodes<br>\nconst TF_Node* const* target_nodes,<br>\nint ntargets,<br>\n// Output handle<br>\nconst char** handle,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// See TF_PRun() below.<br>\nextern void TF_SessionPRun(TF_SessionWithGraph_, const char_ handle,<br>\n// Input tensors<br>\nconst TF_Port* inputs,<br>\nTF_Tensor* const* input_values, int ninputs,<br>\n// Output tensors<br>\nconst TF_Port* outputs, TF_Tensor** output_values,<br>\nint noutputs,<br>\n// Target nodes<br>\nconst TF_Node* const* target_nodes, int ntargets,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// --------------------------------------------------------------------------<br>\n// The deprecated session API.  Please switch to the above instead of<br>\n// TF_ExtendGraph().  TF_Session manages a single graph and execution.</p>\n<p>typedef struct TF_Session TF_Session;</p>\n<p>// Return a new execution session, or NULL on error.<br>\nextern TF_Session* TF_NewSession(const TF_SessionOptions_, TF_Status_ status);</p>\n<p>// Close a session.<br>\nextern void TF_CloseSession(TF_Session_, TF_Status_ status);</p>\n<p>// Destroy a session.  Even if error information is recorded in <em>status,<br>\n// this call discards all resources associated with the session.<br>\nextern void TF_DeleteSession(TF_Session</em>, TF_Status* status);</p>\n<p>// Closes all existing sessions connected to the <code>target</code> specified in the<br>\n// <code>SessionOptions</code>, and frees shared resources in <code>containers</code> on `target'.<br>\n// If no containers are provided, all containers are cleared.<br>\nextern void TF_Reset(const TF_SessionOptions* opt, const char** containers,<br>\nint ncontainers, TF_Status* status);</p>\n<p>// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and<br>\n// add the nodes in that GraphDef to the graph for the session.<br>\nextern void TF_ExtendGraph(TF_Session_, const void_ proto, size_t proto_len,<br>\nTF_Status*);</p>\n<p>// Run the graph associated with the session starting with the<br>\n// supplied inputs (inputs[0,ninputs-1]).  Regardless of success or<br>\n// failure, inputs[] become the property of the implementation (the<br>\n// implementation will eventually call TF_DeleteTensor on each input).<br>\n//<br>\n// Any NULL and non-NULL value combinations for (<code>run_options</code>,<br>\n// <code>run_metadata</code>) are valid.<br>\n//<br>\n//    - <code>run_options</code> may be NULL, in which case it will be ignored; or<br>\n//      non-NULL, in which case it must point to a <code>TF_Buffer</code> containing the<br>\n//      serialized representation of a <code>RunOptions</code> protocol buffer.<br>\n//    - <code>run_metadata</code> may be NULL, in which case it will be ignored; or<br>\n//      non-NULL, in which case it must point to an empty, freshly allocated<br>\n//      <code>TF_Buffer</code> that may be updated to contain the serialized representation<br>\n//      of a <code>RunMetadata</code> protocol buffer.<br>\n//<br>\n// The caller retains the ownership of <code>run_options</code> and/or <code>run_metadata</code> (when<br>\n// not NULL) and should manually call TF_DeleteBuffer on them.<br>\n//<br>\n// On success, the tensors corresponding to output_names[0,noutputs-1]<br>\n// are placed in outputs[], and these outputs[] become the property<br>\n// of the caller (the caller must eventually call TF_DeleteTensor on<br>\n// them).<br>\n//<br>\n// On failure, outputs[] contains NULLs.<br>\nextern void TF_Run(TF_Session_,<br>\n// RunOptions<br>\nconst TF_Buffer_ run_options,<br>\n// Input tensors<br>\nconst char** input_names, TF_Tensor** inputs, int ninputs,<br>\n// Output tensors<br>\nconst char** output_tensor_names, TF_Tensor** outputs,<br>\nint noutputs,<br>\n// Target nodes<br>\nconst char** target_node_names, int ntargets,<br>\n// RunMetadata<br>\nTF_Buffer* run_metadata,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// Set up the graph with the intended feeds and fetches for a sequence<br>\n// of partial run calls.<br>\n//<br>\n// On success, returns a handle that is used for subsequent PRun calls.<br>\n//<br>\n// On failure, out_status contains a tensorflow::Status with an error<br>\n// message.<br>\n// NOTE: This is EXPERIMENTAL and subject to change.<br>\nextern void TF_PRunSetup(TF_Session_,<br>\n// Input names<br>\nconst char_* input_names, int ninputs,<br>\n// Output names<br>\nconst char** output_tensor_names, int noutputs,<br>\n// Target nodes<br>\nconst char** target_node_names, int ntargets,<br>\n// Output handle<br>\nconst char** handle,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// Continue to run the graph with additional feeds and fetches. The<br>\n// execution state is uniquely identified by the handle.<br>\n// NOTE: This is EXPERIMENTAL and subject to change.<br>\nextern void TF_PRun(TF_Session_, const char_ handle,<br>\n// Input tensors<br>\nconst char** input_names, TF_Tensor** inputs, int ninputs,<br>\n// Output tensors<br>\nconst char** output_tensor_names, TF_Tensor** outputs,<br>\nint noutputs,<br>\n// Target nodes<br>\nconst char** target_node_names, int ntargets,<br>\n// Output status<br>\nTF_Status*);</p>\n<p>// --------------------------------------------------------------------------<br>\n// Load plugins containing custom ops and kernels</p>\n<p>// TF_Library holds information about dynamically loaded TensorFlow plugins.<br>\ntypedef struct TF_Library TF_Library;</p>\n<p>// Load the library specified by library_filename and register the ops and<br>\n// kernels present in that library.<br>\n//<br>\n// Pass \"library_filename\" to a platform-specific mechanism for dynamically<br>\n// loading a library. The rules for determining the exact location of the<br>\n// library are platform-specific and are not documented here.<br>\n// Expects the symbols \"RegisterOps\", \"RegisterKernels\", and \"GetOpList\", to be<br>\n// defined in the library.<br>\n//<br>\n// On success, place OK in status and return the newly created library handle.<br>\n// The caller owns the library handle.<br>\n//<br>\n// On failure, place an error status in status and return NULL.<br>\nextern TF_Library* TF_LoadLibrary(const char* library_filename,<br>\nTF_Status* status);</p>\n<p>// Get the OpList of OpDefs defined in the library pointed by lib_handle.<br>\n//<br>\n// Returns a TF_Buffer. The memory pointed to by the result is owned by<br>\n// lib_handle. The data in the buffer will be the serialized OpList proto for<br>\n// ops defined in the library.<br>\nextern TF_Buffer TF_GetOpList(TF_Library* lib_handle);</p>\n<p>#ifdef __cplusplus<br>\n} /* end extern \"C\" */<br>\n#endif</p>\n<p>#endif  // TENSORFLOW_C_C_API_H_</p>", "body_text": "c_api_test.cc src:\n#include \"./c_api.h\"\n#include<stdio.h>\n#include<string.h>\nint main(int argc, char argv[]){\nprintf(\"---- -------start\");\nTF_Status s = TF_NewStatus();\nTF_SessionOptions* opt = TF_NewSessionOptions();\nTF_Session* session = TF_NewSession(opt, s);\nTF_DeleteSessionOptions(opt);\nTF_CloseSession(session,s);\nTF_DeleteStatus(s);\nprintf(\"---- -------end\");\nreturn 1;\n}\nc_api.h file is within tensorflow/c directory :\n/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_C_C_API_H_\n#define TENSORFLOW_C_C_API_H_\n#include <stddef.h>\n#include <stdint.h>\n// --------------------------------------------------------------------------\n// C API for TensorFlow.\n//\n// The API leans towards simplicity and uniformity instead of convenience\n// since most usage will be by language specific wrappers.\n//\n// Conventions:\n// * We use the prefix TF_ for everything in the API.\n// * Objects are always passed around as pointers to opaque structs\n//   and these structs are allocated/deallocated via the API.\n// * TF_Status holds error information.  It is an object type\n//   and therefore is passed around as a pointer to an opaque\n//   struct as mentioned above.\n// * Every call that has a TF_Status* argument clears it on success\n//   and fills it with error info on failure.\n//\n// Questions left to address:\n// * Might at some point need a way for callers to provide their own Env.\n// * Maybe add TF_TensorShape that encapsulates dimension info.\n//\n// Design decisions made:\n// * Backing store for tensor memory has an associated deallocation\n//   function.  This deallocation function will point to client code\n//   for tensors populated by the client.  So the client can do things\n//   like shadowing a numpy array.\n// * We do not provide TF_OK since it is not strictly necessary and we\n//   are not optimizing for convenience.\n// * We make assumption that one session has one graph.  This should be\n//   fine since we have the ability to run sub-graphs.\n// * We could allow NULL for some arguments (e.g., NULL options arg).\n//   However since convenience is not a primary goal, we don't do this.\n// * Devices are not in this API.  Instead, they are created/used internally\n//   and the API just provides high level controls over the number of\n//   devices of each type.\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n// --------------------------------------------------------------------------\n// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.\n// The enum values here are identical to corresponding values in types.proto.\ntypedef enum {\nTF_FLOAT = 1,\nTF_DOUBLE = 2,\nTF_INT32 = 3,  // Int32 tensors are always in 'host' memory.\nTF_UINT8 = 4,\nTF_INT16 = 5,\nTF_INT8 = 6,\nTF_STRING = 7,\nTF_COMPLEX64 = 8,  // Single-precision complex\nTF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility\nTF_INT64 = 9,\nTF_BOOL = 10,\nTF_QINT8 = 11,     // Quantized int8\nTF_QUINT8 = 12,    // Quantized uint8\nTF_QINT32 = 13,    // Quantized int32\nTF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.\nTF_QINT16 = 15,    // Quantized int16\nTF_QUINT16 = 16,   // Quantized uint16\nTF_UINT16 = 17,\nTF_COMPLEX128 = 18,  // Double-precision complex\nTF_HALF = 19,\n} TF_DataType;\n// --------------------------------------------------------------------------\n// TF_Code holds an error code.  The enum values here are identical to\n// corresponding values in error_codes.proto.\ntypedef enum {\nTF_OK = 0,\nTF_CANCELLED = 1,\nTF_UNKNOWN = 2,\nTF_INVALID_ARGUMENT = 3,\nTF_DEADLINE_EXCEEDED = 4,\nTF_NOT_FOUND = 5,\nTF_ALREADY_EXISTS = 6,\nTF_PERMISSION_DENIED = 7,\nTF_UNAUTHENTICATED = 16,\nTF_RESOURCE_EXHAUSTED = 8,\nTF_FAILED_PRECONDITION = 9,\nTF_ABORTED = 10,\nTF_OUT_OF_RANGE = 11,\nTF_UNIMPLEMENTED = 12,\nTF_INTERNAL = 13,\nTF_UNAVAILABLE = 14,\nTF_DATA_LOSS = 15,\n} TF_Code;\n// --------------------------------------------------------------------------\n// TF_Status holds error information.  It either has an OK code, or\n// else an error code with an associated error message.\ntypedef struct TF_Status TF_Status;\n// Return a new status object.\nextern TF_Status* TF_NewStatus();\n// Delete a previously created status object.\nextern void TF_DeleteStatus(TF_Status*);\n// Record <code, msg> in s.  Any previous information is lost.\n// A common use is to clear a status: TF_SetStatus(s, TF_OK, \"\");\nextern void TF_SetStatus(TF_Status s, TF_Code code, const char* msg);\n// Return the code record in s.\nextern TF_Code TF_GetCode(const TF_Status s);\n// Return a pointer to the (null-terminated) error message in s.  The\n// return value points to memory that is only usable until the next\n// mutation to *s.  Always returns an empty string if TF_GetCode(s) is\n// TF_OK.\nextern const char TF_Message(const TF_Status* s);\n// --------------------------------------------------------------------------\n// TF_Buffer holds a pointer to a block of data and its associated length.\n// Typically, the data consists of a serialized protocol buffer, but other data\n// may also be held in a buffer.\n//\n// By default, TF_Buffer itself does not do any memory management of the\n// pointed-to block.  If need be, users of this struct should specify how to\n// deallocate the block by setting the data_deallocator function pointer.\ntypedef struct {\nconst void* data;\nsize_t length;\nvoid (data_deallocator)(void data, size_t length);\n} TF_Buffer;\n// Makes a copy of the input and sets an appropriate deallocator.  Useful for\n// passing in read-only, input protobufs.\nextern TF_Buffer* TF_NewBufferFromString(const void* proto, size_t proto_len);\n// Useful for passing out a protobuf.\nextern TF_Buffer* TF_NewBuffer();\nextern void TF_DeleteBuffer(TF_Buffer*);\nextern TF_Buffer TF_GetBuffer(TF_Buffer* buffer);\n// --------------------------------------------------------------------------\n// TF_Tensor holds a multi-dimensional array of elements of a single data type.\n// For all types other than TF_STRING, the data buffer stores elements\n// in row major order.  E.g. if data is treated as a vector of TF_DataType:\n//\n//   element 0:   index (0, ..., 0)\n//   element 1:   index (0, ..., 1)\n//   ...\n//\n// The format for TF_STRING tensors is:\n//   start_offset: array[uint64]\n//   data:         byte[...]\n//\n//   String length is encoded (varint?) starting at data[start_offset[i]]\n//   String contents follow immediately after string length.\ntypedef struct TF_Tensor TF_Tensor;\n// Return a new tensor that holds the bytes data[0,len-1].\n//\n// The data will be deallocated by a subsequent call to TF_DeleteTensor via:\n//      (deallocator)(data, len, deallocator_arg)\n// Clients must provide a custom deallocator function so they can pass in\n// memory managed by something like numpy.\nextern TF_Tensor TF_NewTensor(TF_DataType, const int64_t* dims, int num_dims,\nvoid* data, size_t len,\nvoid (deallocator)(void data, size_t len,\nvoid* arg),\nvoid* deallocator_arg);\n// Destroy a tensor.\nextern void TF_DeleteTensor(TF_Tensor*);\n// Return the type of a tensor element.\nextern TF_DataType TF_TensorType(const TF_Tensor*);\n// Return the number of dimensions that the tensor has.\nextern int TF_NumDims(const TF_Tensor*);\n// Return the length of the tensor in the \"dim_index\" dimension.\n// REQUIRES: 0 <= dim_index < TF_NumDims(tensor)\nextern int64_t TF_Dim(const TF_Tensor* tensor, int dim_index);\n// Return the size of the underlying data in bytes.\nextern size_t TF_TensorByteSize(const TF_Tensor*);\n// Return a pointer to the underlying data buffer.\nextern void* TF_TensorData(const TF_Tensor*);\n// --------------------------------------------------------------------------\n// TF_SessionOptions holds options that can be passed during session creation.\ntypedef struct TF_SessionOptions TF_SessionOptions;\n// Return a new options object.\nextern TF_SessionOptions* TF_NewSessionOptions();\n// Set the target in TF_SessionOptions.options.\n// target can be empty, a single entry, or a comma separated list of entries.\n// Each entry is in one of the following formats :\n// \"local\"\n// ip:port\n// host:port\nextern void TF_SetTarget(TF_SessionOptions* options, const char* target);\n// Set the config in TF_SessionOptions.options.\n// config should be a serialized tensorflow.ConfigProto proto.\n// If config was not parsed successfully as a ConfigProto, record the\n// error information in status.\nextern void TF_SetConfig(TF_SessionOptions options, const void* proto,\nsize_t proto_len, TF_Status* status);\n// Destroy an options object.\nextern void TF_DeleteSessionOptions(TF_SessionOptions*);\n// TODO(jeff,sanjay):\n// - export functions to set Config fields\n// --------------------------------------------------------------------------\n// The new graph construction API, still under development.\n// Represents a computation graph.  Graphs may be shared between sessions.\n// Graphs are thread-safe when used as directed below.\ntypedef struct TF_Graph TF_Graph;\n// Return a new graph object.\nextern TF_Graph* TF_NewGraph();\n// Destroy an options object.  Graph will be deleted once no more\n// TFSessionWithGraph's are referencing it.\nextern void TF_DeleteGraph(TF_Graph*);\n// Node being built. The underlying graph must outlive this.\ntypedef struct TF_NodeDescription TF_NodeDescription;\n// Node that has been added to the graph. Valid until the graph is\n// deleted -- in particular adding a new node to the graph does not\n// invalidate old TF_Node* pointers.\ntypedef struct TF_Node TF_Node;\n// Represents a specific input or output of a node, e.g. to specify the\n// specific output to pass as an input to an op.\ntypedef struct TF_Port {\nTF_Node* node;\nint index;  // Specifies the index of the input or output within node.\n} TF_Port;\n// Node will only be added to graph when TF_FinishNode() is called\n// (assuming TF_FinishNode() does not return an error).  *graph must\n// not be deleted until after TF_FinishNode() is called.\nextern TF_NodeDescription TF_NewNode(TF_Graph* graph, const char* op_type,\nconst char* node_name);\n// Specify the device for desc.  Defaults to empty, meaning unconstrained.\nextern void TF_SetDevice(TF_NodeDescription* desc, const char* device);\n// The calls to TF_AddInput and TF_AddInputList must match (in number,\n// order, and type) the op declaration.  For example, the \"Concat\" op\n// has registration:\n//   REGISTER_OP(\"Concat\")\n//       .Input(\"concat_dim: int32\")\n//       .Input(\"values: N * T\")\n//       .Output(\"output: T\")\n//       .Attr(\"N: int >= 2\")\n//       .Attr(\"T: type\");\n// that defines two inputs, \"concat_dim\" and \"values\" (in that order).\n// You must use TF_AddInput() for the first input (since it takes a\n// single tensor), and TF_AddInputList() for the second input (since\n// it takes a list, even if you were to pass a list with a single\n// tensor), as in:\n//   TF_NodeDescription* desc = TF_NewNode(graph, \"Concat\", \"c\");\n//   TF_Port concat_dim_input = {...};\n//   TF_AddInput(desc, concat_dim_input);\n//   TF_Port values_inputs[5] = {{...}, ..., {...}};\n//   TF_AddInputList(desc, 5, values_inputs);\n// For inputs that take a single tensor.\nextern void TF_AddInput(TF_NodeDescription* desc, TF_Port input);\n// For inputs that take a list of tensors.\n// inputs must point to TF_Port[num_inputs].\nextern void TF_AddInputList(TF_NodeDescription* desc, const TF_Port* inputs,\nint num_inputs);\n// Call once per control input to desc.\nextern void TF_AddControlInput(TF_NodeDescription* desc, TF_Node* input);\n// Call some TF_SetAttr*() function for every attr that is not\n// inferred from an input and doesn't have a default value you wish to\n// keep.\n// value must point to a string of length length bytes.\nextern void TF_SetAttrString(TF_NodeDescription* desc, const char* attr_name,\nconst void* value, int length);\n// values and lengths both must have lengths num_values.\n// values[i] must point to a string of length lengths[i] bytes.\nextern void TF_SetAttrStringList(TF_NodeDescription* desc,\nconst char* attr_name,\nconst void* const* values, const int* lengths,\nint num_values);\nextern void TF_SetAttrInt(TF_NodeDescription* desc, const char* attr_name,\nint64_t value);\nextern void TF_SetAttrIntList(TF_NodeDescription* desc, const char* attr_name,\nconst int64_t* values, int num_values);\nextern void TF_SetAttrFloat(TF_NodeDescription* desc, const char* attr_name,\nfloat value);\nextern void TF_SetAttrFloatList(TF_NodeDescription* desc, const char* attr_name,\nconst float* values, int num_values);\nextern void TF_SetAttrBool(TF_NodeDescription* desc, const char* attr_name,\nunsigned char value);\nextern void TF_SetAttrBoolList(TF_NodeDescription* desc, const char* attr_name,\nconst unsigned char* values, int num_values);\nextern void TF_SetAttrType(TF_NodeDescription* desc, const char* attr_name,\nTF_DataType value);\nextern void TF_SetAttrTypeList(TF_NodeDescription* desc, const char* attr_name,\nconst TF_DataType* values, int num_values);\n// Set num_dims to -1 to represent \"unknown rank\".  Otherwise,\n// dims points to an array of length num_dims.  dims[i] must be\n// >= -1, with -1 meaning \"unknown dimension\".\nextern void TF_SetAttrShape(TF_NodeDescription* desc, const char* attr_name,\nconst int64_t* dims, int num_dims);\n// dims and num_dims must point to arrays of length num_shapes.\n// Set num_dims[i] to -1 to represent \"unknown rank\".  Otherwise,\n// dims[i] points to an array of length num_dims[i].  dims[i][j]\n// must be >= -1, with -1 meaning \"unknown dimension\".\nextern void TF_SetAttrShapeList(TF_NodeDescription* desc, const char* attr_name,\nconst int64_t* const* dims, const int* num_dims,\nint num_shapes);\n// proto must point to an array of proto_len bytes representing a\n// binary-serialized TensorShapeProto.\nextern void TF_SetAttrTensorShapeProto(TF_NodeDescription* desc,\nconst char* attr_name, void* proto,\nint proto_len, TF_Status* status);\n// protos and proto_lens must point to arrays of length num_shapes.\n// protos[i] must point to an array of proto_lens[i] bytes\n// representing a binary-serialized TensorShapeProto.\nextern void TF_SetAttrTensorShapeProtoList(TF_NodeDescription* desc,\nconst char* attr_name,\nconst void* const* protos,\nconst int* proto_lens,\nint num_shapes, TF_Status* status);\n// This functions takes ownership of value (the\n// implementation will eventually call TF_DeleteTensor).\nextern void TF_SetAttrTensor(TF_NodeDescription desc, const char* attr_name,\nTF_Tensor* value, TF_Status* status);\n// This functions takes ownership of values[0]..values[num_values-1](the\n// implementation will eventually call TF_DeleteTensor on each).\nextern void TF_SetAttrTensorList(TF_NodeDescription* desc,\nconst char* attr_name,\nTF_Tensor* const* values, int num_values,\nTF_Status* status);\n// proto should point to a sequence of bytes of length proto_len\n// representing a binary serialization of an AttrValue protocol\n// buffer.\nextern void TF_SetAttrToAttrValueProto(TF_NodeDescription* desc,\nconst char* attr_name, const void* proto,\nsize_t proto_len, TF_Status* status);\n// If this function succeeds:\n//   * status is set to an OK value,\n//   * a TF_Node is added to the graph,\n//   * a non-null value pointing to the added node is returned --\n//     this value is valid until the underlying graph is deleted.\n// Otherwise:\n//   * *status is set to a non-OK value,\n//   * the graph is not modified,\n//   * a null value is returned.\n// In either case, it deletes desc.\nextern TF_Node TF_FinishNode(TF_NodeDescription* desc, TF_Status* status);\n// TF_Node functions.  Nodes are immutable once created, so these are all\n// query functions.\nextern const char* TF_NodeName(TF_Node* node);\nextern const char* TF_NodeOpType(TF_Node* node);\nextern const char* TF_NodeDevice(TF_Node* node);\nextern int TF_NodeNumOutputs(TF_Node* node);\nextern TF_DataType TF_NodeOutputType(TF_Port node_out);\nextern int TF_NodeOutputListLength(TF_Node* node, const char* arg_name,\nTF_Status* status);\nextern int TF_NodeNumInputs(TF_Node* node);\nextern TF_DataType TF_NodeInputType(TF_Port node_in);\nextern int TF_NodeInputListLength(TF_Node* node, const char* arg_name,\nTF_Status* status);\n// In this code:\n//   TF_Port producer = TF_NodeInput(consumer);\n// There is an edge from producer.node's output (given by\n// producer.index) to consumer.node's input (given by consumer.index).\nextern TF_Port TF_NodeInput(TF_Port node_in);\n// Get the number of current consumers of a node's output.  Note that\n// this number can change when new nodes are added to the graph.\nextern int TF_NodeOutputNumConsumers(TF_Port node_out);\n// Get list of all current consumers of a node's output.  consumers\n// must point to an array of length at least max_consumers (ideally\n// set to TF_NodeOutputNumConsumer(node_out)).  Beware that a\n// concurrent modification of the graph can increase the number of\n// consumers of a node.  Returns the number of output consumers\n// (should match TF_NodeOutputNumConsumers(node_out)).\nextern int TF_NodeOutputConsumers(TF_Port node_out, TF_Port* consumers,\nint max_consumers);\n// Get the number of control inputs to a node.\nextern int TF_NodeNumControlInputs(TF_Node* node);\n// Get list of all control inputs to a node.  control_inputs must\n// point to an array of length max_control_inputs (ideally set to\n// TF_NodeNumControlInputs(node)).  Returns the number of control\n// inputs (should match TF_NodeNumControlInputs(node)).\nextern int TF_NodeGetControlInputs(TF_Node* node, TF_Node** control_inputs,\nint max_control_inputs);\n// Get the number of nodes that have node as a control inputs.\n// Note that this number can change when new nodes are added to the\n// graph.\nextern int TF_NodeNumControlOutputs(TF_Node node);\n// Get the list of nodes that have node as a control input.\n// control_outputs must point to an array of length at least\n// max_control_outputs (ideally set to\n// TF_NodeNumControlOutputs(node)). Beware that a concurrent\n// modification of the graph can increase the number of control\n// outputs.  Returns the number of control outputs (should match\n// TF_NodeNumControlOutputs(node)).\nextern int TF_NodeGetControlOutputs(TF_Node node, TF_Node** control_outputs,\nint max_control_outputs);\n// Sets output_attr_value to the binary-serialized AttrValue proto\n// representation of the value of the attr_name attr of node.\nextern void TF_NodeGetAttrValueProto(TF_Node* node, const char* attr_name,\nTF_Buffer* output_attr_value,\nTF_Status* status);\n// Returns the node in the graph with node_name. Returns nullptr if\n// no node found.\nextern TF_Node* TF_GraphNodeByName(TF_Graph* graph, const char* node_name);\n// Iterate through the nodes of a graph.  To use:\n// size_t pos = 0;\n// TF_Node* node;\n// while ((node = TF_GraphNextNode(graph, &pos)) != nullptr) {\n//   DoSomethingWithNode(node);\n// }\nextern TF_Node* TF_GraphNextNode(TF_Graph* graph, size_t* pos);\n// Note: The following two functions may fail on very large protos in the\n// future.\nextern void TF_GraphToGraphDef(TF_Graph* graph, TF_Buffer* output_graph_def,\nTF_Status* status);\nextern void TF_NodeToNodeDef(TF_Node* node, TF_Buffer* output_node_def,\nTF_Status* status);\n// TODO(josh11b): Query attrs for a Node.\n// TODO(cwhipkey): Query shape for node outputs.\n// TODO(josh11b,mrry): Import GraphDef into TF_Graph.\n// TODO(andydavis): Function to add gradients to a graph.\n// TODO(josh11b): Register OpDef, available to all nodes added\n// to this graph.\n// The following two may both benefit from a subgraph-definition API\n// that re-uses most of the graph-definition API.\n// TODO(andydavis): Add functions to a graph.\n// TODO(yuanbyu): Add while loop to graph.\n// --------------------------------------------------------------------------\n// The new session API that uses TF_Graph*.  The intent is this will\n// replace the TF_ExtendGraph() API.\n// TODO(josh11b): Rename this TF_Session once we delete the old API.\ntypedef struct TF_SessionWithGraph TF_SessionWithGraph;\n// Return a new execution session with the associated graph, or NULL\n// on error.  graph must be a valid graph (not deleted or nullptr).\n// This function will prevent the graph from being deleted until\n// TF_DeleteSessionWithGraph() is called.  Does not take ownership of opts.\n// TODO(josh11b): Rename this TF_NewSession() once we delete the old API.\nextern TF_SessionWithGraph TF_NewSessionWithGraph(\nTF_Graph* graph, const TF_SessionOptions* opts, TF_Status* status);\n// Close a session. This contacts any other processes associated with this\n// session, if applicable. This may not be called after\n// TF_DeleteSessionWithGraph().\n// TODO(josh11b): Rename this TF_CloseSession() once we delete the old API.\nextern void TF_CloseSessionWithGraph(TF_SessionWithGraph_, TF_Status_ status);\n// Destroy a session object.  Even if error information is recorded in\n// status, this call discards all local resources associated with the\n// session.  The session may not be used during or after this call\n// (and the session drops its reference to the corresponding graph).\n// TODO(josh11b): Rename this TF_DeleteSession() once we delete the old API.\nextern void TF_DeleteSessionWithGraph(TF_SessionWithGraph, TF_Status* status);\n// See TF_Run() below.\nextern void TF_SessionRun(TF_SessionWithGraph* session,\n// RunOptions\nconst TF_Buffer* run_options,\n// Input tensors\nconst TF_Port* inputs, TF_Tensor* const* input_values,\nint ninputs,\n// Output tensors\nconst TF_Port* outputs, TF_Tensor** output_values,\nint noutputs,\n// Target nodes\nconst TF_Node* const* target_nodes, int ntargets,\n// RunMetadata\nTF_Buffer* run_metadata,\n// Output status\nTF_Status*);\n// See TF_PRunSetup() below.\nextern void TF_SessionPRunSetup(TF_SessionWithGraph_,\n// Input names\nconst TF_Port_ inputs, int ninputs,\n// Output names\nconst TF_Port* outputs, int noutputs,\n// Target nodes\nconst TF_Node* const* target_nodes,\nint ntargets,\n// Output handle\nconst char** handle,\n// Output status\nTF_Status*);\n// See TF_PRun() below.\nextern void TF_SessionPRun(TF_SessionWithGraph_, const char_ handle,\n// Input tensors\nconst TF_Port* inputs,\nTF_Tensor* const* input_values, int ninputs,\n// Output tensors\nconst TF_Port* outputs, TF_Tensor** output_values,\nint noutputs,\n// Target nodes\nconst TF_Node* const* target_nodes, int ntargets,\n// Output status\nTF_Status*);\n// --------------------------------------------------------------------------\n// The deprecated session API.  Please switch to the above instead of\n// TF_ExtendGraph().  TF_Session manages a single graph and execution.\ntypedef struct TF_Session TF_Session;\n// Return a new execution session, or NULL on error.\nextern TF_Session* TF_NewSession(const TF_SessionOptions_, TF_Status_ status);\n// Close a session.\nextern void TF_CloseSession(TF_Session_, TF_Status_ status);\n// Destroy a session.  Even if error information is recorded in status,\n// this call discards all resources associated with the session.\nextern void TF_DeleteSession(TF_Session, TF_Status* status);\n// Closes all existing sessions connected to the target specified in the\n// SessionOptions, and frees shared resources in containers on `target'.\n// If no containers are provided, all containers are cleared.\nextern void TF_Reset(const TF_SessionOptions* opt, const char** containers,\nint ncontainers, TF_Status* status);\n// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and\n// add the nodes in that GraphDef to the graph for the session.\nextern void TF_ExtendGraph(TF_Session_, const void_ proto, size_t proto_len,\nTF_Status*);\n// Run the graph associated with the session starting with the\n// supplied inputs (inputs[0,ninputs-1]).  Regardless of success or\n// failure, inputs[] become the property of the implementation (the\n// implementation will eventually call TF_DeleteTensor on each input).\n//\n// Any NULL and non-NULL value combinations for (run_options,\n// run_metadata) are valid.\n//\n//    - run_options may be NULL, in which case it will be ignored; or\n//      non-NULL, in which case it must point to a TF_Buffer containing the\n//      serialized representation of a RunOptions protocol buffer.\n//    - run_metadata may be NULL, in which case it will be ignored; or\n//      non-NULL, in which case it must point to an empty, freshly allocated\n//      TF_Buffer that may be updated to contain the serialized representation\n//      of a RunMetadata protocol buffer.\n//\n// The caller retains the ownership of run_options and/or run_metadata (when\n// not NULL) and should manually call TF_DeleteBuffer on them.\n//\n// On success, the tensors corresponding to output_names[0,noutputs-1]\n// are placed in outputs[], and these outputs[] become the property\n// of the caller (the caller must eventually call TF_DeleteTensor on\n// them).\n//\n// On failure, outputs[] contains NULLs.\nextern void TF_Run(TF_Session_,\n// RunOptions\nconst TF_Buffer_ run_options,\n// Input tensors\nconst char** input_names, TF_Tensor** inputs, int ninputs,\n// Output tensors\nconst char** output_tensor_names, TF_Tensor** outputs,\nint noutputs,\n// Target nodes\nconst char** target_node_names, int ntargets,\n// RunMetadata\nTF_Buffer* run_metadata,\n// Output status\nTF_Status*);\n// Set up the graph with the intended feeds and fetches for a sequence\n// of partial run calls.\n//\n// On success, returns a handle that is used for subsequent PRun calls.\n//\n// On failure, out_status contains a tensorflow::Status with an error\n// message.\n// NOTE: This is EXPERIMENTAL and subject to change.\nextern void TF_PRunSetup(TF_Session_,\n// Input names\nconst char_* input_names, int ninputs,\n// Output names\nconst char** output_tensor_names, int noutputs,\n// Target nodes\nconst char** target_node_names, int ntargets,\n// Output handle\nconst char** handle,\n// Output status\nTF_Status*);\n// Continue to run the graph with additional feeds and fetches. The\n// execution state is uniquely identified by the handle.\n// NOTE: This is EXPERIMENTAL and subject to change.\nextern void TF_PRun(TF_Session_, const char_ handle,\n// Input tensors\nconst char** input_names, TF_Tensor** inputs, int ninputs,\n// Output tensors\nconst char** output_tensor_names, TF_Tensor** outputs,\nint noutputs,\n// Target nodes\nconst char** target_node_names, int ntargets,\n// Output status\nTF_Status*);\n// --------------------------------------------------------------------------\n// Load plugins containing custom ops and kernels\n// TF_Library holds information about dynamically loaded TensorFlow plugins.\ntypedef struct TF_Library TF_Library;\n// Load the library specified by library_filename and register the ops and\n// kernels present in that library.\n//\n// Pass \"library_filename\" to a platform-specific mechanism for dynamically\n// loading a library. The rules for determining the exact location of the\n// library are platform-specific and are not documented here.\n// Expects the symbols \"RegisterOps\", \"RegisterKernels\", and \"GetOpList\", to be\n// defined in the library.\n//\n// On success, place OK in status and return the newly created library handle.\n// The caller owns the library handle.\n//\n// On failure, place an error status in status and return NULL.\nextern TF_Library* TF_LoadLibrary(const char* library_filename,\nTF_Status* status);\n// Get the OpList of OpDefs defined in the library pointed by lib_handle.\n//\n// Returns a TF_Buffer. The memory pointed to by the result is owned by\n// lib_handle. The data in the buffer will be the serialized OpList proto for\n// ops defined in the library.\nextern TF_Buffer TF_GetOpList(TF_Library* lib_handle);\n#ifdef __cplusplus\n} /* end extern \"C\" */\n#endif\n#endif  // TENSORFLOW_C_C_API_H_", "body": "c_api_test.cc src:\n#include \"./c_api.h\"\n#include<stdio.h>\n#include<string.h>\n\nint main(int argc, char _argv[]){\n  printf(\"---- -------start\");\n  TF_Status_ s = TF_NewStatus();\n  TF_SessionOptions\\* opt = TF_NewSessionOptions();\n  TF_Session\\* session = TF_NewSession(opt, s); \n  TF_DeleteSessionOptions(opt);\n  TF_CloseSession(session,s);\n  TF_DeleteStatus(s);\n\n  printf(\"---- -------end\");\n  return 1;\n}\n\nc_api.h file is within tensorflow/c directory :\n/\\* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n```\nhttp://www.apache.org/licenses/LICENSE-2.0\n```\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_C_C_API_H_\n#define TENSORFLOW_C_C_API_H_\n\n#include <stddef.h>\n#include <stdint.h>\n\n// --------------------------------------------------------------------------\n// C API for TensorFlow.\n//\n// The API leans towards simplicity and uniformity instead of convenience\n// since most usage will be by language specific wrappers.\n//\n// Conventions:\n// \\* We use the prefix TF_ for everything in the API.\n// \\* Objects are always passed around as pointers to opaque structs\n//   and these structs are allocated/deallocated via the API.\n// \\* TF_Status holds error information.  It is an object type\n//   and therefore is passed around as a pointer to an opaque\n//   struct as mentioned above.\n// \\* Every call that has a TF_Status\\* argument clears it on success\n//   and fills it with error info on failure.\n//\n// Questions left to address:\n// \\* Might at some point need a way for callers to provide their own Env.\n// \\* Maybe add TF_TensorShape that encapsulates dimension info.\n//\n// Design decisions made:\n// \\* Backing store for tensor memory has an associated deallocation\n//   function.  This deallocation function will point to client code\n//   for tensors populated by the client.  So the client can do things\n//   like shadowing a numpy array.\n// \\* We do not provide TF_OK since it is not strictly necessary and we\n//   are not optimizing for convenience.\n// \\* We make assumption that one session has one graph.  This should be\n//   fine since we have the ability to run sub-graphs.\n// \\* We could allow NULL for some arguments (e.g., NULL options arg).\n//   However since convenience is not a primary goal, we don't do this.\n// \\* Devices are not in this API.  Instead, they are created/used internally\n//   and the API just provides high level controls over the number of\n//   devices of each type.\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n// --------------------------------------------------------------------------\n// TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.\n// The enum values here are identical to corresponding values in types.proto.\ntypedef enum {\n  TF_FLOAT = 1,\n  TF_DOUBLE = 2,\n  TF_INT32 = 3,  // Int32 tensors are always in 'host' memory.\n  TF_UINT8 = 4,\n  TF_INT16 = 5,\n  TF_INT8 = 6,\n  TF_STRING = 7,\n  TF_COMPLEX64 = 8,  // Single-precision complex\n  TF_COMPLEX = 8,    // Old identifier kept for API backwards compatibility\n  TF_INT64 = 9,\n  TF_BOOL = 10,\n  TF_QINT8 = 11,     // Quantized int8\n  TF_QUINT8 = 12,    // Quantized uint8\n  TF_QINT32 = 13,    // Quantized int32\n  TF_BFLOAT16 = 14,  // Float32 truncated to 16 bits.  Only for cast ops.\n  TF_QINT16 = 15,    // Quantized int16\n  TF_QUINT16 = 16,   // Quantized uint16\n  TF_UINT16 = 17,\n  TF_COMPLEX128 = 18,  // Double-precision complex\n  TF_HALF = 19,\n} TF_DataType;\n\n// --------------------------------------------------------------------------\n// TF_Code holds an error code.  The enum values here are identical to\n// corresponding values in error_codes.proto.\ntypedef enum {\n  TF_OK = 0,\n  TF_CANCELLED = 1,\n  TF_UNKNOWN = 2,\n  TF_INVALID_ARGUMENT = 3,\n  TF_DEADLINE_EXCEEDED = 4,\n  TF_NOT_FOUND = 5,\n  TF_ALREADY_EXISTS = 6,\n  TF_PERMISSION_DENIED = 7,\n  TF_UNAUTHENTICATED = 16,\n  TF_RESOURCE_EXHAUSTED = 8,\n  TF_FAILED_PRECONDITION = 9,\n  TF_ABORTED = 10,\n  TF_OUT_OF_RANGE = 11,\n  TF_UNIMPLEMENTED = 12,\n  TF_INTERNAL = 13,\n  TF_UNAVAILABLE = 14,\n  TF_DATA_LOSS = 15,\n} TF_Code;\n\n// --------------------------------------------------------------------------\n// TF_Status holds error information.  It either has an OK code, or\n// else an error code with an associated error message.\ntypedef struct TF_Status TF_Status;\n\n// Return a new status object.\nextern TF_Status\\* TF_NewStatus();\n\n// Delete a previously created status object.\nextern void TF_DeleteStatus(TF_Status*);\n\n// Record <code, msg> in _s.  Any previous information is lost.\n// A common use is to clear a status: TF_SetStatus(s, TF_OK, \"\");\nextern void TF_SetStatus(TF_Status_ s, TF_Code code, const char\\* msg);\n\n// Return the code record in _s.\nextern TF_Code TF_GetCode(const TF_Status_ s);\n\n// Return a pointer to the (null-terminated) error message in _s.  The\n// return value points to memory that is only usable until the next\n// mutation to *s.  Always returns an empty string if TF_GetCode(s) is\n// TF_OK.\nextern const char_ TF_Message(const TF_Status\\* s);\n\n// --------------------------------------------------------------------------\n// TF_Buffer holds a pointer to a block of data and its associated length.\n// Typically, the data consists of a serialized protocol buffer, but other data\n// may also be held in a buffer.\n//\n// By default, TF_Buffer itself does not do any memory management of the\n// pointed-to block.  If need be, users of this struct should specify how to\n// deallocate the block by setting the `data_deallocator` function pointer.\ntypedef struct {\n  const void\\* data;\n  size_t length;\n  void (_data_deallocator)(void_ data, size_t length);\n} TF_Buffer;\n\n// Makes a copy of the input and sets an appropriate deallocator.  Useful for\n// passing in read-only, input protobufs.\nextern TF_Buffer\\* TF_NewBufferFromString(const void\\* proto, size_t proto_len);\n\n// Useful for passing _out_ a protobuf.\nextern TF_Buffer\\* TF_NewBuffer();\n\nextern void TF_DeleteBuffer(TF_Buffer*);\n\nextern TF_Buffer TF_GetBuffer(TF_Buffer\\* buffer);\n\n// --------------------------------------------------------------------------\n// TF_Tensor holds a multi-dimensional array of elements of a single data type.\n// For all types other than TF_STRING, the data buffer stores elements\n// in row major order.  E.g. if data is treated as a vector of TF_DataType:\n//\n//   element 0:   index (0, ..., 0)\n//   element 1:   index (0, ..., 1)\n//   ...\n//\n// The format for TF_STRING tensors is:\n//   start_offset: array[uint64]\n//   data:         byte[...]\n//\n//   String length is encoded (varint?) starting at data[start_offset[i]]\n//   String contents follow immediately after string length.\n\ntypedef struct TF_Tensor TF_Tensor;\n\n// Return a new tensor that holds the bytes data[0,len-1].\n//\n// The data will be deallocated by a subsequent call to TF_DeleteTensor via:\n//      (_deallocator)(data, len, deallocator_arg)\n// Clients must provide a custom deallocator function so they can pass in\n// memory managed by something like numpy.\nextern TF_Tensor_ TF_NewTensor(TF_DataType, const int64_t\\* dims, int num_dims,\n                               void\\* data, size_t len,\n                               void (_deallocator)(void_ data, size_t len,\n                                                   void\\* arg),\n                               void\\* deallocator_arg);\n\n// Destroy a tensor.\nextern void TF_DeleteTensor(TF_Tensor*);\n\n// Return the type of a tensor element.\nextern TF_DataType TF_TensorType(const TF_Tensor*);\n\n// Return the number of dimensions that the tensor has.\nextern int TF_NumDims(const TF_Tensor*);\n\n// Return the length of the tensor in the \"dim_index\" dimension.\n// REQUIRES: 0 <= dim_index < TF_NumDims(tensor)\nextern int64_t TF_Dim(const TF_Tensor\\* tensor, int dim_index);\n\n// Return the size of the underlying data in bytes.\nextern size_t TF_TensorByteSize(const TF_Tensor*);\n\n// Return a pointer to the underlying data buffer.\nextern void\\* TF_TensorData(const TF_Tensor*);\n\n// --------------------------------------------------------------------------\n// TF_SessionOptions holds options that can be passed during session creation.\ntypedef struct TF_SessionOptions TF_SessionOptions;\n\n// Return a new options object.\nextern TF_SessionOptions\\* TF_NewSessionOptions();\n\n// Set the target in TF_SessionOptions.options.\n// target can be empty, a single entry, or a comma separated list of entries.\n// Each entry is in one of the following formats :\n// \"local\"\n// ip:port\n// host:port\nextern void TF_SetTarget(TF_SessionOptions\\* options, const char\\* target);\n\n// Set the config in TF_SessionOptions.options.\n// config should be a serialized tensorflow.ConfigProto proto.\n// If config was not parsed successfully as a ConfigProto, record the\n// error information in _status.\nextern void TF_SetConfig(TF_SessionOptions_ options, const void\\* proto,\n                         size_t proto_len, TF_Status\\* status);\n\n// Destroy an options object.\nextern void TF_DeleteSessionOptions(TF_SessionOptions*);\n\n// TODO(jeff,sanjay):\n// - export functions to set Config fields\n\n// --------------------------------------------------------------------------\n// The new graph construction API, still under development.\n\n// Represents a computation graph.  Graphs may be shared between sessions.\n// Graphs are thread-safe when used as directed below.\ntypedef struct TF_Graph TF_Graph;\n\n// Return a new graph object.\nextern TF_Graph\\* TF_NewGraph();\n\n// Destroy an options object.  Graph will be deleted once no more\n// TFSessionWithGraph's are referencing it.\nextern void TF_DeleteGraph(TF_Graph*);\n\n// Node being built. The underlying graph must outlive this.\ntypedef struct TF_NodeDescription TF_NodeDescription;\n\n// Node that has been added to the graph. Valid until the graph is\n// deleted -- in particular adding a new node to the graph does not\n// invalidate old TF_Node\\* pointers.\ntypedef struct TF_Node TF_Node;\n\n// Represents a specific input or output of a node, e.g. to specify the\n// specific output to pass as an input to an op.\ntypedef struct TF_Port {\n  TF_Node\\* node;\n  int index;  // Specifies the index of the input or output within node.\n} TF_Port;\n\n// Node will only be added to _graph when TF_FinishNode() is called\n// (assuming TF_FinishNode() does not return an error).  *graph must\n// not be deleted until after TF_FinishNode() is called.\nextern TF_NodeDescription_ TF_NewNode(TF_Graph\\* graph, const char\\* op_type,\n                                      const char\\* node_name);\n\n// Specify the device for `desc`.  Defaults to empty, meaning unconstrained.\nextern void TF_SetDevice(TF_NodeDescription\\* desc, const char\\* device);\n\n// The calls to TF_AddInput and TF_AddInputList must match (in number,\n// order, and type) the op declaration.  For example, the \"Concat\" op\n// has registration:\n//   REGISTER_OP(\"Concat\")\n//       .Input(\"concat_dim: int32\")\n//       .Input(\"values: N \\* T\")\n//       .Output(\"output: T\")\n//       .Attr(\"N: int >= 2\")\n//       .Attr(\"T: type\");\n// that defines two inputs, \"concat_dim\" and \"values\" (in that order).\n// You must use TF_AddInput() for the first input (since it takes a\n// single tensor), and TF_AddInputList() for the second input (since\n// it takes a list, even if you were to pass a list with a single\n// tensor), as in:\n//   TF_NodeDescription\\* desc = TF_NewNode(graph, \"Concat\", \"c\");\n//   TF_Port concat_dim_input = {...};\n//   TF_AddInput(desc, concat_dim_input);\n//   TF_Port values_inputs[5] = {{...}, ..., {...}};\n//   TF_AddInputList(desc, 5, values_inputs);\n\n// For inputs that take a single tensor.\nextern void TF_AddInput(TF_NodeDescription\\* desc, TF_Port input);\n\n// For inputs that take a list of tensors.\n// inputs must point to TF_Port[num_inputs].\nextern void TF_AddInputList(TF_NodeDescription\\* desc, const TF_Port\\* inputs,\n                            int num_inputs);\n\n// Call once per control input to `desc`.\nextern void TF_AddControlInput(TF_NodeDescription\\* desc, TF_Node\\* input);\n\n// Call some TF_SetAttr*() function for every attr that is not\n// inferred from an input and doesn't have a default value you wish to\n// keep.\n\n// `value` must point to a string of length `length` bytes.\nextern void TF_SetAttrString(TF_NodeDescription\\* desc, const char\\* attr_name,\n                             const void\\* value, int length);\n// `values` and `lengths` both must have lengths `num_values`.\n// `values[i]` must point to a string of length `lengths[i]` bytes.\nextern void TF_SetAttrStringList(TF_NodeDescription\\* desc,\n                                 const char\\* attr_name,\n                                 const void\\* const\\* values, const int\\* lengths,\n                                 int num_values);\nextern void TF_SetAttrInt(TF_NodeDescription\\* desc, const char\\* attr_name,\n                          int64_t value);\nextern void TF_SetAttrIntList(TF_NodeDescription\\* desc, const char\\* attr_name,\n                              const int64_t\\* values, int num_values);\nextern void TF_SetAttrFloat(TF_NodeDescription\\* desc, const char\\* attr_name,\n                            float value);\nextern void TF_SetAttrFloatList(TF_NodeDescription\\* desc, const char\\* attr_name,\n                                const float\\* values, int num_values);\nextern void TF_SetAttrBool(TF_NodeDescription\\* desc, const char\\* attr_name,\n                           unsigned char value);\nextern void TF_SetAttrBoolList(TF_NodeDescription\\* desc, const char\\* attr_name,\n                               const unsigned char\\* values, int num_values);\nextern void TF_SetAttrType(TF_NodeDescription\\* desc, const char\\* attr_name,\n                           TF_DataType value);\nextern void TF_SetAttrTypeList(TF_NodeDescription\\* desc, const char\\* attr_name,\n                               const TF_DataType\\* values, int num_values);\n\n// Set `num_dims` to -1 to represent \"unknown rank\".  Otherwise,\n// `dims` points to an array of length `num_dims`.  `dims[i]` must be\n// >= -1, with -1 meaning \"unknown dimension\".\nextern void TF_SetAttrShape(TF_NodeDescription\\* desc, const char\\* attr_name,\n                            const int64_t\\* dims, int num_dims);\n// `dims` and `num_dims` must point to arrays of length `num_shapes`.\n// Set `num_dims[i]` to -1 to represent \"unknown rank\".  Otherwise,\n// `dims[i]` points to an array of length `num_dims[i]`.  `dims[i][j]`\n// must be >= -1, with -1 meaning \"unknown dimension\".\nextern void TF_SetAttrShapeList(TF_NodeDescription\\* desc, const char\\* attr_name,\n                                const int64_t\\* const\\* dims, const int\\* num_dims,\n                                int num_shapes);\n// `proto` must point to an array of `proto_len` bytes representing a\n// binary-serialized TensorShapeProto.\nextern void TF_SetAttrTensorShapeProto(TF_NodeDescription\\* desc,\n                                       const char\\* attr_name, void\\* proto,\n                                       int proto_len, TF_Status\\* status);\n// `protos` and `proto_lens` must point to arrays of length `num_shapes`.\n// `protos[i]` must point to an array of `proto_lens[i]` bytes\n// representing a binary-serialized TensorShapeProto.\nextern void TF_SetAttrTensorShapeProtoList(TF_NodeDescription\\* desc,\n                                           const char\\* attr_name,\n                                           const void\\* const\\* protos,\n                                           const int\\* proto_lens,\n                                           int num_shapes, TF_Status\\* status);\n\n// This functions takes ownership of _value (the\n// implementation will eventually call TF_DeleteTensor).\nextern void TF_SetAttrTensor(TF_NodeDescription_ desc, const char\\* attr_name,\n                             TF_Tensor\\* value, TF_Status\\* status);\n// This functions takes ownership of values[0]..values[num_values-1](the\n// implementation will eventually call TF_DeleteTensor on each).\nextern void TF_SetAttrTensorList(TF_NodeDescription\\* desc,\n                                 const char\\* attr_name,\n                                 TF_Tensor\\* const\\* values, int num_values,\n                                 TF_Status\\* status);\n\n// `proto` should point to a sequence of bytes of length `proto_len`\n// representing a binary serialization of an AttrValue protocol\n// buffer.\nextern void TF_SetAttrToAttrValueProto(TF_NodeDescription\\* desc,\n                                       const char\\* attr_name, const void\\* proto,\n                                       size_t proto_len, TF_Status\\* status);\n\n// If this function succeeds:\n//   \\* _status is set to an OK value,\n//   \\* a TF_Node is added to the graph,\n//   \\* a non-null value pointing to the added node is returned --\n//     this value is valid until the underlying graph is deleted.\n// Otherwise:\n//   \\* *status is set to a non-OK value,\n//   \\* the graph is not modified,\n//   \\* a null value is returned.\n// In either case, it deletes `desc`.\nextern TF_Node_ TF_FinishNode(TF_NodeDescription\\* desc, TF_Status\\* status);\n\n// TF_Node functions.  Nodes are immutable once created, so these are all\n// query functions.\n\nextern const char\\* TF_NodeName(TF_Node\\* node);\nextern const char\\* TF_NodeOpType(TF_Node\\* node);\nextern const char\\* TF_NodeDevice(TF_Node\\* node);\n\nextern int TF_NodeNumOutputs(TF_Node\\* node);\nextern TF_DataType TF_NodeOutputType(TF_Port node_out);\nextern int TF_NodeOutputListLength(TF_Node\\* node, const char\\* arg_name,\n                                   TF_Status\\* status);\n\nextern int TF_NodeNumInputs(TF_Node\\* node);\nextern TF_DataType TF_NodeInputType(TF_Port node_in);\nextern int TF_NodeInputListLength(TF_Node\\* node, const char\\* arg_name,\n                                  TF_Status\\* status);\n\n// In this code:\n//   TF_Port producer = TF_NodeInput(consumer);\n// There is an edge from producer.node's output (given by\n// producer.index) to consumer.node's input (given by consumer.index).\nextern TF_Port TF_NodeInput(TF_Port node_in);\n\n// Get the number of current consumers of a node's output.  Note that\n// this number can change when new nodes are added to the graph.\nextern int TF_NodeOutputNumConsumers(TF_Port node_out);\n\n// Get list of all current consumers of a node's output.  consumers\n// must point to an array of length at least max_consumers (ideally\n// set to TF_NodeOutputNumConsumer(node_out)).  Beware that a\n// concurrent modification of the graph can increase the number of\n// consumers of a node.  Returns the number of output consumers\n// (should match TF_NodeOutputNumConsumers(node_out)).\nextern int TF_NodeOutputConsumers(TF_Port node_out, TF_Port\\* consumers,\n                                  int max_consumers);\n\n// Get the number of control inputs to a node.\nextern int TF_NodeNumControlInputs(TF_Node\\* node);\n\n// Get list of all control inputs to a node.  control_inputs must\n// point to an array of length max_control_inputs (ideally set to\n// TF_NodeNumControlInputs(node)).  Returns the number of control\n// inputs (should match TF_NodeNumControlInputs(node)).\nextern int TF_NodeGetControlInputs(TF_Node\\* node, TF_Node*\\* control_inputs,\n                                   int max_control_inputs);\n\n// Get the number of nodes that have _node as a control inputs.\n// Note that this number can change when new nodes are added to the\n// graph.\nextern int TF_NodeNumControlOutputs(TF_Node_ node);\n\n// Get the list of nodes that have _node as a control input.\n// control_outputs must point to an array of length at least\n// max_control_outputs (ideally set to\n// TF_NodeNumControlOutputs(node)). Beware that a concurrent\n// modification of the graph can increase the number of control\n// outputs.  Returns the number of control outputs (should match\n// TF_NodeNumControlOutputs(node)).\nextern int TF_NodeGetControlOutputs(TF_Node_ node, TF_Node*\\* control_outputs,\n                                    int max_control_outputs);\n\n// Sets `output_attr_value` to the binary-serialized AttrValue proto\n// representation of the value of the `attr_name` attr of `node`.\nextern void TF_NodeGetAttrValueProto(TF_Node\\* node, const char\\* attr_name,\n                                     TF_Buffer\\* output_attr_value,\n                                     TF_Status\\* status);\n\n// Returns the node in the graph with `node_name`. Returns nullptr if\n// no node found.\nextern TF_Node\\* TF_GraphNodeByName(TF_Graph\\* graph, const char\\* node_name);\n\n// Iterate through the nodes of a graph.  To use:\n// size_t pos = 0;\n// TF_Node\\* node;\n// while ((node = TF_GraphNextNode(graph, &pos)) != nullptr) {\n//   DoSomethingWithNode(node);\n// }\nextern TF_Node\\* TF_GraphNextNode(TF_Graph\\* graph, size_t\\* pos);\n\n// Note: The following two functions may fail on very large protos in the\n// future.\n\nextern void TF_GraphToGraphDef(TF_Graph\\* graph, TF_Buffer\\* output_graph_def,\n                               TF_Status\\* status);\n\nextern void TF_NodeToNodeDef(TF_Node\\* node, TF_Buffer\\* output_node_def,\n                             TF_Status\\* status);\n\n// TODO(josh11b): Query attrs for a Node.\n\n// TODO(cwhipkey): Query shape for node outputs.\n\n// TODO(josh11b,mrry): Import GraphDef into TF_Graph.\n\n// TODO(andydavis): Function to add gradients to a graph.\n\n// TODO(josh11b): Register OpDef, available to all nodes added\n// to this graph.\n\n// The following two may both benefit from a subgraph-definition API\n// that re-uses most of the graph-definition API.\n// TODO(andydavis): Add functions to a graph.\n// TODO(yuanbyu): Add while loop to graph.\n\n// --------------------------------------------------------------------------\n// The new session API that uses TF_Graph*.  The intent is this will\n// replace the TF_ExtendGraph() API.\n\n// TODO(josh11b): Rename this TF_Session once we delete the old API.\ntypedef struct TF_SessionWithGraph TF_SessionWithGraph;\n\n// Return a new execution session with the associated graph, or NULL\n// on error.  _graph must be a valid graph (not deleted or nullptr).\n// This function will prevent the graph from being deleted until\n// TF_DeleteSessionWithGraph() is called.  Does not take ownership of opts.\n// TODO(josh11b): Rename this TF_NewSession() once we delete the old API.\nextern TF_SessionWithGraph_ TF_NewSessionWithGraph(\n    TF_Graph\\* graph, const TF_SessionOptions\\* opts, TF_Status\\* status);\n\n// Close a session. This contacts any other processes associated with this\n// session, if applicable. This may not be called after\n// TF_DeleteSessionWithGraph().\n// TODO(josh11b): Rename this TF_CloseSession() once we delete the old API.\nextern void TF_CloseSessionWithGraph(TF_SessionWithGraph_, TF_Status_ status);\n\n// Destroy a session object.  Even if error information is recorded in\n// _status, this call discards all local resources associated with the\n// session.  The session may not be used during or after this call\n// (and the session drops its reference to the corresponding graph).\n// TODO(josh11b): Rename this TF_DeleteSession() once we delete the old API.\nextern void TF_DeleteSessionWithGraph(TF_SessionWithGraph_, TF_Status\\* status);\n\n// See TF_Run() below.\nextern void TF_SessionRun(TF_SessionWithGraph\\* session,\n                          // RunOptions\n                          const TF_Buffer\\* run_options,\n                          // Input tensors\n                          const TF_Port\\* inputs, TF_Tensor\\* const\\* input_values,\n                          int ninputs,\n                          // Output tensors\n                          const TF_Port\\* outputs, TF_Tensor*\\* output_values,\n                          int noutputs,\n                          // Target nodes\n                          const TF_Node\\* const\\* target_nodes, int ntargets,\n                          // RunMetadata\n                          TF_Buffer\\* run_metadata,\n                          // Output status\n                          TF_Status*);\n\n// See TF_PRunSetup() below.\nextern void TF_SessionPRunSetup(TF_SessionWithGraph_,\n                                // Input names\n                                const TF_Port_ inputs, int ninputs,\n                                // Output names\n                                const TF_Port\\* outputs, int noutputs,\n                                // Target nodes\n                                const TF_Node\\* const\\* target_nodes,\n                                int ntargets,\n                                // Output handle\n                                const char*\\* handle,\n                                // Output status\n                                TF_Status*);\n\n// See TF_PRun() below.\nextern void TF_SessionPRun(TF_SessionWithGraph_, const char_ handle,\n                           // Input tensors\n                           const TF_Port\\* inputs,\n                           TF_Tensor\\* const\\* input_values, int ninputs,\n                           // Output tensors\n                           const TF_Port\\* outputs, TF_Tensor*\\* output_values,\n                           int noutputs,\n                           // Target nodes\n                           const TF_Node\\* const\\* target_nodes, int ntargets,\n                           // Output status\n                           TF_Status*);\n\n// --------------------------------------------------------------------------\n// The deprecated session API.  Please switch to the above instead of\n// TF_ExtendGraph().  TF_Session manages a single graph and execution.\n\ntypedef struct TF_Session TF_Session;\n\n// Return a new execution session, or NULL on error.\nextern TF_Session\\* TF_NewSession(const TF_SessionOptions_, TF_Status_ status);\n\n// Close a session.\nextern void TF_CloseSession(TF_Session_, TF_Status_ status);\n\n// Destroy a session.  Even if error information is recorded in _status,\n// this call discards all resources associated with the session.\nextern void TF_DeleteSession(TF_Session_, TF_Status\\* status);\n\n// Closes all existing sessions connected to the `target` specified in the\n// `SessionOptions`, and frees shared resources in `containers` on `target'.\n// If no containers are provided, all containers are cleared.\nextern void TF_Reset(const TF_SessionOptions\\* opt, const char*\\* containers,\n                     int ncontainers, TF_Status\\* status);\n\n// Treat the bytes proto[0,proto_len-1] as a serialized GraphDef and\n// add the nodes in that GraphDef to the graph for the session.\nextern void TF_ExtendGraph(TF_Session_, const void_ proto, size_t proto_len,\n                           TF_Status*);\n\n// Run the graph associated with the session starting with the\n// supplied inputs (inputs[0,ninputs-1]).  Regardless of success or\n// failure, inputs[] become the property of the implementation (the\n// implementation will eventually call TF_DeleteTensor on each input).\n//\n// Any NULL and non-NULL value combinations for (`run_options`,\n// `run_metadata`) are valid.\n//\n//    - `run_options` may be NULL, in which case it will be ignored; or\n//      non-NULL, in which case it must point to a `TF_Buffer` containing the\n//      serialized representation of a `RunOptions` protocol buffer.\n//    - `run_metadata` may be NULL, in which case it will be ignored; or\n//      non-NULL, in which case it must point to an empty, freshly allocated\n//      `TF_Buffer` that may be updated to contain the serialized representation\n//      of a `RunMetadata` protocol buffer.\n//\n// The caller retains the ownership of `run_options` and/or `run_metadata` (when\n// not NULL) and should manually call TF_DeleteBuffer on them.\n//\n// On success, the tensors corresponding to output_names[0,noutputs-1]\n// are placed in outputs[], and these outputs[] become the property\n// of the caller (the caller must eventually call TF_DeleteTensor on\n// them).\n//\n// On failure, outputs[] contains NULLs.\nextern void TF_Run(TF_Session_,\n                   // RunOptions\n                   const TF_Buffer_ run_options,\n                   // Input tensors\n                   const char*\\* input_names, TF_Tensor*\\* inputs, int ninputs,\n                   // Output tensors\n                   const char*\\* output_tensor_names, TF_Tensor*\\* outputs,\n                   int noutputs,\n                   // Target nodes\n                   const char*\\* target_node_names, int ntargets,\n                   // RunMetadata\n                   TF_Buffer\\* run_metadata,\n                   // Output status\n                   TF_Status*);\n\n// Set up the graph with the intended feeds and fetches for a sequence\n// of partial run calls.\n//\n// On success, returns a handle that is used for subsequent PRun calls.\n//\n// On failure, out_status contains a tensorflow::Status with an error\n// message.\n// NOTE: This is EXPERIMENTAL and subject to change.\nextern void TF_PRunSetup(TF_Session_,\n                         // Input names\n                         const char_\\* input_names, int ninputs,\n                         // Output names\n                         const char*\\* output_tensor_names, int noutputs,\n                         // Target nodes\n                         const char*\\* target_node_names, int ntargets,\n                         // Output handle\n                         const char*\\* handle,\n                         // Output status\n                         TF_Status*);\n\n// Continue to run the graph with additional feeds and fetches. The\n// execution state is uniquely identified by the handle.\n// NOTE: This is EXPERIMENTAL and subject to change.\nextern void TF_PRun(TF_Session_, const char_ handle,\n                    // Input tensors\n                    const char*\\* input_names, TF_Tensor*\\* inputs, int ninputs,\n                    // Output tensors\n                    const char*\\* output_tensor_names, TF_Tensor*\\* outputs,\n                    int noutputs,\n                    // Target nodes\n                    const char*\\* target_node_names, int ntargets,\n                    // Output status\n                    TF_Status*);\n\n// --------------------------------------------------------------------------\n// Load plugins containing custom ops and kernels\n\n// TF_Library holds information about dynamically loaded TensorFlow plugins.\ntypedef struct TF_Library TF_Library;\n\n// Load the library specified by library_filename and register the ops and\n// kernels present in that library.\n//\n// Pass \"library_filename\" to a platform-specific mechanism for dynamically\n// loading a library. The rules for determining the exact location of the\n// library are platform-specific and are not documented here.\n// Expects the symbols \"RegisterOps\", \"RegisterKernels\", and \"GetOpList\", to be\n// defined in the library.\n//\n// On success, place OK in status and return the newly created library handle.\n// The caller owns the library handle.\n//\n// On failure, place an error status in status and return NULL.\nextern TF_Library\\* TF_LoadLibrary(const char\\* library_filename,\n                                  TF_Status\\* status);\n\n// Get the OpList of OpDefs defined in the library pointed by lib_handle.\n//\n// Returns a TF_Buffer. The memory pointed to by the result is owned by\n// lib_handle. The data in the buffer will be the serialized OpList proto for\n// ops defined in the library.\nextern TF_Buffer TF_GetOpList(TF_Library\\* lib_handle);\n\n#ifdef __cplusplus\n} /\\* end extern \"C\" */\n#endif\n\n#endif  // TENSORFLOW_C_C_API_H_\n"}