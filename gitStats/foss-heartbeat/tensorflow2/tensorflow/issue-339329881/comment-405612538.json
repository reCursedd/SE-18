{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/405612538", "html_url": "https://github.com/tensorflow/tensorflow/issues/20639#issuecomment-405612538", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20639", "id": 405612538, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTYxMjUzOA==", "user": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-17T14:57:16Z", "updated_at": "2018-07-17T14:57:16Z", "author_association": "MEMBER", "body_html": "<p>No, it's about TF's execution model. You could theoretically see this result with a single thread.</p>\n<p>Here's the issue: TF will execute an operation once its inputs are ready, which may not correspond to the order operations are defined in your program. If the inputs to multiple ops are ready, there are no guarantees about which one will run first.</p>\n<p>In the case of while_loop, you can imagine the loop is unrolled:</p>\n<div class=\"highlight highlight-source-python\"><pre>i1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> iteration 1</span>\nx1 <span class=\"pl-k\">=</span> a1[i1<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\ny1 <span class=\"pl-k\">=</span> a1[i1<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>]\nz1 <span class=\"pl-k\">=</span> tf.add(x1,y1)\nop1 <span class=\"pl-k\">=</span> a1[i1].assign( tf.add(x1,y1) )\nincrement1 <span class=\"pl-k\">=</span> tf.add(i1, <span class=\"pl-c1\">1</span>)\ni2 <span class=\"pl-k\">=</span> increment1\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> iteration 2</span>\nx2 <span class=\"pl-k\">=</span> a1[i2<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\ny2 <span class=\"pl-k\">=</span> a1[i2<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>]\nz2 <span class=\"pl-k\">=</span> tf.add(x2,y2)\nop2 <span class=\"pl-k\">=</span> a1[i2].assign( tf.add(x2,y2) )\nincrement2 <span class=\"pl-k\">=</span> tf.add(i2, <span class=\"pl-c1\">1</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>Given that the only data input to iteration 2 is <code>i2</code>, which ultimately only depends on <code>i1</code>, TF can actually start executing iteration 2 before iteration 1 completes. This means it might run <code>op2</code> before <code>op1</code> is run, which is what causes the wrong results in your original example. Adding the control dependency forces <code>op{i}</code> to complete before <code>increment{i}</code> can run, which forces all the assign ops to run in the correct order.</p>\n<p>The root issue is that the assign ops have visible side effects (i.e. writing to a1, which is then read in subsequent operations), but the execution doesn't take this into account; it only looks at the direct inputs and control deps.</p>\n<p>This is obviously super confusing and error-prone, so we're working on coming up with better execution semantics. One option is to enable <a href=\"https://www.tensorflow.org/guide/eager\" rel=\"nofollow\">eager exeuction</a>, which does run everything in program order.</p>\n<p>Another option is to use <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/eager/defun\" rel=\"nofollow\">tf.contrib.eager.defun</a>, although this is still being actively developed. This creates a graph, but automatically makes sure that ops with side effects (like variable assignment) happen in the order they're defined. This way you don't have to worry about manually adding control dependencies.</p>\n<p>Sorry this is so long, I hope it helps. I'm gonna close this issue since it's not actually a concurrency bug,  but feel free to comment if something is still confusing or you have more questions.</p>", "body_text": "No, it's about TF's execution model. You could theoretically see this result with a single thread.\nHere's the issue: TF will execute an operation once its inputs are ready, which may not correspond to the order operations are defined in your program. If the inputs to multiple ops are ready, there are no guarantees about which one will run first.\nIn the case of while_loop, you can imagine the loop is unrolled:\ni1 = 2\n# iteration 1\nx1 = a1[i1-1]\ny1 = a1[i1-2]\nz1 = tf.add(x1,y1)\nop1 = a1[i1].assign( tf.add(x1,y1) )\nincrement1 = tf.add(i1, 1)\ni2 = increment1\n# iteration 2\nx2 = a1[i2-1]\ny2 = a1[i2-2]\nz2 = tf.add(x2,y2)\nop2 = a1[i2].assign( tf.add(x2,y2) )\nincrement2 = tf.add(i2, 1)\n# ...\nGiven that the only data input to iteration 2 is i2, which ultimately only depends on i1, TF can actually start executing iteration 2 before iteration 1 completes. This means it might run op2 before op1 is run, which is what causes the wrong results in your original example. Adding the control dependency forces op{i} to complete before increment{i} can run, which forces all the assign ops to run in the correct order.\nThe root issue is that the assign ops have visible side effects (i.e. writing to a1, which is then read in subsequent operations), but the execution doesn't take this into account; it only looks at the direct inputs and control deps.\nThis is obviously super confusing and error-prone, so we're working on coming up with better execution semantics. One option is to enable eager exeuction, which does run everything in program order.\nAnother option is to use tf.contrib.eager.defun, although this is still being actively developed. This creates a graph, but automatically makes sure that ops with side effects (like variable assignment) happen in the order they're defined. This way you don't have to worry about manually adding control dependencies.\nSorry this is so long, I hope it helps. I'm gonna close this issue since it's not actually a concurrency bug,  but feel free to comment if something is still confusing or you have more questions.", "body": "No, it's about TF's execution model. You could theoretically see this result with a single thread.\r\n\r\nHere's the issue: TF will execute an operation once its inputs are ready, which may not correspond to the order operations are defined in your program. If the inputs to multiple ops are ready, there are no guarantees about which one will run first.\r\n\r\nIn the case of while_loop, you can imagine the loop is unrolled:\r\n```python\r\ni1 = 2\r\n# iteration 1\r\nx1 = a1[i1-1]\r\ny1 = a1[i1-2]\r\nz1 = tf.add(x1,y1)\r\nop1 = a1[i1].assign( tf.add(x1,y1) )\r\nincrement1 = tf.add(i1, 1)\r\ni2 = increment1\r\n# iteration 2\r\nx2 = a1[i2-1]\r\ny2 = a1[i2-2]\r\nz2 = tf.add(x2,y2)\r\nop2 = a1[i2].assign( tf.add(x2,y2) )\r\nincrement2 = tf.add(i2, 1)\r\n# ...\r\n```\r\nGiven that the only data input to iteration 2 is `i2`, which ultimately only depends on `i1`, TF can actually start executing iteration 2 before iteration 1 completes. This means it might run `op2` before `op1` is run, which is what causes the wrong results in your original example. Adding the control dependency forces `op{i}` to complete before `increment{i}` can run, which forces all the assign ops to run in the correct order.\r\n\r\nThe root issue is that the assign ops have visible side effects (i.e. writing to a1, which is then read in subsequent operations), but the execution doesn't take this into account; it only looks at the direct inputs and control deps.\r\n\r\nThis is obviously super confusing and error-prone, so we're working on coming up with better execution semantics. One option is to enable [eager exeuction](https://www.tensorflow.org/guide/eager), which does run everything in program order.\r\n\r\nAnother option is to use [tf.contrib.eager.defun](https://www.tensorflow.org/api_docs/python/tf/contrib/eager/defun), although this is still being actively developed. This creates a graph, but automatically makes sure that ops with side effects (like variable assignment) happen in the order they're defined. This way you don't have to worry about manually adding control dependencies.\r\n\r\nSorry this is so long, I hope it helps. I'm gonna close this issue since it's not actually a concurrency bug,  but feel free to comment if something is still confusing or you have more questions."}