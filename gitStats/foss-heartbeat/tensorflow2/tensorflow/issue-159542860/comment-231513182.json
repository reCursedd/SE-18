{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231513182", "html_url": "https://github.com/tensorflow/tensorflow/issues/2773#issuecomment-231513182", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2773", "id": 231513182, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTUxMzE4Mg==", "user": {"login": "lw394", "id": 15891975, "node_id": "MDQ6VXNlcjE1ODkxOTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/15891975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lw394", "html_url": "https://github.com/lw394", "followers_url": "https://api.github.com/users/lw394/followers", "following_url": "https://api.github.com/users/lw394/following{/other_user}", "gists_url": "https://api.github.com/users/lw394/gists{/gist_id}", "starred_url": "https://api.github.com/users/lw394/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lw394/subscriptions", "organizations_url": "https://api.github.com/users/lw394/orgs", "repos_url": "https://api.github.com/users/lw394/repos", "events_url": "https://api.github.com/users/lw394/events{/privacy}", "received_events_url": "https://api.github.com/users/lw394/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-09T03:51:31Z", "updated_at": "2016-07-09T03:51:31Z", "author_association": "NONE", "body_html": "<p>I'm having the same problem as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10738534\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/peterswang\">@peterswang</a>.</p>\n<p>$ python<br>\nPython 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)<br>\n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)] on darwin<br>\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.<br>\nAnaconda is brought to you by Continuum Analytics.<br>\nPlease check out: <a href=\"http://continuum.io/thanks\" rel=\"nofollow\">http://continuum.io/thanks</a> and <a href=\"https://anaconda.org\" rel=\"nofollow\">https://anaconda.org</a></p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import tensorflow<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally<br>\nSegmentation fault: 11</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>Also, running the deviceQuery sample,<br>\n./bin/x86_64/darwin/release/deviceQuery<br>\n./bin/x86_64/darwin/release/deviceQuery Starting...</p>\n<p>CUDA Device Query (Runtime API) version (CUDART static linking)</p>\n<p>Detected 1 CUDA Capable device(s)</p>\n<p>Device 0: \"GeForce GT 750M\"<br>\nCUDA Driver Version / Runtime Version          7.5 / 7.5<br>\nCUDA Capability Major/Minor version number:    3.0<br>\nTotal amount of global memory:                 2048 MBytes (2147024896 bytes)<br>\n( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores<br>\nGPU Max Clock rate:                            926 MHz (0.93 GHz)<br>\nMemory Clock rate:                             2508 Mhz<br>\nMemory Bus Width:                              128-bit<br>\nL2 Cache Size:                                 262144 bytes<br>\nMaximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)<br>\nMaximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers<br>\nMaximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers<br>\nTotal amount of constant memory:               65536 bytes<br>\nTotal amount of shared memory per block:       49152 bytes<br>\nTotal number of registers available per block: 65536<br>\nWarp size:                                     32<br>\nMaximum number of threads per multiprocessor:  2048<br>\nMaximum number of threads per block:           1024<br>\nMax dimension size of a thread block (x,y,z): (1024, 1024, 64)<br>\nMax dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)<br>\nMaximum memory pitch:                          2147483647 bytes<br>\nTexture alignment:                             512 bytes<br>\nConcurrent copy and kernel execution:          Yes with 1 copy engine(s)<br>\nRun time limit on kernels:                     Yes<br>\nIntegrated GPU sharing Host Memory:            No<br>\nSupport host page-locked memory mapping:       Yes<br>\nAlignment requirement for Surfaces:            Yes<br>\nDevice has ECC support:                        Disabled<br>\nDevice supports Unified Addressing (UVA):      Yes<br>\nDevice PCI Domain ID / Bus ID / location ID:   0 / 1 / 0<br>\nCompute Mode:<br>\n&lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</p>\n<p>deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.5, NumDevs = 1, Device0 = GeForce GT 750M<br>\nResult = PASS</p>", "body_text": "I'm having the same problem as @peterswang.\n$ python\nPython 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)\n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n\n\n\nimport tensorflow\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\nSegmentation fault: 11\n\n\n\nAlso, running the deviceQuery sample,\n./bin/x86_64/darwin/release/deviceQuery\n./bin/x86_64/darwin/release/deviceQuery Starting...\nCUDA Device Query (Runtime API) version (CUDART static linking)\nDetected 1 CUDA Capable device(s)\nDevice 0: \"GeForce GT 750M\"\nCUDA Driver Version / Runtime Version          7.5 / 7.5\nCUDA Capability Major/Minor version number:    3.0\nTotal amount of global memory:                 2048 MBytes (2147024896 bytes)\n( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\nGPU Max Clock rate:                            926 MHz (0.93 GHz)\nMemory Clock rate:                             2508 Mhz\nMemory Bus Width:                              128-bit\nL2 Cache Size:                                 262144 bytes\nMaximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\nMaximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\nMaximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\nTotal amount of constant memory:               65536 bytes\nTotal amount of shared memory per block:       49152 bytes\nTotal number of registers available per block: 65536\nWarp size:                                     32\nMaximum number of threads per multiprocessor:  2048\nMaximum number of threads per block:           1024\nMax dimension size of a thread block (x,y,z): (1024, 1024, 64)\nMax dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\nMaximum memory pitch:                          2147483647 bytes\nTexture alignment:                             512 bytes\nConcurrent copy and kernel execution:          Yes with 1 copy engine(s)\nRun time limit on kernels:                     Yes\nIntegrated GPU sharing Host Memory:            No\nSupport host page-locked memory mapping:       Yes\nAlignment requirement for Surfaces:            Yes\nDevice has ECC support:                        Disabled\nDevice supports Unified Addressing (UVA):      Yes\nDevice PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\nCompute Mode:\n< Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.5, NumDevs = 1, Device0 = GeForce GT 750M\nResult = PASS", "body": "I'm having the same problem as @peterswang.\n\n$ python\nPython 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17) \n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n\n> > > import tensorflow\n> > > I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\n> > > I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\n> > > I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\n> > > Segmentation fault: 11\n\nAlso, running the deviceQuery sample,\n./bin/x86_64/darwin/release/deviceQuery \n./bin/x86_64/darwin/release/deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 750M\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.5\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            926 MHz (0.93 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.5, NumDevs = 1, Device0 = GeForce GT 750M\nResult = PASS\n"}