{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13129", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13129/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13129/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13129/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13129", "id": 258539637, "node_id": "MDU6SXNzdWUyNTg1Mzk2Mzc=", "number": 13129, "title": "random crashes while serving multiple frozen models in parallel using go api", "user": {"login": "anight", "id": 1214641, "node_id": "MDQ6VXNlcjEyMTQ2NDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1214641?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anight", "html_url": "https://github.com/anight", "followers_url": "https://api.github.com/users/anight/followers", "following_url": "https://api.github.com/users/anight/following{/other_user}", "gists_url": "https://api.github.com/users/anight/gists{/gist_id}", "starred_url": "https://api.github.com/users/anight/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anight/subscriptions", "organizations_url": "https://api.github.com/users/anight/orgs", "repos_url": "https://api.github.com/users/anight/repos", "events_url": "https://api.github.com/users/anight/events{/privacy}", "received_events_url": "https://api.github.com/users/anight/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-18T16:20:49Z", "updated_at": "2017-09-20T15:20:29Z", "closed_at": "2017-09-20T15:20:29Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>Yes, I have written custom code</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Linux x86_64 SLES12</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>Source, latest master at the moment</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>('v1.3.0-rc1-2265-g6e7539b', '1.4.0-dev')<br>\nI also tried r1.3 with similar result.</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>Python 2.7.9</p>\n<ul>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n</ul>\n<p>Build label: 0.5.4<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)<br>\nBuild timestamp: 1503655200<br>\nBuild timestamp as int: 1503655200</p>\n<ul>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n</ul>\n<p>Not used.</p>\n<ul>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<p>Not used.</p>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>$ ./tfcrash --n_models 16 --n_images 100</p>\n<p>An output of this program can be different. The bug has random nature. In some cases the process just segfaults. Typical output is:</p>\n<p>$ ./tfcrash --n_models 16 --n_images 100<br>\n2017/09/18 16:45:43 setting 8 cpu<br>\n2017/09/18 16:45:43 launching 16 models<br>\n2017/09/18 16:45:43 feeding 100 images<br>\n2017/09/18 16:45:43 waiting<br>\n2017/09/18 16:45:51 session.Run() failed: Expects arg[0] to be uint8 but INVALID is provided</p>\n<p>Or:</p>\n<p>$ ./tfcrash<br>\n2017/09/18 16:57:54 setting 8 cpu<br>\n2017/09/18 16:57:54 launching 16 models<br>\n2017/09/18 16:57:54 feeding 100 images<br>\n2017/09/18 16:57:54 waiting<br>\nSegmentation fault (core dumped)</p>\n<h3>Describe the problem</h3>\n<p>I'm trying to serve predictions from multiple frozen models that I have trained and generated previously using python script. My programming language for serving predictions is golang. I have found that sometimes my process crashes randomly. Exact conditions needed to reproduce this behaviour are unknown. It is also unknown if this bug related to golang bindings or tensorflow itself.<br>\nI also tried different builds of tensorflow, all of them are affected so far, including one built with cuda support. I also noticed that setting lower numbers for --n_images and --n_models parameters decreases probability of bug reproduction. In my experience setting --n_models to 16 and up gives 100% probability of crash.</p>\n<p>I tried both go-1.8.3 and go-1.9 with similar result.</p>\n<h3>Source code / logs</h3>\n<p>I wrote a short program (less than 100 lines in go) which is able to reproduce crash with &gt;90% probability:<br>\n<a href=\"https://gist.github.com/a33c892b17d9ec1da1e40e4fb68fdcf9\">https://gist.github.com/a33c892b17d9ec1da1e40e4fb68fdcf9</a></p>\n<p>The model file (type: .frozen.pb, size: 34Mb): <a href=\"https://drive.google.com/file/d/0B9jZHp3Hh0s2MnAxekRGYlVTVHM/\" rel=\"nofollow\">https://drive.google.com/file/d/0B9jZHp3Hh0s2MnAxekRGYlVTVHM/</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nYes, I have written custom code\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nLinux x86_64 SLES12\n\nTensorFlow installed from (source or binary):\n\nSource, latest master at the moment\n\nTensorFlow version (use command below):\n\n('v1.3.0-rc1-2265-g6e7539b', '1.4.0-dev')\nI also tried r1.3 with similar result.\n\nPython version:\n\nPython 2.7.9\n\nBazel version (if compiling from source):\n\nBuild label: 0.5.4\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)\nBuild timestamp: 1503655200\nBuild timestamp as int: 1503655200\n\nCUDA/cuDNN version:\n\nNot used.\n\nGPU model and memory:\n\nNot used.\n\nExact command to reproduce:\n\n$ ./tfcrash --n_models 16 --n_images 100\nAn output of this program can be different. The bug has random nature. In some cases the process just segfaults. Typical output is:\n$ ./tfcrash --n_models 16 --n_images 100\n2017/09/18 16:45:43 setting 8 cpu\n2017/09/18 16:45:43 launching 16 models\n2017/09/18 16:45:43 feeding 100 images\n2017/09/18 16:45:43 waiting\n2017/09/18 16:45:51 session.Run() failed: Expects arg[0] to be uint8 but INVALID is provided\nOr:\n$ ./tfcrash\n2017/09/18 16:57:54 setting 8 cpu\n2017/09/18 16:57:54 launching 16 models\n2017/09/18 16:57:54 feeding 100 images\n2017/09/18 16:57:54 waiting\nSegmentation fault (core dumped)\nDescribe the problem\nI'm trying to serve predictions from multiple frozen models that I have trained and generated previously using python script. My programming language for serving predictions is golang. I have found that sometimes my process crashes randomly. Exact conditions needed to reproduce this behaviour are unknown. It is also unknown if this bug related to golang bindings or tensorflow itself.\nI also tried different builds of tensorflow, all of them are affected so far, including one built with cuda support. I also noticed that setting lower numbers for --n_images and --n_models parameters decreases probability of bug reproduction. In my experience setting --n_models to 16 and up gives 100% probability of crash.\nI tried both go-1.8.3 and go-1.9 with similar result.\nSource code / logs\nI wrote a short program (less than 100 lines in go) which is able to reproduce crash with >90% probability:\nhttps://gist.github.com/a33c892b17d9ec1da1e40e4fb68fdcf9\nThe model file (type: .frozen.pb, size: 34Mb): https://drive.google.com/file/d/0B9jZHp3Hh0s2MnAxekRGYlVTVHM/", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nYes, I have written custom code\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux x86_64 SLES12\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nSource, latest master at the moment\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n('v1.3.0-rc1-2265-g6e7539b', '1.4.0-dev')\r\nI also tried r1.3 with similar result.\r\n\r\n- **Python version**: \r\n\r\nPython 2.7.9\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\nBuild label: 0.5.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)\r\nBuild timestamp: 1503655200\r\nBuild timestamp as int: 1503655200\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nNot used.\r\n\r\n- **GPU model and memory**:\r\n\r\nNot used.\r\n\r\n- **Exact command to reproduce**:\r\n\r\n$ ./tfcrash --n_models 16 --n_images 100\r\n\r\nAn output of this program can be different. The bug has random nature. In some cases the process just segfaults. Typical output is:\r\n\r\n$ ./tfcrash --n_models 16 --n_images 100\r\n2017/09/18 16:45:43 setting 8 cpu\r\n2017/09/18 16:45:43 launching 16 models\r\n2017/09/18 16:45:43 feeding 100 images\r\n2017/09/18 16:45:43 waiting\r\n2017/09/18 16:45:51 session.Run() failed: Expects arg[0] to be uint8 but INVALID is provided\r\n\r\nOr:\r\n\r\n$ ./tfcrash \r\n2017/09/18 16:57:54 setting 8 cpu\r\n2017/09/18 16:57:54 launching 16 models\r\n2017/09/18 16:57:54 feeding 100 images\r\n2017/09/18 16:57:54 waiting\r\nSegmentation fault (core dumped)\r\n\r\n\r\n### Describe the problem\r\n\r\nI'm trying to serve predictions from multiple frozen models that I have trained and generated previously using python script. My programming language for serving predictions is golang. I have found that sometimes my process crashes randomly. Exact conditions needed to reproduce this behaviour are unknown. It is also unknown if this bug related to golang bindings or tensorflow itself.\r\nI also tried different builds of tensorflow, all of them are affected so far, including one built with cuda support. I also noticed that setting lower numbers for --n_images and --n_models parameters decreases probability of bug reproduction. In my experience setting --n_models to 16 and up gives 100% probability of crash.\r\n\r\nI tried both go-1.8.3 and go-1.9 with similar result.\r\n\r\n### Source code / logs\r\n\r\nI wrote a short program (less than 100 lines in go) which is able to reproduce crash with >90% probability:\r\nhttps://gist.github.com/a33c892b17d9ec1da1e40e4fb68fdcf9\r\n\r\nThe model file (type: .frozen.pb, size: 34Mb): https://drive.google.com/file/d/0B9jZHp3Hh0s2MnAxekRGYlVTVHM/\r\n\r\n"}