{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436121590", "html_url": "https://github.com/tensorflow/tensorflow/issues/120#issuecomment-436121590", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/120", "id": 436121590, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjEyMTU5MA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T03:44:36Z", "updated_at": "2018-11-06T03:44:36Z", "author_association": "MEMBER", "body_html": "<p>I should add that using the graph function, the overheads of the operator overload and the Python-&gt;Tensor conversion are paid for only at graph construction time. So this should work too:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-en\">@tf.contrib.eager.defun</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">c</span>):\n  <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1000</span>):\n    c <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n  <span class=\"pl-k\">return</span> c\n\nc <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Discard the first run, since that includes graph building time</span>\n_ <span class=\"pl-k\">=</span> f(c)\n<span class=\"pl-k\">for</span> e <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>):\n  start <span class=\"pl-k\">=</span> time()\n  c <span class=\"pl-k\">=</span> f(c)\n  end <span class=\"pl-k\">=</span> time()\n  <span class=\"pl-c1\">print</span>(end <span class=\"pl-k\">-</span> start)</pre></div>", "body_text": "I should add that using the graph function, the overheads of the operator overload and the Python->Tensor conversion are paid for only at graph construction time. So this should work too:\n@tf.contrib.eager.defun\ndef f(c):\n  for _ in xrange(1000):\n    c += 1\n  return c\n\nc = tf.constant(0)\n# Discard the first run, since that includes graph building time\n_ = f(c)\nfor e in range(3):\n  start = time()\n  c = f(c)\n  end = time()\n  print(end - start)", "body": "I should add that using the graph function, the overheads of the operator overload and the Python->Tensor conversion are paid for only at graph construction time. So this should work too:\r\n\r\n```python\r\n@tf.contrib.eager.defun\r\ndef f(c):\r\n  for _ in xrange(1000):\r\n    c += 1\r\n  return c\r\n\r\nc = tf.constant(0)\r\n# Discard the first run, since that includes graph building time\r\n_ = f(c)\r\nfor e in range(3):\r\n  start = time()\r\n  c = f(c)\r\n  end = time()\r\n  print(end - start)\r\n```"}