{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/155672879", "html_url": "https://github.com/tensorflow/tensorflow/issues/120#issuecomment-155672879", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/120", "id": 155672879, "node_id": "MDEyOklzc3VlQ29tbWVudDE1NTY3Mjg3OQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-11T05:44:32Z", "updated_at": "2015-11-11T05:44:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>There's a subtle issue that crops up when performing these microbenchmarks on TensorFlow. I ran a version of your code on my laptop (a late-2014 MacBook Air):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.Graph().as_default():\n<span class=\"pl-c1\">...</span>   <span class=\"pl-k\">with</span> tf.Session():\n<span class=\"pl-c1\">...</span>     start <span class=\"pl-k\">=</span> time.time()\n<span class=\"pl-c1\">...</span>     <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1000</span>):\n<span class=\"pl-c1\">...</span>       _ <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>).eval()\n<span class=\"pl-c1\">...</span>     end <span class=\"pl-k\">=</span> time.time()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span> end <span class=\"pl-k\">-</span> start\n<span class=\"pl-c1\">4.721920967102051</span></pre></div>\n<p>The perhaps surprising thing to note about this code is that it is actually the <code>tf.constant(0)</code> method that is the expensive part. If I run this slightly different program, it completes much faster:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.Graph().as_default():\n<span class=\"pl-c1\">...</span>   c <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>)\n<span class=\"pl-c1\">...</span>   <span class=\"pl-k\">with</span> tf.Session():\n<span class=\"pl-c1\">...</span>     start <span class=\"pl-k\">=</span> time.time()\n<span class=\"pl-c1\">...</span>     <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1000</span>):\n<span class=\"pl-c1\">...</span>       _ <span class=\"pl-k\">=</span> c.eval()\n<span class=\"pl-c1\">...</span>     end <span class=\"pl-k\">=</span> time.time()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span> end<span class=\"pl-k\">-</span>start\n<span class=\"pl-c1\">0.0893728733063</span></pre></div>\n<p>In the first version (like in your snippet), I created 1000 identical constant nodes in the graph, and evaluated each of them: this took several seconds. In the second version, I created the constant node once, and evaluated it 1000 times: this took less than 100 milliseconds.</p>\n<p>In summary, it's important to try to reuse the existing graph as much as possible for each step of your model. Adding nodes to the graph isn't free, and we could probably optimize that further. Feel free to share more of your simulation code, and we can look into any major performance issues that it might have.</p>", "body_text": "There's a subtle issue that crops up when performing these microbenchmarks on TensorFlow. I ran a version of your code on my laptop (a late-2014 MacBook Air):\n>>> with tf.Graph().as_default():\n...   with tf.Session():\n...     start = time.time()\n...     for _ in xrange(1000):\n...       _ = tf.constant(0).eval()\n...     end = time.time()\n>>> print end - start\n4.721920967102051\nThe perhaps surprising thing to note about this code is that it is actually the tf.constant(0) method that is the expensive part. If I run this slightly different program, it completes much faster:\n>>> with tf.Graph().as_default():\n...   c = tf.constant(0)\n...   with tf.Session():\n...     start = time.time()\n...     for _ in xrange(1000):\n...       _ = c.eval()\n...     end = time.time()\n>>> print end-start\n0.0893728733063\nIn the first version (like in your snippet), I created 1000 identical constant nodes in the graph, and evaluated each of them: this took several seconds. In the second version, I created the constant node once, and evaluated it 1000 times: this took less than 100 milliseconds.\nIn summary, it's important to try to reuse the existing graph as much as possible for each step of your model. Adding nodes to the graph isn't free, and we could probably optimize that further. Feel free to share more of your simulation code, and we can look into any major performance issues that it might have.", "body": "There's a subtle issue that crops up when performing these microbenchmarks on TensorFlow. I ran a version of your code on my laptop (a late-2014 MacBook Air):\n\n``` python\n>>> with tf.Graph().as_default():\n...   with tf.Session():\n...     start = time.time()\n...     for _ in xrange(1000):\n...       _ = tf.constant(0).eval()\n...     end = time.time()\n>>> print end - start\n4.721920967102051\n```\n\nThe perhaps surprising thing to note about this code is that it is actually the `tf.constant(0)` method that is the expensive part. If I run this slightly different program, it completes much faster:\n\n``` python\n>>> with tf.Graph().as_default():\n...   c = tf.constant(0)\n...   with tf.Session():\n...     start = time.time()\n...     for _ in xrange(1000):\n...       _ = c.eval()\n...     end = time.time()\n>>> print end-start\n0.0893728733063\n```\n\nIn the first version (like in your snippet), I created 1000 identical constant nodes in the graph, and evaluated each of them: this took several seconds. In the second version, I created the constant node once, and evaluated it 1000 times: this took less than 100 milliseconds.\n\nIn summary, it's important to try to reuse the existing graph as much as possible for each step of your model. Adding nodes to the graph isn't free, and we could probably optimize that further. Feel free to share more of your simulation code, and we can look into any major performance issues that it might have.\n"}