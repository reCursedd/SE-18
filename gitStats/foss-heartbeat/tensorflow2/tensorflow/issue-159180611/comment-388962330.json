{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388962330", "html_url": "https://github.com/tensorflow/tensorflow/issues/2732#issuecomment-388962330", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2732", "id": 388962330, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODk2MjMzMA==", "user": {"login": "nikonikolov", "id": 11044035, "node_id": "MDQ6VXNlcjExMDQ0MDM1", "avatar_url": "https://avatars3.githubusercontent.com/u/11044035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikonikolov", "html_url": "https://github.com/nikonikolov", "followers_url": "https://api.github.com/users/nikonikolov/followers", "following_url": "https://api.github.com/users/nikonikolov/following{/other_user}", "gists_url": "https://api.github.com/users/nikonikolov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikonikolov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikonikolov/subscriptions", "organizations_url": "https://api.github.com/users/nikonikolov/orgs", "repos_url": "https://api.github.com/users/nikonikolov/repos", "events_url": "https://api.github.com/users/nikonikolov/events{/privacy}", "received_events_url": "https://api.github.com/users/nikonikolov/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-14T21:04:37Z", "updated_at": "2018-05-14T21:04:37Z", "author_association": "NONE", "body_html": "<p>Hey, so here is a relatively simple example to reproduce. I tried it on CPU and results were the same. However, on GPU they were not. When I decreased number of iterations to 1 or 2, all the time I was able to get the same results (although I did not do a lot of runs). When the number of iterations is higher, say &gt;10, I almost always get different results. Also when there is only 1 dense layer, the results are almost always reproducible.</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nITERATIONS=20\n\ntf.set_random_seed(42)\nnp.random.seed(42)\n\nx_data = np.random.normal(size=[32, 10])\ny_data = np.random.normal(size=[32, 1])\nx_test = np.random.normal(size=[32, 10])\n\nx_in  = tf.placeholder(tf.float32, [None, 10])\ny_in  = tf.placeholder(tf.float32, [None, 1])\nx     = x_in\nx     = tf.layers.dense(x, 200, tf.nn.relu)\nx     = tf.layers.dense(x, 1, tf.nn.relu)\nloss  = tf.losses.mean_squared_error(y_in, x)\n\nmvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\nopt   = tf.train.AdamOptimizer(use_locking=True)\ntrain = opt.minimize(loss)\nconfig= tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\nsess  = tf.Session(config=config)\n\nallvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\nsess.run(tf.global_variables_initializer())\ninit_vals = sess.run(allvars)\n\ndef run():\n  for val, v in zip(init_vals, allvars):\n    sess.run(tf.assign(v, val))\n  \n  ivals = sess.run(allvars)\n  out = []\n  allvals = []\n\n  for i in range(ITERATIONS):\n    l, _ = sess.run([loss, train], feed_dict={x_in: x_data, y_in: y_data})\n    out.append(sess.run(x, feed_dict={x_in: x_test}))\n    allvals.append(sess.run(allvars))\n\n  fvals = sess.run(allvars)\n  # return np.asarray(ivals), np.asarray(fvals), np.asarray(out)\n  return np.asarray(ivals), np.asarray(fvals), np.asarray(out), allvals\n\nivals1, fvals1, out1, all1 = run()\nivals2, fvals2, out2, all2 = run()\n\nsame_init = [np.all(v1 == v2) for v1, v2 in zip(ivals1, ivals2)] \nsame_fin = [np.all(v1 == v2) for v1, v2 in zip(fvals1, fvals2)] \nprint(\"Forward passes were the same: {}\".format( np.all(out1 == out2) ))\nprint(\"Final value of variables are the same: {}\".format( np.all(same_fin) ))\nprint(\"Variables initialized to same values: {}\".format( np.all(same_init) ))\n</code></pre>\n<p>Unfortunately I am really busy with experiments at the moment and do not have the time to narrow this down further, but I hope it will be a good starting point. I tested with python 3.6.5, CUDA 9.0, cudnn 7.1<br>\nand TF 1.8.</p>\n<p>It will be great if we manage to make all operations deterministic. I am running some Reinforcement Learning algorithms and over time I get huge difference in performance even if I use the same seed.</p>", "body_text": "Hey, so here is a relatively simple example to reproduce. I tried it on CPU and results were the same. However, on GPU they were not. When I decreased number of iterations to 1 or 2, all the time I was able to get the same results (although I did not do a lot of runs). When the number of iterations is higher, say >10, I almost always get different results. Also when there is only 1 dense layer, the results are almost always reproducible.\nimport numpy as np\nimport tensorflow as tf\n\nITERATIONS=20\n\ntf.set_random_seed(42)\nnp.random.seed(42)\n\nx_data = np.random.normal(size=[32, 10])\ny_data = np.random.normal(size=[32, 1])\nx_test = np.random.normal(size=[32, 10])\n\nx_in  = tf.placeholder(tf.float32, [None, 10])\ny_in  = tf.placeholder(tf.float32, [None, 1])\nx     = x_in\nx     = tf.layers.dense(x, 200, tf.nn.relu)\nx     = tf.layers.dense(x, 1, tf.nn.relu)\nloss  = tf.losses.mean_squared_error(y_in, x)\n\nmvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\nopt   = tf.train.AdamOptimizer(use_locking=True)\ntrain = opt.minimize(loss)\nconfig= tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\nsess  = tf.Session(config=config)\n\nallvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n\nsess.run(tf.global_variables_initializer())\ninit_vals = sess.run(allvars)\n\ndef run():\n  for val, v in zip(init_vals, allvars):\n    sess.run(tf.assign(v, val))\n  \n  ivals = sess.run(allvars)\n  out = []\n  allvals = []\n\n  for i in range(ITERATIONS):\n    l, _ = sess.run([loss, train], feed_dict={x_in: x_data, y_in: y_data})\n    out.append(sess.run(x, feed_dict={x_in: x_test}))\n    allvals.append(sess.run(allvars))\n\n  fvals = sess.run(allvars)\n  # return np.asarray(ivals), np.asarray(fvals), np.asarray(out)\n  return np.asarray(ivals), np.asarray(fvals), np.asarray(out), allvals\n\nivals1, fvals1, out1, all1 = run()\nivals2, fvals2, out2, all2 = run()\n\nsame_init = [np.all(v1 == v2) for v1, v2 in zip(ivals1, ivals2)] \nsame_fin = [np.all(v1 == v2) for v1, v2 in zip(fvals1, fvals2)] \nprint(\"Forward passes were the same: {}\".format( np.all(out1 == out2) ))\nprint(\"Final value of variables are the same: {}\".format( np.all(same_fin) ))\nprint(\"Variables initialized to same values: {}\".format( np.all(same_init) ))\n\nUnfortunately I am really busy with experiments at the moment and do not have the time to narrow this down further, but I hope it will be a good starting point. I tested with python 3.6.5, CUDA 9.0, cudnn 7.1\nand TF 1.8.\nIt will be great if we manage to make all operations deterministic. I am running some Reinforcement Learning algorithms and over time I get huge difference in performance even if I use the same seed.", "body": "Hey, so here is a relatively simple example to reproduce. I tried it on CPU and results were the same. However, on GPU they were not. When I decreased number of iterations to 1 or 2, all the time I was able to get the same results (although I did not do a lot of runs). When the number of iterations is higher, say >10, I almost always get different results. Also when there is only 1 dense layer, the results are almost always reproducible.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nITERATIONS=20\r\n\r\ntf.set_random_seed(42)\r\nnp.random.seed(42)\r\n\r\nx_data = np.random.normal(size=[32, 10])\r\ny_data = np.random.normal(size=[32, 1])\r\nx_test = np.random.normal(size=[32, 10])\r\n\r\nx_in  = tf.placeholder(tf.float32, [None, 10])\r\ny_in  = tf.placeholder(tf.float32, [None, 1])\r\nx     = x_in\r\nx     = tf.layers.dense(x, 200, tf.nn.relu)\r\nx     = tf.layers.dense(x, 1, tf.nn.relu)\r\nloss  = tf.losses.mean_squared_error(y_in, x)\r\n\r\nmvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\n\r\nopt   = tf.train.AdamOptimizer(use_locking=True)\r\ntrain = opt.minimize(loss)\r\nconfig= tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\r\nsess  = tf.Session(config=config)\r\n\r\nallvars = tf.get_default_graph().get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\r\n\r\nsess.run(tf.global_variables_initializer())\r\ninit_vals = sess.run(allvars)\r\n\r\ndef run():\r\n  for val, v in zip(init_vals, allvars):\r\n    sess.run(tf.assign(v, val))\r\n  \r\n  ivals = sess.run(allvars)\r\n  out = []\r\n  allvals = []\r\n\r\n  for i in range(ITERATIONS):\r\n    l, _ = sess.run([loss, train], feed_dict={x_in: x_data, y_in: y_data})\r\n    out.append(sess.run(x, feed_dict={x_in: x_test}))\r\n    allvals.append(sess.run(allvars))\r\n\r\n  fvals = sess.run(allvars)\r\n  # return np.asarray(ivals), np.asarray(fvals), np.asarray(out)\r\n  return np.asarray(ivals), np.asarray(fvals), np.asarray(out), allvals\r\n\r\nivals1, fvals1, out1, all1 = run()\r\nivals2, fvals2, out2, all2 = run()\r\n\r\nsame_init = [np.all(v1 == v2) for v1, v2 in zip(ivals1, ivals2)] \r\nsame_fin = [np.all(v1 == v2) for v1, v2 in zip(fvals1, fvals2)] \r\nprint(\"Forward passes were the same: {}\".format( np.all(out1 == out2) ))\r\nprint(\"Final value of variables are the same: {}\".format( np.all(same_fin) ))\r\nprint(\"Variables initialized to same values: {}\".format( np.all(same_init) ))\r\n```\r\nUnfortunately I am really busy with experiments at the moment and do not have the time to narrow this down further, but I hope it will be a good starting point. I tested with python 3.6.5, CUDA 9.0, cudnn 7.1\r\n and TF 1.8.\r\n\r\nIt will be great if we manage to make all operations deterministic. I am running some Reinforcement Learning algorithms and over time I get huge difference in performance even if I use the same seed."}