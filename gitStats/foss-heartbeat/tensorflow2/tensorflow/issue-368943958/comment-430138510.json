{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/430138510", "html_url": "https://github.com/tensorflow/tensorflow/issues/22885#issuecomment-430138510", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22885", "id": 430138510, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDEzODUxMA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-16T07:55:52Z", "updated_at": "2018-10-16T07:55:52Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4644029\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wschoong\">@wschoong</a> : Thanks for reporting. Yes, it is running out of memory, and yes it should fail gracefully instead of segfaulting.</p>\n<p>I haven't traced when, but I <em>think</em> this has been fixed, though after 1.11.0, so the fix will only be visible in 1.12.0. I tried the same program out in 1.10.0, 1.11.0, and 1.12.0-rc0 and while I see a segmentation fault in the first two (as you guys did), I see a better error message:</p>\n<pre><code>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15353856,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n         [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at ./test.py:29)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=42, seed2=32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n</code></pre>\n<p>in 1.12.0-rc0.</p>\n<p>Closing this out since it has been fixed since, and we're unlikely to want to patch previous releases.<br>\nFeel free to reopen if you think I'm mistaken.</p>\n<p>Thanks!</p>", "body_text": "@wschoong : Thanks for reporting. Yes, it is running out of memory, and yes it should fail gracefully instead of segfaulting.\nI haven't traced when, but I think this has been fixed, though after 1.11.0, so the fix will only be visible in 1.12.0. I tried the same program out in 1.10.0, 1.11.0, and 1.12.0-rc0 and while I see a segmentation fault in the first two (as you guys did), I see a better error message:\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15353856,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n         [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at ./test.py:29)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=42, seed2=32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\nin 1.12.0-rc0.\nClosing this out since it has been fixed since, and we're unlikely to want to patch previous releases.\nFeel free to reopen if you think I'm mistaken.\nThanks!", "body": "@wschoong : Thanks for reporting. Yes, it is running out of memory, and yes it should fail gracefully instead of segfaulting.\r\n\r\nI haven't traced when, but I _think_ this has been fixed, though after 1.11.0, so the fix will only be visible in 1.12.0. I tried the same program out in 1.10.0, 1.11.0, and 1.12.0-rc0 and while I see a segmentation fault in the first two (as you guys did), I see a better error message:\r\n\r\n```\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15353856,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n         [[node dense/kernel/Initializer/random_uniform/RandomUniform (defined at ./test.py:29)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense/kernel/Assign\"], dtype=DT_FLOAT, seed=42, seed2=32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/kernel/Initializer/random_uniform/shape)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n```\r\n\r\nin 1.12.0-rc0.\r\n\r\nClosing this out since it has been fixed since, and we're unlikely to want to patch previous releases.\r\nFeel free to reopen if you think I'm mistaken.\r\n\r\nThanks!"}