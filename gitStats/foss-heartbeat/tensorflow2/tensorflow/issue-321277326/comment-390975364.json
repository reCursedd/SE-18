{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/390975364", "html_url": "https://github.com/tensorflow/tensorflow/pull/19157#issuecomment-390975364", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19157", "id": 390975364, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MDk3NTM2NA==", "user": {"login": "ngc92", "id": 7938269, "node_id": "MDQ6VXNlcjc5MzgyNjk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7938269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngc92", "html_url": "https://github.com/ngc92", "followers_url": "https://api.github.com/users/ngc92/followers", "following_url": "https://api.github.com/users/ngc92/following{/other_user}", "gists_url": "https://api.github.com/users/ngc92/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngc92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngc92/subscriptions", "organizations_url": "https://api.github.com/users/ngc92/orgs", "repos_url": "https://api.github.com/users/ngc92/repos", "events_url": "https://api.github.com/users/ngc92/events{/privacy}", "received_events_url": "https://api.github.com/users/ngc92/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-22T12:41:41Z", "updated_at": "2018-05-22T12:41:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7244943\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/roumposg\">@roumposg</a><br>\nOk, so I've spent some time thinking about how to implement an adversarial head with the current design (so that you could then do a MultiHead to combine it with your regular training).</p>\n<ol>\n<li>\n<p>A minimal way of doing adversarial training would be to just add the adversarial loss to your <code>Head</code> as an additional regularization loss. However you probably also would want additional eval statistics and eval metrics (i.e. the accuracy on adversarial data) which you would have to add by hand.</p>\n</li>\n<li>\n<p>Using the same head twice. An adversarial training <code>model_fn</code> with the current design could look like this:</p>\n</li>\n</ol>\n<pre><code>logits = logit_fn(features)\nadv_f = make_adversarial(logits, features)\nadv_l = logit_fn(adv_f)\nbase_head = MyHead()\nadv_head = MyHead(name=\"adversarial\")\nhead = MultiHead(base_head, adv_head)\nreturn head.make_estimator_spec(..., logits={\"head\": logits, \"adversarial\": adv_l})\n</code></pre>\n<ol start=\"3\">\n<li>The documentation mentions a split of a model_fn into a head and a logit_fn, which does not seem to be really reflected in the current design. If <code>make_estimator_spec</code> took an actual <code>logit_fn</code> instead of a logit tensor, one could write a head like</li>\n</ol>\n<pre><code>class FGSM_AdvHead(Head):\n  def __init__(self, base_head):\n     ....\n  def make_estimator_spec(features, logit_fn, ...):\n    logits = self.logit_fn(features)\n    adv_f = self.make_adversarial(logits, features)\n    adv_l = self.logit_fn(adv_f)\n    head = MultiHead(self.base_head(name=\"base\"), self.base_head(name=\"adv\"))\n    return head.make_estimator_spec(..., logits={\"base\": logits, \"adv\": adv_l})\n</code></pre>\n<p>where a real implementation would probably do something smarter/more specialized than constructing a temporary MultiHead.</p>\n<p>This last option is currently no possible, right?</p>\n<p>So how could this be fixed?</p>\n<ol>\n<li>Simply state that this is out of scope. Note that this disables to write any head that wants to control the context in which the <code>logit_fn</code> is called, or wants to call <code>logit_fn</code> multiple times. The most direct example I could come up with is the AdversarialHead above, but one might also be interested to call <code>logit_fn</code> for parts of the current batch on different devices, and maybe seq2seq models might also benifit from receiving their input in a functional form instead of a tensors (I haven't really thought about this last point, though). In this case I would rewrite the following paragraph in the documentation:</li>\n</ol>\n<blockquote>\n<p>Head offers an intermediate level of abstraction: the model_fn is split into a logit_fn that contains the ops to create the logits Tensor, and a Head that produces ops for train, eval and infer given those logits. Internally, canned estimators use this scheme. E.g. DNNClassifier and DNNRegressor use the same logit_fn but the former uses a classification head, whereas the latter uses a regression head. This reduces code duplication, improves testing, and makes it easier for users to adapt models for their own use.</p>\n</blockquote>\n<p>at least to me this would insinuate that a usage as above described be possible, instead of this being just the implementation strategy of DNNClassifier/DNNRegressor</p>\n<ol start=\"2\">\n<li>Take a <code>logit_fn</code> instead of logits. This would cause three problems:</li>\n</ol>\n<ul>\n<li>The user might be required to write another function even though for most use cases, if the non-head part of the model_fn does something apart from calculating the logits. This could be fixed by making the interface take either a logit tensor or a function, where fany heads might only work with a function and otherwise raise an exception.</li>\n<li>In the current setting <code>make_estimator_spec</code> also takes regularization losses. These will depend on the calculation of the logits. Therefore one would need the <code>logit_fn</code> to be able to return a <code>(logits, regularization_loss)</code> tuple or more generally a <code>LogitSpec</code> object.</li>\n<li>In MultiHead in most cases one would not like each sub-head to calculate the same logits again. However, MultiHead might amend the <code>logit_fn</code> with some form of LRU cache that only adds ops to the graph if it is called with different features. (Maybe the graph optimizer would be able to fold all logit_fn subgraphs back together?)</li>\n</ul>\n<p>If you do pass in the logits as a function instead of a tensor, this might also allow to lift the Head completely out of <code>model_fn</code> and provide a <code>make_estimator</code> instead of a <code>make_estimator_spec</code> function.</p>", "body_text": "@roumposg\nOk, so I've spent some time thinking about how to implement an adversarial head with the current design (so that you could then do a MultiHead to combine it with your regular training).\n\n\nA minimal way of doing adversarial training would be to just add the adversarial loss to your Head as an additional regularization loss. However you probably also would want additional eval statistics and eval metrics (i.e. the accuracy on adversarial data) which you would have to add by hand.\n\n\nUsing the same head twice. An adversarial training model_fn with the current design could look like this:\n\n\nlogits = logit_fn(features)\nadv_f = make_adversarial(logits, features)\nadv_l = logit_fn(adv_f)\nbase_head = MyHead()\nadv_head = MyHead(name=\"adversarial\")\nhead = MultiHead(base_head, adv_head)\nreturn head.make_estimator_spec(..., logits={\"head\": logits, \"adversarial\": adv_l})\n\n\nThe documentation mentions a split of a model_fn into a head and a logit_fn, which does not seem to be really reflected in the current design. If make_estimator_spec took an actual logit_fn instead of a logit tensor, one could write a head like\n\nclass FGSM_AdvHead(Head):\n  def __init__(self, base_head):\n     ....\n  def make_estimator_spec(features, logit_fn, ...):\n    logits = self.logit_fn(features)\n    adv_f = self.make_adversarial(logits, features)\n    adv_l = self.logit_fn(adv_f)\n    head = MultiHead(self.base_head(name=\"base\"), self.base_head(name=\"adv\"))\n    return head.make_estimator_spec(..., logits={\"base\": logits, \"adv\": adv_l})\n\nwhere a real implementation would probably do something smarter/more specialized than constructing a temporary MultiHead.\nThis last option is currently no possible, right?\nSo how could this be fixed?\n\nSimply state that this is out of scope. Note that this disables to write any head that wants to control the context in which the logit_fn is called, or wants to call logit_fn multiple times. The most direct example I could come up with is the AdversarialHead above, but one might also be interested to call logit_fn for parts of the current batch on different devices, and maybe seq2seq models might also benifit from receiving their input in a functional form instead of a tensors (I haven't really thought about this last point, though). In this case I would rewrite the following paragraph in the documentation:\n\n\nHead offers an intermediate level of abstraction: the model_fn is split into a logit_fn that contains the ops to create the logits Tensor, and a Head that produces ops for train, eval and infer given those logits. Internally, canned estimators use this scheme. E.g. DNNClassifier and DNNRegressor use the same logit_fn but the former uses a classification head, whereas the latter uses a regression head. This reduces code duplication, improves testing, and makes it easier for users to adapt models for their own use.\n\nat least to me this would insinuate that a usage as above described be possible, instead of this being just the implementation strategy of DNNClassifier/DNNRegressor\n\nTake a logit_fn instead of logits. This would cause three problems:\n\n\nThe user might be required to write another function even though for most use cases, if the non-head part of the model_fn does something apart from calculating the logits. This could be fixed by making the interface take either a logit tensor or a function, where fany heads might only work with a function and otherwise raise an exception.\nIn the current setting make_estimator_spec also takes regularization losses. These will depend on the calculation of the logits. Therefore one would need the logit_fn to be able to return a (logits, regularization_loss) tuple or more generally a LogitSpec object.\nIn MultiHead in most cases one would not like each sub-head to calculate the same logits again. However, MultiHead might amend the logit_fn with some form of LRU cache that only adds ops to the graph if it is called with different features. (Maybe the graph optimizer would be able to fold all logit_fn subgraphs back together?)\n\nIf you do pass in the logits as a function instead of a tensor, this might also allow to lift the Head completely out of model_fn and provide a make_estimator instead of a make_estimator_spec function.", "body": "@roumposg\r\nOk, so I've spent some time thinking about how to implement an adversarial head with the current design (so that you could then do a MultiHead to combine it with your regular training).\r\n\r\n1. A minimal way of doing adversarial training would be to just add the adversarial loss to your `Head` as an additional regularization loss. However you probably also would want additional eval statistics and eval metrics (i.e. the accuracy on adversarial data) which you would have to add by hand.\r\n\r\n2. Using the same head twice. An adversarial training `model_fn` with the current design could look like this:\r\n```\r\nlogits = logit_fn(features)\r\nadv_f = make_adversarial(logits, features)\r\nadv_l = logit_fn(adv_f)\r\nbase_head = MyHead()\r\nadv_head = MyHead(name=\"adversarial\")\r\nhead = MultiHead(base_head, adv_head)\r\nreturn head.make_estimator_spec(..., logits={\"head\": logits, \"adversarial\": adv_l})\r\n```\r\n\r\n3. The documentation mentions a split of a model_fn into a head and a logit_fn, which does not seem to be really reflected in the current design. If `make_estimator_spec` took an actual `logit_fn` instead of a logit tensor, one could write a head like\r\n```\r\nclass FGSM_AdvHead(Head):\r\n  def __init__(self, base_head):\r\n     ....\r\n  def make_estimator_spec(features, logit_fn, ...):\r\n    logits = self.logit_fn(features)\r\n    adv_f = self.make_adversarial(logits, features)\r\n    adv_l = self.logit_fn(adv_f)\r\n    head = MultiHead(self.base_head(name=\"base\"), self.base_head(name=\"adv\"))\r\n    return head.make_estimator_spec(..., logits={\"base\": logits, \"adv\": adv_l})\r\n```\r\nwhere a real implementation would probably do something smarter/more specialized than constructing a temporary MultiHead.\r\n\r\nThis last option is currently no possible, right?\r\n\r\nSo how could this be fixed?\r\n1) Simply state that this is out of scope. Note that this disables to write any head that wants to control the context in which the `logit_fn` is called, or wants to call `logit_fn` multiple times. The most direct example I could come up with is the AdversarialHead above, but one might also be interested to call `logit_fn` for parts of the current batch on different devices, and maybe seq2seq models might also benifit from receiving their input in a functional form instead of a tensors (I haven't really thought about this last point, though). In this case I would rewrite the following paragraph in the documentation:\r\n\r\n> Head offers an intermediate level of abstraction: the model_fn is split into a logit_fn that contains the ops to create the logits Tensor, and a Head that produces ops for train, eval and infer given those logits. Internally, canned estimators use this scheme. E.g. DNNClassifier and DNNRegressor use the same logit_fn but the former uses a classification head, whereas the latter uses a regression head. This reduces code duplication, improves testing, and makes it easier for users to adapt models for their own use.\r\n \r\nat least to me this would insinuate that a usage as above described be possible, instead of this being just the implementation strategy of DNNClassifier/DNNRegressor\r\n\r\n2) Take a `logit_fn` instead of logits. This would cause three problems:\r\n * The user might be required to write another function even though for most use cases, if the non-head part of the model_fn does something apart from calculating the logits. This could be fixed by making the interface take either a logit tensor or a function, where fany heads might only work with a function and otherwise raise an exception. \r\n * In the current setting `make_estimator_spec` also takes regularization losses. These will depend on the calculation of the logits. Therefore one would need the `logit_fn` to be able to return a `(logits, regularization_loss)` tuple or more generally a `LogitSpec` object.\r\n* In MultiHead in most cases one would not like each sub-head to calculate the same logits again. However, MultiHead might amend the `logit_fn` with some form of LRU cache that only adds ops to the graph if it is called with different features. (Maybe the graph optimizer would be able to fold all logit_fn subgraphs back together?)\r\n\r\nIf you do pass in the logits as a function instead of a tensor, this might also allow to lift the Head completely out of `model_fn` and provide a `make_estimator` instead of a `make_estimator_spec` function.\r\n\r\n  "}