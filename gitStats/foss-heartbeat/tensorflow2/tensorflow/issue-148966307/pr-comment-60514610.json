{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/60514610", "pull_request_review_id": null, "id": 60514610, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwNTE0NjEw", "diff_hunk": "@@ -0,0 +1,265 @@\n+#ifndef TENSORFLOW_KERNELS_LSTM_OPS_H_\n+#define TENSORFLOW_KERNELS_LSTM_OPS_H_\n+\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"tensorflow/stream_executor/stream.h\"\n+\n+namespace tensorflow {\n+\n+#if GOOGLE_CUDA\n+\n+namespace {\n+template <typename T>\n+perftools::gputools::DeviceMemory<T> AsDeviceMemory(const T* cuda_memory) {\n+  perftools::gputools::DeviceMemoryBase wrapped(const_cast<T*>(cuda_memory));\n+  perftools::gputools::DeviceMemory<T> typed(wrapped);\n+  return typed;\n+}\n+}  // namespace\n+\n+#endif  // GOOGLE_CUDA\n+\n+namespace functor {\n+\n+template <typename Device, bool USE_CUBLAS>", "path": "tensorflow/core/kernels/lstm_ops.h", "position": null, "original_position": 26, "commit_id": "258144b98730f99489437f6963737480be4f5a43", "original_commit_id": "8c2b42003f2b630bbbf571878b868fb6d452199b", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "body": "instead of defining USE_CUBLAS, I would partially specialize the implementation of these operators by their device only, since USE_CUBLAS is equivalent to Device=GPUDevice\n", "created_at": "2016-04-21T01:29:35Z", "updated_at": "2016-05-18T21:31:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r60514610", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/60514610"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r60514610"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002"}}, "body_html": "<p>instead of defining USE_CUBLAS, I would partially specialize the implementation of these operators by their device only, since USE_CUBLAS is equivalent to Device=GPUDevice</p>", "body_text": "instead of defining USE_CUBLAS, I would partially specialize the implementation of these operators by their device only, since USE_CUBLAS is equivalent to Device=GPUDevice"}