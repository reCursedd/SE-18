{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/62930300", "pull_request_review_id": null, "id": 62930300, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYyOTMwMzAw", "diff_hunk": "@@ -0,0 +1,310 @@\n+#ifndef TENSORFLOW_KERNELS_LSTM_OPS_H_\n+#define TENSORFLOW_KERNELS_LSTM_OPS_H_\n+\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/lib/core/blocking_counter.h\"\n+#include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n+namespace perftools {\n+namespace gputools {\n+class Stream;\n+}  // end namespace gputools\n+}  // end namespace perftools\n+\n+namespace tensorflow {\n+class OpKernelContext;\n+\n+namespace functor {\n+\n+template <typename Device, typename T>\n+struct TensorMemZero {\n+  void operator()(const Device& d, typename TTypes<T>::Vec x) {\n+    x.device(d) = x.constant(0);\n+  }\n+};\n+\n+template <typename Device, typename T>\n+struct TensorMemCopy {\n+  void operator()(const Device& d, typename TTypes<T>::ConstVec in,\n+                  typename TTypes<T>::Vec out) {\n+    out.device(d) = in;\n+  }\n+};\n+\n+template <typename T>\n+struct TensorCuBlasGemm {\n+  void operator()(\n+      OpKernelContext* ctx, perftools::gputools::Stream* stream,\n+      bool transa, bool transb, uint64 m, uint64 n, uint64 k, T alpha,\n+      const T* a, int lda, const T* b, int ldb, T beta, T *c, int ldc);\n+};\n+\n+template <typename Device, typename T, bool USE_CUBLAS>\n+struct TensorBlasGemm;\n+\n+template <typename Device, typename T>\n+struct TensorBlasGemm<Device, T, true /* USE_CUBLAS */> {\n+  static void compute(\n+      OpKernelContext* ctx, perftools::gputools::Stream* stream,\n+      const Device& d, bool transa, bool transb, T alpha,\n+      typename TTypes<T>::ConstMatrix a, typename TTypes<T>::ConstMatrix b,\n+      T beta, typename TTypes<T>::Matrix c) {\n+    int64 m = c.dimensions()[0];\n+    int64 n = c.dimensions()[1];\n+    int64 k = transa ? a.dimensions()[0] : a.dimensions()[1];\n+\n+    TensorCuBlasGemm<T>()(\n+        ctx, stream, transb, transa, n, m, k, alpha, b.data(),\n+        transb ? k : n, a.data(), transa ? m : k, beta, c.data(), n);\n+  }\n+};\n+\n+template <typename Device, typename T>\n+struct TensorBlasGemm<Device, T, false /* USE_CUBLAS */ > {\n+  static void compute(\n+      OpKernelContext* ctx, perftools::gputools::Stream* stream,\n+      const Device& d, bool transa, bool transb, T alpha,\n+      typename TTypes<T>::ConstMatrix a, typename TTypes<T>::ConstMatrix b,\n+      T beta, typename TTypes<T>::Matrix c) {\n+    Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_pairs;\n+    contract_pairs[0] = Eigen::IndexPair<Eigen::DenseIndex>(\n+        transa == false, transb == true);\n+    if (alpha == T(1) && beta == T(0)) {\n+      c.device(d) = a.contract(b, contract_pairs);\n+    } else if (alpha == T(1) && beta == T(1)) {\n+      c.device(d) += a.contract(b, contract_pairs);\n+    } else {\n+      c.device(d) = c.constant(alpha) * a.contract(b, contract_pairs) +\n+                    c.constant(beta) * c;\n+    }\n+  }\n+};\n+\n+struct LSTMCellBlock {\n+  LSTMCellBlock(const int batch_size, const int input_size, const int cell_size)\n+    : batch_size_(batch_size), input_size_(input_size), cell_size_(cell_size) {}\n+\n+  Eigen::array<int, 2> icfo_i_offsets() const {", "path": "tensorflow/contrib/rnn/kernels/lstm_ops.h", "position": null, "original_position": 90, "commit_id": "258144b98730f99489437f6963737480be4f5a43", "original_commit_id": "fc40971bba82762fe413b5e7d6fe12a09722876b", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "make all these small bits inline?\n", "created_at": "2016-05-11T21:28:27Z", "updated_at": "2016-05-18T21:31:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r62930300", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/62930300"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r62930300"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002"}}, "body_html": "<p>make all these small bits inline?</p>", "body_text": "make all these small bits inline?"}