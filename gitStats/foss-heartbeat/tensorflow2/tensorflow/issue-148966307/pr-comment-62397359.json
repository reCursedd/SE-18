{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/62397359", "pull_request_review_id": null, "id": 62397359, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYyMzk3MzU5", "diff_hunk": "@@ -19,16 +19,90 @@\n from __future__ import print_function\n \n import math\n+import os\n+import threading\n \n+from tensorflow.contrib.rnn.ops import gen_lstm_ops\n+from tensorflow.python.framework import tensor_shape\n from tensorflow.python.framework import ops\n+from tensorflow.python.framework.load_library import load_op_library\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import clip_ops\n+from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n from tensorflow.python.ops import nn_ops\n from tensorflow.python.ops import rnn_cell\n from tensorflow.python.ops import variable_scope as vs\n from tensorflow.python.ops.math_ops import sigmoid\n from tensorflow.python.ops.math_ops import tanh\n+from tensorflow.python.platform import resource_loader\n+\n+\n+LSTM_OPS_FILE = \"_lstm_ops.so\"\n+\n+_lstm_ops = None\n+_ops_lock = threading.Lock()\n+\n+\n+@ops.RegisterShape(\"LSTMCellBlock\")\n+def _LSTMCellBlockShape(op):\n+  batch_size = op.inputs[0].get_shape().with_rank(2)[0].value\n+  cell_size = op.get_attr(\"cell_size\")\n+\n+  return (tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size * 2]),\n+          tensor_shape.TensorShape([batch_size, cell_size]))\n+\n+\n+@ops.RegisterGradient(\"LSTMCellBlock\")\n+def _LSTMCellBlockGrad(op, *grad):\n+  x = op.inputs[0]\n+  states_prev = op.inputs[1]\n+  w = op.inputs[2]\n+  b = op.inputs[3]\n+\n+  i = op.outputs[0]\n+  cs = op.outputs[1]\n+  f = op.outputs[2]\n+  o = op.outputs[3]\n+  ci = op.outputs[4]\n+  co = op.outputs[5]\n+  # states = op.outputs[6]\n+  h = op.outputs[7]\n+\n+  states_grad = grad[6]\n+  h_grad = grad[7]\n+\n+  parallel_dw = op.get_attr(\"parallel_dw\")\n+\n+  (x_grad, states_prev_grad, w_grad, b_grad, dicfo, xh) = gen_lstm_ops._lstm_cell_block_grad(\n+      x, states_prev, w, b, i, cs, f, o, ci, co, h, states_grad, h_grad,\n+      cell_size=op.get_attr(\"cell_size\"), bprop_dx=op.get_attr(\"bprop_dx\"),\n+      parallel_dw=parallel_dw)\n+\n+  if parallel_dw:\n+    w_grad = math_ops.matmul(xh, dicfo, transpose_a=True)\n+    b_grad = nn_ops.bias_add_grad(dicfo)\n+  return (x_grad, states_prev_grad, w_grad, b_grad)\n+\n+\n+@ops.RegisterShape(\"LSTMCellBlockGrad\")\n+def _LSTMCellBlockGradShape(op):\n+  batch_size = op.inputs[0].get_shape().with_rank(2)[0].value\n+  input_size = op.inputs[0].get_shape().with_rank(2)[1].value\n+  cell_size = op.get_attr(\"cell_size\")\n+\n+  return [tensor_shape.TensorShape([batch_size, input_size]),\n+          tensor_shape.TensorShape([batch_size, cell_size * 2]),\n+          tensor_shape.TensorShape([input_size + cell_size, cell_size * 4]),\n+          tensor_shape.TensorShape([cell_size * 4]),\n+          tensor_shape.TensorShape([batch_size, cell_size * 4]),\n+          tensor_shape.TensorShape([batch_size, input_size + cell_size])]\n \n \n def _get_concat_variable(name, shape, dtype, num_shards):", "path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "position": 73, "original_position": 90, "commit_id": "258144b98730f99489437f6963737480be4f5a43", "original_commit_id": "727e0c76bed212fdf240a221e577e1b1a86848d5", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "fyi see the new get_variable partitioner behavior.  you no longer need to worry about sharding yourself.\n", "created_at": "2016-05-06T22:05:28Z", "updated_at": "2016-05-18T21:31:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r62397359", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/62397359"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/2002#discussion_r62397359"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/2002"}}, "body_html": "<p>fyi see the new get_variable partitioner behavior.  you no longer need to worry about sharding yourself.</p>", "body_text": "fyi see the new get_variable partitioner behavior.  you no longer need to worry about sharding yourself."}