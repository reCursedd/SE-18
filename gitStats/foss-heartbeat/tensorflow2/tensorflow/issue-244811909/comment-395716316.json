{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/395716316", "html_url": "https://github.com/tensorflow/tensorflow/issues/11679#issuecomment-395716316", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11679", "id": 395716316, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTcxNjMxNg==", "user": {"login": "annarailton", "id": 4105011, "node_id": "MDQ6VXNlcjQxMDUwMTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/4105011?v=4", "gravatar_id": "", "url": "https://api.github.com/users/annarailton", "html_url": "https://github.com/annarailton", "followers_url": "https://api.github.com/users/annarailton/followers", "following_url": "https://api.github.com/users/annarailton/following{/other_user}", "gists_url": "https://api.github.com/users/annarailton/gists{/gist_id}", "starred_url": "https://api.github.com/users/annarailton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/annarailton/subscriptions", "organizations_url": "https://api.github.com/users/annarailton/orgs", "repos_url": "https://api.github.com/users/annarailton/repos", "events_url": "https://api.github.com/users/annarailton/events{/privacy}", "received_events_url": "https://api.github.com/users/annarailton/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-08T10:10:39Z", "updated_at": "2018-06-08T10:40:19Z", "author_association": "NONE", "body_html": "<p>I was also struggling with this. I tried various things along the lines of what eddiemundo did, writing iterators to collections. I also tried  <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_saveable_from_iterator\" rel=\"nofollow\"><code>tf.contrib.data.make_saveable_from_iterator()</code></a> (I managed to successfully save an iterator here but not get it back!). No success with this approach.</p>\n<p>I eventually realised what youngwoo-yoon meant by \"new iterator\" -  you can just make an entirely new iterator in your restored model and use that instead. You still need to grab the handle from the saved model though and call <code>iterator.string_handle()</code> on the new iterator. Works with both one shot and initialisable iterators.</p>\n<p>Here's a simple example with <code>make_one_shot_iterator()</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Tensorflow 1.8.0</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">save</span>(<span class=\"pl-smi\">dataset</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Create graph with an Dataset and Iterator and save the model.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    There is some op that is applied to the data from the iterator.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    iterator_handle <span class=\"pl-k\">=</span> tf.placeholder(tf.string, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\n    tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>iterator_handle<span class=\"pl-pds\">'</span></span>, iterator_handle)\n\n    iterator <span class=\"pl-k\">=</span> tf.data.Iterator.from_string_handle(\n        iterator_handle,\n        dataset.output_types,\n        dataset.output_shapes)\n    dataset_iterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\n    element <span class=\"pl-k\">=</span> iterator.get_next()\n\n    some_op <span class=\"pl-k\">=</span> tf.multiply(element, <span class=\"pl-c1\">0.5</span>)\n    tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>some_op<span class=\"pl-pds\">'</span></span>, some_op)\n    v <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>v<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.zeros([]))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Needs a variable to save the model</span>\n\n    saver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n        session.run(tf.global_variables_initializer())\n        handle_val <span class=\"pl-k\">=</span> session.run(dataset_iterator.string_handle())\n        <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>):\n            <span class=\"pl-c1\">print</span>(session.run(some_op,\n                <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{iterator_handle: handle_val}))\n        saver.save(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/fufu<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">restore</span>(<span class=\"pl-smi\">dataset</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Restore the model from file and pass some new data through it<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n        saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/fufu.meta<span class=\"pl-pds\">'</span></span>)\n        saver.restore(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/fufu<span class=\"pl-pds\">'</span></span>)\n        iterator_handle <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>iterator_handle<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Make new iterator</span>\n        iterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\n        new_handle <span class=\"pl-k\">=</span> session.run(iterator.string_handle())\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Don't need to call iterator.get_next() again as `some_op` will use</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> restored `element`</span>\n        some_op <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>some_op<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>):\n            <span class=\"pl-c1\">print</span>(session.run(some_op, {iterator_handle: new_handle}))\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n\n    raw_data <span class=\"pl-k\">=</span> np.array([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                     [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n                     [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>],\n                     [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]])\n    dataset1 <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(tf.constant(raw_data, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32))\n    dataset2 <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(tf.constant(raw_data <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32))\n\n    save(dataset1)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Restore works with any data of the same shape in a tf.data.Dataset</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> To use different shaped data use initialisable iterator</span>\n    restore(dataset1)\n    restore(dataset2)</pre></div>", "body_text": "I was also struggling with this. I tried various things along the lines of what eddiemundo did, writing iterators to collections. I also tried  tf.contrib.data.make_saveable_from_iterator() (I managed to successfully save an iterator here but not get it back!). No success with this approach.\nI eventually realised what youngwoo-yoon meant by \"new iterator\" -  you can just make an entirely new iterator in your restored model and use that instead. You still need to grab the handle from the saved model though and call iterator.string_handle() on the new iterator. Works with both one shot and initialisable iterators.\nHere's a simple example with make_one_shot_iterator():\n# Tensorflow 1.8.0\nimport tensorflow as tf\nimport numpy as np\n\ndef save(dataset):\n    \"\"\"\n    Create graph with an Dataset and Iterator and save the model.\n\n    There is some op that is applied to the data from the iterator.\n    \"\"\"\n    iterator_handle = tf.placeholder(tf.string, shape=[])\n    tf.add_to_collection('iterator_handle', iterator_handle)\n\n    iterator = tf.data.Iterator.from_string_handle(\n        iterator_handle,\n        dataset.output_types,\n        dataset.output_shapes)\n    dataset_iterator = dataset.make_one_shot_iterator()\n    element = iterator.get_next()\n\n    some_op = tf.multiply(element, 0.5)\n    tf.add_to_collection('some_op', some_op)\n    v = tf.get_variable('v', initializer=tf.zeros([]))  # Needs a variable to save the model\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as session:\n        session.run(tf.global_variables_initializer())\n        handle_val = session.run(dataset_iterator.string_handle())\n        for _ in range(4):\n            print(session.run(some_op,\n                feed_dict={iterator_handle: handle_val}))\n        saver.save(session, 'checkpoints/fufu')\n\ndef restore(dataset):\n    \"\"\"Restore the model from file and pass some new data through it\"\"\"\n    with tf.Session() as session:\n        saver = tf.train.import_meta_graph('checkpoints/fufu.meta')\n        saver.restore(session, 'checkpoints/fufu')\n        iterator_handle = tf.get_collection('iterator_handle')[0]\n        # Make new iterator\n        iterator = dataset.make_one_shot_iterator()\n        new_handle = session.run(iterator.string_handle())\n        # Don't need to call iterator.get_next() again as `some_op` will use\n        # restored `element`\n        some_op = tf.get_collection('some_op')[0]\n        for _ in range(4):\n            print(session.run(some_op, {iterator_handle: new_handle}))\n\nif __name__ == '__main__':\n\n    raw_data = np.array([[0, 0],\n                     [0, 1],\n                     [1, 0],\n                     [1, 1]])\n    dataset1 = tf.data.Dataset.from_tensor_slices(tf.constant(raw_data, dtype=tf.float32))\n    dataset2 = tf.data.Dataset.from_tensor_slices(tf.constant(raw_data * 2, dtype=tf.float32))\n\n    save(dataset1)\n\n    # Restore works with any data of the same shape in a tf.data.Dataset\n    # To use different shaped data use initialisable iterator\n    restore(dataset1)\n    restore(dataset2)", "body": "I was also struggling with this. I tried various things along the lines of what eddiemundo did, writing iterators to collections. I also tried  [`tf.contrib.data.make_saveable_from_iterator()`](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_saveable_from_iterator) (I managed to successfully save an iterator here but not get it back!). No success with this approach.\r\n\r\nI eventually realised what youngwoo-yoon meant by \"new iterator\" -  you can just make an entirely new iterator in your restored model and use that instead. You still need to grab the handle from the saved model though and call `iterator.string_handle()` on the new iterator. Works with both one shot and initialisable iterators.\r\n\r\nHere's a simple example with `make_one_shot_iterator()`:\r\n\r\n```python\r\n# Tensorflow 1.8.0\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef save(dataset):\r\n    \"\"\"\r\n    Create graph with an Dataset and Iterator and save the model.\r\n\r\n    There is some op that is applied to the data from the iterator.\r\n    \"\"\"\r\n    iterator_handle = tf.placeholder(tf.string, shape=[])\r\n    tf.add_to_collection('iterator_handle', iterator_handle)\r\n\r\n    iterator = tf.data.Iterator.from_string_handle(\r\n        iterator_handle,\r\n        dataset.output_types,\r\n        dataset.output_shapes)\r\n    dataset_iterator = dataset.make_one_shot_iterator()\r\n    element = iterator.get_next()\r\n\r\n    some_op = tf.multiply(element, 0.5)\r\n    tf.add_to_collection('some_op', some_op)\r\n    v = tf.get_variable('v', initializer=tf.zeros([]))  # Needs a variable to save the model\r\n\r\n    saver = tf.train.Saver()\r\n\r\n    with tf.Session() as session:\r\n        session.run(tf.global_variables_initializer())\r\n        handle_val = session.run(dataset_iterator.string_handle())\r\n        for _ in range(4):\r\n            print(session.run(some_op,\r\n                feed_dict={iterator_handle: handle_val}))\r\n        saver.save(session, 'checkpoints/fufu')\r\n\r\ndef restore(dataset):\r\n    \"\"\"Restore the model from file and pass some new data through it\"\"\"\r\n    with tf.Session() as session:\r\n        saver = tf.train.import_meta_graph('checkpoints/fufu.meta')\r\n        saver.restore(session, 'checkpoints/fufu')\r\n        iterator_handle = tf.get_collection('iterator_handle')[0]\r\n        # Make new iterator\r\n        iterator = dataset.make_one_shot_iterator()\r\n        new_handle = session.run(iterator.string_handle())\r\n        # Don't need to call iterator.get_next() again as `some_op` will use\r\n        # restored `element`\r\n        some_op = tf.get_collection('some_op')[0]\r\n        for _ in range(4):\r\n            print(session.run(some_op, {iterator_handle: new_handle}))\r\n\r\nif __name__ == '__main__':\r\n\r\n    raw_data = np.array([[0, 0],\r\n                     [0, 1],\r\n                     [1, 0],\r\n                     [1, 1]])\r\n    dataset1 = tf.data.Dataset.from_tensor_slices(tf.constant(raw_data, dtype=tf.float32))\r\n    dataset2 = tf.data.Dataset.from_tensor_slices(tf.constant(raw_data * 2, dtype=tf.float32))\r\n\r\n    save(dataset1)\r\n\r\n    # Restore works with any data of the same shape in a tf.data.Dataset\r\n    # To use different shaped data use initialisable iterator\r\n    restore(dataset1)\r\n    restore(dataset2)\r\n```"}