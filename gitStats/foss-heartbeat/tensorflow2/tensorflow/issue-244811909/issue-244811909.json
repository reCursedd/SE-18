{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11679", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11679/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11679/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11679/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11679", "id": 244811909, "node_id": "MDU6SXNzdWUyNDQ4MTE5MDk=", "number": 11679, "title": "Error when running imported/restored model that uses feedable iterator (tf.contrib.data)", "user": {"login": "eddiemundo", "id": 929157, "node_id": "MDQ6VXNlcjkyOTE1Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/929157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddiemundo", "html_url": "https://github.com/eddiemundo", "followers_url": "https://api.github.com/users/eddiemundo/followers", "following_url": "https://api.github.com/users/eddiemundo/following{/other_user}", "gists_url": "https://api.github.com/users/eddiemundo/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddiemundo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddiemundo/subscriptions", "organizations_url": "https://api.github.com/users/eddiemundo/orgs", "repos_url": "https://api.github.com/users/eddiemundo/repos", "events_url": "https://api.github.com/users/eddiemundo/events{/privacy}", "received_events_url": "https://api.github.com/users/eddiemundo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-07-22T00:34:57Z", "updated_at": "2018-06-18T16:23:02Z", "closed_at": "2017-07-22T06:39:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: Build <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"117135596\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/242\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/242/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/242\">#242</a> (Jul 17, 2017 2:25:00 AM)</li>\n<li><strong>Python version</strong>: Python 3.6.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: na</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6.0</li>\n<li><strong>GPU model and memory</strong>: 670 gtx 2gb</li>\n<li><strong>Exact command to reproduce</strong>: na</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I can't restore and run checkpoints of models that use feedable iterators, but I can restore and run checkpoints of models that directly use <code>make_one_shot_iterator()</code>. Below is code for the feedable iterator version, and below that code for the <code>make_one_shot_iterator()</code> version:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.data <span class=\"pl-k\">import</span> Dataset\n\n<span class=\"pl-c1\">BATCH_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\n<span class=\"pl-c1\">ITERATION_COUNT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\ndataset <span class=\"pl-k\">=</span> Dataset.from_tensor_slices(tf.constant([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                  [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n                                                  [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>],\n                                                  [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32))\nbatched_dataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">BATCH_SIZE</span>)\niterator_handle_placeholder <span class=\"pl-k\">=</span> tf.placeholder(tf.string, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\ntf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>, iterator_handle_placeholder)\niterator <span class=\"pl-k\">=</span> tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> create some graph</span>\ninputs <span class=\"pl-k\">=</span> iterator.get_next()\nsum_placeholder <span class=\"pl-k\">=</span> tf.placeholder_with_default(tf.reduce_sum(inputs), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\ntf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>, sum_placeholder)\nsum_variable <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>sum<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[]))\nassign_sum <span class=\"pl-k\">=</span> tf.assign_add(sum_variable, sum_placeholder)\ntf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>assigns<span class=\"pl-pds\">'</span></span>, assign_sum)\nsaver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run graph and save it at the end</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n    session.run(tf.global_variables_initializer())\n    batched_dataset_iterator <span class=\"pl-k\">=</span> batched_dataset.make_one_shot_iterator()\n    batched_dataset_iterator_handle <span class=\"pl-k\">=</span> session.run(batched_dataset_iterator.string_handle())\n    tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>handles<span class=\"pl-pds\">'</span></span>, batched_dataset_iterator_handle)\n    inputs_feed_dict <span class=\"pl-k\">=</span> {iterator_handle_placeholder: batched_dataset_iterator_handle}\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">ITERATION_COUNT</span>):\n        inputs_sum <span class=\"pl-k\">=</span> session.run(assign_sum, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>inputs_feed_dict)\n        inputs_feed_dict[sum_placeholder] <span class=\"pl-k\">=</span> inputs_sum\n        <span class=\"pl-c1\">print</span>(inputs_sum)\n    saver.save(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> restore saved graph and run it</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n    saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha.meta<span class=\"pl-pds\">'</span></span>)\n    saver.restore(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha<span class=\"pl-pds\">'</span></span>)\n    assign_sum <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>assigns<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n    iterator_handle_placeholder <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n    batched_dataset_iterator_handle <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>handles<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n    sum_placeholder <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">1</span>]\n    inputs_feed_dict <span class=\"pl-k\">=</span> {iterator_handle_placeholder: batched_dataset_iterator_handle}\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">ITERATION_COUNT</span>):\n        inputs_sum <span class=\"pl-k\">=</span> session.run(assign_sum, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>inputs_feed_dict)\n        <span class=\"pl-c1\">print</span>(inputs_sum)\n        inputs_feed_dict[sum_placeholder] <span class=\"pl-k\">=</span> inputs_sum</pre></div>\n<p>gives me</p>\n<pre><code>C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\n2017-07-21 20:18:54.013753: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-21 20:18:54.257354: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \nname: GeForce GTX 670\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\npciBusID 0000:02:00.0\nTotal memory: 2.00GiB\nFree memory: 1.64GiB\n2017-07-21 20:18:54.257634: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \n2017-07-21 20:18:54.257773: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \n2017-07-21 20:18:54.257935: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n4.0\n8.0\n2017-07-21 20:18:54.705095: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n2017-07-21 20:18:54.774833: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Not found: Container localhost does not exist.\nTraceback (most recent call last):\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n    return fn(*args)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n    status, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\contextlib.py\", line 88, in __exit__\n    next(self.gen)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 47, in &lt;module&gt;\n    inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'IteratorFromStringHandle', defined at:\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 13, in &lt;module&gt;\n    iterator = tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 238, in from_string_handle\n    string_handle)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 362, in iterator_from_string_handle\n    string_handle=string_handle, name=name)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2628, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\n\nProcess finished with exit code 1\n</code></pre>\n<p>Here's the version that uses just a <code>make_one_shot_iterator()</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.data <span class=\"pl-k\">import</span> Dataset\n\n<span class=\"pl-c1\">BATCH_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\n<span class=\"pl-c1\">ITERATION_COUNT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\ndataset <span class=\"pl-k\">=</span> Dataset.from_tensor_slices(tf.constant([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                  [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n                                                  [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>],\n                                                  [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32))\nbatched_dataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">BATCH_SIZE</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> create some graph</span>\nbatched_dataset_iterator <span class=\"pl-k\">=</span> batched_dataset.make_one_shot_iterator()\ninputs <span class=\"pl-k\">=</span> batched_dataset_iterator.get_next()\nsum_placeholder <span class=\"pl-k\">=</span> tf.placeholder_with_default(tf.reduce_sum(inputs), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[])\ntf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>, sum_placeholder)\nsum_variable <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>sum<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[]))\nassign_sum <span class=\"pl-k\">=</span> tf.assign_add(sum_variable, sum_placeholder)\ntf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>assigns<span class=\"pl-pds\">'</span></span>, assign_sum)\nsaver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> run graph and save it at the end</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n    session.run(tf.global_variables_initializer())\n    inputs_feed_dict <span class=\"pl-k\">=</span> {}\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">ITERATION_COUNT</span>):\n        inputs_sum <span class=\"pl-k\">=</span> session.run(assign_sum, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>inputs_feed_dict)\n        inputs_feed_dict[sum_placeholder] <span class=\"pl-k\">=</span> inputs_sum\n        <span class=\"pl-c1\">print</span>(inputs_sum)\n    saver.save(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> restore saved graph and run it</span>\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n    saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha.meta<span class=\"pl-pds\">'</span></span>)\n    saver.restore(session, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoints/haha<span class=\"pl-pds\">'</span></span>)\n    assign_sum <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>assigns<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n    sum_placeholder <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>placeholders<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">1</span>]\n    inputs_feed_dict <span class=\"pl-k\">=</span> {}\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">ITERATION_COUNT</span>):\n        inputs_sum <span class=\"pl-k\">=</span> session.run(assign_sum, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>inputs_feed_dict)\n        <span class=\"pl-c1\">print</span>(inputs_sum)\n        inputs_feed_dict[sum_placeholder] <span class=\"pl-k\">=</span> inputs_sum</pre></div>\n<p>Result:</p>\n<pre><code>C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\n2017-07-21 20:12:26.273776: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-21 20:12:26.516570: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \nname: GeForce GTX 670\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\npciBusID 0000:02:00.0\nTotal memory: 2.00GiB\nFree memory: 1.64GiB\n2017-07-21 20:12:26.516852: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \n2017-07-21 20:12:26.516992: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \n2017-07-21 20:12:26.517145: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n4.0\n8.0\n2017-07-21 20:12:26.926502: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n12.0\n24.0\n\nProcess finished with exit code 0\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): Build #242 (Jul 17, 2017 2:25:00 AM)\nPython version: Python 3.6.2\nBazel version (if compiling from source): na\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory: 670 gtx 2gb\nExact command to reproduce: na\n\nDescribe the problem\nI can't restore and run checkpoints of models that use feedable iterators, but I can restore and run checkpoints of models that directly use make_one_shot_iterator(). Below is code for the feedable iterator version, and below that code for the make_one_shot_iterator() version:\nimport tensorflow as tf\nfrom tensorflow.contrib.data import Dataset\n\nBATCH_SIZE = 4\nITERATION_COUNT = 2\ndataset = Dataset.from_tensor_slices(tf.constant([[0, 0],\n                                                  [0, 1],\n                                                  [1, 0],\n                                                  [1, 1]], dtype=tf.float32))\nbatched_dataset = dataset.batch(BATCH_SIZE)\niterator_handle_placeholder = tf.placeholder(tf.string, shape=[])\ntf.add_to_collection('placeholders', iterator_handle_placeholder)\niterator = tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\n\n# create some graph\ninputs = iterator.get_next()\nsum_placeholder = tf.placeholder_with_default(tf.reduce_sum(inputs), shape=[])\ntf.add_to_collection('placeholders', sum_placeholder)\nsum_variable = tf.get_variable('sum', initializer=tf.zeros(shape=[]))\nassign_sum = tf.assign_add(sum_variable, sum_placeholder)\ntf.add_to_collection('assigns', assign_sum)\nsaver = tf.train.Saver()\n\n# run graph and save it at the end\nwith tf.Session() as session:\n    session.run(tf.global_variables_initializer())\n    batched_dataset_iterator = batched_dataset.make_one_shot_iterator()\n    batched_dataset_iterator_handle = session.run(batched_dataset_iterator.string_handle())\n    tf.add_to_collection('handles', batched_dataset_iterator_handle)\n    inputs_feed_dict = {iterator_handle_placeholder: batched_dataset_iterator_handle}\n    for i in range(ITERATION_COUNT):\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n        inputs_feed_dict[sum_placeholder] = inputs_sum\n        print(inputs_sum)\n    saver.save(session, 'checkpoints/haha')\n\n# restore saved graph and run it\nwith tf.Session() as session:\n    saver = tf.train.import_meta_graph('checkpoints/haha.meta')\n    saver.restore(session, 'checkpoints/haha')\n    assign_sum = tf.get_collection('assigns')[0]\n    iterator_handle_placeholder = tf.get_collection('placeholders')[0]\n    batched_dataset_iterator_handle = tf.get_collection('handles')[0]\n    sum_placeholder = tf.get_collection('placeholders')[1]\n    inputs_feed_dict = {iterator_handle_placeholder: batched_dataset_iterator_handle}\n    for i in range(ITERATION_COUNT):\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n        print(inputs_sum)\n        inputs_feed_dict[sum_placeholder] = inputs_sum\ngives me\nC:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\n2017-07-21 20:18:54.013753: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-21 20:18:54.257354: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \nname: GeForce GTX 670\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\npciBusID 0000:02:00.0\nTotal memory: 2.00GiB\nFree memory: 1.64GiB\n2017-07-21 20:18:54.257634: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \n2017-07-21 20:18:54.257773: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \n2017-07-21 20:18:54.257935: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n4.0\n8.0\n2017-07-21 20:18:54.705095: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n2017-07-21 20:18:54.774833: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Not found: Container localhost does not exist.\nTraceback (most recent call last):\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n    return fn(*args)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n    status, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\contextlib.py\", line 88, in __exit__\n    next(self.gen)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 47, in <module>\n    inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'IteratorFromStringHandle', defined at:\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 13, in <module>\n    iterator = tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 238, in from_string_handle\n    string_handle)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 362, in iterator_from_string_handle\n    string_handle=string_handle, name=name)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2628, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Container localhost does not exist.\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\n\nProcess finished with exit code 1\n\nHere's the version that uses just a make_one_shot_iterator():\nimport tensorflow as tf\nfrom tensorflow.contrib.data import Dataset\n\nBATCH_SIZE = 4\nITERATION_COUNT = 2\ndataset = Dataset.from_tensor_slices(tf.constant([[0, 0],\n                                                  [0, 1],\n                                                  [1, 0],\n                                                  [1, 1]], dtype=tf.float32))\nbatched_dataset = dataset.batch(BATCH_SIZE)\n\n# create some graph\nbatched_dataset_iterator = batched_dataset.make_one_shot_iterator()\ninputs = batched_dataset_iterator.get_next()\nsum_placeholder = tf.placeholder_with_default(tf.reduce_sum(inputs), shape=[])\ntf.add_to_collection('placeholders', sum_placeholder)\nsum_variable = tf.get_variable('sum', initializer=tf.zeros(shape=[]))\nassign_sum = tf.assign_add(sum_variable, sum_placeholder)\ntf.add_to_collection('assigns', assign_sum)\nsaver = tf.train.Saver()\n\n# run graph and save it at the end\nwith tf.Session() as session:\n    session.run(tf.global_variables_initializer())\n    inputs_feed_dict = {}\n    for i in range(ITERATION_COUNT):\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n        inputs_feed_dict[sum_placeholder] = inputs_sum\n        print(inputs_sum)\n    saver.save(session, 'checkpoints/haha')\n\n# restore saved graph and run it\nwith tf.Session() as session:\n    saver = tf.train.import_meta_graph('checkpoints/haha.meta')\n    saver.restore(session, 'checkpoints/haha')\n    assign_sum = tf.get_collection('assigns')[0]\n    sum_placeholder = tf.get_collection('placeholders')[1]\n    inputs_feed_dict = {}\n    for i in range(ITERATION_COUNT):\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\n        print(inputs_sum)\n        inputs_feed_dict[sum_placeholder] = inputs_sum\nResult:\nC:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\n2017-07-21 20:12:26.273776: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-07-21 20:12:26.516570: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \nname: GeForce GTX 670\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\npciBusID 0000:02:00.0\nTotal memory: 2.00GiB\nFree memory: 1.64GiB\n2017-07-21 20:12:26.516852: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \n2017-07-21 20:12:26.516992: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \n2017-07-21 20:12:26.517145: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n4.0\n8.0\n2017-07-21 20:12:26.926502: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\n12.0\n24.0\n\nProcess finished with exit code 0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: Build #242 (Jul 17, 2017 2:25:00 AM)\r\n- **Python version**: Python 3.6.2\r\n- **Bazel version (if compiling from source)**: na\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: 670 gtx 2gb\r\n- **Exact command to reproduce**: na\r\n\r\n### Describe the problem\r\nI can't restore and run checkpoints of models that use feedable iterators, but I can restore and run checkpoints of models that directly use `make_one_shot_iterator()`. Below is code for the feedable iterator version, and below that code for the `make_one_shot_iterator()` version:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.data import Dataset\r\n\r\nBATCH_SIZE = 4\r\nITERATION_COUNT = 2\r\ndataset = Dataset.from_tensor_slices(tf.constant([[0, 0],\r\n                                                  [0, 1],\r\n                                                  [1, 0],\r\n                                                  [1, 1]], dtype=tf.float32))\r\nbatched_dataset = dataset.batch(BATCH_SIZE)\r\niterator_handle_placeholder = tf.placeholder(tf.string, shape=[])\r\ntf.add_to_collection('placeholders', iterator_handle_placeholder)\r\niterator = tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\r\n\r\n# create some graph\r\ninputs = iterator.get_next()\r\nsum_placeholder = tf.placeholder_with_default(tf.reduce_sum(inputs), shape=[])\r\ntf.add_to_collection('placeholders', sum_placeholder)\r\nsum_variable = tf.get_variable('sum', initializer=tf.zeros(shape=[]))\r\nassign_sum = tf.assign_add(sum_variable, sum_placeholder)\r\ntf.add_to_collection('assigns', assign_sum)\r\nsaver = tf.train.Saver()\r\n\r\n# run graph and save it at the end\r\nwith tf.Session() as session:\r\n    session.run(tf.global_variables_initializer())\r\n    batched_dataset_iterator = batched_dataset.make_one_shot_iterator()\r\n    batched_dataset_iterator_handle = session.run(batched_dataset_iterator.string_handle())\r\n    tf.add_to_collection('handles', batched_dataset_iterator_handle)\r\n    inputs_feed_dict = {iterator_handle_placeholder: batched_dataset_iterator_handle}\r\n    for i in range(ITERATION_COUNT):\r\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\r\n        inputs_feed_dict[sum_placeholder] = inputs_sum\r\n        print(inputs_sum)\r\n    saver.save(session, 'checkpoints/haha')\r\n\r\n# restore saved graph and run it\r\nwith tf.Session() as session:\r\n    saver = tf.train.import_meta_graph('checkpoints/haha.meta')\r\n    saver.restore(session, 'checkpoints/haha')\r\n    assign_sum = tf.get_collection('assigns')[0]\r\n    iterator_handle_placeholder = tf.get_collection('placeholders')[0]\r\n    batched_dataset_iterator_handle = tf.get_collection('handles')[0]\r\n    sum_placeholder = tf.get_collection('placeholders')[1]\r\n    inputs_feed_dict = {iterator_handle_placeholder: batched_dataset_iterator_handle}\r\n    for i in range(ITERATION_COUNT):\r\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\r\n        print(inputs_sum)\r\n        inputs_feed_dict[sum_placeholder] = inputs_sum\r\n```\r\ngives me\r\n```\r\nC:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\r\n2017-07-21 20:18:54.013753: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-21 20:18:54.257354: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \r\nname: GeForce GTX 670\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\r\npciBusID 0000:02:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.64GiB\r\n2017-07-21 20:18:54.257634: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \r\n2017-07-21 20:18:54.257773: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \r\n2017-07-21 20:18:54.257935: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\r\n4.0\r\n8.0\r\n2017-07-21 20:18:54.705095: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\r\n2017-07-21 20:18:54.774833: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Not found: Container localhost does not exist.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\r\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\r\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 47, in <module>\r\n    inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Container localhost does not exist.\r\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\r\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op 'IteratorFromStringHandle', defined at:\r\n  File \"C:/Software Projects/ai/tensorflow/LayerTests.py\", line 13, in <module>\r\n    iterator = tf.contrib.data.Iterator.from_string_handle(iterator_handle_placeholder, batched_dataset.output_types, batched_dataset.output_shapes)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 238, in from_string_handle\r\n    string_handle)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 362, in iterator_from_string_handle\r\n    string_handle=string_handle, name=name)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2628, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Container localhost does not exist.\r\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_Placeholder_0_0)]]\r\n\t [[Node: PlaceholderWithDefault/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_7_PlaceholderWithDefault\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\n\r\nProcess finished with exit code 1\r\n```\r\nHere's the version that uses just a `make_one_shot_iterator()`:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.data import Dataset\r\n\r\nBATCH_SIZE = 4\r\nITERATION_COUNT = 2\r\ndataset = Dataset.from_tensor_slices(tf.constant([[0, 0],\r\n                                                  [0, 1],\r\n                                                  [1, 0],\r\n                                                  [1, 1]], dtype=tf.float32))\r\nbatched_dataset = dataset.batch(BATCH_SIZE)\r\n\r\n# create some graph\r\nbatched_dataset_iterator = batched_dataset.make_one_shot_iterator()\r\ninputs = batched_dataset_iterator.get_next()\r\nsum_placeholder = tf.placeholder_with_default(tf.reduce_sum(inputs), shape=[])\r\ntf.add_to_collection('placeholders', sum_placeholder)\r\nsum_variable = tf.get_variable('sum', initializer=tf.zeros(shape=[]))\r\nassign_sum = tf.assign_add(sum_variable, sum_placeholder)\r\ntf.add_to_collection('assigns', assign_sum)\r\nsaver = tf.train.Saver()\r\n\r\n# run graph and save it at the end\r\nwith tf.Session() as session:\r\n    session.run(tf.global_variables_initializer())\r\n    inputs_feed_dict = {}\r\n    for i in range(ITERATION_COUNT):\r\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\r\n        inputs_feed_dict[sum_placeholder] = inputs_sum\r\n        print(inputs_sum)\r\n    saver.save(session, 'checkpoints/haha')\r\n\r\n# restore saved graph and run it\r\nwith tf.Session() as session:\r\n    saver = tf.train.import_meta_graph('checkpoints/haha.meta')\r\n    saver.restore(session, 'checkpoints/haha')\r\n    assign_sum = tf.get_collection('assigns')[0]\r\n    sum_placeholder = tf.get_collection('placeholders')[1]\r\n    inputs_feed_dict = {}\r\n    for i in range(ITERATION_COUNT):\r\n        inputs_sum = session.run(assign_sum, feed_dict=inputs_feed_dict)\r\n        print(inputs_sum)\r\n        inputs_feed_dict[sum_placeholder] = inputs_sum\r\n```\r\nResult:\r\n```\r\nC:\\Users\\Jonathan\\Miniconda3\\envs\\ai\\python.exe \"C:/Software Projects/ai/tensorflow/LayerTests.py\"\r\n2017-07-21 20:12:26.273776: W C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-21 20:12:26.516570: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties: \r\nname: GeForce GTX 670\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.98\r\npciBusID 0000:02:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.64GiB\r\n2017-07-21 20:12:26.516852: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 \r\n2017-07-21 20:12:26.516992: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y \r\n2017-07-21 20:12:26.517145: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\r\n4.0\r\n8.0\r\n2017-07-21 20:12:26.926502: I C:\\tf_jenkins\\home\\workspace\\nightly-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:02:00.0)\r\n12.0\r\n24.0\r\n\r\nProcess finished with exit code 0\r\n```"}