{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305101419", "html_url": "https://github.com/tensorflow/tensorflow/issues/9906#issuecomment-305101419", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9906", "id": 305101419, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTEwMTQxOQ==", "user": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-31T06:54:27Z", "updated_at": "2017-05-31T06:59:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The queue and enqueue ops don't need to be replicated; only dequeue node is replicated, so that multiple GPUs could dequeue/work in parallel. If there is a lot of preprocessing for input data, you may consider using more threads for input preprocessing, so that it keeps up the GPU computations.</p>\n<p>The time for applying gradients depends on the models. For small models, it may become a bottleneck; for larger models like the PTB one, it takes relatively a small portion of total time, and you can expect about 1.7x speedup using 2 GPUs. Could you label each row in the picture, and name/mark the related ops?</p>", "body_text": "The queue and enqueue ops don't need to be replicated; only dequeue node is replicated, so that multiple GPUs could dequeue/work in parallel. If there is a lot of preprocessing for input data, you may consider using more threads for input preprocessing, so that it keeps up the GPU computations.\nThe time for applying gradients depends on the models. For small models, it may become a bottleneck; for larger models like the PTB one, it takes relatively a small portion of total time, and you can expect about 1.7x speedup using 2 GPUs. Could you label each row in the picture, and name/mark the related ops?", "body": "The queue and enqueue ops don't need to be replicated; only dequeue node is replicated, so that multiple GPUs could dequeue/work in parallel. If there is a lot of preprocessing for input data, you may consider using more threads for input preprocessing, so that it keeps up the GPU computations.\r\n\r\nThe time for applying gradients depends on the models. For small models, it may become a bottleneck; for larger models like the PTB one, it takes relatively a small portion of total time, and you can expect about 1.7x speedup using 2 GPUs. Could you label each row in the picture, and name/mark the related ops?\r\n\r\n"}