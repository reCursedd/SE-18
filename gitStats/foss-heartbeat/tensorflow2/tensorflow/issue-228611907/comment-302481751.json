{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302481751", "html_url": "https://github.com/tensorflow/tensorflow/issues/9906#issuecomment-302481751", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9906", "id": 302481751, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjQ4MTc1MQ==", "user": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-18T17:22:34Z", "updated_at": "2017-05-18T17:24:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>These two Assign nodes could be initializers for two variables. There are two collections in MetaGraphDef, \"trainable_variables\" and \"variables\", where you have a list of VariableDef including a field initializer_name for the corresponding initialization node. After you import the MetaGraphDef, these two collections should be preserved and you can run all initialization nodes in VariableDef.</p>\n<p>Could you be more specific about why queue_running doesn't work with MonitoredTrainingSession? Looks like MonitoredTrainingSession uses queue runner. <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L541\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L541</a></p>\n<p>Yes, follow-up work will support multiple machines with both synchronous and async training; it may take some time for us to get there. For now, I'm not sure if using AutoParallel within a machine on multiple devices could be combined with a machine-level parallelization with SyncReplicasOptimizer; looks like they two should be compatible.</p>", "body_text": "These two Assign nodes could be initializers for two variables. There are two collections in MetaGraphDef, \"trainable_variables\" and \"variables\", where you have a list of VariableDef including a field initializer_name for the corresponding initialization node. After you import the MetaGraphDef, these two collections should be preserved and you can run all initialization nodes in VariableDef.\nCould you be more specific about why queue_running doesn't work with MonitoredTrainingSession? Looks like MonitoredTrainingSession uses queue runner. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L541\nYes, follow-up work will support multiple machines with both synchronous and async training; it may take some time for us to get there. For now, I'm not sure if using AutoParallel within a machine on multiple devices could be combined with a machine-level parallelization with SyncReplicasOptimizer; looks like they two should be compatible.", "body": "These two Assign nodes could be initializers for two variables. There are two collections in MetaGraphDef, \"trainable_variables\" and \"variables\", where you have a list of VariableDef including a field initializer_name for the corresponding initialization node. After you import the MetaGraphDef, these two collections should be preserved and you can run all initialization nodes in VariableDef.\r\n\r\nCould you be more specific about why queue_running doesn't work with MonitoredTrainingSession? Looks like MonitoredTrainingSession uses queue runner. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L541\r\n\r\nYes, follow-up work will support multiple machines with both synchronous and async training; it may take some time for us to get there. For now, I'm not sure if using AutoParallel within a machine on multiple devices could be combined with a machine-level parallelization with SyncReplicasOptimizer; looks like they two should be compatible."}