{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/405666646", "html_url": "https://github.com/tensorflow/tensorflow/issues/20805#issuecomment-405666646", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20805", "id": 405666646, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTY2NjY0Ng==", "user": {"login": "raymond-yuan", "id": 17325195, "node_id": "MDQ6VXNlcjE3MzI1MTk1", "avatar_url": "https://avatars1.githubusercontent.com/u/17325195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raymond-yuan", "html_url": "https://github.com/raymond-yuan", "followers_url": "https://api.github.com/users/raymond-yuan/followers", "following_url": "https://api.github.com/users/raymond-yuan/following{/other_user}", "gists_url": "https://api.github.com/users/raymond-yuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/raymond-yuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raymond-yuan/subscriptions", "organizations_url": "https://api.github.com/users/raymond-yuan/orgs", "repos_url": "https://api.github.com/users/raymond-yuan/repos", "events_url": "https://api.github.com/users/raymond-yuan/events{/privacy}", "received_events_url": "https://api.github.com/users/raymond-yuan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-17T17:42:44Z", "updated_at": "2018-07-17T17:44:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10966954\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nairouz\">@nairouz</a> I'm sorry can you clarify what the second undesirable behavior is and what code you used to reproduce the error? Is it that when defining your own custom layer's <code>build</code> or <code>compute_output_shape</code> function you found that you had to provide the argument <code>value</code> instead of <code>input_shape</code>?</p>\n<pre><code>class MyLayer(keras.layers.Layer):\n\n  def __init__(self, output_dim, **kwargs):\n    self.output_dim = output_dim\n    super(MyLayer, self).__init__(**kwargs)\n\n  def build(self, input_shape):\n    shape = tf.TensorShape((input_shape[1], self.output_dim))\n    # Create a trainable weight variable for this layer.\n    self.kernel = self.add_weight(name='kernel',\n                                  shape=shape,\n                                  initializer='uniform',\n                                  trainable=True)\n    # Be sure to call this at the end\n    super(MyLayer, self).build(input_shape)\n\n  def call(self, inputs):\n    return tf.matmul(inputs, self.kernel)\n\n  def compute_output_shape(self, input_shape):\n    shape = tf.TensorShape(input_shape).as_list()\n    shape[-1] = self.output_dim\n    return tf.TensorShape(shape)\n\n  def get_config(self):\n    base_config = super(MyLayer, self).get_config()\n    base_config['output_dim'] = self.output_dim\n\n  @classmethod\n  def from_config(cls, config):\n    return cls(**config)\n\ninput1 = layers.Input(shape=(10,), name=\"input\")\nlayer = MyLayer(output_dim=5, name='clustering')\nout = layer(input1)\nprint(out)\n</code></pre>\n<p>For reference, this example does not need <code>value</code> and works.</p>", "body_text": "@nairouz I'm sorry can you clarify what the second undesirable behavior is and what code you used to reproduce the error? Is it that when defining your own custom layer's build or compute_output_shape function you found that you had to provide the argument value instead of input_shape?\nclass MyLayer(keras.layers.Layer):\n\n  def __init__(self, output_dim, **kwargs):\n    self.output_dim = output_dim\n    super(MyLayer, self).__init__(**kwargs)\n\n  def build(self, input_shape):\n    shape = tf.TensorShape((input_shape[1], self.output_dim))\n    # Create a trainable weight variable for this layer.\n    self.kernel = self.add_weight(name='kernel',\n                                  shape=shape,\n                                  initializer='uniform',\n                                  trainable=True)\n    # Be sure to call this at the end\n    super(MyLayer, self).build(input_shape)\n\n  def call(self, inputs):\n    return tf.matmul(inputs, self.kernel)\n\n  def compute_output_shape(self, input_shape):\n    shape = tf.TensorShape(input_shape).as_list()\n    shape[-1] = self.output_dim\n    return tf.TensorShape(shape)\n\n  def get_config(self):\n    base_config = super(MyLayer, self).get_config()\n    base_config['output_dim'] = self.output_dim\n\n  @classmethod\n  def from_config(cls, config):\n    return cls(**config)\n\ninput1 = layers.Input(shape=(10,), name=\"input\")\nlayer = MyLayer(output_dim=5, name='clustering')\nout = layer(input1)\nprint(out)\n\nFor reference, this example does not need value and works.", "body": "@nairouz I'm sorry can you clarify what the second undesirable behavior is and what code you used to reproduce the error? Is it that when defining your own custom layer's `build` or `compute_output_shape` function you found that you had to provide the argument `value` instead of `input_shape`?\r\n\r\n```\r\nclass MyLayer(keras.layers.Layer):\r\n\r\n  def __init__(self, output_dim, **kwargs):\r\n    self.output_dim = output_dim\r\n    super(MyLayer, self).__init__(**kwargs)\r\n\r\n  def build(self, input_shape):\r\n    shape = tf.TensorShape((input_shape[1], self.output_dim))\r\n    # Create a trainable weight variable for this layer.\r\n    self.kernel = self.add_weight(name='kernel',\r\n                                  shape=shape,\r\n                                  initializer='uniform',\r\n                                  trainable=True)\r\n    # Be sure to call this at the end\r\n    super(MyLayer, self).build(input_shape)\r\n\r\n  def call(self, inputs):\r\n    return tf.matmul(inputs, self.kernel)\r\n\r\n  def compute_output_shape(self, input_shape):\r\n    shape = tf.TensorShape(input_shape).as_list()\r\n    shape[-1] = self.output_dim\r\n    return tf.TensorShape(shape)\r\n\r\n  def get_config(self):\r\n    base_config = super(MyLayer, self).get_config()\r\n    base_config['output_dim'] = self.output_dim\r\n\r\n  @classmethod\r\n  def from_config(cls, config):\r\n    return cls(**config)\r\n\r\ninput1 = layers.Input(shape=(10,), name=\"input\")\r\nlayer = MyLayer(output_dim=5, name='clustering')\r\nout = layer(input1)\r\nprint(out)\r\n```\r\nFor reference, this example does not need `value` and works. \r\n"}