{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275470982", "html_url": "https://github.com/tensorflow/tensorflow/issues/7025#issuecomment-275470982", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7025", "id": 275470982, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTQ3MDk4Mg==", "user": {"login": "laventura", "id": 419789, "node_id": "MDQ6VXNlcjQxOTc4OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/419789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/laventura", "html_url": "https://github.com/laventura", "followers_url": "https://api.github.com/users/laventura/followers", "following_url": "https://api.github.com/users/laventura/following{/other_user}", "gists_url": "https://api.github.com/users/laventura/gists{/gist_id}", "starred_url": "https://api.github.com/users/laventura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/laventura/subscriptions", "organizations_url": "https://api.github.com/users/laventura/orgs", "repos_url": "https://api.github.com/users/laventura/repos", "events_url": "https://api.github.com/users/laventura/events{/privacy}", "received_events_url": "https://api.github.com/users/laventura/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-26T18:32:35Z", "updated_at": "2017-01-26T18:32:35Z", "author_association": "NONE", "body_html": "<p>Hi  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a></p>\n<p>I'm getting this <code>Dst Tensor Not Initialized</code> error.</p>\n<p>(See my comment (the last one)  in this issue elsewhere: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"158536133\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/aymericdamien/TensorFlow-Examples/issues/38\" data-hovercard-type=\"issue\" data-hovercard-url=\"/aymericdamien/TensorFlow-Examples/issues/38/hovercard\" href=\"https://github.com/aymericdamien/TensorFlow-Examples/issues/38\">aymericdamien/TensorFlow-Examples#38</a>)</p>\n<p>I'm reproducing the stack trace here in case it helps diagnose the issue:</p>\n<pre><code>\u25b6 python imagenet_inference.py \nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 305.92MiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0 97.01MiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 144.00MiB was 128.00MiB, Chunk State: \nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60000 of size 1280\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60500 of size 139520\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82600 of size 512\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82800 of size 1228800\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700bae800 of size 1024\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700baec00 of size 3538944\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0ec00 of size 1536\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0f200 of size 2654208\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197200 of size 1536\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197800 of size 1769472\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701347800 of size 1024\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x701347c00 of size 101725184\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 512 totalling 512B\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1024 totalling 2.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1536 totalling 3.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 139520 totalling 136.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1228800 totalling 1.17MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1769472 totalling 1.69MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2654208 totalling 2.53MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3538944 totalling 3.38MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 8.91MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                   111063040\nInUse:                     9337856\nMaxInUse:                  9337856\nNumAllocs:                      11\nMaxAllocSize:              3538944\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] *********___________________________________________________________________________________________\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 144.00MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:965] Internal: Dst tensor is not initialized.\nE tensorflow/core/common_runtime/executor.cc:390] Executor failed to create kernel. Internal: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...&gt;, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...&gt;, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"imagenet_inference.py\", line 19, in &lt;module&gt;\n    sess.run(init)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...&gt;, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'Variable_10/initial_value', defined at:\n  File \"imagenet_inference.py\", line 16, in &lt;module&gt;\n    probs = AlexNet(x, feature_extract=False)\n  File \"/Users/aa/Developer/courses/self_driving_carnd/traffic-signs/CarND-Alexnet-Feature-Extraction/alexnet.py\", line 139, in AlexNet\n    fc6W = tf.Variable(net_data[\"fc6\"][0])\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\n    expected_shape=expected_shape)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 333, in _init_from_args\n    initial_value, name=\"initial_value\", dtype=dtype)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...&gt;, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\n</code></pre>\n<p>Here's deviceQuery successfully reporting seeing the GPU:</p>\n<pre><code> py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_HOME \n/usr/local/cuda\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_VISIBLE_DEVICES\n\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./deviceQuery \n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 750M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            926 MHz (0.93 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 750M\nResult = PASS\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./bandwidthTest \n[CUDA Bandwidth Test] - Starting...\nRunning on...\n\n Device 0: GeForce GT 750M\n Quick Mode\n\n Host to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t3633.5\n\n Device to Host Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t6343.5\n\n Device to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t42554.1\n\nResult = PASS\n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n</code></pre>\n<p>My System:</p>\n<pre><code>MacBook Pro (Retina, 15-inch, Late 2013)\n2.3 GHz Intel Core i7\n16 GB 1600 MHz DDR3\nNVIDIA GeForce GT 750M 2048 MB\n\n---\nfrom System Report &gt; Graphics\nNVIDIA GeForce GT 750M:\n\n  Chipset Model:\tNVIDIA GeForce GT 750M\n  Type:\tGPU\n  Bus:\tPCIe\n  PCIe Lane Width:\tx8\n  VRAM (Total):\t2048 MB\n  Vendor:\tNVIDIA (0x10de)\n  Device ID:\t0x0fe9\n  Revision ID:\t0x00a2\n  ROM Revision:\t3776\n  gMux Version:\t4.0.8 [3.2.8]\n  Displays:\nColor LCD:\n  Display Type:\tRetina LCD\n  Resolution:\t2880 x 1800 Retina\n  Retina:\tYes\n  Pixel Depth:\t32-Bit Color (ARGB8888)\n  Main Display:\tYes\n  Mirror:\tOff\n  Online:\tYes\n  Built-In:\tYes\n</code></pre>", "body_text": "Hi  @yaroslavvb @zheng-xq\nI'm getting this Dst Tensor Not Initialized error.\n(See my comment (the last one)  in this issue elsewhere: aymericdamien/TensorFlow-Examples#38)\nI'm reproducing the stack trace here in case it helps diagnose the issue:\n\u25b6 python imagenet_inference.py \nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 305.92MiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0 97.01MiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 144.00MiB was 128.00MiB, Chunk State: \nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60000 of size 1280\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60500 of size 139520\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82600 of size 512\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82800 of size 1228800\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700bae800 of size 1024\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700baec00 of size 3538944\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0ec00 of size 1536\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0f200 of size 2654208\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197200 of size 1536\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197800 of size 1769472\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701347800 of size 1024\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x701347c00 of size 101725184\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 512 totalling 512B\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1024 totalling 2.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1536 totalling 3.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 139520 totalling 136.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1228800 totalling 1.17MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1769472 totalling 1.69MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2654208 totalling 2.53MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3538944 totalling 3.38MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 8.91MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                   111063040\nInUse:                     9337856\nMaxInUse:                  9337856\nNumAllocs:                      11\nMaxAllocSize:              3538944\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] *********___________________________________________________________________________________________\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 144.00MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:965] Internal: Dst tensor is not initialized.\nE tensorflow/core/common_runtime/executor.cc:390] Executor failed to create kernel. Internal: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"imagenet_inference.py\", line 19, in <module>\n    sess.run(init)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'Variable_10/initial_value', defined at:\n  File \"imagenet_inference.py\", line 16, in <module>\n    probs = AlexNet(x, feature_extract=False)\n  File \"/Users/aa/Developer/courses/self_driving_carnd/traffic-signs/CarND-Alexnet-Feature-Extraction/alexnet.py\", line 139, in AlexNet\n    fc6W = tf.Variable(net_data[\"fc6\"][0])\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\n    expected_shape=expected_shape)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 333, in _init_from_args\n    initial_value, name=\"initial_value\", dtype=dtype)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Dst tensor is not initialized.\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\n\nHere's deviceQuery successfully reporting seeing the GPU:\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_HOME \n/usr/local/cuda\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_VISIBLE_DEVICES\n\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./deviceQuery \n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 750M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            926 MHz (0.93 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 750M\nResult = PASS\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./bandwidthTest \n[CUDA Bandwidth Test] - Starting...\nRunning on...\n\n Device 0: GeForce GT 750M\n Quick Mode\n\n Host to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t3633.5\n\n Device to Host Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t6343.5\n\n Device to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(MB/s)\n   33554432\t\t\t42554.1\n\nResult = PASS\n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n\nMy System:\nMacBook Pro (Retina, 15-inch, Late 2013)\n2.3 GHz Intel Core i7\n16 GB 1600 MHz DDR3\nNVIDIA GeForce GT 750M 2048 MB\n\n---\nfrom System Report > Graphics\nNVIDIA GeForce GT 750M:\n\n  Chipset Model:\tNVIDIA GeForce GT 750M\n  Type:\tGPU\n  Bus:\tPCIe\n  PCIe Lane Width:\tx8\n  VRAM (Total):\t2048 MB\n  Vendor:\tNVIDIA (0x10de)\n  Device ID:\t0x0fe9\n  Revision ID:\t0x00a2\n  ROM Revision:\t3776\n  gMux Version:\t4.0.8 [3.2.8]\n  Displays:\nColor LCD:\n  Display Type:\tRetina LCD\n  Resolution:\t2880 x 1800 Retina\n  Retina:\tYes\n  Pixel Depth:\t32-Bit Color (ARGB8888)\n  Main Display:\tYes\n  Mirror:\tOff\n  Online:\tYes\n  Built-In:\tYes", "body": "Hi  @yaroslavvb @zheng-xq \r\n\r\nI'm getting this `Dst Tensor Not Initialized` error. \r\n\r\n(See my comment (the last one)  in this issue elsewhere: https://github.com/aymericdamien/TensorFlow-Examples/issues/38)\r\n\r\nI'm reproducing the stack trace here in case it helps diagnose the issue:\r\n\r\n```\r\n\u25b6 python imagenet_inference.py \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GT 750M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 305.92MiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0 97.01MiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 144.00MiB was 128.00MiB, Chunk State: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60000 of size 1280\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a60500 of size 139520\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82600 of size 512\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700a82800 of size 1228800\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700bae800 of size 1024\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700baec00 of size 3538944\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0ec00 of size 1536\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x700f0f200 of size 2654208\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197200 of size 1536\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701197800 of size 1769472\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x701347800 of size 1024\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x701347c00 of size 101725184\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 512 totalling 512B\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1024 totalling 2.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1536 totalling 3.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 139520 totalling 136.2KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1228800 totalling 1.17MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1769472 totalling 1.69MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2654208 totalling 2.53MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3538944 totalling 3.38MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 8.91MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \r\nLimit:                   111063040\r\nInUse:                     9337856\r\nMaxInUse:                  9337856\r\nNumAllocs:                      11\r\nMaxAllocSize:              3538944\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] *********___________________________________________________________________________________________\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 144.00MiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:965] Internal: Dst tensor is not initialized.\r\nE tensorflow/core/common_runtime/executor.cc:390] Executor failed to create kernel. Internal: Dst tensor is not initialized.\r\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\nTraceback (most recent call last):\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\r\n    return fn(*args)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\r\n    status, run_metadata)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\r\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"imagenet_inference.py\", line 19, in <module>\r\n    sess.run(init)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Dst tensor is not initialized.\r\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op 'Variable_10/initial_value', defined at:\r\n  File \"imagenet_inference.py\", line 16, in <module>\r\n    probs = AlexNet(x, feature_extract=False)\r\n  File \"/Users/aa/Developer/courses/self_driving_carnd/traffic-signs/CarND-Alexnet-Feature-Extraction/alexnet.py\", line 139, in AlexNet\r\n    fc6W = tf.Variable(net_data[\"fc6\"][0])\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\r\n    expected_shape=expected_shape)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 333, in _init_from_args\r\n    initial_value, name=\"initial_value\", dtype=dtype)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\r\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/aa/Developer/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInternalError (see above for traceback): Dst tensor is not initialized.\r\n\t [[Node: Variable_10/initial_value = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [9216,4096] values: [-0.0043384791 -0.0071635786 -0.0067223078]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\n```\r\n\r\nHere's deviceQuery successfully reporting seeing the GPU:\r\n\r\n```\r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_HOME \r\n/usr/local/cuda\r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $CUDA_VISIBLE_DEVICES\r\n\r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./deviceQuery \r\n./deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GT 750M\"\r\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\r\n  CUDA Capability Major/Minor version number:    3.0\r\n  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\r\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\r\n  GPU Max Clock rate:                            926 MHz (0.93 GHz)\r\n  Memory Clock rate:                             2508 Mhz\r\n  Memory Bus Width:                              128-bit\r\n  L2 Cache Size:                                 262144 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 750M\r\nResult = PASS\r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 ./bandwidthTest \r\n[CUDA Bandwidth Test] - Starting...\r\nRunning on...\r\n\r\n Device 0: GeForce GT 750M\r\n Quick Mode\r\n\r\n Host to Device Bandwidth, 1 Device(s)\r\n PINNED Memory Transfers\r\n   Transfer Size (Bytes)\tBandwidth(MB/s)\r\n   33554432\t\t\t3633.5\r\n\r\n Device to Host Bandwidth, 1 Device(s)\r\n PINNED Memory Transfers\r\n   Transfer Size (Bytes)\tBandwidth(MB/s)\r\n   33554432\t\t\t6343.5\r\n\r\n Device to Device Bandwidth, 1 Device(s)\r\n PINNED Memory Transfers\r\n   Transfer Size (Bytes)\tBandwidth(MB/s)\r\n   33554432\t\t\t42554.1\r\n\r\nResult = PASS\r\n\r\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\r\n```\r\n\r\nMy System: \r\n```\r\nMacBook Pro (Retina, 15-inch, Late 2013)\r\n2.3 GHz Intel Core i7\r\n16 GB 1600 MHz DDR3\r\nNVIDIA GeForce GT 750M 2048 MB\r\n\r\n---\r\nfrom System Report > Graphics\r\nNVIDIA GeForce GT 750M:\r\n\r\n  Chipset Model:\tNVIDIA GeForce GT 750M\r\n  Type:\tGPU\r\n  Bus:\tPCIe\r\n  PCIe Lane Width:\tx8\r\n  VRAM (Total):\t2048 MB\r\n  Vendor:\tNVIDIA (0x10de)\r\n  Device ID:\t0x0fe9\r\n  Revision ID:\t0x00a2\r\n  ROM Revision:\t3776\r\n  gMux Version:\t4.0.8 [3.2.8]\r\n  Displays:\r\nColor LCD:\r\n  Display Type:\tRetina LCD\r\n  Resolution:\t2880 x 1800 Retina\r\n  Retina:\tYes\r\n  Pixel Depth:\t32-Bit Color (ARGB8888)\r\n  Main Display:\tYes\r\n  Mirror:\tOff\r\n  Online:\tYes\r\n  Built-In:\tYes\r\n```\r\n"}