{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11189", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11189/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11189/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11189/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11189", "id": 239855000, "node_id": "MDU6SXNzdWUyMzk4NTUwMDA=", "number": 11189, "title": "On Network with Shared Weights, Optimizer.minimize has no effect", "user": {"login": "CJMenart", "id": 16726571, "node_id": "MDQ6VXNlcjE2NzI2NTcx", "avatar_url": "https://avatars3.githubusercontent.com/u/16726571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CJMenart", "html_url": "https://github.com/CJMenart", "followers_url": "https://api.github.com/users/CJMenart/followers", "following_url": "https://api.github.com/users/CJMenart/following{/other_user}", "gists_url": "https://api.github.com/users/CJMenart/gists{/gist_id}", "starred_url": "https://api.github.com/users/CJMenart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CJMenart/subscriptions", "organizations_url": "https://api.github.com/users/CJMenart/orgs", "repos_url": "https://api.github.com/users/CJMenart/repos", "events_url": "https://api.github.com/users/CJMenart/events{/privacy}", "received_events_url": "https://api.github.com/users/CJMenart/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-06-30T18:25:49Z", "updated_at": "2017-07-03T15:30:42Z", "closed_at": "2017-07-03T15:30:42Z", "author_association": "NONE", "body_html": "<p>I have a simple siamese network--a network with two branches that share weights--and a script to train it on some very simple data. The loss and gradients are both non-zero, but executing an optimizer.minimize(loss) operation has no effect on the weights. Executing it in two steps with compute_gradients and apply_gradients also has no effect.</p>\n<p>I have tried multiple optimizers and settings, and explored StackOverflow without finding relevant information.</p>\n<p>I have included both scripts (they are small) with the relevant debug statements so that you can easily inspect the weights and gradients as well. You will see that the accuracy/weights/gradients do not change (loss changes because new batches are being computed each iteration).</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li>Windows 10, up to date</li>\n<li>Tensorflow 1.2.0, CPU-only mode</li>\n<li>Python 3.5</li>\n<li>Executing from Windows terminal</li>\n</ul>\n<p>Network constructor:</p>\n<pre><code>import tensorflow as tf\n\nclass SameDiffNet:\n\t# a siamese FC network for classifying vectors as same/different\n\t\n\tdef __init__(self,inputLen):\n\t\t# settings\n\t\tself.NUM_BRANCHES = 2\n\t\tself.LAYER_SIZES = [20,20]\n\t\tself.DATA_TYPE = tf.float32\n\t\tself.NORM_CONSTANT = 0.0001\n\t\t\n\t\t# input\n\t\tself.inputs = []\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\n\n\t\t# network branches\n\t\tself.branches = []\n\t\tself.branchWeights = self.branch_weights(inputLen)\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.branches.append(self.network_branch(branch))\n\t\t\t\t\n\t\t# combination layer and loss\n\t\tself.out = self.distance_layer_euclidean()\n\t\tself.target = tf.placeholder(self.DATA_TYPE,[None, 1])\n\t\tself.loss = self.contrastive_loss()\n\t\tself.accuracy = self.my_accuracy()\n\t\t\n\tdef branch_weights(self,inputLen):\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[0]]), name=\"weights0\"))\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias0\"))\n\t\t\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]), name=\"weights\" + str(layer)))\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]), name=\"bias\" + str(layer)))\n\t\t\n\t\treturn netWeights\n\t\t\n\tdef network_branch(self,branch):\n\t\tfc = self.inputs[branch]\n\t\tfor layer in range(len(self.LAYER_SIZES)):\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\n\t\treturn fc\n\t\t\t\n\tdef distance_layer_euclidean(self):\n\t\tassert self.NUM_BRANCHES == 2\n\t\tdist = tf.subtract(1.0,tf.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1)+self.NORM_CONSTANT)))\n\t\treturn dist\n\t\t\n\tdef cross_entropy_loss(self):\n\t\tloss = tf.reduce_sum(tf.multiply(-1.0,tf.add(tf.multiply(self.target,tf.log(self.out+self.NORM_CONSTANT)),tf.multiply(1-self.target,tf.log(1-self.out+self.NORM_CONSTANT)))))\n\t\treturn loss\n\t\t\n\tdef contrastive_loss(self):\n\t\tloss = tf.reduce_sum(tf.pow(tf.subtract(self.out,self.target),2))\n\t\treturn loss \n\t\t\n         #Does not work either, so I wrote a simple replacement\n\tdef tf_accuracy(self):\n\t\treturn tf.metrics.accuracy(tf.round(self.out),self.target)\n\t\t\n\tdef my_accuracy(self):\n\t\treturn tf.reduce_mean(tf.cast(tf.equal(tf.round(self.out), self.target),tf.float32))\n</code></pre>\n<p>Run script:</p>\n<pre><code>''' A simple test where we train our siamese network on toy examples\nOur training data consists of a pair of 0's and 1's, and our truth output will\nsimply be the XOR of these two values'''\n\nimport time\nimport numpy as np\nimport tensorflow as tf\nfrom sameDiffNet import SameDiffNet\n\nnumTraining = 1000\nnumTest = 500\nnumIter = 10000\n\nsess = tf.InteractiveSession()\nnetwork = SameDiffNet(2)\noptimizer = tf.train.GradientDescentOptimizer(0.1)\ntrain = optimizer.minimize(network.loss)\ngradients = optimizer.compute_gradients(network.loss) #,tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\napplyGrad = optimizer.apply_gradients(gradients)\n\ndata = np.random.randint(0,2,(numTraining+numTest,2))\ntruth = data[:,0] == data[:,1]\ntruth = [float(not truth[b]) for b in range(numTraining+numTest)]\ndata = data.astype(float)\n\ntrainData = data[:numTraining,:]\ntestData = data[numTraining:,:]\ntrainTruth = truth[:numTraining]\ntestTruth = truth[numTraining:]\n\n#Create test data once\ntestPermutationL = np.random.permutation(numTest)\ntestPermutationR = np.random.permutation(numTest)\ntestTarget = [[float(testTruth[testPermutationL[i]] == testTruth[testPermutationR[i]])] for i in range(numTest)]\n\ntf.global_variables_initializer().run()\n\n#debugging\nprint(\"Trainable Variables:\")\nprint(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n\nfor iter in range(numIter):\n\tpermutationL = np.random.permutation(numTraining)\n\tpermutationR = np.random.permutation(numTraining)\n\ttarget = [[float(trainTruth[permutationL[i]] == trainTruth[permutationR[i]])] for i in range(numTraining)]\n\t\n\t# all large debug output is included in triple-quotes\n\t\n\t'''\n\tprint(data[permutationL[1:5],:])\n\tprint(data[permutationR[1:5],:])\n\tprint(target[1:5])\n\t'''\n\t\n\t# you can run the optimization in two steps or one\n\t'''\n\tgrad = sess.run([gradients], feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\n\t\t\t\t\tnetwork.target: target})\n\t\n\tsess.run([applyGrad])\n\t'''\n\t\n\t_, loss = sess.run([train,network.loss], feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\n\t\t\t\t\tnetwork.target: target})\n\t\t\n\ttotalLoss = np.sum(loss)\n\tif np.isnan(totalLoss):\n\t\tprint('Model diverged with loss = NaN')\n\t\tquit()\n\n\tif iter % 10 == 0:\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\n\t\tacc = sess.run([network.accuracy],feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:testData[testPermutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:testData[testPermutationR,:],\n\t\t\t\t\tnetwork.target: testTarget});\n\t\tprint ('step %d: accuracy %.3f' % (iter, np.sum(acc)))\n\n\t#debugging\n\t'''\n\tprint(\"Gradients:\")\n\tprint(grad)\n\t'''\n\t'''\n\tprint(\"First-Layer Weights:\")\n\tprint(sess.run(network.branchWeights[\"weights\"][0]))\n\t'''\n\n</code></pre>", "body_text": "I have a simple siamese network--a network with two branches that share weights--and a script to train it on some very simple data. The loss and gradients are both non-zero, but executing an optimizer.minimize(loss) operation has no effect on the weights. Executing it in two steps with compute_gradients and apply_gradients also has no effect.\nI have tried multiple optimizers and settings, and explored StackOverflow without finding relevant information.\nI have included both scripts (they are small) with the relevant debug statements so that you can easily inspect the weights and gradients as well. You will see that the accuracy/weights/gradients do not change (loss changes because new batches are being computed each iteration).\n\nSystem information\n\nWindows 10, up to date\nTensorflow 1.2.0, CPU-only mode\nPython 3.5\nExecuting from Windows terminal\n\nNetwork constructor:\nimport tensorflow as tf\n\nclass SameDiffNet:\n\t# a siamese FC network for classifying vectors as same/different\n\t\n\tdef __init__(self,inputLen):\n\t\t# settings\n\t\tself.NUM_BRANCHES = 2\n\t\tself.LAYER_SIZES = [20,20]\n\t\tself.DATA_TYPE = tf.float32\n\t\tself.NORM_CONSTANT = 0.0001\n\t\t\n\t\t# input\n\t\tself.inputs = []\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\n\n\t\t# network branches\n\t\tself.branches = []\n\t\tself.branchWeights = self.branch_weights(inputLen)\n\t\tfor branch in range(self.NUM_BRANCHES):\n\t\t\tself.branches.append(self.network_branch(branch))\n\t\t\t\t\n\t\t# combination layer and loss\n\t\tself.out = self.distance_layer_euclidean()\n\t\tself.target = tf.placeholder(self.DATA_TYPE,[None, 1])\n\t\tself.loss = self.contrastive_loss()\n\t\tself.accuracy = self.my_accuracy()\n\t\t\n\tdef branch_weights(self,inputLen):\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[0]]), name=\"weights0\"))\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias0\"))\n\t\t\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]), name=\"weights\" + str(layer)))\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]), name=\"bias\" + str(layer)))\n\t\t\n\t\treturn netWeights\n\t\t\n\tdef network_branch(self,branch):\n\t\tfc = self.inputs[branch]\n\t\tfor layer in range(len(self.LAYER_SIZES)):\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\n\t\treturn fc\n\t\t\t\n\tdef distance_layer_euclidean(self):\n\t\tassert self.NUM_BRANCHES == 2\n\t\tdist = tf.subtract(1.0,tf.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1)+self.NORM_CONSTANT)))\n\t\treturn dist\n\t\t\n\tdef cross_entropy_loss(self):\n\t\tloss = tf.reduce_sum(tf.multiply(-1.0,tf.add(tf.multiply(self.target,tf.log(self.out+self.NORM_CONSTANT)),tf.multiply(1-self.target,tf.log(1-self.out+self.NORM_CONSTANT)))))\n\t\treturn loss\n\t\t\n\tdef contrastive_loss(self):\n\t\tloss = tf.reduce_sum(tf.pow(tf.subtract(self.out,self.target),2))\n\t\treturn loss \n\t\t\n         #Does not work either, so I wrote a simple replacement\n\tdef tf_accuracy(self):\n\t\treturn tf.metrics.accuracy(tf.round(self.out),self.target)\n\t\t\n\tdef my_accuracy(self):\n\t\treturn tf.reduce_mean(tf.cast(tf.equal(tf.round(self.out), self.target),tf.float32))\n\nRun script:\n''' A simple test where we train our siamese network on toy examples\nOur training data consists of a pair of 0's and 1's, and our truth output will\nsimply be the XOR of these two values'''\n\nimport time\nimport numpy as np\nimport tensorflow as tf\nfrom sameDiffNet import SameDiffNet\n\nnumTraining = 1000\nnumTest = 500\nnumIter = 10000\n\nsess = tf.InteractiveSession()\nnetwork = SameDiffNet(2)\noptimizer = tf.train.GradientDescentOptimizer(0.1)\ntrain = optimizer.minimize(network.loss)\ngradients = optimizer.compute_gradients(network.loss) #,tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\napplyGrad = optimizer.apply_gradients(gradients)\n\ndata = np.random.randint(0,2,(numTraining+numTest,2))\ntruth = data[:,0] == data[:,1]\ntruth = [float(not truth[b]) for b in range(numTraining+numTest)]\ndata = data.astype(float)\n\ntrainData = data[:numTraining,:]\ntestData = data[numTraining:,:]\ntrainTruth = truth[:numTraining]\ntestTruth = truth[numTraining:]\n\n#Create test data once\ntestPermutationL = np.random.permutation(numTest)\ntestPermutationR = np.random.permutation(numTest)\ntestTarget = [[float(testTruth[testPermutationL[i]] == testTruth[testPermutationR[i]])] for i in range(numTest)]\n\ntf.global_variables_initializer().run()\n\n#debugging\nprint(\"Trainable Variables:\")\nprint(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n\nfor iter in range(numIter):\n\tpermutationL = np.random.permutation(numTraining)\n\tpermutationR = np.random.permutation(numTraining)\n\ttarget = [[float(trainTruth[permutationL[i]] == trainTruth[permutationR[i]])] for i in range(numTraining)]\n\t\n\t# all large debug output is included in triple-quotes\n\t\n\t'''\n\tprint(data[permutationL[1:5],:])\n\tprint(data[permutationR[1:5],:])\n\tprint(target[1:5])\n\t'''\n\t\n\t# you can run the optimization in two steps or one\n\t'''\n\tgrad = sess.run([gradients], feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\n\t\t\t\t\tnetwork.target: target})\n\t\n\tsess.run([applyGrad])\n\t'''\n\t\n\t_, loss = sess.run([train,network.loss], feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\n\t\t\t\t\tnetwork.target: target})\n\t\t\n\ttotalLoss = np.sum(loss)\n\tif np.isnan(totalLoss):\n\t\tprint('Model diverged with loss = NaN')\n\t\tquit()\n\n\tif iter % 10 == 0:\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\n\t\tacc = sess.run([network.accuracy],feed_dict={\n\t\t\t\t\tnetwork.inputs[0]:testData[testPermutationL,:],\n\t\t\t\t\tnetwork.inputs[1]:testData[testPermutationR,:],\n\t\t\t\t\tnetwork.target: testTarget});\n\t\tprint ('step %d: accuracy %.3f' % (iter, np.sum(acc)))\n\n\t#debugging\n\t'''\n\tprint(\"Gradients:\")\n\tprint(grad)\n\t'''\n\t'''\n\tprint(\"First-Layer Weights:\")\n\tprint(sess.run(network.branchWeights[\"weights\"][0]))\n\t'''", "body": "I have a simple siamese network--a network with two branches that share weights--and a script to train it on some very simple data. The loss and gradients are both non-zero, but executing an optimizer.minimize(loss) operation has no effect on the weights. Executing it in two steps with compute_gradients and apply_gradients also has no effect.\r\n\r\nI have tried multiple optimizers and settings, and explored StackOverflow without finding relevant information.\r\n\r\nI have included both scripts (they are small) with the relevant debug statements so that you can easily inspect the weights and gradients as well. You will see that the accuracy/weights/gradients do not change (loss changes because new batches are being computed each iteration).\r\n\r\n------------------------\r\n\r\n### System information\r\n- Windows 10, up to date\r\n- Tensorflow 1.2.0, CPU-only mode\r\n- Python 3.5\r\n- Executing from Windows terminal\r\n\r\nNetwork constructor:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass SameDiffNet:\r\n\t# a siamese FC network for classifying vectors as same/different\r\n\t\r\n\tdef __init__(self,inputLen):\r\n\t\t# settings\r\n\t\tself.NUM_BRANCHES = 2\r\n\t\tself.LAYER_SIZES = [20,20]\r\n\t\tself.DATA_TYPE = tf.float32\r\n\t\tself.NORM_CONSTANT = 0.0001\r\n\t\t\r\n\t\t# input\r\n\t\tself.inputs = []\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))\r\n\r\n\t\t# network branches\r\n\t\tself.branches = []\r\n\t\tself.branchWeights = self.branch_weights(inputLen)\r\n\t\tfor branch in range(self.NUM_BRANCHES):\r\n\t\t\tself.branches.append(self.network_branch(branch))\r\n\t\t\t\t\r\n\t\t# combination layer and loss\r\n\t\tself.out = self.distance_layer_euclidean()\r\n\t\tself.target = tf.placeholder(self.DATA_TYPE,[None, 1])\r\n\t\tself.loss = self.contrastive_loss()\r\n\t\tself.accuracy = self.my_accuracy()\r\n\t\t\r\n\tdef branch_weights(self,inputLen):\r\n\t\t# weights are shared, so they are computed once and re-used to make multiple graphs\r\n\t\t# They are stored as a dictionary of arrays for flexible layer shapes and sizes\r\n\t\tnetWeights = {\"weights\": [], \"bias\": []}\r\n\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[0]]), name=\"weights0\"))\r\n\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=\"bias0\"))\r\n\t\t\r\n\t\tfor layer in range(1,len(self.LAYER_SIZES)):\r\n\t\t\tnetWeights[\"weights\"].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]), name=\"weights\" + str(layer)))\r\n\t\t\tnetWeights[\"bias\"].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]), name=\"bias\" + str(layer)))\r\n\t\t\r\n\t\treturn netWeights\r\n\t\t\r\n\tdef network_branch(self,branch):\r\n\t\tfc = self.inputs[branch]\r\n\t\tfor layer in range(len(self.LAYER_SIZES)):\r\n\t\t\tfc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[\"weights\"][layer]), self.branchWeights[\"bias\"][layer]))\r\n\t\treturn fc\r\n\t\t\t\r\n\tdef distance_layer_euclidean(self):\r\n\t\tassert self.NUM_BRANCHES == 2\r\n\t\tdist = tf.subtract(1.0,tf.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1)+self.NORM_CONSTANT)))\r\n\t\treturn dist\r\n\t\t\r\n\tdef cross_entropy_loss(self):\r\n\t\tloss = tf.reduce_sum(tf.multiply(-1.0,tf.add(tf.multiply(self.target,tf.log(self.out+self.NORM_CONSTANT)),tf.multiply(1-self.target,tf.log(1-self.out+self.NORM_CONSTANT)))))\r\n\t\treturn loss\r\n\t\t\r\n\tdef contrastive_loss(self):\r\n\t\tloss = tf.reduce_sum(tf.pow(tf.subtract(self.out,self.target),2))\r\n\t\treturn loss \r\n\t\t\r\n         #Does not work either, so I wrote a simple replacement\r\n\tdef tf_accuracy(self):\r\n\t\treturn tf.metrics.accuracy(tf.round(self.out),self.target)\r\n\t\t\r\n\tdef my_accuracy(self):\r\n\t\treturn tf.reduce_mean(tf.cast(tf.equal(tf.round(self.out), self.target),tf.float32))\r\n```\r\n\r\n\r\nRun script:\r\n\r\n```\r\n''' A simple test where we train our siamese network on toy examples\r\nOur training data consists of a pair of 0's and 1's, and our truth output will\r\nsimply be the XOR of these two values'''\r\n\r\nimport time\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom sameDiffNet import SameDiffNet\r\n\r\nnumTraining = 1000\r\nnumTest = 500\r\nnumIter = 10000\r\n\r\nsess = tf.InteractiveSession()\r\nnetwork = SameDiffNet(2)\r\noptimizer = tf.train.GradientDescentOptimizer(0.1)\r\ntrain = optimizer.minimize(network.loss)\r\ngradients = optimizer.compute_gradients(network.loss) #,tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\r\napplyGrad = optimizer.apply_gradients(gradients)\r\n\r\ndata = np.random.randint(0,2,(numTraining+numTest,2))\r\ntruth = data[:,0] == data[:,1]\r\ntruth = [float(not truth[b]) for b in range(numTraining+numTest)]\r\ndata = data.astype(float)\r\n\r\ntrainData = data[:numTraining,:]\r\ntestData = data[numTraining:,:]\r\ntrainTruth = truth[:numTraining]\r\ntestTruth = truth[numTraining:]\r\n\r\n#Create test data once\r\ntestPermutationL = np.random.permutation(numTest)\r\ntestPermutationR = np.random.permutation(numTest)\r\ntestTarget = [[float(testTruth[testPermutationL[i]] == testTruth[testPermutationR[i]])] for i in range(numTest)]\r\n\r\ntf.global_variables_initializer().run()\r\n\r\n#debugging\r\nprint(\"Trainable Variables:\")\r\nprint(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\r\n\r\nfor iter in range(numIter):\r\n\tpermutationL = np.random.permutation(numTraining)\r\n\tpermutationR = np.random.permutation(numTraining)\r\n\ttarget = [[float(trainTruth[permutationL[i]] == trainTruth[permutationR[i]])] for i in range(numTraining)]\r\n\t\r\n\t# all large debug output is included in triple-quotes\r\n\t\r\n\t'''\r\n\tprint(data[permutationL[1:5],:])\r\n\tprint(data[permutationR[1:5],:])\r\n\tprint(target[1:5])\r\n\t'''\r\n\t\r\n\t# you can run the optimization in two steps or one\r\n\t'''\r\n\tgrad = sess.run([gradients], feed_dict={\r\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\r\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\r\n\t\t\t\t\tnetwork.target: target})\r\n\t\r\n\tsess.run([applyGrad])\r\n\t'''\r\n\t\r\n\t_, loss = sess.run([train,network.loss], feed_dict={\r\n\t\t\t\t\tnetwork.inputs[0]:trainData[permutationL,:],\r\n\t\t\t\t\tnetwork.inputs[1]:trainData[permutationR,:],\r\n\t\t\t\t\tnetwork.target: target})\r\n\t\t\r\n\ttotalLoss = np.sum(loss)\r\n\tif np.isnan(totalLoss):\r\n\t\tprint('Model diverged with loss = NaN')\r\n\t\tquit()\r\n\r\n\tif iter % 10 == 0:\r\n\t\tprint ('step %d: loss %.3f' % (iter, totalLoss/numTraining))\r\n\t\tacc = sess.run([network.accuracy],feed_dict={\r\n\t\t\t\t\tnetwork.inputs[0]:testData[testPermutationL,:],\r\n\t\t\t\t\tnetwork.inputs[1]:testData[testPermutationR,:],\r\n\t\t\t\t\tnetwork.target: testTarget});\r\n\t\tprint ('step %d: accuracy %.3f' % (iter, np.sum(acc)))\r\n\r\n\t#debugging\r\n\t'''\r\n\tprint(\"Gradients:\")\r\n\tprint(grad)\r\n\t'''\r\n\t'''\r\n\tprint(\"First-Layer Weights:\")\r\n\tprint(sess.run(network.branchWeights[\"weights\"][0]))\r\n\t'''\r\n\r\n```"}