{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134952606", "pull_request_review_id": 58304946, "id": 134952606, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNDk1MjYwNg==", "diff_hunk": "@@ -19,31 +19,84 @@ limitations under the License.\n // Functor definition for SliceOp, must be compilable by nvcc.\n \n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+#include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/kernels/ops_util.h\"\n \n namespace tensorflow {\n-namespace functor {\n+\n+namespace internal {\n+\n+template <typename Device, typename T>\n+void SliceSimple(const Device& d, Tensor* out, const Tensor& in,\n+                 const gtl::ArraySlice<int64>& slice_indices);\n+template <typename Device, typename T>\n+void SliceSimpleGpu(const Device& d, Tensor* out, const Tensor& in,\n+                 const gtl::ArraySlice<int64>& slice_indices);\n+\n+template <typename Device, typename T>\n+void SliceSimple(const Device& d, Tensor* out, const Tensor& in,\n+                 const gtl::ArraySlice<int64>& slice_indices) {\n+  const int ndims = in.dims();\n+  const int64 nelem = out->NumElements();\n+  const gtl::InlinedVector<int64, 8> in_strides = ComputeStride<int64>(in.shape());\n+  const gtl::InlinedVector<int64, 8> out_strides = ComputeStride<int64>(out->shape());\n+  const T* p = in.flat<T>().data();\n+  T* q = out->flat<T>().data();\n+\n+  for (int64 o_idx = 0; o_idx < nelem; ++o_idx) {", "path": "tensorflow/core/kernels/slice_op.h", "position": null, "original_position": 30, "commit_id": "23f08f5bc71771c90e3c4f6998fd88aa27865682", "original_commit_id": "a5ed7f6106abf2acf58444e45fccc3b65082c5ff", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "body": "You can always unroll loops with Duff's device which batches up the divisions by 8, not if that's what Andy meant. It feels like the inner loop has lots of computation repeated for every element, so if you can work out a version where you have ndims on the outer and nelems on the inner loop then it would be faster.\r\n\r\nIt would be nice to measure the improvement on a benchmark.", "created_at": "2017-08-24T08:12:50Z", "updated_at": "2017-11-02T06:17:16Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/11140#discussion_r134952606", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11140", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/134952606"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/11140#discussion_r134952606"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/11140"}}, "body_html": "<p>You can always unroll loops with Duff's device which batches up the divisions by 8, not if that's what Andy meant. It feels like the inner loop has lots of computation repeated for every element, so if you can work out a version where you have ndims on the outer and nelems on the inner loop then it would be faster.</p>\n<p>It would be nice to measure the improvement on a benchmark.</p>", "body_text": "You can always unroll loops with Duff's device which batches up the divisions by 8, not if that's what Andy meant. It feels like the inner loop has lots of computation repeated for every element, so if you can work out a version where you have ndims on the outer and nelems on the inner loop then it would be faster.\nIt would be nice to measure the improvement on a benchmark.", "in_reply_to_id": 129375448}