{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239921336", "html_url": "https://github.com/tensorflow/tensorflow/pull/3780#issuecomment-239921336", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3780", "id": 239921336, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTkyMTMzNg==", "user": {"login": "keveman", "id": 229914, "node_id": "MDQ6VXNlcjIyOTkxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/229914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keveman", "html_url": "https://github.com/keveman", "followers_url": "https://api.github.com/users/keveman/followers", "following_url": "https://api.github.com/users/keveman/following{/other_user}", "gists_url": "https://api.github.com/users/keveman/gists{/gist_id}", "starred_url": "https://api.github.com/users/keveman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keveman/subscriptions", "organizations_url": "https://api.github.com/users/keveman/orgs", "repos_url": "https://api.github.com/users/keveman/repos", "events_url": "https://api.github.com/users/keveman/events{/privacy}", "received_events_url": "https://api.github.com/users/keveman/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-15T20:37:18Z", "updated_at": "2016-08-15T20:37:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1069617\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Russell91\">@Russell91</a>, perhaps you didn't fully grok what <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> was trying to say. The extension system is indeed quite mature. Look <a href=\"https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html\" rel=\"nofollow\">here</a> for complete instructions on how to add an op to TensorFlow. You have two options, depending on how you want your op to be compiled and used.</p>\n<ul>\n<li>Add it to tensorflow/contrib and send a PR. See <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/linear_optimizer/BUILD\">here</a> for an example BUILD file that compiles a custom op and makes it available TensorFlow users via <code>tensorflow.contrib</code>.</li>\n<li>Maintain your op's source code independent of TensorFlow's source code. In this case, you would need the users to install the binary version of TensorFlow via the PIP package. Look <a href=\"https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html#with-tensorflow-binary-installation\" rel=\"nofollow\">here</a> for how to compile your custom op without using the Bazel build system, say, using plain vanilla Makefile.</li>\n</ul>\n<p>Let me know if you need help with either of those.</p>", "body_text": "@Russell91, perhaps you didn't fully grok what @vrv was trying to say. The extension system is indeed quite mature. Look here for complete instructions on how to add an op to TensorFlow. You have two options, depending on how you want your op to be compiled and used.\n\nAdd it to tensorflow/contrib and send a PR. See here for an example BUILD file that compiles a custom op and makes it available TensorFlow users via tensorflow.contrib.\nMaintain your op's source code independent of TensorFlow's source code. In this case, you would need the users to install the binary version of TensorFlow via the PIP package. Look here for how to compile your custom op without using the Bazel build system, say, using plain vanilla Makefile.\n\nLet me know if you need help with either of those.", "body": "@Russell91, perhaps you didn't fully grok what @vrv was trying to say. The extension system is indeed quite mature. Look [here](https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html) for complete instructions on how to add an op to TensorFlow. You have two options, depending on how you want your op to be compiled and used.\n- Add it to tensorflow/contrib and send a PR. See [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/linear_optimizer/BUILD) for an example BUILD file that compiles a custom op and makes it available TensorFlow users via `tensorflow.contrib`.\n- Maintain your op's source code independent of TensorFlow's source code. In this case, you would need the users to install the binary version of TensorFlow via the PIP package. Look [here](https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html#with-tensorflow-binary-installation) for how to compile your custom op without using the Bazel build system, say, using plain vanilla Makefile.\n\nLet me know if you need help with either of those.\n"}