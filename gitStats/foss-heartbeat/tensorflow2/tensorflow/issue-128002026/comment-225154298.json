{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/225154298", "html_url": "https://github.com/tensorflow/tensorflow/issues/833#issuecomment-225154298", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/833", "id": 225154298, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNTE1NDI5OA==", "user": {"login": "bsautermeister", "id": 2537736, "node_id": "MDQ6VXNlcjI1Mzc3MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2537736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsautermeister", "html_url": "https://github.com/bsautermeister", "followers_url": "https://api.github.com/users/bsautermeister/followers", "following_url": "https://api.github.com/users/bsautermeister/following{/other_user}", "gists_url": "https://api.github.com/users/bsautermeister/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsautermeister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsautermeister/subscriptions", "organizations_url": "https://api.github.com/users/bsautermeister/orgs", "repos_url": "https://api.github.com/users/bsautermeister/repos", "events_url": "https://api.github.com/users/bsautermeister/events{/privacy}", "received_events_url": "https://api.github.com/users/bsautermeister/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-10T11:02:08Z", "updated_at": "2016-06-10T16:00:36Z", "author_association": "NONE", "body_html": "<p>I tried to to it exactly the same way as described here. But Unfortunately, it returns a tensor with unknown dimensions:</p>\n<pre><code>batch_size = tf.shape(something_or_other)[0]\ndeconv_shape = tf.pack([batch_size, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n</code></pre>\n<p>Returns: A  tensor with shape (?, ?, ?, ?).</p>\n<p><code>conv2d_transpose(..., output_shape=[64, 40, 40. 32], ...)</code><br>\nReturns: A  tensor with shape (64, 40, 40, 32).</p>\n<p>It even looks like it's unrelated to the variable batch-size, but to tf.pack():</p>\n<pre><code>deconv_shape = tf.pack([64, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n</code></pre>\n<p>Returns: A  tensor with shape (?, ?, ?, ?).</p>\n<p>So, as soon as i use two conv2d_transposed() operations with variable batch-size one after the other, it is not working for me.<br>\nDoes anyone have the same issues having a unknown tensor-shape. Is is there a way to set the tensor-shape manually?</p>\n<p>Here is the full method I use to simplify the call to conv2d_transpose:</p>\n<pre><code>def conv2d_transpose(name_or_scope, x, n_filters,\n           k_h=5, k_w=5,\n           stride_h=2, stride_w=2,\n           stddev=0.02, bias=0.1,\n           activation=lambda x: x,\n           padding='SAME',):\n\n    with tf.variable_scope(name_or_scope):\n        input_shape = x.get_shape().as_list()\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = tf.shape(x)[0]\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = input_shape[1] * stride_h\n            out_w = input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (input_shape[1] - 1) * stride_h + k_h\n            out_w = (input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n        # out_shape = tf.pack([batch_size, 14, 14, 32])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)\n</code></pre>\n<p><strong>EDIT:</strong><br>\nExecuting this in the session, the result actually has the proper shape, but not during graph construction:</p>\n<pre><code>BATCH_SIZE = 64\n# ...\nconv3t = tt.network.conv2d_transpose(\"Deconv1\", encoder_out,\n                                         32, 5, 5, 2, 2,\n                                         stddev=0.02, bias=0.1,\n                                         activation=tf.nn.relu)\n# ...\nsess.run(tf.initialize_all_variables())\nfeed = {x: np.ones([BATCH_SIZE, 28 ** 2])}\nconv3tres = sess.run([conv3t], feed_dict=feed)\nprint(\"ct\", conv3t)\nprint(\"conv3tres-shape\", np.shape(conv3tres))\n</code></pre>\n<p>Output:<br>\n('ct', &lt; tf.Tensor 'Decoder/Relu:0' shape=(?, ?, ?, ?) dtype=float32 &gt;)<br>\n('conv3tres-shape', (64, 14, 14, 32))</p>\n<p><strong>Solution:</strong><br>\nI could fix it by myself. After checking out a working solution from <a href=\"https://github.com/pkmital/tensorflow_tutorials/blob/master/python/09_convolutional_autoencoder.py\">GitHub</a>, I realized that the return value of shape (?, ?, ?, ?) seems to be normal. What I mixed up was the difference between tf.shape(...) and Tensor.get_shape(...). Here is the working code. Feel free to use it...</p>\n<pre><code>def conv2d_transpose(name_or_scope,\n                     x, n_filters,\n                     batch_size,\n                     k_h=5, k_w=5,\n                     stride_h=2, stride_w=2,\n                     stddev=0.02, bias=0.1,\n                     activation=lambda x: x,\n                     padding='SAME',):\n    with tf.variable_scope(name_or_scope):\n        static_input_shape = x.get_shape().as_list()\n        dyn_input_shape = tf.shape(x)\n\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = dyn_input_shape[0]\n\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, static_input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = dyn_input_shape[1] * stride_h\n            out_w = dyn_input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (dyn_input_shape[1] - 1) * stride_h + k_h\n            out_w = (dyn_input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)\n</code></pre>", "body_text": "I tried to to it exactly the same way as described here. But Unfortunately, it returns a tensor with unknown dimensions:\nbatch_size = tf.shape(something_or_other)[0]\ndeconv_shape = tf.pack([batch_size, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n\nReturns: A  tensor with shape (?, ?, ?, ?).\nconv2d_transpose(..., output_shape=[64, 40, 40. 32], ...)\nReturns: A  tensor with shape (64, 40, 40, 32).\nIt even looks like it's unrelated to the variable batch-size, but to tf.pack():\ndeconv_shape = tf.pack([64, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n\nReturns: A  tensor with shape (?, ?, ?, ?).\nSo, as soon as i use two conv2d_transposed() operations with variable batch-size one after the other, it is not working for me.\nDoes anyone have the same issues having a unknown tensor-shape. Is is there a way to set the tensor-shape manually?\nHere is the full method I use to simplify the call to conv2d_transpose:\ndef conv2d_transpose(name_or_scope, x, n_filters,\n           k_h=5, k_w=5,\n           stride_h=2, stride_w=2,\n           stddev=0.02, bias=0.1,\n           activation=lambda x: x,\n           padding='SAME',):\n\n    with tf.variable_scope(name_or_scope):\n        input_shape = x.get_shape().as_list()\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = tf.shape(x)[0]\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = input_shape[1] * stride_h\n            out_w = input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (input_shape[1] - 1) * stride_h + k_h\n            out_w = (input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n        # out_shape = tf.pack([batch_size, 14, 14, 32])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)\n\nEDIT:\nExecuting this in the session, the result actually has the proper shape, but not during graph construction:\nBATCH_SIZE = 64\n# ...\nconv3t = tt.network.conv2d_transpose(\"Deconv1\", encoder_out,\n                                         32, 5, 5, 2, 2,\n                                         stddev=0.02, bias=0.1,\n                                         activation=tf.nn.relu)\n# ...\nsess.run(tf.initialize_all_variables())\nfeed = {x: np.ones([BATCH_SIZE, 28 ** 2])}\nconv3tres = sess.run([conv3t], feed_dict=feed)\nprint(\"ct\", conv3t)\nprint(\"conv3tres-shape\", np.shape(conv3tres))\n\nOutput:\n('ct', < tf.Tensor 'Decoder/Relu:0' shape=(?, ?, ?, ?) dtype=float32 >)\n('conv3tres-shape', (64, 14, 14, 32))\nSolution:\nI could fix it by myself. After checking out a working solution from GitHub, I realized that the return value of shape (?, ?, ?, ?) seems to be normal. What I mixed up was the difference between tf.shape(...) and Tensor.get_shape(...). Here is the working code. Feel free to use it...\ndef conv2d_transpose(name_or_scope,\n                     x, n_filters,\n                     batch_size,\n                     k_h=5, k_w=5,\n                     stride_h=2, stride_w=2,\n                     stddev=0.02, bias=0.1,\n                     activation=lambda x: x,\n                     padding='SAME',):\n    with tf.variable_scope(name_or_scope):\n        static_input_shape = x.get_shape().as_list()\n        dyn_input_shape = tf.shape(x)\n\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = dyn_input_shape[0]\n\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, static_input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = dyn_input_shape[1] * stride_h\n            out_w = dyn_input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (dyn_input_shape[1] - 1) * stride_h + k_h\n            out_w = (dyn_input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)", "body": "I tried to to it exactly the same way as described here. But Unfortunately, it returns a tensor with unknown dimensions:\n\n```\nbatch_size = tf.shape(something_or_other)[0]\ndeconv_shape = tf.pack([batch_size, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n```\n\nReturns: A  tensor with shape (?, ?, ?, ?).\n\n`conv2d_transpose(..., output_shape=[64, 40, 40. 32], ...)`\nReturns: A  tensor with shape (64, 40, 40, 32).\n\nIt even looks like it's unrelated to the variable batch-size, but to tf.pack():\n\n```\ndeconv_shape = tf.pack([64, 40, 40, 32])\nconv2d_transpose(..., output_shape=deconv_shape, ...)\n```\n\nReturns: A  tensor with shape (?, ?, ?, ?).\n\nSo, as soon as i use two conv2d_transposed() operations with variable batch-size one after the other, it is not working for me.\nDoes anyone have the same issues having a unknown tensor-shape. Is is there a way to set the tensor-shape manually?\n\nHere is the full method I use to simplify the call to conv2d_transpose:\n\n```\ndef conv2d_transpose(name_or_scope, x, n_filters,\n           k_h=5, k_w=5,\n           stride_h=2, stride_w=2,\n           stddev=0.02, bias=0.1,\n           activation=lambda x: x,\n           padding='SAME',):\n\n    with tf.variable_scope(name_or_scope):\n        input_shape = x.get_shape().as_list()\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = tf.shape(x)[0]\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = input_shape[1] * stride_h\n            out_w = input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (input_shape[1] - 1) * stride_h + k_h\n            out_w = (input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n        # out_shape = tf.pack([batch_size, 14, 14, 32])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)\n```\n\n**EDIT:**\nExecuting this in the session, the result actually has the proper shape, but not during graph construction:\n\n```\nBATCH_SIZE = 64\n# ...\nconv3t = tt.network.conv2d_transpose(\"Deconv1\", encoder_out,\n                                         32, 5, 5, 2, 2,\n                                         stddev=0.02, bias=0.1,\n                                         activation=tf.nn.relu)\n# ...\nsess.run(tf.initialize_all_variables())\nfeed = {x: np.ones([BATCH_SIZE, 28 ** 2])}\nconv3tres = sess.run([conv3t], feed_dict=feed)\nprint(\"ct\", conv3t)\nprint(\"conv3tres-shape\", np.shape(conv3tres))\n```\n\nOutput:\n('ct', < tf.Tensor 'Decoder/Relu:0' shape=(?, ?, ?, ?) dtype=float32 >)\n('conv3tres-shape', (64, 14, 14, 32))\n\n**Solution:**\nI could fix it by myself. After checking out a working solution from [GitHub](https://github.com/pkmital/tensorflow_tutorials/blob/master/python/09_convolutional_autoencoder.py), I realized that the return value of shape (?, ?, ?, ?) seems to be normal. What I mixed up was the difference between tf.shape(...) and Tensor.get_shape(...). Here is the working code. Feel free to use it...\n\n```\ndef conv2d_transpose(name_or_scope,\n                     x, n_filters,\n                     batch_size,\n                     k_h=5, k_w=5,\n                     stride_h=2, stride_w=2,\n                     stddev=0.02, bias=0.1,\n                     activation=lambda x: x,\n                     padding='SAME',):\n    with tf.variable_scope(name_or_scope):\n        static_input_shape = x.get_shape().as_list()\n        dyn_input_shape = tf.shape(x)\n\n        # extract batch-size like as a symbolic tensor to allow variable size\n        batch_size = dyn_input_shape[0]\n\n        w = tf.get_variable(\n            'W', [k_h, k_w, n_filters, static_input_shape[3]],\n            initializer=tf.truncated_normal_initializer(stddev=stddev))\n\n        assert padding in {'SAME', 'VALID'}\n        if (padding is 'SAME'):\n            out_h = dyn_input_shape[1] * stride_h\n            out_w = dyn_input_shape[2] * stride_w\n        elif (padding is 'VALID'):\n            out_h = (dyn_input_shape[1] - 1) * stride_h + k_h\n            out_w = (dyn_input_shape[2] - 1) * stride_w + k_w\n\n        out_shape = tf.pack([batch_size, out_h, out_w, n_filters])\n\n        convt = tf.nn.conv2d_transpose(\n            x, w, output_shape=out_shape,\n            strides=[1, stride_h, stride_w, 1], padding=padding)\n        b = tf.get_variable(\n            'b', [n_filters],\n            initializer=tf.constant_initializer(bias))\n        convt += b\n    return activation(convt)\n```\n"}