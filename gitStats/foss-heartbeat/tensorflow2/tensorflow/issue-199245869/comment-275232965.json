{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275232965", "html_url": "https://github.com/tensorflow/tensorflow/issues/6698#issuecomment-275232965", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6698", "id": 275232965, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTIzMjk2NQ==", "user": {"login": "axakak", "id": 1803644, "node_id": "MDQ6VXNlcjE4MDM2NDQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1803644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/axakak", "html_url": "https://github.com/axakak", "followers_url": "https://api.github.com/users/axakak/followers", "following_url": "https://api.github.com/users/axakak/following{/other_user}", "gists_url": "https://api.github.com/users/axakak/gists{/gist_id}", "starred_url": "https://api.github.com/users/axakak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/axakak/subscriptions", "organizations_url": "https://api.github.com/users/axakak/orgs", "repos_url": "https://api.github.com/users/axakak/repos", "events_url": "https://api.github.com/users/axakak/events{/privacy}", "received_events_url": "https://api.github.com/users/axakak/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-25T21:06:49Z", "updated_at": "2017-01-25T21:06:49Z", "author_association": "NONE", "body_html": "<p>I'm encountering the same problem. The graph will run fine when forced to the cpu, but crashed on the gpu.</p>\n<h3>Environment</h3>\n<p>OS: macOS 10.12.2<br>\nGPU: GeForce GT 750M<br>\nTF: 0.12.1 (pip install)<br>\nPython: 3.6.0<br>\nCUDA: 8.0<br>\ncuDNN: 5.1</p>\n<p>(output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>lrwxr-xr-x  1 root  wheel     33 Dec 14 14:25 /usr/local/cuda/lib/libcuda.1.dylib -&gt; /usr/local/cuda/lib/libcuda.dylib\n-rwxr-xr-x  1 root  wheel  13504 Dec  2 16:48 /usr/local/cuda/lib/libcuda.dylib\nlrwxr-xr-x  1 root  wheel     45 Nov  3 11:40 /usr/local/cuda/lib/libcudadevrt.a -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a\nlrwxr-xr-x  1 root  wheel     50 Nov  3 11:40 /usr/local/cuda/lib/libcudart.8.0.dylib -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib\nlrwxr-xr-x  1 root  wheel     46 Nov  3 11:40 /usr/local/cuda/lib/libcudart.dylib -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib\nlrwxr-xr-x  1 root  wheel     49 Nov  3 11:40 /usr/local/cuda/lib/libcudart_static.a -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a\nlrwxr-xr-x  1 root  wheel     47 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.5.dylib -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  wheel     45 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.dylib -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  wheel     48 Dec 14 10:21 /usr/local/cuda/lib/libcudnn_static.a -&gt; /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a\n</code></pre>\n<h3>Example</h3>\n<p>The minimal example provided by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6981180\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ymfa\">@ymfa</a> both fails and succeeds on my setup. The following are three outputs that have been produced.<br>\n<strong>fail(1)</strong></p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.76GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\nF tensorflow/core/kernels/conv_ops.cc:532] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms) \nAbort trap: 6\n</code></pre>\n<p><strong>fail(2)</strong></p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.53GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"issue.py\", line 52, in &lt;module&gt;\n    sess.run(training_operation, feed_dict={x: X, y: Y})\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"issue.py\", line 43, in &lt;module&gt;\n    logits = SimpleNet(x)\n  File \"issue.py\", line 34, in SimpleNet\n    logits = tf.matmul(fc1, fc1_W) + fc1_b\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n</code></pre>\n<p><strong>pass</strong></p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.71GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nTraining complete!\n</code></pre>", "body_text": "I'm encountering the same problem. The graph will run fine when forced to the cpu, but crashed on the gpu.\nEnvironment\nOS: macOS 10.12.2\nGPU: GeForce GT 750M\nTF: 0.12.1 (pip install)\nPython: 3.6.0\nCUDA: 8.0\ncuDNN: 5.1\n(output of ls -l /path/to/cuda/lib/libcud*):\nlrwxr-xr-x  1 root  wheel     33 Dec 14 14:25 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib\n-rwxr-xr-x  1 root  wheel  13504 Dec  2 16:48 /usr/local/cuda/lib/libcuda.dylib\nlrwxr-xr-x  1 root  wheel     45 Nov  3 11:40 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a\nlrwxr-xr-x  1 root  wheel     50 Nov  3 11:40 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib\nlrwxr-xr-x  1 root  wheel     46 Nov  3 11:40 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib\nlrwxr-xr-x  1 root  wheel     49 Nov  3 11:40 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a\nlrwxr-xr-x  1 root  wheel     47 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  wheel     45 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  wheel     48 Dec 14 10:21 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a\n\nExample\nThe minimal example provided by @ymfa both fails and succeeds on my setup. The following are three outputs that have been produced.\nfail(1)\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.76GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\nF tensorflow/core/kernels/conv_ops.cc:532] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \nAbort trap: 6\n\nfail(2)\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.53GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"issue.py\", line 52, in <module>\n    sess.run(training_operation, feed_dict={x: X, y: Y})\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"issue.py\", line 43, in <module>\n    logits = SimpleNet(x)\n  File \"issue.py\", line 34, in SimpleNet\n    logits = tf.matmul(fc1, fc1_W) + fc1_b\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\n\npass\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.71GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nTraining...\nTraining complete!", "body": "I'm encountering the same problem. The graph will run fine when forced to the cpu, but crashed on the gpu.\r\n\r\n### Environment\r\nOS: macOS 10.12.2\r\nGPU: GeForce GT 750M\r\nTF: 0.12.1 (pip install)\r\nPython: 3.6.0\r\nCUDA: 8.0\r\ncuDNN: 5.1\r\n\r\n(output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\nlrwxr-xr-x  1 root  wheel     33 Dec 14 14:25 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib\r\n-rwxr-xr-x  1 root  wheel  13504 Dec  2 16:48 /usr/local/cuda/lib/libcuda.dylib\r\nlrwxr-xr-x  1 root  wheel     45 Nov  3 11:40 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a\r\nlrwxr-xr-x  1 root  wheel     50 Nov  3 11:40 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib\r\nlrwxr-xr-x  1 root  wheel     46 Nov  3 11:40 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib\r\nlrwxr-xr-x  1 root  wheel     49 Nov  3 11:40 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a\r\nlrwxr-xr-x  1 root  wheel     47 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib\r\nlrwxr-xr-x  1 root  wheel     45 Dec 14 10:21 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.dylib\r\nlrwxr-xr-x  1 root  wheel     48 Dec 14 10:21 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn_static.a\r\n```\r\n\r\n### Example\r\nThe minimal example provided by @ymfa both fails and succeeds on my setup. The following are three outputs that have been produced.\r\n**fail(1)**\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GT 750M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.76GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\r\nTraining...\r\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\nF tensorflow/core/kernels/conv_ops.cc:532] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \r\nAbort trap: 6\r\n```\r\n**fail(2)**\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GT 750M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.53GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\r\nTraining...\r\nE tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\nW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 52, in <module>\r\n    sess.run(training_operation, feed_dict={x: X, y: Y})\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\r\n\r\nCaused by op 'MatMul', defined at:\r\n  File \"issue.py\", line 43, in <module>\r\n    logits = SimpleNet(x)\r\n  File \"issue.py\", line 34, in SimpleNet\r\n    logits = tf.matmul(fc1, fc1_W) + fc1_b\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\r\n    transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(20, 400), b.shape=(400, 2), m=20, n=2, k=400\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Flatten/Reshape, Variable_4/read)]]\r\n```\r\n**pass**\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GT 750M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.71GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\r\nTraining...\r\nTraining complete!\r\n```"}