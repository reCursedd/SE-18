{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352675503", "html_url": "https://github.com/tensorflow/tensorflow/issues/6698#issuecomment-352675503", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6698", "id": 352675503, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjY3NTUwMw==", "user": {"login": "SimonWalsh1000", "id": 10141214, "node_id": "MDQ6VXNlcjEwMTQxMjE0", "avatar_url": "https://avatars3.githubusercontent.com/u/10141214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SimonWalsh1000", "html_url": "https://github.com/SimonWalsh1000", "followers_url": "https://api.github.com/users/SimonWalsh1000/followers", "following_url": "https://api.github.com/users/SimonWalsh1000/following{/other_user}", "gists_url": "https://api.github.com/users/SimonWalsh1000/gists{/gist_id}", "starred_url": "https://api.github.com/users/SimonWalsh1000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SimonWalsh1000/subscriptions", "organizations_url": "https://api.github.com/users/SimonWalsh1000/orgs", "repos_url": "https://api.github.com/users/SimonWalsh1000/repos", "events_url": "https://api.github.com/users/SimonWalsh1000/events{/privacy}", "received_events_url": "https://api.github.com/users/SimonWalsh1000/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-19T08:38:30Z", "updated_at": "2017-12-19T08:38:30Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Check out my solution....</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On 19 December 2017 at 08:20, tbchj ***@***.***&gt; wrote:\n same question. Is there any solution to solve the problem?\n My situation is:\n name: GeForce GTX 1080\n totalMemory: 7.92GiB freeMemory: 2.50GiB\n tensorflow: gpu-1.4.0\n\n I'm testing one gpu but running three tensorflow instance.\n in my code like this:\n gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n\n the other two tensorflow instances running fine, but only the last one run\n error like this:\n\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn\n handle: CUDNN_STATUS_INTERNAL_ERROR\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy\n cudnn handle: CUDNN_STATUS_BAD_PARAM\n F tensorflow/core/kernels/conv_ops.cc:672] Check failed:\n stream-&gt;parent()-&gt;GetConvolveAlgorithms( conv_parameters.\n ShouldIncludeWinogradNonfusedAlgo(), &amp;algorithms)\n\n why? Is gpu config too small: gpu_options = tf.GPUOptions(per_process_gpu_\n memory_fraction=0.3)\n I'm not sure. want some suggestion. I'll try.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"199245869\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/6698\" href=\"https://github.com/tensorflow/tensorflow/issues/6698#issuecomment-352670885\">#6698 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AJq-HpINYs1Uae6ghIW3qKCD56SUDhFeks5tB3HZgaJpZM4Lc7S1\">https://github.com/notifications/unsubscribe-auth/AJq-HpINYs1Uae6ghIW3qKCD56SUDhFeks5tB3HZgaJpZM4Lc7S1</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nBest\nSimon\n\nSLFWalsh MD MRCP FFRRCSI\nslfwalsh@gmail.com</div>\n</div>", "body_text": "Check out my solution....\n\u2026\nOn 19 December 2017 at 08:20, tbchj ***@***.***> wrote:\n same question. Is there any solution to solve the problem?\n My situation is:\n name: GeForce GTX 1080\n totalMemory: 7.92GiB freeMemory: 2.50GiB\n tensorflow: gpu-1.4.0\n\n I'm testing one gpu but running three tensorflow instance.\n in my code like this:\n gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n\n the other two tensorflow instances running fine, but only the last one run\n error like this:\n\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn\n handle: CUDNN_STATUS_INTERNAL_ERROR\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy\n cudnn handle: CUDNN_STATUS_BAD_PARAM\n F tensorflow/core/kernels/conv_ops.cc:672] Check failed:\n stream->parent()->GetConvolveAlgorithms( conv_parameters.\n ShouldIncludeWinogradNonfusedAlgo(), &algorithms)\n\n why? Is gpu config too small: gpu_options = tf.GPUOptions(per_process_gpu_\n memory_fraction=0.3)\n I'm not sure. want some suggestion. I'll try.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#6698 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AJq-HpINYs1Uae6ghIW3qKCD56SUDhFeks5tB3HZgaJpZM4Lc7S1>\n .\n\n\n-- \nBest\nSimon\n\nSLFWalsh MD MRCP FFRRCSI\nslfwalsh@gmail.com", "body": "Check out my solution....\n\nOn 19 December 2017 at 08:20, tbchj <notifications@github.com> wrote:\n\n> same question. Is there any solution to solve the problem?\n> My situation is:\n> name: GeForce GTX 1080\n> totalMemory: 7.92GiB freeMemory: 2.50GiB\n> tensorflow: gpu-1.4.0\n>\n> I'm testing one gpu but running three tensorflow instance.\n> in my code like this:\n> gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n> sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n>\n> the other two tensorflow instances running fine, but only the last one run\n> error like this:\n>\n> E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn\n> handle: CUDNN_STATUS_INTERNAL_ERROR\n> E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy\n> cudnn handle: CUDNN_STATUS_BAD_PARAM\n> F tensorflow/core/kernels/conv_ops.cc:672] Check failed:\n> stream->parent()->GetConvolveAlgorithms( conv_parameters.\n> ShouldIncludeWinogradNonfusedAlgo(), &algorithms)\n>\n> why? Is gpu config too small: gpu_options = tf.GPUOptions(per_process_gpu_\n> memory_fraction=0.3)\n> I'm not sure. want some suggestion. I'll try.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6698#issuecomment-352670885>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJq-HpINYs1Uae6ghIW3qKCD56SUDhFeks5tB3HZgaJpZM4Lc7S1>\n> .\n>\n\n\n\n-- \nBest\nSimon\n\nSLFWalsh MD MRCP FFRRCSI\nslfwalsh@gmail.com\n"}