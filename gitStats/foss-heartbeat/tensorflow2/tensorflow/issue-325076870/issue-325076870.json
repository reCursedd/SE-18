{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19444", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19444/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19444/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19444/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19444", "id": 325076870, "node_id": "MDU6SXNzdWUzMjUwNzY4NzA=", "number": 19444, "title": "Cannot use per process memory fraction in tensorflow distributed", "user": {"login": "ronjet", "id": 13630072, "node_id": "MDQ6VXNlcjEzNjMwMDcy", "avatar_url": "https://avatars0.githubusercontent.com/u/13630072?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ronjet", "html_url": "https://github.com/ronjet", "followers_url": "https://api.github.com/users/ronjet/followers", "following_url": "https://api.github.com/users/ronjet/following{/other_user}", "gists_url": "https://api.github.com/users/ronjet/gists{/gist_id}", "starred_url": "https://api.github.com/users/ronjet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ronjet/subscriptions", "organizations_url": "https://api.github.com/users/ronjet/orgs", "repos_url": "https://api.github.com/users/ronjet/repos", "events_url": "https://api.github.com/users/ronjet/events{/privacy}", "received_events_url": "https://api.github.com/users/ronjet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-21T22:14:06Z", "updated_at": "2018-09-18T19:07:22Z", "closed_at": "2018-09-18T19:01:28Z", "author_association": "NONE", "body_html": "<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</p>\n<ul>\n<li>OS Platform and Distribution :  Linux Ubuntu 16.04 (Deep Learning AMI (Ubuntu) Version 8.0 (ami-dff741a0) on AWS)</li>\n<li>TensorFlow installed from binary:</li>\n<li>TensorFlow version : v1.7.0-13-g99322a92bf 1.7.0</li>\n<li>Python version : Python 3.6.4 :: Anaconda, Inc.</li>\n<li>CUDA/cuDNN version : 9.0, V9.0.176</li>\n<li>GPU model and memory : Tesla K80, 12gb</li>\n<li>Bazel version : N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>  train_dataset = tf.data.TFRecordDataset([train_file])\n  train_dataset = train_dataset.map(lambda x : _parse_function(x), num_parallel_calls = 4)\n  train_dataset = train_dataset.batch(train_batch_size)\n  #train_dataset = train_dataset.prefetch(buffer_size = 1000)\n  train_dataset = train_dataset.repeat()\n  train_iterator = train_dataset.make_initializable_iterator()\n  next_train_element = train_iterator.get_next()\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332854-82ac9076-5d0a-11e8-8c81-8ef0f982f41f.png)\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332868-9198bd8a-5d0a-11e8-9f3c-f40b93687371.png)\n\ncluster = tf.train.ClusterSpec({\n            \"ps\": FLAGS.ps_hosts.split(\",\"),\n            \"worker\": FLAGS.worker_hosts.split(\",\")})\n\n  server = tf.train.Server(cluster, \n                           job_name = FLAGS.job_name,\n                           task_index = FLAGS.task_index)\n\nif FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n    with tf.device(tf.train.replica_device_setter(\n                       worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                       cluster=cluster)):\n\n      users_input = tf.placeholder(tf.float32, shape = [None, items_size], name = 'User_input')\n      items_input = tf.placeholder(tf.float32, shape = [None, users_size], name = 'Item_input')\n      ratings_input = tf.placeholder(tf.float32, shape = [None, 1], name = 'Rating_input')\n</code></pre>\n<p>... model defn</p>\n<pre><code>init_op = tf.initialize_all_variables()\nhooks=[tf.train.StopAtStepHook(last_step=10000)]\nsess_config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)\nsess_config.gpu_options.allow_growth = True\nsess_config.gpu_options.per_process_gpu_memory_fraction = 0.33\n\nwith tf.train.MonitoredTrainingSession(master=server.target,\n                                           is_chief=(FLAGS.task_index == 0),\n                                           checkpoint_dir=FLAGS.log_dir,\n                                           hooks=hooks,\n                                           save_summaries_steps = 10,\n                                           config = sess_config) as sess:\n</code></pre>\n<p>... model training</p>\n<p>....</p>\n<p>Processes completely utilize the available gpu memory. I further reduced the batch size to 20, input is sensor input values, not images.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/13630072/40332635-8fa94fd6-5d09-11e8-9bcc-9b0f70946387.png\"><img src=\"https://user-images.githubusercontent.com/13630072/40332635-8fa94fd6-5d09-11e8-9bcc-9b0f70946387.png\" alt=\"screen shot 2018-05-21 at 2 37 10 pm\" style=\"max-width:100%;\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/13630072/40332884-9fa526f2-5d0a-11e8-8a19-12870cd01d2d.png\"><img src=\"https://user-images.githubusercontent.com/13630072/40332884-9fa526f2-5d0a-11e8-8a19-12870cd01d2d.png\" alt=\"screen shot 2018-05-21 at 3 19 59 pm\" style=\"max-width:100%;\"></a></p>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nOS Platform and Distribution :  Linux Ubuntu 16.04 (Deep Learning AMI (Ubuntu) Version 8.0 (ami-dff741a0) on AWS)\nTensorFlow installed from binary:\nTensorFlow version : v1.7.0-13-g99322a92bf 1.7.0\nPython version : Python 3.6.4 :: Anaconda, Inc.\nCUDA/cuDNN version : 9.0, V9.0.176\nGPU model and memory : Tesla K80, 12gb\nBazel version : N/A\nExact command to reproduce:\n\n  train_dataset = tf.data.TFRecordDataset([train_file])\n  train_dataset = train_dataset.map(lambda x : _parse_function(x), num_parallel_calls = 4)\n  train_dataset = train_dataset.batch(train_batch_size)\n  #train_dataset = train_dataset.prefetch(buffer_size = 1000)\n  train_dataset = train_dataset.repeat()\n  train_iterator = train_dataset.make_initializable_iterator()\n  next_train_element = train_iterator.get_next()\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332854-82ac9076-5d0a-11e8-8c81-8ef0f982f41f.png)\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332868-9198bd8a-5d0a-11e8-9f3c-f40b93687371.png)\n\ncluster = tf.train.ClusterSpec({\n            \"ps\": FLAGS.ps_hosts.split(\",\"),\n            \"worker\": FLAGS.worker_hosts.split(\",\")})\n\n  server = tf.train.Server(cluster, \n                           job_name = FLAGS.job_name,\n                           task_index = FLAGS.task_index)\n\nif FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n    with tf.device(tf.train.replica_device_setter(\n                       worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                       cluster=cluster)):\n\n      users_input = tf.placeholder(tf.float32, shape = [None, items_size], name = 'User_input')\n      items_input = tf.placeholder(tf.float32, shape = [None, users_size], name = 'Item_input')\n      ratings_input = tf.placeholder(tf.float32, shape = [None, 1], name = 'Rating_input')\n\n... model defn\ninit_op = tf.initialize_all_variables()\nhooks=[tf.train.StopAtStepHook(last_step=10000)]\nsess_config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)\nsess_config.gpu_options.allow_growth = True\nsess_config.gpu_options.per_process_gpu_memory_fraction = 0.33\n\nwith tf.train.MonitoredTrainingSession(master=server.target,\n                                           is_chief=(FLAGS.task_index == 0),\n                                           checkpoint_dir=FLAGS.log_dir,\n                                           hooks=hooks,\n                                           save_summaries_steps = 10,\n                                           config = sess_config) as sess:\n\n... model training\n....\nProcesses completely utilize the available gpu memory. I further reduced the batch size to 20, input is sensor input values, not images.", "body": "**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- OS Platform and Distribution :  Linux Ubuntu 16.04 (Deep Learning AMI (Ubuntu) Version 8.0 (ami-dff741a0) on AWS)\r\n- TensorFlow installed from binary:\r\n- TensorFlow version : v1.7.0-13-g99322a92bf 1.7.0\r\n- Python version : Python 3.6.4 :: Anaconda, Inc. \r\n- CUDA/cuDNN version : 9.0, V9.0.176\r\n- GPU model and memory : Tesla K80, 12gb\r\n- Bazel version : N/A\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n  train_dataset = tf.data.TFRecordDataset([train_file])\r\n  train_dataset = train_dataset.map(lambda x : _parse_function(x), num_parallel_calls = 4)\r\n  train_dataset = train_dataset.batch(train_batch_size)\r\n  #train_dataset = train_dataset.prefetch(buffer_size = 1000)\r\n  train_dataset = train_dataset.repeat()\r\n  train_iterator = train_dataset.make_initializable_iterator()\r\n  next_train_element = train_iterator.get_next()\r\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332854-82ac9076-5d0a-11e8-8c81-8ef0f982f41f.png)\r\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332868-9198bd8a-5d0a-11e8-9f3c-f40b93687371.png)\r\n\r\ncluster = tf.train.ClusterSpec({\r\n            \"ps\": FLAGS.ps_hosts.split(\",\"),\r\n            \"worker\": FLAGS.worker_hosts.split(\",\")})\r\n\r\n  server = tf.train.Server(cluster, \r\n                           job_name = FLAGS.job_name,\r\n                           task_index = FLAGS.task_index)\r\n\r\nif FLAGS.job_name == \"ps\":\r\n    server.join()\r\n  elif FLAGS.job_name == \"worker\":\r\n    with tf.device(tf.train.replica_device_setter(\r\n                       worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\r\n                       cluster=cluster)):\r\n\r\n      users_input = tf.placeholder(tf.float32, shape = [None, items_size], name = 'User_input')\r\n      items_input = tf.placeholder(tf.float32, shape = [None, users_size], name = 'Item_input')\r\n      ratings_input = tf.placeholder(tf.float32, shape = [None, 1], name = 'Rating_input')\r\n```\r\n\r\n... model defn\r\n\r\n```\r\ninit_op = tf.initialize_all_variables()\r\nhooks=[tf.train.StopAtStepHook(last_step=10000)]\r\nsess_config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)\r\nsess_config.gpu_options.allow_growth = True\r\nsess_config.gpu_options.per_process_gpu_memory_fraction = 0.33\r\n\r\nwith tf.train.MonitoredTrainingSession(master=server.target,\r\n                                           is_chief=(FLAGS.task_index == 0),\r\n                                           checkpoint_dir=FLAGS.log_dir,\r\n                                           hooks=hooks,\r\n                                           save_summaries_steps = 10,\r\n                                           config = sess_config) as sess:\r\n```\r\n... model training \r\n\r\n\r\n\r\n....\r\n\r\nProcesses completely utilize the available gpu memory. I further reduced the batch size to 20, input is sensor input values, not images.\r\n\r\n\r\n![screen shot 2018-05-21 at 2 37 10 pm](https://user-images.githubusercontent.com/13630072/40332635-8fa94fd6-5d09-11e8-9bcc-9b0f70946387.png)\r\n\r\n![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332884-9fa526f2-5d0a-11e8-8a19-12870cd01d2d.png)\r\n\r\n\r\n"}