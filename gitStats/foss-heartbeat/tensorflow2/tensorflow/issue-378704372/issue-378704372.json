{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23599", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23599/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23599/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23599/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23599", "id": 378704372, "node_id": "MDU6SXNzdWUzNzg3MDQzNzI=", "number": 23599, "title": "TFLite constant strided slice wrongly", "user": {"login": "kamwoh", "id": 17477159, "node_id": "MDQ6VXNlcjE3NDc3MTU5", "avatar_url": "https://avatars0.githubusercontent.com/u/17477159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kamwoh", "html_url": "https://github.com/kamwoh", "followers_url": "https://api.github.com/users/kamwoh/followers", "following_url": "https://api.github.com/users/kamwoh/following{/other_user}", "gists_url": "https://api.github.com/users/kamwoh/gists{/gist_id}", "starred_url": "https://api.github.com/users/kamwoh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kamwoh/subscriptions", "organizations_url": "https://api.github.com/users/kamwoh/orgs", "repos_url": "https://api.github.com/users/kamwoh/repos", "events_url": "https://api.github.com/users/kamwoh/events{/privacy}", "received_events_url": "https://api.github.com/users/kamwoh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-11-08T12:10:47Z", "updated_at": "2018-11-20T17:38:57Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version (use command below): 1.11</li>\n<li>Python version: 3.6</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU model and memory:</li>\n</ul>\n<p>After convert to tf lite, my model cannot get the correct output, then i realise it is actually the slicing output is wrong.</p>\n<p>Code to reproduce the error</p>\n<pre><code>class TestModel2(object):\n    def __init__(self):\n        self.sess = tf.Session()\n\n        self.input_placeholder = tf.placeholder(tf.float32, [4, 2])\n\n        self.data = tf.constant([[0, 1, 2, 3],\n                                 [4, 5, 6, 7],\n                                 [8, 9, 10, 11],\n                                 [12, 13, 14, 15]], tf.float32, name='data')\n\n        self.data_slice = self.data[:, :2]\n\n        # self.output_node = self.input_placeholder * self.data_slice\n\n        self.sess.run(tf.global_variables_initializer())\n\n    def test_convert_tflite(self):\n        print('loading from session')\n        converter = tf.contrib.lite.TocoConverter.from_session(self.sess, [self.input_placeholder],\n                                                               [self.data_slice])\n        print('converting to tflite')\n        tflite_model = converter.convert()\n        open('dummy.tflite', 'wb').write(tflite_model)\n\n    def test_run(self, inputs):\n        output = self.sess.run([self.data_slice], feed_dict={self.input_placeholder: inputs})\n        print(output)\n        print('-')\n\nclass TestTFLite(object):\n    def __init__(self, path):\n        # Load TFLite model and allocate tensors.\n        interpreter = tf.contrib.lite.Interpreter(model_path=path)\n        interpreter.allocate_tensors()\n\n        # Get input and output tensors.\n        input_details = interpreter.get_input_details()\n        output_details = interpreter.get_output_details()\n\n        print('input tensor:', input_details[0])\n        print('output tensor:', output_details[0])\n\n        self.interpreter = interpreter\n        self.input_details = input_details\n        self.output_details = output_details\n\n    def test_run(self, inputs):\n        self.interpreter.set_tensor(self.input_details[0]['index'], inputs)\n        self.interpreter.invoke()\n\n        output = self.interpreter.get_tensor(self.output_details[0]['index'])\n        print(output)\n        # output = self.interpreter.get_tensor(self.output_details[1]['index'])\n        # print(output)\n\nif __name__ == '__main__':\n    np.random.seed(1000)\n    inputs = np.random.randn(4, 2).astype(np.float32)\n    tr = TestModel2()\n    tr.test_run(inputs)\n    tr.test_convert_tflite()\n\n    tl = TestTFLite('dummy.tflite')\n    tl.test_run(inputs)\n\n</code></pre>\n<p>tensorflow output</p>\n<pre><code>array([[ 0.,  1.],\n       [ 4.,  5.],\n       [ 8.,  9.],\n       [12., 13.]], dtype=float32)\n</code></pre>\n<p>TFLite output</p>\n<pre><code>[[ 0.  4.]\n [ 8. 12.]\n [ 1.  5.]\n [ 9. 13.]]\n</code></pre>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.11\nPython version: 3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\n\nAfter convert to tf lite, my model cannot get the correct output, then i realise it is actually the slicing output is wrong.\nCode to reproduce the error\nclass TestModel2(object):\n    def __init__(self):\n        self.sess = tf.Session()\n\n        self.input_placeholder = tf.placeholder(tf.float32, [4, 2])\n\n        self.data = tf.constant([[0, 1, 2, 3],\n                                 [4, 5, 6, 7],\n                                 [8, 9, 10, 11],\n                                 [12, 13, 14, 15]], tf.float32, name='data')\n\n        self.data_slice = self.data[:, :2]\n\n        # self.output_node = self.input_placeholder * self.data_slice\n\n        self.sess.run(tf.global_variables_initializer())\n\n    def test_convert_tflite(self):\n        print('loading from session')\n        converter = tf.contrib.lite.TocoConverter.from_session(self.sess, [self.input_placeholder],\n                                                               [self.data_slice])\n        print('converting to tflite')\n        tflite_model = converter.convert()\n        open('dummy.tflite', 'wb').write(tflite_model)\n\n    def test_run(self, inputs):\n        output = self.sess.run([self.data_slice], feed_dict={self.input_placeholder: inputs})\n        print(output)\n        print('-')\n\nclass TestTFLite(object):\n    def __init__(self, path):\n        # Load TFLite model and allocate tensors.\n        interpreter = tf.contrib.lite.Interpreter(model_path=path)\n        interpreter.allocate_tensors()\n\n        # Get input and output tensors.\n        input_details = interpreter.get_input_details()\n        output_details = interpreter.get_output_details()\n\n        print('input tensor:', input_details[0])\n        print('output tensor:', output_details[0])\n\n        self.interpreter = interpreter\n        self.input_details = input_details\n        self.output_details = output_details\n\n    def test_run(self, inputs):\n        self.interpreter.set_tensor(self.input_details[0]['index'], inputs)\n        self.interpreter.invoke()\n\n        output = self.interpreter.get_tensor(self.output_details[0]['index'])\n        print(output)\n        # output = self.interpreter.get_tensor(self.output_details[1]['index'])\n        # print(output)\n\nif __name__ == '__main__':\n    np.random.seed(1000)\n    inputs = np.random.randn(4, 2).astype(np.float32)\n    tr = TestModel2()\n    tr.test_run(inputs)\n    tr.test_convert_tflite()\n\n    tl = TestTFLite('dummy.tflite')\n    tl.test_run(inputs)\n\n\ntensorflow output\narray([[ 0.,  1.],\n       [ 4.,  5.],\n       [ 8.,  9.],\n       [12., 13.]], dtype=float32)\n\nTFLite output\n[[ 0.  4.]\n [ 8. 12.]\n [ 1.  5.]\n [ 9. 13.]]", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.11\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nAfter convert to tf lite, my model cannot get the correct output, then i realise it is actually the slicing output is wrong.\r\n\r\nCode to reproduce the error\r\n```\r\nclass TestModel2(object):\r\n    def __init__(self):\r\n        self.sess = tf.Session()\r\n\r\n        self.input_placeholder = tf.placeholder(tf.float32, [4, 2])\r\n\r\n        self.data = tf.constant([[0, 1, 2, 3],\r\n                                 [4, 5, 6, 7],\r\n                                 [8, 9, 10, 11],\r\n                                 [12, 13, 14, 15]], tf.float32, name='data')\r\n\r\n        self.data_slice = self.data[:, :2]\r\n\r\n        # self.output_node = self.input_placeholder * self.data_slice\r\n\r\n        self.sess.run(tf.global_variables_initializer())\r\n\r\n    def test_convert_tflite(self):\r\n        print('loading from session')\r\n        converter = tf.contrib.lite.TocoConverter.from_session(self.sess, [self.input_placeholder],\r\n                                                               [self.data_slice])\r\n        print('converting to tflite')\r\n        tflite_model = converter.convert()\r\n        open('dummy.tflite', 'wb').write(tflite_model)\r\n\r\n    def test_run(self, inputs):\r\n        output = self.sess.run([self.data_slice], feed_dict={self.input_placeholder: inputs})\r\n        print(output)\r\n        print('-')\r\n\r\nclass TestTFLite(object):\r\n    def __init__(self, path):\r\n        # Load TFLite model and allocate tensors.\r\n        interpreter = tf.contrib.lite.Interpreter(model_path=path)\r\n        interpreter.allocate_tensors()\r\n\r\n        # Get input and output tensors.\r\n        input_details = interpreter.get_input_details()\r\n        output_details = interpreter.get_output_details()\r\n\r\n        print('input tensor:', input_details[0])\r\n        print('output tensor:', output_details[0])\r\n\r\n        self.interpreter = interpreter\r\n        self.input_details = input_details\r\n        self.output_details = output_details\r\n\r\n    def test_run(self, inputs):\r\n        self.interpreter.set_tensor(self.input_details[0]['index'], inputs)\r\n        self.interpreter.invoke()\r\n\r\n        output = self.interpreter.get_tensor(self.output_details[0]['index'])\r\n        print(output)\r\n        # output = self.interpreter.get_tensor(self.output_details[1]['index'])\r\n        # print(output)\r\n\r\nif __name__ == '__main__':\r\n    np.random.seed(1000)\r\n    inputs = np.random.randn(4, 2).astype(np.float32)\r\n    tr = TestModel2()\r\n    tr.test_run(inputs)\r\n    tr.test_convert_tflite()\r\n\r\n    tl = TestTFLite('dummy.tflite')\r\n    tl.test_run(inputs)\r\n\r\n```\r\n\r\ntensorflow output\r\n```\r\narray([[ 0.,  1.],\r\n       [ 4.,  5.],\r\n       [ 8.,  9.],\r\n       [12., 13.]], dtype=float32)\r\n```\r\nTFLite output\r\n```\r\n[[ 0.  4.]\r\n [ 8. 12.]\r\n [ 1.  5.]\r\n [ 9. 13.]]\r\n```"}