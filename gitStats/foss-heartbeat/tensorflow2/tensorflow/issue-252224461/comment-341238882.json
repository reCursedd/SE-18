{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341238882", "html_url": "https://github.com/tensorflow/tensorflow/issues/12522#issuecomment-341238882", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12522", "id": 341238882, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTIzODg4Mg==", "user": {"login": "kjanjua26", "id": 14023660, "node_id": "MDQ6VXNlcjE0MDIzNjYw", "avatar_url": "https://avatars3.githubusercontent.com/u/14023660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kjanjua26", "html_url": "https://github.com/kjanjua26", "followers_url": "https://api.github.com/users/kjanjua26/followers", "following_url": "https://api.github.com/users/kjanjua26/following{/other_user}", "gists_url": "https://api.github.com/users/kjanjua26/gists{/gist_id}", "starred_url": "https://api.github.com/users/kjanjua26/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kjanjua26/subscriptions", "organizations_url": "https://api.github.com/users/kjanjua26/orgs", "repos_url": "https://api.github.com/users/kjanjua26/repos", "events_url": "https://api.github.com/users/kjanjua26/events{/privacy}", "received_events_url": "https://api.github.com/users/kjanjua26/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-01T20:52:42Z", "updated_at": "2017-11-01T20:52:42Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=29923691\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amundle-cs\">@amundle-cs</a> try to print the shape of the last layer, also, if it is 3D tensor, it is still not distributed over time. Re-shape the output of CNN like <code>(nb_samples, timesteps, nb_features)</code> and then you feed it to LSTM.<br>\nUse tf.squeeze on the output of CNN.<br>\n<code>lastCNN = tf.squeeze(lastCNN,[1])</code><br>\nThen you can feed this to LSTM in addition to the <code>sequenceLength</code> which is set according to the highest sequence in your ground truth.<br>\nHave a look: <a href=\"https://github.com/AimeeKing/crnn-tensorflow/blob/master/net/model.py\">https://github.com/AimeeKing/crnn-tensorflow/blob/master/net/model.py</a></p>", "body_text": "@amundle-cs try to print the shape of the last layer, also, if it is 3D tensor, it is still not distributed over time. Re-shape the output of CNN like (nb_samples, timesteps, nb_features) and then you feed it to LSTM.\nUse tf.squeeze on the output of CNN.\nlastCNN = tf.squeeze(lastCNN,[1])\nThen you can feed this to LSTM in addition to the sequenceLength which is set according to the highest sequence in your ground truth.\nHave a look: https://github.com/AimeeKing/crnn-tensorflow/blob/master/net/model.py", "body": "@amundle-cs try to print the shape of the last layer, also, if it is 3D tensor, it is still not distributed over time. Re-shape the output of CNN like `(nb_samples, timesteps, nb_features)` and then you feed it to LSTM.\r\nUse tf.squeeze on the output of CNN. \r\n`lastCNN = tf.squeeze(lastCNN,[1])`\r\nThen you can feed this to LSTM in addition to the `sequenceLength` which is set according to the highest sequence in your ground truth. \r\nHave a look: https://github.com/AimeeKing/crnn-tensorflow/blob/master/net/model.py"}