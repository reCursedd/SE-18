{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16929", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16929/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16929/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16929/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16929", "id": 296174602, "node_id": "MDU6SXNzdWUyOTYxNzQ2MDI=", "number": 16929, "title": "Tensorflow Lite toco convert a quantized model to tflite format crash error", "user": {"login": "sirius-ai", "id": 32933617, "node_id": "MDQ6VXNlcjMyOTMzNjE3", "avatar_url": "https://avatars2.githubusercontent.com/u/32933617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sirius-ai", "html_url": "https://github.com/sirius-ai", "followers_url": "https://api.github.com/users/sirius-ai/followers", "following_url": "https://api.github.com/users/sirius-ai/following{/other_user}", "gists_url": "https://api.github.com/users/sirius-ai/gists{/gist_id}", "starred_url": "https://api.github.com/users/sirius-ai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sirius-ai/subscriptions", "organizations_url": "https://api.github.com/users/sirius-ai/orgs", "repos_url": "https://api.github.com/users/sirius-ai/repos", "events_url": "https://api.github.com/users/sirius-ai/events{/privacy}", "received_events_url": "https://api.github.com/users/sirius-ai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-02-11T09:12:05Z", "updated_at": "2018-11-21T17:08:46Z", "closed_at": "2018-04-25T17:30:16Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: N</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 17.10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: r1.5 / r1.6</li>\n<li><strong>Python version</strong>: python2.7 / python 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: bazel release 0.9.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: GCC/G++ 7.2.0,</li>\n<li><strong>CUDA/cuDNN version</strong>: none</li>\n<li><strong>GPU model and memory</strong>: none</li>\n<li><strong>Exact command to reproduce</strong>: detail description in below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I use facenet framework which base on Inception_resnet_v1 to recognize face, and i use below command to quantize and convert a freeze graph pb file to tflite format:</p>\n<p>quantize cmd:</p>\n<p>bazel-bin/tensorflow/tools/graph_transforms/transform_graph <br>\n--in_graph=/home/andy/datasets/facenet/facenet_model.pb <br>\n--out_graph=/home/andy/datasets/facenet/facenet_model_quantized.pb <br>\n--inputs=input:0 <br>\n--outputs=embeddings:0 <br>\n--transforms='strip_unused_nodes(type=float, shape=\"1,160,160,3\")<br>\nremove_nodes(op=Identity, op=CheckNumerics)<br>\nfold_old_batch_norms<br>\nquantize_weights<br>\nstrip_unused_nodes<br>\nsort_by_execution_order'</p>\n<p>toco convert cmd:</p>\n<p>bazel-bin/tensorflow/contrib/lite/toco/toco <br>\n--input_format=TENSORFLOW_GRAPHDEF <br>\n--input_file=/home/andy/datasets/facenet/facenet_model_quantized.pb <br>\n--output_format=TFLITE <br>\n--output_file=/home/andy/datasets/facenet/facenet_model_quantized.lite <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--inference_input_type=QUANTIZED_UINT8 <br>\n--input_arrays=input <br>\n--output_arrays=embeddings <br>\n--input_shapes=1,160,160,3<br>\n--mean_values=128 <br>\n--std_values=128 <br>\n--default_ranges_min=0 <br>\n--default_ranges_max=6</p>\n<p>I sure facenet_model.pb and facenet_model_quantized.pb can be run normal, but when toco convert the quantized model to tensorflow lite format it crash below error:</p>\n<p><code>2018-02-11 16:52:44.901519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 16:52:44.901544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 16:52:44.906789: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform 2018-02-11 16:52:45.171561: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized) 2018-02-11 16:52:45.309297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 16:52:45.486937: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 16:52:45.489630: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] Check failed: predicate_array.data_type == ArrayDataType::kBool  Aborted (core dumped) </code></p>\n<p>for resolve the issue i add some debug code before the line of resolve_tensorflow_switch.cc:48, it's like that:</p>\n<p>LOG(INFO) &lt;&lt; \"###### predicate_name: \" &lt;&lt; LogName(*switch_op);<br>\nLOG(INFO) &lt;&lt; \"###### predicate_name: \" &lt;&lt; predicate_name;<br>\nswitch (predicate_array.data_type) {<br>\ncase ArrayDataType::kBool:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kBool\";<br>\nbreak;<br>\ncase ArrayDataType::kFloat:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kFloat\";<br>\nbreak;<br>\ncase ArrayDataType::kUint8:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kUint8\";<br>\nbreak;<br>\ncase ArrayDataType::kInt32:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kInt32\";<br>\nbreak;<br>\ncase ArrayDataType::kInt64:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kInt64\";<br>\nbreak;<br>\ncase ArrayDataType::kNone:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type kNone\";<br>\nbreak;<br>\ndefault:<br>\nLOG(INFO) &lt;&lt; \"###### predicate_array.data_type not know\";<br>\n}</p>\n<p>then, i rebuild the toco, and rerun the convert cmd, log show that:</p>\n<p><code>2018-02-11 17:01:34.481749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 17:01:34.486969: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform 2018-02-11 17:01:34.752556: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized) 2018-02-11 17:01:34.888735: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 17:01:35.063875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 17:01:35.066550: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] ###### predicate_name: {TensorFlowSwitch operator with output InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4} 2018-02-11 17:01:35.066558: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:49] ###### predicate_name: Const_1 2018-02-11 17:01:35.066562: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:67] ###### predicate_array.data_type kNone 2018-02-11 17:01:35.066565: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:72] Check failed: predicate_array.data_type == ArrayDataType::kBool  Aborted (core dumped) </code></p>\n<p>i don't know why the \"predicate_name: Const_1\" of op \"InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4\" it's data type is KNone, but the function ResolveTensorFlowSwitch::Run request it's data type should be KBool. The Inception_resnet_v1 Bottleneck is in a fully connect layer, and relation code show below:</p>\n<p>`<br>\nend_points = {}</p>\n<pre><code>with tf.variable_scope(scope, 'InceptionResnetV1', [inputs], reuse=reuse):\n    with slim.arg_scope([slim.batch_norm, slim.dropout],\n                        is_training=is_training):\n        with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                            stride=1, padding='SAME'):\n  \n            # 149 x 149 x 32\n            net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\n                              scope='Conv2d_1a_3x3')\n            end_points['Conv2d_1a_3x3'] = net\n            # 147 x 147 x 32\n            net = slim.conv2d(net, 32, 3, padding='VALID',\n                              scope='Conv2d_2a_3x3')\n            end_points['Conv2d_2a_3x3'] = net\n            # 147 x 147 x 64\n            net = slim.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')\n            end_points['Conv2d_2b_3x3'] = net\n            # 73 x 73 x 64\n            net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                                  scope='MaxPool_3a_3x3')\n            end_points['MaxPool_3a_3x3'] = net\n            # 73 x 73 x 80\n            net = slim.conv2d(net, 80, 1, padding='VALID',\n                              scope='Conv2d_3b_1x1')\n            end_points['Conv2d_3b_1x1'] = net\n            # 71 x 71 x 192\n            net = slim.conv2d(net, 192, 3, padding='VALID',\n                              scope='Conv2d_4a_3x3')\n            end_points['Conv2d_4a_3x3'] = net\n            # 35 x 35 x 256\n            net = slim.conv2d(net, 256, 3, stride=2, padding='VALID',\n                              scope='Conv2d_4b_3x3')\n            end_points['Conv2d_4b_3x3'] = net\n            \n            # 5 x Inception-resnet-A\n            net = slim.repeat(net, 5, block35, scale=0.17)\n            end_points['Mixed_5a'] = net\n    \n            # Reduction-A\n            with tf.variable_scope('Mixed_6a'):\n                net = reduction_a(net, 192, 192, 256, 384)\n            end_points['Mixed_6a'] = net\n            \n            # 10 x Inception-Resnet-B\n            net = slim.repeat(net, 10, block17, scale=0.10)\n            end_points['Mixed_6b'] = net\n            \n            # Reduction-B\n            with tf.variable_scope('Mixed_7a'):\n                net = reduction_b(net)\n            end_points['Mixed_7a'] = net\n            \n            # 5 x Inception-Resnet-C\n            net = slim.repeat(net, 5, block8, scale=0.20)\n            end_points['Mixed_8a'] = net\n            \n            net = block8(net, activation_fn=None)\n            end_points['Mixed_8b'] = net\n            \n            with tf.variable_scope('Logits'):\n                end_points['PrePool'] = net\n                #pylint: disable=no-member\n                net = slim.avg_pool2d(net, net.get_shape()[1:3], padding='VALID',\n                                      scope='AvgPool_1a_8x8')\n                net = slim.flatten(net)\n      \n                net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n                                   scope='Dropout')\n      \n                end_points['PreLogitsFlatten'] = net\n            \n            net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \n                    scope='Bottleneck', reuse=False)\n\nreturn net, end_points\n</code></pre>\n<p>`</p>\n<p>how can i solve the issue, and which step of convert cmd is it wrong?<br>\ni hold someone can help me, thanks!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): r1.5 / r1.6\nPython version: python2.7 / python 3.6\nBazel version (if compiling from source): bazel release 0.9.0\nGCC/Compiler version (if compiling from source): GCC/G++ 7.2.0,\nCUDA/cuDNN version: none\nGPU model and memory: none\nExact command to reproduce: detail description in below\n\nDescribe the problem\nI use facenet framework which base on Inception_resnet_v1 to recognize face, and i use below command to quantize and convert a freeze graph pb file to tflite format:\nquantize cmd:\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \n--in_graph=/home/andy/datasets/facenet/facenet_model.pb \n--out_graph=/home/andy/datasets/facenet/facenet_model_quantized.pb \n--inputs=input:0 \n--outputs=embeddings:0 \n--transforms='strip_unused_nodes(type=float, shape=\"1,160,160,3\")\nremove_nodes(op=Identity, op=CheckNumerics)\nfold_old_batch_norms\nquantize_weights\nstrip_unused_nodes\nsort_by_execution_order'\ntoco convert cmd:\nbazel-bin/tensorflow/contrib/lite/toco/toco \n--input_format=TENSORFLOW_GRAPHDEF \n--input_file=/home/andy/datasets/facenet/facenet_model_quantized.pb \n--output_format=TFLITE \n--output_file=/home/andy/datasets/facenet/facenet_model_quantized.lite \n--inference_type=QUANTIZED_UINT8 \n--inference_input_type=QUANTIZED_UINT8 \n--input_arrays=input \n--output_arrays=embeddings \n--input_shapes=1,160,160,3\n--mean_values=128 \n--std_values=128 \n--default_ranges_min=0 \n--default_ranges_max=6\nI sure facenet_model.pb and facenet_model_quantized.pb can be run normal, but when toco convert the quantized model to tensorflow lite format it crash below error:\n2018-02-11 16:52:44.901519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 16:52:44.901544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 16:52:44.906789: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform 2018-02-11 16:52:45.171561: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized) 2018-02-11 16:52:45.309297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 16:52:45.486937: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 16:52:45.489630: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] Check failed: predicate_array.data_type == ArrayDataType::kBool  Aborted (core dumped) \nfor resolve the issue i add some debug code before the line of resolve_tensorflow_switch.cc:48, it's like that:\nLOG(INFO) << \"###### predicate_name: \" << LogName(*switch_op);\nLOG(INFO) << \"###### predicate_name: \" << predicate_name;\nswitch (predicate_array.data_type) {\ncase ArrayDataType::kBool:\nLOG(INFO) << \"###### predicate_array.data_type kBool\";\nbreak;\ncase ArrayDataType::kFloat:\nLOG(INFO) << \"###### predicate_array.data_type kFloat\";\nbreak;\ncase ArrayDataType::kUint8:\nLOG(INFO) << \"###### predicate_array.data_type kUint8\";\nbreak;\ncase ArrayDataType::kInt32:\nLOG(INFO) << \"###### predicate_array.data_type kInt32\";\nbreak;\ncase ArrayDataType::kInt64:\nLOG(INFO) << \"###### predicate_array.data_type kInt64\";\nbreak;\ncase ArrayDataType::kNone:\nLOG(INFO) << \"###### predicate_array.data_type kNone\";\nbreak;\ndefault:\nLOG(INFO) << \"###### predicate_array.data_type not know\";\n}\nthen, i rebuild the toco, and rerun the convert cmd, log show that:\n2018-02-11 17:01:34.481749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize 2018-02-11 17:01:34.486969: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform 2018-02-11 17:01:34.752556: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized) 2018-02-11 17:01:34.888735: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 17:01:35.063875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized) 2018-02-11 17:01:35.066550: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] ###### predicate_name: {TensorFlowSwitch operator with output InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4} 2018-02-11 17:01:35.066558: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:49] ###### predicate_name: Const_1 2018-02-11 17:01:35.066562: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:67] ###### predicate_array.data_type kNone 2018-02-11 17:01:35.066565: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:72] Check failed: predicate_array.data_type == ArrayDataType::kBool  Aborted (core dumped) \ni don't know why the \"predicate_name: Const_1\" of op \"InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4\" it's data type is KNone, but the function ResolveTensorFlowSwitch::Run request it's data type should be KBool. The Inception_resnet_v1 Bottleneck is in a fully connect layer, and relation code show below:\n`\nend_points = {}\nwith tf.variable_scope(scope, 'InceptionResnetV1', [inputs], reuse=reuse):\n    with slim.arg_scope([slim.batch_norm, slim.dropout],\n                        is_training=is_training):\n        with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                            stride=1, padding='SAME'):\n  \n            # 149 x 149 x 32\n            net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\n                              scope='Conv2d_1a_3x3')\n            end_points['Conv2d_1a_3x3'] = net\n            # 147 x 147 x 32\n            net = slim.conv2d(net, 32, 3, padding='VALID',\n                              scope='Conv2d_2a_3x3')\n            end_points['Conv2d_2a_3x3'] = net\n            # 147 x 147 x 64\n            net = slim.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')\n            end_points['Conv2d_2b_3x3'] = net\n            # 73 x 73 x 64\n            net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                                  scope='MaxPool_3a_3x3')\n            end_points['MaxPool_3a_3x3'] = net\n            # 73 x 73 x 80\n            net = slim.conv2d(net, 80, 1, padding='VALID',\n                              scope='Conv2d_3b_1x1')\n            end_points['Conv2d_3b_1x1'] = net\n            # 71 x 71 x 192\n            net = slim.conv2d(net, 192, 3, padding='VALID',\n                              scope='Conv2d_4a_3x3')\n            end_points['Conv2d_4a_3x3'] = net\n            # 35 x 35 x 256\n            net = slim.conv2d(net, 256, 3, stride=2, padding='VALID',\n                              scope='Conv2d_4b_3x3')\n            end_points['Conv2d_4b_3x3'] = net\n            \n            # 5 x Inception-resnet-A\n            net = slim.repeat(net, 5, block35, scale=0.17)\n            end_points['Mixed_5a'] = net\n    \n            # Reduction-A\n            with tf.variable_scope('Mixed_6a'):\n                net = reduction_a(net, 192, 192, 256, 384)\n            end_points['Mixed_6a'] = net\n            \n            # 10 x Inception-Resnet-B\n            net = slim.repeat(net, 10, block17, scale=0.10)\n            end_points['Mixed_6b'] = net\n            \n            # Reduction-B\n            with tf.variable_scope('Mixed_7a'):\n                net = reduction_b(net)\n            end_points['Mixed_7a'] = net\n            \n            # 5 x Inception-Resnet-C\n            net = slim.repeat(net, 5, block8, scale=0.20)\n            end_points['Mixed_8a'] = net\n            \n            net = block8(net, activation_fn=None)\n            end_points['Mixed_8b'] = net\n            \n            with tf.variable_scope('Logits'):\n                end_points['PrePool'] = net\n                #pylint: disable=no-member\n                net = slim.avg_pool2d(net, net.get_shape()[1:3], padding='VALID',\n                                      scope='AvgPool_1a_8x8')\n                net = slim.flatten(net)\n      \n                net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n                                   scope='Dropout')\n      \n                end_points['PreLogitsFlatten'] = net\n            \n            net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \n                    scope='Bottleneck', reuse=False)\n\nreturn net, end_points\n\n`\nhow can i solve the issue, and which step of convert cmd is it wrong?\ni hold someone can help me, thanks!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: r1.5 / r1.6\r\n- **Python version**: python2.7 / python 3.6\r\n- **Bazel version (if compiling from source)**: bazel release 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: GCC/G++ 7.2.0, \r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: detail description in below\r\n\r\n### Describe the problem\r\n\r\nI use facenet framework which base on Inception_resnet_v1 to recognize face, and i use below command to quantize and convert a freeze graph pb file to tflite format:\r\n\r\nquantize cmd:\r\n\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n   --in_graph=/home/andy/datasets/facenet/facenet_model.pb \\\r\n   --out_graph=/home/andy/datasets/facenet/facenet_model_quantized.pb \\\r\n   --inputs=input:0 \\\r\n   --outputs=embeddings:0 \\\r\n   --transforms='strip_unused_nodes(type=float, shape=\"1,160,160,3\")\r\n    remove_nodes(op=Identity, op=CheckNumerics)\r\n    fold_old_batch_norms\r\n    quantize_weights\r\n    strip_unused_nodes \r\n    sort_by_execution_order'\r\n\r\ntoco convert cmd:\r\n\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --input_file=/home/andy/datasets/facenet/facenet_model_quantized.pb \\\r\n  --output_format=TFLITE \\\r\n  --output_file=/home/andy/datasets/facenet/facenet_model_quantized.lite \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --inference_input_type=QUANTIZED_UINT8 \\\r\n  --input_arrays=input \\\r\n  --output_arrays=embeddings \\\r\n  --input_shapes=1,160,160,3\\\r\n  --mean_values=128 \\\r\n  --std_values=128 \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6\r\n\r\nI sure facenet_model.pb and facenet_model_quantized.pb can be run normal, but when toco convert the quantized model to tensorflow lite format it crash below error:\r\n\r\n`2018-02-11 16:52:44.901519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 16:52:44.901544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 16:52:44.906789: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\r\n2018-02-11 16:52:45.171561: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized)\r\n2018-02-11 16:52:45.309297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 16:52:45.486937: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 16:52:45.489630: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] Check failed: predicate_array.data_type == ArrayDataType::kBool \r\nAborted (core dumped)\r\n`\r\n\r\nfor resolve the issue i add some debug code before the line of resolve_tensorflow_switch.cc:48, it's like that:\r\n\r\nLOG(INFO) << \"###### predicate_name: \" << LogName(*switch_op);\r\nLOG(INFO) << \"###### predicate_name: \" << predicate_name;\r\nswitch (predicate_array.data_type) {\r\ncase ArrayDataType::kBool:\r\n  LOG(INFO) << \"###### predicate_array.data_type kBool\";\r\n  break;\r\ncase ArrayDataType::kFloat:\r\n  LOG(INFO) << \"###### predicate_array.data_type kFloat\";\r\n  break;\r\ncase ArrayDataType::kUint8:\r\n  LOG(INFO) << \"###### predicate_array.data_type kUint8\";\r\n  break;\r\ncase ArrayDataType::kInt32:\r\n  LOG(INFO) << \"###### predicate_array.data_type kInt32\";\r\n  break;\r\ncase ArrayDataType::kInt64:\r\n  LOG(INFO) << \"###### predicate_array.data_type kInt64\";\r\n  break;\r\ncase ArrayDataType::kNone:\r\n  LOG(INFO) << \"###### predicate_array.data_type kNone\";\r\n  break;\r\ndefault:\r\n  LOG(INFO) << \"###### predicate_array.data_type not know\";\r\n}\r\n\r\nthen, i rebuild the toco, and rerun the convert cmd, log show that:\r\n\r\n`2018-02-11 17:01:34.481749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 17:01:34.486969: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\r\n2018-02-11 17:01:34.752556: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized)\r\n2018-02-11 17:01:34.888735: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 17:01:35.063875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 17:01:35.066550: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] ###### predicate_name: {TensorFlowSwitch operator with output InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4}\r\n2018-02-11 17:01:35.066558: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:49] ###### predicate_name: Const_1\r\n2018-02-11 17:01:35.066562: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:67] ###### predicate_array.data_type kNone\r\n2018-02-11 17:01:35.066565: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:72] Check failed: predicate_array.data_type == ArrayDataType::kBool \r\nAborted (core dumped)\r\n`\r\n\r\ni don't know why the \"predicate_name: Const_1\" of op \"InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4\" it's data type is KNone, but the function ResolveTensorFlowSwitch::Run request it's data type should be KBool. The Inception_resnet_v1 Bottleneck is in a fully connect layer, and relation code show below:\r\n \r\n`\r\nend_points = {}\r\n  \r\n    with tf.variable_scope(scope, 'InceptionResnetV1', [inputs], reuse=reuse):\r\n        with slim.arg_scope([slim.batch_norm, slim.dropout],\r\n                            is_training=is_training):\r\n            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\r\n                                stride=1, padding='SAME'):\r\n      \r\n                # 149 x 149 x 32\r\n                net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\r\n                                  scope='Conv2d_1a_3x3')\r\n                end_points['Conv2d_1a_3x3'] = net\r\n                # 147 x 147 x 32\r\n                net = slim.conv2d(net, 32, 3, padding='VALID',\r\n                                  scope='Conv2d_2a_3x3')\r\n                end_points['Conv2d_2a_3x3'] = net\r\n                # 147 x 147 x 64\r\n                net = slim.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')\r\n                end_points['Conv2d_2b_3x3'] = net\r\n                # 73 x 73 x 64\r\n                net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\r\n                                      scope='MaxPool_3a_3x3')\r\n                end_points['MaxPool_3a_3x3'] = net\r\n                # 73 x 73 x 80\r\n                net = slim.conv2d(net, 80, 1, padding='VALID',\r\n                                  scope='Conv2d_3b_1x1')\r\n                end_points['Conv2d_3b_1x1'] = net\r\n                # 71 x 71 x 192\r\n                net = slim.conv2d(net, 192, 3, padding='VALID',\r\n                                  scope='Conv2d_4a_3x3')\r\n                end_points['Conv2d_4a_3x3'] = net\r\n                # 35 x 35 x 256\r\n                net = slim.conv2d(net, 256, 3, stride=2, padding='VALID',\r\n                                  scope='Conv2d_4b_3x3')\r\n                end_points['Conv2d_4b_3x3'] = net\r\n                \r\n                # 5 x Inception-resnet-A\r\n                net = slim.repeat(net, 5, block35, scale=0.17)\r\n                end_points['Mixed_5a'] = net\r\n        \r\n                # Reduction-A\r\n                with tf.variable_scope('Mixed_6a'):\r\n                    net = reduction_a(net, 192, 192, 256, 384)\r\n                end_points['Mixed_6a'] = net\r\n                \r\n                # 10 x Inception-Resnet-B\r\n                net = slim.repeat(net, 10, block17, scale=0.10)\r\n                end_points['Mixed_6b'] = net\r\n                \r\n                # Reduction-B\r\n                with tf.variable_scope('Mixed_7a'):\r\n                    net = reduction_b(net)\r\n                end_points['Mixed_7a'] = net\r\n                \r\n                # 5 x Inception-Resnet-C\r\n                net = slim.repeat(net, 5, block8, scale=0.20)\r\n                end_points['Mixed_8a'] = net\r\n                \r\n                net = block8(net, activation_fn=None)\r\n                end_points['Mixed_8b'] = net\r\n                \r\n                with tf.variable_scope('Logits'):\r\n                    end_points['PrePool'] = net\r\n                    #pylint: disable=no-member\r\n                    net = slim.avg_pool2d(net, net.get_shape()[1:3], padding='VALID',\r\n                                          scope='AvgPool_1a_8x8')\r\n                    net = slim.flatten(net)\r\n          \r\n                    net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                                       scope='Dropout')\r\n          \r\n                    end_points['PreLogitsFlatten'] = net\r\n                \r\n                net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \r\n                        scope='Bottleneck', reuse=False)\r\n  \r\n    return net, end_points\r\n`\r\n\r\nhow can i solve the issue, and which step of convert cmd is it wrong?\r\ni hold someone can help me, thanks!\r\n"}