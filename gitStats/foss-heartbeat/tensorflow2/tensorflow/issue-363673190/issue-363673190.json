{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22505", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22505/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22505/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22505/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22505", "id": 363673190, "node_id": "MDU6SXNzdWUzNjM2NzMxOTA=", "number": 22505, "title": "Lookup Error : Gradient Registry has no entry for  StatefulPartitionedCall", "user": {"login": "vibss2397", "id": 22891797, "node_id": "MDQ6VXNlcjIyODkxNzk3", "avatar_url": "https://avatars1.githubusercontent.com/u/22891797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vibss2397", "html_url": "https://github.com/vibss2397", "followers_url": "https://api.github.com/users/vibss2397/followers", "following_url": "https://api.github.com/users/vibss2397/following{/other_user}", "gists_url": "https://api.github.com/users/vibss2397/gists{/gist_id}", "starred_url": "https://api.github.com/users/vibss2397/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vibss2397/subscriptions", "organizations_url": "https://api.github.com/users/vibss2397/orgs", "repos_url": "https://api.github.com/users/vibss2397/repos", "events_url": "https://api.github.com/users/vibss2397/events{/privacy}", "received_events_url": "https://api.github.com/users/vibss2397/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 1097547147, "node_id": "MDU6TGFiZWwxMDk3NTQ3MTQ3", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:ops", "name": "comp:ops", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-25T16:52:46Z", "updated_at": "2018-11-22T16:37:46Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: v9.0 (Cuda)</li>\n<li><strong>GPU model and memory</strong>: gtx 930m, 2GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I was implementing the gradient penalty for improved stability for wgan in tensorflow eager</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.GradientTape() <span class=\"pl-k\">as</span> critic_tape:\n    generated_images <span class=\"pl-k\">=</span> generator(tf.random_normal([<span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">100</span>]), <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    a <span class=\"pl-k\">=</span> tf.convert_to_tensor(images)\n    real_output <span class=\"pl-k\">=</span> critic(a, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    generated_output <span class=\"pl-k\">=</span> critic(generated_images, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)               \n    <span class=\"pl-k\">with</span> tf.GradientTape() <span class=\"pl-k\">as</span> gtape:\n        epsilon <span class=\"pl-k\">=</span> tf.random_uniform([], <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>)\n        xhat <span class=\"pl-k\">=</span> epsilon<span class=\"pl-k\">*</span>a <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>epsilon)<span class=\"pl-k\">*</span>generated_images\n        dhat <span class=\"pl-k\">=</span> critic(xhat, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        gtape.watch(xhat)\n    dhat2 <span class=\"pl-k\">=</span> gtape.gradient(dhat, xhat)\n    slopes <span class=\"pl-k\">=</span> tf.sqrt(tf.reduce_sum(tf.square(dhat2), <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>]))\n    gradient_penalty <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span><span class=\"pl-k\">*</span>tf.reduce_mean((slopes<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>)<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>)\n    critic_loss <span class=\"pl-k\">=</span> get_critic_loss(real_output, generated_output)\n    critic_loss<span class=\"pl-k\">+=</span> gradient_penalty                \ngradients_of_critic <span class=\"pl-k\">=</span> critic_tape.gradient(critic_loss, critic.variables)\n<span class=\"pl-c1\">print</span>(gradients_of_critic) </pre></div>\n<p>and the error stack i recieve is</p>\n<pre lang=\"--------------------------------------------------------------------------\"><code>LookupError                               Traceback (most recent call last)\n&lt;ipython-input-512-cbc8ebf905ac&gt; in &lt;module&gt;()\n     16     critic_loss = get_critic_loss(real_output, generated_output)\n     17     critic_loss+= gradient_penalty\n---&gt; 18 gradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\n     19 print(gradients_of_critic)\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in gradient(self, target, sources, output_gradients)\n    856     flat_grad = imperative_grad.imperative_grad(\n    857         _default_vspace, self._tape, nest.flatten(target), flat_sources,\n--&gt; 858         output_gradients=output_gradients)\n    859 \n    860     if not self._persistent:\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py in imperative_grad(vspace, tape, target, sources, output_gradients)\n     61   \"\"\"\n     62   return pywrap_tensorflow.TFE_Py_TapeGradient(\n---&gt; 63       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\n    110   \"\"\"\n    111   mock_op = _MockOp(attr_tuple, inputs, outputs, op_name)\n--&gt; 112   grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    113   if grad_fn is None:\n    114     return [None] * num_inputs\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py in lookup(self, name)\n     91     else:\n     92       raise LookupError(\n---&gt; 93           \"%s registry has no entry for: %s\" % (self._name, name))\n\nLookupError: gradient registry has no entry for: StatefulPartitionedCall\n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.10.1\nPython version: 3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: v9.0 (Cuda)\nGPU model and memory: gtx 930m, 2GB\nExact command to reproduce:\n\nDescribe the problem\nI was implementing the gradient penalty for improved stability for wgan in tensorflow eager\nSource code / logs\nwith tf.GradientTape() as critic_tape:\n    generated_images = generator(tf.random_normal([16, 100]), training=True)\n    a = tf.convert_to_tensor(images)\n    real_output = critic(a, training=True)\n    generated_output = critic(generated_images, training=True)               \n    with tf.GradientTape() as gtape:\n        epsilon = tf.random_uniform([], 0, 1)\n        xhat = epsilon*a + (1-epsilon)*generated_images\n        dhat = critic(xhat, training=True)\n        gtape.watch(xhat)\n    dhat2 = gtape.gradient(dhat, xhat)\n    slopes = tf.sqrt(tf.reduce_sum(tf.square(dhat2), reduction_indices=[1]))\n    gradient_penalty = 10*tf.reduce_mean((slopes-1.0)**2)\n    critic_loss = get_critic_loss(real_output, generated_output)\n    critic_loss+= gradient_penalty                \ngradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\nprint(gradients_of_critic) \nand the error stack i recieve is\nLookupError                               Traceback (most recent call last)\n<ipython-input-512-cbc8ebf905ac> in <module>()\n     16     critic_loss = get_critic_loss(real_output, generated_output)\n     17     critic_loss+= gradient_penalty\n---> 18 gradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\n     19 print(gradients_of_critic)\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in gradient(self, target, sources, output_gradients)\n    856     flat_grad = imperative_grad.imperative_grad(\n    857         _default_vspace, self._tape, nest.flatten(target), flat_sources,\n--> 858         output_gradients=output_gradients)\n    859 \n    860     if not self._persistent:\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py in imperative_grad(vspace, tape, target, sources, output_gradients)\n     61   \"\"\"\n     62   return pywrap_tensorflow.TFE_Py_TapeGradient(\n---> 63       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\n    110   \"\"\"\n    111   mock_op = _MockOp(attr_tuple, inputs, outputs, op_name)\n--> 112   grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    113   if grad_fn is None:\n    114     return [None] * num_inputs\n\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py in lookup(self, name)\n     91     else:\n     92       raise LookupError(\n---> 93           \"%s registry has no entry for: %s\" % (self._name, name))\n\nLookupError: gradient registry has no entry for: StatefulPartitionedCall", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: v9.0 (Cuda)\r\n- **GPU model and memory**: gtx 930m, 2GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI was implementing the gradient penalty for improved stability for wgan in tensorflow eager\r\n\r\n### Source code / logs\r\n``` python\r\nwith tf.GradientTape() as critic_tape:\r\n    generated_images = generator(tf.random_normal([16, 100]), training=True)\r\n    a = tf.convert_to_tensor(images)\r\n    real_output = critic(a, training=True)\r\n    generated_output = critic(generated_images, training=True)               \r\n    with tf.GradientTape() as gtape:\r\n        epsilon = tf.random_uniform([], 0, 1)\r\n        xhat = epsilon*a + (1-epsilon)*generated_images\r\n        dhat = critic(xhat, training=True)\r\n        gtape.watch(xhat)\r\n    dhat2 = gtape.gradient(dhat, xhat)\r\n    slopes = tf.sqrt(tf.reduce_sum(tf.square(dhat2), reduction_indices=[1]))\r\n    gradient_penalty = 10*tf.reduce_mean((slopes-1.0)**2)\r\n    critic_loss = get_critic_loss(real_output, generated_output)\r\n    critic_loss+= gradient_penalty                \r\ngradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\r\nprint(gradients_of_critic) \r\n```\r\n\r\nand the error stack i recieve is \r\n```--------------------------------------------------------------------------\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-512-cbc8ebf905ac> in <module>()\r\n     16     critic_loss = get_critic_loss(real_output, generated_output)\r\n     17     critic_loss+= gradient_penalty\r\n---> 18 gradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\r\n     19 print(gradients_of_critic)\r\n\r\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in gradient(self, target, sources, output_gradients)\r\n    856     flat_grad = imperative_grad.imperative_grad(\r\n    857         _default_vspace, self._tape, nest.flatten(target), flat_sources,\r\n--> 858         output_gradients=output_gradients)\r\n    859 \r\n    860     if not self._persistent:\r\n\r\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py in imperative_grad(vspace, tape, target, sources, output_gradients)\r\n     61   \"\"\"\r\n     62   return pywrap_tensorflow.TFE_Py_TapeGradient(\r\n---> 63       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\r\n\r\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\r\n    110   \"\"\"\r\n    111   mock_op = _MockOp(attr_tuple, inputs, outputs, op_name)\r\n--> 112   grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\r\n    113   if grad_fn is None:\r\n    114     return [None] * num_inputs\r\n\r\nc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py in lookup(self, name)\r\n     91     else:\r\n     92       raise LookupError(\r\n---> 93           \"%s registry has no entry for: %s\" % (self._name, name))\r\n\r\nLookupError: gradient registry has no entry for: StatefulPartitionedCall\r\n\r\n"}