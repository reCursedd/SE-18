{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397409213", "html_url": "https://github.com/tensorflow/tensorflow/issues/20026#issuecomment-397409213", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20026", "id": 397409213, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzQwOTIxMw==", "user": {"login": "jrbtaylor", "id": 15191858, "node_id": "MDQ6VXNlcjE1MTkxODU4", "avatar_url": "https://avatars3.githubusercontent.com/u/15191858?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbtaylor", "html_url": "https://github.com/jrbtaylor", "followers_url": "https://api.github.com/users/jrbtaylor/followers", "following_url": "https://api.github.com/users/jrbtaylor/following{/other_user}", "gists_url": "https://api.github.com/users/jrbtaylor/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbtaylor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbtaylor/subscriptions", "organizations_url": "https://api.github.com/users/jrbtaylor/orgs", "repos_url": "https://api.github.com/users/jrbtaylor/repos", "events_url": "https://api.github.com/users/jrbtaylor/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbtaylor/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-14T19:20:31Z", "updated_at": "2018-06-14T19:20:31Z", "author_association": "NONE", "body_html": "<p>Here's a self-contained example:</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import graph_editor as ge\n\ndef prune_test():\n    # make a simple graph\n    x = tf.placeholder(tf.float32, shape=[1, 2], name='x')\n    w0 = tf.Variable(np.array([[1, 2, 3, 4], [6, 7, 8, 9]], dtype=np.float32), name='w0')\n    x1 = tf.matmul(x, w0, name='x1')\n    w1 = tf.Variable(np.array([[-1], [2], [-3], [4]], dtype=np.float32), name='w1')\n    y = tf.matmul(x1, w1, name='y')\n\n    def vars_to_tensors(v_list):\n        def rsub(string, sub):\n            return string[:len(string)-len(sub)] if string.endswith(sub) else string\n        graph = tf.get_default_graph()\n        nodes = [n for n in graph.as_graph_def().node if n.op == 'VariableV2']\n        nodes = [next(n for n in nodes if rsub(v.name, ':0') == rsub(n.name, ':0')) for v in v_list]\n        return [graph.get_tensor_by_name(node.name + ':0') for node in nodes]\n\n    w0p = tf.Variable(np.array([[1, 2, 3], [6, 7, 8]], dtype=np.float32), name='w0_pruned')\n    w1p = tf.Variable(np.array([[-1], [2], [-3]], dtype=np.float32), name='w1_pruned')\n\n    # get tensors since graph_replace doesn't work with variables directly\n    [w0, w1, w0p, w1p] = vars_to_tensors([w0, w1, w0p, w1p])\n    replacements = {w0: w0p, w1: w1p}\n    yp = ge.graph_replace(y, replacements)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        output, pruned_output = sess.run([y, yp], feed_dict={x: [[4., 7.]]})\n    print(output)\n    print(pruned_output)\n</code></pre>\n<p>With the default value for copy_shape in copy_op_handler set to True, this fails with a shape error. With it set to False, this runs as expected.</p>", "body_text": "Here's a self-contained example:\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import graph_editor as ge\n\ndef prune_test():\n    # make a simple graph\n    x = tf.placeholder(tf.float32, shape=[1, 2], name='x')\n    w0 = tf.Variable(np.array([[1, 2, 3, 4], [6, 7, 8, 9]], dtype=np.float32), name='w0')\n    x1 = tf.matmul(x, w0, name='x1')\n    w1 = tf.Variable(np.array([[-1], [2], [-3], [4]], dtype=np.float32), name='w1')\n    y = tf.matmul(x1, w1, name='y')\n\n    def vars_to_tensors(v_list):\n        def rsub(string, sub):\n            return string[:len(string)-len(sub)] if string.endswith(sub) else string\n        graph = tf.get_default_graph()\n        nodes = [n for n in graph.as_graph_def().node if n.op == 'VariableV2']\n        nodes = [next(n for n in nodes if rsub(v.name, ':0') == rsub(n.name, ':0')) for v in v_list]\n        return [graph.get_tensor_by_name(node.name + ':0') for node in nodes]\n\n    w0p = tf.Variable(np.array([[1, 2, 3], [6, 7, 8]], dtype=np.float32), name='w0_pruned')\n    w1p = tf.Variable(np.array([[-1], [2], [-3]], dtype=np.float32), name='w1_pruned')\n\n    # get tensors since graph_replace doesn't work with variables directly\n    [w0, w1, w0p, w1p] = vars_to_tensors([w0, w1, w0p, w1p])\n    replacements = {w0: w0p, w1: w1p}\n    yp = ge.graph_replace(y, replacements)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        output, pruned_output = sess.run([y, yp], feed_dict={x: [[4., 7.]]})\n    print(output)\n    print(pruned_output)\n\nWith the default value for copy_shape in copy_op_handler set to True, this fails with a shape error. With it set to False, this runs as expected.", "body": "Here's a self-contained example:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import graph_editor as ge\r\n\r\ndef prune_test():\r\n    # make a simple graph\r\n    x = tf.placeholder(tf.float32, shape=[1, 2], name='x')\r\n    w0 = tf.Variable(np.array([[1, 2, 3, 4], [6, 7, 8, 9]], dtype=np.float32), name='w0')\r\n    x1 = tf.matmul(x, w0, name='x1')\r\n    w1 = tf.Variable(np.array([[-1], [2], [-3], [4]], dtype=np.float32), name='w1')\r\n    y = tf.matmul(x1, w1, name='y')\r\n\r\n    def vars_to_tensors(v_list):\r\n        def rsub(string, sub):\r\n            return string[:len(string)-len(sub)] if string.endswith(sub) else string\r\n        graph = tf.get_default_graph()\r\n        nodes = [n for n in graph.as_graph_def().node if n.op == 'VariableV2']\r\n        nodes = [next(n for n in nodes if rsub(v.name, ':0') == rsub(n.name, ':0')) for v in v_list]\r\n        return [graph.get_tensor_by_name(node.name + ':0') for node in nodes]\r\n\r\n    w0p = tf.Variable(np.array([[1, 2, 3], [6, 7, 8]], dtype=np.float32), name='w0_pruned')\r\n    w1p = tf.Variable(np.array([[-1], [2], [-3]], dtype=np.float32), name='w1_pruned')\r\n\r\n    # get tensors since graph_replace doesn't work with variables directly\r\n    [w0, w1, w0p, w1p] = vars_to_tensors([w0, w1, w0p, w1p])\r\n    replacements = {w0: w0p, w1: w1p}\r\n    yp = ge.graph_replace(y, replacements)\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        output, pruned_output = sess.run([y, yp], feed_dict={x: [[4., 7.]]})\r\n    print(output)\r\n    print(pruned_output)\r\n```\r\n\r\nWith the default value for copy_shape in copy_op_handler set to True, this fails with a shape error. With it set to False, this runs as expected."}