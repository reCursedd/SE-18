{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9001", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9001/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9001/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9001/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9001", "id": 219736079, "node_id": "MDU6SXNzdWUyMTk3MzYwNzk=", "number": 9001, "title": "Feature Request : Stochastic Depth", "user": {"login": "alexanderalang", "id": 22649804, "node_id": "MDQ6VXNlcjIyNjQ5ODA0", "avatar_url": "https://avatars1.githubusercontent.com/u/22649804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexanderalang", "html_url": "https://github.com/alexanderalang", "followers_url": "https://api.github.com/users/alexanderalang/followers", "following_url": "https://api.github.com/users/alexanderalang/following{/other_user}", "gists_url": "https://api.github.com/users/alexanderalang/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexanderalang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexanderalang/subscriptions", "organizations_url": "https://api.github.com/users/alexanderalang/orgs", "repos_url": "https://api.github.com/users/alexanderalang/repos", "events_url": "https://api.github.com/users/alexanderalang/events{/privacy}", "received_events_url": "https://api.github.com/users/alexanderalang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-04-05T22:39:40Z", "updated_at": "2017-05-19T20:13:57Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Stochastic Depth (aka layer dropout) has been shown to speed up and improve training in ResNets, as well as overall accuracy on testing sets. Essentially, every training step a random subset of residual layers are entirely removed from the network, and training proceeds on the remaining layers. Direct connections are made between the missing layers.</p>\n<p>It is described in this paper: <a href=\"https://arxiv.org/pdf/1603.09382.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1603.09382.pdf</a>. (Deep Networks with Stochastic Depth by Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger)</p>\n<p>I can't think of a way to implement this with the python API without reconstructing the model every training iteration, and I'm not familiar the with the C++ API / Cudnn to try to write the op myself.</p>\n<p>Of course I'm willing to try any python-only suggestions.</p>\n<p>Thanks in advance,</p>\n<p>Alex</p>", "body_text": "Stochastic Depth (aka layer dropout) has been shown to speed up and improve training in ResNets, as well as overall accuracy on testing sets. Essentially, every training step a random subset of residual layers are entirely removed from the network, and training proceeds on the remaining layers. Direct connections are made between the missing layers.\nIt is described in this paper: https://arxiv.org/pdf/1603.09382.pdf. (Deep Networks with Stochastic Depth by Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger)\nI can't think of a way to implement this with the python API without reconstructing the model every training iteration, and I'm not familiar the with the C++ API / Cudnn to try to write the op myself.\nOf course I'm willing to try any python-only suggestions.\nThanks in advance,\nAlex", "body": "Stochastic Depth (aka layer dropout) has been shown to speed up and improve training in ResNets, as well as overall accuracy on testing sets. Essentially, every training step a random subset of residual layers are entirely removed from the network, and training proceeds on the remaining layers. Direct connections are made between the missing layers.  \r\n\r\nIt is described in this paper: https://arxiv.org/pdf/1603.09382.pdf. (Deep Networks with Stochastic Depth by Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger)\r\n\r\nI can't think of a way to implement this with the python API without reconstructing the model every training iteration, and I'm not familiar the with the C++ API / Cudnn to try to write the op myself.\r\n\r\nOf course I'm willing to try any python-only suggestions.\r\n\r\nThanks in advance,\r\n\r\nAlex "}