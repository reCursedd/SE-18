{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114473579", "pull_request_review_id": 35940332, "id": 114473579, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNDQ3MzU3OQ==", "diff_hunk": "@@ -1926,3 +1927,158 @@ def call(self, inputs, state):\n     new_state = core_rnn_cell.LSTMStateTuple(new_c, new_h)\n \n     return new_h, new_state\n+\n+class GLSTMCell(core_rnn_cell.RNNCell):\n+  \"\"\"Group LSTM cell (G-LSTM).\n+\n+  The implementation is based on:\n+\n+    https://arxiv.org/abs/1703.10722\n+\n+  O. Kuchaiev and B. Ginsburg\n+  \"Factorization Tricks for LSTM Networks\", ICLR 2017 workshop.\n+  \"\"\"\n+\n+  def __init__(self, num_units, initializer=None, num_proj=None,\n+               number_of_groups=1, forget_bias=1.0, activation=tanh):\n+    \"\"\"Initialize the parameters of G-LSTM cell.\n+\n+    Args:\n+      num_units: int, The number of units in the G-LSTM cell\n+      initializer: (optional) The initializer to use for the weight and\n+        projection matrices.\n+      num_proj: (optional) int, The output dimensionality for the projection\n+        matrices.  If None, no projection is performed.\n+      number_of_groups: (optional) int, number of groups to use. If number_of_groups=1,\n+        then it should be equivalent to LSTMP cell\n+      forget_bias: Biases of the forget gate are initialized by default to 1\n+        in order to reduce the scale of forgetting at the beginning of\n+        the training.\n+      activation: Activation function of the inner states.\n+    \"\"\"\n+    self._num_units = num_units\n+    self._initializer = initializer\n+    self._num_proj = num_proj\n+    self._forget_bias = forget_bias\n+    self._activation = activation\n+    self._number_of_groups = number_of_groups\n+\n+    assert (self._num_units % self._number_of_groups == 0)\n+    if self._num_proj:\n+      assert (self._num_proj % self._number_of_groups == 0)\n+      self._group_shape = [int(self._num_proj / self._number_of_groups),\n+                           int(self._num_units / self._number_of_groups)]\n+    else:\n+      self._group_shape = [int(self._num_units / self._number_of_groups),\n+                           int(self._num_units / self._number_of_groups)]\n+\n+    if num_proj:\n+      self._state_size = (core_rnn_cell.LSTMStateTuple(num_units, num_proj))\n+      self._output_size = num_proj\n+    else:\n+      self._state_size = (core_rnn_cell.LSTMStateTuple(num_units, num_units))\n+      self._output_size = num_units\n+\n+  @property\n+  def state_size(self):\n+    return self._state_size\n+\n+  @property\n+  def output_size(self):\n+    return self._output_size\n+\n+  def _get_input_for_group(self, inpt, group_id, group_size):\n+    \"\"\"Slices inputs into groups to prepare for processing by cell's groups\n+\n+    Args:\n+      inpt: inputs\n+      group_id: group id, for which to prepare extract input_group_id\n+      group_size: size of the group\n+\n+    Returns:\n+      subset of inputs corresponding to group \"group_id\"\n+    \"\"\"\n+    return array_ops.slice(input_=inpt,\n+                           begin=[0, group_id * group_size],\n+                           size=[inpt.get_shape()[0].value, group_size],\n+                           name=\"GLSTMinputGroupCreation\")\n+\n+  def __call__(self, inputs, state):\n+    \"\"\"Run one step of G-LSTM.\n+\n+    Args:\n+      inputs: input Tensor, 2D, batch x num_units.\n+      state: this must be a tuple of state Tensors, both `2-D`, with column sizes `c_state` and `m_state`.\n+\n+    Returns:\n+      A tuple containing:\n+\n+      - A `2-D, [batch x output_dim]`, Tensor representing the output of the\n+        G-LSTM after reading `inputs` when previous state was `state`.\n+        Here output_dim is:\n+           num_proj if num_proj was set,\n+           num_units otherwise.\n+      - Tensor(s) representing the new state of G-LSTM after reading `inputs` when\n+        the previous state was `state`.  Same type and shape(s) as `state`.\n+\n+    Raises:\n+      ValueError: If input size cannot be inferred from inputs via\n+        static shape inference.\n+    \"\"\"\n+    (c_prev, m_prev) = state\n+\n+    input_size = inputs.get_shape().with_rank(2)[1]\n+    if input_size.value is None:\n+      raise ValueError(\"Could not infer input size from inputs.get_shape()[-1]\")\n+    dtype = inputs.dtype\n+    with vs.variable_scope(\"glstm_cell\",\n+                           initializer=self._initializer):\n+      i_parts = []\n+      j_parts = []\n+      f_parts = []\n+      o_parts = []\n+\n+      for group_id in xrange(self._number_of_groups):\n+        with vs.variable_scope(\"group%d\"%group_id):\n+          x_g_id = array_ops.concat([self._get_input_for_group(inputs, group_id, self._group_shape[0]),\n+                                     self._get_input_for_group(m_prev, group_id, self._group_shape[0])], axis=1)\n+          R_k = _linear(x_g_id, 4 * self._group_shape[1], bias=False)\n+          i_k, j_k, f_k, o_k = array_ops.split(R_k, 4, 1)\n+\n+        i_parts.append(i_k)\n+        j_parts.append(j_k)\n+        f_parts.append(f_k)\n+        o_parts.append(o_k)\n+\n+      #it is more efficient to have per total gate biases compared to per gate, per group biases\n+      bi = vs.get_variable(name=\"biases_i\",", "path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "position": null, "original_position": 136, "commit_id": "103a31c06570b93905c6e9aa118c1efd5463f773", "original_commit_id": "58bfb9af36da88b5e141680a01abd124eaf717fd", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "use \"bias_i\" instead of \"biases_i\" etc; we're going to be doing a global rename of all RNNCells to match keras naming conventions; they use \"kernel\" for the matrix and \"bias\" for the biases.", "created_at": "2017-05-03T05:16:33Z", "updated_at": "2017-05-04T04:29:30Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9606#discussion_r114473579", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9606", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114473579"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9606#discussion_r114473579"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9606"}}, "body_html": "<p>use \"bias_i\" instead of \"biases_i\" etc; we're going to be doing a global rename of all RNNCells to match keras naming conventions; they use \"kernel\" for the matrix and \"bias\" for the biases.</p>", "body_text": "use \"bias_i\" instead of \"biases_i\" etc; we're going to be doing a global rename of all RNNCells to match keras naming conventions; they use \"kernel\" for the matrix and \"bias\" for the biases."}