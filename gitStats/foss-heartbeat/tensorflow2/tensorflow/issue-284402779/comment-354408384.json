{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354408384", "html_url": "https://github.com/tensorflow/tensorflow/issues/15621#issuecomment-354408384", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15621", "id": 354408384, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDQwODM4NA==", "user": {"login": "TianXIA88", "id": 19329725, "node_id": "MDQ6VXNlcjE5MzI5NzI1", "avatar_url": "https://avatars1.githubusercontent.com/u/19329725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TianXIA88", "html_url": "https://github.com/TianXIA88", "followers_url": "https://api.github.com/users/TianXIA88/followers", "following_url": "https://api.github.com/users/TianXIA88/following{/other_user}", "gists_url": "https://api.github.com/users/TianXIA88/gists{/gist_id}", "starred_url": "https://api.github.com/users/TianXIA88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TianXIA88/subscriptions", "organizations_url": "https://api.github.com/users/TianXIA88/orgs", "repos_url": "https://api.github.com/users/TianXIA88/repos", "events_url": "https://api.github.com/users/TianXIA88/events{/privacy}", "received_events_url": "https://api.github.com/users/TianXIA88/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-29T07:15:27Z", "updated_at": "2018-01-02T01:54:59Z", "author_association": "NONE", "body_html": "<p>It seems the float type  GPU declaration somehow hit a library-missing issue.  The problem code is as below:<br>\nIn \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" :</p>\n<pre lang=\"//\" data-meta=\"Registration of the GPU implementations.\"><code>REGISTER_KERNEL_BUILDER(\n    Name(\"FusedConv2DBiasActivation\")\n        .Device(DEVICE_GPU)\n        .TypeConstraint&lt;float&gt;(\"T\")\n        .TypeConstraint&lt;float&gt;(\"Tbias\")\n        .HostMemory(\"conv_input_scale\")\n        .HostMemory(\"side_input_scale\"),\n    FusedConv2DBiasActivationOp&lt;GPUDevice, float, float, float&gt;);\n</code></pre>\n<p>I have worked out a workaround for this issue, and I will post it here in case someone wants to use this fused_conv2d_bias_activation_op:</p>\n<p>First add addtional link opt<br>\n<code>linkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"] </code><br>\nto the BUILD file in tensorflow/contrib/fused_conv/BUILD:</p>\n<pre lang=\"tf_custom_op_library(\"><code>    name = \"python/ops/_fused_conv2d_bias_activation_op.so\",\n    srcs = [\n        \"kernels/fused_conv2d_bias_activation_op.cc\",\n        \"kernels/fused_conv2d_bias_activation_op.h\",\n        \"kernels/fused_conv_ops_gpu.h\",\n        \"ops/fused_conv2d_bias_activation_op.cc\",\n    ],\n    deps = [\n        \"//tensorflow/core:lib_proto_parsing\",\n        \"//tensorflow/core/kernels:bounds_check_lib\",\n        \"//tensorflow/core/kernels:conv_2d_hdrs\",\n        \"//tensorflow/core/kernels:conv_ops_gpu_hdrs\",\n        \"//tensorflow/core/kernels:gpu_util_hdrs\",\n        \"//tensorflow/core/kernels:ops_util_hdrs\",\n    ],\n    linkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"],\n)\n</code></pre>\n<p>This is to explicitly link against the _pywrap_tensorflow_internal.so since some symbols are hidden by Bazel in new version (from <a href=\"https://github.com/tensorflow/tensorflow/issues/15582\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/15582/hovercard\">Issue 15582</a> ). And this \"--unresolved-symbols=ignore-in-shared-libs\" option will help you get the line that causes the \"undefined symbol\" error.</p>\n<p>After this is done, use bazel to rebuild the op and you can find out the reason causing the problem:</p>\n<pre lang=\"bazel-out/local_linux-opt/bin/tensorflow/contrib/fused_conv/_objs/python/ops/_fused_conv2d_bias_activation_op.so/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.pic.o:\" data-meta=\"In function :\"><code>**tensorflow::LaunchFusedConv2DBiasActivationOp&lt;Eigen::GpuDevice, float, float, float&gt;::launch(tensorflow::OpKernelContext*, bool, tensorflow::Tensor const&amp;, float, tensorflow::Tensor const&amp;, int, int, Eigen::PaddingType const&amp;, tensorflow::Tensor const&amp;, float, tensorflow::Tensor const&amp;, tensorflow::ActivationMode, tensorflow::TensorFormat, tensorflow::FilterTensorFormat, tensorflow::Tensor*)**\nfused_conv2d_bias_activation_op.cc:(.text._ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_[_ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_]+0x1b5b): undefined reference to Eigen::internal::TensorExecutor&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 4, 1, int&gt;, 16, Eigen::MakePointer&gt;, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;int, 4&gt; const, Eigen::TensorShufflingOp&lt;Eigen::DSizes&lt;int, 3&gt; const, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;int, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, int&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const&gt; const&gt; const, Eigen::GpuDevice, false&gt;::run(Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 4, 1, int&gt;, 16, Eigen::MakePointer&gt;, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;int, 4&gt; const, Eigen::TensorShufflingOp&lt;Eigen::DSizes&lt;int, 3&gt; const, Eigen::TensorReshapingOp&lt;Eigen::DSizes&lt;int, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, int&gt;, 16, Eigen::MakePointer&gt; const&gt; const&gt; const&gt; const&gt; const&amp;, Eigen::GpuDevice const&amp;)'\n</code></pre>\n<p>Then we go to the \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" file and <strong>comment out</strong> the GPU-Float specific:</p>\n<pre lang=\"//\" data-meta=\"Registration of the GPU implementations.\"><code>/*\nREGISTER_KERNEL_BUILDER(\n    Name(\"FusedConv2DBiasActivation\")\n        .Device(DEVICE_GPU)\n        .TypeConstraint&lt;float&gt;(\"T\")\n        .TypeConstraint&lt;float&gt;(\"Tbias\")\n        .HostMemory(\"conv_input_scale\")\n        .HostMemory(\"side_input_scale\"),\n    FusedConv2DBiasActivationOp&lt;GPUDevice, float, float, float&gt;);\n*/\n</code></pre>\n<p>Then you can rebuild tensorflow and now the FusedConv2DBiasActivation should be OK to use, But only the INT8(qint8) type input is allowed (since we eliminated the float implementation).</p>", "body_text": "It seems the float type  GPU declaration somehow hit a library-missing issue.  The problem code is as below:\nIn \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" :\nREGISTER_KERNEL_BUILDER(\n    Name(\"FusedConv2DBiasActivation\")\n        .Device(DEVICE_GPU)\n        .TypeConstraint<float>(\"T\")\n        .TypeConstraint<float>(\"Tbias\")\n        .HostMemory(\"conv_input_scale\")\n        .HostMemory(\"side_input_scale\"),\n    FusedConv2DBiasActivationOp<GPUDevice, float, float, float>);\n\nI have worked out a workaround for this issue, and I will post it here in case someone wants to use this fused_conv2d_bias_activation_op:\nFirst add addtional link opt\nlinkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"] \nto the BUILD file in tensorflow/contrib/fused_conv/BUILD:\n    name = \"python/ops/_fused_conv2d_bias_activation_op.so\",\n    srcs = [\n        \"kernels/fused_conv2d_bias_activation_op.cc\",\n        \"kernels/fused_conv2d_bias_activation_op.h\",\n        \"kernels/fused_conv_ops_gpu.h\",\n        \"ops/fused_conv2d_bias_activation_op.cc\",\n    ],\n    deps = [\n        \"//tensorflow/core:lib_proto_parsing\",\n        \"//tensorflow/core/kernels:bounds_check_lib\",\n        \"//tensorflow/core/kernels:conv_2d_hdrs\",\n        \"//tensorflow/core/kernels:conv_ops_gpu_hdrs\",\n        \"//tensorflow/core/kernels:gpu_util_hdrs\",\n        \"//tensorflow/core/kernels:ops_util_hdrs\",\n    ],\n    linkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"],\n)\n\nThis is to explicitly link against the _pywrap_tensorflow_internal.so since some symbols are hidden by Bazel in new version (from Issue 15582 ). And this \"--unresolved-symbols=ignore-in-shared-libs\" option will help you get the line that causes the \"undefined symbol\" error.\nAfter this is done, use bazel to rebuild the op and you can find out the reason causing the problem:\n**tensorflow::LaunchFusedConv2DBiasActivationOp<Eigen::GpuDevice, float, float, float>::launch(tensorflow::OpKernelContext*, bool, tensorflow::Tensor const&, float, tensorflow::Tensor const&, int, int, Eigen::PaddingType const&, tensorflow::Tensor const&, float, tensorflow::Tensor const&, tensorflow::ActivationMode, tensorflow::TensorFormat, tensorflow::FilterTensorFormat, tensorflow::Tensor*)**\nfused_conv2d_bias_activation_op.cc:(.text._ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_[_ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_]+0x1b5b): undefined reference to Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReshapingOp<Eigen::DSizes<int, 4> const, Eigen::TensorShufflingOp<Eigen::DSizes<int, 3> const, Eigen::TensorReshapingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const> const> const, Eigen::GpuDevice, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReshapingOp<Eigen::DSizes<int, 4> const, Eigen::TensorShufflingOp<Eigen::DSizes<int, 3> const, Eigen::TensorReshapingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const> const> const&, Eigen::GpuDevice const&)'\n\nThen we go to the \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" file and comment out the GPU-Float specific:\n/*\nREGISTER_KERNEL_BUILDER(\n    Name(\"FusedConv2DBiasActivation\")\n        .Device(DEVICE_GPU)\n        .TypeConstraint<float>(\"T\")\n        .TypeConstraint<float>(\"Tbias\")\n        .HostMemory(\"conv_input_scale\")\n        .HostMemory(\"side_input_scale\"),\n    FusedConv2DBiasActivationOp<GPUDevice, float, float, float>);\n*/\n\nThen you can rebuild tensorflow and now the FusedConv2DBiasActivation should be OK to use, But only the INT8(qint8) type input is allowed (since we eliminated the float implementation).", "body": "It seems the float type  GPU declaration somehow hit a library-missing issue.  The problem code is as below:\r\nIn \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" :\r\n```// Registration of the GPU implementations.\r\nREGISTER_KERNEL_BUILDER(\r\n    Name(\"FusedConv2DBiasActivation\")\r\n        .Device(DEVICE_GPU)\r\n        .TypeConstraint<float>(\"T\")\r\n        .TypeConstraint<float>(\"Tbias\")\r\n        .HostMemory(\"conv_input_scale\")\r\n        .HostMemory(\"side_input_scale\"),\r\n    FusedConv2DBiasActivationOp<GPUDevice, float, float, float>);\r\n```\r\n\r\nI have worked out a workaround for this issue, and I will post it here in case someone wants to use this fused_conv2d_bias_activation_op:\r\n\r\nFirst add addtional link opt \r\n```linkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"] ```\r\nto the BUILD file in tensorflow/contrib/fused_conv/BUILD:\r\n\r\n```tf_custom_op_library(\r\n    name = \"python/ops/_fused_conv2d_bias_activation_op.so\",\r\n    srcs = [\r\n        \"kernels/fused_conv2d_bias_activation_op.cc\",\r\n        \"kernels/fused_conv2d_bias_activation_op.h\",\r\n        \"kernels/fused_conv_ops_gpu.h\",\r\n        \"ops/fused_conv2d_bias_activation_op.cc\",\r\n    ],\r\n    deps = [\r\n        \"//tensorflow/core:lib_proto_parsing\",\r\n        \"//tensorflow/core/kernels:bounds_check_lib\",\r\n        \"//tensorflow/core/kernels:conv_2d_hdrs\",\r\n        \"//tensorflow/core/kernels:conv_ops_gpu_hdrs\",\r\n        \"//tensorflow/core/kernels:gpu_util_hdrs\",\r\n        \"//tensorflow/core/kernels:ops_util_hdrs\",\r\n    ],\r\n    linkopts = [\"-shared-libgcc /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so -Xlinker --unresolved-symbols=ignore-in-shared-libs\"],\r\n)\r\n```\r\n\r\nThis is to explicitly link against the _pywrap_tensorflow_internal.so since some symbols are hidden by Bazel in new version (from [Issue 15582](https://github.com/tensorflow/tensorflow/issues/15582) ). And this \"--unresolved-symbols=ignore-in-shared-libs\" option will help you get the line that causes the \"undefined symbol\" error.\r\n\r\nAfter this is done, use bazel to rebuild the op and you can find out the reason causing the problem:\r\n\r\n```bazel-out/local_linux-opt/bin/tensorflow/contrib/fused_conv/_objs/python/ops/_fused_conv2d_bias_activation_op.so/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.pic.o: In function :\r\n**tensorflow::LaunchFusedConv2DBiasActivationOp<Eigen::GpuDevice, float, float, float>::launch(tensorflow::OpKernelContext*, bool, tensorflow::Tensor const&, float, tensorflow::Tensor const&, int, int, Eigen::PaddingType const&, tensorflow::Tensor const&, float, tensorflow::Tensor const&, tensorflow::ActivationMode, tensorflow::TensorFormat, tensorflow::FilterTensorFormat, tensorflow::Tensor*)**\r\nfused_conv2d_bias_activation_op.cc:(.text._ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_[_ZN10tensorflow33LaunchFusedConv2DBiasActivationOpIN5Eigen9GpuDeviceEfffE6launchEPNS_15OpKernelContextEbRKNS_6TensorEfS8_iiRKNS1_11PaddingTypeES8_fS8_NS_14ActivationModeENS_12TensorFormatENS_18FilterTensorFormatEPS6_]+0x1b5b): undefined reference to Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReshapingOp<Eigen::DSizes<int, 4> const, Eigen::TensorShufflingOp<Eigen::DSizes<int, 3> const, Eigen::TensorReshapingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const> const> const, Eigen::GpuDevice, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReshapingOp<Eigen::DSizes<int, 4> const, Eigen::TensorShufflingOp<Eigen::DSizes<int, 3> const, Eigen::TensorReshapingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const> const> const&, Eigen::GpuDevice const&)'\r\n```\r\n\r\nThen we go to the \"tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc\" file and **comment out** the GPU-Float specific:\r\n```// Registration of the GPU implementations.\r\n/*\r\nREGISTER_KERNEL_BUILDER(\r\n    Name(\"FusedConv2DBiasActivation\")\r\n        .Device(DEVICE_GPU)\r\n        .TypeConstraint<float>(\"T\")\r\n        .TypeConstraint<float>(\"Tbias\")\r\n        .HostMemory(\"conv_input_scale\")\r\n        .HostMemory(\"side_input_scale\"),\r\n    FusedConv2DBiasActivationOp<GPUDevice, float, float, float>);\r\n*/\r\n```\r\n\r\nThen you can rebuild tensorflow and now the FusedConv2DBiasActivation should be OK to use, But only the INT8(qint8) type input is allowed (since we eliminated the float implementation)."}