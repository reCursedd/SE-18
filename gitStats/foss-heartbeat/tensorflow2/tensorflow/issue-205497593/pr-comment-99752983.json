{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/99752983", "pull_request_review_id": 20437371, "id": 99752983, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk5NzUyOTgz", "diff_hunk": "@@ -0,0 +1,392 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# =============================================================================\n+\"\"\"Tests for tensorflow.python.training.saver.py.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import contextlib\n+import os\n+import shutil\n+import tempfile\n+import time\n+\n+from tensorflow.core.protobuf import saver_pb2\n+from tensorflow.python import pywrap_tensorflow\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n+from tensorflow.python.framework import ops as ops_lib\n+from tensorflow.python.ops import gen_data_flow_ops\n+from tensorflow.python.ops import variables\n+import tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\n+from tensorflow.python.platform import gfile\n+from tensorflow.python.platform import test\n+from tensorflow.python.training import saver as saver_module\n+from tensorflow.python.util import compat\n+\n+\n+class CheckpointedOp(object):\n+  \"\"\"Op with a custom checkpointing implementation.\n+\n+  Defined as part of the test because the MutableHashTable Python code is\n+  currently in contrib.\n+  \"\"\"\n+\n+  def __init__(self, name):\n+    self._table_ref = gen_data_flow_ops._mutable_hash_table(\n+        key_dtype=dtypes.string, value_dtype=dtypes.float32, name=name)\n+    self._name = name\n+    self._saveable = CheckpointedOp.CustomSaveable(self, name)\n+    ops_lib.add_to_collection(ops_lib.GraphKeys.SAVEABLE_OBJECTS,\n+                              self._saveable)\n+\n+  @property\n+  def name(self):\n+    return self._name\n+\n+  @property\n+  def saveable(self):\n+    return self._saveable\n+\n+  def insert(self, keys, values):\n+    return gen_data_flow_ops._lookup_table_insert(self._table_ref, keys, values)\n+\n+  def keys(self):\n+    return self._export()[0]\n+\n+  def values(self):\n+    return self._export()[1]\n+\n+  def _export(self):\n+    return gen_data_flow_ops._lookup_table_export(self._table_ref,\n+                                                  dtypes.string, dtypes.float32)\n+\n+  class CustomSaveable(saver_module.BaseSaverBuilder.SaveableObject):\n+\n+    def __init__(self, table, name):\n+      tensors = table._export()\n+      specs = [\n+          saver_module.BaseSaverBuilder.SaveSpec(tensors[0], \"\",\n+                                                 name + \"-keys\"),\n+          saver_module.BaseSaverBuilder.SaveSpec(tensors[1], \"\",\n+                                                 name + \"-values\")\n+      ]\n+      super(CheckpointedOp.CustomSaveable, self).__init__(table, specs, name)\n+\n+    def restore(self, restore_tensors, shapes):\n+      return gen_data_flow_ops._lookup_table_import(self.op._table_ref,\n+                                                    restore_tensors[0],\n+                                                    restore_tensors[1])\n+\n+\n+class KeepCheckpointEveryNHoursTest(test.TestCase):\n+\n+  def _get_test_dir(self, dirname):\n+    test_dir = os.path.join(self.get_temp_dir(), dirname)\n+    gfile.MakeDirs(test_dir)\n+    return test_dir\n+\n+  def testNonSharded(self):\n+    save_dir = self._get_test_dir(\"keep_checkpoint_every_n_hours\")\n+\n+    with self.test_session() as sess:\n+      v = variables.Variable([10.0], name=\"v\")\n+      # Run the initializer NOW to avoid the 0.5s overhead of the first Run()\n+      # call, which throws the test timing off in fastbuild mode.\n+      variables.global_variables_initializer().run()\n+      # Create a saver that will keep the last 2 checkpoints plus one every 0.7\n+      # seconds.\n+      start_time = time.time()\n+      save = saver_module.Saver(\n+          {\n+              \"v\": v\n+          }, max_to_keep=2, keep_checkpoint_every_n_hours=0.7 / 3600)\n+      self.assertEqual([], save.last_checkpoints)\n+\n+      # Wait till 0.7 second have elapsed so s1 will be old enough to keep.\n+      time.sleep((time.time() + 0.7) - start_time)\n+      s1 = save.save(sess, os.path.join(save_dir, \"s1\"))\n+      self.assertEqual([s1], save.last_checkpoints)\n+\n+      s2 = save.save(sess, os.path.join(save_dir, \"s2\"))\n+      self.assertEqual([s1, s2], save.last_checkpoints)\n+\n+      # We now have 2 'last_checkpoints': [s1, s2].  The next call to Save(),\n+      # would normally delete s1, because max_to_keep is 2.  However, s1 is\n+      # older than 0.7s so we must keep it.\n+      s3 = save.save(sess, os.path.join(save_dir, \"s3\"))\n+      self.assertEqual([s2, s3], save.last_checkpoints)\n+\n+      # s1 should still be here, we are Not checking now to reduce time\n+      # variance in the test.\n+\n+      # We now have 2 'last_checkpoints': [s2, s3], and s1 on disk.  The next\n+      # call to Save(), will delete s2, because max_to_keep is 2, and because\n+      # we already kept the old s1. s2 is very close in time to s1 so it gets\n+      # deleted.\n+      s4 = save.save(sess, os.path.join(save_dir, \"s4\"))\n+      self.assertEqual([s3, s4], save.last_checkpoints)\n+\n+      # Check that s1 is still here, but s2 is gone.\n+      self.assertTrue(saver_module.checkpoint_exists(s1))\n+      self.assertFalse(saver_module.checkpoint_exists(s2))\n+      self.assertTrue(saver_module.checkpoint_exists(s3))\n+      self.assertTrue(saver_module.checkpoint_exists(s4))\n+\n+\n+class LatestCheckpointWithRelativePaths(test.TestCase):", "path": "tensorflow/python/training/saver_checkpoint_test.py", "position": null, "original_position": 150, "commit_id": "a531fefdbd52042ff707664193035ba836ff6837", "original_commit_id": "e5df4006b2ba312b7a941080789997dffa8791f9", "user": {"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}, "body": "Done", "created_at": "2017-02-07T06:26:18Z", "updated_at": "2017-02-07T06:26:20Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/7280#discussion_r99752983", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7280", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/99752983"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/7280#discussion_r99752983"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7280"}}, "body_html": "<p>Done</p>", "body_text": "Done", "in_reply_to_id": 99744602}