{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114593000", "pull_request_review_id": 36065451, "id": 114593000, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNDU5MzAwMA==", "diff_hunk": "@@ -0,0 +1,236 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/util/work_sharder.h\"\n+\n+namespace tensorflow{\n+\n+namespace {\n+\n+template <typename T>\n+struct MemCopier {\n+  \n+  inline void Copy(const T* input, T* output, int64 size){\n+    std::copy(input, input + size, output);\n+  }\n+};\n+\n+} // end namespace\n+\n+template <typename T>\n+void RepeatCPUImpl(const Tensor& input,\n+                   const typename TTypes<int32>::ConstFlat& repeats_flat,\n+                   int axis, Tensor* output) {\n+  auto input_flat = input.flat<T>();\n+  auto output_flat = output->flat<T>();\n+  MemCopier<T> copier;\n+    \n+  // A batch is inner dimensions > axis\n+  size_t batch_size = 1;\n+  int32 dims = input.shape().dims();\n+  for (int32 i = axis + 1; i < dims; ++i) {\n+    batch_size *= input.shape().dim_size(i);\n+  }\n+  int64 num_batch = input_flat.size() / batch_size;\n+  \n+  const T* in = input_flat.data();\n+  T* out = output_flat.data();\n+  if (repeats_flat.size() == 1) {", "path": "tensorflow/contrib/repeat/kernels/repeat_op_cpu_impl.cc", "position": null, "original_position": 55, "commit_id": "a81df6aff5a399d566502ef7fdf3dedd38ee0f46", "original_commit_id": "6d725adcfa53bda6126e4097d096e9601e1902e3", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "body": "Could the duplicated code here be reduced by pushing this block into a function  templatized on a `TFUNC`. Then the if could be a call to the same function with a lambda that is either repeats_flat(0) or repeats_flat(i%repeats_flat.size()). (This strategy is probably more important below, where the amount of similar and almost entirely duplicated code is very large).\r\n\r\nHowever, if you are sure there is a significant performance advantage in the single size repeats_flat case to warrant the duplication, you should leave it as is (in addition to inlining which can be accomplished by the lambda approach I outlined).", "created_at": "2017-05-03T16:37:32Z", "updated_at": "2017-09-27T06:06:37Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8954#discussion_r114593000", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8954", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114593000"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8954#discussion_r114593000"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8954"}}, "body_html": "<p>Could the duplicated code here be reduced by pushing this block into a function  templatized on a <code>TFUNC</code>. Then the if could be a call to the same function with a lambda that is either repeats_flat(0) or repeats_flat(i%repeats_flat.size()). (This strategy is probably more important below, where the amount of similar and almost entirely duplicated code is very large).</p>\n<p>However, if you are sure there is a significant performance advantage in the single size repeats_flat case to warrant the duplication, you should leave it as is (in addition to inlining which can be accomplished by the lambda approach I outlined).</p>", "body_text": "Could the duplicated code here be reduced by pushing this block into a function  templatized on a TFUNC. Then the if could be a call to the same function with a lambda that is either repeats_flat(0) or repeats_flat(i%repeats_flat.size()). (This strategy is probably more important below, where the amount of similar and almost entirely duplicated code is very large).\nHowever, if you are sure there is a significant performance advantage in the single size repeats_flat case to warrant the duplication, you should leave it as is (in addition to inlining which can be accomplished by the lambda approach I outlined)."}