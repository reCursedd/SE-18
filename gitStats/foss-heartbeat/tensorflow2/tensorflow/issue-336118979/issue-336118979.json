{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20334", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20334/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20334/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20334/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20334", "id": 336118979, "node_id": "MDU6SXNzdWUzMzYxMTg5Nzk=", "number": 20334, "title": "Incompatible shapes between op input and calculated input gradient.", "user": {"login": "Aaron19960821", "id": 16146613, "node_id": "MDQ6VXNlcjE2MTQ2NjEz", "avatar_url": "https://avatars2.githubusercontent.com/u/16146613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron19960821", "html_url": "https://github.com/Aaron19960821", "followers_url": "https://api.github.com/users/Aaron19960821/followers", "following_url": "https://api.github.com/users/Aaron19960821/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron19960821/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron19960821/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron19960821/subscriptions", "organizations_url": "https://api.github.com/users/Aaron19960821/orgs", "repos_url": "https://api.github.com/users/Aaron19960821/repos", "events_url": "https://api.github.com/users/Aaron19960821/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron19960821/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2018-06-27T08:03:53Z", "updated_at": "2018-08-16T17:19:06Z", "closed_at": "2018-08-16T17:19:06Z", "author_association": "NONE", "body_html": "<p>When I try to implement a SegNet with tensorflow, I met up with the following issue:</p>\n<pre><code>Incompatible shapes between op input and calculated input gradient.\n</code></pre>\n<p>My net structure is here below:</p>\n<pre><code> def buildNet(self):\n        #TODO: Implemente this method\n        self.X = tf.placeholder(dtype=tf.float32, shape=(self.batchsize, self.width, self.height, self.channel))\n        self.Y = tf.placeholder(dtype=tf.int32, shape=(self.batchsize, self.width, self.height))\n\n        norm = tf.nn.lrn(self.X, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        # Encoder of segnet\n        self.enconv1 = batchnorm(conv2d(norm, [3,3,self.channel,64], [1,1,1,1]))\n        self.enconv2 = batchnorm(conv2d(self.enconv1, [3,3,64,64], [1,1,1,1]))\n        self.enpool1 = maxpooling2d(self.enconv2, [1,2,2,1], [1,2,2,1])\n\n        self.enconv3 = batchnorm(conv2d(self.enpool1, [3,3,64,128], [1,1,1,1]))\n        self.enconv4 = batchnorm(conv2d(self.enconv3, [3,3,128,128], [1,1,1,1]))\n        self.enpool2 = maxpooling2d(self.enconv4, [1,2,2,1], [1,2,2,1])\n\n        self.enconv5 = batchnorm(conv2d(self.enpool2, [3,3,128,256], [1,1,1,1]))\n        self.enconv6 = batchnorm(conv2d(self.enconv5, [3,3,256,256], [1,1,1,1]))\n        self.enpool3 = maxpooling2d(self.enconv6, [1,2,2,1], [1,2,2,1])\n\n        self.enconv7 = batchnorm(conv2d(self.enpool3, [3,3,256,512], [1,1,1,1]))\n        self.enconv8 = batchnorm(conv2d(self.enconv7, [3,3,512,512], [1,1,1,1]))\n        self.enpool4 = maxpooling2d(self.enconv8, [1,2,2,1], [1,2,2,1])\n\n        self.enconv9 = batchnorm(conv2d(self.enpool4, [3,3,512,512], [1,1,1,1]))\n        self.enconv10 = batchnorm(conv2d(self.enconv9, [3,3,512,512], [1,1,1,1]))\n        self.enpool5 = maxpooling2d(self.enconv10, [1,2,2,1], [1,2,2,1])\n\n        # Decoder of segnet\n        self.depool1 = deconv2d(self.enpool5, [3,3,512,512], self.enconv10.shape, [1,1,1,1])\n        self.deconv1 = batchnorm(conv2d(self.depool1, [3,3,512,512], [1,1,1,1]))\n        self.deconv2 = batchnorm(conv2d(self.deconv1, [3,3,512,512], [1,1,1,1]))\n\n        self.depool2 = deconv2d(self.deconv2, [3,3,512,512], self.enconv8.shape, [1,1,1,1])\n        self.deconv3 = batchnorm(conv2d(self.depool2, [3,3,512,256], [1,1,1,1]))\n        self.deconv4 = batchnorm(conv2d(self.deconv3, [3,3,256,256], [1,1,1,1]))\n\n        self.depool3 = deconv2d(self.deconv4, [3,3,256,256], self.enconv6.shape, [1,1,1,1])\n        self.deconv5 = batchnorm(conv2d(self.depool3, [3,3,256,128], [1,1,1,1]))\n        self.deconv6 = batchnorm(conv2d(self.deconv5, [3,3,128,128], [1,1,1,1]))\n\n        self.depool4 = deconv2d(self.deconv6, [3,3,128,128], self.enconv4.shape, [1,1,1,1])\n        self.deconv7 = batchnorm(conv2d(self.depool4, [3,3,128,64], [1,1,1,1]))\n        self.deconv8 = batchnorm(conv2d(self.deconv7, [3,3,64,64], [1,1,1,1]))\n\n        self.depool5 = deconv2d(self.deconv8, [3,3,64,64], self.enconv2.shape, [1,1,1,1])\n        self.deconv9 = batchnorm(conv2d(self.depool5, [3,3,64,32], [1,1,1,1]))\n        self.deconv10 = batchnorm(conv2d(self.deconv9, [3,3,32,self.classes], [1,1,1,1]))\n\n        self.pred = tf.nn.softmax(self.deconv10)\n        self.oneHotY = tf.one_hot(self.Y, depth=2, on_value=1.0, off_value=0.0)\n        self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.oneHotY, logits=self.pred))\n        print self.loss.shape\n        self.optimizer = tf.train.AdamOptimizer(self.learningrate).minimize(self.loss)\n</code></pre>\n<p>I think it is the problem of <strong>tf.conv2d_trainspose</strong>. Does anyone have idea about it?</p>", "body_text": "When I try to implement a SegNet with tensorflow, I met up with the following issue:\nIncompatible shapes between op input and calculated input gradient.\n\nMy net structure is here below:\n def buildNet(self):\n        #TODO: Implemente this method\n        self.X = tf.placeholder(dtype=tf.float32, shape=(self.batchsize, self.width, self.height, self.channel))\n        self.Y = tf.placeholder(dtype=tf.int32, shape=(self.batchsize, self.width, self.height))\n\n        norm = tf.nn.lrn(self.X, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n        # Encoder of segnet\n        self.enconv1 = batchnorm(conv2d(norm, [3,3,self.channel,64], [1,1,1,1]))\n        self.enconv2 = batchnorm(conv2d(self.enconv1, [3,3,64,64], [1,1,1,1]))\n        self.enpool1 = maxpooling2d(self.enconv2, [1,2,2,1], [1,2,2,1])\n\n        self.enconv3 = batchnorm(conv2d(self.enpool1, [3,3,64,128], [1,1,1,1]))\n        self.enconv4 = batchnorm(conv2d(self.enconv3, [3,3,128,128], [1,1,1,1]))\n        self.enpool2 = maxpooling2d(self.enconv4, [1,2,2,1], [1,2,2,1])\n\n        self.enconv5 = batchnorm(conv2d(self.enpool2, [3,3,128,256], [1,1,1,1]))\n        self.enconv6 = batchnorm(conv2d(self.enconv5, [3,3,256,256], [1,1,1,1]))\n        self.enpool3 = maxpooling2d(self.enconv6, [1,2,2,1], [1,2,2,1])\n\n        self.enconv7 = batchnorm(conv2d(self.enpool3, [3,3,256,512], [1,1,1,1]))\n        self.enconv8 = batchnorm(conv2d(self.enconv7, [3,3,512,512], [1,1,1,1]))\n        self.enpool4 = maxpooling2d(self.enconv8, [1,2,2,1], [1,2,2,1])\n\n        self.enconv9 = batchnorm(conv2d(self.enpool4, [3,3,512,512], [1,1,1,1]))\n        self.enconv10 = batchnorm(conv2d(self.enconv9, [3,3,512,512], [1,1,1,1]))\n        self.enpool5 = maxpooling2d(self.enconv10, [1,2,2,1], [1,2,2,1])\n\n        # Decoder of segnet\n        self.depool1 = deconv2d(self.enpool5, [3,3,512,512], self.enconv10.shape, [1,1,1,1])\n        self.deconv1 = batchnorm(conv2d(self.depool1, [3,3,512,512], [1,1,1,1]))\n        self.deconv2 = batchnorm(conv2d(self.deconv1, [3,3,512,512], [1,1,1,1]))\n\n        self.depool2 = deconv2d(self.deconv2, [3,3,512,512], self.enconv8.shape, [1,1,1,1])\n        self.deconv3 = batchnorm(conv2d(self.depool2, [3,3,512,256], [1,1,1,1]))\n        self.deconv4 = batchnorm(conv2d(self.deconv3, [3,3,256,256], [1,1,1,1]))\n\n        self.depool3 = deconv2d(self.deconv4, [3,3,256,256], self.enconv6.shape, [1,1,1,1])\n        self.deconv5 = batchnorm(conv2d(self.depool3, [3,3,256,128], [1,1,1,1]))\n        self.deconv6 = batchnorm(conv2d(self.deconv5, [3,3,128,128], [1,1,1,1]))\n\n        self.depool4 = deconv2d(self.deconv6, [3,3,128,128], self.enconv4.shape, [1,1,1,1])\n        self.deconv7 = batchnorm(conv2d(self.depool4, [3,3,128,64], [1,1,1,1]))\n        self.deconv8 = batchnorm(conv2d(self.deconv7, [3,3,64,64], [1,1,1,1]))\n\n        self.depool5 = deconv2d(self.deconv8, [3,3,64,64], self.enconv2.shape, [1,1,1,1])\n        self.deconv9 = batchnorm(conv2d(self.depool5, [3,3,64,32], [1,1,1,1]))\n        self.deconv10 = batchnorm(conv2d(self.deconv9, [3,3,32,self.classes], [1,1,1,1]))\n\n        self.pred = tf.nn.softmax(self.deconv10)\n        self.oneHotY = tf.one_hot(self.Y, depth=2, on_value=1.0, off_value=0.0)\n        self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.oneHotY, logits=self.pred))\n        print self.loss.shape\n        self.optimizer = tf.train.AdamOptimizer(self.learningrate).minimize(self.loss)\n\nI think it is the problem of tf.conv2d_trainspose. Does anyone have idea about it?", "body": "When I try to implement a SegNet with tensorflow, I met up with the following issue:  \r\n\r\n```\r\nIncompatible shapes between op input and calculated input gradient.\r\n```\r\n\r\nMy net structure is here below:  \r\n\r\n```\r\n def buildNet(self):\r\n        #TODO: Implemente this method\r\n        self.X = tf.placeholder(dtype=tf.float32, shape=(self.batchsize, self.width, self.height, self.channel))\r\n        self.Y = tf.placeholder(dtype=tf.int32, shape=(self.batchsize, self.width, self.height))\r\n\r\n        norm = tf.nn.lrn(self.X, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\r\n        # Encoder of segnet\r\n        self.enconv1 = batchnorm(conv2d(norm, [3,3,self.channel,64], [1,1,1,1]))\r\n        self.enconv2 = batchnorm(conv2d(self.enconv1, [3,3,64,64], [1,1,1,1]))\r\n        self.enpool1 = maxpooling2d(self.enconv2, [1,2,2,1], [1,2,2,1])\r\n\r\n        self.enconv3 = batchnorm(conv2d(self.enpool1, [3,3,64,128], [1,1,1,1]))\r\n        self.enconv4 = batchnorm(conv2d(self.enconv3, [3,3,128,128], [1,1,1,1]))\r\n        self.enpool2 = maxpooling2d(self.enconv4, [1,2,2,1], [1,2,2,1])\r\n\r\n        self.enconv5 = batchnorm(conv2d(self.enpool2, [3,3,128,256], [1,1,1,1]))\r\n        self.enconv6 = batchnorm(conv2d(self.enconv5, [3,3,256,256], [1,1,1,1]))\r\n        self.enpool3 = maxpooling2d(self.enconv6, [1,2,2,1], [1,2,2,1])\r\n\r\n        self.enconv7 = batchnorm(conv2d(self.enpool3, [3,3,256,512], [1,1,1,1]))\r\n        self.enconv8 = batchnorm(conv2d(self.enconv7, [3,3,512,512], [1,1,1,1]))\r\n        self.enpool4 = maxpooling2d(self.enconv8, [1,2,2,1], [1,2,2,1])\r\n\r\n        self.enconv9 = batchnorm(conv2d(self.enpool4, [3,3,512,512], [1,1,1,1]))\r\n        self.enconv10 = batchnorm(conv2d(self.enconv9, [3,3,512,512], [1,1,1,1]))\r\n        self.enpool5 = maxpooling2d(self.enconv10, [1,2,2,1], [1,2,2,1])\r\n\r\n        # Decoder of segnet\r\n        self.depool1 = deconv2d(self.enpool5, [3,3,512,512], self.enconv10.shape, [1,1,1,1])\r\n        self.deconv1 = batchnorm(conv2d(self.depool1, [3,3,512,512], [1,1,1,1]))\r\n        self.deconv2 = batchnorm(conv2d(self.deconv1, [3,3,512,512], [1,1,1,1]))\r\n\r\n        self.depool2 = deconv2d(self.deconv2, [3,3,512,512], self.enconv8.shape, [1,1,1,1])\r\n        self.deconv3 = batchnorm(conv2d(self.depool2, [3,3,512,256], [1,1,1,1]))\r\n        self.deconv4 = batchnorm(conv2d(self.deconv3, [3,3,256,256], [1,1,1,1]))\r\n\r\n        self.depool3 = deconv2d(self.deconv4, [3,3,256,256], self.enconv6.shape, [1,1,1,1])\r\n        self.deconv5 = batchnorm(conv2d(self.depool3, [3,3,256,128], [1,1,1,1]))\r\n        self.deconv6 = batchnorm(conv2d(self.deconv5, [3,3,128,128], [1,1,1,1]))\r\n\r\n        self.depool4 = deconv2d(self.deconv6, [3,3,128,128], self.enconv4.shape, [1,1,1,1])\r\n        self.deconv7 = batchnorm(conv2d(self.depool4, [3,3,128,64], [1,1,1,1]))\r\n        self.deconv8 = batchnorm(conv2d(self.deconv7, [3,3,64,64], [1,1,1,1]))\r\n\r\n        self.depool5 = deconv2d(self.deconv8, [3,3,64,64], self.enconv2.shape, [1,1,1,1])\r\n        self.deconv9 = batchnorm(conv2d(self.depool5, [3,3,64,32], [1,1,1,1]))\r\n        self.deconv10 = batchnorm(conv2d(self.deconv9, [3,3,32,self.classes], [1,1,1,1]))\r\n\r\n        self.pred = tf.nn.softmax(self.deconv10)\r\n        self.oneHotY = tf.one_hot(self.Y, depth=2, on_value=1.0, off_value=0.0)\r\n        self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.oneHotY, logits=self.pred))\r\n        print self.loss.shape\r\n        self.optimizer = tf.train.AdamOptimizer(self.learningrate).minimize(self.loss)\r\n```\r\n\r\nI think it is the problem of **tf.conv2d_trainspose**. Does anyone have idea about it?\r\n"}