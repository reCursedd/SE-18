{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323590099", "html_url": "https://github.com/tensorflow/tensorflow/issues/12425#issuecomment-323590099", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12425", "id": 323590099, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzU5MDA5OQ==", "user": {"login": "chhwang", "id": 8018170, "node_id": "MDQ6VXNlcjgwMTgxNzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/8018170?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chhwang", "html_url": "https://github.com/chhwang", "followers_url": "https://api.github.com/users/chhwang/followers", "following_url": "https://api.github.com/users/chhwang/following{/other_user}", "gists_url": "https://api.github.com/users/chhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/chhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chhwang/subscriptions", "organizations_url": "https://api.github.com/users/chhwang/orgs", "repos_url": "https://api.github.com/users/chhwang/repos", "events_url": "https://api.github.com/users/chhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/chhwang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-20T14:55:40Z", "updated_at": "2017-08-20T14:55:40Z", "author_association": "NONE", "body_html": "<p>TensorFlow uses every available CPUs as if they are unified all together as single CPU, which means that there is no such device like <code>'/cpu:1'</code> or <code>'/cpu:2'</code>, only <code>'/cpu:0'</code>is legal. You cannot distinguish each CPU over TensorFlow as far as I know, and maybe, you don't need to in most cases. You can just write:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_cpus):\n        outputs.append(tf.matmul(inputs[i], b))</pre></div>\n<p>then it will use all available CPUs automatically.</p>", "body_text": "TensorFlow uses every available CPUs as if they are unified all together as single CPU, which means that there is no such device like '/cpu:1' or '/cpu:2', only '/cpu:0'is legal. You cannot distinguish each CPU over TensorFlow as far as I know, and maybe, you don't need to in most cases. You can just write:\nwith tf.device('/cpu:0'):\n    for i in range(num_cpus):\n        outputs.append(tf.matmul(inputs[i], b))\nthen it will use all available CPUs automatically.", "body": "TensorFlow uses every available CPUs as if they are unified all together as single CPU, which means that there is no such device like `'/cpu:1'` or `'/cpu:2'`, only `'/cpu:0'`is legal. You cannot distinguish each CPU over TensorFlow as far as I know, and maybe, you don't need to in most cases. You can just write:\r\n``` python\r\nwith tf.device('/cpu:0'):\r\n    for i in range(num_cpus):\r\n        outputs.append(tf.matmul(inputs[i], b))\r\n```\r\nthen it will use all available CPUs automatically."}