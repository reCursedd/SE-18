{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/776", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/776/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/776/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/776/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/776", "id": 126759498, "node_id": "MDU6SXNzdWUxMjY3NTk0OTg=", "number": 776, "title": "assertion failed: status == cudaSuccess in convolutional.py", "user": {"login": "sayanghosh", "id": 5829343, "node_id": "MDQ6VXNlcjU4MjkzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5829343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sayanghosh", "html_url": "https://github.com/sayanghosh", "followers_url": "https://api.github.com/users/sayanghosh/followers", "following_url": "https://api.github.com/users/sayanghosh/following{/other_user}", "gists_url": "https://api.github.com/users/sayanghosh/gists{/gist_id}", "starred_url": "https://api.github.com/users/sayanghosh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sayanghosh/subscriptions", "organizations_url": "https://api.github.com/users/sayanghosh/orgs", "repos_url": "https://api.github.com/users/sayanghosh/repos", "events_url": "https://api.github.com/users/sayanghosh/events{/privacy}", "received_events_url": "https://api.github.com/users/sayanghosh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284463744, "node_id": "MDU6TGFiZWwyODQ0NjM3NDQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cuda", "name": "cuda", "color": "f7c6c7", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2016-01-14T22:07:27Z", "updated_at": "2016-06-09T16:15:57Z", "closed_at": "2016-06-09T16:15:57Z", "author_association": "NONE", "body_html": "<p>When trying to run convolutional.py on a Ubuntu 14.04 system with Titan, and CUDA Toolkit 7 and CUDNN 6.5, I get this error trying to run convolutional.py :</p>\n<p>(tensorflow_env)sghosh@halaklin:~/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/tensorflow$ python -m tensorflow.models.image.mnist.convolutional<br>\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally<br>\nExtracting data/train-images-idx3-ubyte.gz<br>\nExtracting data/train-labels-idx1-ubyte.gz<br>\nExtracting data/t10k-images-idx3-ubyte.gz<br>\nExtracting data/t10k-labels-idx1-ubyte.gz<br>\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:<br>\nname: GeForce GTX TITAN<br>\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755<br>\npciBusID 0000:02:00.0<br>\nTotal memory: 6.00GiB<br>\nFree memory: 5.15GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:02:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.86GiB bytes.<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x600200000 extends to 0x737401000<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB<br>\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8<br>\nassertion failed: status == cudaSuccess in function void Eigen::initializeDeviceProp() at third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceType.h:464<br>\nAborted (core dumped)</p>", "body_text": "When trying to run convolutional.py on a Ubuntu 14.04 system with Titan, and CUDA Toolkit 7 and CUDNN 6.5, I get this error trying to run convolutional.py :\n(tensorflow_env)sghosh@halaklin:~/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/tensorflow$ python -m tensorflow.models.image.mnist.convolutional\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:\nname: GeForce GTX TITAN\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\npciBusID 0000:02:00.0\nTotal memory: 6.00GiB\nFree memory: 5.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.86GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x600200000 extends to 0x737401000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8\nassertion failed: status == cudaSuccess in function void Eigen::initializeDeviceProp() at third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceType.h:464\nAborted (core dumped)", "body": "When trying to run convolutional.py on a Ubuntu 14.04 system with Titan, and CUDA Toolkit 7 and CUDNN 6.5, I get this error trying to run convolutional.py :  \n\n (tensorflow_env)sghosh@halaklin:~/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/tensorflow$ python -m tensorflow.models.image.mnist.convolutional\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: \nname: GeForce GTX TITAN\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\npciBusID 0000:02:00.0\nTotal memory: 6.00GiB\nFree memory: 5.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 4.86GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x600200000 extends to 0x737401000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 8\nassertion failed: status == cudaSuccess in function void Eigen::initializeDeviceProp() at third_party/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceType.h:464\nAborted (core dumped)\n"}