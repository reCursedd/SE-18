{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9627", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9627/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9627/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9627/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9627", "id": 225955034, "node_id": "MDU6SXNzdWUyMjU5NTUwMzQ=", "number": 9627, "title": "Out of memory when running small network with mnist?", "user": {"login": "zzd1992", "id": 11853283, "node_id": "MDQ6VXNlcjExODUzMjgz", "avatar_url": "https://avatars3.githubusercontent.com/u/11853283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zzd1992", "html_url": "https://github.com/zzd1992", "followers_url": "https://api.github.com/users/zzd1992/followers", "following_url": "https://api.github.com/users/zzd1992/following{/other_user}", "gists_url": "https://api.github.com/users/zzd1992/gists{/gist_id}", "starred_url": "https://api.github.com/users/zzd1992/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zzd1992/subscriptions", "organizations_url": "https://api.github.com/users/zzd1992/orgs", "repos_url": "https://api.github.com/users/zzd1992/repos", "events_url": "https://api.github.com/users/zzd1992/events{/privacy}", "received_events_url": "https://api.github.com/users/zzd1992/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-03T11:26:46Z", "updated_at": "2017-05-03T17:01:26Z", "closed_at": "2017-05-03T17:01:26Z", "author_association": "NONE", "body_html": "<p>I work in Ubuntu14.04 with 1080Ti(12GB memory).<br>\nWhen I run a small network using mnist data set, at the beginning, everything is OK. But after nearly 3000<br>\niterations with batchsize 128, tensorflow returns out of memory error. It looks something is accumulated into memory, but I don't know what it is. Here is the error log:</p>\n<pre><code>I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 802816 totalling 1.86GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 3211264 totalling 7.45GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3212544 totalling 3.06MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 3686400 totalling 7.03MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3937280 totalling 3.75MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6422528 totalling 6.12MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 12845056 totalling 12.25MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 21105152 totalling 20.13MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 9.86GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                 10584624333\nInUse:                 10582817024\nMaxInUse:              10582817280\nNumAllocs:                 1438980\nMaxAllocSize:            115605504\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 3.06MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[128,32,14,14]\n</code></pre>\n<p>And here is part of my code:</p>\n<pre><code>def iterate_minibatches(inputs, batchsize, shuffle=False):\n    if shuffle:\n        indices = np.arange(len(inputs))\n        np.random.shuffle(indices)\n    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n        if shuffle:\n            excerpt = indices[start_idx:start_idx + batchsize]\n        else:\n            excerpt = slice(start_idx, start_idx + batchsize)\n        yield inputs[excerpt]\n\nX = np.load('mnist.npz')['x_train']\nX = np.reshape(X,(-1,28,28,1))\nepoch = 200\nnum = 0 \nfor i in range(epoch):\n    for batch in iterate_minibatches(X, batchsize, shuffle=True):\n        Rng = np.random.rand(batchsize,100).astype('float32')\n        if  num%6!=0:\n            _, p_d, err_d = sess.run([train_d,p_real,d_loss/batchsize],{real:batch,rng:Rng})\n        else:\n            _, p_g, err_g = sess.run([train_g,p_fake,g_loss/batchsize],{rng:Rng})\n            del _\n        if (num+1)%200==0:\n            _img = sess.run([fake],{rng:Rng})[0]\n            img = np.reshape(_img,(-1,28,28))\n            img = np.array(255*img,dtype='uint8')\n            save_images(img,str(num+1)+'.png')\n</code></pre>\n<p>What is the problem? ( No other programs occupy GPU memory\uff09</p>", "body_text": "I work in Ubuntu14.04 with 1080Ti(12GB memory).\nWhen I run a small network using mnist data set, at the beginning, everything is OK. But after nearly 3000\niterations with batchsize 128, tensorflow returns out of memory error. It looks something is accumulated into memory, but I don't know what it is. Here is the error log:\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 802816 totalling 1.86GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 3211264 totalling 7.45GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3212544 totalling 3.06MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 3686400 totalling 7.03MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3937280 totalling 3.75MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6422528 totalling 6.12MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 12845056 totalling 12.25MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 21105152 totalling 20.13MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 9.86GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                 10584624333\nInUse:                 10582817024\nMaxInUse:              10582817280\nNumAllocs:                 1438980\nMaxAllocSize:            115605504\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 3.06MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[128,32,14,14]\n\nAnd here is part of my code:\ndef iterate_minibatches(inputs, batchsize, shuffle=False):\n    if shuffle:\n        indices = np.arange(len(inputs))\n        np.random.shuffle(indices)\n    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n        if shuffle:\n            excerpt = indices[start_idx:start_idx + batchsize]\n        else:\n            excerpt = slice(start_idx, start_idx + batchsize)\n        yield inputs[excerpt]\n\nX = np.load('mnist.npz')['x_train']\nX = np.reshape(X,(-1,28,28,1))\nepoch = 200\nnum = 0 \nfor i in range(epoch):\n    for batch in iterate_minibatches(X, batchsize, shuffle=True):\n        Rng = np.random.rand(batchsize,100).astype('float32')\n        if  num%6!=0:\n            _, p_d, err_d = sess.run([train_d,p_real,d_loss/batchsize],{real:batch,rng:Rng})\n        else:\n            _, p_g, err_g = sess.run([train_g,p_fake,g_loss/batchsize],{rng:Rng})\n            del _\n        if (num+1)%200==0:\n            _img = sess.run([fake],{rng:Rng})[0]\n            img = np.reshape(_img,(-1,28,28))\n            img = np.array(255*img,dtype='uint8')\n            save_images(img,str(num+1)+'.png')\n\nWhat is the problem? ( No other programs occupy GPU memory\uff09", "body": "I work in Ubuntu14.04 with 1080Ti(12GB memory).\r\nWhen I run a small network using mnist data set, at the beginning, everything is OK. But after nearly 3000\r\n iterations with batchsize 128, tensorflow returns out of memory error. It looks something is accumulated into memory, but I don't know what it is. Here is the error log:\r\n```\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 802816 totalling 1.86GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 3211264 totalling 7.45GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3212544 totalling 3.06MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 3686400 totalling 7.03MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3937280 totalling 3.75MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6422528 totalling 6.12MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 12845056 totalling 12.25MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 21105152 totalling 20.13MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 9.86GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \r\nLimit:                 10584624333\r\nInUse:                 10582817024\r\nMaxInUse:              10582817280\r\nNumAllocs:                 1438980\r\nMaxAllocSize:            115605504\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 3.06MiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[128,32,14,14]\r\n```\r\nAnd here is part of my code:\r\n```\r\ndef iterate_minibatches(inputs, batchsize, shuffle=False):\r\n    if shuffle:\r\n        indices = np.arange(len(inputs))\r\n        np.random.shuffle(indices)\r\n    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\r\n        if shuffle:\r\n            excerpt = indices[start_idx:start_idx + batchsize]\r\n        else:\r\n            excerpt = slice(start_idx, start_idx + batchsize)\r\n        yield inputs[excerpt]\r\n\r\nX = np.load('mnist.npz')['x_train']\r\nX = np.reshape(X,(-1,28,28,1))\r\nepoch = 200\r\nnum = 0 \r\nfor i in range(epoch):\r\n    for batch in iterate_minibatches(X, batchsize, shuffle=True):\r\n        Rng = np.random.rand(batchsize,100).astype('float32')\r\n        if  num%6!=0:\r\n            _, p_d, err_d = sess.run([train_d,p_real,d_loss/batchsize],{real:batch,rng:Rng})\r\n        else:\r\n            _, p_g, err_g = sess.run([train_g,p_fake,g_loss/batchsize],{rng:Rng})\r\n            del _\r\n        if (num+1)%200==0:\r\n            _img = sess.run([fake],{rng:Rng})[0]\r\n            img = np.reshape(_img,(-1,28,28))\r\n            img = np.array(255*img,dtype='uint8')\r\n            save_images(img,str(num+1)+'.png')\r\n```\r\nWhat is the problem? ( No other programs occupy GPU memory\uff09\r\n\r\n\r\n"}