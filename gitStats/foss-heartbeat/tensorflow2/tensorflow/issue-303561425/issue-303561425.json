{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17564", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17564/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17564/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17564/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17564", "id": 303561425, "node_id": "MDU6SXNzdWUzMDM1NjE0MjU=", "number": 17564, "title": "Provide tensor/outer product method 'tf.outer'", "user": {"login": "4d55397500", "id": 6155946, "node_id": "MDQ6VXNlcjYxNTU5NDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6155946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/4d55397500", "html_url": "https://github.com/4d55397500", "followers_url": "https://api.github.com/users/4d55397500/followers", "following_url": "https://api.github.com/users/4d55397500/following{/other_user}", "gists_url": "https://api.github.com/users/4d55397500/gists{/gist_id}", "starred_url": "https://api.github.com/users/4d55397500/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/4d55397500/subscriptions", "organizations_url": "https://api.github.com/users/4d55397500/orgs", "repos_url": "https://api.github.com/users/4d55397500/repos", "events_url": "https://api.github.com/users/4d55397500/events{/privacy}", "received_events_url": "https://api.github.com/users/4d55397500/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-03-08T17:18:37Z", "updated_at": "2018-11-19T23:25:04Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>System information<br>\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No<br>\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 16.04<br>\nTensorFlow installed from (source or binary): binary<br>\nTensorFlow version (use command below): 1.4.1 gpu<br>\nPython version: 3.5.4<br>\nBazel version (if compiling from source):<br>\nGCC/Compiler version (if compiling from source):<br>\nCUDA/cuDNN version: Cuda 8.0/Cudnn 6.0<br>\nGPU model and memory: Titan xp<br>\nExact command to reproduce: no method for outer product</p>\n<p>Describe the problem</p>\n<p>Tensor (outer product) is the fundamental operation on tensors, but there appears to be no method <code>tf.outer</code> in <code>tensorflow</code> analogous to <code>np.outer</code> in <code>numpy</code> to compute the outer product of arbitrary tensors. A google search pulls up these implementation suggestions on stackoverflow: <a href=\"https://stackoverflow.com/questions/33858021/outer-product-in-tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/33858021/outer-product-in-tensorflow</a>, but these require the dimensions of the tensors to be accessed/known beforehand.</p>\n<p>I have the following hack. It would be nice to express this in terms of a pairwise (given associativity) operation <code>tf.outer</code>.</p>\n<p>The tensor product for an arbitrary collection of tensors can be computed:</p>\n<pre><code>def tensor_product(*e):\n    \"\"\" Tensor product of elements \"\"\"\n    if len(e) == 1:\n        return e\n    elif len(e) == 2:\n        a, b = e\n        r_a = len(a.get_shape().as_list())\n        r_b = len(b.get_shape().as_list())\n        s_a = tf.concat([tf.shape(a), tf.constant([1] * r_b)], axis=0)\n        s_b = tf.concat([tf.constant([1] * r_a), tf.shape(b)], axis=0)\n        a_reshaped = tf.reshape(a, s_a)\n        b_reshaped = tf.reshape(b, s_b)\n        return a_reshaped * b_reshaped\n    prod = e[0]\n    for tensor in e[1:]:\n        prod = tensor_product(prod, tensor)\n    return prod\n\n\n</code></pre>\n<p>The tensor product allows more elegant expression of rank-2 and greater tensors in a loss function.<br>\nFor example here is a diagonal and elliptical (weighted terms) quadratic term:</p>\n<pre><code>def diagonal_M(batch_size, d):\n    \"\"\" M_abij = delta_ab delta_ij \"\"\"\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([1.] * d))\n\n</code></pre>\n<pre><code>def biased_diagonal_M(batch_size, d):\n    \"\"\" M_abij = lambda_i delta_ab delta_ij \"\"\"\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([5.] + [1.] * (d-1)))\n\n</code></pre>\n<p>ref: <a href=\"https://github.com/4d55397500/quadratic-forms-tensorflow\">https://github.com/4d55397500/quadratic-forms-tensorflow</a></p>", "body_text": "System information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.4.1 gpu\nPython version: 3.5.4\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: Cuda 8.0/Cudnn 6.0\nGPU model and memory: Titan xp\nExact command to reproduce: no method for outer product\nDescribe the problem\nTensor (outer product) is the fundamental operation on tensors, but there appears to be no method tf.outer in tensorflow analogous to np.outer in numpy to compute the outer product of arbitrary tensors. A google search pulls up these implementation suggestions on stackoverflow: https://stackoverflow.com/questions/33858021/outer-product-in-tensorflow, but these require the dimensions of the tensors to be accessed/known beforehand.\nI have the following hack. It would be nice to express this in terms of a pairwise (given associativity) operation tf.outer.\nThe tensor product for an arbitrary collection of tensors can be computed:\ndef tensor_product(*e):\n    \"\"\" Tensor product of elements \"\"\"\n    if len(e) == 1:\n        return e\n    elif len(e) == 2:\n        a, b = e\n        r_a = len(a.get_shape().as_list())\n        r_b = len(b.get_shape().as_list())\n        s_a = tf.concat([tf.shape(a), tf.constant([1] * r_b)], axis=0)\n        s_b = tf.concat([tf.constant([1] * r_a), tf.shape(b)], axis=0)\n        a_reshaped = tf.reshape(a, s_a)\n        b_reshaped = tf.reshape(b, s_b)\n        return a_reshaped * b_reshaped\n    prod = e[0]\n    for tensor in e[1:]:\n        prod = tensor_product(prod, tensor)\n    return prod\n\n\n\nThe tensor product allows more elegant expression of rank-2 and greater tensors in a loss function.\nFor example here is a diagonal and elliptical (weighted terms) quadratic term:\ndef diagonal_M(batch_size, d):\n    \"\"\" M_abij = delta_ab delta_ij \"\"\"\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([1.] * d))\n\n\ndef biased_diagonal_M(batch_size, d):\n    \"\"\" M_abij = lambda_i delta_ab delta_ij \"\"\"\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([5.] + [1.] * (d-1)))\n\n\nref: https://github.com/4d55397500/quadratic-forms-tensorflow", "body": "System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 16.04\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.4.1 gpu\r\nPython version: 3.5.4\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: Cuda 8.0/Cudnn 6.0\r\nGPU model and memory: Titan xp\r\nExact command to reproduce: no method for outer product\r\n\r\nDescribe the problem\r\n\r\nTensor (outer product) is the fundamental operation on tensors, but there appears to be no method `tf.outer` in `tensorflow` analogous to `np.outer` in `numpy` to compute the outer product of arbitrary tensors. A google search pulls up these implementation suggestions on stackoverflow: https://stackoverflow.com/questions/33858021/outer-product-in-tensorflow, but these require the dimensions of the tensors to be accessed/known beforehand.\r\n\r\n\r\nI have the following hack. It would be nice to express this in terms of a pairwise (given associativity) operation `tf.outer`.\r\n\r\nThe tensor product for an arbitrary collection of tensors can be computed:\r\n```\r\ndef tensor_product(*e):\r\n    \"\"\" Tensor product of elements \"\"\"\r\n    if len(e) == 1:\r\n        return e\r\n    elif len(e) == 2:\r\n        a, b = e\r\n        r_a = len(a.get_shape().as_list())\r\n        r_b = len(b.get_shape().as_list())\r\n        s_a = tf.concat([tf.shape(a), tf.constant([1] * r_b)], axis=0)\r\n        s_b = tf.concat([tf.constant([1] * r_a), tf.shape(b)], axis=0)\r\n        a_reshaped = tf.reshape(a, s_a)\r\n        b_reshaped = tf.reshape(b, s_b)\r\n        return a_reshaped * b_reshaped\r\n    prod = e[0]\r\n    for tensor in e[1:]:\r\n        prod = tensor_product(prod, tensor)\r\n    return prod\r\n\r\n\r\n```\r\n\r\nThe tensor product allows more elegant expression of rank-2 and greater tensors in a loss function. \r\nFor example here is a diagonal and elliptical (weighted terms) quadratic term:\r\n\r\n```\r\ndef diagonal_M(batch_size, d):\r\n    \"\"\" M_abij = delta_ab delta_ij \"\"\"\r\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([1.] * d))\r\n\r\n```\r\n\r\n```\r\ndef biased_diagonal_M(batch_size, d):\r\n    \"\"\" M_abij = lambda_i delta_ab delta_ij \"\"\"\r\n    return tensor_product(tf.diag([1.] * batch_size), tf.diag([5.] + [1.] * (d-1)))\r\n\r\n```\r\nref: https://github.com/4d55397500/quadratic-forms-tensorflow"}