{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415607267", "html_url": "https://github.com/tensorflow/tensorflow/pull/19792#issuecomment-415607267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19792", "id": 415607267, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTYwNzI2Nw==", "user": {"login": "eladeban", "id": 40275510, "node_id": "MDQ6VXNlcjQwMjc1NTEw", "avatar_url": "https://avatars1.githubusercontent.com/u/40275510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eladeban", "html_url": "https://github.com/eladeban", "followers_url": "https://api.github.com/users/eladeban/followers", "following_url": "https://api.github.com/users/eladeban/following{/other_user}", "gists_url": "https://api.github.com/users/eladeban/gists{/gist_id}", "starred_url": "https://api.github.com/users/eladeban/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eladeban/subscriptions", "organizations_url": "https://api.github.com/users/eladeban/orgs", "repos_url": "https://api.github.com/users/eladeban/repos", "events_url": "https://api.github.com/users/eladeban/events{/privacy}", "received_events_url": "https://api.github.com/users/eladeban/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-23T23:44:29Z", "updated_at": "2018-08-23T23:44:29Z", "author_association": "NONE", "body_html": "<p>I would like to push back on this change for the following reasons:</p>\n<p>It is not clear if the fix is even correct in practice. I mean that is that the flops ARE mq(2p-1). I agree this is the case on the white board but, the following very reasonable implementation:</p>\n<p>sum = 0<br>\nfor i=0 to p<br>\nsum += a[i] * b[i]</p>\n<p>has 2mpq FLOPS and not mq(2p-1)</p>\n<ol start=\"2\">\n<li>\n<p>The change is incomplete (i.e. it creates inconsistencies). The flop computation of conv2d, depthwise convolutions and possibly others where not fixed. I think that having slightly inflated <strong>consistent</strong> flop computation is  better than having two formulas giving different results.</p>\n</li>\n<li>\n<p>This change is negligible when used for diagnostic reasons (unless one is multiplying very small matrices), but brakes some code that actually uses these numbers.</p>\n</li>\n</ol>", "body_text": "I would like to push back on this change for the following reasons:\nIt is not clear if the fix is even correct in practice. I mean that is that the flops ARE mq(2p-1). I agree this is the case on the white board but, the following very reasonable implementation:\nsum = 0\nfor i=0 to p\nsum += a[i] * b[i]\nhas 2mpq FLOPS and not mq(2p-1)\n\n\nThe change is incomplete (i.e. it creates inconsistencies). The flop computation of conv2d, depthwise convolutions and possibly others where not fixed. I think that having slightly inflated consistent flop computation is  better than having two formulas giving different results.\n\n\nThis change is negligible when used for diagnostic reasons (unless one is multiplying very small matrices), but brakes some code that actually uses these numbers.", "body": "I would like to push back on this change for the following reasons: \r\n\r\nIt is not clear if the fix is even correct in practice. I mean that is that the flops ARE mq(2p-1). I agree this is the case on the white board but, the following very reasonable implementation:\r\n\r\nsum = 0\r\nfor i=0 to p\r\nsum += a[i] * b[i]\r\n\r\nhas 2mpq FLOPS and not mq(2p-1)\r\n\r\n2. The change is incomplete (i.e. it creates inconsistencies). The flop computation of conv2d, depthwise convolutions and possibly others where not fixed. I think that having slightly inflated **consistent** flop computation is  better than having two formulas giving different results.\r\n\r\n3. This change is negligible when used for diagnostic reasons (unless one is multiplying very small matrices), but brakes some code that actually uses these numbers.\r\n\r\n"}