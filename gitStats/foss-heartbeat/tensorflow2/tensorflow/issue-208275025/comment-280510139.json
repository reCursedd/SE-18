{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280510139", "html_url": "https://github.com/tensorflow/tensorflow/issues/7595#issuecomment-280510139", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7595", "id": 280510139, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDUxMDEzOQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-17T00:23:23Z", "updated_at": "2017-02-17T00:23:23Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Yup you're expecting too much :)  the dynamic_rnn will stop at the max of\nseq_len, but that max can change from one minibatch to the next!  So it's\nalso not known.\n\nThe new attentional mechanism should be able to handle an unknown sequence\nlength; we'll keep this in mind as we're designing it.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Feb 16, 2017 at 3:47 PM, Shubham Toshniwal ***@***.*** &gt; wrote:\n Thanks for such a quick response !\n You are right that the dynamic_rnn can't fill in the unknown time steps\n but really it should stop at max of seq_len and can thus, fill in this\n dimension (am I expecting too much ?).\n Yeah the attention mechanism currently requires the size of input to be\n known. Thanks for the heads up about the new version. But how are you guys\n planning on handling this. Is it a matter of upgrading Tensorflow or is\n there something that can be done in the current version itself ?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"208275025\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7595\" href=\"https://github.com/tensorflow/tensorflow/issues/7595#issuecomment-280502372\">#7595 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtimw33Nx_vzLSn6SCCUiQiag-Ta7EQks5rdOAEgaJpZM4MDp5g\">https://github.com/notifications/unsubscribe-auth/ABtimw33Nx_vzLSn6SCCUiQiag-Ta7EQks5rdOAEgaJpZM4MDp5g</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Yup you're expecting too much :)  the dynamic_rnn will stop at the max of\nseq_len, but that max can change from one minibatch to the next!  So it's\nalso not known.\n\nThe new attentional mechanism should be able to handle an unknown sequence\nlength; we'll keep this in mind as we're designing it.\n\u2026\nOn Thu, Feb 16, 2017 at 3:47 PM, Shubham Toshniwal ***@***.*** > wrote:\n Thanks for such a quick response !\n You are right that the dynamic_rnn can't fill in the unknown time steps\n but really it should stop at max of seq_len and can thus, fill in this\n dimension (am I expecting too much ?).\n Yeah the attention mechanism currently requires the size of input to be\n known. Thanks for the heads up about the new version. But how are you guys\n planning on handling this. Is it a matter of upgrading Tensorflow or is\n there something that can be done in the current version itself ?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#7595 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtimw33Nx_vzLSn6SCCUiQiag-Ta7EQks5rdOAEgaJpZM4MDp5g>\n .", "body": "Yup you're expecting too much :)  the dynamic_rnn will stop at the max of\nseq_len, but that max can change from one minibatch to the next!  So it's\nalso not known.\n\nThe new attentional mechanism should be able to handle an unknown sequence\nlength; we'll keep this in mind as we're designing it.\n\nOn Thu, Feb 16, 2017 at 3:47 PM, Shubham Toshniwal <notifications@github.com\n> wrote:\n\n> Thanks for such a quick response !\n> You are right that the dynamic_rnn can't fill in the unknown time steps\n> but really it should stop at max of seq_len and can thus, fill in this\n> dimension (am I expecting too much ?).\n> Yeah the attention mechanism currently requires the size of input to be\n> known. Thanks for the heads up about the new version. But how are you guys\n> planning on handling this. Is it a matter of upgrading Tensorflow or is\n> there something that can be done in the current version itself ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7595#issuecomment-280502372>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimw33Nx_vzLSn6SCCUiQiag-Ta7EQks5rdOAEgaJpZM4MDp5g>\n> .\n>\n"}