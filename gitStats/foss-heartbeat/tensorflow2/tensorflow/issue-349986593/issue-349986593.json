{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21573", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21573/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21573/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21573/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21573", "id": 349986593, "node_id": "MDU6SXNzdWUzNDk5ODY1OTM=", "number": 21573, "title": "Question: Scatter_nd_op order of operations on GPU ", "user": {"login": "Brolock", "id": 8103001, "node_id": "MDQ6VXNlcjgxMDMwMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/8103001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Brolock", "html_url": "https://github.com/Brolock", "followers_url": "https://api.github.com/users/Brolock/followers", "following_url": "https://api.github.com/users/Brolock/following{/other_user}", "gists_url": "https://api.github.com/users/Brolock/gists{/gist_id}", "starred_url": "https://api.github.com/users/Brolock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Brolock/subscriptions", "organizations_url": "https://api.github.com/users/Brolock/orgs", "repos_url": "https://api.github.com/users/Brolock/repos", "events_url": "https://api.github.com/users/Brolock/events{/privacy}", "received_events_url": "https://api.github.com/users/Brolock/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-08-13T11:14:16Z", "updated_at": "2018-09-12T13:30:54Z", "closed_at": "2018-09-12T13:30:54Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc4.8</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: AMD R9 Nano</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>Hi,<br>\nWe are working on a SYCL implementation of TensorFlow. When implementing the backend for the scatter_nd operation we were wondering what is the behavior of concurrent updates.<br>\nThe test in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/scatter_nd_ops_test.py#L231\">scatter_nd_ops_test.py</a> assumes that the operations are applied in a non-deterministic order, which matches what the <a href=\"https://www.tensorflow.org/api_docs/python/tf/scatter_nd\" rel=\"nofollow\">documentation</a> says. This corner case is costly to handle on the GPU and it seems that the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc#L81\">CUDA</a> implementation does not handle it, neither does ours.</p>\n<p>The documentation says:</p>\n<blockquote>\n<p>The order in which updates are applied is nondeterministic, so the output will be nondeterministic if indices contains duplicates.</p>\n</blockquote>\n<p>The test checks for Add and Sub of two concurrent indices to result in the total summation (or subtraction) of both updates to apply (order of additions is nondeterministic but the result is). On a replace operation the output would be nondeterministic (hence the test not checking for it).<br>\nWith a non blocking GPU implementation the second update applied to an index may (and will probably) overwrite the first update from a different thread.</p>\n<p>Our question then is:<br>\nIs the test wrong to test that concurrent summation &amp; subtraction is deterministic (in which case we would be happy to write a PR to correct that)?<br>\nOtherwise, is the CUDA implementation wrong? In which case the documentation should probably be more descriptive on what happens with concurrent add/sub compared to replace.</p>\n<p>Thanks,</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.8\nPython version: 2.7\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): gcc4.8\nCUDA/cuDNN version: N/A\nGPU model and memory: AMD R9 Nano\nExact command to reproduce: N/A\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nHi,\nWe are working on a SYCL implementation of TensorFlow. When implementing the backend for the scatter_nd operation we were wondering what is the behavior of concurrent updates.\nThe test in scatter_nd_ops_test.py assumes that the operations are applied in a non-deterministic order, which matches what the documentation says. This corner case is costly to handle on the GPU and it seems that the CUDA implementation does not handle it, neither does ours.\nThe documentation says:\n\nThe order in which updates are applied is nondeterministic, so the output will be nondeterministic if indices contains duplicates.\n\nThe test checks for Add and Sub of two concurrent indices to result in the total summation (or subtraction) of both updates to apply (order of additions is nondeterministic but the result is). On a replace operation the output would be nondeterministic (hence the test not checking for it).\nWith a non blocking GPU implementation the second update applied to an index may (and will probably) overwrite the first update from a different thread.\nOur question then is:\nIs the test wrong to test that concurrent summation & subtraction is deterministic (in which case we would be happy to write a PR to correct that)?\nOtherwise, is the CUDA implementation wrong? In which case the documentation should probably be more descriptive on what happens with concurrent add/sub compared to replace.\nThanks,", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc4.8\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: AMD R9 Nano\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nHi,\r\nWe are working on a SYCL implementation of TensorFlow. When implementing the backend for the scatter_nd operation we were wondering what is the behavior of concurrent updates.\r\nThe test in [scatter_nd_ops_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/scatter_nd_ops_test.py#L231) assumes that the operations are applied in a non-deterministic order, which matches what the [documentation](https://www.tensorflow.org/api_docs/python/tf/scatter_nd) says. This corner case is costly to handle on the GPU and it seems that the [CUDA](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc#L81) implementation does not handle it, neither does ours.\r\n\r\n\r\nThe documentation says: \r\n\r\n> The order in which updates are applied is nondeterministic, so the output will be nondeterministic if indices contains duplicates.\r\n\r\nThe test checks for Add and Sub of two concurrent indices to result in the total summation (or subtraction) of both updates to apply (order of additions is nondeterministic but the result is). On a replace operation the output would be nondeterministic (hence the test not checking for it).\r\nWith a non blocking GPU implementation the second update applied to an index may (and will probably) overwrite the first update from a different thread.\r\n\r\nOur question then is:\r\nIs the test wrong to test that concurrent summation & subtraction is deterministic (in which case we would be happy to write a PR to correct that)?\r\nOtherwise, is the CUDA implementation wrong? In which case the documentation should probably be more descriptive on what happens with concurrent add/sub compared to replace.\r\n\r\nThanks,\r\n"}