{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17410", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17410/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17410/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17410/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17410", "id": 302069783, "node_id": "MDU6SXNzdWUzMDIwNjk3ODM=", "number": 17410, "title": "CUDNN rnn error -Failed to call ThenRnnForward", "user": {"login": "pdcoded", "id": 9830931, "node_id": "MDQ6VXNlcjk4MzA5MzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/9830931?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pdcoded", "html_url": "https://github.com/pdcoded", "followers_url": "https://api.github.com/users/pdcoded/followers", "following_url": "https://api.github.com/users/pdcoded/following{/other_user}", "gists_url": "https://api.github.com/users/pdcoded/gists{/gist_id}", "starred_url": "https://api.github.com/users/pdcoded/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pdcoded/subscriptions", "organizations_url": "https://api.github.com/users/pdcoded/orgs", "repos_url": "https://api.github.com/users/pdcoded/repos", "events_url": "https://api.github.com/users/pdcoded/events{/privacy}", "received_events_url": "https://api.github.com/users/pdcoded/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-04T09:10:33Z", "updated_at": "2018-04-03T17:10:29Z", "closed_at": "2018-04-03T17:10:29Z", "author_association": "NONE", "body_html": "<p>OS Platform and Distribution - Ubuntu 16.04<br>\nTensorFlow installed from TensorFlow version -1.4 from<br>\nBazel Version 0.6.1<br>\nCUDA Version 9.0.176<br>\nMachine Type -n1-standard-32 (32 vCPUs, 120 GB memory)<br>\nGPU - 4 x NVIDIA Tesla P100<br>\nI am using a cudnnrnnrelu like this ::<br>\nwith tf.variable_scope('cudnn_rnn_stack', reuse = reuse) as scope:<br>\nrnn = tf.contrib.cudnn_rnn.CudnnRNNRelu(5,n_hidden,\"linear_input\", \"bidirectional\")<br>\noutput, _ = rnn(tf.transpose(layer_1,[1,0,2]), training=True)<br>\noutput_rnn_stack = tf.concat(output, 2)<br>\nInitially the epochs were running fine. But I encountered this error after 2-3 epochs:<br>\nInternalError (see above for traceback): Failed to call ThenRnnForward<br>\n[[Node: tower_0/cudnn_rnn_stack/cudnn_rnn_relu/CudnnRNN = CudnnRNN[T=DT_FLOAT, direc<br>\ntion=\"bidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"rnn_r<br>\nelu\", seed=0, seed2=0, <em>device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](tower_0/cudnn</em><br>\nrnn_stack/transpose, tower_0/cudnn_rnn_stack/cudnn_rnn_relu/zeros, tower_0/cudnn_rnn_stack/cu<br>\ndnn_rnn_relu/Const, cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/read)]]<br>\n[[Node: Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam/_870 = _R<br>\necv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send<br>\n_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_nam<br>\ne=\"edge_2200_Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam\", tensor_type<br>\n=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"</a>]]</p>\n<p>Running it on a distributed gpu setting in gcp instances</p>", "body_text": "OS Platform and Distribution - Ubuntu 16.04\nTensorFlow installed from TensorFlow version -1.4 from\nBazel Version 0.6.1\nCUDA Version 9.0.176\nMachine Type -n1-standard-32 (32 vCPUs, 120 GB memory)\nGPU - 4 x NVIDIA Tesla P100\nI am using a cudnnrnnrelu like this ::\nwith tf.variable_scope('cudnn_rnn_stack', reuse = reuse) as scope:\nrnn = tf.contrib.cudnn_rnn.CudnnRNNRelu(5,n_hidden,\"linear_input\", \"bidirectional\")\noutput, _ = rnn(tf.transpose(layer_1,[1,0,2]), training=True)\noutput_rnn_stack = tf.concat(output, 2)\nInitially the epochs were running fine. But I encountered this error after 2-3 epochs:\nInternalError (see above for traceback): Failed to call ThenRnnForward\n[[Node: tower_0/cudnn_rnn_stack/cudnn_rnn_relu/CudnnRNN = CudnnRNN[T=DT_FLOAT, direc\ntion=\"bidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"rnn_r\nelu\", seed=0, seed2=0, device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](tower_0/cudnn\nrnn_stack/transpose, tower_0/cudnn_rnn_stack/cudnn_rnn_relu/zeros, tower_0/cudnn_rnn_stack/cu\ndnn_rnn_relu/Const, cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/read)]]\n[[Node: Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam/_870 = _R\necvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send\n_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_nam\ne=\"edge_2200_Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam\", tensor_type\n=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\nRunning it on a distributed gpu setting in gcp instances", "body": "OS Platform and Distribution - Ubuntu 16.04\r\nTensorFlow installed from TensorFlow version -1.4 from \r\nBazel Version 0.6.1\r\nCUDA Version 9.0.176\r\nMachine Type -n1-standard-32 (32 vCPUs, 120 GB memory)\r\nGPU - 4 x NVIDIA Tesla P100\r\nI am using a cudnnrnnrelu like this ::\r\nwith tf.variable_scope('cudnn_rnn_stack', reuse = reuse) as scope:\r\n            rnn = tf.contrib.cudnn_rnn.CudnnRNNRelu(5,n_hidden,\"linear_input\", \"bidirectional\")\r\n            output, _ = rnn(tf.transpose(layer_1,[1,0,2]), training=True)\r\n            output_rnn_stack = tf.concat(output, 2)\r\nInitially the epochs were running fine. But I encountered this error after 2-3 epochs:\r\nInternalError (see above for traceback): Failed to call ThenRnnForward\r\n         [[Node: tower_0/cudnn_rnn_stack/cudnn_rnn_relu/CudnnRNN = CudnnRNN[T=DT_FLOAT, direc\r\ntion=\"bidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"rnn_r\r\nelu\", seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](tower_0/cudnn_\r\nrnn_stack/transpose, tower_0/cudnn_rnn_stack/cudnn_rnn_relu/zeros, tower_0/cudnn_rnn_stack/cu\r\ndnn_rnn_relu/Const, cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/read)]]\r\n         [[Node: Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam/_870 = _R\r\necv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send\r\n_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_nam\r\ne=\"edge_2200_Adam/update_cudnn_rnn_stack/cudnn_rnn_relu/opaque_kernel/ApplyAdam\", tensor_type\r\n=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n\r\nRunning it on a distributed gpu setting in gcp instances"}