{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269488692", "html_url": "https://github.com/tensorflow/tensorflow/pull/6387#issuecomment-269488692", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387", "id": 269488692, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTQ4ODY5Mg==", "user": {"login": "AndreasMadsen", "id": 505333, "node_id": "MDQ6VXNlcjUwNTMzMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/505333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndreasMadsen", "html_url": "https://github.com/AndreasMadsen", "followers_url": "https://api.github.com/users/AndreasMadsen/followers", "following_url": "https://api.github.com/users/AndreasMadsen/following{/other_user}", "gists_url": "https://api.github.com/users/AndreasMadsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndreasMadsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndreasMadsen/subscriptions", "organizations_url": "https://api.github.com/users/AndreasMadsen/orgs", "repos_url": "https://api.github.com/users/AndreasMadsen/repos", "events_url": "https://api.github.com/users/AndreasMadsen/events{/privacy}", "received_events_url": "https://api.github.com/users/AndreasMadsen/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-28T15:02:05Z", "updated_at": "2016-12-28T15:02:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here is an initial benchmark:</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">size &amp; case</th>\n<th align=\"left\">kernel CPU</th>\n<th align=\"left\">name_scope CPU</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">(1000, 10) sparsemax</td>\n<td align=\"left\">0.052 \u00b1 0.0032</td>\n<td align=\"left\">0.203 \u00b1 0.0364</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 10) sparsemax_grad</td>\n<td align=\"left\">0.071 \u00b1 0.0009</td>\n<td align=\"left\">0.300 \u00b1 0.0122</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 10) sparsemax_loss</td>\n<td align=\"left\">0.060 \u00b1 0.0021</td>\n<td align=\"left\">0.213 \u00b1 0.0112</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 10) sparsemax_loss_grad</td>\n<td align=\"left\">0.066 \u00b1 0.0015</td>\n<td align=\"left\">0.310 \u00b1 0.0127</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 100) sparsemax</td>\n<td align=\"left\">0.293 \u00b1 0.0094</td>\n<td align=\"left\">0.988 \u00b1 0.0689</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 100) sparsemax_grad</td>\n<td align=\"left\">0.373 \u00b1 0.0172</td>\n<td align=\"left\">1.410 \u00b1 0.0110</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 100) sparsemax_loss</td>\n<td align=\"left\">0.330 \u00b1 0.0085</td>\n<td align=\"left\">0.979 \u00b1 0.0119</td>\n</tr>\n<tr>\n<td align=\"left\">(1000, 100) sparsemax_loss_grad</td>\n<td align=\"left\">0.447 \u00b1 0.0158</td>\n<td align=\"left\">1.597 \u00b1 0.0159</td>\n</tr>\n</tbody>\n</table>\n<p><em><code>size</code> specifies the size of the logits and label matrix, both where randomly generated. For each case, 100 iterations where performed to avoid clock issues and <code>tf.Variable().initializer</code> was used to avoid a memory transfer overhead. Finally each experiment was repeated 10 times, the summary of those repetitions are shown as <code>mean \u00b1 95% confidence interval</code>.</em></p>", "body_text": "Here is an initial benchmark:\n\n\n\nsize & case\nkernel CPU\nname_scope CPU\n\n\n\n\n(1000, 10) sparsemax\n0.052 \u00b1 0.0032\n0.203 \u00b1 0.0364\n\n\n(1000, 10) sparsemax_grad\n0.071 \u00b1 0.0009\n0.300 \u00b1 0.0122\n\n\n(1000, 10) sparsemax_loss\n0.060 \u00b1 0.0021\n0.213 \u00b1 0.0112\n\n\n(1000, 10) sparsemax_loss_grad\n0.066 \u00b1 0.0015\n0.310 \u00b1 0.0127\n\n\n(1000, 100) sparsemax\n0.293 \u00b1 0.0094\n0.988 \u00b1 0.0689\n\n\n(1000, 100) sparsemax_grad\n0.373 \u00b1 0.0172\n1.410 \u00b1 0.0110\n\n\n(1000, 100) sparsemax_loss\n0.330 \u00b1 0.0085\n0.979 \u00b1 0.0119\n\n\n(1000, 100) sparsemax_loss_grad\n0.447 \u00b1 0.0158\n1.597 \u00b1 0.0159\n\n\n\nsize specifies the size of the logits and label matrix, both where randomly generated. For each case, 100 iterations where performed to avoid clock issues and tf.Variable().initializer was used to avoid a memory transfer overhead. Finally each experiment was repeated 10 times, the summary of those repetitions are shown as mean \u00b1 95% confidence interval.", "body": "Here is an initial benchmark:\r\n\r\n| size & case                                | kernel CPU     | name_scope CPU   |\r\n|:--------------------------------|:---------------|:-----------------|\r\n| (1000, 10) sparsemax            | 0.052 \u00b1 0.0032 | 0.203 \u00b1 0.0364   |\r\n| (1000, 10) sparsemax_grad       | 0.071 \u00b1 0.0009 | 0.300 \u00b1 0.0122   |\r\n| (1000, 10) sparsemax_loss       | 0.060 \u00b1 0.0021 | 0.213 \u00b1 0.0112   |\r\n| (1000, 10) sparsemax_loss_grad  | 0.066 \u00b1 0.0015 | 0.310 \u00b1 0.0127   |\r\n| (1000, 100) sparsemax           | 0.293 \u00b1 0.0094 | 0.988 \u00b1 0.0689   |\r\n| (1000, 100) sparsemax_grad      | 0.373 \u00b1 0.0172 | 1.410 \u00b1 0.0110   |\r\n| (1000, 100) sparsemax_loss      | 0.330 \u00b1 0.0085 | 0.979 \u00b1 0.0119   |\r\n| (1000, 100) sparsemax_loss_grad | 0.447 \u00b1 0.0158 | 1.597 \u00b1 0.0159   |\r\n\r\n_`size` specifies the size of the logits and label matrix, both where randomly generated. For each case, 100 iterations where performed to avoid clock issues and `tf.Variable().initializer` was used to avoid a memory transfer overhead. Finally each experiment was repeated 10 times, the summary of those repetitions are shown as `mean \u00b1 95% confidence interval`._"}