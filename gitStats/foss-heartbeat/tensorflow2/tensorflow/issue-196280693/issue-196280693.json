{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/6387", "id": 196280693, "node_id": "MDExOlB1bGxSZXF1ZXN0OTg0NzczNDk=", "number": 6387, "title": "Sparsemax", "user": {"login": "AndreasMadsen", "id": 505333, "node_id": "MDQ6VXNlcjUwNTMzMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/505333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndreasMadsen", "html_url": "https://github.com/AndreasMadsen", "followers_url": "https://api.github.com/users/AndreasMadsen/followers", "following_url": "https://api.github.com/users/AndreasMadsen/following{/other_user}", "gists_url": "https://api.github.com/users/AndreasMadsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndreasMadsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndreasMadsen/subscriptions", "organizations_url": "https://api.github.com/users/AndreasMadsen/orgs", "repos_url": "https://api.github.com/users/AndreasMadsen/repos", "events_url": "https://api.github.com/users/AndreasMadsen/events{/privacy}", "received_events_url": "https://api.github.com/users/AndreasMadsen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 74, "created_at": "2016-12-18T15:13:22Z", "updated_at": "2017-02-04T09:47:36Z", "closed_at": "2017-02-03T19:14:12Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6387", "html_url": "https://github.com/tensorflow/tensorflow/pull/6387", "diff_url": "https://github.com/tensorflow/tensorflow/pull/6387.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/6387.patch"}, "body_html": "<p>The sparsemax op is an alternative to the softmax op, that allows the<br>\noutput to be sparse (zero properbility) while stil sharing many<br>\nmathematical properties with softmax.</p>\n<p>The cross entropy loss doesn't work with sparsemax as log(0) is not<br>\ndefined, thus there is also a sparsemax loss function. This loss<br>\nfunction have a gradient equivalent to that of cross entropy when<br>\nusing softmax.</p>\n<p>Original sparsemax article: <a href=\"https://arxiv.org/abs/1602.02068\" rel=\"nofollow\">https://arxiv.org/abs/1602.02068</a></p>\n<hr>\n<p>I had some issues with getting the numerical precision good enough for <code>assertAllCloseAccordingToType</code>. subtracting <code>mean(logits)</code> helped a bit but not enough, thus I have expanded the assert method such that the tolerance can be specified.</p>\n<hr>\n<p><em>This code was developed by me (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=505333\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AndreasMadsen\">@AndreasMadsen</a>), <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7152845\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/FrederikWR\">@FrederikWR</a> and @MarcoDalFarra. The original code can be found in <a href=\"https://github.com/AndreasMadsen/course-02456-sparsemax\">https://github.com/AndreasMadsen/course-02456-sparsemax</a>. The project was supervised by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12167999\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alrojo\">@alrojo</a>.</em></p>", "body_text": "The sparsemax op is an alternative to the softmax op, that allows the\noutput to be sparse (zero properbility) while stil sharing many\nmathematical properties with softmax.\nThe cross entropy loss doesn't work with sparsemax as log(0) is not\ndefined, thus there is also a sparsemax loss function. This loss\nfunction have a gradient equivalent to that of cross entropy when\nusing softmax.\nOriginal sparsemax article: https://arxiv.org/abs/1602.02068\n\nI had some issues with getting the numerical precision good enough for assertAllCloseAccordingToType. subtracting mean(logits) helped a bit but not enough, thus I have expanded the assert method such that the tolerance can be specified.\n\nThis code was developed by me (@AndreasMadsen), @FrederikWR and @MarcoDalFarra. The original code can be found in https://github.com/AndreasMadsen/course-02456-sparsemax. The project was supervised by @alrojo.", "body": "The sparsemax op is an alternative to the softmax op, that allows the\r\noutput to be sparse (zero properbility) while stil sharing many\r\nmathematical properties with softmax.\r\n\r\nThe cross entropy loss doesn't work with sparsemax as log(0) is not\r\ndefined, thus there is also a sparsemax loss function. This loss\r\nfunction have a gradient equivalent to that of cross entropy when\r\nusing softmax.\r\n\r\nOriginal sparsemax article: https://arxiv.org/abs/1602.02068\r\n\r\n----\r\n\r\nI had some issues with getting the numerical precision good enough for `assertAllCloseAccordingToType`. subtracting `mean(logits)` helped a bit but not enough, thus I have expanded the assert method such that the tolerance can be specified.\r\n\r\n----\r\n\r\n_This code was developed by me (@andreasmadsen), @FrederikWR and @MarcoDalFarra. The original code can be found in https://github.com/AndreasMadsen/course-02456-sparsemax. The project was supervised by @alrojo._\r\n"}