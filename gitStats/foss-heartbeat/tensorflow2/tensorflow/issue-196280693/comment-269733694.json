{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269733694", "html_url": "https://github.com/tensorflow/tensorflow/pull/6387#issuecomment-269733694", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6387", "id": 269733694, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTczMzY5NA==", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-30T05:17:59Z", "updated_at": "2016-12-30T05:17:59Z", "author_association": "MEMBER", "body_html": "<p>I think there is something I don't understand about how you specify sizes. A normal softmax from vectors of size 512 into 16K labels easily fits into any GPU, so I'm clearly not understanding something here.</p>\n<p>But as for your benchmarks: you should always first run at least one iteration and throw away the timing, only later start true measurements. The graph does a fair bit of one-time allocations, especially with Defun, no need to measure them.</p>\n<p>Give it another look, if the benchmarks still show that the Defun isn't helping, then I think we should check in the code without it and focus on optimizing that. Did you look at the TF timeline to see what takes so much time? (We can optimize performance after checking this in too, as you prefer.)</p>", "body_text": "I think there is something I don't understand about how you specify sizes. A normal softmax from vectors of size 512 into 16K labels easily fits into any GPU, so I'm clearly not understanding something here.\nBut as for your benchmarks: you should always first run at least one iteration and throw away the timing, only later start true measurements. The graph does a fair bit of one-time allocations, especially with Defun, no need to measure them.\nGive it another look, if the benchmarks still show that the Defun isn't helping, then I think we should check in the code without it and focus on optimizing that. Did you look at the TF timeline to see what takes so much time? (We can optimize performance after checking this in too, as you prefer.)", "body": "I think there is something I don't understand about how you specify sizes. A normal softmax from vectors of size 512 into 16K labels easily fits into any GPU, so I'm clearly not understanding something here.\r\n\r\nBut as for your benchmarks: you should always first run at least one iteration and throw away the timing, only later start true measurements. The graph does a fair bit of one-time allocations, especially with Defun, no need to measure them.\r\n\r\nGive it another look, if the benchmarks still show that the Defun isn't helping, then I think we should check in the code without it and focus on optimizing that. Did you look at the TF timeline to see what takes so much time? (We can optimize performance after checking this in too, as you prefer.)"}