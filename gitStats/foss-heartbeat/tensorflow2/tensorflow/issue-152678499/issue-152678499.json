{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2199", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2199/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2199/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2199/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2199", "id": 152678499, "node_id": "MDU6SXNzdWUxNTI2Nzg0OTk=", "number": 2199, "title": "Tensorflow GRU error when trying to concatenate activations to outputs", "user": {"login": "ushnish", "id": 3603839, "node_id": "MDQ6VXNlcjM2MDM4Mzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/3603839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ushnish", "html_url": "https://github.com/ushnish", "followers_url": "https://api.github.com/users/ushnish/followers", "following_url": "https://api.github.com/users/ushnish/following{/other_user}", "gists_url": "https://api.github.com/users/ushnish/gists{/gist_id}", "starred_url": "https://api.github.com/users/ushnish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ushnish/subscriptions", "organizations_url": "https://api.github.com/users/ushnish/orgs", "repos_url": "https://api.github.com/users/ushnish/repos", "events_url": "https://api.github.com/users/ushnish/events{/privacy}", "received_events_url": "https://api.github.com/users/ushnish/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-05-03T00:57:08Z", "updated_at": "2016-05-16T16:22:07Z", "closed_at": "2016-05-16T16:22:07Z", "author_association": "NONE", "body_html": "<p>I have been trying to grab the activations of the GRU cell layer in the following manner</p>\n<pre><code>def __call__(self, inputs, state, scope=None):\n    \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n    with vs.variable_scope(scope or type(self).__name__):  # \"GRUCell\"\n      with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n        # We start with bias of 1.0 to not reset and not update.\n        r, u = array_ops.split(1, 2, linear([inputs, state], 2 * self._num_units, True, 1.0))\n        r, u = sigmoid(r), sigmoid(u)\n      with vs.variable_scope(\"Candidate\"):\n        c = tanh(linear([inputs, r * state], self._num_units, True))\n      new_h = u * state + (1 - u) * c\n\n      # store the activations, everything else is the same\n      h_activations = array_ops.concat(1, [new_h,r,u,c])\n    return h_activations, h_activations\n</code></pre>\n<p>Later I try to grab the activations in the following way</p>\n<p><code>cell = ClusterableGRUCell(num_units=hidden_neurons) initial_state = tf.zeros([batch_size, cell.state_size]) outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s) outputs_activations = tf.concat(0, outputs_activations) outputs, rs, us, cs = tf.split(1, 4, outputs_activations) activations = tf.concat(1, [rs, us, cs])</code></p>\n<p>However this fails in the <code>rnn()</code> step with the following error</p>\n<p>Traceback (most recent call last):<br>\nFile \"myautoencoder.py\", line 29, in <br>\noutputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)<br>\nFile \"xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 141, in rnn<br>\nzero_output, state, call_cell)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 265, in _rnn_step<br>\n_maybe_copy_some_through)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond<br>\nres_f = context_f.BuildCondBranch(fn2)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch<br>\nr = fn()<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in _maybe_copy_some_through<br>\nlambda: _copy_some_through(new_output, new_state))<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond<br>\nres_f = context_f.BuildCondBranch(fn2)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch<br>\nr = fn()<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in <br>\nlambda: _copy_some_through(new_output, new_state))<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 236, in _copy_some_through<br>\nreturn (math_ops.select(copy_cond, zero_output, new_output),<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1396, in select<br>\nname=name)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op<br>\nop_def=op_def)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2156, in create_op<br>\nset_shapes_for_outputs(ret)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1612, in set_shapes_for_outputs<br>\nshapes = shape_func(op)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1411, in _SelectShape<br>\nt_e_shape = t_shape.merge_with(e_shape)<br>\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 554, in merge_with<br>\n(self, other))<br>\nValueError: Shapes (32, 33) and (32, 132) are not compatible</p>\n<p>My batch size is 32 and number of neurons is 33, 132 = 33*4 which makes sense. What I dont understand is why is there a lingering (32,33) tensor? Thank you.</p>", "body_text": "I have been trying to grab the activations of the GRU cell layer in the following manner\ndef __call__(self, inputs, state, scope=None):\n    \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n    with vs.variable_scope(scope or type(self).__name__):  # \"GRUCell\"\n      with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n        # We start with bias of 1.0 to not reset and not update.\n        r, u = array_ops.split(1, 2, linear([inputs, state], 2 * self._num_units, True, 1.0))\n        r, u = sigmoid(r), sigmoid(u)\n      with vs.variable_scope(\"Candidate\"):\n        c = tanh(linear([inputs, r * state], self._num_units, True))\n      new_h = u * state + (1 - u) * c\n\n      # store the activations, everything else is the same\n      h_activations = array_ops.concat(1, [new_h,r,u,c])\n    return h_activations, h_activations\n\nLater I try to grab the activations in the following way\ncell = ClusterableGRUCell(num_units=hidden_neurons) initial_state = tf.zeros([batch_size, cell.state_size]) outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s) outputs_activations = tf.concat(0, outputs_activations) outputs, rs, us, cs = tf.split(1, 4, outputs_activations) activations = tf.concat(1, [rs, us, cs])\nHowever this fails in the rnn() step with the following error\nTraceback (most recent call last):\nFile \"myautoencoder.py\", line 29, in \noutputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)\nFile \"xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 141, in rnn\nzero_output, state, call_cell)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 265, in _rnn_step\n_maybe_copy_some_through)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\nres_f = context_f.BuildCondBranch(fn2)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\nr = fn()\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in _maybe_copy_some_through\nlambda: _copy_some_through(new_output, new_state))\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\nres_f = context_f.BuildCondBranch(fn2)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\nr = fn()\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in \nlambda: _copy_some_through(new_output, new_state))\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 236, in _copy_some_through\nreturn (math_ops.select(copy_cond, zero_output, new_output),\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1396, in select\nname=name)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\nop_def=op_def)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2156, in create_op\nset_shapes_for_outputs(ret)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1612, in set_shapes_for_outputs\nshapes = shape_func(op)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1411, in _SelectShape\nt_e_shape = t_shape.merge_with(e_shape)\nFile \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 554, in merge_with\n(self, other))\nValueError: Shapes (32, 33) and (32, 132) are not compatible\nMy batch size is 32 and number of neurons is 33, 132 = 33*4 which makes sense. What I dont understand is why is there a lingering (32,33) tensor? Thank you.", "body": "I have been trying to grab the activations of the GRU cell layer in the following manner\n\n```\ndef __call__(self, inputs, state, scope=None):\n    \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n    with vs.variable_scope(scope or type(self).__name__):  # \"GRUCell\"\n      with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n        # We start with bias of 1.0 to not reset and not update.\n        r, u = array_ops.split(1, 2, linear([inputs, state], 2 * self._num_units, True, 1.0))\n        r, u = sigmoid(r), sigmoid(u)\n      with vs.variable_scope(\"Candidate\"):\n        c = tanh(linear([inputs, r * state], self._num_units, True))\n      new_h = u * state + (1 - u) * c\n\n      # store the activations, everything else is the same\n      h_activations = array_ops.concat(1, [new_h,r,u,c])\n    return h_activations, h_activations\n```\n\nLater I try to grab the activations in the following way\n\n`cell = ClusterableGRUCell(num_units=hidden_neurons)\ninitial_state = tf.zeros([batch_size, cell.state_size])\noutputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)\noutputs_activations = tf.concat(0, outputs_activations)\noutputs, rs, us, cs = tf.split(1, 4, outputs_activations)\nactivations = tf.concat(1, [rs, us, cs])`\n\nHowever this fails in the `rnn()` step with the following error\n\nTraceback (most recent call last):\n  File \"myautoencoder.py\", line 29, in <module>\n    outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)\n  File \"xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 141, in rnn\n    zero_output, state, call_cell)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 265, in _rnn_step\n    _maybe_copy_some_through)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\n    res_f = context_f.BuildCondBranch(fn2)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\n    r = fn()\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in _maybe_copy_some_through\n    lambda: _copy_some_through(new_output, new_state))\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\n    res_f = context_f.BuildCondBranch(fn2)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\n    r = fn()\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in <lambda>\n    lambda: _copy_some_through(new_output, new_state))\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 236, in _copy_some_through\n    return (math_ops.select(copy_cond, zero_output, new_output),\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1396, in select\n    name=name)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2156, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1612, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1411, in _SelectShape\n    t_e_shape = t_shape.merge_with(e_shape)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 554, in merge_with\n    (self, other))\nValueError: Shapes (32, 33) and (32, 132) are not compatible\n\nMy batch size is 32 and number of neurons is 33, 132 = 33*4 which makes sense. What I dont understand is why is there a lingering (32,33) tensor? Thank you.\n"}