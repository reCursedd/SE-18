{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439557079", "html_url": "https://github.com/tensorflow/tensorflow/issues/21526#issuecomment-439557079", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21526", "id": 439557079, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTU1NzA3OQ==", "user": {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-16T23:12:44Z", "updated_at": "2018-11-16T23:12:44Z", "author_association": "MEMBER", "body_html": "<blockquote>\n<p>Hi, is it worth waiting for implementation FakeQuantWithMinMaxVarsPerChannel?</p>\n</blockquote>\n<p>It is unlikely that we'll adding additional support for FakeQuant ops in the near future. Your best bet is to look into using <a href=\"https://www.tensorflow.org/lite/performance/post_training_quantization\" rel=\"nofollow\">post-training quantization</a>.</p>", "body_text": "Hi, is it worth waiting for implementation FakeQuantWithMinMaxVarsPerChannel?\n\nIt is unlikely that we'll adding additional support for FakeQuant ops in the near future. Your best bet is to look into using post-training quantization.", "body": "> Hi, is it worth waiting for implementation FakeQuantWithMinMaxVarsPerChannel?\r\n\r\nIt is unlikely that we'll adding additional support for FakeQuant ops in the near future. Your best bet is to look into using [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).\r\n\r\n"}