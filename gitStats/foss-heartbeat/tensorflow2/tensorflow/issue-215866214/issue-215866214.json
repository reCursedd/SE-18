{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8596", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8596/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8596/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8596/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8596", "id": 215866214, "node_id": "MDU6SXNzdWUyMTU4NjYyMTQ=", "number": 8596, "title": "tf.nn.conv3d ignoring first spacial dimension", "user": {"login": "alexanderalang", "id": 22649804, "node_id": "MDQ6VXNlcjIyNjQ5ODA0", "avatar_url": "https://avatars1.githubusercontent.com/u/22649804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexanderalang", "html_url": "https://github.com/alexanderalang", "followers_url": "https://api.github.com/users/alexanderalang/followers", "following_url": "https://api.github.com/users/alexanderalang/following{/other_user}", "gists_url": "https://api.github.com/users/alexanderalang/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexanderalang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexanderalang/subscriptions", "organizations_url": "https://api.github.com/users/alexanderalang/orgs", "repos_url": "https://api.github.com/users/alexanderalang/repos", "events_url": "https://api.github.com/users/alexanderalang/events{/privacy}", "received_events_url": "https://api.github.com/users/alexanderalang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-03-21T20:22:57Z", "updated_at": "2017-03-23T16:34:31Z", "closed_at": "2017-03-23T16:34:31Z", "author_association": "NONE", "body_html": "<p>Im using tensorflow 1.0.0 (python 3.5) on OSX(10.11.6 El Capitan), but the same problem occurred with tf version 1.0.1. also got this error when I tried to run the module with the google ml-engine.</p>\n<h1><strong>Relevant code</strong></h1>\n<pre><code>def conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\n    with tf.name_scope(layer_name):\n        with tf.name_scope('weights'):\n            tf.add_to_collection(tf.GraphKeys.WEIGHTS, weights)\n            variable_summaries(weights)\n        with tf.name_scope('biases'):\n            variable_summaries(biases)\n        with tf.name_scope('convWx_plus_b'):\n            preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\n            #preactivate = tf.nn.convolution(inputs,weights,padding,data_format='NDHWC')\n            tf.summary.histogram('preactivate', preactivate)\n            activation = act(preactivate) \n            tf.summary.histogram('activation', activation)\n    return activation\n</code></pre>\n<pre><code>def weight_variable(shape,dtype=np.float32,partition_info=None):\n    shape[shape==None] = 1\n    n = np.prod(shape)\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\n    return tf.Variable(w.reshape(shape),trainable=True)\n</code></pre>\n<pre><code>def bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial,trainable=True)\n\n</code></pre>\n<pre><code>def maxpool(inputs,padding='VALID'):\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\n</code></pre>\n<pre><code>def ll_model(inputs):\n    \n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\n    \n    W_conv1 = weight_variable([3,3,3,2,16])\n    b_conv1 = bias_variable([16])\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\n\n    print(conv1.get_shape().as_list())\n\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\n    print(pad.get_shape().as_list())\n    maxpool1 = maxpool(pad)\n    print(maxpool1.get_shape().as_list())\n\n    W_conv2 = weight_variable([3,3,3,16,24])\n    b_conv2 = bias_variable([24])\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\n    print(conv2.get_shape().as_list())\n    W_conv3 = weight_variable([3,3,3,24,28])\n    b_conv3 = bias_variable([28])\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\n    print(conv3.get_shape().as_list())\n    W_conv4 = weight_variable([4,4,4,28,34])\n    b_conv4 = bias_variable([34])\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\n    print(conv4.get_shape().as_list())\n    W_conv5 = weight_variable([5,5,5,34,42])\n    b_conv5 = bias_variable([42])\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\n    print(conv5.get_shape().as_list())\n    W_conv6 = weight_variable([5,5,5,42,50])\n    b_conv6 = bias_variable([50])\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\n    print(conv6.get_shape().as_list())\n    W_conv7 = weight_variable([5,5,5,50,50])\n    b_conv7 = bias_variable([50])\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\n    print(conv7.get_shape().as_list())\n    W_conv8 = weight_variable([1,1,1,50,2])\n    b_conv8 = bias_variable([2])\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output',act=depth_softmax)\n    \n    return conv8\n</code></pre>\n<p>the error happens when compiling the model. conv8 is supposed to have the shape [None,17,17,17,2].</p>\n<h1>The Error:</h1>\n<pre><code>python task.py                                                                       \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 ins\ntructions, but these are available on your machine and could speed up CPU computations.                     \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 ins\ntructions, but these are available on your machine and could speed up CPU computations.                     \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instru\nctions, but these are available on your machine and could speed up CPU computations.                        \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instr\nuctions, but these are available on your machine and could speed up CPU computations.                       \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instru\nctions, but these are available on your machine and could speed up CPU computations.                        \n[None, 65, 63, 63, 16]                                                                                      \n[None, 66, 64, 64, 16]                                                                                      \n[None, 33, 32, 32, 16]                                                                                      \n[None, 33, 32, 32, 24]                                                                                      \n[None, 33, 32, 32, 28]                                                                                      \n[None, 33, 29, 29, 34]                                                                                      \n[None, 33, 25, 25, 42]                                                                                      \n[None, 33, 21, 21, 50]                                                                                      \n[None, 33, 17, 17, 50]                                                                                      \nTraceback (most recent call last):                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 670, in _call_cpp_shape_fn_impl                                                     \n    status)                                                                                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__      \n    next(self.gen)                                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nerrors_impl.py\", line 469, in raise_exception_on_not_ok_status                                              \n    pywrap_tensorflow.TF_GetCode(status))                                                                   \ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 17 and 33 fo\nr 'SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,17,17,17,2], [?,33,17,17,2].          \n                                                                                                            \nDuring handling of the above exception, another exception occurred:                                         \n                                                                                                            \nTraceback (most recent call last):                                                                          \n  File \"task.py\", line 33, in &lt;module&gt;                                                                      \n    loss = mean_square_error(y,ll_model(x))                                                                 \n  File \"/Users/vhasfclanga/tflow_trainer/trainer/functions.py\", line 80, in mean_square_error               \n    return tf.reduce_sum(tf.squared_difference(a,b)) / N                                                    \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_ma\nth_ops.py\", line 2754, in squared_difference                                                                \n    result = _op_def_lib.apply_op(\"SquaredDifference\", x=x, y=y, name=name)                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nop_def_library.py\", line 763, in apply_op                                                                   \n    op_def=op_def)                                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 2397, in create_op                                                                            \n    set_shapes_for_outputs(ret)                                                                             \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 1757, in set_shapes_for_outputs                                                               \n    shapes = shape_func(op)                                                                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 1707, in call_with_requiring                                                                  \n    return call_cpp_shape_fn(op, require_shape_fn=True)                                                     \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 610, in call_cpp_shape_fn                                                           \n    debug_python_shape_fn, require_shape_fn)                                                                \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 675, in _call_cpp_shape_fn_impl                                                     \n    raise ValueError(err.message)                                                                           \nValueError: Dimensions must be equal, but are 17 and 33 for 'SquaredDifference' (op: 'SquaredDifference') wi\nth input shapes: [?,17,17,17,2], [?,33,17,17,2].\n</code></pre>\n<p>As you can see, these are the shapes of the tensors resulting from each convolutional layer.</p>\n<p>[None, 65, 63, 63, 16]<br>\n[None, 66, 64, 64, 16]<br>\n[None, 33, 32, 32, 16]<br>\n[None, 33, 32, 32, 24]<br>\n[None, 33, 32, 32, 28]<br>\n[None, 33, 29, 29, 34]<br>\n[None, 33, 25, 25, 42]<br>\n[None, 33, 21, 21, 50]<br>\n[None, 33, 17, 17, 50]</p>\n<p>Notice the first spacial dimension is only effected by pooling and padding layers, and is totally ignored by convolutional layers. It's strange to me because everything should be symmetric across spatial dimensions.</p>\n<p>I've tried using tf.nn.convolution as seen in my conv3d wrapper, that yielded the same result. I've tried switching up the padding, that also didn't work. I tried using the higher level functions in tf.layers to construct the model, that also didn't work. The fact that none of these methods worked makes me think this must be a programming error on my part, but the error is coming from a simple propagation of tensor shapes, starting with placeholders</p>\n<pre><code>with tf.name_scope('inputs'):\n    x = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\n    tf.summary.histogram('feature-hist', x)\nwith tf.name_scope('ground_truth'):\n    y = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\n    tf.summary.histogram('target-hist', y)\n\n</code></pre>\n<p>So I'm not sure where I could have possibly gone wrong.</p>\n<p>Also, this exact model structure resulted in the correct output shape when used with the Estimator + ModelFnOps API.</p>\n<p>the error can be reproduced by using one of the built in loss functions and running</p>\n<p><code>tf.some_loss_function(y,ll_model(x))</code></p>\n<p>the function I was using was</p>\n<pre><code>def mean_square_error(a,b):\n    shape = a.get_shape().as_list()\n    shape[shape==None] = 1\n    N = np.prod(shape)\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\n\n</code></pre>\n<p>Does anyone know if this is a bug or programming error on my part?</p>\n<p>Thanks in advance,<br>\nAlex</p>", "body_text": "Im using tensorflow 1.0.0 (python 3.5) on OSX(10.11.6 El Capitan), but the same problem occurred with tf version 1.0.1. also got this error when I tried to run the module with the google ml-engine.\nRelevant code\ndef conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\n    with tf.name_scope(layer_name):\n        with tf.name_scope('weights'):\n            tf.add_to_collection(tf.GraphKeys.WEIGHTS, weights)\n            variable_summaries(weights)\n        with tf.name_scope('biases'):\n            variable_summaries(biases)\n        with tf.name_scope('convWx_plus_b'):\n            preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\n            #preactivate = tf.nn.convolution(inputs,weights,padding,data_format='NDHWC')\n            tf.summary.histogram('preactivate', preactivate)\n            activation = act(preactivate) \n            tf.summary.histogram('activation', activation)\n    return activation\n\ndef weight_variable(shape,dtype=np.float32,partition_info=None):\n    shape[shape==None] = 1\n    n = np.prod(shape)\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\n    return tf.Variable(w.reshape(shape),trainable=True)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial,trainable=True)\n\n\ndef maxpool(inputs,padding='VALID'):\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\n\ndef ll_model(inputs):\n    \n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\n    \n    W_conv1 = weight_variable([3,3,3,2,16])\n    b_conv1 = bias_variable([16])\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\n\n    print(conv1.get_shape().as_list())\n\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\n    print(pad.get_shape().as_list())\n    maxpool1 = maxpool(pad)\n    print(maxpool1.get_shape().as_list())\n\n    W_conv2 = weight_variable([3,3,3,16,24])\n    b_conv2 = bias_variable([24])\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\n    print(conv2.get_shape().as_list())\n    W_conv3 = weight_variable([3,3,3,24,28])\n    b_conv3 = bias_variable([28])\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\n    print(conv3.get_shape().as_list())\n    W_conv4 = weight_variable([4,4,4,28,34])\n    b_conv4 = bias_variable([34])\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\n    print(conv4.get_shape().as_list())\n    W_conv5 = weight_variable([5,5,5,34,42])\n    b_conv5 = bias_variable([42])\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\n    print(conv5.get_shape().as_list())\n    W_conv6 = weight_variable([5,5,5,42,50])\n    b_conv6 = bias_variable([50])\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\n    print(conv6.get_shape().as_list())\n    W_conv7 = weight_variable([5,5,5,50,50])\n    b_conv7 = bias_variable([50])\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\n    print(conv7.get_shape().as_list())\n    W_conv8 = weight_variable([1,1,1,50,2])\n    b_conv8 = bias_variable([2])\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output',act=depth_softmax)\n    \n    return conv8\n\nthe error happens when compiling the model. conv8 is supposed to have the shape [None,17,17,17,2].\nThe Error:\npython task.py                                                                       \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 ins\ntructions, but these are available on your machine and could speed up CPU computations.                     \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 ins\ntructions, but these are available on your machine and could speed up CPU computations.                     \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instru\nctions, but these are available on your machine and could speed up CPU computations.                        \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instr\nuctions, but these are available on your machine and could speed up CPU computations.                       \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instru\nctions, but these are available on your machine and could speed up CPU computations.                        \n[None, 65, 63, 63, 16]                                                                                      \n[None, 66, 64, 64, 16]                                                                                      \n[None, 33, 32, 32, 16]                                                                                      \n[None, 33, 32, 32, 24]                                                                                      \n[None, 33, 32, 32, 28]                                                                                      \n[None, 33, 29, 29, 34]                                                                                      \n[None, 33, 25, 25, 42]                                                                                      \n[None, 33, 21, 21, 50]                                                                                      \n[None, 33, 17, 17, 50]                                                                                      \nTraceback (most recent call last):                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 670, in _call_cpp_shape_fn_impl                                                     \n    status)                                                                                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__      \n    next(self.gen)                                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nerrors_impl.py\", line 469, in raise_exception_on_not_ok_status                                              \n    pywrap_tensorflow.TF_GetCode(status))                                                                   \ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 17 and 33 fo\nr 'SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,17,17,17,2], [?,33,17,17,2].          \n                                                                                                            \nDuring handling of the above exception, another exception occurred:                                         \n                                                                                                            \nTraceback (most recent call last):                                                                          \n  File \"task.py\", line 33, in <module>                                                                      \n    loss = mean_square_error(y,ll_model(x))                                                                 \n  File \"/Users/vhasfclanga/tflow_trainer/trainer/functions.py\", line 80, in mean_square_error               \n    return tf.reduce_sum(tf.squared_difference(a,b)) / N                                                    \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_ma\nth_ops.py\", line 2754, in squared_difference                                                                \n    result = _op_def_lib.apply_op(\"SquaredDifference\", x=x, y=y, name=name)                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nop_def_library.py\", line 763, in apply_op                                                                   \n    op_def=op_def)                                                                                          \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 2397, in create_op                                                                            \n    set_shapes_for_outputs(ret)                                                                             \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 1757, in set_shapes_for_outputs                                                               \n    shapes = shape_func(op)                                                                                 \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\nops.py\", line 1707, in call_with_requiring                                                                  \n    return call_cpp_shape_fn(op, require_shape_fn=True)                                                     \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 610, in call_cpp_shape_fn                                                           \n    debug_python_shape_fn, require_shape_fn)                                                                \n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\ncommon_shapes.py\", line 675, in _call_cpp_shape_fn_impl                                                     \n    raise ValueError(err.message)                                                                           \nValueError: Dimensions must be equal, but are 17 and 33 for 'SquaredDifference' (op: 'SquaredDifference') wi\nth input shapes: [?,17,17,17,2], [?,33,17,17,2].\n\nAs you can see, these are the shapes of the tensors resulting from each convolutional layer.\n[None, 65, 63, 63, 16]\n[None, 66, 64, 64, 16]\n[None, 33, 32, 32, 16]\n[None, 33, 32, 32, 24]\n[None, 33, 32, 32, 28]\n[None, 33, 29, 29, 34]\n[None, 33, 25, 25, 42]\n[None, 33, 21, 21, 50]\n[None, 33, 17, 17, 50]\nNotice the first spacial dimension is only effected by pooling and padding layers, and is totally ignored by convolutional layers. It's strange to me because everything should be symmetric across spatial dimensions.\nI've tried using tf.nn.convolution as seen in my conv3d wrapper, that yielded the same result. I've tried switching up the padding, that also didn't work. I tried using the higher level functions in tf.layers to construct the model, that also didn't work. The fact that none of these methods worked makes me think this must be a programming error on my part, but the error is coming from a simple propagation of tensor shapes, starting with placeholders\nwith tf.name_scope('inputs'):\n    x = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\n    tf.summary.histogram('feature-hist', x)\nwith tf.name_scope('ground_truth'):\n    y = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\n    tf.summary.histogram('target-hist', y)\n\n\nSo I'm not sure where I could have possibly gone wrong.\nAlso, this exact model structure resulted in the correct output shape when used with the Estimator + ModelFnOps API.\nthe error can be reproduced by using one of the built in loss functions and running\ntf.some_loss_function(y,ll_model(x))\nthe function I was using was\ndef mean_square_error(a,b):\n    shape = a.get_shape().as_list()\n    shape[shape==None] = 1\n    N = np.prod(shape)\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\n\n\nDoes anyone know if this is a bug or programming error on my part?\nThanks in advance,\nAlex", "body": "Im using tensorflow 1.0.0 (python 3.5) on OSX(10.11.6 El Capitan), but the same problem occurred with tf version 1.0.1. also got this error when I tried to run the module with the google ml-engine.\r\n\r\n# **Relevant code**\r\n\r\n\r\n\r\n````\r\ndef conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\r\n    with tf.name_scope(layer_name):\r\n        with tf.name_scope('weights'):\r\n            tf.add_to_collection(tf.GraphKeys.WEIGHTS, weights)\r\n            variable_summaries(weights)\r\n        with tf.name_scope('biases'):\r\n            variable_summaries(biases)\r\n        with tf.name_scope('convWx_plus_b'):\r\n            preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\r\n            #preactivate = tf.nn.convolution(inputs,weights,padding,data_format='NDHWC')\r\n            tf.summary.histogram('preactivate', preactivate)\r\n            activation = act(preactivate) \r\n            tf.summary.histogram('activation', activation)\r\n    return activation\r\n````        \r\n\r\n```\r\ndef weight_variable(shape,dtype=np.float32,partition_info=None):\r\n    shape[shape==None] = 1\r\n    n = np.prod(shape)\r\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\r\n    return tf.Variable(w.reshape(shape),trainable=True)\r\n```\r\n\r\n```\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0.1, shape=shape)\r\n    return tf.Variable(initial,trainable=True)\r\n\r\n```\r\n\r\n\r\n```\r\ndef maxpool(inputs,padding='VALID'):\r\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\r\n```\r\n\r\n```\r\ndef ll_model(inputs):\r\n    \r\n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\r\n    \r\n    W_conv1 = weight_variable([3,3,3,2,16])\r\n    b_conv1 = bias_variable([16])\r\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\r\n\r\n    print(conv1.get_shape().as_list())\r\n\r\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\r\n    print(pad.get_shape().as_list())\r\n    maxpool1 = maxpool(pad)\r\n    print(maxpool1.get_shape().as_list())\r\n\r\n    W_conv2 = weight_variable([3,3,3,16,24])\r\n    b_conv2 = bias_variable([24])\r\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\r\n    print(conv2.get_shape().as_list())\r\n    W_conv3 = weight_variable([3,3,3,24,28])\r\n    b_conv3 = bias_variable([28])\r\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\r\n    print(conv3.get_shape().as_list())\r\n    W_conv4 = weight_variable([4,4,4,28,34])\r\n    b_conv4 = bias_variable([34])\r\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\r\n    print(conv4.get_shape().as_list())\r\n    W_conv5 = weight_variable([5,5,5,34,42])\r\n    b_conv5 = bias_variable([42])\r\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\r\n    print(conv5.get_shape().as_list())\r\n    W_conv6 = weight_variable([5,5,5,42,50])\r\n    b_conv6 = bias_variable([50])\r\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\r\n    print(conv6.get_shape().as_list())\r\n    W_conv7 = weight_variable([5,5,5,50,50])\r\n    b_conv7 = bias_variable([50])\r\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\r\n    print(conv7.get_shape().as_list())\r\n    W_conv8 = weight_variable([1,1,1,50,2])\r\n    b_conv8 = bias_variable([2])\r\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output',act=depth_softmax)\r\n    \r\n    return conv8\r\n```\r\n\r\n\r\nthe error happens when compiling the model. conv8 is supposed to have the shape [None,17,17,17,2].\r\n\r\n# The Error:\r\n\r\n```\r\npython task.py                                                                       \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 ins\r\ntructions, but these are available on your machine and could speed up CPU computations.                     \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 ins\r\ntructions, but these are available on your machine and could speed up CPU computations.                     \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instru\r\nctions, but these are available on your machine and could speed up CPU computations.                        \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instr\r\nuctions, but these are available on your machine and could speed up CPU computations.                       \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instru\r\nctions, but these are available on your machine and could speed up CPU computations.                        \r\n[None, 65, 63, 63, 16]                                                                                      \r\n[None, 66, 64, 64, 16]                                                                                      \r\n[None, 33, 32, 32, 16]                                                                                      \r\n[None, 33, 32, 32, 24]                                                                                      \r\n[None, 33, 32, 32, 28]                                                                                      \r\n[None, 33, 29, 29, 34]                                                                                      \r\n[None, 33, 25, 25, 42]                                                                                      \r\n[None, 33, 21, 21, 50]                                                                                      \r\n[None, 33, 17, 17, 50]                                                                                      \r\nTraceback (most recent call last):                                                                          \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\ncommon_shapes.py\", line 670, in _call_cpp_shape_fn_impl                                                     \r\n    status)                                                                                                 \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__      \r\n    next(self.gen)                                                                                          \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\nerrors_impl.py\", line 469, in raise_exception_on_not_ok_status                                              \r\n    pywrap_tensorflow.TF_GetCode(status))                                                                   \r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 17 and 33 fo\r\nr 'SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,17,17,17,2], [?,33,17,17,2].          \r\n                                                                                                            \r\nDuring handling of the above exception, another exception occurred:                                         \r\n                                                                                                            \r\nTraceback (most recent call last):                                                                          \r\n  File \"task.py\", line 33, in <module>                                                                      \r\n    loss = mean_square_error(y,ll_model(x))                                                                 \r\n  File \"/Users/vhasfclanga/tflow_trainer/trainer/functions.py\", line 80, in mean_square_error               \r\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N                                                    \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_ma\r\nth_ops.py\", line 2754, in squared_difference                                                                \r\n    result = _op_def_lib.apply_op(\"SquaredDifference\", x=x, y=y, name=name)                                 \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\nop_def_library.py\", line 763, in apply_op                                                                   \r\n    op_def=op_def)                                                                                          \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\nops.py\", line 2397, in create_op                                                                            \r\n    set_shapes_for_outputs(ret)                                                                             \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\nops.py\", line 1757, in set_shapes_for_outputs                                                               \r\n    shapes = shape_func(op)                                                                                 \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\nops.py\", line 1707, in call_with_requiring                                                                  \r\n    return call_cpp_shape_fn(op, require_shape_fn=True)                                                     \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\ncommon_shapes.py\", line 610, in call_cpp_shape_fn                                                           \r\n    debug_python_shape_fn, require_shape_fn)                                                                \r\n  File \"/Users/vhasfclanga/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/\r\ncommon_shapes.py\", line 675, in _call_cpp_shape_fn_impl                                                     \r\n    raise ValueError(err.message)                                                                           \r\nValueError: Dimensions must be equal, but are 17 and 33 for 'SquaredDifference' (op: 'SquaredDifference') wi\r\nth input shapes: [?,17,17,17,2], [?,33,17,17,2].\r\n```\r\n\r\nAs you can see, these are the shapes of the tensors resulting from each convolutional layer.\r\n\r\n[None, 65, 63, 63, 16]                                                                                      \r\n[None, 66, 64, 64, 16]                                                                                      \r\n[None, 33, 32, 32, 16]                                                                                      \r\n[None, 33, 32, 32, 24]                                                                                      \r\n[None, 33, 32, 32, 28]                                                                                      \r\n[None, 33, 29, 29, 34]                                                                                      \r\n[None, 33, 25, 25, 42]                                                                                      \r\n[None, 33, 21, 21, 50]                                                                                      \r\n[None, 33, 17, 17, 50]     \r\n\r\n\r\nNotice the first spacial dimension is only effected by pooling and padding layers, and is totally ignored by convolutional layers. It's strange to me because everything should be symmetric across spatial dimensions.\r\n\r\nI've tried using tf.nn.convolution as seen in my conv3d wrapper, that yielded the same result. I've tried switching up the padding, that also didn't work. I tried using the higher level functions in tf.layers to construct the model, that also didn't work. The fact that none of these methods worked makes me think this must be a programming error on my part, but the error is coming from a simple propagation of tensor shapes, starting with placeholders\r\n\r\n```\r\nwith tf.name_scope('inputs'):\r\n    x = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\r\n    tf.summary.histogram('feature-hist', x)\r\nwith tf.name_scope('ground_truth'):\r\n    y = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\r\n    tf.summary.histogram('target-hist', y)\r\n\r\n```\r\nSo I'm not sure where I could have possibly gone wrong.\r\n\r\nAlso, this exact model structure resulted in the correct output shape when used with the Estimator + ModelFnOps API.\r\n\r\nthe error can be reproduced by using one of the built in loss functions and running\r\n\r\n`tf.some_loss_function(y,ll_model(x))`\r\n\r\nthe function I was using was \r\n```\r\ndef mean_square_error(a,b):\r\n    shape = a.get_shape().as_list()\r\n    shape[shape==None] = 1\r\n    N = np.prod(shape)\r\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\r\n\r\n```\r\nDoes anyone know if this is a bug or programming error on my part?\r\n\r\nThanks in advance,\r\nAlex"}