{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288461428", "html_url": "https://github.com/tensorflow/tensorflow/issues/8596#issuecomment-288461428", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8596", "id": 288461428, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODQ2MTQyOA==", "user": {"login": "alexanderalang", "id": 22649804, "node_id": "MDQ6VXNlcjIyNjQ5ODA0", "avatar_url": "https://avatars1.githubusercontent.com/u/22649804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexanderalang", "html_url": "https://github.com/alexanderalang", "followers_url": "https://api.github.com/users/alexanderalang/followers", "following_url": "https://api.github.com/users/alexanderalang/following{/other_user}", "gists_url": "https://api.github.com/users/alexanderalang/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexanderalang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexanderalang/subscriptions", "organizations_url": "https://api.github.com/users/alexanderalang/orgs", "repos_url": "https://api.github.com/users/alexanderalang/repos", "events_url": "https://api.github.com/users/alexanderalang/events{/privacy}", "received_events_url": "https://api.github.com/users/alexanderalang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T16:42:54Z", "updated_at": "2017-03-22T16:42:54Z", "author_association": "NONE", "body_html": "<p>here is an error producing script, I tried to simplify it a bit</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\n    preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\n    activation = act(preactivate) \n    return activation        \n\ndef maxpool(inputs,padding='VALID'):\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\n\ndef weight_variable(shape,dtype=np.float32,partition_info=None):\n    shape[shape==None] = 1\n    n = np.prod(shape)\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\n    return tf.Variable(w.reshape(shape),trainable=True)\n\n## initializes biases\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial,trainable=True)\n\ndef mean_square_error(a,b):\n    shape = a.get_shape().as_list()\n    shape[shape==None] = 1\n    N = np.prod(shape)\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\n\n\n###  low level api ################################ \ndef ll_model(inputs):\n    \n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\n    \n    W_conv1 = weight_variable([3,3,3,2,16])\n    b_conv1 = bias_variable([16])\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\n\n    print(conv1.get_shape().as_list())\n\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\n    print(pad.get_shape().as_list())\n    \n    maxpool1 = maxpool(pad)\n    print(maxpool1.get_shape().as_list())\n\n    W_conv2 = weight_variable([3,3,3,16,24])\n    b_conv2 = bias_variable([24])\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\n    print(conv2.get_shape().as_list())\n    \n    W_conv3 = weight_variable([3,3,3,24,28])\n    b_conv3 = bias_variable([28])\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\n    print(conv3.get_shape().as_list())\n    \n    W_conv4 = weight_variable([4,4,4,28,34])\n    b_conv4 = bias_variable([34])\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\n    print(conv4.get_shape().as_list())\n    \n    W_conv5 = weight_variable([5,5,5,34,42])\n    b_conv5 = bias_variable([42])\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\n    print(conv5.get_shape().as_list())\n    \n    W_conv6 = weight_variable([5,5,5,42,50])\n    b_conv6 = bias_variable([50])\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\n    print(conv6.get_shape().as_list())\n    \n    W_conv7 = weight_variable([5,5,5,50,50])\n    b_conv7 = bias_variable([50])\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\n    print(conv7.get_shape().as_list())\n    \n    W_conv8 = weight_variable([1,1,1,50,2])\n    b_conv8 = bias_variable([2])\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output')\n    \n    return conv8\n\n\nsess = tf.Session()    \n## placeholders\nx = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\n\n\ny = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\n\nloss = mean_square_error(y,ll_model(x))\n</code></pre>", "body_text": "here is an error producing script, I tried to simplify it a bit\nimport tensorflow as tf\nimport numpy as np\n\ndef conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\n    preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\n    activation = act(preactivate) \n    return activation        \n\ndef maxpool(inputs,padding='VALID'):\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\n\ndef weight_variable(shape,dtype=np.float32,partition_info=None):\n    shape[shape==None] = 1\n    n = np.prod(shape)\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\n    return tf.Variable(w.reshape(shape),trainable=True)\n\n## initializes biases\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial,trainable=True)\n\ndef mean_square_error(a,b):\n    shape = a.get_shape().as_list()\n    shape[shape==None] = 1\n    N = np.prod(shape)\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\n\n\n###  low level api ################################ \ndef ll_model(inputs):\n    \n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\n    \n    W_conv1 = weight_variable([3,3,3,2,16])\n    b_conv1 = bias_variable([16])\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\n\n    print(conv1.get_shape().as_list())\n\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\n    print(pad.get_shape().as_list())\n    \n    maxpool1 = maxpool(pad)\n    print(maxpool1.get_shape().as_list())\n\n    W_conv2 = weight_variable([3,3,3,16,24])\n    b_conv2 = bias_variable([24])\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\n    print(conv2.get_shape().as_list())\n    \n    W_conv3 = weight_variable([3,3,3,24,28])\n    b_conv3 = bias_variable([28])\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\n    print(conv3.get_shape().as_list())\n    \n    W_conv4 = weight_variable([4,4,4,28,34])\n    b_conv4 = bias_variable([34])\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\n    print(conv4.get_shape().as_list())\n    \n    W_conv5 = weight_variable([5,5,5,34,42])\n    b_conv5 = bias_variable([42])\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\n    print(conv5.get_shape().as_list())\n    \n    W_conv6 = weight_variable([5,5,5,42,50])\n    b_conv6 = bias_variable([50])\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\n    print(conv6.get_shape().as_list())\n    \n    W_conv7 = weight_variable([5,5,5,50,50])\n    b_conv7 = bias_variable([50])\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\n    print(conv7.get_shape().as_list())\n    \n    W_conv8 = weight_variable([1,1,1,50,2])\n    b_conv8 = bias_variable([2])\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output')\n    \n    return conv8\n\n\nsess = tf.Session()    \n## placeholders\nx = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\n\n\ny = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\n\nloss = mean_square_error(y,ll_model(x))", "body": "here is an error producing script, I tried to simplify it a bit\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef conv3d(inputs,weights, biases,layer_name,act=tf.nn.relu,padding='VALID'):\r\n    preactivate = tf.nn.conv3d(inputs,weights,strides=[1,1,1,1,1],padding=padding) + biases\r\n    activation = act(preactivate) \r\n    return activation        \r\n\r\ndef maxpool(inputs,padding='VALID'):\r\n    return tf.nn.max_pool3d(inputs,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding=padding)\r\n\r\ndef weight_variable(shape,dtype=np.float32,partition_info=None):\r\n    shape[shape==None] = 1\r\n    n = np.prod(shape)\r\n    w = (np.random.randn(n) * np.sqrt(2./n)).astype(np.float32)\r\n    return tf.Variable(w.reshape(shape),trainable=True)\r\n\r\n## initializes biases\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0.1, shape=shape)\r\n    return tf.Variable(initial,trainable=True)\r\n\r\ndef mean_square_error(a,b):\r\n    shape = a.get_shape().as_list()\r\n    shape[shape==None] = 1\r\n    N = np.prod(shape)\r\n    return tf.reduce_sum(tf.squared_difference(a,b)) / N\r\n\r\n\r\n###  low level api ################################ \r\ndef ll_model(inputs):\r\n    \r\n    input_layer = tf.reshape(inputs,[-1,65,65,65,2])\r\n    \r\n    W_conv1 = weight_variable([3,3,3,2,16])\r\n    b_conv1 = bias_variable([16])\r\n    conv1 = conv3d(input_layer,W_conv1,b_conv1,'conv1')\r\n\r\n    print(conv1.get_shape().as_list())\r\n\r\n    pad = tf.pad(conv1,[[0,0],[1,0],[1,0],[1,0],[0,0]],mode='CONSTANT')\r\n    print(pad.get_shape().as_list())\r\n    \r\n    maxpool1 = maxpool(pad)\r\n    print(maxpool1.get_shape().as_list())\r\n\r\n    W_conv2 = weight_variable([3,3,3,16,24])\r\n    b_conv2 = bias_variable([24])\r\n    conv2 = conv3d(maxpool1,W_conv2, b_conv2,'conv2',padding=\"SAME\")\r\n    print(conv2.get_shape().as_list())\r\n    \r\n    W_conv3 = weight_variable([3,3,3,24,28])\r\n    b_conv3 = bias_variable([28])\r\n    conv3 = conv3d(conv2,W_conv3,b_conv3,'conv3',padding=\"SAME\")\r\n    print(conv3.get_shape().as_list())\r\n    \r\n    W_conv4 = weight_variable([4,4,4,28,34])\r\n    b_conv4 = bias_variable([34])\r\n    conv4 = conv3d(conv3,W_conv4,b_conv4,'conv4')\r\n    print(conv4.get_shape().as_list())\r\n    \r\n    W_conv5 = weight_variable([5,5,5,34,42])\r\n    b_conv5 = bias_variable([42])\r\n    conv5 = conv3d(conv4,W_conv5,b_conv5,'conv5')\r\n    print(conv5.get_shape().as_list())\r\n    \r\n    W_conv6 = weight_variable([5,5,5,42,50])\r\n    b_conv6 = bias_variable([50])\r\n    conv6 = conv3d(conv5,W_conv6,b_conv6,'conv6')\r\n    print(conv6.get_shape().as_list())\r\n    \r\n    W_conv7 = weight_variable([5,5,5,50,50])\r\n    b_conv7 = bias_variable([50])\r\n    conv7 = conv3d(conv6,W_conv7,b_conv7,'conv7')\r\n    print(conv7.get_shape().as_list())\r\n    \r\n    W_conv8 = weight_variable([1,1,1,50,2])\r\n    b_conv8 = bias_variable([2])\r\n    conv8 = conv3d(conv7,W_conv8, b_conv8,'output')\r\n    \r\n    return conv8\r\n\r\n\r\nsess = tf.Session()    \r\n## placeholders\r\nx = tf.placeholder(tf.float32,shape=[None,65,65,65,2],name='features')\r\n\r\n\r\ny = tf.placeholder(tf.float32,shape=[None,17,17,17,2],name='targets')\r\n\r\nloss = mean_square_error(y,ll_model(x))\r\n```"}