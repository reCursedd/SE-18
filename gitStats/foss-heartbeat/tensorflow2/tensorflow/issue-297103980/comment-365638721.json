{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/365638721", "html_url": "https://github.com/tensorflow/tensorflow/issues/17011#issuecomment-365638721", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17011", "id": 365638721, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTYzODcyMQ==", "user": {"login": "voegtlel", "id": 5764745, "node_id": "MDQ6VXNlcjU3NjQ3NDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5764745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/voegtlel", "html_url": "https://github.com/voegtlel", "followers_url": "https://api.github.com/users/voegtlel/followers", "following_url": "https://api.github.com/users/voegtlel/following{/other_user}", "gists_url": "https://api.github.com/users/voegtlel/gists{/gist_id}", "starred_url": "https://api.github.com/users/voegtlel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/voegtlel/subscriptions", "organizations_url": "https://api.github.com/users/voegtlel/orgs", "repos_url": "https://api.github.com/users/voegtlel/repos", "events_url": "https://api.github.com/users/voegtlel/events{/privacy}", "received_events_url": "https://api.github.com/users/voegtlel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T15:17:10Z", "updated_at": "2018-02-14T15:17:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Unfortunately it doesn't. That only replaces the \"finally cropping/padding\" part, but still there are three memory costly operations needed to perform the desired operation (namely <code>tf.pad</code> such that the rotation does not crop parts of the input, then <code>tf.contrib.image.transform</code>, and finally <code>tf.image.resize_image_with_crop_or_pad</code>). Also it is limited, such that you cannot specify the offset but it always uses central cropping/padding. Unfortunately this is a bottleneck for our training, because the padding and cropping seems to take quite long for large inputs (I guess due to memory allocations?).</p>\n<p>By my guess it should not be too complicated to implement parametrizable output size. As far as I checked the source code, the output is generated in <a href=\"https://github.com/tensorflow/tensorflow/blob/1b6453bec58e3c0c020fe654d04ba4fb8dbb20a3/tensorflow/contrib/image/kernels/image_ops.h#L164\">tensorflow/contrib/image/kernels/image_ops.h:164</a>. The problem I see is that it is generated by \"images.generate\", which should be something like \"output-&gt;generate\" (unfortunately I do not know further details on these interfaces). Finally adding allocation by argument to <a href=\"https://github.com/tensorflow/tensorflow/blob/f1f2fff2c149ea3a848ec61b7d3fcd39a6dc3f06/tensorflow/contrib/image/kernels/image_ops.cc#L86\">tensorflow/contrib/image/kernels/image_ops.cc:86</a> should solve the issue? Maybe someone with more insight than me can comment on this.</p>", "body_text": "Unfortunately it doesn't. That only replaces the \"finally cropping/padding\" part, but still there are three memory costly operations needed to perform the desired operation (namely tf.pad such that the rotation does not crop parts of the input, then tf.contrib.image.transform, and finally tf.image.resize_image_with_crop_or_pad). Also it is limited, such that you cannot specify the offset but it always uses central cropping/padding. Unfortunately this is a bottleneck for our training, because the padding and cropping seems to take quite long for large inputs (I guess due to memory allocations?).\nBy my guess it should not be too complicated to implement parametrizable output size. As far as I checked the source code, the output is generated in tensorflow/contrib/image/kernels/image_ops.h:164. The problem I see is that it is generated by \"images.generate\", which should be something like \"output->generate\" (unfortunately I do not know further details on these interfaces). Finally adding allocation by argument to tensorflow/contrib/image/kernels/image_ops.cc:86 should solve the issue? Maybe someone with more insight than me can comment on this.", "body": "Unfortunately it doesn't. That only replaces the \"finally cropping/padding\" part, but still there are three memory costly operations needed to perform the desired operation (namely `tf.pad` such that the rotation does not crop parts of the input, then `tf.contrib.image.transform`, and finally `tf.image.resize_image_with_crop_or_pad`). Also it is limited, such that you cannot specify the offset but it always uses central cropping/padding. Unfortunately this is a bottleneck for our training, because the padding and cropping seems to take quite long for large inputs (I guess due to memory allocations?).\r\n\r\nBy my guess it should not be too complicated to implement parametrizable output size. As far as I checked the source code, the output is generated in [tensorflow/contrib/image/kernels/image_ops.h:164](https://github.com/tensorflow/tensorflow/blob/1b6453bec58e3c0c020fe654d04ba4fb8dbb20a3/tensorflow/contrib/image/kernels/image_ops.h#L164). The problem I see is that it is generated by \"images.generate\", which should be something like \"output->generate\" (unfortunately I do not know further details on these interfaces). Finally adding allocation by argument to [tensorflow/contrib/image/kernels/image_ops.cc:86](https://github.com/tensorflow/tensorflow/blob/f1f2fff2c149ea3a848ec61b7d3fcd39a6dc3f06/tensorflow/contrib/image/kernels/image_ops.cc#L86) should solve the issue? Maybe someone with more insight than me can comment on this."}