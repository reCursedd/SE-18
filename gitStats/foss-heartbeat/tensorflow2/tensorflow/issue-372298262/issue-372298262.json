{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23147", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23147/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23147/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23147/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23147", "id": 372298262, "node_id": "MDU6SXNzdWUzNzIyOTgyNjI=", "number": 23147, "title": "Trying to connect from process to Tensorflow Server, cannot use frozen graph", "user": {"login": "hcl14", "id": 2828322, "node_id": "MDQ6VXNlcjI4MjgzMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2828322?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hcl14", "html_url": "https://github.com/hcl14", "followers_url": "https://api.github.com/users/hcl14/followers", "following_url": "https://api.github.com/users/hcl14/following{/other_user}", "gists_url": "https://api.github.com/users/hcl14/gists{/gist_id}", "starred_url": "https://api.github.com/users/hcl14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hcl14/subscriptions", "organizations_url": "https://api.github.com/users/hcl14/orgs", "repos_url": "https://api.github.com/users/hcl14/repos", "events_url": "https://api.github.com/users/hcl14/events{/privacy}", "received_events_url": "https://api.github.com/users/hcl14/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1105108936, "node_id": "MDU6TGFiZWwxMTA1MTA4OTM2", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:model", "name": "comp:model", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-21T10:00:25Z", "updated_at": "2018-11-12T04:22:47Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi everyone, I have an issue which can possibly be a bug, for which I am trying to find solution for quite some time:</p>\n<p>Stack Overflow:<br>\n<a href=\"https://stackoverflow.com/questions/52700621/tensorflow-server-i-dont-want-to-initialize-global-variables-for-every-session\" rel=\"nofollow\">https://stackoverflow.com/questions/52700621/tensorflow-server-i-dont-want-to-initialize-global-variables-for-every-session</a></p>\n<p>Discuss:<br>\n<a href=\"https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/rARPP1_ilNA\" rel=\"nofollow\">https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/rARPP1_ilNA</a></p>\n<p>My story in short is that I create processes dynamically in Python and do model predictions using a session for Tensorflow Server <code>tf.train.Server</code>. Graph is saved in global scope, as I hope that default python 'fork' mode will not create any overhead as long as data in RAM is not changed (\"copy-on-change\" policy). Anyway, it's too long and expensive for me to reload model for each new process. Perhaps there might be a more efficient way to define model on server side, but I don't know it.</p>\n<p>The problem is that somewhy I need to run initialization of global variables (<code>sess.run(tf.global_variables_initializer())</code>) each time I create new process and open new session. I tried to do dummy sun of the model before locking graph so that all the variables must be initialized, but no success - I still get the uninitialized variable error. Can anyone help me with that?</p>\n<p>I have a small reproducible example of the problem compatible with Tensorflow 1.11:</p>\n<p><a href=\"https://github.com/hcl14/Tensorflow-server-launched-from-child-process\">https://github.com/hcl14/Tensorflow-server-launched-from-child-process</a></p>\n<p>The places in the code are marked with <code>\"PROBLEM\"</code> comment.</p>\n<p>Also, maybe I am doing everything wrong and there is a better way to quickly do model predictions from dynamically created processes?</p>", "body_text": "Hi everyone, I have an issue which can possibly be a bug, for which I am trying to find solution for quite some time:\nStack Overflow:\nhttps://stackoverflow.com/questions/52700621/tensorflow-server-i-dont-want-to-initialize-global-variables-for-every-session\nDiscuss:\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/rARPP1_ilNA\nMy story in short is that I create processes dynamically in Python and do model predictions using a session for Tensorflow Server tf.train.Server. Graph is saved in global scope, as I hope that default python 'fork' mode will not create any overhead as long as data in RAM is not changed (\"copy-on-change\" policy). Anyway, it's too long and expensive for me to reload model for each new process. Perhaps there might be a more efficient way to define model on server side, but I don't know it.\nThe problem is that somewhy I need to run initialization of global variables (sess.run(tf.global_variables_initializer())) each time I create new process and open new session. I tried to do dummy sun of the model before locking graph so that all the variables must be initialized, but no success - I still get the uninitialized variable error. Can anyone help me with that?\nI have a small reproducible example of the problem compatible with Tensorflow 1.11:\nhttps://github.com/hcl14/Tensorflow-server-launched-from-child-process\nThe places in the code are marked with \"PROBLEM\" comment.\nAlso, maybe I am doing everything wrong and there is a better way to quickly do model predictions from dynamically created processes?", "body": "Hi everyone, I have an issue which can possibly be a bug, for which I am trying to find solution for quite some time:\r\n\r\nStack Overflow:\r\nhttps://stackoverflow.com/questions/52700621/tensorflow-server-i-dont-want-to-initialize-global-variables-for-every-session\r\n\r\nDiscuss:\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/rARPP1_ilNA\r\n\r\nMy story in short is that I create processes dynamically in Python and do model predictions using a session for Tensorflow Server `tf.train.Server`. Graph is saved in global scope, as I hope that default python 'fork' mode will not create any overhead as long as data in RAM is not changed (\"copy-on-change\" policy). Anyway, it's too long and expensive for me to reload model for each new process. Perhaps there might be a more efficient way to define model on server side, but I don't know it.\r\n\r\nThe problem is that somewhy I need to run initialization of global variables (`sess.run(tf.global_variables_initializer())`) each time I create new process and open new session. I tried to do dummy sun of the model before locking graph so that all the variables must be initialized, but no success - I still get the uninitialized variable error. Can anyone help me with that?\r\n\r\nI have a small reproducible example of the problem compatible with Tensorflow 1.11:\r\n\r\nhttps://github.com/hcl14/Tensorflow-server-launched-from-child-process\r\n\r\nThe places in the code are marked with `\"PROBLEM\"` comment.\r\n\r\nAlso, maybe I am doing everything wrong and there is a better way to quickly do model predictions from dynamically created processes?\r\n"}