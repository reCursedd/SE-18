{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/307677775", "html_url": "https://github.com/tensorflow/tensorflow/issues/10581#issuecomment-307677775", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10581", "id": 307677775, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzY3Nzc3NQ==", "user": {"login": "JcmeLs", "id": 12932339, "node_id": "MDQ6VXNlcjEyOTMyMzM5", "avatar_url": "https://avatars2.githubusercontent.com/u/12932339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JcmeLs", "html_url": "https://github.com/JcmeLs", "followers_url": "https://api.github.com/users/JcmeLs/followers", "following_url": "https://api.github.com/users/JcmeLs/following{/other_user}", "gists_url": "https://api.github.com/users/JcmeLs/gists{/gist_id}", "starred_url": "https://api.github.com/users/JcmeLs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JcmeLs/subscriptions", "organizations_url": "https://api.github.com/users/JcmeLs/orgs", "repos_url": "https://api.github.com/users/JcmeLs/repos", "events_url": "https://api.github.com/users/JcmeLs/events{/privacy}", "received_events_url": "https://api.github.com/users/JcmeLs/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-12T02:39:38Z", "updated_at": "2017-06-12T02:39:38Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16437156\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Androbin\">@Androbin</a>  I try.But it have a error.<br>\nlog:</p>\n<pre><code>ZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph =/Users/liba/Desktop/OptimizeCTNModel.pb --out_graph =/Users/liba/DesktoRouddndedOptimizeCTodel.pb  --inputs = 'inputs/X' --outputs = 'output/outputs' --transforms = 'strip_unused_nodes\uff08type = float\uff0cshape =\u201c1,256,256,1\u201d\uff09fold_constants\uff08ignore_errors = true) fold_batch_norms fold_old_batch_norms round_weights\uff08num_steps = 256\uff09'\n2017-06-12 10:36:01.153946: E tensorflow/tools/graph_transforms/transform_graph.cc:164] Unknown argument --in_graph.\nusage: bazel-bin/tensorflow/tools/graph_transforms/transform_graph\nFlags:\n\t--in_graph=\"\"                    \tstring\tinput graph file name\n\t--out_graph=\"\"                   \tstring\toutput graph file name\n\t--inputs=\"\"                      \tstring\tinputs\n\t--outputs=\"\"                     \tstring\toutputs\n\t--transforms=\"\"                  \tstring\tlist of transforms\n\t--output_as_text=false           \tbool\twhether to write the graph in text protobuf format\n\nTransforms are:\nadd_default_attributes\nbackport_concatv2\nbackport_tensor_array_v3\nfold_batch_norms\nfold_constants\nfold_old_batch_norms\nfreeze_requantization_ranges\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\ninsert_logging\nmerge_duplicate_nodes\nobfuscate_names\nquantize_nodes\nquantize_weights\nremove_attribute\nremove_device\nremove_nodes\nrename_attribute\nrename_op\nrewrite_quantized_stripped_model_for_hexagon\nround_weights\nset_device\nsort_by_execution_order\nsparsify_gather\nstrip_unused_nodes\n</code></pre>", "body_text": "@Androbin  I try.But it have a error.\nlog:\nZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph =/Users/liba/Desktop/OptimizeCTNModel.pb --out_graph =/Users/liba/DesktoRouddndedOptimizeCTodel.pb  --inputs = 'inputs/X' --outputs = 'output/outputs' --transforms = 'strip_unused_nodes\uff08type = float\uff0cshape =\u201c1,256,256,1\u201d\uff09fold_constants\uff08ignore_errors = true) fold_batch_norms fold_old_batch_norms round_weights\uff08num_steps = 256\uff09'\n2017-06-12 10:36:01.153946: E tensorflow/tools/graph_transforms/transform_graph.cc:164] Unknown argument --in_graph.\nusage: bazel-bin/tensorflow/tools/graph_transforms/transform_graph\nFlags:\n\t--in_graph=\"\"                    \tstring\tinput graph file name\n\t--out_graph=\"\"                   \tstring\toutput graph file name\n\t--inputs=\"\"                      \tstring\tinputs\n\t--outputs=\"\"                     \tstring\toutputs\n\t--transforms=\"\"                  \tstring\tlist of transforms\n\t--output_as_text=false           \tbool\twhether to write the graph in text protobuf format\n\nTransforms are:\nadd_default_attributes\nbackport_concatv2\nbackport_tensor_array_v3\nfold_batch_norms\nfold_constants\nfold_old_batch_norms\nfreeze_requantization_ranges\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\ninsert_logging\nmerge_duplicate_nodes\nobfuscate_names\nquantize_nodes\nquantize_weights\nremove_attribute\nremove_device\nremove_nodes\nrename_attribute\nrename_op\nrewrite_quantized_stripped_model_for_hexagon\nround_weights\nset_device\nsort_by_execution_order\nsparsify_gather\nstrip_unused_nodes", "body": "@Androbin  I try.But it have a error.\r\nlog:\r\n``` \r\nZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph =/Users/liba/Desktop/OptimizeCTNModel.pb --out_graph =/Users/liba/DesktoRouddndedOptimizeCTodel.pb  --inputs = 'inputs/X' --outputs = 'output/outputs' --transforms = 'strip_unused_nodes\uff08type = float\uff0cshape =\u201c1,256,256,1\u201d\uff09fold_constants\uff08ignore_errors = true) fold_batch_norms fold_old_batch_norms round_weights\uff08num_steps = 256\uff09'\r\n2017-06-12 10:36:01.153946: E tensorflow/tools/graph_transforms/transform_graph.cc:164] Unknown argument --in_graph.\r\nusage: bazel-bin/tensorflow/tools/graph_transforms/transform_graph\r\nFlags:\r\n\t--in_graph=\"\"                    \tstring\tinput graph file name\r\n\t--out_graph=\"\"                   \tstring\toutput graph file name\r\n\t--inputs=\"\"                      \tstring\tinputs\r\n\t--outputs=\"\"                     \tstring\toutputs\r\n\t--transforms=\"\"                  \tstring\tlist of transforms\r\n\t--output_as_text=false           \tbool\twhether to write the graph in text protobuf format\r\n\r\nTransforms are:\r\nadd_default_attributes\r\nbackport_concatv2\r\nbackport_tensor_array_v3\r\nfold_batch_norms\r\nfold_constants\r\nfold_old_batch_norms\r\nfreeze_requantization_ranges\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\ninsert_logging\r\nmerge_duplicate_nodes\r\nobfuscate_names\r\nquantize_nodes\r\nquantize_weights\r\nremove_attribute\r\nremove_device\r\nremove_nodes\r\nrename_attribute\r\nrename_op\r\nrewrite_quantized_stripped_model_for_hexagon\r\nround_weights\r\nset_device\r\nsort_by_execution_order\r\nsparsify_gather\r\nstrip_unused_nodes\r\n```"}