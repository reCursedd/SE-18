{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411769532", "html_url": "https://github.com/tensorflow/tensorflow/issues/21444#issuecomment-411769532", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21444", "id": 411769532, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTc2OTUzMg==", "user": {"login": "iliTheFallen", "id": 8805234, "node_id": "MDQ6VXNlcjg4MDUyMzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8805234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iliTheFallen", "html_url": "https://github.com/iliTheFallen", "followers_url": "https://api.github.com/users/iliTheFallen/followers", "following_url": "https://api.github.com/users/iliTheFallen/following{/other_user}", "gists_url": "https://api.github.com/users/iliTheFallen/gists{/gist_id}", "starred_url": "https://api.github.com/users/iliTheFallen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iliTheFallen/subscriptions", "organizations_url": "https://api.github.com/users/iliTheFallen/orgs", "repos_url": "https://api.github.com/users/iliTheFallen/repos", "events_url": "https://api.github.com/users/iliTheFallen/events{/privacy}", "received_events_url": "https://api.github.com/users/iliTheFallen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-09T14:05:24Z", "updated_at": "2018-08-09T14:09:34Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1112263\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/facaiy\">@facaiy</a> It is absolutely weird... Code is simple:</p>\n<pre><code>\ndef model_fn(features, labels, mode):\n    \n    loss = tfsi_model(features)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op, grads, saver = minimize(loss)\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\n        chkpt_hook = tf.train.CheckpointSaverHook(\n            FLAGS.model_dir, \n            save_steps=FLAGS.saving_ckpt_freq, \n            saver=saver\n        )\n        summ_hook = tf.train.SummarySaverHook(\n            save_steps=FLAGS.saving_summ_freq,\n            output_dir=FLAGS.log_directory, \n            summary_writer=writer,\n            summary_op=merged\n        )\n        hooks = [chkpt_hook, summ_hook]\n        return tf.estimator.EstimatorSpec(mode, \n                                          loss=loss, \n                                          train_op=train_op, \n                                          training_chief_hooks=hooks)\n    else:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n\nconfig = tf.estimator.RunConfig(\n    model_dir=\"./output\",\n    save_summary_steps=FLAGS.saving_summ_freq, \n    save_checkpoints_steps=FLAGS.saving_ckpt_freq,\n    keep_checkpoint_max=3,\n    train_distribute=tf.contrib.distribute.MirroredStrategy()\n)\nclassifier = tf.estimator.Estimator(\n    model_fn, \n    config=config\n)\ntrain_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\nvalid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\ntf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\n</code></pre>\n<p>I think you don't need the rest of the code for it is irrelevant to the problem. Note that... I'm using Python3. Perhaps the behavior attributed to \"isinstance(...)\" had changed since Python2.x.</p>", "body_text": "@facaiy It is absolutely weird... Code is simple:\n\ndef model_fn(features, labels, mode):\n    \n    loss = tfsi_model(features)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op, grads, saver = minimize(loss)\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\n        chkpt_hook = tf.train.CheckpointSaverHook(\n            FLAGS.model_dir, \n            save_steps=FLAGS.saving_ckpt_freq, \n            saver=saver\n        )\n        summ_hook = tf.train.SummarySaverHook(\n            save_steps=FLAGS.saving_summ_freq,\n            output_dir=FLAGS.log_directory, \n            summary_writer=writer,\n            summary_op=merged\n        )\n        hooks = [chkpt_hook, summ_hook]\n        return tf.estimator.EstimatorSpec(mode, \n                                          loss=loss, \n                                          train_op=train_op, \n                                          training_chief_hooks=hooks)\n    else:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n\nconfig = tf.estimator.RunConfig(\n    model_dir=\"./output\",\n    save_summary_steps=FLAGS.saving_summ_freq, \n    save_checkpoints_steps=FLAGS.saving_ckpt_freq,\n    keep_checkpoint_max=3,\n    train_distribute=tf.contrib.distribute.MirroredStrategy()\n)\nclassifier = tf.estimator.Estimator(\n    model_fn, \n    config=config\n)\ntrain_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\nvalid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\ntf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\n\nI think you don't need the rest of the code for it is irrelevant to the problem. Note that... I'm using Python3. Perhaps the behavior attributed to \"isinstance(...)\" had changed since Python2.x.", "body": "@facaiy It is absolutely weird... Code is simple:\r\n```\r\n\r\ndef model_fn(features, labels, mode):\r\n    \r\n    loss = tfsi_model(features)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        train_op, grads, saver = minimize(loss)\r\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\r\n        chkpt_hook = tf.train.CheckpointSaverHook(\r\n            FLAGS.model_dir, \r\n            save_steps=FLAGS.saving_ckpt_freq, \r\n            saver=saver\r\n        )\r\n        summ_hook = tf.train.SummarySaverHook(\r\n            save_steps=FLAGS.saving_summ_freq,\r\n            output_dir=FLAGS.log_directory, \r\n            summary_writer=writer,\r\n            summary_op=merged\r\n        )\r\n        hooks = [chkpt_hook, summ_hook]\r\n        return tf.estimator.EstimatorSpec(mode, \r\n                                          loss=loss, \r\n                                          train_op=train_op, \r\n                                          training_chief_hooks=hooks)\r\n    else:\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n\r\nconfig = tf.estimator.RunConfig(\r\n    model_dir=\"./output\",\r\n    save_summary_steps=FLAGS.saving_summ_freq, \r\n    save_checkpoints_steps=FLAGS.saving_ckpt_freq,\r\n    keep_checkpoint_max=3,\r\n    train_distribute=tf.contrib.distribute.MirroredStrategy()\r\n)\r\nclassifier = tf.estimator.Estimator(\r\n    model_fn, \r\n    config=config\r\n)\r\ntrain_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\r\nvalid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\r\ntf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\r\n```\r\n\r\nI think you don't need the rest of the code for it is irrelevant to the problem. Note that... I'm using Python3. Perhaps the behavior attributed to \"isinstance(...)\" had changed since Python2.x."}