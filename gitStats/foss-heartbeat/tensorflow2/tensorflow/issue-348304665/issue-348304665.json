{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21444", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21444/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21444/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21444/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21444", "id": 348304665, "node_id": "MDU6SXNzdWUzNDgzMDQ2NjU=", "number": 21444, "title": "Estimator API -- Incorrect Super-Type Check for Hooks", "user": {"login": "iliTheFallen", "id": 8805234, "node_id": "MDQ6VXNlcjg4MDUyMzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8805234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iliTheFallen", "html_url": "https://github.com/iliTheFallen", "followers_url": "https://api.github.com/users/iliTheFallen/followers", "following_url": "https://api.github.com/users/iliTheFallen/following{/other_user}", "gists_url": "https://api.github.com/users/iliTheFallen/gists{/gist_id}", "starred_url": "https://api.github.com/users/iliTheFallen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iliTheFallen/subscriptions", "organizations_url": "https://api.github.com/users/iliTheFallen/orgs", "repos_url": "https://api.github.com/users/iliTheFallen/repos", "events_url": "https://api.github.com/users/iliTheFallen/events{/privacy}", "received_events_url": "https://api.github.com/users/iliTheFallen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2018-08-07T12:44:04Z", "updated_at": "2018-08-31T07:05:07Z", "closed_at": "2018-08-31T02:11:49Z", "author_association": "NONE", "body_html": "<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: 16.04.4 LTS (Xenial Xerus)</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: From source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>: 7.1.4.18</li>\n<li><strong>GPU model and memory</strong>: Quadro K620 and Tesla K40c -- 2GB and 11.5GB respectively.</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>def model_fn(features, labels, mode):\n    \n    loss = tfsi_model(features)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op, grads, saver = minimize(loss)\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\n        chkpt_hook = tf.train.CheckpointSaverHook(\n            FLAGS.model_dir, \n            save_steps=FLAGS.saving_ckpt_freq, \n            saver=saver\n        )\n        summ_hook = tf.train.SummarySaverHook(\n            save_steps=FLAGS.saving_summ_freq,\n            output_dir=FLAGS.log_directory, \n            summary_writer=writer,\n            summary_op=merged\n        )\n        hooks = [chkpt_hook, summ_hook]\n        return tf.estimator.EstimatorSpec(mode, \n                                          loss=loss, \n                                          train_op=train_op, \n                                          training_chief_hooks=hooks)\n    else:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n</code></pre>\n<p>Hello Tensorflow Devs,<br>\nI'm sorry to report too many failures within Estimator API just in couple of days; but it seems it is really buggy, guys. When it checks out for the (super)type of session hooks, it looks for <strong>tensorflow.python.training.session_run_hook.SessionRunHook</strong>; but \"isinstance\" method fails to do so for it assumes that their type is <strong>tensorflow.python.training.basic_session_run_hooks</strong> though it is not. Would you mind replacing it with a proper validation method, please?</p>\n<pre><code>\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_keep_checkpoint_max': 3, '_save_checkpoints_steps': 15, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 1, '_train_distribute': &lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f8d98aaf780&gt;, '_tf_random_seed': None, '_task_id': 0, '_device_fn': None, '_model_dir': './output', '_save_summary_steps': 5, '_session_config': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8d98aafcf8&gt;, '_log_step_count_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_is_chief': True, '_task_type': 'worker', '_master': ''}\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:batch_all_reduce invoked for batches size = 66 with algorithm = nccl and num_packs = 1\nPreparing Tensor Summaries...\nAdding summary for training loss\nINFO:tensorflow:Create CheckpointSaverHook.\nType of hook:  &lt;class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'&gt;\nINFO:tensorflow:Done calling model_fn.\nPreparing Tensor Summaries...\nAdding summary for training loss\nINFO:tensorflow:Create CheckpointSaverHook.\nType of hook:  &lt;class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'&gt;\nINFO:tensorflow:Done calling model_fn.\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-10-cc8d515a6342&gt; in &lt;module&gt;()\n     12 train_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\n     13 valid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\n---&gt; 14 tf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\n    445         '(with task id 0).  Given task id {}'.format(config.task_id))\n    446 \n--&gt; 447   return executor.run()\n    448 \n    449 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run(self)\n    529         config.task_type != run_config_lib.TaskType.EVALUATOR):\n    530       logging.info('Running training and evaluation locally (non-distributed).')\n--&gt; 531       return self.run_local()\n    532 \n    533     # Distributed case.\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run_local(self)\n    667           input_fn=self._train_spec.input_fn,\n    668           max_steps=self._train_spec.max_steps,\n--&gt; 669           hooks=train_hooks)\n    670 \n    671       if not self._continuous_eval_listener.before_eval():\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364 \n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1115   def _train_model(self, input_fn, hooks, saving_listeners):\n   1116     if self._distribution:\n-&gt; 1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1118     else:\n   1119       return self._train_model_default(input_fn, hooks, saving_listeners)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\n   1248             training_hooks=training_hooks,\n   1249             training_chief_hooks=training_chief_hooks,\n-&gt; 1250             scaffold=scaffold)\n   1251         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1252                                                hooks, global_step_read_tensor,\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/model_fn.py in __new__(cls, mode, predictions, loss, train_op, eval_metric_ops, export_outputs, training_chief_hooks, training_hooks, scaffold, evaluation_hooks, prediction_hooks)\n    304         raise TypeError(\n    305             'All hooks must be SessionRunHook instances, given: {}'.format(\n--&gt; 306                 hook))\n    307 \n    308     scaffold = scaffold or monitored_session.Scaffold()\n\nTypeError: All hooks must be SessionRunHook instances, given: PerDevice:{'/job:localhost/replica:0/task:0/device:GPU:1': &lt;tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8ce4173ac8&gt;, '/job:localhost/replica:0/task:0/device:GPU:0': &lt;tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8d140390b8&gt;}\n</code></pre>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.4 LTS (Xenial Xerus)\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): From source\nTensorFlow version (use command below): 1.9.0\nPython version: 3.5\nBazel version (if compiling from source): 0.11.0\nGCC/Compiler version (if compiling from source): (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCUDA/cuDNN version: 7.1.4.18\nGPU model and memory: Quadro K620 and Tesla K40c -- 2GB and 11.5GB respectively.\nExact command to reproduce:\n\ndef model_fn(features, labels, mode):\n    \n    loss = tfsi_model(features)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op, grads, saver = minimize(loss)\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\n        chkpt_hook = tf.train.CheckpointSaverHook(\n            FLAGS.model_dir, \n            save_steps=FLAGS.saving_ckpt_freq, \n            saver=saver\n        )\n        summ_hook = tf.train.SummarySaverHook(\n            save_steps=FLAGS.saving_summ_freq,\n            output_dir=FLAGS.log_directory, \n            summary_writer=writer,\n            summary_op=merged\n        )\n        hooks = [chkpt_hook, summ_hook]\n        return tf.estimator.EstimatorSpec(mode, \n                                          loss=loss, \n                                          train_op=train_op, \n                                          training_chief_hooks=hooks)\n    else:\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\n\nHello Tensorflow Devs,\nI'm sorry to report too many failures within Estimator API just in couple of days; but it seems it is really buggy, guys. When it checks out for the (super)type of session hooks, it looks for tensorflow.python.training.session_run_hook.SessionRunHook; but \"isinstance\" method fails to do so for it assumes that their type is tensorflow.python.training.basic_session_run_hooks though it is not. Would you mind replacing it with a proper validation method, please?\n\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_keep_checkpoint_max': 3, '_save_checkpoints_steps': 15, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 1, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f8d98aaf780>, '_tf_random_seed': None, '_task_id': 0, '_device_fn': None, '_model_dir': './output', '_save_summary_steps': 5, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8d98aafcf8>, '_log_step_count_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_is_chief': True, '_task_type': 'worker', '_master': ''}\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:batch_all_reduce invoked for batches size = 66 with algorithm = nccl and num_packs = 1\nPreparing Tensor Summaries...\nAdding summary for training loss\nINFO:tensorflow:Create CheckpointSaverHook.\nType of hook:  <class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'>\nINFO:tensorflow:Done calling model_fn.\nPreparing Tensor Summaries...\nAdding summary for training loss\nINFO:tensorflow:Create CheckpointSaverHook.\nType of hook:  <class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'>\nINFO:tensorflow:Done calling model_fn.\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-10-cc8d515a6342> in <module>()\n     12 train_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\n     13 valid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\n---> 14 tf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\n    445         '(with task id 0).  Given task id {}'.format(config.task_id))\n    446 \n--> 447   return executor.run()\n    448 \n    449 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run(self)\n    529         config.task_type != run_config_lib.TaskType.EVALUATOR):\n    530       logging.info('Running training and evaluation locally (non-distributed).')\n--> 531       return self.run_local()\n    532 \n    533     # Distributed case.\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run_local(self)\n    667           input_fn=self._train_spec.input_fn,\n    668           max_steps=self._train_spec.max_steps,\n--> 669           hooks=train_hooks)\n    670 \n    671       if not self._continuous_eval_listener.before_eval():\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    364 \n    365       saving_listeners = _check_listeners_type(saving_listeners)\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\n    367       logging.info('Loss for final step: %s.', loss)\n    368       return self\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1115   def _train_model(self, input_fn, hooks, saving_listeners):\n   1116     if self._distribution:\n-> 1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1118     else:\n   1119       return self._train_model_default(input_fn, hooks, saving_listeners)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\n   1248             training_hooks=training_hooks,\n   1249             training_chief_hooks=training_chief_hooks,\n-> 1250             scaffold=scaffold)\n   1251         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1252                                                hooks, global_step_read_tensor,\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/model_fn.py in __new__(cls, mode, predictions, loss, train_op, eval_metric_ops, export_outputs, training_chief_hooks, training_hooks, scaffold, evaluation_hooks, prediction_hooks)\n    304         raise TypeError(\n    305             'All hooks must be SessionRunHook instances, given: {}'.format(\n--> 306                 hook))\n    307 \n    308     scaffold = scaffold or monitored_session.Scaffold()\n\nTypeError: All hooks must be SessionRunHook instances, given: PerDevice:{'/job:localhost/replica:0/task:0/device:GPU:1': <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8ce4173ac8>, '/job:localhost/replica:0/task:0/device:GPU:0': <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8d140390b8>}", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.4 LTS (Xenial Xerus)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: From source\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 7.1.4.18\r\n- **GPU model and memory**: Quadro K620 and Tesla K40c -- 2GB and 11.5GB respectively.\r\n- **Exact command to reproduce**:\r\n```\r\ndef model_fn(features, labels, mode):\r\n    \r\n    loss = tfsi_model(features)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        train_op, grads, saver = minimize(loss)\r\n        writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\r\n        chkpt_hook = tf.train.CheckpointSaverHook(\r\n            FLAGS.model_dir, \r\n            save_steps=FLAGS.saving_ckpt_freq, \r\n            saver=saver\r\n        )\r\n        summ_hook = tf.train.SummarySaverHook(\r\n            save_steps=FLAGS.saving_summ_freq,\r\n            output_dir=FLAGS.log_directory, \r\n            summary_writer=writer,\r\n            summary_op=merged\r\n        )\r\n        hooks = [chkpt_hook, summ_hook]\r\n        return tf.estimator.EstimatorSpec(mode, \r\n                                          loss=loss, \r\n                                          train_op=train_op, \r\n                                          training_chief_hooks=hooks)\r\n    else:\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n```\r\n\r\nHello Tensorflow Devs,\r\nI'm sorry to report too many failures within Estimator API just in couple of days; but it seems it is really buggy, guys. When it checks out for the (super)type of session hooks, it looks for **tensorflow.python.training.session_run_hook.SessionRunHook**; but \"isinstance\" method fails to do so for it assumes that their type is **tensorflow.python.training.basic_session_run_hooks** though it is not. Would you mind replacing it with a proper validation method, please?\r\n\r\n```\r\n\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_keep_checkpoint_max': 3, '_save_checkpoints_steps': 15, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 1, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f8d98aaf780>, '_tf_random_seed': None, '_task_id': 0, '_device_fn': None, '_model_dir': './output', '_save_summary_steps': 5, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8d98aafcf8>, '_log_step_count_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_is_chief': True, '_task_type': 'worker', '_master': ''}\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Configured nccl all-reduce.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 66 with algorithm = nccl and num_packs = 1\r\nPreparing Tensor Summaries...\r\nAdding summary for training loss\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nType of hook:  <class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'>\r\nINFO:tensorflow:Done calling model_fn.\r\nPreparing Tensor Summaries...\r\nAdding summary for training loss\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nType of hook:  <class 'tensorflow.python.training.basic_session_run_hooks.SummarySaverHook'>\r\nINFO:tensorflow:Done calling model_fn.\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-10-cc8d515a6342> in <module>()\r\n     12 train_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\r\n     13 valid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\r\n---> 14 tf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\r\n    445         '(with task id 0).  Given task id {}'.format(config.task_id))\r\n    446 \r\n--> 447   return executor.run()\r\n    448 \r\n    449 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run(self)\r\n    529         config.task_type != run_config_lib.TaskType.EVALUATOR):\r\n    530       logging.info('Running training and evaluation locally (non-distributed).')\r\n--> 531       return self.run_local()\r\n    532 \r\n    533     # Distributed case.\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py in run_local(self)\r\n    667           input_fn=self._train_spec.input_fn,\r\n    668           max_steps=self._train_spec.max_steps,\r\n--> 669           hooks=train_hooks)\r\n    670 \r\n    671       if not self._continuous_eval_listener.before_eval():\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    364 \r\n    365       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    367       logging.info('Loss for final step: %s.', loss)\r\n    368       return self\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1115   def _train_model(self, input_fn, hooks, saving_listeners):\r\n   1116     if self._distribution:\r\n-> 1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1118     else:\r\n   1119       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\r\n   1248             training_hooks=training_hooks,\r\n   1249             training_chief_hooks=training_chief_hooks,\r\n-> 1250             scaffold=scaffold)\r\n   1251         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n   1252                                                hooks, global_step_read_tensor,\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/model_fn.py in __new__(cls, mode, predictions, loss, train_op, eval_metric_ops, export_outputs, training_chief_hooks, training_hooks, scaffold, evaluation_hooks, prediction_hooks)\r\n    304         raise TypeError(\r\n    305             'All hooks must be SessionRunHook instances, given: {}'.format(\r\n--> 306                 hook))\r\n    307 \r\n    308     scaffold = scaffold or monitored_session.Scaffold()\r\n\r\nTypeError: All hooks must be SessionRunHook instances, given: PerDevice:{'/job:localhost/replica:0/task:0/device:GPU:1': <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8ce4173ac8>, '/job:localhost/replica:0/task:0/device:GPU:0': <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f8d140390b8>}\r\n```"}