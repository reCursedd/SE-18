{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245892647", "html_url": "https://github.com/tensorflow/tensorflow/issues/4281#issuecomment-245892647", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4281", "id": 245892647, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTg5MjY0Nw==", "user": {"login": "marekmodry", "id": 8523511, "node_id": "MDQ6VXNlcjg1MjM1MTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/8523511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marekmodry", "html_url": "https://github.com/marekmodry", "followers_url": "https://api.github.com/users/marekmodry/followers", "following_url": "https://api.github.com/users/marekmodry/following{/other_user}", "gists_url": "https://api.github.com/users/marekmodry/gists{/gist_id}", "starred_url": "https://api.github.com/users/marekmodry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marekmodry/subscriptions", "organizations_url": "https://api.github.com/users/marekmodry/orgs", "repos_url": "https://api.github.com/users/marekmodry/repos", "events_url": "https://api.github.com/users/marekmodry/events{/privacy}", "received_events_url": "https://api.github.com/users/marekmodry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-09T11:54:16Z", "updated_at": "2016-09-09T11:54:16Z", "author_association": "NONE", "body_html": "<p>I managed to fix the problem. However, I believe that there has to be a better way how to do it.</p>\n<p>I changed the following rows of the <code>decode</code> method in <code>translate.py</code>.</p>\n<pre><code># model.batch_size = 1 -&gt; Changed the size of the batch to 64 (expected size)\nmodel.batch_size = 64\n\n# ...\n\n# encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n#         {bucket_id: [(token_ids, [])]}, bucket_id)  -&gt; Extended the data list to 64 items\nencoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]*64}, bucket_id)\n\n# ...\n\n# outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits] -&gt; Get only the first batch from the output\noutputs = [int(np.argmax(logit[:1,:], axis=1)) for logit in output_logits] \n</code></pre>\n<p>As I have mentioned, it is not effective and I believe there is a better way how to fix the problem. My changes work as a hot fix, though.</p>\n<p>Thanks for any additional advices, tips or ideas</p>", "body_text": "I managed to fix the problem. However, I believe that there has to be a better way how to do it.\nI changed the following rows of the decode method in translate.py.\n# model.batch_size = 1 -> Changed the size of the batch to 64 (expected size)\nmodel.batch_size = 64\n\n# ...\n\n# encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n#         {bucket_id: [(token_ids, [])]}, bucket_id)  -> Extended the data list to 64 items\nencoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]*64}, bucket_id)\n\n# ...\n\n# outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits] -> Get only the first batch from the output\noutputs = [int(np.argmax(logit[:1,:], axis=1)) for logit in output_logits] \n\nAs I have mentioned, it is not effective and I believe there is a better way how to fix the problem. My changes work as a hot fix, though.\nThanks for any additional advices, tips or ideas", "body": "I managed to fix the problem. However, I believe that there has to be a better way how to do it.\n\nI changed the following rows of the `decode` method in `translate.py`.\n\n```\n# model.batch_size = 1 -> Changed the size of the batch to 64 (expected size)\nmodel.batch_size = 64\n\n# ...\n\n# encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n#         {bucket_id: [(token_ids, [])]}, bucket_id)  -> Extended the data list to 64 items\nencoder_inputs, decoder_inputs, target_weights = model.get_batch(\n          {bucket_id: [(token_ids, [])]*64}, bucket_id)\n\n# ...\n\n# outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits] -> Get only the first batch from the output\noutputs = [int(np.argmax(logit[:1,:], axis=1)) for logit in output_logits] \n```\n\nAs I have mentioned, it is not effective and I believe there is a better way how to fix the problem. My changes work as a hot fix, though.\n\nThanks for any additional advices, tips or ideas\n"}