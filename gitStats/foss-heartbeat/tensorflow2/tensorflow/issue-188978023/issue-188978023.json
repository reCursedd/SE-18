{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5584", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5584/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5584/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5584/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5584", "id": 188978023, "node_id": "MDU6SXNzdWUxODg5NzgwMjM=", "number": 5584, "title": "Who can help me about my cuda-convnet2 reproduction in low accuracy", "user": {"login": "SunAriesCN", "id": 17171866, "node_id": "MDQ6VXNlcjE3MTcxODY2", "avatar_url": "https://avatars3.githubusercontent.com/u/17171866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SunAriesCN", "html_url": "https://github.com/SunAriesCN", "followers_url": "https://api.github.com/users/SunAriesCN/followers", "following_url": "https://api.github.com/users/SunAriesCN/following{/other_user}", "gists_url": "https://api.github.com/users/SunAriesCN/gists{/gist_id}", "starred_url": "https://api.github.com/users/SunAriesCN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SunAriesCN/subscriptions", "organizations_url": "https://api.github.com/users/SunAriesCN/orgs", "repos_url": "https://api.github.com/users/SunAriesCN/repos", "events_url": "https://api.github.com/users/SunAriesCN/events{/privacy}", "received_events_url": "https://api.github.com/users/SunAriesCN/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-11-13T16:06:12Z", "updated_at": "2016-11-14T16:43:17Z", "closed_at": "2016-11-14T16:43:17Z", "author_association": "NONE", "body_html": "<p>I followed the tutorials of cnn and  tried the<a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html#convolutional-neural-networks\" rel=\"nofollow\"> exercise</a> about reproducing  cifar10 model in<a href=\"https://github.com/akrizhevsky/cuda-convnet2\"> cuda-convnet2.</a><br>\nRecently, I thought I had worked it out, with implementing the local unshared layer by extract_image_patch function and batch_matmul function. <a href=\"https://github.com/SunAriesCN/tensorflow_learning/blob/master/cifar10/exercise/ex2/cifar10_ex2_cuda_convnet.py\">Here is my code of the cifar10.py</a> However, I found that the trained model is useless, because its accuracy is just 0.101, too low, for evaluation as below:<br>\n<code>precision @ 1 = 0.101</code><br>\nMy inference() function just like this:</p>\n<pre><code>def inference(images):\n  \"\"\"Build the CIFAR-10 model.\n  Args:\n    images: Images returned from distorted_inputs() or inputs().\n  Returns:\n    Logits.\n  \"\"\"\n  # We instantiate all variables using tf.get_variable() instead of\n  # tf.Variable() in order to share variables across multiple GPU training runs.\n  # If we only ran this model on a single GPU, we could simplify this function\n  # by replacing all instances of tf.get_variable() with tf.Variable().\n  #\n  # conv1\n  with tf.variable_scope('conv1') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],\n                                         stddev=1e-4, wd=0.0)\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n    bias = tf.nn.bias_add(conv, biases)\n    conv1 = tf.nn.relu(bias, name=scope.name)\n    _activation_summary(conv1)\n\n  # pool1\n  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n                         padding='SAME', name='pool1')\n  # norm1\n  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n                    name='norm1')\n\n  # conv2\n  with tf.variable_scope('conv2') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64],\n                                         stddev=1e-4, wd=0.0)\n    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n    print('conv2 is', conv)\n    print('biases2 is', biases)\n    bias = tf.nn.bias_add(conv, biases)\n    conv2 = tf.nn.relu(bias, name=scope.name)\n    _activation_summary(conv2)\n\n  # norm2\n  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n                    name='norm2')\n  # pool2\n  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n\n  # local3\n  with tf.variable_scope('local3') as scope:\n    print('pool2 is', pool2)\n    local3_extract_imgs = tf.extract_image_patches(pool2,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\n    print('local3_extract_imgs is', local3_extract_imgs)\n    #local3_reshape = tf.reshape(local3_extract_imgs,[FLAGS.batch_size,6,6,3*3*64,1])\n    #print('local3_reshape is', local3_reshape)\n    kernel = _variable_with_weight_decay('weights', shape=[6,6,64,3*3*64], stddev=0.04, wd=0.004)\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n    local3_list = []\n    for img in tf.unpack(value=local3_extract_imgs,axis=0):\n      #print('raw img is', img)\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\n      local = tf.reshape(tf.batch_matmul(kernel, img),[6,6,64])\n      #print( 'local is', local)\n      local3_list.append(local)\n\n    local3 = tf.nn.relu(tf.nn.bias_add(tf.pack(local3_list), biases), name=scope.name)\n    print('local3 is', local3)\n    _activation_summary(local3)\n\n  # local4\n  with tf.variable_scope('local4') as scope:\n    local4_extract_imgs = tf.extract_image_patches(local3,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\n    #local4_reshape = tf.reshape(local4_extract_imgs, [FLAGS.batch_size, 6, 6, 3*3*64, 1])\n    kernel = _variable_with_weight_decay( 'weights', shape=[6,6,32,3*3*64], stddev=0.04, wd=0.004) \n    biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n    local4_list = []\n    for img in tf.unpack(value=local4_extract_imgs, axis=0):\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\n      local = tf.reshape(tf.batch_matmul(kernel, img), shape=[6,6,32])\n      local4_list.append(local)\n\n    local4 = tf.nn.relu(tf.nn.bias_add(tf.pack(local4_list), biases), name=scope.name)\n    print('local4 is', local4)\n    _activation_summary(local4)\n\n  # softmax, i.e. softmax(WX + b)\n  with tf.variable_scope('softmax_linear') as scope:\n    reshape = tf.reshape(tensor=local4, shape=[FLAGS.batch_size,-1])\n\n    weights = _variable_with_weight_decay('weights', [6*6*32, NUM_CLASSES],\n                                          stddev=1/192.0, wd=0.0)\n    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n                              tf.constant_initializer(0.0))\n    softmax_linear = tf.nn.softmax(tf.add(tf.matmul(reshape, weights), biases, name=scope.name))\n    _activation_summary(softmax_linear)\n\nreturn softmax_linear\n</code></pre>\n<p>I have tried my best, and I think my local layer implementation is  theorectically correct, so I have no idea where is wrong on my code. Who can give me some advices?</p>", "body_text": "I followed the tutorials of cnn and  tried the exercise about reproducing  cifar10 model in cuda-convnet2.\nRecently, I thought I had worked it out, with implementing the local unshared layer by extract_image_patch function and batch_matmul function. Here is my code of the cifar10.py However, I found that the trained model is useless, because its accuracy is just 0.101, too low, for evaluation as below:\nprecision @ 1 = 0.101\nMy inference() function just like this:\ndef inference(images):\n  \"\"\"Build the CIFAR-10 model.\n  Args:\n    images: Images returned from distorted_inputs() or inputs().\n  Returns:\n    Logits.\n  \"\"\"\n  # We instantiate all variables using tf.get_variable() instead of\n  # tf.Variable() in order to share variables across multiple GPU training runs.\n  # If we only ran this model on a single GPU, we could simplify this function\n  # by replacing all instances of tf.get_variable() with tf.Variable().\n  #\n  # conv1\n  with tf.variable_scope('conv1') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],\n                                         stddev=1e-4, wd=0.0)\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n    bias = tf.nn.bias_add(conv, biases)\n    conv1 = tf.nn.relu(bias, name=scope.name)\n    _activation_summary(conv1)\n\n  # pool1\n  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n                         padding='SAME', name='pool1')\n  # norm1\n  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n                    name='norm1')\n\n  # conv2\n  with tf.variable_scope('conv2') as scope:\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64],\n                                         stddev=1e-4, wd=0.0)\n    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n    print('conv2 is', conv)\n    print('biases2 is', biases)\n    bias = tf.nn.bias_add(conv, biases)\n    conv2 = tf.nn.relu(bias, name=scope.name)\n    _activation_summary(conv2)\n\n  # norm2\n  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n                    name='norm2')\n  # pool2\n  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n\n  # local3\n  with tf.variable_scope('local3') as scope:\n    print('pool2 is', pool2)\n    local3_extract_imgs = tf.extract_image_patches(pool2,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\n    print('local3_extract_imgs is', local3_extract_imgs)\n    #local3_reshape = tf.reshape(local3_extract_imgs,[FLAGS.batch_size,6,6,3*3*64,1])\n    #print('local3_reshape is', local3_reshape)\n    kernel = _variable_with_weight_decay('weights', shape=[6,6,64,3*3*64], stddev=0.04, wd=0.004)\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n    local3_list = []\n    for img in tf.unpack(value=local3_extract_imgs,axis=0):\n      #print('raw img is', img)\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\n      local = tf.reshape(tf.batch_matmul(kernel, img),[6,6,64])\n      #print( 'local is', local)\n      local3_list.append(local)\n\n    local3 = tf.nn.relu(tf.nn.bias_add(tf.pack(local3_list), biases), name=scope.name)\n    print('local3 is', local3)\n    _activation_summary(local3)\n\n  # local4\n  with tf.variable_scope('local4') as scope:\n    local4_extract_imgs = tf.extract_image_patches(local3,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\n    #local4_reshape = tf.reshape(local4_extract_imgs, [FLAGS.batch_size, 6, 6, 3*3*64, 1])\n    kernel = _variable_with_weight_decay( 'weights', shape=[6,6,32,3*3*64], stddev=0.04, wd=0.004) \n    biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n    local4_list = []\n    for img in tf.unpack(value=local4_extract_imgs, axis=0):\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\n      local = tf.reshape(tf.batch_matmul(kernel, img), shape=[6,6,32])\n      local4_list.append(local)\n\n    local4 = tf.nn.relu(tf.nn.bias_add(tf.pack(local4_list), biases), name=scope.name)\n    print('local4 is', local4)\n    _activation_summary(local4)\n\n  # softmax, i.e. softmax(WX + b)\n  with tf.variable_scope('softmax_linear') as scope:\n    reshape = tf.reshape(tensor=local4, shape=[FLAGS.batch_size,-1])\n\n    weights = _variable_with_weight_decay('weights', [6*6*32, NUM_CLASSES],\n                                          stddev=1/192.0, wd=0.0)\n    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n                              tf.constant_initializer(0.0))\n    softmax_linear = tf.nn.softmax(tf.add(tf.matmul(reshape, weights), biases, name=scope.name))\n    _activation_summary(softmax_linear)\n\nreturn softmax_linear\n\nI have tried my best, and I think my local layer implementation is  theorectically correct, so I have no idea where is wrong on my code. Who can give me some advices?", "body": "I followed the tutorials of cnn and  tried the[ exercise](https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html#convolutional-neural-networks) about reproducing  cifar10 model in[ cuda-convnet2.](https://github.com/akrizhevsky/cuda-convnet2)\r\nRecently, I thought I had worked it out, with implementing the local unshared layer by extract_image_patch function and batch_matmul function. [Here is my code of the cifar10.py](https://github.com/SunAriesCN/tensorflow_learning/blob/master/cifar10/exercise/ex2/cifar10_ex2_cuda_convnet.py) However, I found that the trained model is useless, because its accuracy is just 0.101, too low, for evaluation as below:\r\n`precision @ 1 = 0.101`\r\nMy inference() function just like this:\r\n```\r\ndef inference(images):\r\n  \"\"\"Build the CIFAR-10 model.\r\n  Args:\r\n    images: Images returned from distorted_inputs() or inputs().\r\n  Returns:\r\n    Logits.\r\n  \"\"\"\r\n  # We instantiate all variables using tf.get_variable() instead of\r\n  # tf.Variable() in order to share variables across multiple GPU training runs.\r\n  # If we only ran this model on a single GPU, we could simplify this function\r\n  # by replacing all instances of tf.get_variable() with tf.Variable().\r\n  #\r\n  # conv1\r\n  with tf.variable_scope('conv1') as scope:\r\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],\r\n                                         stddev=1e-4, wd=0.0)\r\n    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\r\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\r\n    bias = tf.nn.bias_add(conv, biases)\r\n    conv1 = tf.nn.relu(bias, name=scope.name)\r\n    _activation_summary(conv1)\r\n\r\n  # pool1\r\n  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\r\n                         padding='SAME', name='pool1')\r\n  # norm1\r\n  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\r\n                    name='norm1')\r\n\r\n  # conv2\r\n  with tf.variable_scope('conv2') as scope:\r\n    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64],\r\n                                         stddev=1e-4, wd=0.0)\r\n    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\r\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\r\n    print('conv2 is', conv)\r\n    print('biases2 is', biases)\r\n    bias = tf.nn.bias_add(conv, biases)\r\n    conv2 = tf.nn.relu(bias, name=scope.name)\r\n    _activation_summary(conv2)\r\n\r\n  # norm2\r\n  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\r\n                    name='norm2')\r\n  # pool2\r\n  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\r\n                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\r\n\r\n  # local3\r\n  with tf.variable_scope('local3') as scope:\r\n    print('pool2 is', pool2)\r\n    local3_extract_imgs = tf.extract_image_patches(pool2,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\r\n    print('local3_extract_imgs is', local3_extract_imgs)\r\n    #local3_reshape = tf.reshape(local3_extract_imgs,[FLAGS.batch_size,6,6,3*3*64,1])\r\n    #print('local3_reshape is', local3_reshape)\r\n    kernel = _variable_with_weight_decay('weights', shape=[6,6,64,3*3*64], stddev=0.04, wd=0.004)\r\n    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\r\n    local3_list = []\r\n    for img in tf.unpack(value=local3_extract_imgs,axis=0):\r\n      #print('raw img is', img)\r\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\r\n      local = tf.reshape(tf.batch_matmul(kernel, img),[6,6,64])\r\n      #print( 'local is', local)\r\n      local3_list.append(local)\r\n\r\n    local3 = tf.nn.relu(tf.nn.bias_add(tf.pack(local3_list), biases), name=scope.name)\r\n    print('local3 is', local3)\r\n    _activation_summary(local3)\r\n\r\n  # local4\r\n  with tf.variable_scope('local4') as scope:\r\n    local4_extract_imgs = tf.extract_image_patches(local3,[1,3,3,1],[1,1,1,1],[1,1,1,1],'SAME')\r\n    #local4_reshape = tf.reshape(local4_extract_imgs, [FLAGS.batch_size, 6, 6, 3*3*64, 1])\r\n    kernel = _variable_with_weight_decay( 'weights', shape=[6,6,32,3*3*64], stddev=0.04, wd=0.004) \r\n    biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\r\n    local4_list = []\r\n    for img in tf.unpack(value=local4_extract_imgs, axis=0):\r\n      img = tf.reshape(img, [6, 6, 3*3*64, 1])\r\n      local = tf.reshape(tf.batch_matmul(kernel, img), shape=[6,6,32])\r\n      local4_list.append(local)\r\n\r\n    local4 = tf.nn.relu(tf.nn.bias_add(tf.pack(local4_list), biases), name=scope.name)\r\n    print('local4 is', local4)\r\n    _activation_summary(local4)\r\n\r\n  # softmax, i.e. softmax(WX + b)\r\n  with tf.variable_scope('softmax_linear') as scope:\r\n    reshape = tf.reshape(tensor=local4, shape=[FLAGS.batch_size,-1])\r\n\r\n    weights = _variable_with_weight_decay('weights', [6*6*32, NUM_CLASSES],\r\n                                          stddev=1/192.0, wd=0.0)\r\n    biases = _variable_on_cpu('biases', [NUM_CLASSES],\r\n                              tf.constant_initializer(0.0))\r\n    softmax_linear = tf.nn.softmax(tf.add(tf.matmul(reshape, weights), biases, name=scope.name))\r\n    _activation_summary(softmax_linear)\r\n\r\nreturn softmax_linear\r\n```\r\n\r\nI have tried my best, and I think my local layer implementation is  theorectically correct, so I have no idea where is wrong on my code. Who can give me some advices?"}