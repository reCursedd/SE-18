{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232495730", "html_url": "https://github.com/tensorflow/tensorflow/issues/110#issuecomment-232495730", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/110", "id": 232495730, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjQ5NTczMA==", "user": {"login": "mukul1992", "id": 18251677, "node_id": "MDQ6VXNlcjE4MjUxNjc3", "avatar_url": "https://avatars0.githubusercontent.com/u/18251677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mukul1992", "html_url": "https://github.com/mukul1992", "followers_url": "https://api.github.com/users/mukul1992/followers", "following_url": "https://api.github.com/users/mukul1992/following{/other_user}", "gists_url": "https://api.github.com/users/mukul1992/gists{/gist_id}", "starred_url": "https://api.github.com/users/mukul1992/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mukul1992/subscriptions", "organizations_url": "https://api.github.com/users/mukul1992/orgs", "repos_url": "https://api.github.com/users/mukul1992/repos", "events_url": "https://api.github.com/users/mukul1992/events{/privacy}", "received_events_url": "https://api.github.com/users/mukul1992/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-13T21:42:45Z", "updated_at": "2016-07-13T21:42:45Z", "author_association": "NONE", "body_html": "<p>Hello,<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5150559\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rdipietro\">@rdipietro</a> :  I am trying to install tensorflow/0.9.0 on a cluster running CentOS 6.7. I have bazel installed already. Here is the error I am getting.<br>\n<code>ERROR: /gpfs_home/mdave/.cache/bazel/_bazel_mdave/541ff47a1a214f62e91d090e1e816e43/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127. /gpfs/runtime/opt/python/2.7.3/bin/python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory Target //tensorflow/tools/pip_package:build_pip_package failed to build</code></p>\n<p>I suppose the fix for this, as mentioned by you in the step-wise directions is:<br>\n4. Edit <code>bazel-out/host/bin/tensorflow/swig</code> and add <code>export LD_LIBRARY_PATH=custom:paths:$LD_LIBRARY_PATH</code> before <code>swig</code> is run. Otherwise <code>swig</code>won't find libraries that exist in our <code>LD_LIBRARY_PATH</code>. This is another hack to get around the confined environment.</p>\n<p>This should add the python library path while setting up the build but I do not seem to find a file such as <code>bazel-out/host/bin/tensorflow/swig</code> in the source tree, while the <code>bazel-out/host/bin/tensorflow</code> directory does exist. If I create a file named <code>swig</code> myself and add the command to export the paths, it still does not work. Any ideas? I have followed all other steps as mentioned.</p>\n<p>Thank you for the help. Your responses here have already been very helpful. :)</p>", "body_text": "Hello,\n@rdipietro :  I am trying to install tensorflow/0.9.0 on a cluster running CentOS 6.7. I have bazel installed already. Here is the error I am getting.\nERROR: /gpfs_home/mdave/.cache/bazel/_bazel_mdave/541ff47a1a214f62e91d090e1e816e43/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127. /gpfs/runtime/opt/python/2.7.3/bin/python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory Target //tensorflow/tools/pip_package:build_pip_package failed to build\nI suppose the fix for this, as mentioned by you in the step-wise directions is:\n4. Edit bazel-out/host/bin/tensorflow/swig and add export LD_LIBRARY_PATH=custom:paths:$LD_LIBRARY_PATH before swig is run. Otherwise swigwon't find libraries that exist in our LD_LIBRARY_PATH. This is another hack to get around the confined environment.\nThis should add the python library path while setting up the build but I do not seem to find a file such as bazel-out/host/bin/tensorflow/swig in the source tree, while the bazel-out/host/bin/tensorflow directory does exist. If I create a file named swig myself and add the command to export the paths, it still does not work. Any ideas? I have followed all other steps as mentioned.\nThank you for the help. Your responses here have already been very helpful. :)", "body": "Hello,\n@rdipietro :  I am trying to install tensorflow/0.9.0 on a cluster running CentOS 6.7. I have bazel installed already. Here is the error I am getting.\n`ERROR: /gpfs_home/mdave/.cache/bazel/_bazel_mdave/541ff47a1a214f62e91d090e1e816e43/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.\n/gpfs/runtime/opt/python/2.7.3/bin/python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build`\n\nI suppose the fix for this, as mentioned by you in the step-wise directions is:\n4. Edit `bazel-out/host/bin/tensorflow/swig` and add `export LD_LIBRARY_PATH=custom:paths:$LD_LIBRARY_PATH` before `swig` is run. Otherwise `swig`won't find libraries that exist in our `LD_LIBRARY_PATH`. This is another hack to get around the confined environment.\n\nThis should add the python library path while setting up the build but I do not seem to find a file such as `bazel-out/host/bin/tensorflow/swig` in the source tree, while the `bazel-out/host/bin/tensorflow` directory does exist. If I create a file named `swig` myself and add the command to export the paths, it still does not work. Any ideas? I have followed all other steps as mentioned.\n\nThank you for the help. Your responses here have already been very helpful. :)\n"}