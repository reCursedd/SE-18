{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16315", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16315/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16315/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16315/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16315", "id": 290735786, "node_id": "MDU6SXNzdWUyOTA3MzU3ODY=", "number": 16315, "title": "Remove Variables from a TF Server (e.g.)", "user": {"login": "xldrx", "id": 1114830, "node_id": "MDQ6VXNlcjExMTQ4MzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1114830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xldrx", "html_url": "https://github.com/xldrx", "followers_url": "https://api.github.com/users/xldrx/followers", "following_url": "https://api.github.com/users/xldrx/following{/other_user}", "gists_url": "https://api.github.com/users/xldrx/gists{/gist_id}", "starred_url": "https://api.github.com/users/xldrx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xldrx/subscriptions", "organizations_url": "https://api.github.com/users/xldrx/orgs", "repos_url": "https://api.github.com/users/xldrx/repos", "events_url": "https://api.github.com/users/xldrx/events{/privacy}", "received_events_url": "https://api.github.com/users/xldrx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-23T07:33:05Z", "updated_at": "2018-01-23T21:29:30Z", "closed_at": "2018-01-23T21:29:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have a cluster of long-lived TensorFlow servers  (//tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server).<br>\nMy problem is how to reset variables on these server.</p>\n<p>There is a behavior in distributed TensorFlow in which a variable defined on a worker (e.g. PS) outlives the session which defines it. I understand this behavior is intentional to support between graph model-replica.</p>\n<p>However, In my use case this behavior causes unexpected problem. I have not found a mechanism to override this. It there is, I believe it is helpful to better reflect it in the documentation, if there is not, I hope I can make a case to motivate its existence.</p>\n<p>In my use case different training jobs are ran <em>sequentially</em> (i.e. one training job at a time) on this cluster, each using one client (which connects to only one master).</p>\n<p>The problem I have is if a variable is defined in two training job with a same name but different shape sizes, the latter client gets the following error on \"Session\" creation:</p>\n<pre><code>InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [100] rhs shape= [200]%0A%09 [[Node: a/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@a\"], use_locking=true, validate_shape=true, _device=\"/job:worker/replica:0/task:0/device:GPU:0\"](a, a/Initializer/random_uniform)]]\n</code></pre>\n<p><code>tf.reset_default_graph</code> does not help. The solution to this problem could be a mechanism similar <code>tf.reset_default_graph</code> that resets variables in all the workers.</p>\n<p>To replicate this problem let say we have two workers: (one PS, and on Worker)</p>\n<p>Worker 1:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>worker 1</span>\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps|localhost:2222,worker|localhost:2223<span class=\"pl-pds\">\"</span></span> --job_name=worker --task_id=0 <span class=\"pl-k\">&amp;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>worker 2</span>\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps|localhost:2222,worker|localhost:2223<span class=\"pl-pds\">\"</span></span> --job_name=worker --task_id=0</pre></div>\n<p>(Same result with <code>tf.train.Server</code> workers.)</p>\n<p>Then run the simple code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nvar <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>A<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">100</span>,))\n<span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2223<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> sess:\n   <span class=\"pl-k\">pass</span></pre></div>\n<p>It should work just fine.<br>\nThen when this code (which is identical except the variable shape) is ran:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nvar <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>A<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">5000</span>,))\n<span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost:2223<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> sess:\n   <span class=\"pl-k\">pass</span></pre></div>\n<p>This example fails.</p>", "body_text": "I have a cluster of long-lived TensorFlow servers  (//tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server).\nMy problem is how to reset variables on these server.\nThere is a behavior in distributed TensorFlow in which a variable defined on a worker (e.g. PS) outlives the session which defines it. I understand this behavior is intentional to support between graph model-replica.\nHowever, In my use case this behavior causes unexpected problem. I have not found a mechanism to override this. It there is, I believe it is helpful to better reflect it in the documentation, if there is not, I hope I can make a case to motivate its existence.\nIn my use case different training jobs are ran sequentially (i.e. one training job at a time) on this cluster, each using one client (which connects to only one master).\nThe problem I have is if a variable is defined in two training job with a same name but different shape sizes, the latter client gets the following error on \"Session\" creation:\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [100] rhs shape= [200]%0A%09 [[Node: a/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@a\"], use_locking=true, validate_shape=true, _device=\"/job:worker/replica:0/task:0/device:GPU:0\"](a, a/Initializer/random_uniform)]]\n\ntf.reset_default_graph does not help. The solution to this problem could be a mechanism similar tf.reset_default_graph that resets variables in all the workers.\nTo replicate this problem let say we have two workers: (one PS, and on Worker)\nWorker 1:\n#worker 1\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0 &\n#worker 2\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0\n(Same result with tf.train.Server workers.)\nThen run the simple code:\nimport tensorflow as tf\nvar = tf.get_variable(\"A\", shape=(100,))\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\n   pass\nIt should work just fine.\nThen when this code (which is identical except the variable shape) is ran:\nimport tensorflow as tf\nvar = tf.get_variable(\"A\", shape=(5000,))\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\n   pass\nThis example fails.", "body": "I have a cluster of long-lived TensorFlow servers  (//tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server).\r\nMy problem is how to reset variables on these server. \r\n\r\nThere is a behavior in distributed TensorFlow in which a variable defined on a worker (e.g. PS) outlives the session which defines it. I understand this behavior is intentional to support between graph model-replica.\r\n\r\nHowever, In my use case this behavior causes unexpected problem. I have not found a mechanism to override this. It there is, I believe it is helpful to better reflect it in the documentation, if there is not, I hope I can make a case to motivate its existence.\r\n\r\nIn my use case different training jobs are ran _sequentially_ (i.e. one training job at a time) on this cluster, each using one client (which connects to only one master). \r\n\r\nThe problem I have is if a variable is defined in two training job with a same name but different shape sizes, the latter client gets the following error on \"Session\" creation:\r\n```\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [100] rhs shape= [200]%0A%09 [[Node: a/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@a\"], use_locking=true, validate_shape=true, _device=\"/job:worker/replica:0/task:0/device:GPU:0\"](a, a/Initializer/random_uniform)]]\r\n```\r\n\r\n`tf.reset_default_graph` does not help. The solution to this problem could be a mechanism similar `tf.reset_default_graph` that resets variables in all the workers.\r\n\r\nTo replicate this problem let say we have two workers: (one PS, and on Worker)\r\n\r\nWorker 1:\r\n```bash\r\n#worker 1\r\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0 &\r\n#worker 2\r\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0\r\n```\r\n(Same result with `tf.train.Server` workers.)\r\n\r\nThen run the simple code:\r\n```python\r\nimport tensorflow as tf\r\nvar = tf.get_variable(\"A\", shape=(100,))\r\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\r\n   pass\r\n```\r\nIt should work just fine.\r\nThen when this code (which is identical except the variable shape) is ran:\r\n```python\r\nimport tensorflow as tf\r\nvar = tf.get_variable(\"A\", shape=(5000,))\r\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\r\n   pass\r\n```\r\nThis example fails.\r\n"}