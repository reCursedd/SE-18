{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9855", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9855/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9855/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9855/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9855", "id": 228226445, "node_id": "MDU6SXNzdWUyMjgyMjY0NDU=", "number": 9855, "title": "Unexpected error at contrib.seq2seq's BeamSearchDecoder", "user": {"login": "shuuki4", "id": 12455653, "node_id": "MDQ6VXNlcjEyNDU1NjUz", "avatar_url": "https://avatars2.githubusercontent.com/u/12455653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shuuki4", "html_url": "https://github.com/shuuki4", "followers_url": "https://api.github.com/users/shuuki4/followers", "following_url": "https://api.github.com/users/shuuki4/following{/other_user}", "gists_url": "https://api.github.com/users/shuuki4/gists{/gist_id}", "starred_url": "https://api.github.com/users/shuuki4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shuuki4/subscriptions", "organizations_url": "https://api.github.com/users/shuuki4/orgs", "repos_url": "https://api.github.com/users/shuuki4/repos", "events_url": "https://api.github.com/users/shuuki4/events{/privacy}", "received_events_url": "https://api.github.com/users/shuuki4/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-12T08:47:01Z", "updated_at": "2018-01-18T10:56:46Z", "closed_at": "2017-05-13T07:48:16Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>:  v1.1.0-rc2-773-g7fa0cf39f</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>:  None</li>\n<li><strong>GPU model and memory</strong>: CPU</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, <em>when the beam width is smaller than number of vocabs</em>.<br>\nThis is a part of <code>_beam_search_step</code> operation in <code>beam_search_decoder.py</code>:</p>\n<pre><code>  scores = _get_scores(\n      log_probs=total_probs,\n      sequence_lengths=new_prediction_lengths,\n      length_penalty_weight=length_penalty_weight)\n\n  time = ops.convert_to_tensor(time, name=\"time\")\n  # During the first time step we only consider the initial beam\n  scores_flat = control_flow_ops.cond(\n      time &gt; 0,\n      lambda: array_ops.reshape(scores, [batch_size, -1]),\n      lambda: scores[:, 0])\n\n  # Pick the next beams according to the specified successors function\n  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)\n  next_beam_scores.set_shape([static_batch_size, beam_width])\n  word_indices.set_shape([static_batch_size, beam_width])\n</code></pre>\n<p>Since the shape of <code>scores</code> is <code>[batch_size, beam_width, vocab_size]</code>,  the shape of <code>scores_flat</code> is<code>[batch_size, vocab_size]</code> at time step 0. However, if <code>k &lt; shape[-1]</code> in <code>nn.top_k</code> operation, it just throws <code>InvalidArgumentError: input must have at least k columns</code>. Thus the code just throws an error and dies.<br>\nI think code should be modified to handle cases where <code>vocab_size ** n &lt; beam_width</code>, or at least throw an appropriate error message when the input is <code>vocab_size &lt; beam_width</code>.</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below):  v1.1.0-rc2-773-g7fa0cf39f\nBazel version (if compiling from source):  0.4.5\nCUDA/cuDNN version:  None\nGPU model and memory: CPU\n\nDescribe the problem\nI encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, when the beam width is smaller than number of vocabs.\nThis is a part of _beam_search_step operation in beam_search_decoder.py:\n  scores = _get_scores(\n      log_probs=total_probs,\n      sequence_lengths=new_prediction_lengths,\n      length_penalty_weight=length_penalty_weight)\n\n  time = ops.convert_to_tensor(time, name=\"time\")\n  # During the first time step we only consider the initial beam\n  scores_flat = control_flow_ops.cond(\n      time > 0,\n      lambda: array_ops.reshape(scores, [batch_size, -1]),\n      lambda: scores[:, 0])\n\n  # Pick the next beams according to the specified successors function\n  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)\n  next_beam_scores.set_shape([static_batch_size, beam_width])\n  word_indices.set_shape([static_batch_size, beam_width])\n\nSince the shape of scores is [batch_size, beam_width, vocab_size],  the shape of scores_flat is[batch_size, vocab_size] at time step 0. However, if k < shape[-1] in nn.top_k operation, it just throws InvalidArgumentError: input must have at least k columns. Thus the code just throws an error and dies.\nI think code should be modified to handle cases where vocab_size ** n < beam_width, or at least throw an appropriate error message when the input is vocab_size < beam_width.", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**:  v1.1.0-rc2-773-g7fa0cf39f\r\n- **Bazel version (if compiling from source)**:  0.4.5\r\n- **CUDA/cuDNN version**:  None\r\n- **GPU model and memory**: CPU\r\n\r\n### Describe the problem\r\n\r\nI encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, *when the beam width is smaller than number of vocabs*.\r\nThis is a part of `_beam_search_step` operation in `beam_search_decoder.py`:\r\n\r\n```\r\n  scores = _get_scores(\r\n      log_probs=total_probs,\r\n      sequence_lengths=new_prediction_lengths,\r\n      length_penalty_weight=length_penalty_weight)\r\n\r\n  time = ops.convert_to_tensor(time, name=\"time\")\r\n  # During the first time step we only consider the initial beam\r\n  scores_flat = control_flow_ops.cond(\r\n      time > 0,\r\n      lambda: array_ops.reshape(scores, [batch_size, -1]),\r\n      lambda: scores[:, 0])\r\n\r\n  # Pick the next beams according to the specified successors function\r\n  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)\r\n  next_beam_scores.set_shape([static_batch_size, beam_width])\r\n  word_indices.set_shape([static_batch_size, beam_width])\r\n```\r\n\r\nSince the shape of `scores` is `[batch_size, beam_width, vocab_size]`,  the shape of `scores_flat` is`[batch_size, vocab_size]` at time step 0. However, if `k < shape[-1]` in `nn.top_k` operation, it just throws `InvalidArgumentError: input must have at least k columns`. Thus the code just throws an error and dies.\r\nI think code should be modified to handle cases where `vocab_size ** n < beam_width`, or at least throw an appropriate error message when the input is `vocab_size < beam_width`.\r\n\r\n"}