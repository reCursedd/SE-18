{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/374748914", "html_url": "https://github.com/tensorflow/tensorflow/issues/17246#issuecomment-374748914", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17246", "id": 374748914, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDc0ODkxNA==", "user": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-20T20:40:47Z", "updated_at": "2018-03-20T20:40:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes that's before it went in; 2.25 or 2.26 I believe.</p>\n<p>That article is nearly a decade old and out of date.  The memcpy maintainer in glibc works for Intel.  There are assembly routines for every specialized architecture variant including AVX 512 in the latest versions (but AVX2 is preferred because of the large down clocks associated with using AVX 512).</p>\n<p>I think your bandwidth calculation is off by a factor of 2, it only includes bytes read.</p>\n<p>That being said, it does seem like I was incorrect and multi-threading does provide a benefit, especially on skylake.  However, 2.5 GB/sec from single threaded system memcpy seems way too low (even lowly skylake should get 10 GB/sec), so I don't know that we completely understand what's going on here.</p>", "body_text": "Yes that's before it went in; 2.25 or 2.26 I believe.\nThat article is nearly a decade old and out of date.  The memcpy maintainer in glibc works for Intel.  There are assembly routines for every specialized architecture variant including AVX 512 in the latest versions (but AVX2 is preferred because of the large down clocks associated with using AVX 512).\nI think your bandwidth calculation is off by a factor of 2, it only includes bytes read.\nThat being said, it does seem like I was incorrect and multi-threading does provide a benefit, especially on skylake.  However, 2.5 GB/sec from single threaded system memcpy seems way too low (even lowly skylake should get 10 GB/sec), so I don't know that we completely understand what's going on here.", "body": "Yes that's before it went in; 2.25 or 2.26 I believe.\r\n\r\nThat article is nearly a decade old and out of date.  The memcpy maintainer in glibc works for Intel.  There are assembly routines for every specialized architecture variant including AVX 512 in the latest versions (but AVX2 is preferred because of the large down clocks associated with using AVX 512).\r\n\r\nI think your bandwidth calculation is off by a factor of 2, it only includes bytes read.\r\n\r\nThat being said, it does seem like I was incorrect and multi-threading does provide a benefit, especially on skylake.  However, 2.5 GB/sec from single threaded system memcpy seems way too low (even lowly skylake should get 10 GB/sec), so I don't know that we completely understand what's going on here."}