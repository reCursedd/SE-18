{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/219951942", "html_url": "https://github.com/tensorflow/tensorflow/issues/2386#issuecomment-219951942", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2386", "id": 219951942, "node_id": "MDEyOklzc3VlQ29tbWVudDIxOTk1MTk0Mg==", "user": {"login": "smartcat2010", "id": 10429114, "node_id": "MDQ6VXNlcjEwNDI5MTE0", "avatar_url": "https://avatars1.githubusercontent.com/u/10429114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smartcat2010", "html_url": "https://github.com/smartcat2010", "followers_url": "https://api.github.com/users/smartcat2010/followers", "following_url": "https://api.github.com/users/smartcat2010/following{/other_user}", "gists_url": "https://api.github.com/users/smartcat2010/gists{/gist_id}", "starred_url": "https://api.github.com/users/smartcat2010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smartcat2010/subscriptions", "organizations_url": "https://api.github.com/users/smartcat2010/orgs", "repos_url": "https://api.github.com/users/smartcat2010/repos", "events_url": "https://api.github.com/users/smartcat2010/events{/privacy}", "received_events_url": "https://api.github.com/users/smartcat2010/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-18T07:50:39Z", "updated_at": "2016-05-18T07:50:39Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15792374\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jmchen-g\">@jmchen-g</a><br>\nThank you very much for your quick help!<br>\nI updated my code following your guide. I run 1 ps and 2 workers like this:</p>\n<pre><code>cluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.65:2223\"] })\nwith tf.device(tf.train.replica_device_setter(cluster = cluster_spec)) :\n</code></pre>\n<p>My code file:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/269861/mnist_softmax.py.txt\">mnist_softmax.py.txt</a></p>\n<p>Then worker0 runs smoothly, worker1 shows the following error:</p>\n<pre><code>I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -&gt; {10.141.33.61:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; {10.141.33.61:2223, localhost:2223}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nTraceback (most recent call last):\n  File \"./mnist_softmax.py\", line 83, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 70, in run_training\n    _, cost, acc, step = sess.run([train_step, cross_entropy, accuracy, global_step], feed_dict = { x: source_data, y_ : labels_one_hot })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Expected size[0] in [0, 0], but got 1\n     [[Node: get_local_step = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/gpu:0\"](local_steps_S11, Reshape, get_local_step/size)]]\nCaused by op u'get_local_step', defined at:\n  File \"./mnist_softmax.py\", line 83, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 45, in run_training\n    train_step = opt.minimize(cross_entropy, global_step = global_step)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 192, in minimize\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/sync_replicas_optimizer.py\", line 334, in apply_gradients\n    name=\"get_local_step\")\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 217, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1318, in _slice\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p>When I change it to run the 2 workers in the same machine as follows, then both of the workers runs smoothly.<br>\n<code>cluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.61:2224\"] })</code></p>\n<p>So is there something wrong in my multi-machine code?</p>", "body_text": "@jmchen-g\nThank you very much for your quick help!\nI updated my code following your guide. I run 1 ps and 2 workers like this:\ncluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.65:2223\"] })\nwith tf.device(tf.train.replica_device_setter(cluster = cluster_spec)) :\n\nMy code file:\nmnist_softmax.py.txt\nThen worker0 runs smoothly, worker1 shows the following error:\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {10.141.33.61:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {10.141.33.61:2223, localhost:2223}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nTraceback (most recent call last):\n  File \"./mnist_softmax.py\", line 83, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 70, in run_training\n    _, cost, acc, step = sess.run([train_step, cross_entropy, accuracy, global_step], feed_dict = { x: source_data, y_ : labels_one_hot })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Expected size[0] in [0, 0], but got 1\n     [[Node: get_local_step = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/gpu:0\"](local_steps_S11, Reshape, get_local_step/size)]]\nCaused by op u'get_local_step', defined at:\n  File \"./mnist_softmax.py\", line 83, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 45, in run_training\n    train_step = opt.minimize(cross_entropy, global_step = global_step)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 192, in minimize\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/sync_replicas_optimizer.py\", line 334, in apply_gradients\n    name=\"get_local_step\")\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 217, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1318, in _slice\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\nWhen I change it to run the 2 workers in the same machine as follows, then both of the workers runs smoothly.\ncluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.61:2224\"] })\nSo is there something wrong in my multi-machine code?", "body": "@jmchen-g \nThank you very much for your quick help!\nI updated my code following your guide. I run 1 ps and 2 workers like this:\n\n```\ncluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.65:2223\"] })\nwith tf.device(tf.train.replica_device_setter(cluster = cluster_spec)) :\n```\n\nMy code file:\n[mnist_softmax.py.txt](https://github.com/tensorflow/tensorflow/files/269861/mnist_softmax.py.txt)\n\nThen worker0 runs smoothly, worker1 shows the following error:\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {10.141.33.61:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {10.141.33.61:2223, localhost:2223}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nTraceback (most recent call last):\n  File \"./mnist_softmax.py\", line 83, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 70, in run_training\n    _, cost, acc, step = sess.run([train_step, cross_entropy, accuracy, global_step], feed_dict = { x: source_data, y_ : labels_one_hot })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Expected size[0] in [0, 0], but got 1\n     [[Node: get_local_step = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/gpu:0\"](local_steps_S11, Reshape, get_local_step/size)]]\nCaused by op u'get_local_step', defined at:\n  File \"./mnist_softmax.py\", line 83, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_softmax.py\", line 80, in main\n    run_training(server, cluster_spec)\n  File \"./mnist_softmax.py\", line 45, in run_training\n    train_step = opt.minimize(cross_entropy, global_step = global_step)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 192, in minimize\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/sync_replicas_optimizer.py\", line 334, in apply_gradients\n    name=\"get_local_step\")\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 217, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1318, in _slice\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n```\n\nWhen I change it to run the 2 workers in the same machine as follows, then both of the workers runs smoothly.\n`cluster_spec = tf.train.ClusterSpec({ \"ps\":[\"10.141.33.61:2222\"], \"worker\" : [\"10.141.33.61:2223\", \"10.141.33.61:2224\"] })`\n\nSo is there something wrong in my multi-machine code?\n"}