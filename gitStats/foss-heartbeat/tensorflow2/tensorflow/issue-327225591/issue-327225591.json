{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19613", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19613/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19613/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19613/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19613", "id": 327225591, "node_id": "MDU6SXNzdWUzMjcyMjU1OTE=", "number": 19613, "title": "Cannot create initializer for non-floating point type", "user": {"login": "nairouz", "id": 10966954, "node_id": "MDQ6VXNlcjEwOTY2OTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/10966954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairouz", "html_url": "https://github.com/nairouz", "followers_url": "https://api.github.com/users/nairouz/followers", "following_url": "https://api.github.com/users/nairouz/following{/other_user}", "gists_url": "https://api.github.com/users/nairouz/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairouz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairouz/subscriptions", "organizations_url": "https://api.github.com/users/nairouz/orgs", "repos_url": "https://api.github.com/users/nairouz/repos", "events_url": "https://api.github.com/users/nairouz/events{/privacy}", "received_events_url": "https://api.github.com/users/nairouz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-29T08:51:12Z", "updated_at": "2018-05-30T15:07:27Z", "closed_at": "2018-05-29T23:29:39Z", "author_association": "NONE", "body_html": "<p>I m using tensorflow.contrib.slim for creating my model and google Colaboratory for running my code.<br>\nMy code was working like a charm with tensorflow 1.7 but when the new version 1.8 was installed in the cloud, I got the following error:</p>\n<p>`TypeError                                 Traceback (most recent call last)<br>\n/content/drive/Colab/baby_training_model_estimators/train_model.py in ()<br>\n100     import logging<br>\n101     logging.getLogger('tensorflow').propagate = False<br>\n--&gt; 102     run_train()</p>\n<p>/content/drive/Colab/baby_training_model_estimators/train_model.py in run_train(args)<br>\n94                                       run_config=run_config,<br>\n95                                       schedule=\"train_and_evaluate\",<br>\n---&gt; 96                                       hparams=params)<br>\n97<br>\n98 if <strong>name</strong> == '<strong>main</strong>':</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)<br>\n248               'in a future version' if date is None else ('after %s' % date),<br>\n249               instructions)<br>\n--&gt; 250       return func(*args, **kwargs)<br>\n251     return tf_decorator.make_decorator(<br>\n252         func, new_func, 'deprecated',</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)<br>\n223   schedule = schedule or _get_default_schedule(run_config)<br>\n224<br>\n--&gt; 225   return _execute_schedule(experiment, schedule)<br>\n226<br>\n227</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)<br>\n50     logging.error('Allowed values for this experiment are: %s', valid_tasks)<br>\n51     raise TypeError('Schedule references non-callable member %s' % schedule)<br>\n---&gt; 52   return task()<br>\n53<br>\n54</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)<br>\n664                   hooks=self._eval_hooks)<br>\n665           ]<br>\n--&gt; 666       self.train(delay_secs=0)<br>\n667<br>\n668     # If the checkpoint_and_export flag and appropriate estimator configuration</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)<br>\n387         max_steps=self._train_steps,<br>\n388         hooks=self._train_monitors + extra_hooks,<br>\n--&gt; 389         saving_listeners=self._saving_listeners)<br>\n390<br>\n391   def evaluate(self, delay_secs=None, name=None):</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)<br>\n874           max_steps=max_steps,<br>\n875           hooks=hooks,<br>\n--&gt; 876           saving_listeners=saving_listeners)<br>\n877     else:<br>\n878       return self._estimator.fit(</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)<br>\n361<br>\n362     saving_listeners = _check_listeners_type(saving_listeners)<br>\n--&gt; 363     loss = self._train_model(input_fn, hooks, saving_listeners)<br>\n364     logging.info('Loss for final step: %s.', loss)<br>\n365     return self</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)<br>\n841       return self._train_model_distributed(input_fn, hooks, saving_listeners)<br>\n842     else:<br>\n--&gt; 843       return self._train_model_default(input_fn, hooks, saving_listeners)<br>\n844<br>\n845   def _train_model_default(self, input_fn, hooks, saving_listeners):</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)<br>\n854       worker_hooks.extend(input_hooks)<br>\n855       estimator_spec = self._call_model_fn(<br>\n--&gt; 856           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)<br>\n857       return self._train_with_estimator_spec(estimator_spec, worker_hooks,<br>\n858                                              hooks, global_step_tensor,</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)<br>\n829<br>\n830     logging.info('Calling model_fn.')<br>\n--&gt; 831     model_fn_results = self._model_fn(features=features, **kwargs)<br>\n832     logging.info('Done calling model_fn.')<br>\n833</p>\n<p>/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/estimator.py in _model_fn(features, labels, mode)<br>\n92                                                  dropout=dropout,<br>\n93                                                  weight_decay=weight_decay,<br>\n---&gt; 94                                                  mode=mode)<br>\n95             return _create_estimator_spec_from_logits(labels=labels,<br>\n96                                                       logits=logits,</p>\n<p>/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fully_connected_autoencoder(network_type, model_id, sparse_coding, inputs, hidden_units, activation_fn, dropout, weight_decay, mode)<br>\n90         with tf.variable_scope(scope, 'FCAutoencoder', [inputs]):<br>\n91                 with slim.arg_scope(autoencoder_arg_scope(activation_fn, dropout, weight_decay, None, mode)):<br>\n---&gt; 92                         net = fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)<br>\n93                         n_features = inputs.shape[1].value<br>\n94                         decoder_units = hidden_units[:-1][::-1] + [n_features]</p>\n<p>/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)<br>\n15                         with tf.variable_scope('layer_{}'.format(layer_id), values=(net,)) as layer_scope:<br>\n16                                 print(num_hidden_units)<br>\n---&gt; 17                                 net = slim.fully_connected(net, num_outputs= num_hidden_units, scope=layer_scope)<br>\n18                                 if sparse_coding is not None:<br>\n19                                         tf.losses.mean_squared_error(net, tf.zeros_like(net), weights=sparse_coding, scope=layer_scope)</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)<br>\n181       current_args = current_scope[key_func].copy()<br>\n182       current_args.update(kwargs)<br>\n--&gt; 183     return func(*args, **current_args)<br>\n184<br>\n185   _add_op(func)</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in fully_connected(inputs, num_outputs, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)<br>\n1714         _scope=sc,<br>\n1715         _reuse=reuse)<br>\n-&gt; 1716     outputs = layer.apply(inputs)<br>\n1717<br>\n1718     # Add variables to collections.</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)<br>\n826       Output tensor(s).<br>\n827     \"\"\"<br>\n--&gt; 828     return self.<strong>call</strong>(inputs, *args, **kwargs)<br>\n829<br>\n830   def _add_inbound_node(self,</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in <strong>call</strong>(self, inputs, *args, **kwargs)<br>\n697           if all(hasattr(x, 'get_shape') for x in input_list):<br>\n698             input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)<br>\n--&gt; 699           self.build(input_shapes)<br>\n700         try:<br>\n701           # Note: not all sub-classes of Layer call Layer.<strong>init</strong> (especially</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py in build(self, input_shape)<br>\n136                                     constraint=self.kernel_constraint,<br>\n137                                     dtype=self.dtype,<br>\n--&gt; 138                                     trainable=True)<br>\n139     if self.use_bias:<br>\n140       self.bias = self.add_variable('bias',</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in add_variable(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)<br>\n544             constraint=constraint,<br>\n545             trainable=trainable and self.trainable,<br>\n--&gt; 546             partitioner=partitioner)<br>\n547<br>\n548         if init_graph is not None:  # pylint: disable=protected-access</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)<br>\n434     new_variable = getter(<br>\n435         name=name, shape=shape, dtype=dtype, initializer=initializer,<br>\n--&gt; 436         **kwargs_for_getter)<br>\n437<br>\n438     # If we set an initializer and the variable processed it, tracking will not</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)<br>\n1315       partitioner=partitioner, validate_shape=validate_shape,<br>\n1316       use_resource=use_resource, custom_getter=custom_getter,<br>\n-&gt; 1317       constraint=constraint)<br>\n1318 get_variable_or_local_docstring = (<br>\n1319     \"\"\"%s</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)<br>\n1077           partitioner=partitioner, validate_shape=validate_shape,<br>\n1078           use_resource=use_resource, custom_getter=custom_getter,<br>\n-&gt; 1079           constraint=constraint)<br>\n1080<br>\n1081   def _get_partitioned_variable(self,</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)<br>\n415       if \"constraint\" in estimator_util.fn_args(custom_getter):<br>\n416         custom_getter_kwargs[\"constraint\"] = constraint<br>\n--&gt; 417       return custom_getter(**custom_getter_kwargs)<br>\n418     else:<br>\n419       return _true_getter(</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)<br>\n1609   def layer_variable_getter(getter, *args, **kwargs):<br>\n1610     kwargs['rename'] = rename<br>\n-&gt; 1611     return _model_variable_getter(getter, *args, **kwargs)<br>\n1612<br>\n1613   return layer_variable_getter</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in <em>model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **</em>)<br>\n1600       partitioner=partitioner,<br>\n1601       custom_getter=getter,<br>\n-&gt; 1602       use_resource=use_resource)<br>\n1603<br>\n1604</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)<br>\n181       current_args = current_scope[key_func].copy()<br>\n182       current_args.update(kwargs)<br>\n--&gt; 183     return func(*args, **current_args)<br>\n184<br>\n185   _add_op(func)</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)<br>\n289                  caching_device=caching_device, device=device,<br>\n290                  partitioner=partitioner, custom_getter=custom_getter,<br>\n--&gt; 291                  use_resource=use_resource)<br>\n292   return var<br>\n293</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)<br>\n181       current_args = current_scope[key_func].copy()<br>\n182       current_args.update(kwargs)<br>\n--&gt; 183     return func(*args, **current_args)<br>\n184<br>\n185   _add_op(func)</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)<br>\n244                   caching_device=caching_device,<br>\n245                   partitioner=partitioner,<br>\n--&gt; 246                   use_resource=use_resource)<br>\n247<br>\n248</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)<br>\n392           trainable=trainable, collections=collections,<br>\n393           caching_device=caching_device, validate_shape=validate_shape,<br>\n--&gt; 394           use_resource=use_resource, constraint=constraint)<br>\n395<br>\n396     if custom_getter is not None:</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)<br>\n784         validate_shape=validate_shape,<br>\n785         constraint=constraint,<br>\n--&gt; 786         use_resource=use_resource)<br>\n787     if not context.executing_eagerly() or self._store_eager_variables:<br>\n788       # In eager mode we do not want to keep default references to Variable</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in variable(initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint, use_resource)<br>\n2218                          name=name, dtype=dtype,<br>\n2219                          constraint=constraint,<br>\n-&gt; 2220                          use_resource=use_resource)<br>\n2221<br>\n2222</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in (**kwargs)<br>\n2208              constraint=None,<br>\n2209              use_resource=None):<br>\n-&gt; 2210   previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)<br>\n2211   for getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access<br>\n2212     previous_getter = _make_getter(getter, previous_getter)</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)<br>\n2191         collections=collections, validate_shape=validate_shape,<br>\n2192         caching_device=caching_device, name=name, dtype=dtype,<br>\n-&gt; 2193         constraint=constraint)<br>\n2194<br>\n2195</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in <strong>init</strong>(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)<br>\n233           dtype=dtype,<br>\n234           expected_shape=expected_shape,<br>\n--&gt; 235           constraint=constraint)<br>\n236<br>\n237   def <strong>repr</strong>(self):</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)<br>\n341             with ops.name_scope(\"Initializer\"), ops.device(None):<br>\n342               self._initial_value = ops.convert_to_tensor(<br>\n--&gt; 343                   initial_value(), name=\"initial_value\", dtype=dtype)<br>\n344               shape = (self._initial_value.get_shape()<br>\n345                        if validate_shape else tensor_shape.unknown_shape())</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in ()<br>\n768           initializer = initializer(dtype=dtype)<br>\n769         init_val = lambda: initializer(  # pylint: disable=g-long-lambda<br>\n--&gt; 770             shape.as_list(), dtype=dtype, partition_info=partition_info)<br>\n771         variable_dtype = dtype.base_dtype<br>\n772</p>\n<p>/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/initializers.py in _initializer(shape, dtype, partition_info)<br>\n118     \"\"\"Initializer function.\"\"\"<br>\n119     if not dtype.is_floating:<br>\n--&gt; 120       raise TypeError('Cannot create initializer for non-floating point type.')<br>\n121     # Estimating fan_in and fan_out is not possible to do perfectly, but we try.<br>\n122     # This is the right thing for matrix multiply and convolutions.</p>\n<p>TypeError: Cannot create initializer for non-floating point type.</p>\n<p>`</p>\n<p>I think it is related to a previous bug: <a href=\"https://github.com/tensorflow/tensorflow/issues/6342\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/6342/hovercard\">#6342</a></p>", "body_text": "I m using tensorflow.contrib.slim for creating my model and google Colaboratory for running my code.\nMy code was working like a charm with tensorflow 1.7 but when the new version 1.8 was installed in the cloud, I got the following error:\n`TypeError                                 Traceback (most recent call last)\n/content/drive/Colab/baby_training_model_estimators/train_model.py in ()\n100     import logging\n101     logging.getLogger('tensorflow').propagate = False\n--> 102     run_train()\n/content/drive/Colab/baby_training_model_estimators/train_model.py in run_train(args)\n94                                       run_config=run_config,\n95                                       schedule=\"train_and_evaluate\",\n---> 96                                       hparams=params)\n97\n98 if name == 'main':\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n248               'in a future version' if date is None else ('after %s' % date),\n249               instructions)\n--> 250       return func(*args, **kwargs)\n251     return tf_decorator.make_decorator(\n252         func, new_func, 'deprecated',\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\n223   schedule = schedule or _get_default_schedule(run_config)\n224\n--> 225   return _execute_schedule(experiment, schedule)\n226\n227\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)\n50     logging.error('Allowed values for this experiment are: %s', valid_tasks)\n51     raise TypeError('Schedule references non-callable member %s' % schedule)\n---> 52   return task()\n53\n54\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)\n664                   hooks=self._eval_hooks)\n665           ]\n--> 666       self.train(delay_secs=0)\n667\n668     # If the checkpoint_and_export flag and appropriate estimator configuration\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)\n387         max_steps=self._train_steps,\n388         hooks=self._train_monitors + extra_hooks,\n--> 389         saving_listeners=self._saving_listeners)\n390\n391   def evaluate(self, delay_secs=None, name=None):\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)\n874           max_steps=max_steps,\n875           hooks=hooks,\n--> 876           saving_listeners=saving_listeners)\n877     else:\n878       return self._estimator.fit(\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n361\n362     saving_listeners = _check_listeners_type(saving_listeners)\n--> 363     loss = self._train_model(input_fn, hooks, saving_listeners)\n364     logging.info('Loss for final step: %s.', loss)\n365     return self\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n841       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n842     else:\n--> 843       return self._train_model_default(input_fn, hooks, saving_listeners)\n844\n845   def _train_model_default(self, input_fn, hooks, saving_listeners):\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n854       worker_hooks.extend(input_hooks)\n855       estimator_spec = self._call_model_fn(\n--> 856           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n857       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n858                                              hooks, global_step_tensor,\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\n829\n830     logging.info('Calling model_fn.')\n--> 831     model_fn_results = self._model_fn(features=features, **kwargs)\n832     logging.info('Done calling model_fn.')\n833\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/estimator.py in _model_fn(features, labels, mode)\n92                                                  dropout=dropout,\n93                                                  weight_decay=weight_decay,\n---> 94                                                  mode=mode)\n95             return _create_estimator_spec_from_logits(labels=labels,\n96                                                       logits=logits,\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fully_connected_autoencoder(network_type, model_id, sparse_coding, inputs, hidden_units, activation_fn, dropout, weight_decay, mode)\n90         with tf.variable_scope(scope, 'FCAutoencoder', [inputs]):\n91                 with slim.arg_scope(autoencoder_arg_scope(activation_fn, dropout, weight_decay, None, mode)):\n---> 92                         net = fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)\n93                         n_features = inputs.shape[1].value\n94                         decoder_units = hidden_units[:-1][::-1] + [n_features]\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)\n15                         with tf.variable_scope('layer_{}'.format(layer_id), values=(net,)) as layer_scope:\n16                                 print(num_hidden_units)\n---> 17                                 net = slim.fully_connected(net, num_outputs= num_hidden_units, scope=layer_scope)\n18                                 if sparse_coding is not None:\n19                                         tf.losses.mean_squared_error(net, tf.zeros_like(net), weights=sparse_coding, scope=layer_scope)\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n181       current_args = current_scope[key_func].copy()\n182       current_args.update(kwargs)\n--> 183     return func(*args, **current_args)\n184\n185   _add_op(func)\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in fully_connected(inputs, num_outputs, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\n1714         _scope=sc,\n1715         _reuse=reuse)\n-> 1716     outputs = layer.apply(inputs)\n1717\n1718     # Add variables to collections.\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)\n826       Output tensor(s).\n827     \"\"\"\n--> 828     return self.call(inputs, *args, **kwargs)\n829\n830   def _add_inbound_node(self,\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in call(self, inputs, *args, **kwargs)\n697           if all(hasattr(x, 'get_shape') for x in input_list):\n698             input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\n--> 699           self.build(input_shapes)\n700         try:\n701           # Note: not all sub-classes of Layer call Layer.init (especially\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py in build(self, input_shape)\n136                                     constraint=self.kernel_constraint,\n137                                     dtype=self.dtype,\n--> 138                                     trainable=True)\n139     if self.use_bias:\n140       self.bias = self.add_variable('bias',\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in add_variable(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\n544             constraint=constraint,\n545             trainable=trainable and self.trainable,\n--> 546             partitioner=partitioner)\n547\n548         if init_graph is not None:  # pylint: disable=protected-access\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\n434     new_variable = getter(\n435         name=name, shape=shape, dtype=dtype, initializer=initializer,\n--> 436         **kwargs_for_getter)\n437\n438     # If we set an initializer and the variable processed it, tracking will not\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\n1315       partitioner=partitioner, validate_shape=validate_shape,\n1316       use_resource=use_resource, custom_getter=custom_getter,\n-> 1317       constraint=constraint)\n1318 get_variable_or_local_docstring = (\n1319     \"\"\"%s\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\n1077           partitioner=partitioner, validate_shape=validate_shape,\n1078           use_resource=use_resource, custom_getter=custom_getter,\n-> 1079           constraint=constraint)\n1080\n1081   def _get_partitioned_variable(self,\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\n415       if \"constraint\" in estimator_util.fn_args(custom_getter):\n416         custom_getter_kwargs[\"constraint\"] = constraint\n--> 417       return custom_getter(**custom_getter_kwargs)\n418     else:\n419       return _true_getter(\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)\n1609   def layer_variable_getter(getter, *args, **kwargs):\n1610     kwargs['rename'] = rename\n-> 1611     return _model_variable_getter(getter, *args, **kwargs)\n1612\n1613   return layer_variable_getter\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **)\n1600       partitioner=partitioner,\n1601       custom_getter=getter,\n-> 1602       use_resource=use_resource)\n1603\n1604\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n181       current_args = current_scope[key_func].copy()\n182       current_args.update(kwargs)\n--> 183     return func(*args, **current_args)\n184\n185   _add_op(func)\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\n289                  caching_device=caching_device, device=device,\n290                  partitioner=partitioner, custom_getter=custom_getter,\n--> 291                  use_resource=use_resource)\n292   return var\n293\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n181       current_args = current_scope[key_func].copy()\n182       current_args.update(kwargs)\n--> 183     return func(*args, **current_args)\n184\n185   _add_op(func)\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\n244                   caching_device=caching_device,\n245                   partitioner=partitioner,\n--> 246                   use_resource=use_resource)\n247\n248\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\n392           trainable=trainable, collections=collections,\n393           caching_device=caching_device, validate_shape=validate_shape,\n--> 394           use_resource=use_resource, constraint=constraint)\n395\n396     if custom_getter is not None:\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\n784         validate_shape=validate_shape,\n785         constraint=constraint,\n--> 786         use_resource=use_resource)\n787     if not context.executing_eagerly() or self._store_eager_variables:\n788       # In eager mode we do not want to keep default references to Variable\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in variable(initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint, use_resource)\n2218                          name=name, dtype=dtype,\n2219                          constraint=constraint,\n-> 2220                          use_resource=use_resource)\n2221\n2222\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in (**kwargs)\n2208              constraint=None,\n2209              use_resource=None):\n-> 2210   previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n2211   for getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\n2212     previous_getter = _make_getter(getter, previous_getter)\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\n2191         collections=collections, validate_shape=validate_shape,\n2192         caching_device=caching_device, name=name, dtype=dtype,\n-> 2193         constraint=constraint)\n2194\n2195\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in init(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\n233           dtype=dtype,\n234           expected_shape=expected_shape,\n--> 235           constraint=constraint)\n236\n237   def repr(self):\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\n341             with ops.name_scope(\"Initializer\"), ops.device(None):\n342               self._initial_value = ops.convert_to_tensor(\n--> 343                   initial_value(), name=\"initial_value\", dtype=dtype)\n344               shape = (self._initial_value.get_shape()\n345                        if validate_shape else tensor_shape.unknown_shape())\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in ()\n768           initializer = initializer(dtype=dtype)\n769         init_val = lambda: initializer(  # pylint: disable=g-long-lambda\n--> 770             shape.as_list(), dtype=dtype, partition_info=partition_info)\n771         variable_dtype = dtype.base_dtype\n772\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/initializers.py in _initializer(shape, dtype, partition_info)\n118     \"\"\"Initializer function.\"\"\"\n119     if not dtype.is_floating:\n--> 120       raise TypeError('Cannot create initializer for non-floating point type.')\n121     # Estimating fan_in and fan_out is not possible to do perfectly, but we try.\n122     # This is the right thing for matrix multiply and convolutions.\nTypeError: Cannot create initializer for non-floating point type.\n`\nI think it is related to a previous bug: #6342", "body": "I m using tensorflow.contrib.slim for creating my model and google Colaboratory for running my code.\r\nMy code was working like a charm with tensorflow 1.7 but when the new version 1.8 was installed in the cloud, I got the following error:\r\n\r\n`TypeError                                 Traceback (most recent call last)\r\n/content/drive/Colab/baby_training_model_estimators/train_model.py in <module>()\r\n    100     import logging\r\n    101     logging.getLogger('tensorflow').propagate = False\r\n--> 102     run_train()\r\n\r\n/content/drive/Colab/baby_training_model_estimators/train_model.py in run_train(args)\r\n     94                                       run_config=run_config,\r\n     95                                       schedule=\"train_and_evaluate\",\r\n---> 96                                       hparams=params)\r\n     97 \r\n     98 if __name__ == '__main__':\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    248               'in a future version' if date is None else ('after %s' % date),\r\n    249               instructions)\r\n--> 250       return func(*args, **kwargs)\r\n    251     return tf_decorator.make_decorator(\r\n    252         func, new_func, 'deprecated',\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\r\n    223   schedule = schedule or _get_default_schedule(run_config)\r\n    224 \r\n--> 225   return _execute_schedule(experiment, schedule)\r\n    226 \r\n    227 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)\r\n     50     logging.error('Allowed values for this experiment are: %s', valid_tasks)\r\n     51     raise TypeError('Schedule references non-callable member %s' % schedule)\r\n---> 52   return task()\r\n     53 \r\n     54 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)\r\n    664                   hooks=self._eval_hooks)\r\n    665           ]\r\n--> 666       self.train(delay_secs=0)\r\n    667 \r\n    668     # If the checkpoint_and_export flag and appropriate estimator configuration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)\r\n    387         max_steps=self._train_steps,\r\n    388         hooks=self._train_monitors + extra_hooks,\r\n--> 389         saving_listeners=self._saving_listeners)\r\n    390 \r\n    391   def evaluate(self, delay_secs=None, name=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)\r\n    874           max_steps=max_steps,\r\n    875           hooks=hooks,\r\n--> 876           saving_listeners=saving_listeners)\r\n    877     else:\r\n    878       return self._estimator.fit(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    361 \r\n    362     saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 363     loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    364     logging.info('Loss for final step: %s.', loss)\r\n    365     return self\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n    841       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n    842     else:\r\n--> 843       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n    844 \r\n    845   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n    854       worker_hooks.extend(input_hooks)\r\n    855       estimator_spec = self._call_model_fn(\r\n--> 856           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n    857       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n    858                                              hooks, global_step_tensor,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n    829 \r\n    830     logging.info('Calling model_fn.')\r\n--> 831     model_fn_results = self._model_fn(features=features, **kwargs)\r\n    832     logging.info('Done calling model_fn.')\r\n    833 \r\n\r\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/estimator.py in _model_fn(features, labels, mode)\r\n     92                                                  dropout=dropout,\r\n     93                                                  weight_decay=weight_decay,\r\n---> 94                                                  mode=mode)\r\n     95             return _create_estimator_spec_from_logits(labels=labels,\r\n     96                                                       logits=logits,\r\n\r\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fully_connected_autoencoder(network_type, model_id, sparse_coding, inputs, hidden_units, activation_fn, dropout, weight_decay, mode)\r\n     90         with tf.variable_scope(scope, 'FCAutoencoder', [inputs]):\r\n     91                 with slim.arg_scope(autoencoder_arg_scope(activation_fn, dropout, weight_decay, None, mode)):\r\n---> 92                         net = fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)\r\n     93                         n_features = inputs.shape[1].value\r\n     94                         decoder_units = hidden_units[:-1][::-1] + [n_features]\r\n\r\n/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)\r\n     15                         with tf.variable_scope('layer_{}'.format(layer_id), values=(net,)) as layer_scope:\r\n     16                                 print(num_hidden_units)\r\n---> 17                                 net = slim.fully_connected(net, num_outputs= num_hidden_units, scope=layer_scope)\r\n     18                                 if sparse_coding is not None:\r\n     19                                         tf.losses.mean_squared_error(net, tf.zeros_like(net), weights=sparse_coding, scope=layer_scope)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    181       current_args = current_scope[key_func].copy()\r\n    182       current_args.update(kwargs)\r\n--> 183     return func(*args, **current_args)\r\n    184 \r\n    185   _add_op(func)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in fully_connected(inputs, num_outputs, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\r\n   1714         _scope=sc,\r\n   1715         _reuse=reuse)\r\n-> 1716     outputs = layer.apply(inputs)\r\n   1717 \r\n   1718     # Add variables to collections.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)\r\n    826       Output tensor(s).\r\n    827     \"\"\"\r\n--> 828     return self.__call__(inputs, *args, **kwargs)\r\n    829 \r\n    830   def _add_inbound_node(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    697           if all(hasattr(x, 'get_shape') for x in input_list):\r\n    698             input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\r\n--> 699           self.build(input_shapes)\r\n    700         try:\r\n    701           # Note: not all sub-classes of Layer call Layer.__init__ (especially\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py in build(self, input_shape)\r\n    136                                     constraint=self.kernel_constraint,\r\n    137                                     dtype=self.dtype,\r\n--> 138                                     trainable=True)\r\n    139     if self.use_bias:\r\n    140       self.bias = self.add_variable('bias',\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in add_variable(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\r\n    544             constraint=constraint,\r\n    545             trainable=trainable and self.trainable,\r\n--> 546             partitioner=partitioner)\r\n    547 \r\n    548         if init_graph is not None:  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    434     new_variable = getter(\r\n    435         name=name, shape=shape, dtype=dtype, initializer=initializer,\r\n--> 436         **kwargs_for_getter)\r\n    437 \r\n    438     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1315       partitioner=partitioner, validate_shape=validate_shape,\r\n   1316       use_resource=use_resource, custom_getter=custom_getter,\r\n-> 1317       constraint=constraint)\r\n   1318 get_variable_or_local_docstring = (\r\n   1319     \"\"\"%s\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1077           partitioner=partitioner, validate_shape=validate_shape,\r\n   1078           use_resource=use_resource, custom_getter=custom_getter,\r\n-> 1079           constraint=constraint)\r\n   1080 \r\n   1081   def _get_partitioned_variable(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n    415       if \"constraint\" in estimator_util.fn_args(custom_getter):\r\n    416         custom_getter_kwargs[\"constraint\"] = constraint\r\n--> 417       return custom_getter(**custom_getter_kwargs)\r\n    418     else:\r\n    419       return _true_getter(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)\r\n   1609   def layer_variable_getter(getter, *args, **kwargs):\r\n   1610     kwargs['rename'] = rename\r\n-> 1611     return _model_variable_getter(getter, *args, **kwargs)\r\n   1612 \r\n   1613   return layer_variable_getter\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in _model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **_)\r\n   1600       partitioner=partitioner,\r\n   1601       custom_getter=getter,\r\n-> 1602       use_resource=use_resource)\r\n   1603 \r\n   1604 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    181       current_args = current_scope[key_func].copy()\r\n    182       current_args.update(kwargs)\r\n--> 183     return func(*args, **current_args)\r\n    184 \r\n    185   _add_op(func)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\r\n    289                  caching_device=caching_device, device=device,\r\n    290                  partitioner=partitioner, custom_getter=custom_getter,\r\n--> 291                  use_resource=use_resource)\r\n    292   return var\r\n    293 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    181       current_args = current_scope[key_func].copy()\r\n    182       current_args.update(kwargs)\r\n--> 183     return func(*args, **current_args)\r\n    184 \r\n    185   _add_op(func)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\r\n    244                   caching_device=caching_device,\r\n    245                   partitioner=partitioner,\r\n--> 246                   use_resource=use_resource)\r\n    247 \r\n    248 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\r\n    392           trainable=trainable, collections=collections,\r\n    393           caching_device=caching_device, validate_shape=validate_shape,\r\n--> 394           use_resource=use_resource, constraint=constraint)\r\n    395 \r\n    396     if custom_getter is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\r\n    784         validate_shape=validate_shape,\r\n    785         constraint=constraint,\r\n--> 786         use_resource=use_resource)\r\n    787     if not context.executing_eagerly() or self._store_eager_variables:\r\n    788       # In eager mode we do not want to keep default references to Variable\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in variable(initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint, use_resource)\r\n   2218                          name=name, dtype=dtype,\r\n   2219                          constraint=constraint,\r\n-> 2220                          use_resource=use_resource)\r\n   2221 \r\n   2222 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>(**kwargs)\r\n   2208              constraint=None,\r\n   2209              use_resource=None):\r\n-> 2210   previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n   2211   for getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n   2212     previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2191         collections=collections, validate_shape=validate_shape,\r\n   2192         caching_device=caching_device, name=name, dtype=dtype,\r\n-> 2193         constraint=constraint)\r\n   2194 \r\n   2195 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\r\n    233           dtype=dtype,\r\n    234           expected_shape=expected_shape,\r\n--> 235           constraint=constraint)\r\n    236 \r\n    237   def __repr__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\r\n    341             with ops.name_scope(\"Initializer\"), ops.device(None):\r\n    342               self._initial_value = ops.convert_to_tensor(\r\n--> 343                   initial_value(), name=\"initial_value\", dtype=dtype)\r\n    344               shape = (self._initial_value.get_shape()\r\n    345                        if validate_shape else tensor_shape.unknown_shape())\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>()\r\n    768           initializer = initializer(dtype=dtype)\r\n    769         init_val = lambda: initializer(  # pylint: disable=g-long-lambda\r\n--> 770             shape.as_list(), dtype=dtype, partition_info=partition_info)\r\n    771         variable_dtype = dtype.base_dtype\r\n    772 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/initializers.py in _initializer(shape, dtype, partition_info)\r\n    118     \"\"\"Initializer function.\"\"\"\r\n    119     if not dtype.is_floating:\r\n--> 120       raise TypeError('Cannot create initializer for non-floating point type.')\r\n    121     # Estimating fan_in and fan_out is not possible to do perfectly, but we try.\r\n    122     # This is the right thing for matrix multiply and convolutions.\r\n\r\nTypeError: Cannot create initializer for non-floating point type.\r\n\r\n`\r\n\r\nI think it is related to a previous bug: [#6342](https://github.com/tensorflow/tensorflow/issues/6342)\r\n"}