{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408107332", "html_url": "https://github.com/tensorflow/tensorflow/issues/21124#issuecomment-408107332", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21124", "id": 408107332, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODEwNzMzMg==", "user": {"login": "longchr123", "id": 15262666, "node_id": "MDQ6VXNlcjE1MjYyNjY2", "avatar_url": "https://avatars0.githubusercontent.com/u/15262666?v=4", "gravatar_id": "", "url": "https://api.github.com/users/longchr123", "html_url": "https://github.com/longchr123", "followers_url": "https://api.github.com/users/longchr123/followers", "following_url": "https://api.github.com/users/longchr123/following{/other_user}", "gists_url": "https://api.github.com/users/longchr123/gists{/gist_id}", "starred_url": "https://api.github.com/users/longchr123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/longchr123/subscriptions", "organizations_url": "https://api.github.com/users/longchr123/orgs", "repos_url": "https://api.github.com/users/longchr123/repos", "events_url": "https://api.github.com/users/longchr123/events{/privacy}", "received_events_url": "https://api.github.com/users/longchr123/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-26T14:00:26Z", "updated_at": "2018-07-26T14:03:58Z", "author_association": "NONE", "body_html": "<p><strong>network demo</strong></p>\n<pre><code>weight_decay = 1e-4\ndef relu(x, name='relu6'):\n    return tf.nn.relu6(x, name)\n\ndef batch_norm(x, momentum=0.9, epsilon=1e-5, train=True, name='bn'):\n    return tf.layers.batch_normalization(x,\n                      momentum=momentum,\n                      epsilon=epsilon,\n                      scale=True,\n                      training=train,\n                      name=name)\n\ndef conv2d(input_, output_dim, k_h, k_w, d_h, d_w, stddev=0.02, name='conv2d', bias=False):\n    with tf.variable_scope(name):\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n              regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n              initializer=tf.truncated_normal_initializer(stddev=stddev))\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n        if bias:\n            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\n            conv = tf.nn.bias_add(conv, biases)\n        return conv\ndef conv2d_block(input, out_dim, k, s, is_train, name):\n    with tf.name_scope(name), tf.variable_scope(name):\n        net = conv2d(input, out_dim, k, k, s, s, name='conv2d')\n        net = batch_norm(net, train=is_train, name='bn')\n        net = relu(net)\n        return net\ndef conv_1x1(input, output_dim, name, bias=False):\n    with tf.name_scope(name):\n        return conv2d(input, output_dim, 1,1,1,1, stddev=0.02, name=name, bias=bias)\ndef pwise_block(input, output_dim, is_train, name, bias=False):\n    with tf.name_scope(name), tf.variable_scope(name):\n        out=conv_1x1(input, output_dim, bias=bias, name='pwb')\n        out=batch_norm(out, train=is_train, name='bn')\n        out=relu(out)\n        return out\ndef global_avg(x):\n    with tf.name_scope('global_avg'):\n        net=tf.layers.average_pooling2d(x, x.get_shape()[1:-1], 1)\n        return net\ndef flatten(x):\n    return tf.contrib.layers.flatten(x)\ndef mobilenetv2(inputs, num_output, is_train=True):\n\twith tf.variable_scope('mobilenetv2_128'):\n\t\tnet = conv2d_block(inputs, 32, 3, 2, is_train, name='conv1_1')\n                net = pwise_block(net, 160, is_train, name='conv7_1')\n                net = global_avg(net)\n                net = flatten(conv_1x1(net, num_output, name='logits'))\n\treturn net\n</code></pre>\n<p><strong>test demo</strong></p>\n<pre><code>def read_image_cv(image_dir,sess):  # read image, bbx and landmarks\n    image_names = os.listdir(image_dir)\n    image_names = sorted(image_names)\n    image_paths = [image_dir + name for name in image_names]\n    image_list = []\n    for image_path in image_paths:\n        image = cv.imread(image_path)\n        image = tf.reshape(image, [128, 128, 3])\n        image = tf.cast(image, tf.float64)\n        image = tf.image.per_image_standardization(image)\n        x_test = image.eval(session=sess)\n        image_list.append(x_test)\n    return image_list\ndef predict_test_set_index(meta_path,checkpoint_path, test_image_dir, index):\n    saver = tf.train.import_meta_graph(meta_path)\n    saver.restore(sess, checkpoint_path)\n    test_image_path = [test_image_dir + name for name in sorted(os.listdir(test_image_dir))]\n    with tf.Session() as session:\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n        image = read_image_cv(test_image_dir, session)\n        out = session.run(output, feed_dict={input: image})\n    image_path = test_image_path[index]\n    return out, image_path\ndef predict_test_one(meta_path,checkpoint_path, test_image_path):\n    saver = tf.train.import_meta_graph(meta_path)\n    saver.restore(sess, checkpoint_path)\n    with tf.Session() as session:\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n        image = cv.imread(test_image_path)\n        image = tf.reshape(image, [128, 128, 3])\n        image = tf.cast(image, tf.float64)\n        image = tf.image.per_image_standardization(image)\n        x_test = image.eval(session=session)\n        x_test = x_test[np.newaxis, :]\n        out = session.run(output, feed_dict={input: x_test})\n    return out\ndef test_one_img():\n    image_name = '182121.jpg'\n    output = predict_test_one(meta_path,checkpoint_path, TEST_IMAGINE_PATH+image_name)\n    print(output)\ndef test_set_img():\n    index = 0\n    # there are 100 images in this directory(TEST_IMAGINE_PATH),the index 0 is 182121.jpg\n    output,image_path= predict_test_set_index(meta_path,checkpoint_path, TEST_IMAGINE_PATH,index)\n    print(output[index])\n\ntest_set_img()\ntest_one_img()\n</code></pre>", "body_text": "network demo\nweight_decay = 1e-4\ndef relu(x, name='relu6'):\n    return tf.nn.relu6(x, name)\n\ndef batch_norm(x, momentum=0.9, epsilon=1e-5, train=True, name='bn'):\n    return tf.layers.batch_normalization(x,\n                      momentum=momentum,\n                      epsilon=epsilon,\n                      scale=True,\n                      training=train,\n                      name=name)\n\ndef conv2d(input_, output_dim, k_h, k_w, d_h, d_w, stddev=0.02, name='conv2d', bias=False):\n    with tf.variable_scope(name):\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n              regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\n              initializer=tf.truncated_normal_initializer(stddev=stddev))\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n        if bias:\n            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\n            conv = tf.nn.bias_add(conv, biases)\n        return conv\ndef conv2d_block(input, out_dim, k, s, is_train, name):\n    with tf.name_scope(name), tf.variable_scope(name):\n        net = conv2d(input, out_dim, k, k, s, s, name='conv2d')\n        net = batch_norm(net, train=is_train, name='bn')\n        net = relu(net)\n        return net\ndef conv_1x1(input, output_dim, name, bias=False):\n    with tf.name_scope(name):\n        return conv2d(input, output_dim, 1,1,1,1, stddev=0.02, name=name, bias=bias)\ndef pwise_block(input, output_dim, is_train, name, bias=False):\n    with tf.name_scope(name), tf.variable_scope(name):\n        out=conv_1x1(input, output_dim, bias=bias, name='pwb')\n        out=batch_norm(out, train=is_train, name='bn')\n        out=relu(out)\n        return out\ndef global_avg(x):\n    with tf.name_scope('global_avg'):\n        net=tf.layers.average_pooling2d(x, x.get_shape()[1:-1], 1)\n        return net\ndef flatten(x):\n    return tf.contrib.layers.flatten(x)\ndef mobilenetv2(inputs, num_output, is_train=True):\n\twith tf.variable_scope('mobilenetv2_128'):\n\t\tnet = conv2d_block(inputs, 32, 3, 2, is_train, name='conv1_1')\n                net = pwise_block(net, 160, is_train, name='conv7_1')\n                net = global_avg(net)\n                net = flatten(conv_1x1(net, num_output, name='logits'))\n\treturn net\n\ntest demo\ndef read_image_cv(image_dir,sess):  # read image, bbx and landmarks\n    image_names = os.listdir(image_dir)\n    image_names = sorted(image_names)\n    image_paths = [image_dir + name for name in image_names]\n    image_list = []\n    for image_path in image_paths:\n        image = cv.imread(image_path)\n        image = tf.reshape(image, [128, 128, 3])\n        image = tf.cast(image, tf.float64)\n        image = tf.image.per_image_standardization(image)\n        x_test = image.eval(session=sess)\n        image_list.append(x_test)\n    return image_list\ndef predict_test_set_index(meta_path,checkpoint_path, test_image_dir, index):\n    saver = tf.train.import_meta_graph(meta_path)\n    saver.restore(sess, checkpoint_path)\n    test_image_path = [test_image_dir + name for name in sorted(os.listdir(test_image_dir))]\n    with tf.Session() as session:\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n        image = read_image_cv(test_image_dir, session)\n        out = session.run(output, feed_dict={input: image})\n    image_path = test_image_path[index]\n    return out, image_path\ndef predict_test_one(meta_path,checkpoint_path, test_image_path):\n    saver = tf.train.import_meta_graph(meta_path)\n    saver.restore(sess, checkpoint_path)\n    with tf.Session() as session:\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n        image = cv.imread(test_image_path)\n        image = tf.reshape(image, [128, 128, 3])\n        image = tf.cast(image, tf.float64)\n        image = tf.image.per_image_standardization(image)\n        x_test = image.eval(session=session)\n        x_test = x_test[np.newaxis, :]\n        out = session.run(output, feed_dict={input: x_test})\n    return out\ndef test_one_img():\n    image_name = '182121.jpg'\n    output = predict_test_one(meta_path,checkpoint_path, TEST_IMAGINE_PATH+image_name)\n    print(output)\ndef test_set_img():\n    index = 0\n    # there are 100 images in this directory(TEST_IMAGINE_PATH),the index 0 is 182121.jpg\n    output,image_path= predict_test_set_index(meta_path,checkpoint_path, TEST_IMAGINE_PATH,index)\n    print(output[index])\n\ntest_set_img()\ntest_one_img()", "body": "**network demo**\r\n```\r\nweight_decay = 1e-4\r\ndef relu(x, name='relu6'):\r\n    return tf.nn.relu6(x, name)\r\n\r\ndef batch_norm(x, momentum=0.9, epsilon=1e-5, train=True, name='bn'):\r\n    return tf.layers.batch_normalization(x,\r\n                      momentum=momentum,\r\n                      epsilon=epsilon,\r\n                      scale=True,\r\n                      training=train,\r\n                      name=name)\r\n\r\ndef conv2d(input_, output_dim, k_h, k_w, d_h, d_w, stddev=0.02, name='conv2d', bias=False):\r\n    with tf.variable_scope(name):\r\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\r\n              regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\r\n              initializer=tf.truncated_normal_initializer(stddev=stddev))\r\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\r\n        if bias:\r\n            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\r\n            conv = tf.nn.bias_add(conv, biases)\r\n        return conv\r\ndef conv2d_block(input, out_dim, k, s, is_train, name):\r\n    with tf.name_scope(name), tf.variable_scope(name):\r\n        net = conv2d(input, out_dim, k, k, s, s, name='conv2d')\r\n        net = batch_norm(net, train=is_train, name='bn')\r\n        net = relu(net)\r\n        return net\r\ndef conv_1x1(input, output_dim, name, bias=False):\r\n    with tf.name_scope(name):\r\n        return conv2d(input, output_dim, 1,1,1,1, stddev=0.02, name=name, bias=bias)\r\ndef pwise_block(input, output_dim, is_train, name, bias=False):\r\n    with tf.name_scope(name), tf.variable_scope(name):\r\n        out=conv_1x1(input, output_dim, bias=bias, name='pwb')\r\n        out=batch_norm(out, train=is_train, name='bn')\r\n        out=relu(out)\r\n        return out\r\ndef global_avg(x):\r\n    with tf.name_scope('global_avg'):\r\n        net=tf.layers.average_pooling2d(x, x.get_shape()[1:-1], 1)\r\n        return net\r\ndef flatten(x):\r\n    return tf.contrib.layers.flatten(x)\r\ndef mobilenetv2(inputs, num_output, is_train=True):\r\n\twith tf.variable_scope('mobilenetv2_128'):\r\n\t\tnet = conv2d_block(inputs, 32, 3, 2, is_train, name='conv1_1')\r\n                net = pwise_block(net, 160, is_train, name='conv7_1')\r\n                net = global_avg(net)\r\n                net = flatten(conv_1x1(net, num_output, name='logits'))\r\n\treturn net\r\n```\r\n**test demo**\r\n\r\n```\r\ndef read_image_cv(image_dir,sess):  # read image, bbx and landmarks\r\n    image_names = os.listdir(image_dir)\r\n    image_names = sorted(image_names)\r\n    image_paths = [image_dir + name for name in image_names]\r\n    image_list = []\r\n    for image_path in image_paths:\r\n        image = cv.imread(image_path)\r\n        image = tf.reshape(image, [128, 128, 3])\r\n        image = tf.cast(image, tf.float64)\r\n        image = tf.image.per_image_standardization(image)\r\n        x_test = image.eval(session=sess)\r\n        image_list.append(x_test)\r\n    return image_list\r\ndef predict_test_set_index(meta_path,checkpoint_path, test_image_dir, index):\r\n    saver = tf.train.import_meta_graph(meta_path)\r\n    saver.restore(sess, checkpoint_path)\r\n    test_image_path = [test_image_dir + name for name in sorted(os.listdir(test_image_dir))]\r\n    with tf.Session() as session:\r\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\r\n        image = read_image_cv(test_image_dir, session)\r\n        out = session.run(output, feed_dict={input: image})\r\n    image_path = test_image_path[index]\r\n    return out, image_path\r\ndef predict_test_one(meta_path,checkpoint_path, test_image_path):\r\n    saver = tf.train.import_meta_graph(meta_path)\r\n    saver.restore(sess, checkpoint_path)\r\n    with tf.Session() as session:\r\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\r\n        image = cv.imread(test_image_path)\r\n        image = tf.reshape(image, [128, 128, 3])\r\n        image = tf.cast(image, tf.float64)\r\n        image = tf.image.per_image_standardization(image)\r\n        x_test = image.eval(session=session)\r\n        x_test = x_test[np.newaxis, :]\r\n        out = session.run(output, feed_dict={input: x_test})\r\n    return out\r\ndef test_one_img():\r\n    image_name = '182121.jpg'\r\n    output = predict_test_one(meta_path,checkpoint_path, TEST_IMAGINE_PATH+image_name)\r\n    print(output)\r\ndef test_set_img():\r\n    index = 0\r\n    # there are 100 images in this directory(TEST_IMAGINE_PATH),the index 0 is 182121.jpg\r\n    output,image_path= predict_test_set_index(meta_path,checkpoint_path, TEST_IMAGINE_PATH,index)\r\n    print(output[index])\r\n\r\ntest_set_img()\r\ntest_one_img()\r\n```\r\n"}