{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/87889583", "pull_request_review_id": 8481319, "id": 87889583, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDg3ODg5NTgz", "diff_hunk": "@@ -1388,6 +1391,66 @@ def _crop_and_resize_shape(op):\n ops.RegisterShape('NonMaxSuppression')(common_shapes.call_cpp_shape_fn)\n \n \n+def decode_image(contents, channels=None, ratio=None, fancy_upscaling=None,\n+                 try_recover_truncated=None, acceptable_fraction=None,\n+                 name=None):\n+  \"\"\"Convenience function for `decode_gif`, `decode_jpeg`, and `decode_png`.\n+  Detects whether an image is a GIF, JPEG, or PNG, and performs the appropriate \n+  operation to convert the input bytes `string` into a `Tensor` of type `uint8`.\n+\n+  Note: `decode_gif` returns a 4-D array `[num_frames, height, width, 3]`, as \n+  opposed to `decode_jpeg` and `decode_png`, which return 3-D arrays \n+  `[height, width, num_channels]`. Make sure to take this into account when \n+  constructing your graph if you are intermixing GIF files with JPEG and/or PNG \n+  files.\n+\n+  Args:\n+    contents: 0-D `string`. The encoded image bytes.\n+    channels: Number of color channels for the decoded image.\n+    ratio: Downscaling ratio (only used when decoding JPEG images)\n+    fancy_upscaling: If true use a slower but nicer upscaling of the chroma \n+      planes (yuv420/422 JPEG images only).\n+    try_recover_truncated: If true, try to recover an image from truncated input\n+      (only used when decoding JPEG images).\n+    acceptable_fraction: The minimum required fraction of lines before a \n+      truncated input is accepted (only used when decoding JPEG images).\n+  \n+  Returns:\n+    `Tensor` with type `uint8`. Shape `[height, width, num_channels]` for JPEG \n+      and PNG images. Shape `[num_frames, height, width, 3]` for GIF images.\n+  \"\"\"\n+  with ops.name_scope(name, 'decode_image') as scope:\n+    def _gif():\n+      return gen_image_ops.decode_gif(contents)\n+\n+    def _jpeg():\n+      return gen_image_ops.decode_jpeg(contents, channels, ratio, \n+                                       fancy_upscaling, try_recover_truncated, \n+                                       acceptable_fraction)\n+    def _png():\n+      return gen_image_ops.decode_png(contents, channels, dtypes.uint8)\n+\n+    is_gif = math_ops.equal(gen_string_ops.substr(contents, 0, 4),\n+                            b'\\x47\\x49\\x46\\x38')\n+    is_jpeg = math_ops.equal(gen_string_ops.substr(contents, 0, 4), \n+                            b'\\xff\\xd8\\xff\\xe0')\n+    is_png = math_ops.equal(gen_string_ops.substr(contents, 0, 8), \n+                            b'\\211PNG\\r\\n\\032\\n')\n+    is_decodable = math_ops.logical_or(is_gif, is_jpeg)\n+    is_decodable = math_ops.logical_or(is_decodable, is_png)\n+    assert_decodable = control_flow_ops.Assert(is_decodable, \n+                                               [b'Unable to decode bytes as a '\n+                                                b'PNG or JPEG. Is the file '\n+                                                b'encoded properly?'])\n+    # Leaving default case to be decode_png\n+    cases = [(is_gif, _gif),\n+             (is_jpeg, _jpeg),\n+            ]\n+    with ops.control_dependencies([assert_decodable]):\n+      return control_flow_ops.case(cases, _png, exclusive=True, \n+                                   name=scope)", "path": "tensorflow/python/ops/image_ops.py", "position": null, "original_position": 78, "commit_id": "30a964bda83860f7398189669c3cd44afed1c0d8", "original_commit_id": "9f2f2f2ab1dd174e8de128ae7f568b76273dde2b", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "body": "Use nested cases in the following order for speed:\n1. Check for jpeg, decode jpeg if so.\n2. Check for png, decode png if so.\n3. Check for gif, decode gif if so.\n4. Throw the assertion.\n\nThe point is that we should waste time checking for gif or png in the jpeg case, which is the most common.\n", "created_at": "2016-11-14T20:50:41Z", "updated_at": "2016-11-30T21:00:32Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4222#discussion_r87889583", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4222", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/87889583"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4222#discussion_r87889583"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4222"}}, "body_html": "<p>Use nested cases in the following order for speed:</p>\n<ol>\n<li>Check for jpeg, decode jpeg if so.</li>\n<li>Check for png, decode png if so.</li>\n<li>Check for gif, decode gif if so.</li>\n<li>Throw the assertion.</li>\n</ol>\n<p>The point is that we should waste time checking for gif or png in the jpeg case, which is the most common.</p>", "body_text": "Use nested cases in the following order for speed:\n\nCheck for jpeg, decode jpeg if so.\nCheck for png, decode png if so.\nCheck for gif, decode gif if so.\nThrow the assertion.\n\nThe point is that we should waste time checking for gif or png in the jpeg case, which is the most common."}