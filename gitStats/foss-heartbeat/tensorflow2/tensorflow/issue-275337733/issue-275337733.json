{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14719", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14719/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14719/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14719/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14719", "id": 275337733, "node_id": "MDU6SXNzdWUyNzUzMzc3MzM=", "number": 14719, "title": "Tensorflow Lite demo app with inception-v3/Mobilenet_v1 (float) model crashes", "user": {"login": "atrah22", "id": 26916352, "node_id": "MDQ6VXNlcjI2OTE2MzUy", "avatar_url": "https://avatars0.githubusercontent.com/u/26916352?v=4", "gravatar_id": "", "url": "https://api.github.com/users/atrah22", "html_url": "https://github.com/atrah22", "followers_url": "https://api.github.com/users/atrah22/followers", "following_url": "https://api.github.com/users/atrah22/following{/other_user}", "gists_url": "https://api.github.com/users/atrah22/gists{/gist_id}", "starred_url": "https://api.github.com/users/atrah22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/atrah22/subscriptions", "organizations_url": "https://api.github.com/users/atrah22/orgs", "repos_url": "https://api.github.com/users/atrah22/repos", "events_url": "https://api.github.com/users/atrah22/events{/privacy}", "received_events_url": "https://api.github.com/users/atrah22/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 20, "created_at": "2017-11-20T12:23:26Z", "updated_at": "2018-08-21T14:36:15Z", "closed_at": "2017-11-30T01:16:43Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 14.04</li>\n<li><strong>Python version</strong>: 3.4.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.4</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Device: Galaxy S8<br>\nI downloaded the \"Inception V3 Slim 2016\" from <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md</a> . I pushed the imagenet_2015_label_strings.txt and the \"inceptionv3_non_slim_2015.tflite\" to the asset folder</p>\n<p>I edited the ImageClassifier.java of tflite demo app. The changes are the followings:<br>\nprivate static final String MODEL_PATH = \"/inceptionv3_non_slim_2015.tflite\";<br>\nstatic final int DIM_IMG_SIZE_X = 299;<br>\nstatic final int DIM_IMG_SIZE_Y = 299;</p>\n<p>The app hangs when it starts! (I could run the app with the default mobilenet quantized graph).<br>\nSimilar is the case with mobilenet_v1_224_Float graph as well (the app hangs or crashes). I assume, the float model graph is not yet supported by TF Lite. However, in the documentation its written that it does support float for most operations. I am thinking the error is due to image pre-processing output and input size of float model grpah. The error log is stated below:</p>\n<p>The Error log:<br>\n11-21 14:31:43.034 2111-2416/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground<br>\nProcess: android.example.com.tflitecamerademo, PID: 2111<br>\njava.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 1072812 bytes, but found 268203 bytes.<br>\nat org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)<br>\nat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)<br>\nat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)<br>\nat org.tensorflow.lite.Interpreter.run(Interpreter.java:93)<br>\nat com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:112)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)<br>\nat com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)<br>\nat android.os.Handler.handleCallback(Handler.java:751)<br>\nat android.os.Handler.dispatchMessage(Handler.java:95)<br>\nat android.os.Looper.loop(Looper.java:154)<br>\nat android.os.HandlerThread.run(HandlerThread.java:61)</p>\n<h3>Additional Questions:</h3>\n<ol>\n<li>On the app the the tensorflow lite graph format is \".tflite\". However, on the documentation <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md</a> the format is written as \".lite\"</li>\n</ol>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 14.04\nPython version: 3.4.3\nBazel version (if compiling from source): 0.5.4\n\nDescribe the problem\nDevice: Galaxy S8\nI downloaded the \"Inception V3 Slim 2016\" from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md . I pushed the imagenet_2015_label_strings.txt and the \"inceptionv3_non_slim_2015.tflite\" to the asset folder\nI edited the ImageClassifier.java of tflite demo app. The changes are the followings:\nprivate static final String MODEL_PATH = \"/inceptionv3_non_slim_2015.tflite\";\nstatic final int DIM_IMG_SIZE_X = 299;\nstatic final int DIM_IMG_SIZE_Y = 299;\nThe app hangs when it starts! (I could run the app with the default mobilenet quantized graph).\nSimilar is the case with mobilenet_v1_224_Float graph as well (the app hangs or crashes). I assume, the float model graph is not yet supported by TF Lite. However, in the documentation its written that it does support float for most operations. I am thinking the error is due to image pre-processing output and input size of float model grpah. The error log is stated below:\nThe Error log:\n11-21 14:31:43.034 2111-2416/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground\nProcess: android.example.com.tflitecamerademo, PID: 2111\njava.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 1072812 bytes, but found 268203 bytes.\nat org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)\nat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)\nat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\nat org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\nat com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:112)\nat com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)\nat com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)\nat com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)\nat android.os.Handler.handleCallback(Handler.java:751)\nat android.os.Handler.dispatchMessage(Handler.java:95)\nat android.os.Looper.loop(Looper.java:154)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nAdditional Questions:\n\nOn the app the the tensorflow lite graph format is \".tflite\". However, on the documentation https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md the format is written as \".lite\"", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 14.04\r\n- **Python version**: 3.4.3\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n\r\n\r\n### Describe the problem\r\nDevice: Galaxy S8\r\nI downloaded the \"Inception V3 Slim 2016\" from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md . I pushed the imagenet_2015_label_strings.txt and the \"inceptionv3_non_slim_2015.tflite\" to the asset folder\r\n\r\nI edited the ImageClassifier.java of tflite demo app. The changes are the followings:\r\nprivate static final String MODEL_PATH = \"/inceptionv3_non_slim_2015.tflite\";\r\nstatic final int DIM_IMG_SIZE_X = 299;\r\nstatic final int DIM_IMG_SIZE_Y = 299;\r\n\r\nThe app hangs when it starts! (I could run the app with the default mobilenet quantized graph).\r\nSimilar is the case with mobilenet_v1_224_Float graph as well (the app hangs or crashes). I assume, the float model graph is not yet supported by TF Lite. However, in the documentation its written that it does support float for most operations. I am thinking the error is due to image pre-processing output and input size of float model grpah. The error log is stated below:\r\n\r\nThe Error log:\r\n11-21 14:31:43.034 2111-2416/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground\r\n                                                                                    Process: android.example.com.tflitecamerademo, PID: 2111\r\n                                                                                    java.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 1072812 bytes, but found 268203 bytes.\r\n                                                                                        at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)\r\n                                                                                        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)\r\n                                                                                        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\r\n                                                                                        at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\r\n                                                                                        at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:112)\r\n                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)\r\n                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)\r\n                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)\r\n                                                                                        at android.os.Handler.handleCallback(Handler.java:751)\r\n                                                                                        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                                        at android.os.Looper.loop(Looper.java:154)\r\n                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n\r\n\r\n### Additional Questions:\r\n1) On the app the the tensorflow lite graph format is \".tflite\". However, on the documentation https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md the format is written as \".lite\"\r\n\r\n\r\n"}