{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322552683", "html_url": "https://github.com/tensorflow/tensorflow/issues/11650#issuecomment-322552683", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11650", "id": 322552683, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjU1MjY4Mw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-15T18:41:26Z", "updated_at": "2017-08-15T18:41:26Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">I'm testing a fix for LSTM-type cells now.  GRU, as you suggested, is\nharder to fix.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mon, Aug 14, 2017 at 12:52 PM, davidhstern ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/santon834\">@santon834</a> &lt;<a href=\"https://github.com/santon834\">https://github.com/santon834</a>&gt; You might want to check out\n <a href=\"https://arxiv.org/pdf/1603.05118.pdf\">https://arxiv.org/pdf/1603.05118.pdf</a>\n\n It looks like not dropping the LSTM memory state might actually be the key\n to getting good performance from dropout in LSTMs. Using one mask per\n sequence might be redundant as long as you do this.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"244452691\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11650\" href=\"https://github.com/tensorflow/tensorflow/issues/11650#issuecomment-322291027\">#11650 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim65PMlLDU66Zf5WvgYO3W_BBb4V3ks5sYKVtgaJpZM4Oee9R\">https://github.com/notifications/unsubscribe-auth/ABtim65PMlLDU66Zf5WvgYO3W_BBb4V3ks5sYKVtgaJpZM4Oee9R</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "I'm testing a fix for LSTM-type cells now.  GRU, as you suggested, is\nharder to fix.\n\u2026\nOn Mon, Aug 14, 2017 at 12:52 PM, davidhstern ***@***.***> wrote:\n @santon834 <https://github.com/santon834> You might want to check out\n https://arxiv.org/pdf/1603.05118.pdf\n\n It looks like not dropping the LSTM memory state might actually be the key\n to getting good performance from dropout in LSTMs. Using one mask per\n sequence might be redundant as long as you do this.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#11650 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim65PMlLDU66Zf5WvgYO3W_BBb4V3ks5sYKVtgaJpZM4Oee9R>\n .", "body": "I'm testing a fix for LSTM-type cells now.  GRU, as you suggested, is\nharder to fix.\n\nOn Mon, Aug 14, 2017 at 12:52 PM, davidhstern <notifications@github.com>\nwrote:\n\n> @santon834 <https://github.com/santon834> You might want to check out\n> https://arxiv.org/pdf/1603.05118.pdf\n>\n> It looks like not dropping the LSTM memory state might actually be the key\n> to getting good performance from dropout in LSTMs. Using one mask per\n> sequence might be redundant as long as you do this.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11650#issuecomment-322291027>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim65PMlLDU66Zf5WvgYO3W_BBb4V3ks5sYKVtgaJpZM4Oee9R>\n> .\n>\n"}