{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408583055", "html_url": "https://github.com/tensorflow/tensorflow/issues/10805#issuecomment-408583055", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10805", "id": 408583055, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODU4MzA1NQ==", "user": {"login": "sharvil", "id": 391004, "node_id": "MDQ6VXNlcjM5MTAwNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/391004?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharvil", "html_url": "https://github.com/sharvil", "followers_url": "https://api.github.com/users/sharvil/followers", "following_url": "https://api.github.com/users/sharvil/following{/other_user}", "gists_url": "https://api.github.com/users/sharvil/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharvil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharvil/subscriptions", "organizations_url": "https://api.github.com/users/sharvil/orgs", "repos_url": "https://api.github.com/users/sharvil/repos", "events_url": "https://api.github.com/users/sharvil/events{/privacy}", "received_events_url": "https://api.github.com/users/sharvil/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-28T05:02:48Z", "updated_at": "2018-07-28T05:02:48Z", "author_association": "NONE", "body_html": "<p>I also need to write a custom attention mechanism and ran into this issue. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a>, I'm unclear how copy/pasting the implementation will break external users any less than simply exposing the implementation publicly.</p>\n<p>If you add a new method/property to <code>_BaseAttentionMechanism</code> and make use of it in <code>AttentionWrapper</code>, all external users who followed the advice to copy the implementation will be broken. Worse yet, if you changed the semantics of an existing method, users who copied the code could be broken silently. In such cases, subclassing the original <code>_BaseAttentionMechanism</code> would have been a much better solution for everyone involved.</p>\n<p>That said, I understand if you're not prepared to define a public-facing interface to plug in custom attention mechanisms. A comment to that effect in <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionMechanism\" rel=\"nofollow\">AttentionMechanism</a> would be much appreciated.</p>", "body_text": "I also need to write a custom attention mechanism and ran into this issue. @ebrevdo, I'm unclear how copy/pasting the implementation will break external users any less than simply exposing the implementation publicly.\nIf you add a new method/property to _BaseAttentionMechanism and make use of it in AttentionWrapper, all external users who followed the advice to copy the implementation will be broken. Worse yet, if you changed the semantics of an existing method, users who copied the code could be broken silently. In such cases, subclassing the original _BaseAttentionMechanism would have been a much better solution for everyone involved.\nThat said, I understand if you're not prepared to define a public-facing interface to plug in custom attention mechanisms. A comment to that effect in AttentionMechanism would be much appreciated.", "body": "I also need to write a custom attention mechanism and ran into this issue. @ebrevdo, I'm unclear how copy/pasting the implementation will break external users any less than simply exposing the implementation publicly.\r\n\r\nIf you add a new method/property to `_BaseAttentionMechanism` and make use of it in `AttentionWrapper`, all external users who followed the advice to copy the implementation will be broken. Worse yet, if you changed the semantics of an existing method, users who copied the code could be broken silently. In such cases, subclassing the original `_BaseAttentionMechanism` would have been a much better solution for everyone involved.\r\n\r\nThat said, I understand if you're not prepared to define a public-facing interface to plug in custom attention mechanisms. A comment to that effect in [AttentionMechanism](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionMechanism) would be much appreciated."}