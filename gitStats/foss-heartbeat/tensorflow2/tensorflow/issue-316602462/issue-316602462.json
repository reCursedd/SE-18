{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18779", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18779/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18779/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18779/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18779", "id": 316602462, "node_id": "MDU6SXNzdWUzMTY2MDI0NjI=", "number": 18779, "title": "Feature Request / Question: IP-Cam object detection (How-to)", "user": {"login": "SJRogue", "id": 10557456, "node_id": "MDQ6VXNlcjEwNTU3NDU2", "avatar_url": "https://avatars1.githubusercontent.com/u/10557456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SJRogue", "html_url": "https://github.com/SJRogue", "followers_url": "https://api.github.com/users/SJRogue/followers", "following_url": "https://api.github.com/users/SJRogue/following{/other_user}", "gists_url": "https://api.github.com/users/SJRogue/gists{/gist_id}", "starred_url": "https://api.github.com/users/SJRogue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SJRogue/subscriptions", "organizations_url": "https://api.github.com/users/SJRogue/orgs", "repos_url": "https://api.github.com/users/SJRogue/repos", "events_url": "https://api.github.com/users/SJRogue/events{/privacy}", "received_events_url": "https://api.github.com/users/SJRogue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-22T18:40:05Z", "updated_at": "2018-06-21T22:44:05Z", "closed_at": "2018-04-24T23:43:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No, I've followed a tutorial and haven't touched the base setup of it. <a href=\"https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\">https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10</a></li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0</li>\n<li><strong>Python version</strong>:  3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  Couldn't get the capture script to return this</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: b'unknown'</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 7.05</li>\n<li><strong>GPU model and memory</strong>: Nvidia GeForce GTX 960M / 2Gb?</li>\n<li><strong>Exact command to reproduce</strong>: No idea</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Hello Tensorflow, my question is pretty straightforward and maybe was already answered somewhere, but I'm not finding the answer : )).. Hence, I turn to you. If there is already a clear guide out there on how to do it, could you point me in the right direction?</p>\n<p>Given this script that launches the object detection with a webcam, how do I modify it to launch the detector by giving an IP address as input and receiving that video feed (and bounding boxes) as output? (Source in the last section).</p>\n<p>I am aware we can always set an IP cam to be a webcam in the machine's webcam list, but I'd like to access the IP address directly. Can this be done? Is this already implemented?</p>\n<p>Thanks in advance!</p>\n<h3>Source code / logs</h3>\n<p>import os<br>\nimport cv2<br>\nimport numpy as np<br>\nimport tensorflow as tf<br>\nimport sys</p>\n<p>sys.path.append(\"..\")</p>\n<p>from utils import label_map_util<br>\nfrom utils import visualization_utils as vis_util</p>\n<p>MODEL_NAME = 'inference_graph'</p>\n<p>CWD_PATH = os.getcwd()</p>\n<p>PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')</p>\n<p>PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')</p>\n<p>NUM_CLASSES = 6</p>\n<p>label_map = label_map_util.load_labelmap(PATH_TO_LABELS)<br>\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)<br>\ncategory_index = label_map_util.create_category_index(categories)</p>\n<p>detection_graph = tf.Graph()<br>\nwith detection_graph.as_default():<br>\nod_graph_def = tf.GraphDef()<br>\nwith tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:<br>\nserialized_graph = fid.read()<br>\nod_graph_def.ParseFromString(serialized_graph)<br>\ntf.import_graph_def(od_graph_def, name='')</p>\n<pre><code>sess = tf.Session(graph=detection_graph)\n</code></pre>\n<p>image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')</p>\n<p>detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')</p>\n<p>detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')<br>\ndetection_classes = detection_graph.get_tensor_by_name('detection_classes:0')</p>\n<p>num_detections = detection_graph.get_tensor_by_name('num_detections:0')</p>\n<p>video = cv2.VideoCapture(0)<br>\nret = video.set(3,1280)<br>\nret = video.set(4,720)</p>\n<p>while(True):</p>\n<pre><code>ret, frame = video.read()\nframe_expanded = np.expand_dims(frame, axis=0)\n\n\n(boxes, scores, classes, num) = sess.run(\n    [detection_boxes, detection_scores, detection_classes, num_detections],\n    feed_dict={image_tensor: frame_expanded})\n\n\nvis_util.visualize_boxes_and_labels_on_image_array(\n    frame,\n    np.squeeze(boxes),\n    np.squeeze(classes).astype(np.int32),\n    np.squeeze(scores),\n    category_index,\n    use_normalized_coordinates=True,\n    line_thickness=8,\n    min_score_thresh=0.85)\n\n\ncv2.imshow('Object detector', frame)\n\nif cv2.waitKey(1) == ord('q'):\n    break\n</code></pre>\n<p>video.release()<br>\ncv2.destroyAllWindows()</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No, I've followed a tutorial and haven't touched the base setup of it. https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.5.0\nPython version:  3.6\nBazel version (if compiling from source):  Couldn't get the capture script to return this\nGCC/Compiler version (if compiling from source): b'unknown'\nCUDA/cuDNN version: 9.0 / 7.05\nGPU model and memory: Nvidia GeForce GTX 960M / 2Gb?\nExact command to reproduce: No idea\n\nDescribe the problem\nHello Tensorflow, my question is pretty straightforward and maybe was already answered somewhere, but I'm not finding the answer : )).. Hence, I turn to you. If there is already a clear guide out there on how to do it, could you point me in the right direction?\nGiven this script that launches the object detection with a webcam, how do I modify it to launch the detector by giving an IP address as input and receiving that video feed (and bounding boxes) as output? (Source in the last section).\nI am aware we can always set an IP cam to be a webcam in the machine's webcam list, but I'd like to access the IP address directly. Can this be done? Is this already implemented?\nThanks in advance!\nSource code / logs\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport sys\nsys.path.append(\"..\")\nfrom utils import label_map_util\nfrom utils import visualization_utils as vis_util\nMODEL_NAME = 'inference_graph'\nCWD_PATH = os.getcwd()\nPATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\nPATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\nNUM_CLASSES = 6\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\nod_graph_def = tf.GraphDef()\nwith tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\nserialized_graph = fid.read()\nod_graph_def.ParseFromString(serialized_graph)\ntf.import_graph_def(od_graph_def, name='')\nsess = tf.Session(graph=detection_graph)\n\nimage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\ndetection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\ndetection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\ndetection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\nnum_detections = detection_graph.get_tensor_by_name('num_detections:0')\nvideo = cv2.VideoCapture(0)\nret = video.set(3,1280)\nret = video.set(4,720)\nwhile(True):\nret, frame = video.read()\nframe_expanded = np.expand_dims(frame, axis=0)\n\n\n(boxes, scores, classes, num) = sess.run(\n    [detection_boxes, detection_scores, detection_classes, num_detections],\n    feed_dict={image_tensor: frame_expanded})\n\n\nvis_util.visualize_boxes_and_labels_on_image_array(\n    frame,\n    np.squeeze(boxes),\n    np.squeeze(classes).astype(np.int32),\n    np.squeeze(scores),\n    category_index,\n    use_normalized_coordinates=True,\n    line_thickness=8,\n    min_score_thresh=0.85)\n\n\ncv2.imshow('Object detector', frame)\n\nif cv2.waitKey(1) == ord('q'):\n    break\n\nvideo.release()\ncv2.destroyAllWindows()", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I've followed a tutorial and haven't touched the base setup of it. https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**:  Couldn't get the capture script to return this\r\n- **GCC/Compiler version (if compiling from source)**: b'unknown'\r\n- **CUDA/cuDNN version**: 9.0 / 7.05\r\n- **GPU model and memory**: Nvidia GeForce GTX 960M / 2Gb?\r\n- **Exact command to reproduce**: No idea\r\n\r\n### Describe the problem\r\n\r\nHello Tensorflow, my question is pretty straightforward and maybe was already answered somewhere, but I'm not finding the answer : )).. Hence, I turn to you. If there is already a clear guide out there on how to do it, could you point me in the right direction?\r\n\r\nGiven this script that launches the object detection with a webcam, how do I modify it to launch the detector by giving an IP address as input and receiving that video feed (and bounding boxes) as output? (Source in the last section).\r\n\r\nI am aware we can always set an IP cam to be a webcam in the machine's webcam list, but I'd like to access the IP address directly. Can this be done? Is this already implemented? \r\n\r\nThanks in advance!\r\n\r\n\r\n### Source code / logs\r\n \r\n\r\nimport os\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport sys\r\n\r\n\r\nsys.path.append(\"..\")\r\n\r\n\r\nfrom utils import label_map_util\r\nfrom utils import visualization_utils as vis_util\r\n\r\n\r\nMODEL_NAME = 'inference_graph'\r\n\r\nCWD_PATH = os.getcwd()\r\n\r\nPATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\r\n\r\n\r\nPATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\r\n\r\n\r\nNUM_CLASSES = 6\r\n\r\n\r\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\ncategory_index = label_map_util.create_category_index(categories)\r\n\r\ndetection_graph = tf.Graph()\r\nwith detection_graph.as_default():\r\n    od_graph_def = tf.GraphDef()\r\n    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n\r\n    sess = tf.Session(graph=detection_graph)\r\n\r\n\r\n\r\nimage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\n\r\n\r\ndetection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\n\r\ndetection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\ndetection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n\r\n\r\nnum_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n\r\n\r\nvideo = cv2.VideoCapture(0)\r\nret = video.set(3,1280)\r\nret = video.set(4,720)\r\n\r\nwhile(True):\r\n\r\n    ret, frame = video.read()\r\n    frame_expanded = np.expand_dims(frame, axis=0)\r\n\r\n   \r\n    (boxes, scores, classes, num) = sess.run(\r\n        [detection_boxes, detection_scores, detection_classes, num_detections],\r\n        feed_dict={image_tensor: frame_expanded})\r\n\r\n\r\n    vis_util.visualize_boxes_and_labels_on_image_array(\r\n        frame,\r\n        np.squeeze(boxes),\r\n        np.squeeze(classes).astype(np.int32),\r\n        np.squeeze(scores),\r\n        category_index,\r\n        use_normalized_coordinates=True,\r\n        line_thickness=8,\r\n        min_score_thresh=0.85)\r\n\r\n   \r\n    cv2.imshow('Object detector', frame)\r\n\r\n    if cv2.waitKey(1) == ord('q'):\r\n        break\r\n\r\nvideo.release()\r\ncv2.destroyAllWindows()\r\n\r\n"}