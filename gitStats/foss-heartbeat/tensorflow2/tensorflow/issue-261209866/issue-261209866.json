{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13354", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13354/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13354/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13354/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13354", "id": 261209866, "node_id": "MDU6SXNzdWUyNjEyMDk4NjY=", "number": 13354, "title": "Dynamic loading / freeing GPU devices", "user": {"login": "chhwang", "id": 8018170, "node_id": "MDQ6VXNlcjgwMTgxNzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/8018170?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chhwang", "html_url": "https://github.com/chhwang", "followers_url": "https://api.github.com/users/chhwang/followers", "following_url": "https://api.github.com/users/chhwang/following{/other_user}", "gists_url": "https://api.github.com/users/chhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/chhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chhwang/subscriptions", "organizations_url": "https://api.github.com/users/chhwang/orgs", "repos_url": "https://api.github.com/users/chhwang/repos", "events_url": "https://api.github.com/users/chhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/chhwang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-28T06:47:12Z", "updated_at": "2017-10-07T19:34:16Z", "closed_at": "2017-10-07T19:34:16Z", "author_association": "NONE", "body_html": "<p>I wonder whether there are any on-going works or plans on dynamic loading / freeing GPUs.</p>\n<p>What I mean by dynamic loading is a client-side feature <code>sess.load_device()</code> like below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> start with /gpu:0 only</span>\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>0<span class=\"pl-pds\">'</span></span>\nsess <span class=\"pl-k\">=</span> tf.Session()\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n  a <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.5</span>)\nsess.run(a)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> add new device /gpu:1</span>\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>0,1<span class=\"pl-pds\">'</span></span>\nsess.load_device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:1<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:1<span class=\"pl-pds\">'</span></span>):\n  b <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.3</span>)\nsess.run(a <span class=\"pl-k\">+</span> b)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> free device /gpu:0</span>\nsess.free_device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>)</pre></div>\n<p>I'm trying to test whether I can run <code>BaseGPUDeviceFactory::CreateDevices()</code> after the session is created, but if there are any better ways, would you please give me some hints?</p>", "body_text": "I wonder whether there are any on-going works or plans on dynamic loading / freeing GPUs.\nWhat I mean by dynamic loading is a client-side feature sess.load_device() like below:\n# start with /gpu:0 only\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nsess = tf.Session()\nwith tf.device('/gpu:0'):\n  a = tf.constant(0.5)\nsess.run(a)\n\n# add new device /gpu:1\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\nsess.load_device('/gpu:1')\nwith tf.device('/gpu:1'):\n  b = tf.constant(0.3)\nsess.run(a + b)\n\n# free device /gpu:0\nsess.free_device('/gpu:0')\nI'm trying to test whether I can run BaseGPUDeviceFactory::CreateDevices() after the session is created, but if there are any better ways, would you please give me some hints?", "body": "I wonder whether there are any on-going works or plans on dynamic loading / freeing GPUs.\r\n\r\nWhat I mean by dynamic loading is a client-side feature <code>sess.load_device()</code> like below:\r\n\r\n```python\r\n# start with /gpu:0 only\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\nsess = tf.Session()\r\nwith tf.device('/gpu:0'):\r\n  a = tf.constant(0.5)\r\nsess.run(a)\r\n\r\n# add new device /gpu:1\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\r\nsess.load_device('/gpu:1')\r\nwith tf.device('/gpu:1'):\r\n  b = tf.constant(0.3)\r\nsess.run(a + b)\r\n\r\n# free device /gpu:0\r\nsess.free_device('/gpu:0')\r\n```\r\n\r\nI'm trying to test whether I can run <code>BaseGPUDeviceFactory::CreateDevices()</code> after the session is created, but if there are any better ways, would you please give me some hints?"}