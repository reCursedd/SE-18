{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13308", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13308/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13308/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13308/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13308", "id": 260571953, "node_id": "MDU6SXNzdWUyNjA1NzE5NTM=", "number": 13308, "title": "Attempting to use the CPU Work Sharder segfaults on g++ 5.4.0", "user": {"login": "sjperkins", "id": 3530212, "node_id": "MDQ6VXNlcjM1MzAyMTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/3530212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sjperkins", "html_url": "https://github.com/sjperkins", "followers_url": "https://api.github.com/users/sjperkins/followers", "following_url": "https://api.github.com/users/sjperkins/following{/other_user}", "gists_url": "https://api.github.com/users/sjperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/sjperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sjperkins/subscriptions", "organizations_url": "https://api.github.com/users/sjperkins/orgs", "repos_url": "https://api.github.com/users/sjperkins/repos", "events_url": "https://api.github.com/users/sjperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/sjperkins/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 22, "created_at": "2017-09-26T10:25:09Z", "updated_at": "2018-11-11T18:39:08Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n</ul>\n<p>I've adapted the ZeroOut operator from the <a href=\"https://www.tensorflow.org/extend/adding_an_op\" rel=\"nofollow\">Adding a New Op</a> example.</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Linux Ubuntu 16.04</p>\n<ul>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n</ul>\n<p>binary GPU 1.3.0</p>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n</ul>\n<p>$ python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\n('v1.3.0-rc2-20-g0787eee', '1.3.0')</p>\n<ul>\n<li><strong>Python version</strong>:</li>\n</ul>\n<p>2.7.12</p>\n<ul>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n</ul>\n<p>N/A</p>\n<ul>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n</ul>\n<p>N/A</p>\n<ul>\n<li><strong>GPU model and memory</strong>:</li>\n</ul>\n<p>N/A</p>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>Test operator: <a href=\"https://github.com/tensorflow/tensorflow/files/1332745/shard_fails.zip\">shard_fails.zip</a></p>\n<div class=\"highlight highlight-source-shell\"><pre>$ make\n$ python test_op.py</pre></div>\n<h3>Describe the problem</h3>\n<p>When the above C++ operator runs, it'll print the number of threads in the pool (8) and then segfault on the Shard call.</p>\n<h3>Source code / logs</h3>\n<p>C++ operator code:</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">define</span> <span class=\"pl-en\">EIGEN_USE_THREADS</span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/lib/core/threadpool.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op_kernel.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/shape_inference.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/util/work_sharder.h<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tensorflow</span><span class=\"pl-k\">;</span>\n\n<span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ZeroOut<span class=\"pl-pds\">\"</span></span>)\n    .Input(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>to_zero: int32<span class=\"pl-pds\">\"</span></span>)\n    .Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>zeroed: int32<span class=\"pl-pds\">\"</span></span>)\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c-&gt;<span class=\"pl-c1\">set_output</span>(<span class=\"pl-c1\">0</span>, c-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>));\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">Status::OK</span>();\n    });\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ZeroOutOp</span> : <span class=\"pl-k\">public</span> <span class=\"pl-en\">OpKernel</span> {\n <span class=\"pl-k\">public:</span>\n  <span class=\"pl-k\">explicit</span> <span class=\"pl-en\">ZeroOutOp</span>(OpKernelConstruction* context) : OpKernel(context) {}\n\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">Compute</span>(OpKernelContext* context) <span class=\"pl-k\">override</span> {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Grab the input tensor</span>\n    <span class=\"pl-k\">const</span> Tensor&amp; input_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>);\n    <span class=\"pl-k\">auto</span> input = input_tensor.<span class=\"pl-smi\">flat</span>&lt;int32&gt;();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Create an output tensor</span>\n    Tensor* output_tensor = <span class=\"pl-c1\">NULL</span>;\n    <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">0</span>, input_tensor.<span class=\"pl-c1\">shape</span>(),\n                                                     &amp;output_tensor));\n    <span class=\"pl-k\">auto</span> output_flat = output_tensor-&gt;<span class=\"pl-smi\">flat</span>&lt;int32&gt;();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Set all but the first element of the output tensor to 0.</span>\n    <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N = input.<span class=\"pl-c1\">size</span>();\n\n    <span class=\"pl-k\">auto</span> pool = context-&gt;<span class=\"pl-c1\">device</span>()-&gt;<span class=\"pl-c1\">tensorflow_cpu_worker_threads</span>()-&gt;<span class=\"pl-smi\">workers</span>;\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Pool Threads %d<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>, pool-&gt;<span class=\"pl-c1\">NumThreads</span>());\n    <span class=\"pl-c1\">Shard</span>(pool-&gt;<span class=\"pl-c1\">NumThreads</span>(), pool, N, <span class=\"pl-c1\">10</span>, [&amp;](int64 start, int64 end) {\n        <span class=\"pl-k\">for</span>(int64 i=start; i&lt;end; ++i)\n            { <span class=\"pl-c1\">output_flat</span>(i) = <span class=\"pl-c1\">0</span>; }\n    });\n\n    <span class=\"pl-k\">if</span>(N &gt; <span class=\"pl-c1\">0</span>)\n        { <span class=\"pl-c1\">output_flat</span>(<span class=\"pl-c1\">0</span>) = <span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>); }\n  }\n};\n\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ZeroOut<span class=\"pl-pds\">\"</span></span>).Device(DEVICE_CPU), ZeroOutOp);</pre></div>\n<p>See below the gdb trace:</p>\n<pre><code>Core was generated by `python test_op.py'.\nProgram terminated with signal SIGSEGV, Segmentation fault.\n#0  std::_Function_handler&lt;void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long long&amp;&amp;, std::_Any_data const&amp;) (__functor=..., __args#0=&lt;unknown type in tfop.so, CU 0x0, DIE 0x41c73&gt;, __args#1=&lt;unknown type in tfop.so, CU 0x0, DIE 0x41c78&gt;) at /usr/include/c++/5/functional:1871\n1871\t\t(*_Base::_M_get_pointer(__functor))(\n[Current thread is 1 (Thread 0x7f38a6605700 (LWP 3771))]\n(gdb) bt\n#0  std::_Function_handler&lt;void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long long&amp;&amp;, std::_Any_data const&amp;) (__functor=..., __args#0=&lt;unknown type in tfop.so, CU 0x0, DIE 0x41c73&gt;, __args#1=&lt;unknown type in tfop.so, CU 0x0, DIE 0x41c78&gt;) at /usr/include/c++/5/functional:1871\n#1  0x00007f3879dcc75d in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#2  0x00007f3879dcc93f in tensorflow::thread::ThreadPool::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#3  0x00007f3879d4d995 in tensorflow::Shard(int, tensorflow::thread::ThreadPool*, long long, long long, std::function&lt;void (long long, long long)&gt;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#4  0x00007f3850bfb79e in ZeroOutOp::Compute (this=0x62dacc0, context=0x7ffd1a20fe30) at tf_op.cpp:42\n#5  0x00007f3879a2563c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#6  0x00007f38799f5a58 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#7  0x00007f38799f61fa in std::_Function_handler&lt;void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector&lt;tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8&gt; const&amp;, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#8  0x00007f3879a035c4 in std::_Function_handler&lt;void (std::function&lt;void ()&gt;), tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;tensorflow::Tensor, std::allocator&lt;tensorflow::Tensor&gt; &gt;*)::{lambda(std::function&lt;void ()&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::function&lt;void ()&gt;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#9  0x00007f38799e895b in std::function&lt;void (std::function&lt;void ()&gt;)&gt;::operator()(std::function&lt;void ()&gt;) const ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#10 0x00007f38799e9043 in tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector&lt;tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8&gt; const&amp;, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*) [clone .part.246] () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#11 0x00007f38799ecf5e in tensorflow::(anonymous namespace)::ExecutorImpl::RunAsync(tensorflow::Executor::Args const&amp;, std::function&lt;void (tensorflow::Status const&amp;)&gt;) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#12 0x00007f3879a045e4 in tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;tensorflow::Tensor, std::allocator&lt;tensorflow::Tensor&gt; &gt;*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#13 0x00007f38799dce27 in tensorflow::ConstantFold(tensorflow::ConstantFoldingOptions const&amp;, tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, tensorflow::Graph*, bool*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#14 0x00007f3879a02fea in tensorflow::GraphOptimizer::Optimize(tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, std::unique_ptr&lt;tensorflow::Graph, std::default_delete&lt;tensorflow::Graph&gt; &gt;*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#15 0x00007f38799a9469 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice&lt;std::string&gt;, tensorflow::gtl::ArraySlice&lt;std::string&gt;, tensorflow::gtl::ArraySlice&lt;std::string&gt;, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#16 0x00007f38799aa06c in tensorflow::DirectSession::Run(tensorflow::RunOptions const&amp;, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;tensorflow::Tensor, std::allocator&lt;tensorflow::Tensor&gt; &gt;*, tensorflow::RunMetadata*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#17 0x00007f387799b2d7 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, TF_Tensor**, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, TF_Buffer*, TF_Status*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#18 0x00007f387799b604 in TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#19 0x00007f38778037e2 in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector&lt;char const*, 8&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;char const*, 8&gt; const&amp;, TF_Status*, tensorflow::gtl::InlinedVector&lt;_object*, 8&gt;*, TF_Buffer*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#20 0x00007f3877803be1 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector&lt;char const*, 8&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;char const*, 8&gt; const&amp;, TF_Status*, tensorflow::gtl::InlinedVector&lt;_object*, 8&gt;*, TF_Buffer*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#21 0x00007f38777ca793 in _wrap_TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#22 0x00000000004c468a in PyEval_EvalFrameEx ()\n#23 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#24 0x00000000004de6fe in ?? ()\n#25 0x00000000004b0cb3 in PyObject_Call ()\n#26 0x00000000004c6ad1 in PyEval_EvalFrameEx ()\n#27 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#28 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#29 0x00000000004c2765 in PyEval_EvalCodeEx ()\n---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---\n#30 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#31 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#32 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#33 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#34 0x00000000004ca099 in PyEval_EvalFrameEx ()\n#35 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#36 0x00000000004c2509 in PyEval_EvalCode ()\n#37 0x00000000004f1def in ?? ()\n#38 0x00000000004ec652 in PyRun_FileExFlags ()\n#39 0x00000000004eae31 in PyRun_SimpleFileExFlags ()\n#40 0x000000000049e14a in Py_Main ()\n#41 0x00007f38a5e4c830 in __libc_start_main (main=0x49dab0 &lt;main&gt;, argc=2, argv=0x7ffd1a213618, init=&lt;optimised out&gt;, fini=&lt;optimised out&gt;, rtld_fini=&lt;optimised out&gt;, stack_end=0x7ffd1a213608)\n    at ../csu/libc-start.c:291\n#42 0x000000000049d9d9 in _start ()\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\nI've adapted the ZeroOut operator from the Adding a New Op example.\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nLinux Ubuntu 16.04\n\nTensorFlow installed from (source or binary):\n\nbinary GPU 1.3.0\n\nTensorFlow version (use command below):\n\n$ python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n('v1.3.0-rc2-20-g0787eee', '1.3.0')\n\nPython version:\n\n2.7.12\n\nBazel version (if compiling from source):\n\nN/A\n\nCUDA/cuDNN version:\n\nN/A\n\nGPU model and memory:\n\nN/A\n\nExact command to reproduce:\n\nTest operator: shard_fails.zip\n$ make\n$ python test_op.py\nDescribe the problem\nWhen the above C++ operator runs, it'll print the number of threads in the pool (8) and then segfault on the Shard call.\nSource code / logs\nC++ operator code:\n#define EIGEN_USE_THREADS\n\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\")\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output_flat = output_tensor->flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n\n    auto pool = context->device()->tensorflow_cpu_worker_threads()->workers;\n    printf(\"Pool Threads %d\\n\", pool->NumThreads());\n    Shard(pool->NumThreads(), pool, N, 10, [&](int64 start, int64 end) {\n        for(int64 i=start; i<end; ++i)\n            { output_flat(i) = 0; }\n    });\n\n    if(N > 0)\n        { output_flat(0) = input(0); }\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\nSee below the gdb trace:\nCore was generated by `python test_op.py'.\nProgram terminated with signal SIGSEGV, Segmentation fault.\n#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871\n1871\t\t(*_Base::_M_get_pointer(__functor))(\n[Current thread is 1 (Thread 0x7f38a6605700 (LWP 3771))]\n(gdb) bt\n#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871\n#1  0x00007f3879dcc75d in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#2  0x00007f3879dcc93f in tensorflow::thread::ThreadPool::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#3  0x00007f3879d4d995 in tensorflow::Shard(int, tensorflow::thread::ThreadPool*, long long, long long, std::function<void (long long, long long)>) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#4  0x00007f3850bfb79e in ZeroOutOp::Compute (this=0x62dacc0, context=0x7ffd1a20fe30) at tf_op.cpp:42\n#5  0x00007f3879a2563c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#6  0x00007f38799f5a58 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#7  0x00007f38799f61fa in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#8  0x00007f3879a035c4 in std::_Function_handler<void (std::function<void ()>), tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)::{lambda(std::function<void ()>)#1}>::_M_invoke(std::_Any_data const&, std::function<void ()>) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#9  0x00007f38799e895b in std::function<void (std::function<void ()>)>::operator()(std::function<void ()>) const ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#10 0x00007f38799e9043 in tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*) [clone .part.246] () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#11 0x00007f38799ecf5e in tensorflow::(anonymous namespace)::ExecutorImpl::RunAsync(tensorflow::Executor::Args const&, std::function<void (tensorflow::Status const&)>) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#12 0x00007f3879a045e4 in tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#13 0x00007f38799dce27 in tensorflow::ConstantFold(tensorflow::ConstantFoldingOptions const&, tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, tensorflow::Graph*, bool*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#14 0x00007f3879a02fea in tensorflow::GraphOptimizer::Optimize(tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#15 0x00007f38799a9469 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#16 0x00007f38799aa06c in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#17 0x00007f387799b2d7 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#18 0x00007f387799b604 in TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#19 0x00007f38778037e2 in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#20 0x00007f3877803be1 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#21 0x00007f38777ca793 in _wrap_TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n#22 0x00000000004c468a in PyEval_EvalFrameEx ()\n#23 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#24 0x00000000004de6fe in ?? ()\n#25 0x00000000004b0cb3 in PyObject_Call ()\n#26 0x00000000004c6ad1 in PyEval_EvalFrameEx ()\n#27 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#28 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#29 0x00000000004c2765 in PyEval_EvalCodeEx ()\n---Type <return> to continue, or q <return> to quit---\n#30 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#31 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#32 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\n#33 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#34 0x00000000004ca099 in PyEval_EvalFrameEx ()\n#35 0x00000000004c2765 in PyEval_EvalCodeEx ()\n#36 0x00000000004c2509 in PyEval_EvalCode ()\n#37 0x00000000004f1def in ?? ()\n#38 0x00000000004ec652 in PyRun_FileExFlags ()\n#39 0x00000000004eae31 in PyRun_SimpleFileExFlags ()\n#40 0x000000000049e14a in Py_Main ()\n#41 0x00007f38a5e4c830 in __libc_start_main (main=0x49dab0 <main>, argc=2, argv=0x7ffd1a213618, init=<optimised out>, fini=<optimised out>, rtld_fini=<optimised out>, stack_end=0x7ffd1a213608)\n    at ../csu/libc-start.c:291\n#42 0x000000000049d9d9 in _start ()", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n  \r\nI've adapted the ZeroOut operator from the [Adding a New Op](https://www.tensorflow.org/extend/adding_an_op) example.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nbinary GPU 1.3.0\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n$ python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n\r\n- **Python version**: \r\n\r\n2.7.12\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nN/A\r\n\r\n- **GPU model and memory**:\r\n\r\nN/A\r\n\r\n- **Exact command to reproduce**:\r\n\r\nTest operator: [shard_fails.zip](https://github.com/tensorflow/tensorflow/files/1332745/shard_fails.zip)\r\n\r\n```bash\r\n$ make\r\n$ python test_op.py\r\n```\r\n\r\n\r\n\r\n### Describe the problem\r\n\r\nWhen the above C++ operator runs, it'll print the number of threads in the pool (8) and then segfault on the Shard call.\r\n\r\n### Source code / logs\r\n\r\nC++ operator code:\r\n\r\n```cpp\r\n#define EIGEN_USE_THREADS\r\n\r\n#include \"tensorflow/core/lib/core/threadpool.h\"\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/util/work_sharder.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"ZeroOut\")\r\n    .Input(\"to_zero: int32\")\r\n    .Output(\"zeroed: int32\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      c->set_output(0, c->input(0));\r\n      return Status::OK();\r\n    });\r\n\r\nclass ZeroOutOp : public OpKernel {\r\n public:\r\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    // Grab the input tensor\r\n    const Tensor& input_tensor = context->input(0);\r\n    auto input = input_tensor.flat<int32>();\r\n\r\n    // Create an output tensor\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n                                                     &output_tensor));\r\n    auto output_flat = output_tensor->flat<int32>();\r\n\r\n    // Set all but the first element of the output tensor to 0.\r\n    const int N = input.size();\r\n\r\n    auto pool = context->device()->tensorflow_cpu_worker_threads()->workers;\r\n    printf(\"Pool Threads %d\\n\", pool->NumThreads());\r\n    Shard(pool->NumThreads(), pool, N, 10, [&](int64 start, int64 end) {\r\n        for(int64 i=start; i<end; ++i)\r\n            { output_flat(i) = 0; }\r\n    });\r\n\r\n    if(N > 0)\r\n        { output_flat(0) = input(0); }\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n```\r\n\r\n\r\nSee below the gdb trace:\r\n\r\n```\r\nCore was generated by `python test_op.py'.\r\nProgram terminated with signal SIGSEGV, Segmentation fault.\r\n#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871\r\n1871\t\t(*_Base::_M_get_pointer(__functor))(\r\n[Current thread is 1 (Thread 0x7f38a6605700 (LWP 3771))]\r\n(gdb) bt\r\n#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871\r\n#1  0x00007f3879dcc75d in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007f3879dcc93f in tensorflow::thread::ThreadPool::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007f3879d4d995 in tensorflow::Shard(int, tensorflow::thread::ThreadPool*, long long, long long, std::function<void (long long, long long)>) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007f3850bfb79e in ZeroOutOp::Compute (this=0x62dacc0, context=0x7ffd1a20fe30) at tf_op.cpp:42\r\n#5  0x00007f3879a2563c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007f38799f5a58 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007f38799f61fa in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007f3879a035c4 in std::_Function_handler<void (std::function<void ()>), tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)::{lambda(std::function<void ()>)#1}>::_M_invoke(std::_Any_data const&, std::function<void ()>) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007f38799e895b in std::function<void (std::function<void ()>)>::operator()(std::function<void ()>) const ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007f38799e9043 in tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*) [clone .part.246] () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007f38799ecf5e in tensorflow::(anonymous namespace)::ExecutorImpl::RunAsync(tensorflow::Executor::Args const&, std::function<void (tensorflow::Status const&)>) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007f3879a045e4 in tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#13 0x00007f38799dce27 in tensorflow::ConstantFold(tensorflow::ConstantFoldingOptions const&, tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, tensorflow::Graph*, bool*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#14 0x00007f3879a02fea in tensorflow::GraphOptimizer::Optimize(tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#15 0x00007f38799a9469 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#16 0x00007f38799aa06c in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#17 0x00007f387799b2d7 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#18 0x00007f387799b604 in TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#19 0x00007f38778037e2 in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#20 0x00007f3877803be1 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#21 0x00007f38777ca793 in _wrap_TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#22 0x00000000004c468a in PyEval_EvalFrameEx ()\r\n#23 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#24 0x00000000004de6fe in ?? ()\r\n#25 0x00000000004b0cb3 in PyObject_Call ()\r\n#26 0x00000000004c6ad1 in PyEval_EvalFrameEx ()\r\n#27 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#28 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\r\n#29 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n---Type <return> to continue, or q <return> to quit---\r\n#30 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\r\n#31 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#32 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\r\n#33 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#34 0x00000000004ca099 in PyEval_EvalFrameEx ()\r\n#35 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#36 0x00000000004c2509 in PyEval_EvalCode ()\r\n#37 0x00000000004f1def in ?? ()\r\n#38 0x00000000004ec652 in PyRun_FileExFlags ()\r\n#39 0x00000000004eae31 in PyRun_SimpleFileExFlags ()\r\n#40 0x000000000049e14a in Py_Main ()\r\n#41 0x00007f38a5e4c830 in __libc_start_main (main=0x49dab0 <main>, argc=2, argv=0x7ffd1a213618, init=<optimised out>, fini=<optimised out>, rtld_fini=<optimised out>, stack_end=0x7ffd1a213608)\r\n    at ../csu/libc-start.c:291\r\n#42 0x000000000049d9d9 in _start ()\r\n```"}