{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/124382034", "pull_request_review_id": 46664791, "id": 124382034, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyNDM4MjAzNA==", "diff_hunk": "@@ -1472,3 +1473,104 @@ def total_variation(images, name=None):\n                math_ops.reduce_sum(math_ops.abs(pixel_dif2), axis=sum_axis))\n \n   return tot_var\n+\n+\n+def sample_distorted_bounding_box(image_size, bounding_boxes, seed=None,\n+                                  seed2=None, min_object_covered=None,\n+                                  aspect_ratio_range=None, area_range=None,\n+                                  max_attempts=None,\n+                                  use_image_if_no_bounding_boxes=None,\n+                                  name=None):\n+  \"\"\"Generate a single randomly distorted bounding box for an image.\n+\n+  Bounding box annotations are often supplied in addition to ground-truth labels\n+  in image recognition or object localization tasks. A common technique for\n+  training such a system is to randomly distort an image while preserving\n+  its content, i.e. *data augmentation*. This Op outputs a randomly distorted\n+  localization of an object, i.e. bounding box, given an `image_size`,\n+  `bounding_boxes` and a series of constraints.\n+\n+  The output of this Op is a single bounding box that may be used to crop the\n+  original image. The output is returned as 3 tensors: `begin`, `size` and\n+  `bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the\n+  image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize\n+  what the bounding box looks like.\n+\n+  Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The\n+  bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and\n+  height of the underlying image.\n+\n+  For example,\n+\n+  ```python\n+      # Generate a single distorted bounding box.\n+      begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(\n+          tf.shape(image),\n+          bounding_boxes=bounding_boxes)\n+\n+      # Draw the bounding box in an image summary.\n+      image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),\n+                                                    bbox_for_draw)\n+      tf.image_summary('images_with_box', image_with_box)\n+\n+      # Employ the bounding box to distort the image.\n+      distorted_image = tf.slice(image, begin, size)\n+  ```\n+\n+  Note that if no bounding box information is available, setting\n+  `use_image_if_no_bounding_boxes = true` will assume there is a single implicit\n+  bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is\n+  false and no bounding boxes are supplied, an error is raised.\n+\n+  Args:\n+    image_size: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`.\n+      1-D, containing `[height, width, channels]`.\n+    bounding_boxes: A `Tensor` of type `float32`.\n+      3-D with shape `[batch, N, 4]` describing the N bounding boxes\n+      associated with the image.\n+    seed: An optional `int`. Defaults to `0`.\n+      If either `seed` or `seed2` are set to non-zero, the random number\n+      generator is seeded by the given `seed`.  Otherwise, it is seeded by a random\n+      seed.\n+    seed2: An optional `int`. Defaults to `0`.\n+      A second seed to avoid seed collision.\n+    min_object_covered: An optional `float`. Defaults to `0.1`.\n+      The cropped area of the image must contain at least this\n+      fraction of any bounding box supplied. The value of this parameter should be\n+      non-negative. In the case of 0, the cropped area does not need to overlap\n+      any of the bounding boxes supplied.\n+    aspect_ratio_range: An optional list of `floats`. Defaults to `[0.75, 1.33]`.\n+      The cropped area of the image must have an aspect ratio =\n+      width / height within this range.\n+    area_range: An optional list of `floats`. Defaults to `[0.05, 1]`.\n+      The cropped area of the image must contain a fraction of the\n+      supplied image within in this range.\n+    max_attempts: An optional `int`. Defaults to `100`.\n+      Number of attempts at generating a cropped region of the image\n+      of the specified constraints. After `max_attempts` failures, return the entire\n+      image.\n+    use_image_if_no_bounding_boxes: An optional `bool`. Defaults to `False`.\n+      Controls behavior if no bounding boxes supplied.\n+      If true, assume an implicit bounding box covering the whole input. If false,\n+      raise an error.\n+    name: A name for the operation (optional).\n+\n+  Returns:\n+    A tuple of `Tensor` objects (begin, size, bboxes).\n+\n+    begin: A `Tensor`. Has the same type as `image_size`. 1-D, containing `[offset_height, offset_width, 0]`. Provide as input to\n+      `tf.slice`.\n+    size: A `Tensor`. Has the same type as `image_size`. 1-D, containing `[target_height, target_width, -1]`. Provide as input to\n+      `tf.slice`.\n+    bboxes: A `Tensor` of type `float32`. 3-D with shape `[1, 1, 4]` containing the distorted bounding box.\n+      Provide as input to `tf.image.draw_bounding_boxes`.\n+  \"\"\"\n+\n+  with ops.name_scope(name, 'sample_distorted_bounding_box'):\n+    return gen_image_ops._sample_distorted_bounding_box_v2(image_size,", "path": "tensorflow/python/ops/image_ops_impl.py", "position": null, "original_position": 106, "commit_id": "c1dfc0b0f6f7a89035fa19c67f4b58216539fffe", "original_commit_id": "695e6940a66f6bcd255b9d0a1b671ad5fcd489d8", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "body": "You need the v1 version, then we'll switch this one to V2 in three weeks.", "created_at": "2017-06-27T20:09:59Z", "updated_at": "2017-06-28T10:36:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/10840#discussion_r124382034", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10840", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/124382034"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/10840#discussion_r124382034"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10840"}}, "body_html": "<p>You need the v1 version, then we'll switch this one to V2 in three weeks.</p>", "body_text": "You need the v1 version, then we'll switch this one to V2 in three weeks."}