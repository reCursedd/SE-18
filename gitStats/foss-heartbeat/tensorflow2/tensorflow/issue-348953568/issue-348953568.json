{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21502", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21502/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21502/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21502/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21502", "id": 348953568, "node_id": "MDU6SXNzdWUzNDg5NTM1Njg=", "number": 21502, "title": "tf.train.Saver() will save both the checkpoint and meta-graph", "user": {"login": "xu-song", "id": 13825126, "node_id": "MDQ6VXNlcjEzODI1MTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/13825126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xu-song", "html_url": "https://github.com/xu-song", "followers_url": "https://api.github.com/users/xu-song/followers", "following_url": "https://api.github.com/users/xu-song/following{/other_user}", "gists_url": "https://api.github.com/users/xu-song/gists{/gist_id}", "starred_url": "https://api.github.com/users/xu-song/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xu-song/subscriptions", "organizations_url": "https://api.github.com/users/xu-song/orgs", "repos_url": "https://api.github.com/users/xu-song/repos", "events_url": "https://api.github.com/users/xu-song/events{/privacy}", "received_events_url": "https://api.github.com/users/xu-song/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-08-09T02:21:17Z", "updated_at": "2018-08-30T22:49:09Z", "closed_at": "2018-08-30T22:49:09Z", "author_association": "NONE", "body_html": "<p>I found that, <code>tf.train.Saver()</code> will save both the <code>checkpoint</code> and <code>meta-graph</code>.<br>\nHowever in many tensorflow tutorial, it adopt the following usage:</p>\n<div class=\"highlight highlight-source-python\"><pre>saver <span class=\"pl-k\">=</span> tf.train.Saver()\nsaver.save(sess, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>my-save-dir/my-model-10000<span class=\"pl-pds\">'</span></span>)    <span class=\"pl-c\"><span class=\"pl-c\">#</span> will generate my-model-10000.meta</span>\nsaver.export_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>my-save-dir/my-model-10000.meta<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> not need</span></pre></div>\n<h1>the following case</h1>\n<p><a href=\"https://www.tensorflow.org/api_guides/python/meta_graph#Import_a_MetaGraph\" rel=\"nofollow\">https://www.tensorflow.org/api_guides/python/meta_graph#Import_a_MetaGraph</a></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> math\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Creates an inference graph.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Hidden 1</span>\nimages <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.2</span>, tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">28</span>])\n<span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden1<span class=\"pl-pds\">\"</span></span>):\n  weights <span class=\"pl-k\">=</span> tf.Variable(\n      tf.truncated_normal([<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">128</span>],\n                          <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> math.sqrt(<span class=\"pl-c1\">float</span>(<span class=\"pl-c1\">28</span>))),\n      <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weights<span class=\"pl-pds\">\"</span></span>)\n  biases <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">128</span>]),\n                       <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>biases<span class=\"pl-pds\">\"</span></span>)\n  hidden1 <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(images, weights) <span class=\"pl-k\">+</span> biases)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Hidden 2</span>\n<span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hidden2<span class=\"pl-pds\">\"</span></span>):\n  weights <span class=\"pl-k\">=</span> tf.Variable(\n      tf.truncated_normal([<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">32</span>],\n                          <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> math.sqrt(<span class=\"pl-c1\">float</span>(<span class=\"pl-c1\">128</span>))),\n      <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weights<span class=\"pl-pds\">\"</span></span>)\n  biases <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">32</span>]),\n                       <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>biases<span class=\"pl-pds\">\"</span></span>)\n  hidden2 <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(hidden1, weights) <span class=\"pl-k\">+</span> biases)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Linear</span>\n<span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>softmax_linear<span class=\"pl-pds\">\"</span></span>):\n  weights <span class=\"pl-k\">=</span> tf.Variable(\n      tf.truncated_normal([<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">10</span>],\n                          <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span> <span class=\"pl-k\">/</span> math.sqrt(<span class=\"pl-c1\">float</span>(<span class=\"pl-c1\">32</span>))),\n      <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>weights<span class=\"pl-pds\">\"</span></span>)\n  biases <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">10</span>]),\n                       <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>biases<span class=\"pl-pds\">\"</span></span>)\n  logits <span class=\"pl-k\">=</span> tf.matmul(hidden2, weights) <span class=\"pl-k\">+</span> biases\n  tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>logits<span class=\"pl-pds\">\"</span></span>, logits)\n\ninit_all_op <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Initializes all the variables.</span>\n  sess.run(init_all_op)\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Runs to logit.</span>\n  sess.run(logits)\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Creates a saver.</span>\n  saver0 <span class=\"pl-k\">=</span> tf.train.Saver()\n  saver0.save(sess, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>my-save-dir/my-model-10000<span class=\"pl-pds\">'</span></span>)            <span class=\"pl-c\"><span class=\"pl-c\">#</span> it save both checkpoints and meta-graph</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Generates MetaGraphDef.</span>\n  saver0.export_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>my-save-dir/my-model-10000.meta<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> you can comment this line</span></pre></div>\n<h1>env</h1>\n<div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-s\">tensorflow=1.8.0</span></pre></div>\n<h1>background</h1>\n<p>I read the tensorflow docs, and search in stackoverflow.<br>\nI just find similar question, but no proper answer, like this one</p>\n<p><a href=\"https://stackoverflow.com/questions/45208587/relationship-between-tensorflow-saver-exporter-and-\" rel=\"nofollow\">https://stackoverflow.com/questions/45208587/relationship-between-tensorflow-saver-exporter-and-</a></p>", "body_text": "I found that, tf.train.Saver() will save both the checkpoint and meta-graph.\nHowever in many tensorflow tutorial, it adopt the following usage:\nsaver = tf.train.Saver()\nsaver.save(sess, 'my-save-dir/my-model-10000')    # will generate my-model-10000.meta\nsaver.export_meta_graph('my-save-dir/my-model-10000.meta')  # not need\nthe following case\nhttps://www.tensorflow.org/api_guides/python/meta_graph#Import_a_MetaGraph\nimport tensorflow as tf\nimport math\n# Creates an inference graph.\n# Hidden 1\nimages = tf.constant(1.2, tf.float32, shape=[100, 28])\nwith tf.name_scope(\"hidden1\"):\n  weights = tf.Variable(\n      tf.truncated_normal([28, 128],\n                          stddev=1.0 / math.sqrt(float(28))),\n      name=\"weights\")\n  biases = tf.Variable(tf.zeros([128]),\n                       name=\"biases\")\n  hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n# Hidden 2\nwith tf.name_scope(\"hidden2\"):\n  weights = tf.Variable(\n      tf.truncated_normal([128, 32],\n                          stddev=1.0 / math.sqrt(float(128))),\n      name=\"weights\")\n  biases = tf.Variable(tf.zeros([32]),\n                       name=\"biases\")\n  hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n# Linear\nwith tf.name_scope(\"softmax_linear\"):\n  weights = tf.Variable(\n      tf.truncated_normal([32, 10],\n                          stddev=1.0 / math.sqrt(float(32))),\n      name=\"weights\")\n  biases = tf.Variable(tf.zeros([10]),\n                       name=\"biases\")\n  logits = tf.matmul(hidden2, weights) + biases\n  tf.add_to_collection(\"logits\", logits)\n\ninit_all_op = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n  # Initializes all the variables.\n  sess.run(init_all_op)\n  # Runs to logit.\n  sess.run(logits)\n  # Creates a saver.\n  saver0 = tf.train.Saver()\n  saver0.save(sess, 'my-save-dir/my-model-10000')            # it save both checkpoints and meta-graph\n  # Generates MetaGraphDef.\n  saver0.export_meta_graph('my-save-dir/my-model-10000.meta')  # you can comment this line\nenv\ntensorflow=1.8.0\nbackground\nI read the tensorflow docs, and search in stackoverflow.\nI just find similar question, but no proper answer, like this one\nhttps://stackoverflow.com/questions/45208587/relationship-between-tensorflow-saver-exporter-and-", "body": "I found that, `tf.train.Saver()` will save both the `checkpoint` and `meta-graph`.\r\nHowever in many tensorflow tutorial, it adopt the following usage:\r\n```py\r\nsaver = tf.train.Saver()\r\nsaver.save(sess, 'my-save-dir/my-model-10000')    # will generate my-model-10000.meta\r\nsaver.export_meta_graph('my-save-dir/my-model-10000.meta')  # not need\r\n```\r\n\r\n\r\n# the following case\r\n\r\nhttps://www.tensorflow.org/api_guides/python/meta_graph#Import_a_MetaGraph\r\n\r\n```py\r\nimport tensorflow as tf\r\nimport math\r\n# Creates an inference graph.\r\n# Hidden 1\r\nimages = tf.constant(1.2, tf.float32, shape=[100, 28])\r\nwith tf.name_scope(\"hidden1\"):\r\n  weights = tf.Variable(\r\n      tf.truncated_normal([28, 128],\r\n                          stddev=1.0 / math.sqrt(float(28))),\r\n      name=\"weights\")\r\n  biases = tf.Variable(tf.zeros([128]),\r\n                       name=\"biases\")\r\n  hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\r\n# Hidden 2\r\nwith tf.name_scope(\"hidden2\"):\r\n  weights = tf.Variable(\r\n      tf.truncated_normal([128, 32],\r\n                          stddev=1.0 / math.sqrt(float(128))),\r\n      name=\"weights\")\r\n  biases = tf.Variable(tf.zeros([32]),\r\n                       name=\"biases\")\r\n  hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\r\n# Linear\r\nwith tf.name_scope(\"softmax_linear\"):\r\n  weights = tf.Variable(\r\n      tf.truncated_normal([32, 10],\r\n                          stddev=1.0 / math.sqrt(float(32))),\r\n      name=\"weights\")\r\n  biases = tf.Variable(tf.zeros([10]),\r\n                       name=\"biases\")\r\n  logits = tf.matmul(hidden2, weights) + biases\r\n  tf.add_to_collection(\"logits\", logits)\r\n\r\ninit_all_op = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n  # Initializes all the variables.\r\n  sess.run(init_all_op)\r\n  # Runs to logit.\r\n  sess.run(logits)\r\n  # Creates a saver.\r\n  saver0 = tf.train.Saver()\r\n  saver0.save(sess, 'my-save-dir/my-model-10000')            # it save both checkpoints and meta-graph\r\n  # Generates MetaGraphDef.\r\n  saver0.export_meta_graph('my-save-dir/my-model-10000.meta')  # you can comment this line\r\n```\r\n\r\n# env\r\n```yml\r\ntensorflow=1.8.0\r\n```\r\n\r\n# background\r\n\r\nI read the tensorflow docs, and search in stackoverflow.\r\nI just find similar question, but no proper answer, like this one\r\n\r\nhttps://stackoverflow.com/questions/45208587/relationship-between-tensorflow-saver-exporter-and-"}