{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9374", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9374/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9374/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9374/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9374", "id": 223471259, "node_id": "MDU6SXNzdWUyMjM0NzEyNTk=", "number": 9374, "title": "`tensorflow.python.client.device_lib.list_local_devices()` Bug", "user": {"login": "RuofanKong", "id": 7396554, "node_id": "MDQ6VXNlcjczOTY1NTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7396554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RuofanKong", "html_url": "https://github.com/RuofanKong", "followers_url": "https://api.github.com/users/RuofanKong/followers", "following_url": "https://api.github.com/users/RuofanKong/following{/other_user}", "gists_url": "https://api.github.com/users/RuofanKong/gists{/gist_id}", "starred_url": "https://api.github.com/users/RuofanKong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RuofanKong/subscriptions", "organizations_url": "https://api.github.com/users/RuofanKong/orgs", "repos_url": "https://api.github.com/users/RuofanKong/repos", "events_url": "https://api.github.com/users/RuofanKong/events{/privacy}", "received_events_url": "https://api.github.com/users/RuofanKong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-04-21T19:11:28Z", "updated_at": "2017-04-22T18:10:47Z", "closed_at": "2017-04-22T18:10:47Z", "author_association": "NONE", "body_html": "<p>I am trying to set up GPU configuration for Tensorflow. The step is very simple - Call <code>tensorflow.python.client.device_lib.list_local_devices()</code> to detect the number of gpu devices on the machine, and then set <code>config</code> for Tensorflow.  The following is the code for reproducing:</p>\n<pre><code>from logging import getLogger\n\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n\nlog = getLogger(__name__)\n\n\ndef get_available_gpus():\n    \"\"\" Get available GPU devices info. \"\"\"\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n\n\ndef test_gpu_memory_usage():\n    # Detect available GPU devices info.\n    log.info(\"On this machine, GPU devices: \", get_available_gpus())\n\n    # Set Tensorflow GPU configuration.\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n    tf_config=tf.ConfigProto(\n        allow_soft_placement=True,\n        device_count={'GPU': len(get_available_gpus())},\n        gpu_options=gpu_options,\n        log_device_placement=True)\n    session = tf.Session(config=tf_config)\n\n    # Mimick training process.\n    while True:\n        pass\n        \n\ntest_gpu_memory_usage()\n</code></pre>\n<p>If you run the above code, you could notice that even though you set GPU memory fraction per process to 0.1, it still allocates the whole GPU memory by looking at command <code>nvidia-smi</code>. However, if you don't call <code>get_available_gpus()</code>, the memory allocation works fine. That means, there might be a bug in <code>device_lib.list_local_devices()</code> to prevent setting up Tensorflow GPU memory usage.</p>\n<p>PS. My code runs on machine with GPU <code>GeForce GTX 1080</code>, CUDA 8.0, OS Ubuntu 16.04 and Python 3.5, and the above issue could be reproduced using either Tensorflow v.0.12, v.1.0 or v.1.1.</p>", "body_text": "I am trying to set up GPU configuration for Tensorflow. The step is very simple - Call tensorflow.python.client.device_lib.list_local_devices() to detect the number of gpu devices on the machine, and then set config for Tensorflow.  The following is the code for reproducing:\nfrom logging import getLogger\n\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n\nlog = getLogger(__name__)\n\n\ndef get_available_gpus():\n    \"\"\" Get available GPU devices info. \"\"\"\n    local_device_protos = device_lib.list_local_devices()\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n\n\ndef test_gpu_memory_usage():\n    # Detect available GPU devices info.\n    log.info(\"On this machine, GPU devices: \", get_available_gpus())\n\n    # Set Tensorflow GPU configuration.\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n    tf_config=tf.ConfigProto(\n        allow_soft_placement=True,\n        device_count={'GPU': len(get_available_gpus())},\n        gpu_options=gpu_options,\n        log_device_placement=True)\n    session = tf.Session(config=tf_config)\n\n    # Mimick training process.\n    while True:\n        pass\n        \n\ntest_gpu_memory_usage()\n\nIf you run the above code, you could notice that even though you set GPU memory fraction per process to 0.1, it still allocates the whole GPU memory by looking at command nvidia-smi. However, if you don't call get_available_gpus(), the memory allocation works fine. That means, there might be a bug in device_lib.list_local_devices() to prevent setting up Tensorflow GPU memory usage.\nPS. My code runs on machine with GPU GeForce GTX 1080, CUDA 8.0, OS Ubuntu 16.04 and Python 3.5, and the above issue could be reproduced using either Tensorflow v.0.12, v.1.0 or v.1.1.", "body": "I am trying to set up GPU configuration for Tensorflow. The step is very simple - Call `tensorflow.python.client.device_lib.list_local_devices()` to detect the number of gpu devices on the machine, and then set `config` for Tensorflow.  The following is the code for reproducing:\r\n\r\n```\r\nfrom logging import getLogger\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import device_lib\r\n\r\n\r\nlog = getLogger(__name__)\r\n\r\n\r\ndef get_available_gpus():\r\n    \"\"\" Get available GPU devices info. \"\"\"\r\n    local_device_protos = device_lib.list_local_devices()\r\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\r\n\r\n\r\ndef test_gpu_memory_usage():\r\n    # Detect available GPU devices info.\r\n    log.info(\"On this machine, GPU devices: \", get_available_gpus())\r\n\r\n    # Set Tensorflow GPU configuration.\r\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\r\n    tf_config=tf.ConfigProto(\r\n        allow_soft_placement=True,\r\n        device_count={'GPU': len(get_available_gpus())},\r\n        gpu_options=gpu_options,\r\n        log_device_placement=True)\r\n    session = tf.Session(config=tf_config)\r\n\r\n    # Mimick training process.\r\n    while True:\r\n        pass\r\n        \r\n\r\ntest_gpu_memory_usage()\r\n```\r\nIf you run the above code, you could notice that even though you set GPU memory fraction per process to 0.1, it still allocates the whole GPU memory by looking at command `nvidia-smi`. However, if you don't call `get_available_gpus()`, the memory allocation works fine. That means, there might be a bug in `device_lib.list_local_devices()` to prevent setting up Tensorflow GPU memory usage.\r\n\r\nPS. My code runs on machine with GPU `GeForce GTX 1080`, CUDA 8.0, OS Ubuntu 16.04 and Python 3.5, and the above issue could be reproduced using either Tensorflow v.0.12, v.1.0 or v.1.1."}