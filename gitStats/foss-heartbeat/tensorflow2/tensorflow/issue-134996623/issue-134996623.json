{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1205", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1205/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1205/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1205/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1205", "id": 134996623, "node_id": "MDU6SXNzdWUxMzQ5OTY2MjM=", "number": 1205, "title": "Inconsistent memory usage between CPU and GPU", "user": {"login": "jstaker7", "id": 1364252, "node_id": "MDQ6VXNlcjEzNjQyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1364252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jstaker7", "html_url": "https://github.com/jstaker7", "followers_url": "https://api.github.com/users/jstaker7/followers", "following_url": "https://api.github.com/users/jstaker7/following{/other_user}", "gists_url": "https://api.github.com/users/jstaker7/gists{/gist_id}", "starred_url": "https://api.github.com/users/jstaker7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jstaker7/subscriptions", "organizations_url": "https://api.github.com/users/jstaker7/orgs", "repos_url": "https://api.github.com/users/jstaker7/repos", "events_url": "https://api.github.com/users/jstaker7/events{/privacy}", "received_events_url": "https://api.github.com/users/jstaker7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-02-19T23:02:01Z", "updated_at": "2016-02-24T04:57:09Z", "closed_at": "2016-02-24T04:57:09Z", "author_association": "NONE", "body_html": "<p>Running a large network on CPU uses ~2GB memory, whereas running the same network on GPU takes ~6GB of memory (the full size of the card). Is it just allocating all the available GPU memory even though it might not all be utilized? This is using the recent 0.7 pip version.</p>", "body_text": "Running a large network on CPU uses ~2GB memory, whereas running the same network on GPU takes ~6GB of memory (the full size of the card). Is it just allocating all the available GPU memory even though it might not all be utilized? This is using the recent 0.7 pip version.", "body": "Running a large network on CPU uses ~2GB memory, whereas running the same network on GPU takes ~6GB of memory (the full size of the card). Is it just allocating all the available GPU memory even though it might not all be utilized? This is using the recent 0.7 pip version.\n"}