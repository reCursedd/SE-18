{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364357596", "html_url": "https://github.com/tensorflow/tensorflow/issues/14171#issuecomment-364357596", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14171", "id": 364357596, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDM1NzU5Ng==", "user": {"login": "w4nderlust", "id": 349256, "node_id": "MDQ6VXNlcjM0OTI1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/349256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/w4nderlust", "html_url": "https://github.com/w4nderlust", "followers_url": "https://api.github.com/users/w4nderlust/followers", "following_url": "https://api.github.com/users/w4nderlust/following{/other_user}", "gists_url": "https://api.github.com/users/w4nderlust/gists{/gist_id}", "starred_url": "https://api.github.com/users/w4nderlust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/w4nderlust/subscriptions", "organizations_url": "https://api.github.com/users/w4nderlust/orgs", "repos_url": "https://api.github.com/users/w4nderlust/repos", "events_url": "https://api.github.com/users/w4nderlust/events{/privacy}", "received_events_url": "https://api.github.com/users/w4nderlust/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-09T07:33:45Z", "updated_at": "2018-02-09T07:33:45Z", "author_association": "NONE", "body_html": "<p>Thank you guys for shedding light on the issue. In my specific case, this additional usage of memory for a smaller batch size was making the model go out of memory, not immediately but at the end of the epoch. So if I may have a suggestion. Now I know that setting TF_CUDNN_USE_AUTOTUNE I can keep the memory usage constant.<br>\nSo may I suggest adding an option to ConfigProto? Setting it the user would know that he can rely on constant memory consumption and he can tune the size of the model and the batch size accordingly, without weird surprises at the end of the epoch that will result in out of memory errors.</p>", "body_text": "Thank you guys for shedding light on the issue. In my specific case, this additional usage of memory for a smaller batch size was making the model go out of memory, not immediately but at the end of the epoch. So if I may have a suggestion. Now I know that setting TF_CUDNN_USE_AUTOTUNE I can keep the memory usage constant.\nSo may I suggest adding an option to ConfigProto? Setting it the user would know that he can rely on constant memory consumption and he can tune the size of the model and the batch size accordingly, without weird surprises at the end of the epoch that will result in out of memory errors.", "body": "Thank you guys for shedding light on the issue. In my specific case, this additional usage of memory for a smaller batch size was making the model go out of memory, not immediately but at the end of the epoch. So if I may have a suggestion. Now I know that setting TF_CUDNN_USE_AUTOTUNE I can keep the memory usage constant.\r\nSo may I suggest adding an option to ConfigProto? Setting it the user would know that he can rely on constant memory consumption and he can tune the size of the model and the batch size accordingly, without weird surprises at the end of the epoch that will result in out of memory errors."}