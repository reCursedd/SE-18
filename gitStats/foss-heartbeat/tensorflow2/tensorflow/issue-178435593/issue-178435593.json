{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4518", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4518/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4518/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4518/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4518", "id": 178435593, "node_id": "MDU6SXNzdWUxNzg0MzU1OTM=", "number": 4518, "title": "GPU kernel for MatrixTriangularSolve ", "user": {"login": "alexggmatthews", "id": 6596998, "node_id": "MDQ6VXNlcjY1OTY5OTg=", "avatar_url": "https://avatars2.githubusercontent.com/u/6596998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexggmatthews", "html_url": "https://github.com/alexggmatthews", "followers_url": "https://api.github.com/users/alexggmatthews/followers", "following_url": "https://api.github.com/users/alexggmatthews/following{/other_user}", "gists_url": "https://api.github.com/users/alexggmatthews/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexggmatthews/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexggmatthews/subscriptions", "organizations_url": "https://api.github.com/users/alexggmatthews/orgs", "repos_url": "https://api.github.com/users/alexggmatthews/repos", "events_url": "https://api.github.com/users/alexggmatthews/events{/privacy}", "received_events_url": "https://api.github.com/users/alexggmatthews/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284463744, "node_id": "MDU6TGFiZWwyODQ0NjM3NDQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cuda", "name": "cuda", "color": "f7c6c7", "default": false}, {"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-09-21T19:06:28Z", "updated_at": "2016-11-18T00:10:37Z", "closed_at": "2016-11-18T00:10:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>A feature request. This should be possible without too much disruption because it relies on a CUBLAS call and therefore would not require changes to stream_executor, see section 3.4.6 of the linked document.</p>\n<p><a href=\"https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf\" rel=\"nofollow\">https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf</a></p>\n<p>The requisite blas function is called <em>cublasStrsm</em> and seems to be already in stream executor in this file</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/6d04d601e9e8758ec4642fa9d548b7321d804d63/tensorflow/stream_executor/cuda/cuda_blas.cc\">https://github.com/tensorflow/tensorflow/blob/6d04d601e9e8758ec4642fa9d548b7321d804d63/tensorflow/stream_executor/cuda/cuda_blas.cc</a></p>\n<p>I know that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16907534\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rmlarsen\">@rmlarsen</a> has been interested in this sort of area in the past.</p>\n<p>I don't think it is possible to do this as a user op added at run time because stream executor is not part of the tf includes in the binary, but I'd be happy to be wrong.</p>", "body_text": "A feature request. This should be possible without too much disruption because it relies on a CUBLAS call and therefore would not require changes to stream_executor, see section 3.4.6 of the linked document.\nhttps://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf\nThe requisite blas function is called cublasStrsm and seems to be already in stream executor in this file\nhttps://github.com/tensorflow/tensorflow/blob/6d04d601e9e8758ec4642fa9d548b7321d804d63/tensorflow/stream_executor/cuda/cuda_blas.cc\nI know that @rmlarsen has been interested in this sort of area in the past.\nI don't think it is possible to do this as a user op added at run time because stream executor is not part of the tf includes in the binary, but I'd be happy to be wrong.", "body": "A feature request. This should be possible without too much disruption because it relies on a CUBLAS call and therefore would not require changes to stream_executor, see section 3.4.6 of the linked document. \n\nhttps://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf\n\nThe requisite blas function is called _cublasStrsm_ and seems to be already in stream executor in this file\n\nhttps://github.com/tensorflow/tensorflow/blob/6d04d601e9e8758ec4642fa9d548b7321d804d63/tensorflow/stream_executor/cuda/cuda_blas.cc\n\nI know that @rmlarsen has been interested in this sort of area in the past. \n\nI don't think it is possible to do this as a user op added at run time because stream executor is not part of the tf includes in the binary, but I'd be happy to be wrong. \n"}