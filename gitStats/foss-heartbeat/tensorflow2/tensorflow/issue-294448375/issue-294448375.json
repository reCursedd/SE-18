{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16776", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16776/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16776/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16776/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16776", "id": 294448375, "node_id": "MDU6SXNzdWUyOTQ0NDgzNzU=", "number": 16776, "title": "Unnamed Op not showing in list_tensors command during debug session", "user": {"login": "burglarhobbit", "id": 15987266, "node_id": "MDQ6VXNlcjE1OTg3MjY2", "avatar_url": "https://avatars2.githubusercontent.com/u/15987266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/burglarhobbit", "html_url": "https://github.com/burglarhobbit", "followers_url": "https://api.github.com/users/burglarhobbit/followers", "following_url": "https://api.github.com/users/burglarhobbit/following{/other_user}", "gists_url": "https://api.github.com/users/burglarhobbit/gists{/gist_id}", "starred_url": "https://api.github.com/users/burglarhobbit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/burglarhobbit/subscriptions", "organizations_url": "https://api.github.com/users/burglarhobbit/orgs", "repos_url": "https://api.github.com/users/burglarhobbit/repos", "events_url": "https://api.github.com/users/burglarhobbit/events{/privacy}", "received_events_url": "https://api.github.com/users/burglarhobbit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-02-05T16:09:27Z", "updated_at": "2018-09-28T21:48:35Z", "closed_at": "2018-09-28T21:48:35Z", "author_association": "NONE", "body_html": "<p>I have these two unnamed op tensors <code>logits</code> and <code>outputs</code> under a variable scope, but the <code>lt</code> command isn't listing these two tensors under the op 'MatMul' and 'Softmax' during the <code>tfdbg</code> session after a test run on a checkpoint. Here is a snapshot of the code:</p>\n<pre><code>    with tf.variable_scope(scope):\n        d_inputs = dropout(inputs, keep_prob=keep_prob, is_train=is_train)\n\t\td_memory = dropout(memory, keep_prob=keep_prob, is_train=is_train)\n\t\tJX = tf.shape(inputs)[1]\n\n\t\twith tf.variable_scope(\"attention\"):\n\t\t\tinputs_ = tf.nn.relu(dense(d_inputs, hidden, use_bias=False, scope=\"inputs\"))\n\t\t\tmemory_ = tf.nn.relu(dense(d_memory, hidden, use_bias=False, scope=\"memory\"))\n\t\t\toutputs = tf.matmul(inputs_, tf.transpose(memory_, [0, 2, 1])) / (hidden ** 0.5)\n\t\t\tmask = tf.tile(tf.expand_dims(mask, axis=1), [1, JX, 1])\n            # The tensor down below \n\t\t\tlogits = tf.nn.softmax(softmax_mask(outputs, mask))\n            # And the tensor down below here as well\n\t\t\toutputs = tf.matmul(logits, memory)\n\t\t\tres = tf.concat([inputs, outputs], axis=2)\n</code></pre>\n<p>What can I do to retrieve these variables for testing purposes on <code>tfdbg</code>?<br>\nFor alternative purposes, can I retrieve them using the normal tensorflow session by using <code>tf.add_to_collection(op_name, tensor)</code> as mentioned in <a href=\"https://stackoverflow.com/questions/44639260/retrieving-an-unnamed-variable-in-tensorflow\" rel=\"nofollow\">this answer</a>?</p>", "body_text": "I have these two unnamed op tensors logits and outputs under a variable scope, but the lt command isn't listing these two tensors under the op 'MatMul' and 'Softmax' during the tfdbg session after a test run on a checkpoint. Here is a snapshot of the code:\n    with tf.variable_scope(scope):\n        d_inputs = dropout(inputs, keep_prob=keep_prob, is_train=is_train)\n\t\td_memory = dropout(memory, keep_prob=keep_prob, is_train=is_train)\n\t\tJX = tf.shape(inputs)[1]\n\n\t\twith tf.variable_scope(\"attention\"):\n\t\t\tinputs_ = tf.nn.relu(dense(d_inputs, hidden, use_bias=False, scope=\"inputs\"))\n\t\t\tmemory_ = tf.nn.relu(dense(d_memory, hidden, use_bias=False, scope=\"memory\"))\n\t\t\toutputs = tf.matmul(inputs_, tf.transpose(memory_, [0, 2, 1])) / (hidden ** 0.5)\n\t\t\tmask = tf.tile(tf.expand_dims(mask, axis=1), [1, JX, 1])\n            # The tensor down below \n\t\t\tlogits = tf.nn.softmax(softmax_mask(outputs, mask))\n            # And the tensor down below here as well\n\t\t\toutputs = tf.matmul(logits, memory)\n\t\t\tres = tf.concat([inputs, outputs], axis=2)\n\nWhat can I do to retrieve these variables for testing purposes on tfdbg?\nFor alternative purposes, can I retrieve them using the normal tensorflow session by using tf.add_to_collection(op_name, tensor) as mentioned in this answer?", "body": "I have these two unnamed op tensors `logits` and `outputs` under a variable scope, but the `lt` command isn't listing these two tensors under the op 'MatMul' and 'Softmax' during the `tfdbg` session after a test run on a checkpoint. Here is a snapshot of the code:\r\n```\r\n    with tf.variable_scope(scope):\r\n        d_inputs = dropout(inputs, keep_prob=keep_prob, is_train=is_train)\r\n\t\td_memory = dropout(memory, keep_prob=keep_prob, is_train=is_train)\r\n\t\tJX = tf.shape(inputs)[1]\r\n\r\n\t\twith tf.variable_scope(\"attention\"):\r\n\t\t\tinputs_ = tf.nn.relu(dense(d_inputs, hidden, use_bias=False, scope=\"inputs\"))\r\n\t\t\tmemory_ = tf.nn.relu(dense(d_memory, hidden, use_bias=False, scope=\"memory\"))\r\n\t\t\toutputs = tf.matmul(inputs_, tf.transpose(memory_, [0, 2, 1])) / (hidden ** 0.5)\r\n\t\t\tmask = tf.tile(tf.expand_dims(mask, axis=1), [1, JX, 1])\r\n            # The tensor down below \r\n\t\t\tlogits = tf.nn.softmax(softmax_mask(outputs, mask))\r\n            # And the tensor down below here as well\r\n\t\t\toutputs = tf.matmul(logits, memory)\r\n\t\t\tres = tf.concat([inputs, outputs], axis=2)\r\n```\r\nWhat can I do to retrieve these variables for testing purposes on `tfdbg`?  \r\nFor alternative purposes, can I retrieve them using the normal tensorflow session by using `tf.add_to_collection(op_name, tensor)` as mentioned in [this answer][1]?\r\n\r\n\r\n  [1]: https://stackoverflow.com/questions/44639260/retrieving-an-unnamed-variable-in-tensorflow"}