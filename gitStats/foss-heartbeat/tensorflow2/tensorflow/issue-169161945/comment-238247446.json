{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238247446", "html_url": "https://github.com/tensorflow/tensorflow/issues/3624#issuecomment-238247446", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3624", "id": 238247446, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODI0NzQ0Ng==", "user": {"login": "sbrodeur", "id": 4322357, "node_id": "MDQ6VXNlcjQzMjIzNTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4322357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sbrodeur", "html_url": "https://github.com/sbrodeur", "followers_url": "https://api.github.com/users/sbrodeur/followers", "following_url": "https://api.github.com/users/sbrodeur/following{/other_user}", "gists_url": "https://api.github.com/users/sbrodeur/gists{/gist_id}", "starred_url": "https://api.github.com/users/sbrodeur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sbrodeur/subscriptions", "organizations_url": "https://api.github.com/users/sbrodeur/orgs", "repos_url": "https://api.github.com/users/sbrodeur/repos", "events_url": "https://api.github.com/users/sbrodeur/events{/privacy}", "received_events_url": "https://api.github.com/users/sbrodeur/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-08T14:02:21Z", "updated_at": "2016-08-08T14:03:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=890531\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibab\">@ibab</a>: I did not yet attempt a fix. I've looked a at little at Eigen:<br>\n\"<em>By default, Eigen currently supports standard floating-point types (float, double, std::complex, std::complex, long double), as well as all native integer types (e.g., int, unsigned int, short, etc.), and bool.</em>\"<br>\n[https://eigen.tuxfamily.org/dox-devel/TopicCustomizingEigen.html]</p>\n<p>Thus, for the simple calculations here, should I expect Eigen to provide compatible functors, e.g. :</p>\n<pre><code>template &lt;typename T&gt;\nstruct add : base&lt;T, Eigen::internal::scalar_sum_op&lt;T&gt; &gt; {\n  static const bool use_bcast_optimization = true;\n};\n</code></pre>\n<p>This code is in file <em>cwise_ops.h</em></p>\n<p>Does this means the fix is similar to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153590809\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2263\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/2263/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/2263\">#2263</a>, i.e. just adding the complex64 type when we register the kernels?</p>", "body_text": "@ibab: I did not yet attempt a fix. I've looked a at little at Eigen:\n\"By default, Eigen currently supports standard floating-point types (float, double, std::complex, std::complex, long double), as well as all native integer types (e.g., int, unsigned int, short, etc.), and bool.\"\n[https://eigen.tuxfamily.org/dox-devel/TopicCustomizingEigen.html]\nThus, for the simple calculations here, should I expect Eigen to provide compatible functors, e.g. :\ntemplate <typename T>\nstruct add : base<T, Eigen::internal::scalar_sum_op<T> > {\n  static const bool use_bcast_optimization = true;\n};\n\nThis code is in file cwise_ops.h\nDoes this means the fix is similar to #2263, i.e. just adding the complex64 type when we register the kernels?", "body": "@ibab: I did not yet attempt a fix. I've looked a at little at Eigen:\n\"_By default, Eigen currently supports standard floating-point types (float, double, std::complex<float>, std::complex<double>, long double), as well as all native integer types (e.g., int, unsigned int, short, etc.), and bool._\"\n[https://eigen.tuxfamily.org/dox-devel/TopicCustomizingEigen.html]\n\nThus, for the simple calculations here, should I expect Eigen to provide compatible functors, e.g. :\n\n```\ntemplate <typename T>\nstruct add : base<T, Eigen::internal::scalar_sum_op<T> > {\n  static const bool use_bcast_optimization = true;\n};\n```\n\nThis code is in file _cwise_ops.h_\n\nDoes this means the fix is similar to #2263, i.e. just adding the complex64 type when we register the kernels?\n"}