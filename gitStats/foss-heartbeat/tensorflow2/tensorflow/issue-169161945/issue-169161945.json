{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3624", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3624/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3624/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3624/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3624", "id": 169161945, "node_id": "MDU6SXNzdWUxNjkxNjE5NDU=", "number": 3624, "title": "Basic Element-wise Complex Number Calculations Not Available On GPU", "user": {"login": "sbrodeur", "id": 4322357, "node_id": "MDQ6VXNlcjQzMjIzNTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4322357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sbrodeur", "html_url": "https://github.com/sbrodeur", "followers_url": "https://api.github.com/users/sbrodeur/followers", "following_url": "https://api.github.com/users/sbrodeur/following{/other_user}", "gists_url": "https://api.github.com/users/sbrodeur/gists{/gist_id}", "starred_url": "https://api.github.com/users/sbrodeur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sbrodeur/subscriptions", "organizations_url": "https://api.github.com/users/sbrodeur/orgs", "repos_url": "https://api.github.com/users/sbrodeur/repos", "events_url": "https://api.github.com/users/sbrodeur/events{/privacy}", "received_events_url": "https://api.github.com/users/sbrodeur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 31, "created_at": "2016-08-03T15:32:28Z", "updated_at": "2017-07-14T13:38:14Z", "closed_at": "2016-10-25T18:04:29Z", "author_association": "NONE", "body_html": "<p>Basic element-wise addition, subtraction, multiplication or division for any Tensor of type tf.complex64 is not implemented on GPU.</p>\n<h3>Environment info</h3>\n<p>Operating System: Centos 7,  3.10.0-327.22.2.el7.x86_64</p>\n<p>Installed version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 7.0-v4<br>\n-rw-r--r--. 1 root root 189170 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudadevrt.a<br>\nlrwxrwxrwx. 1 root root     16 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so -&gt; libcudart.so.7.5<br>\nlrwxrwxrwx. 1 root root     19 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -&gt; libcudart.so.7.5.18<br>\n-rwxr-xr-x. 1 root root 311596 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18<br>\n-rw-r--r--. 1 root root 558020 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart_static.a</p>\n<p>Tensorflow installed from source:</p>\n<ol>\n<li>Commit hash <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/00700f00fdf71baec1342d1afd7849e16fbd2a33/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/00700f00fdf71baec1342d1afd7849e16fbd2a33\"><tt>00700f0</tt></a></li>\n<li>Bazel information:<br>\nBuild label: 0.3.0-2016-07-22 (@ca36b06)<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri Jul 22 19:23:10 2016 (1469215390)<br>\nBuild timestamp: 1469215390<br>\nBuild timestamp as int: 1469215390</li>\n</ol>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Add, subtract, multiply or divide any Tensor of type tf.complex64. A code example is shown here for element-wise addition:</li>\n</ol>\n<pre><code>import tensorflow as tf\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        c = a + b\n\n        with tf.Session() as sess:\n            c = sess.run(c)\n</code></pre>\n<p>The code returns the following output if run on GPU (works well on CPU):</p>\n<p>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.4.0.7 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: Tesla K40c<br>\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745<br>\npciBusID 0000:02:00.0<br>\nTotal memory: 12.00GiB<br>\nFree memory: 11.90GiB<br>\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x5168890<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:<br>\nname: GeForce GT 610<br>\nmajor: 2 minor: 1 memoryClockRate (GHz) 1.62<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 1023.19MiB<br>\nFree memory: 396.98MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:814] Ignoring gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:01:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.5.<br>\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.<br>\n[[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]<br>\nTraceback (most recent call last):<br>\nFile \"test_div_gpu_prob.py\", line 12, in <br>\nc = sess.run(c)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.<br>\n[[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]<br>\nCaused by op u'add', defined at:<br>\nFile \"test_div_gpu_prob.py\", line 9, in <br>\nc = a + b<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 755, in binary_op_wrapper<br>\nreturn func(x, y, name=name)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 70, in add<br>\nresult = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op<br>\nop_def=op_def)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<h3>What have you tried?</h3>\n<ol>\n<li>Implementation using builtin Tensorflow functions works, if the real and imaginary parts are separated. See the code below:</li>\n</ol>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\ndef complex_add(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr + yr, xi + yi)\n\ndef complex_sub(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr - yr, xi - yi)\n\ndef complex_mul(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr*yr - xi*yi, xr*yi + xi*yr)\n\ndef complex_div(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    d = tf.square(yr) + tf.square(yi)\n    return tf.complex((xr*yr+xi*yi)/d, (xi*yr-xr*yi)/d)\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n\n        with tf.Session() as sess:\n\n            a_, b_, c = sess.run([a,b,complex_add(a,b)])\n            assert np.allclose(c, a_ + b_)\n\n            a_, b_, c = sess.run([a,b,complex_sub(a,b)])\n            assert np.allclose(c, a_ - b_)\n\n            a_, b_, c = sess.run([a,b,complex_mul(a,b)])\n            assert np.allclose(c, a_ * b_)\n\n            a_, b_, c = sess.run([a,b,complex_div(a,b)])\n            assert np.allclose(c, a_ / b_)\n</code></pre>\n<p>It would be nice to have such functions transparent with the built-in CPU implementations.</p>", "body_text": "Basic element-wise addition, subtraction, multiplication or division for any Tensor of type tf.complex64 is not implemented on GPU.\nEnvironment info\nOperating System: Centos 7,  3.10.0-327.22.2.el7.x86_64\nInstalled version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 7.0-v4\n-rw-r--r--. 1 root root 189170 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudadevrt.a\nlrwxrwxrwx. 1 root root     16 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx. 1 root root     19 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x. 1 root root 311596 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18\n-rw-r--r--. 1 root root 558020 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart_static.a\nTensorflow installed from source:\n\nCommit hash 00700f0\nBazel information:\nBuild label: 0.3.0-2016-07-22 (@ca36b06)\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 22 19:23:10 2016 (1469215390)\nBuild timestamp: 1469215390\nBuild timestamp as int: 1469215390\n\nSteps to reproduce\n\nAdd, subtract, multiply or divide any Tensor of type tf.complex64. A code example is shown here for element-wise addition:\n\nimport tensorflow as tf\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        c = a + b\n\n        with tf.Session() as sess:\n            c = sess.run(c)\n\nThe code returns the following output if run on GPU (works well on CPU):\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.4.0.7 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: Tesla K40c\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:02:00.0\nTotal memory: 12.00GiB\nFree memory: 11.90GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x5168890\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:\nname: GeForce GT 610\nmajor: 2 minor: 1 memoryClockRate (GHz) 1.62\npciBusID 0000:01:00.0\nTotal memory: 1023.19MiB\nFree memory: 396.98MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:814] Ignoring gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:01:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.5.\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n[[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]\nTraceback (most recent call last):\nFile \"test_div_gpu_prob.py\", line 12, in \nc = sess.run(c)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\nrun_metadata_ptr)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\ntarget_list, options, run_metadata)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n[[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]\nCaused by op u'add', defined at:\nFile \"test_div_gpu_prob.py\", line 9, in \nc = a + b\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 755, in binary_op_wrapper\nreturn func(x, y, name=name)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 70, in add\nresult = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\nop_def=op_def)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in init\nself._traceback = _extract_stack()\nWhat have you tried?\n\nImplementation using builtin Tensorflow functions works, if the real and imaginary parts are separated. See the code below:\n\nimport numpy as np\nimport tensorflow as tf\n\ndef complex_add(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr + yr, xi + yi)\n\ndef complex_sub(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr - yr, xi - yi)\n\ndef complex_mul(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr*yr - xi*yi, xr*yi + xi*yr)\n\ndef complex_div(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    d = tf.square(yr) + tf.square(yi)\n    return tf.complex((xr*yr+xi*yi)/d, (xi*yr-xr*yi)/d)\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n\n        with tf.Session() as sess:\n\n            a_, b_, c = sess.run([a,b,complex_add(a,b)])\n            assert np.allclose(c, a_ + b_)\n\n            a_, b_, c = sess.run([a,b,complex_sub(a,b)])\n            assert np.allclose(c, a_ - b_)\n\n            a_, b_, c = sess.run([a,b,complex_mul(a,b)])\n            assert np.allclose(c, a_ * b_)\n\n            a_, b_, c = sess.run([a,b,complex_div(a,b)])\n            assert np.allclose(c, a_ / b_)\n\nIt would be nice to have such functions transparent with the built-in CPU implementations.", "body": "Basic element-wise addition, subtraction, multiplication or division for any Tensor of type tf.complex64 is not implemented on GPU.\n### Environment info\n\nOperating System: Centos 7,  3.10.0-327.22.2.el7.x86_64\n\nInstalled version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 7.0-v4\n-rw-r--r--. 1 root root 189170 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudadevrt.a\nlrwxrwxrwx. 1 root root     16 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx. 1 root root     19 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x. 1 root root 311596 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18\n-rw-r--r--. 1 root root 558020 Jul 22 16:14 /usr/local/cuda-7.5/lib/libcudart_static.a\n\nTensorflow installed from source: \n1. Commit hash 00700f00fdf71baec1342d1afd7849e16fbd2a33\n2. Bazel information:\nBuild label: 0.3.0-2016-07-22 (@ca36b06)\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 22 19:23:10 2016 (1469215390)\nBuild timestamp: 1469215390\nBuild timestamp as int: 1469215390\n### Steps to reproduce\n1. Add, subtract, multiply or divide any Tensor of type tf.complex64. A code example is shown here for element-wise addition:\n\n```\nimport tensorflow as tf\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        c = a + b\n\n        with tf.Session() as sess:\n            c = sess.run(c)\n```\n\nThe code returns the following output if run on GPU (works well on CPU):\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.4.0.7 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K40c\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:02:00.0\nTotal memory: 12.00GiB\nFree memory: 11.90GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x5168890\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GT 610\nmajor: 2 minor: 1 memoryClockRate (GHz) 1.62\npciBusID 0000:01:00.0\nTotal memory: 1023.19MiB\nFree memory: 396.98MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:814] Ignoring gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:01:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.5.\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n     [[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]\nTraceback (most recent call last):\n  File \"test_div_gpu_prob.py\", line 12, in <module>\n    c = sess.run(c)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'add': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n     [[Node: add = Add[T=DT_COMPLEX64, _device=\"/device:GPU:0\"](Complex, Complex_1)]]\nCaused by op u'add', defined at:\n  File \"test_div_gpu_prob.py\", line 9, in <module>\n    c = a + b\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 755, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 70, in add\n    result = _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n### What have you tried?\n1.  Implementation using builtin Tensorflow functions works, if the real and imaginary parts are separated. See the code below:\n\n```\nimport numpy as np\nimport tensorflow as tf\n\ndef complex_add(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr + yr, xi + yi)\n\ndef complex_sub(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr - yr, xi - yi)\n\ndef complex_mul(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    return tf.complex(xr*yr - xi*yi, xr*yi + xi*yr)\n\ndef complex_div(x, y):\n    xr, xi = tf.real(x), tf.imag(x)\n    yr, yi = tf.real(y), tf.imag(y)\n    d = tf.square(yr) + tf.square(yi)\n    return tf.complex((xr*yr+xi*yi)/d, (xi*yr-xr*yi)/d)\n\nif __name__ == '__main__':\n\n    with tf.device('/gpu:0'):\n        N = 100\n        a = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n        b = tf.complex(tf.random_normal((N,)), tf.random_normal((N,)))\n\n        with tf.Session() as sess:\n\n            a_, b_, c = sess.run([a,b,complex_add(a,b)])\n            assert np.allclose(c, a_ + b_)\n\n            a_, b_, c = sess.run([a,b,complex_sub(a,b)])\n            assert np.allclose(c, a_ - b_)\n\n            a_, b_, c = sess.run([a,b,complex_mul(a,b)])\n            assert np.allclose(c, a_ * b_)\n\n            a_, b_, c = sess.run([a,b,complex_div(a,b)])\n            assert np.allclose(c, a_ / b_)\n```\n\nIt would be nice to have such functions transparent with the built-in CPU implementations.\n"}