{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23019", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23019/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23019/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23019/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23019", "id": 370534507, "node_id": "MDU6SXNzdWUzNzA1MzQ1MDc=", "number": 23019, "title": "`tf.layers.Conv2D`'s padding doesn't allow variable reuse in some cases", "user": {"login": "fabio12345", "id": 33119878, "node_id": "MDQ6VXNlcjMzMTE5ODc4", "avatar_url": "https://avatars1.githubusercontent.com/u/33119878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabio12345", "html_url": "https://github.com/fabio12345", "followers_url": "https://api.github.com/users/fabio12345/followers", "following_url": "https://api.github.com/users/fabio12345/following{/other_user}", "gists_url": "https://api.github.com/users/fabio12345/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabio12345/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabio12345/subscriptions", "organizations_url": "https://api.github.com/users/fabio12345/orgs", "repos_url": "https://api.github.com/users/fabio12345/repos", "events_url": "https://api.github.com/users/fabio12345/events{/privacy}", "received_events_url": "https://api.github.com/users/fabio12345/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-10-16T10:03:29Z", "updated_at": "2018-10-24T18:23:48Z", "closed_at": "2018-10-17T17:23:33Z", "author_association": "NONE", "body_html": "<p>Minimal code to reproduce:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nexample_image <span class=\"pl-k\">=</span> tf.zeros([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">1</span>])\nexample_image2 <span class=\"pl-k\">=</span> tf.zeros([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">41</span>, <span class=\"pl-c1\">1</span>])\n\n\nconvolution_op <span class=\"pl-k\">=</span> tf.layers.Conv2D(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SAME<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">dilation_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n\nconvolution_op(example_image)\nconvolution_op(example_image2)</pre></div>\n<p>Error:</p>\n<pre><code>InvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\n   1575   try:\n-&gt; 1576     c_op = c_api.TF_FinishOperation(op_desc)\n   1577   except errors.InvalidArgumentError as e:\n\nInvalidArgumentError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = &lt;4 4&gt;, input[2] = &lt;[4 4][4 4]&gt;.\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-1-05cd8b9e8ce2&gt; in &lt;module&gt;()\n      8 \n      9 convolution_op(example_image)\n---&gt; 10 convolution_op(example_image2)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\n    360 \n    361       # Actually call layer\n--&gt; 362       outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    363 \n    364     if not context.executing_eagerly():\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\n    734 \n    735       if not in_deferred_mode:\n--&gt; 736         outputs = self.call(inputs, *args, **kwargs)\n    737         if outputs is None:\n    738           raise ValueError('A layer\\'s `call` method should return a Tensor '\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\n    184 \n    185   def call(self, inputs):\n--&gt; 186     outputs = self._convolution_op(inputs, self.kernel)\n    187 \n    188     if self.use_bias:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\n    866 \n    867   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\n--&gt; 868     return self.conv_op(inp, filter)\n    869 \n    870 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\n    518 \n    519   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\n--&gt; 520     return self.call(inp, filter)\n    521 \n    522 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in _with_space_to_batch_call(self, inp, filter)\n    501     crops = _with_space_to_batch_adjust(crops, 0, spatial_dims)\n    502     input_converted = array_ops.space_to_batch_nd(\n--&gt; 503         input=inp, block_shape=dilation_rate, paddings=paddings)\n    504 \n    505     result = self.op(input_converted, filter)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in space_to_batch_nd(input, block_shape, paddings, name)\n   7568     _, _, _op = _op_def_lib._apply_op_helper(\n   7569         \"SpaceToBatchND\", input=input, block_shape=block_shape,\n-&gt; 7570         paddings=paddings, name=name)\n   7571     _result = _op.outputs[:]\n   7572     _inputs_flat = _op.inputs\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--&gt; 787                          op_def=op_def)\n    788       return output_structure, op_def.is_stateful, op\n    789 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    452                 'in a future version' if date is None else ('after %s' % date),\n    453                 instructions)\n--&gt; 454       return func(*args, **kwargs)\n    455     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n    456                                        _add_deprecated_arg_notice_to_docstring(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in create_op(***failed resolving arguments***)\n   3153           input_types=input_types,\n   3154           original_op=self._default_original_op,\n-&gt; 3155           op_def=op_def)\n   3156       self._create_op_helper(ret, compute_device=compute_device)\n   3157     return ret\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\n   1729           op_def, inputs, node_def.attr)\n   1730       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n-&gt; 1731                                 control_input_ops)\n   1732 \n   1733     # Initialize self._outputs.\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\n   1577   except errors.InvalidArgumentError as e:\n   1578     # Convert to ValueError for backwards compatibility.\n-&gt; 1579     raise ValueError(str(e))\n   1580 \n   1581   return c_op\n\nValueError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = &lt;4 4&gt;, input[2] = &lt;[4 4][4 4]&gt;.\n\n</code></pre>\n<p>A different error happens if the order of calls to <code>convolution_op</code> is inverted:</p>\n<pre><code>import tensorflow as tf\n\nexample_image = tf.zeros([1, 32, 32, 1])\nexample_image2 = tf.zeros([1, 41, 41, 1])\n\n\nconvolution_op = tf.layers.Conv2D(32, 3, padding=\"SAME\", dilation_rate=4)\n\nconvolution_op(example_image2)\nconvolution_op(example_image)\n</code></pre>\n<p>which is in short</p>\n<pre><code>InvalidArgumentError: Dimension size must be evenly divisible by 4 but is 43 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,32,32,1], [2], [2,2] and with computed input tensors: input[1] = &lt;4 4&gt;, input[2] = &lt;[4 7][4 7]&gt;.\n\n</code></pre>\n<p>I don't think this is the correct behaviour. I understand that the object oriented tf.layers classes such as <code>tf.layers.Conv2D</code> are meant to be the preferred way of doing variable reuse, but the padding seems to be set with the first call to the function, reducing utility of those functions.</p>\n<p>Have I written custom code<br>\nN/A<br>\nOS Platform and Distribution<br>\nN/A<br>\nTensorFlow installed from<br>\npip<br>\nTensorFlow version<br>\n1.10.1<br>\nBazel version<br>\nN/A<br>\nCUDA/cuDNN version<br>\nN/A<br>\nGPU model and memory<br>\nN/A<br>\nExact command to reproduce<br>\nN/A<br>\nMobile device<br>\nN/A</p>", "body_text": "Minimal code to reproduce:\nimport tensorflow as tf\n\nexample_image = tf.zeros([1, 32, 32, 1])\nexample_image2 = tf.zeros([1, 41, 41, 1])\n\n\nconvolution_op = tf.layers.Conv2D(32, 3, padding=\"SAME\", dilation_rate=4)\n\nconvolution_op(example_image)\nconvolution_op(example_image2)\nError:\nInvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\n   1575   try:\n-> 1576     c_op = c_api.TF_FinishOperation(op_desc)\n   1577   except errors.InvalidArgumentError as e:\n\nInvalidArgumentError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 4][4 4]>.\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n<ipython-input-1-05cd8b9e8ce2> in <module>()\n      8 \n      9 convolution_op(example_image)\n---> 10 convolution_op(example_image2)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\n    360 \n    361       # Actually call layer\n--> 362       outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    363 \n    364     if not context.executing_eagerly():\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\n    734 \n    735       if not in_deferred_mode:\n--> 736         outputs = self.call(inputs, *args, **kwargs)\n    737         if outputs is None:\n    738           raise ValueError('A layer\\'s `call` method should return a Tensor '\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\n    184 \n    185   def call(self, inputs):\n--> 186     outputs = self._convolution_op(inputs, self.kernel)\n    187 \n    188     if self.use_bias:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\n    866 \n    867   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\n--> 868     return self.conv_op(inp, filter)\n    869 \n    870 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\n    518 \n    519   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\n--> 520     return self.call(inp, filter)\n    521 \n    522 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in _with_space_to_batch_call(self, inp, filter)\n    501     crops = _with_space_to_batch_adjust(crops, 0, spatial_dims)\n    502     input_converted = array_ops.space_to_batch_nd(\n--> 503         input=inp, block_shape=dilation_rate, paddings=paddings)\n    504 \n    505     result = self.op(input_converted, filter)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in space_to_batch_nd(input, block_shape, paddings, name)\n   7568     _, _, _op = _op_def_lib._apply_op_helper(\n   7569         \"SpaceToBatchND\", input=input, block_shape=block_shape,\n-> 7570         paddings=paddings, name=name)\n   7571     _result = _op.outputs[:]\n   7572     _inputs_flat = _op.inputs\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--> 787                          op_def=op_def)\n    788       return output_structure, op_def.is_stateful, op\n    789 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    452                 'in a future version' if date is None else ('after %s' % date),\n    453                 instructions)\n--> 454       return func(*args, **kwargs)\n    455     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n    456                                        _add_deprecated_arg_notice_to_docstring(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in create_op(***failed resolving arguments***)\n   3153           input_types=input_types,\n   3154           original_op=self._default_original_op,\n-> 3155           op_def=op_def)\n   3156       self._create_op_helper(ret, compute_device=compute_device)\n   3157     return ret\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\n   1729           op_def, inputs, node_def.attr)\n   1730       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n-> 1731                                 control_input_ops)\n   1732 \n   1733     # Initialize self._outputs.\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\n   1577   except errors.InvalidArgumentError as e:\n   1578     # Convert to ValueError for backwards compatibility.\n-> 1579     raise ValueError(str(e))\n   1580 \n   1581   return c_op\n\nValueError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 4][4 4]>.\n\n\nA different error happens if the order of calls to convolution_op is inverted:\nimport tensorflow as tf\n\nexample_image = tf.zeros([1, 32, 32, 1])\nexample_image2 = tf.zeros([1, 41, 41, 1])\n\n\nconvolution_op = tf.layers.Conv2D(32, 3, padding=\"SAME\", dilation_rate=4)\n\nconvolution_op(example_image2)\nconvolution_op(example_image)\n\nwhich is in short\nInvalidArgumentError: Dimension size must be evenly divisible by 4 but is 43 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,32,32,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 7][4 7]>.\n\n\nI don't think this is the correct behaviour. I understand that the object oriented tf.layers classes such as tf.layers.Conv2D are meant to be the preferred way of doing variable reuse, but the padding seems to be set with the first call to the function, reducing utility of those functions.\nHave I written custom code\nN/A\nOS Platform and Distribution\nN/A\nTensorFlow installed from\npip\nTensorFlow version\n1.10.1\nBazel version\nN/A\nCUDA/cuDNN version\nN/A\nGPU model and memory\nN/A\nExact command to reproduce\nN/A\nMobile device\nN/A", "body": "Minimal code to reproduce:\r\n```python\r\nimport tensorflow as tf\r\n\r\nexample_image = tf.zeros([1, 32, 32, 1])\r\nexample_image2 = tf.zeros([1, 41, 41, 1])\r\n\r\n\r\nconvolution_op = tf.layers.Conv2D(32, 3, padding=\"SAME\", dilation_rate=4)\r\n\r\nconvolution_op(example_image)\r\nconvolution_op(example_image2)\r\n```\r\nError:\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\r\n   1575   try:\r\n-> 1576     c_op = c_api.TF_FinishOperation(op_desc)\r\n   1577   except errors.InvalidArgumentError as e:\r\n\r\nInvalidArgumentError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 4][4 4]>.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-05cd8b9e8ce2> in <module>()\r\n      8 \r\n      9 convolution_op(example_image)\r\n---> 10 convolution_op(example_image2)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    360 \r\n    361       # Actually call layer\r\n--> 362       outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n    363 \r\n    364     if not context.executing_eagerly():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    734 \r\n    735       if not in_deferred_mode:\r\n--> 736         outputs = self.call(inputs, *args, **kwargs)\r\n    737         if outputs is None:\r\n    738           raise ValueError('A layer\\'s `call` method should return a Tensor '\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\r\n    184 \r\n    185   def call(self, inputs):\r\n--> 186     outputs = self._convolution_op(inputs, self.kernel)\r\n    187 \r\n    188     if self.use_bias:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n    866 \r\n    867   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n--> 868     return self.conv_op(inp, filter)\r\n    869 \r\n    870 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n    518 \r\n    519   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n--> 520     return self.call(inp, filter)\r\n    521 \r\n    522 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py in _with_space_to_batch_call(self, inp, filter)\r\n    501     crops = _with_space_to_batch_adjust(crops, 0, spatial_dims)\r\n    502     input_converted = array_ops.space_to_batch_nd(\r\n--> 503         input=inp, block_shape=dilation_rate, paddings=paddings)\r\n    504 \r\n    505     result = self.op(input_converted, filter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in space_to_batch_nd(input, block_shape, paddings, name)\r\n   7568     _, _, _op = _op_def_lib._apply_op_helper(\r\n   7569         \"SpaceToBatchND\", input=input, block_shape=block_shape,\r\n-> 7570         paddings=paddings, name=name)\r\n   7571     _result = _op.outputs[:]\r\n   7572     _inputs_flat = _op.inputs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\r\n    786                          input_types=input_types, attrs=attr_protos,\r\n--> 787                          op_def=op_def)\r\n    788       return output_structure, op_def.is_stateful, op\r\n    789 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    452                 'in a future version' if date is None else ('after %s' % date),\r\n    453                 instructions)\r\n--> 454       return func(*args, **kwargs)\r\n    455     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    456                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in create_op(***failed resolving arguments***)\r\n   3153           input_types=input_types,\r\n   3154           original_op=self._default_original_op,\r\n-> 3155           op_def=op_def)\r\n   3156       self._create_op_helper(ret, compute_device=compute_device)\r\n   3157     return ret\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\r\n   1729           op_def, inputs, node_def.attr)\r\n   1730       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\r\n-> 1731                                 control_input_ops)\r\n   1732 \r\n   1733     # Initialize self._outputs.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\r\n   1577   except errors.InvalidArgumentError as e:\r\n   1578     # Convert to ValueError for backwards compatibility.\r\n-> 1579     raise ValueError(str(e))\r\n   1580 \r\n   1581   return c_op\r\n\r\nValueError: Dimension size must be evenly divisible by 4 but is 49 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,41,41,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 4][4 4]>.\r\n\r\n```\r\n\r\nA different error happens if the order of calls to `convolution_op` is inverted:\r\n```\r\nimport tensorflow as tf\r\n\r\nexample_image = tf.zeros([1, 32, 32, 1])\r\nexample_image2 = tf.zeros([1, 41, 41, 1])\r\n\r\n\r\nconvolution_op = tf.layers.Conv2D(32, 3, padding=\"SAME\", dilation_rate=4)\r\n\r\nconvolution_op(example_image2)\r\nconvolution_op(example_image)\r\n```\r\nwhich is in short\r\n```\r\nInvalidArgumentError: Dimension size must be evenly divisible by 4 but is 43 for 'conv2d/SpaceToBatchND_1' (op: 'SpaceToBatchND') with input shapes: [1,32,32,1], [2], [2,2] and with computed input tensors: input[1] = <4 4>, input[2] = <[4 7][4 7]>.\r\n\r\n```\r\n\r\nI don't think this is the correct behaviour. I understand that the object oriented tf.layers classes such as `tf.layers.Conv2D` are meant to be the preferred way of doing variable reuse, but the padding seems to be set with the first call to the function, reducing utility of those functions.\r\n\r\n\r\nHave I written custom code\r\nN/A\r\nOS Platform and Distribution\r\nN/A\r\nTensorFlow installed from\r\npip\r\nTensorFlow version\r\n1.10.1\r\nBazel version \r\nN/A\r\nCUDA/cuDNN version\r\nN/A\r\nGPU model and memory\r\nN/A\r\nExact command to reproduce\r\nN/A\r\nMobile device\r\nN/A\r\n"}