{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/440064511", "html_url": "https://github.com/tensorflow/tensorflow/issues/23590#issuecomment-440064511", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23590", "id": 440064511, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDA2NDUxMQ==", "user": {"login": "dhingratul", "id": 4759327, "node_id": "MDQ6VXNlcjQ3NTkzMjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/4759327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhingratul", "html_url": "https://github.com/dhingratul", "followers_url": "https://api.github.com/users/dhingratul/followers", "following_url": "https://api.github.com/users/dhingratul/following{/other_user}", "gists_url": "https://api.github.com/users/dhingratul/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhingratul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhingratul/subscriptions", "organizations_url": "https://api.github.com/users/dhingratul/orgs", "repos_url": "https://api.github.com/users/dhingratul/repos", "events_url": "https://api.github.com/users/dhingratul/events{/privacy}", "received_events_url": "https://api.github.com/users/dhingratul/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-19T22:26:56Z", "updated_at": "2018-11-19T22:27:26Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=42781361\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/harshini-gadige\">@harshini-gadige</a> Here you go</p>\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport tensorflow as tf\nimport numpy as np\nimport time\nslim = tf.contrib.slim\nimport timeit\nfrom tensorflow.python.client import timeline\n\n\ndef _repr(inputs, num_groups, scope=None):\n    if num_groups == 1:\n        return inputs\n    with tf.variable_scope(scope, 'channel_shift', [inputs]) as sc:\n        depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)\n        assert depth_in % num_groups == 0, (\n            \"depth_in=%d is not divisible by num_groups=%d\" %\n            (depth_in, num_groups))\n        # group size, depth = g * n\n        group_size = depth_in // num_groups\n        net = tf.manip.roll(inputs, group_size, axis=3)\n\n        return net\n\n\nif __name__ == \"__main__\":\n    batch = 5\n    mini_batch = 1\n    h = 704\n    w = 800\n    c = 6\n    # _inputs = tf.placeholder(tf.float32, shape=[1, h, w, c], name='Inputs')\n    _inputs = tf.Variable(tf.random_normal([1, h, w, c], stddev=0.1), name=\"Inputs\")\n    def create_mini_batch(mini_batch):\n        np.random.seed(i)\n        inputs = np.random.randn(mini_batch, h, w, c)\n        return inputs\n\n    # Network\n    net = _repr(_inputs, 2)\n\n    init = tf.global_variables_initializer()\n    times = []\n    with tf.Session() as sess:\n        sess.run(init)\n        summary_writer = tf.summary.FileWriter(\"logs_viz_unit\",graph=tf.get_default_graph())\n        for i in range(batch//mini_batch):\n            options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n            print(\"Step {}/{}\".format(i,batch//mini_batch))\n            inputs = create_mini_batch(mini_batch)\n            for j in range(mini_batch):\n                start_time = timeit.default_timer()\n                a = sess.run([net], feed_dict={_inputs:np.expand_dims(inputs[j,:,:,:], 0)}, options=options, run_metadata=run_metadata)\n                elapsed = timeit.default_timer() - start_time\n                times.append(elapsed)\n            fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n            fid = \"timeline_{}.json\".format(i)\n            chrome_trace = fetched_timeline.generate_chrome_trace_format()\n            with open(fid, 'w') as f:\n                f.write(chrome_trace)\n        print(\"Inference times(ms): {}\".format((sum(times[1:])/(batch - 1)) * 1000))\n</code></pre>", "body_text": "@harshini-gadige Here you go\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport tensorflow as tf\nimport numpy as np\nimport time\nslim = tf.contrib.slim\nimport timeit\nfrom tensorflow.python.client import timeline\n\n\ndef _repr(inputs, num_groups, scope=None):\n    if num_groups == 1:\n        return inputs\n    with tf.variable_scope(scope, 'channel_shift', [inputs]) as sc:\n        depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)\n        assert depth_in % num_groups == 0, (\n            \"depth_in=%d is not divisible by num_groups=%d\" %\n            (depth_in, num_groups))\n        # group size, depth = g * n\n        group_size = depth_in // num_groups\n        net = tf.manip.roll(inputs, group_size, axis=3)\n\n        return net\n\n\nif __name__ == \"__main__\":\n    batch = 5\n    mini_batch = 1\n    h = 704\n    w = 800\n    c = 6\n    # _inputs = tf.placeholder(tf.float32, shape=[1, h, w, c], name='Inputs')\n    _inputs = tf.Variable(tf.random_normal([1, h, w, c], stddev=0.1), name=\"Inputs\")\n    def create_mini_batch(mini_batch):\n        np.random.seed(i)\n        inputs = np.random.randn(mini_batch, h, w, c)\n        return inputs\n\n    # Network\n    net = _repr(_inputs, 2)\n\n    init = tf.global_variables_initializer()\n    times = []\n    with tf.Session() as sess:\n        sess.run(init)\n        summary_writer = tf.summary.FileWriter(\"logs_viz_unit\",graph=tf.get_default_graph())\n        for i in range(batch//mini_batch):\n            options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n            print(\"Step {}/{}\".format(i,batch//mini_batch))\n            inputs = create_mini_batch(mini_batch)\n            for j in range(mini_batch):\n                start_time = timeit.default_timer()\n                a = sess.run([net], feed_dict={_inputs:np.expand_dims(inputs[j,:,:,:], 0)}, options=options, run_metadata=run_metadata)\n                elapsed = timeit.default_timer() - start_time\n                times.append(elapsed)\n            fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n            fid = \"timeline_{}.json\".format(i)\n            chrome_trace = fetched_timeline.generate_chrome_trace_format()\n            with open(fid, 'w') as f:\n                f.write(chrome_trace)\n        print(\"Inference times(ms): {}\".format((sum(times[1:])/(batch - 1)) * 1000))", "body": "@harshini-gadige Here you go\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport collections\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\nslim = tf.contrib.slim\r\nimport timeit\r\nfrom tensorflow.python.client import timeline\r\n\r\n\r\ndef _repr(inputs, num_groups, scope=None):\r\n    if num_groups == 1:\r\n        return inputs\r\n    with tf.variable_scope(scope, 'channel_shift', [inputs]) as sc:\r\n        depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)\r\n        assert depth_in % num_groups == 0, (\r\n            \"depth_in=%d is not divisible by num_groups=%d\" %\r\n            (depth_in, num_groups))\r\n        # group size, depth = g * n\r\n        group_size = depth_in // num_groups\r\n        net = tf.manip.roll(inputs, group_size, axis=3)\r\n\r\n        return net\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    batch = 5\r\n    mini_batch = 1\r\n    h = 704\r\n    w = 800\r\n    c = 6\r\n    # _inputs = tf.placeholder(tf.float32, shape=[1, h, w, c], name='Inputs')\r\n    _inputs = tf.Variable(tf.random_normal([1, h, w, c], stddev=0.1), name=\"Inputs\")\r\n    def create_mini_batch(mini_batch):\r\n        np.random.seed(i)\r\n        inputs = np.random.randn(mini_batch, h, w, c)\r\n        return inputs\r\n\r\n    # Network\r\n    net = _repr(_inputs, 2)\r\n\r\n    init = tf.global_variables_initializer()\r\n    times = []\r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n        summary_writer = tf.summary.FileWriter(\"logs_viz_unit\",graph=tf.get_default_graph())\r\n        for i in range(batch//mini_batch):\r\n            options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n            run_metadata = tf.RunMetadata()\r\n            print(\"Step {}/{}\".format(i,batch//mini_batch))\r\n            inputs = create_mini_batch(mini_batch)\r\n            for j in range(mini_batch):\r\n                start_time = timeit.default_timer()\r\n                a = sess.run([net], feed_dict={_inputs:np.expand_dims(inputs[j,:,:,:], 0)}, options=options, run_metadata=run_metadata)\r\n                elapsed = timeit.default_timer() - start_time\r\n                times.append(elapsed)\r\n            fetched_timeline = timeline.Timeline(run_metadata.step_stats)\r\n            fid = \"timeline_{}.json\".format(i)\r\n            chrome_trace = fetched_timeline.generate_chrome_trace_format()\r\n            with open(fid, 'w') as f:\r\n                f.write(chrome_trace)\r\n        print(\"Inference times(ms): {}\".format((sum(times[1:])/(batch - 1)) * 1000))\r\n```"}