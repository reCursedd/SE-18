{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/140115377", "pull_request_review_id": 64123689, "id": 140115377, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MDExNTM3Nw==", "diff_hunk": "@@ -422,29 +595,131 @@ void RunSwapDimension1And2InTensor3(const GPUDevice& d, const T* input,\n   // If both dimensions are not trivial, use tiles for the actual swapping.\n   // Otherwise, the trivial swapping relying on the ldg cache is more efficient.\n   static const int kMinDimensionToUseTiles = 16;\n-  bool use_tiles = (input_dims[1] >= kMinDimensionToUseTiles &&\n-                    input_dims[2] >= kMinDimensionToUseTiles);\n-  if (use_tiles) {\n+  static const int kMinDimensionToUseRectTiles = 96;\n+\n+  bool large_matrix = (input_dims[1] >= kMinDimensionToUseTiles &&\n+                       input_dims[2] >= kMinDimensionToUseTiles);\n+  bool narrow_matrix = (input_dims[1] >= kMinDimensionToUseRectTiles ||\n+                      input_dims[2] >= kMinDimensionToUseRectTiles);\n+  if (large_matrix) {\n     // We get best performance when TileSize is the number of threads in a warp\n     // (32 on our GPUs) and NumSubTiles is 8, so our block size is 8 * 32 = 256\n     // threads.\n     static const int TileSize = 32;\n-    static const int NumSubTiles = 8;\n+    static const int ThreadNum = 256;\n+\n     Dimension<3> input_dims_in_tiles = {\n         input_dims[0], (input_dims[1] + TileSize - 1) / TileSize,\n         (input_dims[2] + TileSize - 1) / TileSize,\n     };\n+\n+    int total_tiles_count = input_dims_in_tiles[0] * input_dims_in_tiles[1] *\n+                            input_dims_in_tiles[2];\n+    SwapDimension1And2InTensor3UsingTiles<\n+        T, ThreadNum, TileSize,\n+        TileSize><<<total_tiles_count, ThreadNum, 0, d.stream()>>>(\n+        input, input_dims, output);\n+\n+  } else if (narrow_matrix) {\n+    // Define available tile sizes here for each size of data type supported:\n+    std::map<int, int> tile_spec_128 = {{32, 15}, {64, 15}, {128, 15},\n+                                        {256, 2}};\n+    std::map<int, int> tile_spec_64  = {{32, 15},  {64, 15}, {128, 15},\n+                                        {256, 8},  {512, 2}};\n+    std::map<int, int> tile_spec_32  = {{32, 15},  {64, 15}, {128, 15},\n+                                        {256, 10}, {512, 4}, {1024, 2}};\n+    std::map<int, int> tile_spec_16  = {{32, 15},  {64, 15}, {128, 15},\n+                                        {256, 10}, {512, 4}, {1024, 2}};\n+    std::map<int, int> tile_spec_8   = {{32, 15},  {64, 15}, {128, 15},\n+                                        {256, 10}, {512, 4}, {1024, 2}};", "path": "tensorflow/core/kernels/conv_ops_gpu_3.cu.cc", "position": null, "original_position": 372, "commit_id": "63d7a082d37c7db42ce52410cf240efda92eaa74", "original_commit_id": "4c36dee945836ac2b83f058ee6107d7cc876d484", "user": {"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}, "body": "I'm concerned constructing all these std::maps may add a nontrivial overhead to kernel launches.  std::map is kind of evil.\r\n\r\nAs a first change, it seems like you could accomplish basically the same thing with fewer maps by doing something like:\r\n\r\n```\r\n  std::map<int, int> tile_spec = []() -> std::map<int, int> {\r\n  switch (sizeof(T)) {\r\n    case 1: return {{32, 15}, ...};\r\n    case 2: ...\r\n  }();\r\n```\r\n\r\nBut looking closer, it seems that we also don't use the fact that this is a map, as opposed to, say, a `vector<pair<int, int>>`?  We could optimize further, but constructing one small vector is probably fine in terms of overhead.\r\n\r\nWhat do you think of pulling this whole computation out into a separate function?", "created_at": "2017-09-20T23:11:21Z", "updated_at": "2017-12-28T20:26:00Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13049#discussion_r140115377", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13049", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/140115377"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13049#discussion_r140115377"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13049"}}, "body_html": "<p>I'm concerned constructing all these std::maps may add a nontrivial overhead to kernel launches.  std::map is kind of evil.</p>\n<p>As a first change, it seems like you could accomplish basically the same thing with fewer maps by doing something like:</p>\n<pre><code>  std::map&lt;int, int&gt; tile_spec = []() -&gt; std::map&lt;int, int&gt; {\n  switch (sizeof(T)) {\n    case 1: return {{32, 15}, ...};\n    case 2: ...\n  }();\n</code></pre>\n<p>But looking closer, it seems that we also don't use the fact that this is a map, as opposed to, say, a <code>vector&lt;pair&lt;int, int&gt;&gt;</code>?  We could optimize further, but constructing one small vector is probably fine in terms of overhead.</p>\n<p>What do you think of pulling this whole computation out into a separate function?</p>", "body_text": "I'm concerned constructing all these std::maps may add a nontrivial overhead to kernel launches.  std::map is kind of evil.\nAs a first change, it seems like you could accomplish basically the same thing with fewer maps by doing something like:\n  std::map<int, int> tile_spec = []() -> std::map<int, int> {\n  switch (sizeof(T)) {\n    case 1: return {{32, 15}, ...};\n    case 2: ...\n  }();\n\nBut looking closer, it seems that we also don't use the fact that this is a map, as opposed to, say, a vector<pair<int, int>>?  We could optimize further, but constructing one small vector is probably fine in terms of overhead.\nWhat do you think of pulling this whole computation out into a separate function?"}