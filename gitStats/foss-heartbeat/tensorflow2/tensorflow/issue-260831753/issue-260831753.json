{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13329", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13329/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13329/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13329/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13329", "id": 260831753, "node_id": "MDU6SXNzdWUyNjA4MzE3NTM=", "number": 13329, "title": "Auto-Parallel excludes update operators of sparse tensors", "user": {"login": "sj6077", "id": 2465713, "node_id": "MDQ6VXNlcjI0NjU3MTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2465713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sj6077", "html_url": "https://github.com/sj6077", "followers_url": "https://api.github.com/users/sj6077/followers", "following_url": "https://api.github.com/users/sj6077/following{/other_user}", "gists_url": "https://api.github.com/users/sj6077/gists{/gist_id}", "starred_url": "https://api.github.com/users/sj6077/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sj6077/subscriptions", "organizations_url": "https://api.github.com/users/sj6077/orgs", "repos_url": "https://api.github.com/users/sj6077/repos", "events_url": "https://api.github.com/users/sj6077/events{/privacy}", "received_events_url": "https://api.github.com/users/sj6077/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-27T03:00:47Z", "updated_at": "2018-04-04T06:39:24Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nr1.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\ncuda 8.0/cudnn 5.1.5</li>\n<li><strong>GPU model and memory</strong>:<br>\nTesla P40</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to use auto_parallel in grappler, but I found it only controls dense tensors. In the code, only below operators update averaged gradients, but what about 'ScatterSub' for sparse tensors? Do you have a plan to implement it?</p>\n<pre><code>const std::set&lt;string&gt; apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n</code></pre>\n<h3>Source code / logs</h3>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 14.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\nr1.3\nBazel version (if compiling from source):\n0.4.5\nCUDA/cuDNN version:\ncuda 8.0/cudnn 5.1.5\nGPU model and memory:\nTesla P40\nExact command to reproduce:\n\nDescribe the problem\nI'm trying to use auto_parallel in grappler, but I found it only controls dense tensors. In the code, only below operators update averaged gradients, but what about 'ScatterSub' for sparse tensors? Do you have a plan to implement it?\nconst std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n\nSource code / logs", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nr1.3\r\n- **Bazel version (if compiling from source)**:\r\n0.4.5\r\n- **CUDA/cuDNN version**:\r\ncuda 8.0/cudnn 5.1.5\r\n- **GPU model and memory**:\r\nTesla P40 \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm trying to use auto_parallel in grappler, but I found it only controls dense tensors. In the code, only below operators update averaged gradients, but what about 'ScatterSub' for sparse tensors? Do you have a plan to implement it? \r\n\r\n```\r\nconst std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\r\n                                                \"ApplyProximalGradientDescent\",\r\n                                                \"ApplyAdadelta\",\r\n                                                \"ApplyAdagrad\",\r\n                                                \"ApplyProximalAdagrad\",\r\n                                                \"ApplyAdagradDA\",\r\n                                                \"ApplyFtrl\",\r\n                                                \"ApplyMomentum\",\r\n                                                \"ApplyAdam\",\r\n                                                \"ApplyRMSProp\",\r\n                                                \"ApplyCenteredRMSProp\"};\r\n```\r\n\r\n### Source code / logs"}