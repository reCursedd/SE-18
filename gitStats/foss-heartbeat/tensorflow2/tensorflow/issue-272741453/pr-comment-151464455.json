{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/151464455", "pull_request_review_id": 77176619, "id": 151464455, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MTQ2NDQ1NQ==", "diff_hunk": "@@ -794,6 +794,183 @@ Status MinOrMaxGrad(const Scope& scope, const Operation& op,\n REGISTER_GRADIENT_OP(\"Min\", MinOrMaxGrad);\n REGISTER_GRADIENT_OP(\"Max\", MinOrMaxGrad);\n \n+Status ProdGrad(const Scope& scope, const Operation& op,\n+                const std::vector<Output>& grad_inputs,\n+                std::vector<Output>* grad_outputs) {\n+  auto zero = Const(scope, 0);\n+  auto one = Const(scope, 1);\n+\n+  // The gradient can be expressed by dividing the product by each entry of\n+  // the input tensor. If our input is\n+  // [\n+  //  [3, 4],\n+  //  [5, 6],\n+  //  [7, 8]\n+  // ]\n+  // and we do a Prod operation on the axis 1, we will obtain [[105, 192]].\n+  // The gradient will have the same shape as the input\n+  //     [\n+  //       [105/3, 192/4],\n+  // dz *  [105/5, 192/6],\n+  //       [105/7, 192/6]\n+  //     ]\n+  // If the input contains a zero, the division is impossible but\n+  // if we take the calculation that gave the first gradient\n+  // (3 * 5 * 6)/3 is equal to 5 * 6\n+  // the trick will be to cumprod the elements on the axis without\n+  // the element at the current position (3 in the example above).\n+  // We will take as example:\n+  // [\n+  //   [\n+  //     [3.0, 4.0],\n+  //     [5.0, 6.0],\n+  //     [7.0, 8.0]\n+  //   ],\n+  //   [\n+  //     [3.0, 5.0],\n+  //     [0.0, 6.0],\n+  //     [5.0, 6.0]\n+  //   ]\n+  // ]\n+\n+  // [2, 3, 2]\n+  auto input_shape = Shape(scope, op.input(0));\n+\n+  // The Reshape with -1 flattens the reduction indices.\n+  // [1]\n+  auto reduction_indices = Reshape(scope, op.input(1), {-1});\n+\n+  // [2, 1, 2]\n+  auto output_shape_kept_dims =\n+      ReducedShapeHelper(scope, input_shape, reduction_indices);\n+\n+  // [1, 3, 1]\n+  auto tile_scaling = SafeDivHelper(scope, input_shape, output_shape_kept_dims);\n+\n+  // [[[105, 192]], [[0, 180]]]\n+  auto grad = Reshape(scope, grad_inputs[0], output_shape_kept_dims);\n+\n+  // [[[105, 192], [105, 192], [105, 192]], [[0, 180], [0, 180], [0, 180]]]\n+  auto grad_tiled = Tile(scope, grad, tile_scaling);\n+\n+  Scope cpu_scope = scope.WithDevice(\"/cpu:0\");\n+\n+  // [3]\n+  auto rank = Rank(cpu_scope, op.input(0));\n+\n+\n+  // Normalize any negative indices in the reduction_axes to positive values.\n+  auto reduction_indices_pos = Mod(scope, Add(scope, reduction_indices, rank), rank);", "path": "tensorflow/cc/gradients/math_grad.cc", "position": null, "original_position": 70, "commit_id": "e79833391ed232db739e45cfcd02b5446a7ba8fc", "original_commit_id": "cbdae0cf40b067db45c7d7fadb44bd1e126aee55", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "If this is intended as a line-by-line translation of the python code these operations should be in the cpu_scope as well and not in scope.", "created_at": "2017-11-16T16:23:20Z", "updated_at": "2017-12-21T16:21:58Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14422#discussion_r151464455", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14422", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/151464455"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14422#discussion_r151464455"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14422"}}, "body_html": "<p>If this is intended as a line-by-line translation of the python code these operations should be in the cpu_scope as well and not in scope.</p>", "body_text": "If this is intended as a line-by-line translation of the python code these operations should be in the cpu_scope as well and not in scope."}