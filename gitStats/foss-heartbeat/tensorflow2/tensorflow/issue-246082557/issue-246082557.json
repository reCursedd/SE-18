{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11821", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11821/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11821/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11821/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11821", "id": 246082557, "node_id": "MDU6SXNzdWUyNDYwODI1NTc=", "number": 11821, "title": "Gradient for self_adjoint_eigvals fails (self_adjoint_eig works fine)", "user": {"login": "st--", "id": 5763727, "node_id": "MDQ6VXNlcjU3NjM3Mjc=", "avatar_url": "https://avatars0.githubusercontent.com/u/5763727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/st--", "html_url": "https://github.com/st--", "followers_url": "https://api.github.com/users/st--/followers", "following_url": "https://api.github.com/users/st--/following{/other_user}", "gists_url": "https://api.github.com/users/st--/gists{/gist_id}", "starred_url": "https://api.github.com/users/st--/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/st--/subscriptions", "organizations_url": "https://api.github.com/users/st--/orgs", "repos_url": "https://api.github.com/users/st--/repos", "events_url": "https://api.github.com/users/st--/events{/privacy}", "received_events_url": "https://api.github.com/users/st--/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-07-27T15:38:11Z", "updated_at": "2017-08-21T23:52:27Z", "closed_at": "2017-08-21T23:52:26Z", "author_association": "NONE", "body_html": "<p>As also noted in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"148052287\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1915\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1915/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1915\">#1915</a> already (but that ticket had been closed), there is a bug in the implementation of <code>self_adjoint_eigvals</code> (whereas <code>self_adjoint_eig</code> works fine, but it is rather inefficient to compute eigenvectors and their gradients if I only require the eigenvalues!).</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no - stock usage of <code>tf.self_adjoint_eigvals</code> - minimal failing example below</li>\n<li><strong>OS Platform and Distribution</strong>:  Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from</strong>: source</li>\n<li><strong>TensorFlow version</strong>: v1.2.1-2-gc996c7b</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.2 (binary install)</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 1070 with 8 GB memory</li>\n<li><strong>Exact command to reproduce</strong>: see below</li>\n</ul>\n<h2>Minimal failing example:</h2>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> tf.random_normal((<span class=\"pl-c1\">10000</span>,<span class=\"pl-c1\">3</span>))\ncovar <span class=\"pl-k\">=</span> tf.matmul(tf.transpose(a), a)\neigvals, eigvect_holder <span class=\"pl-k\">=</span> tf.self_adjoint_eig(covar)\neigvects <span class=\"pl-k\">=</span> tf.transpose(eigvect_holder)\npure_eigvals <span class=\"pl-k\">=</span> tf.self_adjoint_eigvals(covar)\ntf.Session().run(tf.gradients(eigvals, a))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> works fine</span>\ntf.Session().run(tf.gradients(pure_eigvals, a))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> throws the error below</span></pre></div>\n<h3>Error message:</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gradients_impl.py <span class=\"pl-k\">in</span> _MaybeCompile(scope, op, func, grad_fn)\n    <span class=\"pl-c1\">340</span>     <span class=\"pl-k\">try</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">341</span>       xla_compile <span class=\"pl-k\">=</span> op.get_attr(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>_XlaCompile<span class=\"pl-pds\">\"</span></span>)\n    <span class=\"pl-c1\">342</span>       xla_separate_compiled_gradients <span class=\"pl-k\">=</span> op.get_attr(\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>framework<span class=\"pl-k\">/</span>ops.py <span class=\"pl-k\">in</span> get_attr(<span class=\"pl-c1\">self</span>, name)\n   <span class=\"pl-c1\">1666</span>       <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>No attr named '<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> name <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>' in <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span>\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1667</span>                        <span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>._node_def))\n   <span class=\"pl-c1\">1668</span>     <span class=\"pl-v\">x</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._node_def.attr[name]\n\n<span class=\"pl-c1\">ValueError</span>: No attr named <span class=\"pl-s\"><span class=\"pl-pds\">'</span>_XlaCompile<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">in</span> name: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SelfAdjointEigV2_16<span class=\"pl-pds\">\"</span></span>\nop: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SelfAdjointEigV2<span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-c1\">input</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MatMul_5<span class=\"pl-pds\">\"</span></span>\nattr {\n  key: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>T<span class=\"pl-pds\">\"</span></span>\n  value {\n    <span class=\"pl-c1\">type</span>: <span class=\"pl-c1\">DT_FLOAT</span>\n  }\n}\nattr {\n  key: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>compute_v<span class=\"pl-pds\">\"</span></span>\n  value {\n    b: false\n  }\n}\n\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>framework<span class=\"pl-k\">/</span>common_shapes.py <span class=\"pl-k\">in</span> _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\n    <span class=\"pl-c1\">670</span>           graph_def_version, node_def_str, input_shapes, input_tensors,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">671</span>           input_tensors_as_shapes, status)\n    <span class=\"pl-c1\">672</span>   <span class=\"pl-k\">except</span> errors.InvalidArgumentError <span class=\"pl-k\">as</span> err:\n\n<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>contextlib.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__exit__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">type</span>, value, traceback)\n     <span class=\"pl-c1\">65</span>             <span class=\"pl-k\">try</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">66</span>                 <span class=\"pl-c1\">next</span>(<span class=\"pl-c1\">self</span>.gen)\n     <span class=\"pl-c1\">67</span>             <span class=\"pl-k\">except</span> <span class=\"pl-c1\">StopIteration</span>:\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>framework<span class=\"pl-k\">/</span>errors_impl.py <span class=\"pl-k\">in</span> raise_exception_on_not_ok_status()\n    <span class=\"pl-c1\">465</span>           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">466</span>           pywrap_tensorflow.TF_GetCode(status))\n    <span class=\"pl-c1\">467</span>   <span class=\"pl-k\">finally</span>:\n\nInvalidArgumentError: Shape must be rank <span class=\"pl-c1\">2</span> but <span class=\"pl-k\">is</span> rank <span class=\"pl-c1\">1</span> <span class=\"pl-k\">for</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>gradients_4/SelfAdjointEigV2_16_grad/MatMul<span class=\"pl-pds\">'</span></span> (op: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>MatMul<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">with</span> <span class=\"pl-c1\">input</span> shapes: [<span class=\"pl-c1\">0</span>], [<span class=\"pl-c1\">0</span>].\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"pl-c1\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">53</span><span class=\"pl-k\">-</span>c60afbcdc03b<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n      <span class=\"pl-c1\">5</span> pure_eigvals <span class=\"pl-k\">=</span> tf.self_adjoint_eigvals(covar)\n      <span class=\"pl-c1\">6</span> tf.Session().run(tf.gradients(eigvals, a))\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">7</span> tf.Session().run(tf.gradients(pure_eigvals, a))\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gradients_impl.py <span class=\"pl-k\">in</span> gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\n    <span class=\"pl-c1\">538</span>                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> functions.</span>\n    <span class=\"pl-c1\">539</span>                 in_grads <span class=\"pl-k\">=</span> _MaybeCompile(\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">540</span>                     grad_scope, op, func_call, <span class=\"pl-k\">lambda</span>: grad_fn(op, <span class=\"pl-k\">*</span>out_grads))\n    <span class=\"pl-c1\">541</span>               <span class=\"pl-k\">else</span>:\n    <span class=\"pl-c1\">542</span>                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> For function call ops, we add a 'SymbolicGradient'</span>\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gradients_impl.py <span class=\"pl-k\">in</span> _MaybeCompile(scope, op, func, grad_fn)\n    <span class=\"pl-c1\">344</span>       xla_scope <span class=\"pl-k\">=</span> op.get_attr(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>_XlaScope<span class=\"pl-pds\">\"</span></span>).decode()\n    <span class=\"pl-c1\">345</span>     <span class=\"pl-k\">except</span> <span class=\"pl-c1\">ValueError</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">346</span>       <span class=\"pl-k\">return</span> grad_fn()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Exit early</span>\n    <span class=\"pl-c1\">347</span> \n    <span class=\"pl-c1\">348</span>   <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> xla_compile:\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gradients_impl.py <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span><span class=\"pl-k\">lambda</span>&gt;()\n    <span class=\"pl-c1\">538</span>                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> functions.</span>\n    <span class=\"pl-c1\">539</span>                 in_grads <span class=\"pl-k\">=</span> _MaybeCompile(\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">540</span>                     grad_scope, op, func_call, <span class=\"pl-k\">lambda</span>: grad_fn(op, <span class=\"pl-k\">*</span>out_grads))\n    <span class=\"pl-c1\">541</span>               <span class=\"pl-k\">else</span>:\n    <span class=\"pl-c1\">542</span>                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> For function call ops, we add a 'SymbolicGradient'</span>\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>linalg_grad.py <span class=\"pl-k\">in</span> _SelfAdjointEigV2Grad(op, grad_e, grad_v)\n    <span class=\"pl-c1\">203</span>           math_ops.matmul(\n    <span class=\"pl-c1\">204</span>               array_ops.matrix_diag(grad_e) <span class=\"pl-k\">+</span> f <span class=\"pl-k\">*</span> math_ops.matmul(\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">205</span>                   v, grad_v, <span class=\"pl-v\">adjoint_a</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>),\n    <span class=\"pl-c1\">206</span>               v,\n    <span class=\"pl-c1\">207</span>               <span class=\"pl-v\">adjoint_b</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>math_ops.py <span class=\"pl-k\">in</span> matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\n   <span class=\"pl-c1\">1814</span>     <span class=\"pl-k\">else</span>:\n   <span class=\"pl-c1\">1815</span>       <span class=\"pl-k\">return</span> gen_math_ops._mat_mul(\n<span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">1816</span>           a, b, <span class=\"pl-v\">transpose_a</span><span class=\"pl-k\">=</span>transpose_a, <span class=\"pl-v\">transpose_b</span><span class=\"pl-k\">=</span>transpose_b, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n   <span class=\"pl-c1\">1817</span> \n   <span class=\"pl-c1\">1818</span> \n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>stj<span class=\"pl-k\">/</span>pio<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>ops<span class=\"pl-k\">/</span>gen_math_ops.py <span class=\"pl-k\">in</span> _mat_mul(a, b, transpose_a, transpose_b, name)\n   <span class=\"pl-c1\">1215</span>   <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">   1216   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,</span>\n<span class=\"pl-s\">-&gt; 1217                                 transpose_b=transpose_b, name=name)</span>\n<span class=\"pl-s\">   1218   return result</span>\n<span class=\"pl-s\">   1219 </span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in apply_op(self, op_type_name, name, **keywords)</span>\n<span class=\"pl-s\">    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,</span>\n<span class=\"pl-s\">    766                          input_types=input_types, attrs=attr_protos,</span>\n<span class=\"pl-s\">--&gt; 767                          op_def=op_def)</span>\n<span class=\"pl-s\">    768         if output_structure:</span>\n<span class=\"pl-s\">    769           outputs = op.outputs</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)</span>\n<span class=\"pl-s\">   2506                     original_op=self._default_original_op, op_def=op_def)</span>\n<span class=\"pl-s\">   2507     if compute_shapes:</span>\n<span class=\"pl-s\">-&gt; 2508       set_shapes_for_outputs(ret)</span>\n<span class=\"pl-s\">   2509     self._add_op(ret)</span>\n<span class=\"pl-s\">   2510     self._record_op_seen_by_control_dependencies(ret)</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op)</span>\n<span class=\"pl-s\">   1871       shape_func = _call_cpp_shape_fn_and_require_op</span>\n<span class=\"pl-s\">   1872 </span>\n<span class=\"pl-s\">-&gt; 1873   shapes = shape_func(op)</span>\n<span class=\"pl-s\">   1874   if shapes is None:</span>\n<span class=\"pl-s\">   1875     raise RuntimeError(</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op)</span>\n<span class=\"pl-s\">   1821 </span>\n<span class=\"pl-s\">   1822   def call_with_requiring(op):</span>\n<span class=\"pl-s\">-&gt; 1823     return call_cpp_shape_fn(op, require_shape_fn=True)</span>\n<span class=\"pl-s\">   1824 </span>\n<span class=\"pl-s\">   1825   _call_cpp_shape_fn_and_require_op = call_with_requiring</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)</span>\n<span class=\"pl-s\">    608     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,</span>\n<span class=\"pl-s\">    609                                   input_tensors_as_shapes_needed,</span>\n<span class=\"pl-s\">--&gt; 610                                   debug_python_shape_fn, require_shape_fn)</span>\n<span class=\"pl-s\">    611     if not isinstance(res, dict):</span>\n<span class=\"pl-s\">    612       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)</span>\n<span class=\"pl-s\">    674       missing_shape_fn = True</span>\n<span class=\"pl-s\">    675     else:</span>\n<span class=\"pl-s\">--&gt; 676       raise ValueError(err.message)</span>\n<span class=\"pl-s\">    677 </span>\n<span class=\"pl-s\">    678   if missing_shape_fn:</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">ValueError: Shape must be rank 2 but is rank 1 for 'gradients_4/SelfAdjointEigV2_16_grad/MatMul' (op: 'MatMul') with input shapes: [0], [0].</span></pre></div>\n<p>Thanks!</p>", "body_text": "As also noted in #1915 already (but that ticket had been closed), there is a bug in the implementation of self_adjoint_eigvals (whereas self_adjoint_eig works fine, but it is rather inefficient to compute eigenvectors and their gradients if I only require the eigenvalues!).\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no - stock usage of tf.self_adjoint_eigvals - minimal failing example below\nOS Platform and Distribution:  Linux Ubuntu 16.04\nTensorFlow installed from: source\nTensorFlow version: v1.2.1-2-gc996c7b\nPython version: 3.5.2\nBazel version (if compiling from source): 0.5.2 (binary install)\nCUDA/cuDNN version: 8.0\nGPU model and memory: GeForce GTX 1070 with 8 GB memory\nExact command to reproduce: see below\n\nMinimal failing example:\na = tf.random_normal((10000,3))\ncovar = tf.matmul(tf.transpose(a), a)\neigvals, eigvect_holder = tf.self_adjoint_eig(covar)\neigvects = tf.transpose(eigvect_holder)\npure_eigvals = tf.self_adjoint_eigvals(covar)\ntf.Session().run(tf.gradients(eigvals, a))  # works fine\ntf.Session().run(tf.gradients(pure_eigvals, a))  # throws the error below\nError message:\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\n    340     try:\n--> 341       xla_compile = op.get_attr(\"_XlaCompile\")\n    342       xla_separate_compiled_gradients = op.get_attr(\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\n   1666       raise ValueError(\"No attr named '\" + name + \"' in \" +\n-> 1667                        str(self._node_def))\n   1668     x = self._node_def.attr[name]\n\nValueError: No attr named '_XlaCompile' in name: \"SelfAdjointEigV2_16\"\nop: \"SelfAdjointEigV2\"\ninput: \"MatMul_5\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"compute_v\"\n  value {\n    b: false\n  }\n}\n\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\n    670           graph_def_version, node_def_str, input_shapes, input_tensors,\n--> 671           input_tensors_as_shapes, status)\n    672   except errors.InvalidArgumentError as err:\n\n/usr/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n\nInvalidArgumentError: Shape must be rank 2 but is rank 1 for 'gradients_4/SelfAdjointEigV2_16_grad/MatMul' (op: 'MatMul') with input shapes: [0], [0].\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n<ipython-input-53-c60afbcdc03b> in <module>()\n      5 pure_eigvals = tf.self_adjoint_eigvals(covar)\n      6 tf.Session().run(tf.gradients(eigvals, a))\n----> 7 tf.Session().run(tf.gradients(pure_eigvals, a))\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\n    538                 # functions.\n    539                 in_grads = _MaybeCompile(\n--> 540                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n    541               else:\n    542                 # For function call ops, we add a 'SymbolicGradient'\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\n    344       xla_scope = op.get_attr(\"_XlaScope\").decode()\n    345     except ValueError:\n--> 346       return grad_fn()  # Exit early\n    347 \n    348   if not xla_compile:\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in <lambda>()\n    538                 # functions.\n    539                 in_grads = _MaybeCompile(\n--> 540                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n    541               else:\n    542                 # For function call ops, we add a 'SymbolicGradient'\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/linalg_grad.py in _SelfAdjointEigV2Grad(op, grad_e, grad_v)\n    203           math_ops.matmul(\n    204               array_ops.matrix_diag(grad_e) + f * math_ops.matmul(\n--> 205                   v, grad_v, adjoint_a=True),\n    206               v,\n    207               adjoint_b=True))\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\n   1814     else:\n   1815       return gen_math_ops._mat_mul(\n-> 1816           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n   1817 \n   1818 \n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py in _mat_mul(a, b, transpose_a, transpose_b, name)\n   1215   \"\"\"\n   1216   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n-> 1217                                 transpose_b=transpose_b, name=name)\n   1218   return result\n   1219 \n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in apply_op(self, op_type_name, name, **keywords)\n    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    766                          input_types=input_types, attrs=attr_protos,\n--> 767                          op_def=op_def)\n    768         if output_structure:\n    769           outputs = op.outputs\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\n   2506                     original_op=self._default_original_op, op_def=op_def)\n   2507     if compute_shapes:\n-> 2508       set_shapes_for_outputs(ret)\n   2509     self._add_op(ret)\n   2510     self._record_op_seen_by_control_dependencies(ret)\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op)\n   1871       shape_func = _call_cpp_shape_fn_and_require_op\n   1872 \n-> 1873   shapes = shape_func(op)\n   1874   if shapes is None:\n   1875     raise RuntimeError(\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op)\n   1821 \n   1822   def call_with_requiring(op):\n-> 1823     return call_cpp_shape_fn(op, require_shape_fn=True)\n   1824 \n   1825   _call_cpp_shape_fn_and_require_op = call_with_requiring\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\n    608     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n    609                                   input_tensors_as_shapes_needed,\n--> 610                                   debug_python_shape_fn, require_shape_fn)\n    611     if not isinstance(res, dict):\n    612       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\n\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\n    674       missing_shape_fn = True\n    675     else:\n--> 676       raise ValueError(err.message)\n    677 \n    678   if missing_shape_fn:\n\nValueError: Shape must be rank 2 but is rank 1 for 'gradients_4/SelfAdjointEigV2_16_grad/MatMul' (op: 'MatMul') with input shapes: [0], [0].\nThanks!", "body": "As also noted in #1915 already (but that ticket had been closed), there is a bug in the implementation of `self_adjoint_eigvals` (whereas `self_adjoint_eig` works fine, but it is rather inefficient to compute eigenvectors and their gradients if I only require the eigenvalues!).\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no - stock usage of `tf.self_adjoint_eigvals` - minimal failing example below\r\n- **OS Platform and Distribution**:  Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: v1.2.1-2-gc996c7b\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.5.2 (binary install)\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce GTX 1070 with 8 GB memory\r\n- **Exact command to reproduce**: see below\r\n\r\n## Minimal failing example:\r\n```python\r\na = tf.random_normal((10000,3))\r\ncovar = tf.matmul(tf.transpose(a), a)\r\neigvals, eigvect_holder = tf.self_adjoint_eig(covar)\r\neigvects = tf.transpose(eigvect_holder)\r\npure_eigvals = tf.self_adjoint_eigvals(covar)\r\ntf.Session().run(tf.gradients(eigvals, a))  # works fine\r\ntf.Session().run(tf.gradients(pure_eigvals, a))  # throws the error below\r\n```\r\n\r\n### Error message:\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    340     try:\r\n--> 341       xla_compile = op.get_attr(\"_XlaCompile\")\r\n    342       xla_separate_compiled_gradients = op.get_attr(\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\r\n   1666       raise ValueError(\"No attr named '\" + name + \"' in \" +\r\n-> 1667                        str(self._node_def))\r\n   1668     x = self._node_def.attr[name]\r\n\r\nValueError: No attr named '_XlaCompile' in name: \"SelfAdjointEigV2_16\"\r\nop: \"SelfAdjointEigV2\"\r\ninput: \"MatMul_5\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"compute_v\"\r\n  value {\r\n    b: false\r\n  }\r\n}\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\r\n    670           graph_def_version, node_def_str, input_shapes, input_tensors,\r\n--> 671           input_tensors_as_shapes, status)\r\n    672   except errors.InvalidArgumentError as err:\r\n\r\n/usr/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n\r\nInvalidArgumentError: Shape must be rank 2 but is rank 1 for 'gradients_4/SelfAdjointEigV2_16_grad/MatMul' (op: 'MatMul') with input shapes: [0], [0].\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-53-c60afbcdc03b> in <module>()\r\n      5 pure_eigvals = tf.self_adjoint_eigvals(covar)\r\n      6 tf.Session().run(tf.gradients(eigvals, a))\r\n----> 7 tf.Session().run(tf.gradients(pure_eigvals, a))\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\r\n    538                 # functions.\r\n    539                 in_grads = _MaybeCompile(\r\n--> 540                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n    541               else:\r\n    542                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    344       xla_scope = op.get_attr(\"_XlaScope\").decode()\r\n    345     except ValueError:\r\n--> 346       return grad_fn()  # Exit early\r\n    347 \r\n    348   if not xla_compile:\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py in <lambda>()\r\n    538                 # functions.\r\n    539                 in_grads = _MaybeCompile(\r\n--> 540                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n    541               else:\r\n    542                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/linalg_grad.py in _SelfAdjointEigV2Grad(op, grad_e, grad_v)\r\n    203           math_ops.matmul(\r\n    204               array_ops.matrix_diag(grad_e) + f * math_ops.matmul(\r\n--> 205                   v, grad_v, adjoint_a=True),\r\n    206               v,\r\n    207               adjoint_b=True))\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\r\n   1814     else:\r\n   1815       return gen_math_ops._mat_mul(\r\n-> 1816           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n   1817 \r\n   1818 \r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py in _mat_mul(a, b, transpose_a, transpose_b, name)\r\n   1215   \"\"\"\r\n   1216   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\r\n-> 1217                                 transpose_b=transpose_b, name=name)\r\n   1218   return result\r\n   1219 \r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in apply_op(self, op_type_name, name, **keywords)\r\n    765         op = g.create_op(op_type_name, inputs, output_types, name=scope,\r\n    766                          input_types=input_types, attrs=attr_protos,\r\n--> 767                          op_def=op_def)\r\n    768         if output_structure:\r\n    769           outputs = op.outputs\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\r\n   2506                     original_op=self._default_original_op, op_def=op_def)\r\n   2507     if compute_shapes:\r\n-> 2508       set_shapes_for_outputs(ret)\r\n   2509     self._add_op(ret)\r\n   2510     self._record_op_seen_by_control_dependencies(ret)\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op)\r\n   1871       shape_func = _call_cpp_shape_fn_and_require_op\r\n   1872 \r\n-> 1873   shapes = shape_func(op)\r\n   1874   if shapes is None:\r\n   1875     raise RuntimeError(\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op)\r\n   1821 \r\n   1822   def call_with_requiring(op):\r\n-> 1823     return call_cpp_shape_fn(op, require_shape_fn=True)\r\n   1824 \r\n   1825   _call_cpp_shape_fn_and_require_op = call_with_requiring\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\r\n    608     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\r\n    609                                   input_tensors_as_shapes_needed,\r\n--> 610                                   debug_python_shape_fn, require_shape_fn)\r\n    611     if not isinstance(res, dict):\r\n    612       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\r\n\r\n/home/stj/pio/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\r\n    674       missing_shape_fn = True\r\n    675     else:\r\n--> 676       raise ValueError(err.message)\r\n    677 \r\n    678   if missing_shape_fn:\r\n\r\nValueError: Shape must be rank 2 but is rank 1 for 'gradients_4/SelfAdjointEigV2_16_grad/MatMul' (op: 'MatMul') with input shapes: [0], [0].\r\n```\r\n\r\nThanks!"}