{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20921", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20921/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20921/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20921/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20921", "id": 342293441, "node_id": "MDU6SXNzdWUzNDIyOTM0NDE=", "number": 20921, "title": " ValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'", "user": {"login": "elksie5000", "id": 890324, "node_id": "MDQ6VXNlcjg5MDMyNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/890324?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elksie5000", "html_url": "https://github.com/elksie5000", "followers_url": "https://api.github.com/users/elksie5000/followers", "following_url": "https://api.github.com/users/elksie5000/following{/other_user}", "gists_url": "https://api.github.com/users/elksie5000/gists{/gist_id}", "starred_url": "https://api.github.com/users/elksie5000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elksie5000/subscriptions", "organizations_url": "https://api.github.com/users/elksie5000/orgs", "repos_url": "https://api.github.com/users/elksie5000/repos", "events_url": "https://api.github.com/users/elksie5000/events{/privacy}", "received_events_url": "https://api.github.com/users/elksie5000/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-07-18T11:45:27Z", "updated_at": "2018-07-18T22:14:29Z", "closed_at": "2018-07-18T22:14:29Z", "author_association": "NONE", "body_html": "<p>I'm very new to Tensorflow. And it hurts. A lot.</p>\n<h1>coding: utf-8</h1>\n<h1># Training a DCGAN to draw fake and real images</h1>\n<h1>In[1]:</h1>\n<p>directory = \"../Data/image_files/\"<br>\nnew_dir = \"../Data/image_files/cropped\"<br>\nimport urllib<br>\nimport urllib.request<br>\nimport tarfile<br>\nimport os<br>\nimport tarfile<br>\nimport numpy as np<br>\nimport matplotlib.pyplot as plt<br>\nfrom matplotlib.image import imread<br>\nfrom scipy.misc import imresize, imsave<br>\nimport tensorflow as tf<br>\nimport imageio<br>\nimport skimage<br>\nget_ipython().run_line_magic('matplotlib', 'inline')</p>\n<h1>## Modifying the images (reducing their size)</h1>\n<h1>In[2]:</h1>\n<p>height_width = 100</p>\n<p>filepaths = []<br>\nfor dir_, <em>, files in os.walk(directory):<br>\nfor fileName in files:<br>\nrelDir = os.path.relpath(dir</em>, directory)<br>\nrelFile = os.path.join(relDir, fileName)<br>\nfilepaths.append(directory + \"/\" + relFile)<br>\nfail_count = 0<br>\nfor i, fp in enumerate(filepaths):<br>\ntry:<br>\nimg = imread(fp, 0) #/ 255.0<br>\nimg = skimage.transform.resize(img, (height_width, height_width))<br>\nimageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)<br>\nexcept:<br>\nfail_count += 1<br>\nimg = imread(\"../Data/white_square.png\", 0) #/ 100 width square<br>\nimageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)<br>\nwith open(\"../Data/fail_log.text\", \"a+\") as f:<br>\nf.write(fp)<br>\nprint(fail_count)</p>\n<h1>Load the file names of files into a list</h1>\n<h1>In[3]:</h1>\n<p>filepaths_new = []<br>\nfor dir_, <em>, files in os.walk(new_dir):<br>\nfor fileName in files:<br>\nif not fileName.endswith(\".png\"):<br>\ncontinue<br>\nrelDir = os.path.relpath(dir</em>, directory)<br>\nrelFile = os.path.join(relDir, fileName)<br>\nfilepaths_new.append(directory + \"/\" + relFile)</p>\n<h1>## Define next batch</h1>\n<h1>In[4]:</h1>\n<p>def next_batch(num=64, data=filepaths_new):<br>\nidx = np.arange(0 , len(data))<br>\nnp.random.shuffle(idx)<br>\nidx = idx[:num]<br>\nprint(idx)<br>\ndata_shuffle = [imread(data[i]) for i in idx]</p>\n<pre><code>shuffled = np.asarray(data_shuffle)\nprint(\"shuffled:\", shuffled.shape)\nreturn np.asarray(data_shuffle)\n</code></pre>\n<h1>## Code for creating montages (by Parag Mital)</h1>\n<h1>In[5]:</h1>\n<h1>Code by Parag Mital (<a href=\"https://github.com/pkmital/CADL/\">https://github.com/pkmital/CADL/</a>)</h1>\n<p>def montage(images):<br>\nif isinstance(images, list):<br>\nimages = np.array(images)<br>\nimg_h = images.shape[1]<br>\nimg_w = images.shape[2]<br>\nn_plots = int(np.ceil(np.sqrt(images.shape[0])))<br>\nif len(images.shape) == 4 and images.shape[3] == 3:<br>\nm = np.ones(<br>\n(images.shape[1] * n_plots + n_plots + 1,<br>\nimages.shape[2] * n_plots + n_plots + 1, 3)) * 0.5<br>\nelif len(images.shape) == 4 and images.shape[3] == 1:<br>\nm = np.ones(<br>\n(images.shape[1] * n_plots + n_plots + 1,<br>\nimages.shape[2] * n_plots + n_plots + 1, 1)) * 0.5<br>\nelif len(images.shape) == 3:<br>\nm = np.ones(<br>\n(images.shape[1] * n_plots + n_plots + 1,<br>\nimages.shape[2] * n_plots + n_plots + 1)) * 0.5<br>\nelse:<br>\nraise ValueError('Could not parse image shape of {}'.format(<br>\nimages.shape))<br>\nfor i in range(n_plots):<br>\nfor j in range(n_plots):<br>\nthis_filter = i * n_plots + j<br>\nif this_filter &lt; images.shape[0]:<br>\nthis_img = images[this_filter]<br>\nm[1 + i + i * img_h:1 + i + (i + 1) * img_h,<br>\n1 + j + j * img_w:1 + j + (j + 1) * img_w] = this_img<br>\nreturn m</p>\n<h1>## Definition of the neural network</h1>\n<h1>In[6]:</h1>\n<p>tf.reset_default_graph()<br>\nbatch_size = 5<br>\nn_noise = 28</p>\n<p>#config = tf.ConfigProto()<br>\n#config.gpu_options.allocator_type ='BFC'<br>\n#config.gpu_options.per_process_gpu_memory_fraction = 0.90</p>\n<p>X_in = tf.placeholder(dtype=tf.float32, shape=[None, height_width, height_width], name='X')<br>\nnoise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])</p>\n<p>keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')<br>\nis_training = tf.placeholder(dtype=tf.bool, name='is_training')</p>\n<p>def lrelu(x):<br>\nreturn tf.maximum(x, tf.multiply(x, 0.2))</p>\n<p>def binary_cross_entropy(x, z):<br>\neps = 1e-12<br>\nreturn (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))</p>\n<p>def discriminator(img_in, reuse=None, keep_prob=keep_prob):<br>\nactivation = lrelu<br>\nwith tf.variable_scope(\"discriminator\", reuse=reuse):<br>\nx = tf.reshape(img_in, shape=[-1, height_width, height_width, 3])<br>\nx = tf.layers.conv2d(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)<br>\nx = tf.layers.dropout(x, keep_prob)<br>\nx = tf.layers.conv2d(x, kernel_size=5, filters=128, strides=1, padding='same', activation=activation)<br>\nx = tf.layers.dropout(x, keep_prob)<br>\nx = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)<br>\nx = tf.layers.dropout(x, keep_prob)<br>\nx = tf.contrib.layers.flatten(x)<br>\nx = tf.layers.dense(x, units=128, activation=activation)<br>\nx = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)<br>\nreturn x</p>\n<p>def generator(z, keep_prob=keep_prob, is_training=is_training):<br>\nactivation = lrelu<br>\nmomentum = 0.9<br>\nwith tf.variable_scope(\"generator\", reuse=None):<br>\nx = z</p>\n<pre><code>    d1 = 4#3\n    d2 = 3\n    \n    x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\n    x = tf.layers.dropout(x, keep_prob)      \n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)  \n    \n    x = tf.reshape(x, shape=[-1, d1, d1, d2])\n    x = tf.image.resize_images(x, size=[50, 50])\n    \n    \n    \n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=128, strides=2, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=3, strides=1, padding='same', activation=tf.nn.sigmoid)\n    return x    \n</code></pre>\n<h1>In[ ]:</h1>\n<h1>## Losses and optimizers</h1>\n<h1>In[7]:</h1>\n<p>g = generator(noise, keep_prob, is_training)<br>\nprint(g)<br>\nd_real = discriminator(X_in)<br>\nd_fake = discriminator(g, reuse=True)</p>\n<p>vars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]<br>\nvars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]</p>\n<p>d_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)<br>\ng_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)</p>\n<p>loss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)<br>\nloss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)<br>\nloss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))</p>\n<p>loss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))</p>\n<p>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)<br>\nwith tf.control_dependencies(update_ops):<br>\noptimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss_d + d_reg, var_list=vars_d)<br>\noptimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.0002).minimize(loss_g + g_reg, var_list=vars_g)<br>\nsess = tf.Session()<br>\nsess.run(tf.global_variables_initializer())</p>\n<h1>## Training the network</h1>\n<h1>In[8]:</h1>\n<p>for i in range(60000):<br>\ntrain_d = True<br>\ntrain_g = True<br>\nkeep_prob_train = 0.6 # 0.5</p>\n<pre><code>n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \nbatch = [b for b in next_batch(num=batch_size)]  \n\nd_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\n\nd_fake_ls_init = d_fake_ls\n\nd_real_ls = np.mean(d_real_ls)\nd_fake_ls = np.mean(d_fake_ls)\ng_ls = g_ls\nd_ls = d_ls\n    \nif g_ls * 1.35 &lt; d_ls:\n    train_g = False\n    pass\nif d_ls * 1.35 &lt; g_ls:\n    train_d = False\n    pass\n\nif train_d:\n    sess.run(optimizer_d, feed_dict={noise: n, X_in: batch, keep_prob: keep_prob_train, is_training:True})\n    \n    \nif train_g:\n    sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})\n    \n    \nif not i % 10:\n    print (i, d_ls, g_ls)\n    if not train_g:\n        print(\"not training generator\")\n    if not train_d:\n        print(\"not training discriminator\")\n    gen_imgs = sess.run(g, feed_dict = {noise: n, keep_prob: 1.0, is_training:False})\n    imgs = [img[:,:,:] for img in gen_imgs]\n    m = montage(imgs)\n    #m = imgs[0]\n    plt.axis('off')\n    plt.imshow(m, cmap='gray')\n    plt.show()\n</code></pre>\n<h2>Generates this error.</h2>\n<p>ValueError                                Traceback (most recent call last)<br>\n in ()<br>\n8     batch = [b for b in next_batch(num=batch_size)]<br>\n9<br>\n---&gt; 10     d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})<br>\n11<br>\n12     d_fake_ls_init = d_fake_ls</p>\n<p>~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)<br>\n898     try:<br>\n899       result = self._run(None, fetches, feed_dict, options_ptr,<br>\n--&gt; 900                          run_metadata_ptr)<br>\n901       if run_metadata:<br>\n902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)</p>\n<p>~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)<br>\n1109                              'which has shape %r' %<br>\n1110                              (np_val.shape, subfeed_t.name,<br>\n-&gt; 1111                               str(subfeed_t.get_shape())))<br>\n1112           if not self.graph.is_feedable(subfeed_t):<br>\n1113             raise ValueError('Tensor %s may not be fed.' % subfeed_t)</p>\n<p>ValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'</p>\n<p>No idea how to debug this. Need a bit of help.</p>", "body_text": "I'm very new to Tensorflow. And it hurts. A lot.\ncoding: utf-8\n# Training a DCGAN to draw fake and real images\nIn[1]:\ndirectory = \"../Data/image_files/\"\nnew_dir = \"../Data/image_files/cropped\"\nimport urllib\nimport urllib.request\nimport tarfile\nimport os\nimport tarfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom scipy.misc import imresize, imsave\nimport tensorflow as tf\nimport imageio\nimport skimage\nget_ipython().run_line_magic('matplotlib', 'inline')\n## Modifying the images (reducing their size)\nIn[2]:\nheight_width = 100\nfilepaths = []\nfor dir_, , files in os.walk(directory):\nfor fileName in files:\nrelDir = os.path.relpath(dir, directory)\nrelFile = os.path.join(relDir, fileName)\nfilepaths.append(directory + \"/\" + relFile)\nfail_count = 0\nfor i, fp in enumerate(filepaths):\ntry:\nimg = imread(fp, 0) #/ 255.0\nimg = skimage.transform.resize(img, (height_width, height_width))\nimageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)\nexcept:\nfail_count += 1\nimg = imread(\"../Data/white_square.png\", 0) #/ 100 width square\nimageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)\nwith open(\"../Data/fail_log.text\", \"a+\") as f:\nf.write(fp)\nprint(fail_count)\nLoad the file names of files into a list\nIn[3]:\nfilepaths_new = []\nfor dir_, , files in os.walk(new_dir):\nfor fileName in files:\nif not fileName.endswith(\".png\"):\ncontinue\nrelDir = os.path.relpath(dir, directory)\nrelFile = os.path.join(relDir, fileName)\nfilepaths_new.append(directory + \"/\" + relFile)\n## Define next batch\nIn[4]:\ndef next_batch(num=64, data=filepaths_new):\nidx = np.arange(0 , len(data))\nnp.random.shuffle(idx)\nidx = idx[:num]\nprint(idx)\ndata_shuffle = [imread(data[i]) for i in idx]\nshuffled = np.asarray(data_shuffle)\nprint(\"shuffled:\", shuffled.shape)\nreturn np.asarray(data_shuffle)\n\n## Code for creating montages (by Parag Mital)\nIn[5]:\nCode by Parag Mital (https://github.com/pkmital/CADL/)\ndef montage(images):\nif isinstance(images, list):\nimages = np.array(images)\nimg_h = images.shape[1]\nimg_w = images.shape[2]\nn_plots = int(np.ceil(np.sqrt(images.shape[0])))\nif len(images.shape) == 4 and images.shape[3] == 3:\nm = np.ones(\n(images.shape[1] * n_plots + n_plots + 1,\nimages.shape[2] * n_plots + n_plots + 1, 3)) * 0.5\nelif len(images.shape) == 4 and images.shape[3] == 1:\nm = np.ones(\n(images.shape[1] * n_plots + n_plots + 1,\nimages.shape[2] * n_plots + n_plots + 1, 1)) * 0.5\nelif len(images.shape) == 3:\nm = np.ones(\n(images.shape[1] * n_plots + n_plots + 1,\nimages.shape[2] * n_plots + n_plots + 1)) * 0.5\nelse:\nraise ValueError('Could not parse image shape of {}'.format(\nimages.shape))\nfor i in range(n_plots):\nfor j in range(n_plots):\nthis_filter = i * n_plots + j\nif this_filter < images.shape[0]:\nthis_img = images[this_filter]\nm[1 + i + i * img_h:1 + i + (i + 1) * img_h,\n1 + j + j * img_w:1 + j + (j + 1) * img_w] = this_img\nreturn m\n## Definition of the neural network\nIn[6]:\ntf.reset_default_graph()\nbatch_size = 5\nn_noise = 28\n#config = tf.ConfigProto()\n#config.gpu_options.allocator_type ='BFC'\n#config.gpu_options.per_process_gpu_memory_fraction = 0.90\nX_in = tf.placeholder(dtype=tf.float32, shape=[None, height_width, height_width], name='X')\nnoise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\nkeep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\nis_training = tf.placeholder(dtype=tf.bool, name='is_training')\ndef lrelu(x):\nreturn tf.maximum(x, tf.multiply(x, 0.2))\ndef binary_cross_entropy(x, z):\neps = 1e-12\nreturn (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))\ndef discriminator(img_in, reuse=None, keep_prob=keep_prob):\nactivation = lrelu\nwith tf.variable_scope(\"discriminator\", reuse=reuse):\nx = tf.reshape(img_in, shape=[-1, height_width, height_width, 3])\nx = tf.layers.conv2d(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\nx = tf.layers.dropout(x, keep_prob)\nx = tf.layers.conv2d(x, kernel_size=5, filters=128, strides=1, padding='same', activation=activation)\nx = tf.layers.dropout(x, keep_prob)\nx = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\nx = tf.layers.dropout(x, keep_prob)\nx = tf.contrib.layers.flatten(x)\nx = tf.layers.dense(x, units=128, activation=activation)\nx = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\nreturn x\ndef generator(z, keep_prob=keep_prob, is_training=is_training):\nactivation = lrelu\nmomentum = 0.9\nwith tf.variable_scope(\"generator\", reuse=None):\nx = z\n    d1 = 4#3\n    d2 = 3\n    \n    x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\n    x = tf.layers.dropout(x, keep_prob)      \n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)  \n    \n    x = tf.reshape(x, shape=[-1, d1, d1, d2])\n    x = tf.image.resize_images(x, size=[50, 50])\n    \n    \n    \n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=128, strides=2, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n    x = tf.layers.dropout(x, keep_prob)\n    x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n    x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=3, strides=1, padding='same', activation=tf.nn.sigmoid)\n    return x    \n\nIn[ ]:\n## Losses and optimizers\nIn[7]:\ng = generator(noise, keep_prob, is_training)\nprint(g)\nd_real = discriminator(X_in)\nd_fake = discriminator(g, reuse=True)\nvars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\nvars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\nd_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\ng_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\nloss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\nloss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\nloss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\nloss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nwith tf.control_dependencies(update_ops):\noptimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss_d + d_reg, var_list=vars_d)\noptimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.0002).minimize(loss_g + g_reg, var_list=vars_g)\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n## Training the network\nIn[8]:\nfor i in range(60000):\ntrain_d = True\ntrain_g = True\nkeep_prob_train = 0.6 # 0.5\nn = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \nbatch = [b for b in next_batch(num=batch_size)]  \n\nd_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\n\nd_fake_ls_init = d_fake_ls\n\nd_real_ls = np.mean(d_real_ls)\nd_fake_ls = np.mean(d_fake_ls)\ng_ls = g_ls\nd_ls = d_ls\n    \nif g_ls * 1.35 < d_ls:\n    train_g = False\n    pass\nif d_ls * 1.35 < g_ls:\n    train_d = False\n    pass\n\nif train_d:\n    sess.run(optimizer_d, feed_dict={noise: n, X_in: batch, keep_prob: keep_prob_train, is_training:True})\n    \n    \nif train_g:\n    sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})\n    \n    \nif not i % 10:\n    print (i, d_ls, g_ls)\n    if not train_g:\n        print(\"not training generator\")\n    if not train_d:\n        print(\"not training discriminator\")\n    gen_imgs = sess.run(g, feed_dict = {noise: n, keep_prob: 1.0, is_training:False})\n    imgs = [img[:,:,:] for img in gen_imgs]\n    m = montage(imgs)\n    #m = imgs[0]\n    plt.axis('off')\n    plt.imshow(m, cmap='gray')\n    plt.show()\n\nGenerates this error.\nValueError                                Traceback (most recent call last)\n in ()\n8     batch = [b for b in next_batch(num=batch_size)]\n9\n---> 10     d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\n11\n12     d_fake_ls_init = d_fake_ls\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\n898     try:\n899       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 900                          run_metadata_ptr)\n901       if run_metadata:\n902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n1109                              'which has shape %r' %\n1110                              (np_val.shape, subfeed_t.name,\n-> 1111                               str(subfeed_t.get_shape())))\n1112           if not self.graph.is_feedable(subfeed_t):\n1113             raise ValueError('Tensor %s may not be fed.' % subfeed_t)\nValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'\nNo idea how to debug this. Need a bit of help.", "body": "I'm very new to Tensorflow. And it hurts. A lot.\r\n \r\n# coding: utf-8\r\n\r\n# # Training a DCGAN to draw fake and real images\r\n\r\n# In[1]:\r\n\r\n\r\ndirectory = \"../Data/image_files/\"\r\nnew_dir = \"../Data/image_files/cropped\"\r\nimport urllib\r\nimport urllib.request\r\nimport tarfile\r\nimport os\r\nimport tarfile\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.image import imread\r\nfrom scipy.misc import imresize, imsave\r\nimport tensorflow as tf\r\nimport imageio\r\nimport skimage\r\nget_ipython().run_line_magic('matplotlib', 'inline')\r\n\r\n\r\n# ## Modifying the images (reducing their size)\r\n\r\n# In[2]:\r\n\r\n\r\nheight_width = 100\r\n\r\nfilepaths = []\r\nfor dir_, _, files in os.walk(directory):\r\n    for fileName in files:\r\n        relDir = os.path.relpath(dir_, directory)\r\n        relFile = os.path.join(relDir, fileName)\r\n        filepaths.append(directory + \"/\" + relFile)\r\nfail_count = 0         \r\nfor i, fp in enumerate(filepaths):\r\n    try: \r\n        img = imread(fp, 0) #/ 255.0\r\n        img = skimage.transform.resize(img, (height_width, height_width))\r\n        imageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)        \r\n    except:\r\n        fail_count += 1\r\n        img = imread(\"../Data/white_square.png\", 0) #/ 100 width square\r\n        imageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img) \r\n        with open(\"../Data/fail_log.text\", \"a+\") as f:\r\n            f.write(fp)\r\nprint(fail_count)\r\n\r\n\r\n# Load the file names of files into a list\r\n\r\n# In[3]:\r\n\r\n\r\nfilepaths_new = []\r\nfor dir_, _, files in os.walk(new_dir):\r\n    for fileName in files:\r\n        if not fileName.endswith(\".png\"):\r\n            continue\r\n        relDir = os.path.relpath(dir_, directory)\r\n        relFile = os.path.join(relDir, fileName)\r\n        filepaths_new.append(directory + \"/\" + relFile)\r\n\r\n\r\n# ## Define next batch\r\n\r\n# In[4]:\r\n\r\n\r\ndef next_batch(num=64, data=filepaths_new):\r\n    idx = np.arange(0 , len(data))\r\n    np.random.shuffle(idx)\r\n    idx = idx[:num]\r\n    print(idx)\r\n    data_shuffle = [imread(data[i]) for i in idx]\r\n\r\n    shuffled = np.asarray(data_shuffle)\r\n    print(\"shuffled:\", shuffled.shape)\r\n    return np.asarray(data_shuffle)\r\n\r\n\r\n# ## Code for creating montages (by Parag Mital)\r\n\r\n# In[5]:\r\n\r\n\r\n# Code by Parag Mital (https://github.com/pkmital/CADL/)\r\ndef montage(images):    \r\n    if isinstance(images, list):\r\n        images = np.array(images)\r\n    img_h = images.shape[1]\r\n    img_w = images.shape[2]\r\n    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\r\n    if len(images.shape) == 4 and images.shape[3] == 3:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1, 3)) * 0.5\r\n    elif len(images.shape) == 4 and images.shape[3] == 1:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1, 1)) * 0.5\r\n    elif len(images.shape) == 3:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1)) * 0.5\r\n    else:\r\n        raise ValueError('Could not parse image shape of {}'.format(\r\n            images.shape))\r\n    for i in range(n_plots):\r\n        for j in range(n_plots):\r\n            this_filter = i * n_plots + j\r\n            if this_filter < images.shape[0]:\r\n                this_img = images[this_filter]\r\n                m[1 + i + i * img_h:1 + i + (i + 1) * img_h,\r\n                  1 + j + j * img_w:1 + j + (j + 1) * img_w] = this_img\r\n    return m\r\n\r\n\r\n# ## Definition of the neural network\r\n\r\n# In[6]:\r\n\r\n\r\ntf.reset_default_graph()\r\nbatch_size = 5\r\nn_noise = 28\r\n\r\n#config = tf.ConfigProto()\r\n#config.gpu_options.allocator_type ='BFC'\r\n#config.gpu_options.per_process_gpu_memory_fraction = 0.90\r\n\r\nX_in = tf.placeholder(dtype=tf.float32, shape=[None, height_width, height_width], name='X')\r\nnoise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\r\n\r\nkeep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\r\nis_training = tf.placeholder(dtype=tf.bool, name='is_training')\r\n\r\ndef lrelu(x):\r\n    return tf.maximum(x, tf.multiply(x, 0.2))\r\n\r\ndef binary_cross_entropy(x, z):\r\n    eps = 1e-12\r\n    return (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))\r\n\r\ndef discriminator(img_in, reuse=None, keep_prob=keep_prob):\r\n    activation = lrelu\r\n    with tf.variable_scope(\"discriminator\", reuse=reuse):\r\n        x = tf.reshape(img_in, shape=[-1, height_width, height_width, 3])\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=128, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.flatten(x)\r\n        x = tf.layers.dense(x, units=128, activation=activation)\r\n        x = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\r\n        return x\r\n    \r\ndef generator(z, keep_prob=keep_prob, is_training=is_training):\r\n    activation = lrelu\r\n    momentum = 0.9\r\n    with tf.variable_scope(\"generator\", reuse=None):\r\n        x = z\r\n        \r\n        d1 = 4#3\r\n        d2 = 3\r\n        \r\n        x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)      \r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)  \r\n        \r\n        x = tf.reshape(x, shape=[-1, d1, d1, d2])\r\n        x = tf.image.resize_images(x, size=[50, 50])\r\n        \r\n        \r\n        \r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=128, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=3, strides=1, padding='same', activation=tf.nn.sigmoid)\r\n        return x    \r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n\r\n\r\n# ## Losses and optimizers\r\n\r\n# In[7]:\r\n\r\n\r\n\r\n\r\ng = generator(noise, keep_prob, is_training)\r\nprint(g)\r\nd_real = discriminator(X_in)\r\nd_fake = discriminator(g, reuse=True)\r\n\r\nvars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\r\nvars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\r\n\r\n\r\nd_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\r\ng_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\r\n\r\nloss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\r\nloss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\r\nloss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\r\n\r\nloss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\r\n\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    optimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss_d + d_reg, var_list=vars_d)\r\n    optimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.0002).minimize(loss_g + g_reg, var_list=vars_g)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\n\r\n# ## Training the network\r\n\r\n# In[8]:\r\n\r\n\r\nfor i in range(60000):\r\n    train_d = True\r\n    train_g = True\r\n    keep_prob_train = 0.6 # 0.5\r\n    \r\n    \r\n    n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \r\n    batch = [b for b in next_batch(num=batch_size)]  \r\n    \r\n    d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\r\n    \r\n    d_fake_ls_init = d_fake_ls\r\n    \r\n    d_real_ls = np.mean(d_real_ls)\r\n    d_fake_ls = np.mean(d_fake_ls)\r\n    g_ls = g_ls\r\n    d_ls = d_ls\r\n        \r\n    if g_ls * 1.35 < d_ls:\r\n        train_g = False\r\n        pass\r\n    if d_ls * 1.35 < g_ls:\r\n        train_d = False\r\n        pass\r\n    \r\n    if train_d:\r\n        sess.run(optimizer_d, feed_dict={noise: n, X_in: batch, keep_prob: keep_prob_train, is_training:True})\r\n        \r\n        \r\n    if train_g:\r\n        sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})\r\n        \r\n        \r\n    if not i % 10:\r\n        print (i, d_ls, g_ls)\r\n        if not train_g:\r\n            print(\"not training generator\")\r\n        if not train_d:\r\n            print(\"not training discriminator\")\r\n        gen_imgs = sess.run(g, feed_dict = {noise: n, keep_prob: 1.0, is_training:False})\r\n        imgs = [img[:,:,:] for img in gen_imgs]\r\n        m = montage(imgs)\r\n        #m = imgs[0]\r\n        plt.axis('off')\r\n        plt.imshow(m, cmap='gray')\r\n        plt.show()\r\n\r\nGenerates this error.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-3639a81d708d> in <module>()\r\n      8     batch = [b for b in next_batch(num=batch_size)]\r\n      9 \r\n---> 10     d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\r\n     11 \r\n     12     d_fake_ls_init = d_fake_ls\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1109                              'which has shape %r' %\r\n   1110                              (np_val.shape, subfeed_t.name,\r\n-> 1111                               str(subfeed_t.get_shape())))\r\n   1112           if not self.graph.is_feedable(subfeed_t):\r\n   1113             raise ValueError('Tensor %s may not be fed.' % subfeed_t)\r\n\r\nValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'\r\n\r\n\r\nNo idea how to debug this. Need a bit of help."}