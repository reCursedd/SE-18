{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396688264", "html_url": "https://github.com/tensorflow/tensorflow/issues/19933#issuecomment-396688264", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19933", "id": 396688264, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjY4ODI2NA==", "user": {"login": "alexbeloi", "id": 9807648, "node_id": "MDQ6VXNlcjk4MDc2NDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/9807648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbeloi", "html_url": "https://github.com/alexbeloi", "followers_url": "https://api.github.com/users/alexbeloi/followers", "following_url": "https://api.github.com/users/alexbeloi/following{/other_user}", "gists_url": "https://api.github.com/users/alexbeloi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbeloi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbeloi/subscriptions", "organizations_url": "https://api.github.com/users/alexbeloi/orgs", "repos_url": "https://api.github.com/users/alexbeloi/repos", "events_url": "https://api.github.com/users/alexbeloi/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbeloi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T18:26:21Z", "updated_at": "2018-06-12T18:26:21Z", "author_association": "NONE", "body_html": "<p>I have had similar issues with dataset, it's seems very sensitive to the sequence of operations used and diagnosing the bottleneck can be hard.</p>\n<p>From my experience it's best to have your parser <code>dataset.map(parse_tfrecord)</code> and <code>dataset.batch</code> at the end of the pipeline. For me this sequence seems to be fairly fast when using multiple tfrecords files.</p>\n<div class=\"highlight highlight-source-python\"><pre>files <span class=\"pl-k\">=</span> tf.match_files(glob)\ndataset <span class=\"pl-k\">=</span> tf.data.TFRecordDataset(files, <span class=\"pl-v\">num_parallel_reads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">CPU_COUNT</span>)\n<span class=\"pl-k\">if</span> shard:\n    dataset <span class=\"pl-k\">=</span> dataset.shard(<span class=\"pl-c1\">WORKER_COUNT</span>, <span class=\"pl-c1\">TASK_ID</span>)\ndataset <span class=\"pl-k\">=</span> dataset.repeat(num_epochs)\n<span class=\"pl-k\">if</span> shuffle:\n    dataset <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span>batch_size <span class=\"pl-k\">*</span> <span class=\"pl-c1\">10</span>)\ndataset <span class=\"pl-k\">=</span> dataset.map(parse_example, <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">CPU_COUNT</span>)\ndataset <span class=\"pl-k\">=</span> dataset.batch(batch_size)</pre></div>\n<p>You might also try moving (or removing) the prefetch operation, it may be making your first call to <code>sess.run(train_op)</code> very slow because of a massive disk read, but subsequent calls should be faster.</p>", "body_text": "I have had similar issues with dataset, it's seems very sensitive to the sequence of operations used and diagnosing the bottleneck can be hard.\nFrom my experience it's best to have your parser dataset.map(parse_tfrecord) and dataset.batch at the end of the pipeline. For me this sequence seems to be fairly fast when using multiple tfrecords files.\nfiles = tf.match_files(glob)\ndataset = tf.data.TFRecordDataset(files, num_parallel_reads=CPU_COUNT)\nif shard:\n    dataset = dataset.shard(WORKER_COUNT, TASK_ID)\ndataset = dataset.repeat(num_epochs)\nif shuffle:\n    dataset = dataset.shuffle(buffer_size=batch_size * 10)\ndataset = dataset.map(parse_example, num_parallel_calls=CPU_COUNT)\ndataset = dataset.batch(batch_size)\nYou might also try moving (or removing) the prefetch operation, it may be making your first call to sess.run(train_op) very slow because of a massive disk read, but subsequent calls should be faster.", "body": "I have had similar issues with dataset, it's seems very sensitive to the sequence of operations used and diagnosing the bottleneck can be hard.\r\n\r\nFrom my experience it's best to have your parser `dataset.map(parse_tfrecord)` and `dataset.batch` at the end of the pipeline. For me this sequence seems to be fairly fast when using multiple tfrecords files.\r\n\r\n```python\r\nfiles = tf.match_files(glob)\r\ndataset = tf.data.TFRecordDataset(files, num_parallel_reads=CPU_COUNT)\r\nif shard:\r\n    dataset = dataset.shard(WORKER_COUNT, TASK_ID)\r\ndataset = dataset.repeat(num_epochs)\r\nif shuffle:\r\n    dataset = dataset.shuffle(buffer_size=batch_size * 10)\r\ndataset = dataset.map(parse_example, num_parallel_calls=CPU_COUNT)\r\ndataset = dataset.batch(batch_size)\r\n```\r\n\r\nYou might also try moving (or removing) the prefetch operation, it may be making your first call to `sess.run(train_op)` very slow because of a massive disk read, but subsequent calls should be faster."}