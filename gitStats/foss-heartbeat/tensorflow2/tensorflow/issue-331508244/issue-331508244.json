{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19933", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19933/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19933/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19933/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19933", "id": 331508244, "node_id": "MDU6SXNzdWUzMzE1MDgyNDQ=", "number": 19933, "title": "Using feed_dict is more than 5x faster than using dataset API?", "user": {"login": "codescv", "id": 124190, "node_id": "MDQ6VXNlcjEyNDE5MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/124190?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codescv", "html_url": "https://github.com/codescv", "followers_url": "https://api.github.com/users/codescv/followers", "following_url": "https://api.github.com/users/codescv/following{/other_user}", "gists_url": "https://api.github.com/users/codescv/gists{/gist_id}", "starred_url": "https://api.github.com/users/codescv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codescv/subscriptions", "organizations_url": "https://api.github.com/users/codescv/orgs", "repos_url": "https://api.github.com/users/codescv/repos", "events_url": "https://api.github.com/users/codescv/events{/privacy}", "received_events_url": "https://api.github.com/users/codescv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-06-12T09:27:44Z", "updated_at": "2018-10-05T21:16:17Z", "closed_at": "2018-10-05T21:16:17Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS 10.13.4 (on Linux Ubuntu 16.04 you get similar results)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7 cpu</li>\n<li><strong>Python version</strong>:  3.6.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I created a dataset in TFRecord format for testing. Every entry contains 200 columns, named C1 - C199, each being a strings list, and a label column to denote the labels. The code to create the data can be found here: <a href=\"https://github.com/codescv/tf-dist/blob/8bb3c44f55939fc66b3727a730c57887113e899c/src/gen_data.py#L25\">https://github.com/codescv/tf-dist/blob/8bb3c44f55939fc66b3727a730c57887113e899c/src/gen_data.py#L25</a></p>\n<p>Then I used a linear model to train the data. The first approach looks like this:</p>\n<pre><code>dataset = tf.data.TFRecordDataset(data_file)\ndataset = dataset.prefetch(buffer_size=batch_size*10)\ndataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\ndataset = dataset.repeat(num_epochs)\ndataset = dataset.batch(batch_size)\n\nfeatures, labels = dataset.make_one_shot_iterator().get_next()    \nlogits = tf.feature_column.linear_model(features=features, feature_columns=columns, cols_to_vars=cols_to_vars)\ntrain_op = ...\n\nwith tf.Session() as sess:\n    sess.run(train_op)\n</code></pre>\n<p>The full code can be found here: <a href=\"https://github.com/codescv/tf-dist/blob/master/src/lr_single.py\">https://github.com/codescv/tf-dist/blob/master/src/lr_single.py</a></p>\n<p>When I run the code above, I get 0.85 steps/sec (batch size being 1024).</p>\n<p>In the second approach, I manually get batches from Dataset into python, then feed them to a placeholder, like this:</p>\n<pre><code>example = tf.placeholder(dtype=tf.string, shape=[None])\nfeatures = tf.parse_example(example, features=tf.feature_column.make_parse_example_spec(columns+[tf.feature_column.numeric_column('label', dtype=tf.float32, default_value=0)]))\nlabels = features.pop('label')\ntrain_op = ...\n\ndataset = tf.data.TFRecordDataset(data_file).repeat().batch(batch_size)\nnext_batch = dataset.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n    data_batch = sess.run(next_batch)\n    sess.run(train_op, feed_dict={example: data_batch})\n</code></pre>\n<p>The full code can be found here: <a href=\"https://github.com/codescv/tf-dist/blob/master/src/lr_single_feed.py\">https://github.com/codescv/tf-dist/blob/master/src/lr_single_feed.py</a></p>\n<p>When I run the code above, I get 5 steps/sec. That is 5x faster than the first approach. This is what I do not understand, because theoretically the second should be slower due to the extra serialization/deserialization of data batches.</p>\n<p>Is this possibly a bug or am I using it mistakenly ?</p>\n<p>Thanks!</p>\n<h3>Source code / logs</h3>\n<p>I have also included some profile traces below:</p>\n<p>(using tf Dataset API)<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/124190/41281915-3b049342-6e65-11e8-8b04-4d4611a96fa8.png\"><img src=\"https://user-images.githubusercontent.com/124190/41281915-3b049342-6e65-11e8-8b04-4d4611a96fa8.png\" alt=\"lr_single\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/2093402/profile-101.json.zip\">profile-101.json.zip</a></p>\n<p>(using feed_dict)<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/124190/41281927-4186bcae-6e65-11e8-80a6-e19dcd6b5c53.png\"><img src=\"https://user-images.githubusercontent.com/124190/41281927-4186bcae-6e65-11e8-80a6-e19dcd6b5c53.png\" alt=\"lr_single_feed\" style=\"max-width:100%;\"></a></p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/2093405/profile-101.json.zip\">profile-101.json.zip</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.4 (on Linux Ubuntu 16.04 you get similar results)\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7 cpu\nPython version:  3.6.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI created a dataset in TFRecord format for testing. Every entry contains 200 columns, named C1 - C199, each being a strings list, and a label column to denote the labels. The code to create the data can be found here: https://github.com/codescv/tf-dist/blob/8bb3c44f55939fc66b3727a730c57887113e899c/src/gen_data.py#L25\nThen I used a linear model to train the data. The first approach looks like this:\ndataset = tf.data.TFRecordDataset(data_file)\ndataset = dataset.prefetch(buffer_size=batch_size*10)\ndataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\ndataset = dataset.repeat(num_epochs)\ndataset = dataset.batch(batch_size)\n\nfeatures, labels = dataset.make_one_shot_iterator().get_next()    \nlogits = tf.feature_column.linear_model(features=features, feature_columns=columns, cols_to_vars=cols_to_vars)\ntrain_op = ...\n\nwith tf.Session() as sess:\n    sess.run(train_op)\n\nThe full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single.py\nWhen I run the code above, I get 0.85 steps/sec (batch size being 1024).\nIn the second approach, I manually get batches from Dataset into python, then feed them to a placeholder, like this:\nexample = tf.placeholder(dtype=tf.string, shape=[None])\nfeatures = tf.parse_example(example, features=tf.feature_column.make_parse_example_spec(columns+[tf.feature_column.numeric_column('label', dtype=tf.float32, default_value=0)]))\nlabels = features.pop('label')\ntrain_op = ...\n\ndataset = tf.data.TFRecordDataset(data_file).repeat().batch(batch_size)\nnext_batch = dataset.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n    data_batch = sess.run(next_batch)\n    sess.run(train_op, feed_dict={example: data_batch})\n\nThe full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single_feed.py\nWhen I run the code above, I get 5 steps/sec. That is 5x faster than the first approach. This is what I do not understand, because theoretically the second should be slower due to the extra serialization/deserialization of data batches.\nIs this possibly a bug or am I using it mistakenly ?\nThanks!\nSource code / logs\nI have also included some profile traces below:\n(using tf Dataset API)\n\nprofile-101.json.zip\n(using feed_dict)\n\nprofile-101.json.zip", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.4 (on Linux Ubuntu 16.04 you get similar results)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7 cpu\r\n- **Python version**:  3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI created a dataset in TFRecord format for testing. Every entry contains 200 columns, named C1 - C199, each being a strings list, and a label column to denote the labels. The code to create the data can be found here: https://github.com/codescv/tf-dist/blob/8bb3c44f55939fc66b3727a730c57887113e899c/src/gen_data.py#L25\r\n\r\nThen I used a linear model to train the data. The first approach looks like this:\r\n\r\n```\r\ndataset = tf.data.TFRecordDataset(data_file)\r\ndataset = dataset.prefetch(buffer_size=batch_size*10)\r\ndataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\r\ndataset = dataset.repeat(num_epochs)\r\ndataset = dataset.batch(batch_size)\r\n\r\nfeatures, labels = dataset.make_one_shot_iterator().get_next()    \r\nlogits = tf.feature_column.linear_model(features=features, feature_columns=columns, cols_to_vars=cols_to_vars)\r\ntrain_op = ...\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(train_op)\r\n```\r\nThe full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single.py\r\n\r\nWhen I run the code above, I get 0.85 steps/sec (batch size being 1024).\r\n\r\nIn the second approach, I manually get batches from Dataset into python, then feed them to a placeholder, like this:\r\n\r\n```\r\nexample = tf.placeholder(dtype=tf.string, shape=[None])\r\nfeatures = tf.parse_example(example, features=tf.feature_column.make_parse_example_spec(columns+[tf.feature_column.numeric_column('label', dtype=tf.float32, default_value=0)]))\r\nlabels = features.pop('label')\r\ntrain_op = ...\r\n\r\ndataset = tf.data.TFRecordDataset(data_file).repeat().batch(batch_size)\r\nnext_batch = dataset.make_one_shot_iterator().get_next()\r\n\r\nwith tf.Session() as sess:\r\n    data_batch = sess.run(next_batch)\r\n    sess.run(train_op, feed_dict={example: data_batch})\r\n```\r\nThe full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single_feed.py\r\n\r\nWhen I run the code above, I get 5 steps/sec. That is 5x faster than the first approach. This is what I do not understand, because theoretically the second should be slower due to the extra serialization/deserialization of data batches.\r\n\r\nIs this possibly a bug or am I using it mistakenly ?\r\n\r\nThanks!\r\n\r\n### Source code / logs\r\nI have also included some profile traces below:\r\n\r\n(using tf Dataset API)\r\n![lr_single](https://user-images.githubusercontent.com/124190/41281915-3b049342-6e65-11e8-8b04-4d4611a96fa8.png)\r\n\r\n[profile-101.json.zip](https://github.com/tensorflow/tensorflow/files/2093402/profile-101.json.zip)\r\n\r\n\r\n(using feed_dict)\r\n![lr_single_feed](https://user-images.githubusercontent.com/124190/41281927-4186bcae-6e65-11e8-80a6-e19dcd6b5c53.png)\r\n\r\n[profile-101.json.zip](https://github.com/tensorflow/tensorflow/files/2093405/profile-101.json.zip)\r\n\r\n\r\n\r\n"}