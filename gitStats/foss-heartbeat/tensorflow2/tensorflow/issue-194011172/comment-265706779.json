{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265706779", "html_url": "https://github.com/tensorflow/tensorflow/issues/6153#issuecomment-265706779", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6153", "id": 265706779, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTcwNjc3OQ==", "user": {"login": "Mojusko", "id": 1837393, "node_id": "MDQ6VXNlcjE4MzczOTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1837393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mojusko", "html_url": "https://github.com/Mojusko", "followers_url": "https://api.github.com/users/Mojusko/followers", "following_url": "https://api.github.com/users/Mojusko/following{/other_user}", "gists_url": "https://api.github.com/users/Mojusko/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mojusko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mojusko/subscriptions", "organizations_url": "https://api.github.com/users/Mojusko/orgs", "repos_url": "https://api.github.com/users/Mojusko/repos", "events_url": "https://api.github.com/users/Mojusko/events{/privacy}", "received_events_url": "https://api.github.com/users/Mojusko/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-08T10:27:57Z", "updated_at": "2016-12-08T10:27:57Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a>, No I have a rather sophisticated validation stopping but in essence it boils down to iteration. So it is not the time I am concerned with it is really the computation. Could it be that there are different floating point standards leading to this, or the Adam optimizer behaves differently on GPU than on CPU. As I said raising the learning rate by 10 led to the same behavior.</p>", "body_text": "@yaroslavvb, No I have a rather sophisticated validation stopping but in essence it boils down to iteration. So it is not the time I am concerned with it is really the computation. Could it be that there are different floating point standards leading to this, or the Adam optimizer behaves differently on GPU than on CPU. As I said raising the learning rate by 10 led to the same behavior.", "body": "@yaroslavvb, No I have a rather sophisticated validation stopping but in essence it boils down to iteration. So it is not the time I am concerned with it is really the computation. Could it be that there are different floating point standards leading to this, or the Adam optimizer behaves differently on GPU than on CPU. As I said raising the learning rate by 10 led to the same behavior. "}