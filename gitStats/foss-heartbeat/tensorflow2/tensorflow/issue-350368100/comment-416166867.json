{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/416166867", "html_url": "https://github.com/tensorflow/tensorflow/issues/21602#issuecomment-416166867", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21602", "id": 416166867, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjE2Njg2Nw==", "user": {"login": "alokranjan007", "id": 19912807, "node_id": "MDQ6VXNlcjE5OTEyODA3", "avatar_url": "https://avatars1.githubusercontent.com/u/19912807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alokranjan007", "html_url": "https://github.com/alokranjan007", "followers_url": "https://api.github.com/users/alokranjan007/followers", "following_url": "https://api.github.com/users/alokranjan007/following{/other_user}", "gists_url": "https://api.github.com/users/alokranjan007/gists{/gist_id}", "starred_url": "https://api.github.com/users/alokranjan007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alokranjan007/subscriptions", "organizations_url": "https://api.github.com/users/alokranjan007/orgs", "repos_url": "https://api.github.com/users/alokranjan007/repos", "events_url": "https://api.github.com/users/alokranjan007/events{/privacy}", "received_events_url": "https://api.github.com/users/alokranjan007/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-27T09:16:52Z", "updated_at": "2018-08-27T09:19:47Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=479117\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jdduke\">@jdduke</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4723042\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/achowdhery\">@achowdhery</a> ,<br>\nSince the quantized model is not detecting any thing after building over android. I tried my luck with <code>ssd_mobilenet_v2_coco</code> model. I  trained the model for 20000 training steps.</p>\n<p>Then, I converted the trained model to get a frozen graph using <code>export_tflite_ssd_graph</code> then converted the .pb file into <code>tflite</code>.</p>\n<p>I followed your suggestion and have used <code>inference_type=FLOAT</code> and made a change accordingly in the DetectorActivity.java file i.e. <code>private static final boolean TF_OD_API_IS_QUANTIZED = false;</code>.</p>\n<p>Then i build it over phone. The detector app is installed.  But the concern is the app is getting crashed after a minute. It shows the detection, but getting crashed.</p>\n<p>I used the logcat and found a fatal error about</p>\n<blockquote>\n<p>08-27 12:13:54.129 11179 11208 E AndroidRuntime: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 602112 bytes.</p>\n</blockquote>\n<p>I am not getting I have used float inference and have changed the detector file also then why this is throwing such error.</p>\n<p>Note: For configuration I had used image size as 300 and 300. But learning from the log file it is taking somewhere (224 <em>224</em> 3* 4=602112). For the conversion also I had used <code>--input_shapes=1,300,300,3</code>.</p>\n<p>I am attaching the txt file for your perusal.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2323215/ssd_mobilenet_v2_27_Aug.txt\">ssd_mobilenet_v2_27_Aug.txt</a></p>\n<p>Could you please share your views on this? How should I rectify this?</p>\n<p>Thank you for your help.</p>", "body_text": "Hi @jdduke and @achowdhery ,\nSince the quantized model is not detecting any thing after building over android. I tried my luck with ssd_mobilenet_v2_coco model. I  trained the model for 20000 training steps.\nThen, I converted the trained model to get a frozen graph using export_tflite_ssd_graph then converted the .pb file into tflite.\nI followed your suggestion and have used inference_type=FLOAT and made a change accordingly in the DetectorActivity.java file i.e. private static final boolean TF_OD_API_IS_QUANTIZED = false;.\nThen i build it over phone. The detector app is installed.  But the concern is the app is getting crashed after a minute. It shows the detection, but getting crashed.\nI used the logcat and found a fatal error about\n\n08-27 12:13:54.129 11179 11208 E AndroidRuntime: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 602112 bytes.\n\nI am not getting I have used float inference and have changed the detector file also then why this is throwing such error.\nNote: For configuration I had used image size as 300 and 300. But learning from the log file it is taking somewhere (224 224 3* 4=602112). For the conversion also I had used --input_shapes=1,300,300,3.\nI am attaching the txt file for your perusal.\nssd_mobilenet_v2_27_Aug.txt\nCould you please share your views on this? How should I rectify this?\nThank you for your help.", "body": "Hi @jdduke and @achowdhery ,\r\nSince the quantized model is not detecting any thing after building over android. I tried my luck with `ssd_mobilenet_v2_coco` model. I  trained the model for 20000 training steps. \r\n\r\nThen, I converted the trained model to get a frozen graph using `export_tflite_ssd_graph` then converted the .pb file into `tflite`. \r\n\r\nI followed your suggestion and have used `inference_type=FLOAT` and made a change accordingly in the DetectorActivity.java file i.e. `private static final boolean TF_OD_API_IS_QUANTIZED = false;`.\r\n\r\nThen i build it over phone. The detector app is installed.  But the concern is the app is getting crashed after a minute. It shows the detection, but getting crashed.\r\n\r\nI used the logcat and found a fatal error about \r\n\r\n> 08-27 12:13:54.129 11179 11208 E AndroidRuntime: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1080000 bytes and a ByteBuffer with 602112 bytes.\r\n\r\n\r\nI am not getting I have used float inference and have changed the detector file also then why this is throwing such error.\r\n\r\nNote: For configuration I had used image size as 300 and 300. But learning from the log file it is taking somewhere (224 *224* 3* 4=602112). For the conversion also I had used `--input_shapes=1,300,300,3`.\r\n\r\nI am attaching the txt file for your perusal.\r\n[ssd_mobilenet_v2_27_Aug.txt](https://github.com/tensorflow/tensorflow/files/2323215/ssd_mobilenet_v2_27_Aug.txt)\r\n\r\nCould you please share your views on this? How should I rectify this?\r\n\r\nThank you for your help."}