{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19686", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19686/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19686/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19686/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19686", "id": 328454099, "node_id": "MDU6SXNzdWUzMjg0NTQwOTk=", "number": 19686, "title": "feature request: tf.string_split cannot split more than twice, when the maxlengths are not same", "user": {"login": "ZhuoyuWei", "id": 6711360, "node_id": "MDQ6VXNlcjY3MTEzNjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6711360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhuoyuWei", "html_url": "https://github.com/ZhuoyuWei", "followers_url": "https://api.github.com/users/ZhuoyuWei/followers", "following_url": "https://api.github.com/users/ZhuoyuWei/following{/other_user}", "gists_url": "https://api.github.com/users/ZhuoyuWei/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhuoyuWei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhuoyuWei/subscriptions", "organizations_url": "https://api.github.com/users/ZhuoyuWei/orgs", "repos_url": "https://api.github.com/users/ZhuoyuWei/repos", "events_url": "https://api.github.com/users/ZhuoyuWei/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhuoyuWei/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "robieta", "id": 13089297, "node_id": "MDQ6VXNlcjEzMDg5Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/13089297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robieta", "html_url": "https://github.com/robieta", "followers_url": "https://api.github.com/users/robieta/followers", "following_url": "https://api.github.com/users/robieta/following{/other_user}", "gists_url": "https://api.github.com/users/robieta/gists{/gist_id}", "starred_url": "https://api.github.com/users/robieta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robieta/subscriptions", "organizations_url": "https://api.github.com/users/robieta/orgs", "repos_url": "https://api.github.com/users/robieta/repos", "events_url": "https://api.github.com/users/robieta/events{/privacy}", "received_events_url": "https://api.github.com/users/robieta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-06-01T09:52:36Z", "updated_at": "2018-06-04T03:12:58Z", "closed_at": "2018-06-04T03:12:58Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Windows10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.7</li>\n<li><strong>Python version</strong>: 3.6.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0 / cuDNN7</li>\n<li><strong>GPU model and memory</strong>:  NVIDIA Quadro K620</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I used Dataset API to process NLP task.<br>\nIn input function, I have a string col, which contains three kinds of  delimiter '\\1', '\\2', ' '.<br>\nFor example, the string is a ducument, the '\\1' is used to split passages and '\\2' is used to split sentecnes and ' ' is used to split tokens(words).<br>\nI want to split it into a 3-D tensor, whose shape may be [None,None,None], and before the data is truly read, these three numbers cannot be determined.</p>\n<p>Firstly, I try the following code to directly call tf.string_split three times:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>parsed_line[4] is the string col, Tensor(\"DecodeCSV:5\", shape=(), dtype=string)</span>\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.string_split([parsed_line[<span class=\"pl-c1\">4</span>]],<span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\2</span><span class=\"pl-pds\">'</span></span>).values\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.string_split(parsed_line[<span class=\"pl-c1\">4</span>],<span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\1</span><span class=\"pl-pds\">'</span></span>).values\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.string_split(parsed_line[<span class=\"pl-c1\">4</span>],<span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span> <span class=\"pl-pds\">'</span></span>)\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.sparse_tensor_to_dense(parsed_line[<span class=\"pl-c1\">4</span>], <span class=\"pl-v\">default_value</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>after processing, parsed_line[4] is Tensor(\"SparseToDense_2:0\", shape=(?, ?), dtype=string)</span></pre></div>\n<p>However, I want to get [None,None,None], but not [None,None], because it loss the information which passage the sencences are belong to.</p>\n<p>Secondly, I try tf.map_fn as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>parsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.string_split([parsed_line[<span class=\"pl-c1\">4</span>]],<span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\2</span><span class=\"pl-pds\">'</span></span>).values\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.string_split(parsed_line[<span class=\"pl-c1\">4</span>],<span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\1</span><span class=\"pl-pds\">'</span></span>)\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.SparseTensor(parsed_line[<span class=\"pl-c1\">4</span>].indices,tf.map_fn(tf.string_split,[parsed_line[<span class=\"pl-c1\">4</span>].values]),parsed_line[<span class=\"pl-c1\">4</span>].dense_shape)\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.sparse_tensor_to_dense(parsed_line[<span class=\"pl-c1\">4</span>], <span class=\"pl-v\">default_value</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>Then it will throw out the following errors:</p>\n<pre><code>Traceback (most recent call last):\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 179, in &lt;module&gt;\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in train_input\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\n    return MapDataset(self, map_func)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\n    self._map_func.add_to_graph(ops.get_default_graph())\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\n    self._create_definition_if_needed()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\n    self._create_definition_if_needed_impl()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\n    outputs = self._func(*inputs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\n    ret = map_func(nested_args)\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in &lt;lambda&gt;\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 54, in decode_tsv_indexing\n    parsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 413, in map_fn\n    swap_memory=swap_memory)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3202, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2940, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2877, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 404, in compute\n    nest.assert_same_structure(dtype or elems, packed_fn_values)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 267, in assert_same_structure\n    _recursive_assert_same_structure(nest1, nest2, check_types)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 193, in _recursive_assert_same_structure\n    \"First structure: %s\\n\\nSecond structure: %s.\" % (nest1, nest2))\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: [tf.string]\n\nSecond structure: SparseTensor(indices=Tensor(\"map/while/StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"map/while/StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"map/while/StringSplit:2\", shape=(2,), dtype=int64)).\n\nProcess finished with exit code 1\n</code></pre>\n<p>I think it is caused by the lengths (the last dimensionality) of each sentence are different.</p>\n<p>To valid my guess, I split this col to 5 cols in the input file, and I run tf.string_split on each of them to get [None,None] tensor, and finally, I try to stack them int one tensor [None,None,None]</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">9</span>):\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.string_split([parsed_line[i]], <span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\1</span><span class=\"pl-pds\">'</span></span>).values\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.string_split(parsed_line[i])\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.sparse_tensor_to_dense(parsed_line[i], <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.stack(parsed_line[<span class=\"pl-c1\">4</span>:<span class=\"pl-c1\">9</span>])</pre></div>\n<p>Yes, it throws an error:</p>\n<pre><code>2018-06-01 17:41:31.412421: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:891 : Invalid argument: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n    return fn(*args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1420, in _call_tf_sessionrun\n    status, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,?], [?,5,?,?], [?,?], [?,?,?], [?,?], [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\n</code></pre>\n<p>When truly read the input data, two sentences has 31 tokens and 35 tokens, respectively.<br>\nFinally, I try to pad them dynamically as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">9</span>):\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.string_split([parsed_line[i]], <span class=\"pl-v\">delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\1</span><span class=\"pl-pds\">'</span></span>).values\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.string_split(parsed_line[i])\n    parsed_line[i] <span class=\"pl-k\">=</span> tf.sparse_tensor_to_dense(parsed_line[i], <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n\nshape_list<span class=\"pl-k\">=</span>[]\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">9</span>):\n    tmp<span class=\"pl-k\">=</span>tf.convert_to_tensor(parsed_line[i].shape,<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n    shape_list.append(tmp)\nshape_stack<span class=\"pl-k\">=</span>tf.stack(shape_list)\nmaxs<span class=\"pl-k\">=</span>tf.reduce_max(shape_stack,<span class=\"pl-c1\">0</span>)\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">9</span>):\n    paddings<span class=\"pl-k\">=</span>tf.stack([tf.constant([<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>],<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>),maxs<span class=\"pl-k\">-</span>parsed_line[i].shape])\n    parsed_line[i]<span class=\"pl-k\">=</span>tf.pad(parsed_line[i],paddings,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CONSTANT<span class=\"pl-pds\">\"</span></span>)\nparsed_line[<span class=\"pl-c1\">4</span>]<span class=\"pl-k\">=</span>tf.stack(parsed_line[<span class=\"pl-c1\">4</span>:<span class=\"pl-c1\">9</span>])</pre></div>\n<p>This code throws the following erros:</p>\n<pre><code>Traceback (most recent call last):\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 175, in &lt;module&gt;\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in train_input\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\n    return MapDataset(self, map_func)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\n    self._map_func.add_to_graph(ops.get_default_graph())\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\n    self._create_definition_if_needed()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\n    self._create_definition_if_needed_impl()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\n    outputs = self._func(*inputs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\n    ret = map_func(nested_args)\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in &lt;lambda&gt;\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 71, in decode_tsv_indexing\n    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 950, in convert_to_tensor\n    as_ref=False)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1040, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 256, in _tensor_shape_tensor_conversion_function\n    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\nValueError: Cannot convert a partially known TensorShape to a Tensor: (?, ?)\n</code></pre>\n<p>\"Cannot convert a partially known TensorShape to a Tensor: (?, ?)\"<br>\nThus, I don't know whether there is other methods to solve my problems.</p>\n<p>Thanks.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):1.7\nPython version: 3.6.2\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA 9.0 / cuDNN7\nGPU model and memory:  NVIDIA Quadro K620\nExact command to reproduce:\n\nDescribe the problem\nI used Dataset API to process NLP task.\nIn input function, I have a string col, which contains three kinds of  delimiter '\\1', '\\2', ' '.\nFor example, the string is a ducument, the '\\1' is used to split passages and '\\2' is used to split sentecnes and ' ' is used to split tokens(words).\nI want to split it into a 3-D tensor, whose shape may be [None,None,None], and before the data is truly read, these three numbers cannot be determined.\nFirstly, I try the following code to directly call tf.string_split three times:\n#parsed_line[4] is the string col, Tensor(\"DecodeCSV:5\", shape=(), dtype=string)\nparsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\\2').values\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter='\\1').values\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter=' ')\nparsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = \"\")\n#after processing, parsed_line[4] is Tensor(\"SparseToDense_2:0\", shape=(?, ?), dtype=string)\nHowever, I want to get [None,None,None], but not [None,None], because it loss the information which passage the sencences are belong to.\nSecondly, I try tf.map_fn as follows:\nparsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\\2').values\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter='\\1')\nparsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)\nparsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = \"\")\nThen it will throw out the following errors:\nTraceback (most recent call last):\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 179, in <module>\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in train_input\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\n    return MapDataset(self, map_func)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\n    self._map_func.add_to_graph(ops.get_default_graph())\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\n    self._create_definition_if_needed()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\n    self._create_definition_if_needed_impl()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\n    outputs = self._func(*inputs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\n    ret = map_func(nested_args)\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in <lambda>\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 54, in decode_tsv_indexing\n    parsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 413, in map_fn\n    swap_memory=swap_memory)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3202, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2940, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2877, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 404, in compute\n    nest.assert_same_structure(dtype or elems, packed_fn_values)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 267, in assert_same_structure\n    _recursive_assert_same_structure(nest1, nest2, check_types)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 193, in _recursive_assert_same_structure\n    \"First structure: %s\\n\\nSecond structure: %s.\" % (nest1, nest2))\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: [tf.string]\n\nSecond structure: SparseTensor(indices=Tensor(\"map/while/StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"map/while/StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"map/while/StringSplit:2\", shape=(2,), dtype=int64)).\n\nProcess finished with exit code 1\n\nI think it is caused by the lengths (the last dimensionality) of each sentence are different.\nTo valid my guess, I split this col to 5 cols in the input file, and I run tf.string_split on each of them to get [None,None] tensor, and finally, I try to stack them int one tensor [None,None,None]\nfor i in range(4,9):\n    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\\1').values\n    parsed_line[i] = tf.string_split(parsed_line[i])\n    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value=\"\")\nparsed_line[4]=tf.stack(parsed_line[4:9])\nYes, it throws an error:\n2018-06-01 17:41:31.412421: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:891 : Invalid argument: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n    return fn(*args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1420, in _call_tf_sessionrun\n    status, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,?], [?,5,?,?], [?,?], [?,?,?], [?,?], [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\n\nWhen truly read the input data, two sentences has 31 tokens and 35 tokens, respectively.\nFinally, I try to pad them dynamically as follows:\nfor i in range(4,9):\n    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\\1').values\n    parsed_line[i] = tf.string_split(parsed_line[i])\n    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value=\"\")\n\nshape_list=[]\nfor i in range(4, 9):\n    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)\n    shape_list.append(tmp)\nshape_stack=tf.stack(shape_list)\nmaxs=tf.reduce_max(shape_stack,0)\nfor i in range(4,9):\n    paddings=tf.stack([tf.constant([0,0],dtype='int32'),maxs-parsed_line[i].shape])\n    parsed_line[i]=tf.pad(parsed_line[i],paddings,\"CONSTANT\")\nparsed_line[4]=tf.stack(parsed_line[4:9])\nThis code throws the following erros:\nTraceback (most recent call last):\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 175, in <module>\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in train_input\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\n    return MapDataset(self, map_func)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\n    self._map_func.add_to_graph(ops.get_default_graph())\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\n    self._create_definition_if_needed()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\n    self._create_definition_if_needed_impl()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\n    outputs = self._func(*inputs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\n    ret = map_func(nested_args)\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in <lambda>\n    .map(lambda x: decode_tsv_indexing(x)))\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 71, in decode_tsv_indexing\n    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 950, in convert_to_tensor\n    as_ref=False)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1040, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 256, in _tensor_shape_tensor_conversion_function\n    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\nValueError: Cannot convert a partially known TensorShape to a Tensor: (?, ?)\n\n\"Cannot convert a partially known TensorShape to a Tensor: (?, ?)\"\nThus, I don't know whether there is other methods to solve my problems.\nThanks.", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.7\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN7\r\n- **GPU model and memory**:  NVIDIA Quadro K620\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI used Dataset API to process NLP task.\r\nIn input function, I have a string col, which contains three kinds of  delimiter '\\1', '\\2', ' '.\r\nFor example, the string is a ducument, the '\\1' is used to split passages and '\\2' is used to split sentecnes and ' ' is used to split tokens(words).\r\nI want to split it into a 3-D tensor, whose shape may be [None,None,None], and before the data is truly read, these three numbers cannot be determined.\r\n\r\nFirstly, I try the following code to directly call tf.string_split three times:\r\n```python \r\n#parsed_line[4] is the string col, Tensor(\"DecodeCSV:5\", shape=(), dtype=string)\r\nparsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\\2').values\r\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter='\\1').values\r\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter=' ')\r\nparsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = \"\")\r\n#after processing, parsed_line[4] is Tensor(\"SparseToDense_2:0\", shape=(?, ?), dtype=string)\r\n```\r\nHowever, I want to get [None,None,None], but not [None,None], because it loss the information which passage the sencences are belong to.\r\n\r\nSecondly, I try tf.map_fn as follows:\r\n```python\r\nparsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\\2').values\r\nparsed_line[4]=tf.string_split(parsed_line[4],delimiter='\\1')\r\nparsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)\r\nparsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = \"\")\r\n```\r\nThen it will throw out the following errors:\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 179, in <module>\r\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in train_input\r\n    .map(lambda x: decode_tsv_indexing(x)))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\r\n    return MapDataset(self, map_func)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\r\n    outputs = self._func(*inputs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\r\n    ret = map_func(nested_args)\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 109, in <lambda>\r\n    .map(lambda x: decode_tsv_indexing(x)))\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 54, in decode_tsv_indexing\r\n    parsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 413, in map_fn\r\n    swap_memory=swap_memory)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3202, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2940, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2877, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 404, in compute\r\n    nest.assert_same_structure(dtype or elems, packed_fn_values)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 267, in assert_same_structure\r\n    _recursive_assert_same_structure(nest1, nest2, check_types)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 193, in _recursive_assert_same_structure\r\n    \"First structure: %s\\n\\nSecond structure: %s.\" % (nest1, nest2))\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: [tf.string]\r\n\r\nSecond structure: SparseTensor(indices=Tensor(\"map/while/StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"map/while/StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"map/while/StringSplit:2\", shape=(2,), dtype=int64)).\r\n\r\nProcess finished with exit code 1\r\n```\r\nI think it is caused by the lengths (the last dimensionality) of each sentence are different.\r\n\r\nTo valid my guess, I split this col to 5 cols in the input file, and I run tf.string_split on each of them to get [None,None] tensor, and finally, I try to stack them int one tensor [None,None,None]\r\n```python\r\nfor i in range(4,9):\r\n    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\\1').values\r\n    parsed_line[i] = tf.string_split(parsed_line[i])\r\n    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value=\"\")\r\nparsed_line[4]=tf.stack(parsed_line[4:9])\r\n```\r\nYes, it throws an error:\r\n```\r\n2018-06-01 17:41:31.412421: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:891 : Invalid argument: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\r\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1420, in _call_tf_sessionrun\r\n    status, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]\r\n\t [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,?], [?,5,?,?], [?,?], [?,?,?], [?,?], [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n\r\n```\r\nWhen truly read the input data, two sentences has 31 tokens and 35 tokens, respectively.\r\nFinally, I try to pad them dynamically as follows:\r\n```python\r\nfor i in range(4,9):\r\n    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\\1').values\r\n    parsed_line[i] = tf.string_split(parsed_line[i])\r\n    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value=\"\")\r\n\r\nshape_list=[]\r\nfor i in range(4, 9):\r\n    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)\r\n    shape_list.append(tmp)\r\nshape_stack=tf.stack(shape_list)\r\nmaxs=tf.reduce_max(shape_stack,0)\r\nfor i in range(4,9):\r\n    paddings=tf.stack([tf.constant([0,0],dtype='int32'),maxs-parsed_line[i].shape])\r\n    parsed_line[i]=tf.pad(parsed_line[i],paddings,\"CONSTANT\")\r\nparsed_line[4]=tf.stack(parsed_line[4:9])\r\n```\r\nThis code throws the following erros:\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 175, in <module>\r\n    first_batch = sess.run(binput.input_fn(r'D:\\Datadump\\LSAT\\debug_data\\test_tsv.tsv','train'))\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in train_input\r\n    .map(lambda x: decode_tsv_indexing(x)))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 838, in map\r\n    return MapDataset(self, map_func)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1826, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 488, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 321, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 338, in _create_definition_if_needed_impl\r\n    outputs = self._func(*inputs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1791, in tf_map_func\r\n    ret = map_func(nested_args)\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 105, in <lambda>\r\n    .map(lambda x: decode_tsv_indexing(x)))\r\n  File \"D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py\", line 71, in decode_tsv_indexing\r\n    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 950, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1040, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 256, in _tensor_shape_tensor_conversion_function\r\n    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\r\nValueError: Cannot convert a partially known TensorShape to a Tensor: (?, ?)\r\n```\r\n\"Cannot convert a partially known TensorShape to a Tensor: (?, ?)\"\r\nThus, I don't know whether there is other methods to solve my problems.\r\n\r\nThanks."}