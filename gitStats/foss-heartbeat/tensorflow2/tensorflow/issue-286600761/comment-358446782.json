{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358446782", "html_url": "https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-358446782", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15933", "id": 358446782, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODQ0Njc4Mg==", "user": {"login": "Gemesys", "id": 16905336, "node_id": "MDQ6VXNlcjE2OTA1MzM2", "avatar_url": "https://avatars1.githubusercontent.com/u/16905336?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gemesys", "html_url": "https://github.com/Gemesys", "followers_url": "https://api.github.com/users/Gemesys/followers", "following_url": "https://api.github.com/users/Gemesys/following{/other_user}", "gists_url": "https://api.github.com/users/Gemesys/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gemesys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gemesys/subscriptions", "organizations_url": "https://api.github.com/users/Gemesys/orgs", "repos_url": "https://api.github.com/users/Gemesys/repos", "events_url": "https://api.github.com/users/Gemesys/events{/privacy}", "received_events_url": "https://api.github.com/users/Gemesys/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-17T21:11:58Z", "updated_at": "2018-01-17T21:11:58Z", "author_association": "NONE", "body_html": "<p>As promised, here is a more direct example of the operational difference noted between MacOS and Linux versions of TensorFlow 1.4.1.  I've removed all randomness from the initial conditions of the test program, and removed the need to use scipy, PIL/Pillow and matplotlib (and the TkAgg backend).   All we are basically doing here his calling TensorFlow routines: \"tf.expand_dims\" and \"tf.nn.depthwise_conv2d\" to set things up, \"tf.group\" to define the step, \"tf.global_variables_initializer\" to initialize variables, and \"step.run\" to iterate.</p>\n<p>Row 20 of the matrix \"U\" is displayed using U.eval.  This prints 400 numbers.  After only 1000 iterations, the Linux version of TensorFlow 1.4.1 shows the first number in row 20 of U as a value that is typically around 1.4 to 1.5.  The MacOS version (running on MacOS 10.10.5 (Yosemite)), typically shows a value around 0.336 to 0.337.  One can simply interupt the running Python program with control-c, and examine the 400 numbers displayed for iteration 1000, when the program displays the iteration=1000 information.</p>\n<p>These differences remain essentially the same, with small floating-point numeric variations between runs, the source of which is unclear at this time. Each machine shows small variations in its results each time, after only 1000 iterations  (a few percentage points different).  This may be due to characteristic operation of the floating-point solid-state electronics.   But between platforms, the difference exceeds 300 percent, and this has to be seen as unacceptable.  From run to run, this magnitude of difference remains consistant.  So far, I have been unable to detect any specifc flaw in floating point operations on the Macbook Pro running under MacOS 10.10.5, nor on the HP box, which is running under CentOS Linux 7.4.</p>\n<p>TensorFlow is producing quite different results on two different (but architecturally similar) computers.</p>\n<p>The test program, \"laptestnum.py\"  is attached below.</p>\n<pre><code>#-------------------------------------------------------------------------------\n# Prgm: laptestnum.py\n#\n# --- all randomness at startup is removed.  Program begins with specified\n# --- input values that are exactly the same for each run.\n#\n# --- this is a stripped-down version of LapTest.py, just produces numbers,\n# --- and a final image to \"tensor_new.jpg\".  Does not require scipy.misc\n# --- does not require PIL/Pillow image processing library\n# --- does not use or require matplotlib or TkAgg backend\n# --- does not produce images while running - only outputs row 20 of matrix U.eval()\n# --- \n# --- one may interrupt program with ctrl-c after only 1000 iterations, and\n# --- note the dramatic difference between the Apple Mac (10.10.5 MacOS) and\n# --- Linux version.  \n#\n# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)\n# --- updated for TensorFlow 1.4.0 running on CentOS-7.4 &amp; Python 2.7.14\n#     compiled (configured, actually) with the \"--enable-unicode=ucs4\" option\n#                                             (Python compile default is ucs2)\n#                                             (which caused TensorFlow 1.4 to)\n#                                             (fail to load. Building Python )\n#                                             (with ucs4, =&gt; pip can install )\n#                                             (TensorFlow 1.4.0 successfully.)\n\n# --- Import various libraries for simulation\nimport tensorflow as tf\nimport numpy as np\n# import scipy.misc\nimport imageio\n# import os\nimport sys\nimport subprocess\n# import PIL\n# import time    \n\n\n# --- Import for visualization and jpeg encoder  \n# import matplotlib\n# matplotlib.rcParams[\"backend\"]= 'TkAgg'\n# from matplotlib import pyplot as plt\n# from PIL import Image, ImageDraw\nfrom io import BytesIO\n#  from IPython.display import clear_output, Image, display\n\n#--- we need this to get a sane for-loop...\ndef jump_range(start, end, step):\n    while start &lt;= end:\n        yield start\n        start += step\n\n# --- function for displaying state of the pond's surface as an image\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\n  global proc\n  # proc.kill() \n  # \"\"\"Display an array as a picture. \"\"\"\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\n  amod = np.clip(a, 0, 255)\n  a = np.uint8(amod)\n#  a = np.clip(a, 0, 255) \n#  a = np.uint8(a) \n#  np.clip(a, 0, 255, out=a )\n#  a = a.astype('uint8')\n  print \" \"\n  print \" ----------- This is a: =&gt; row 20  ------------\"\n  print a[20]\n  print \" ----------------------------------------------\"\n  f = BytesIO()\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\n  # PIL.Image.fromarray(a).save(f,fmt)\n  # --- clear_output(wait = True)  --- only for IPython\n  # display(Image(data=f.getvalue()))\n  # --- write the image\n  # --- write the simulation images to .jpg files\n  # scipy.misc.imsave(\"tensor.jpg\", a)\n  # pic = PIL.Image.open(\"tensor.jpg\")\n  # --- new approach... use subprocess, wait for time(2) then kill it\n  # proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\n  # time.sleep(0.5)\n  # pic.show()\n  # clear_output(wait=True)\n  # --- this line below doesn't work outside of the Jupyter environment...\n  # display(Image(data=f.getvalue()))\n  #\n  # pic.close()  &lt;--- does not work to close image.  Just removes the pointer to image in memory\n    \ndef DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):\n  # \"\"\"Display an array as a picture to a file... \"\"\"\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\n  a = np.uint8(np.clip(a, 0, 255))\n  f = BytesIO()\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\n  # PIL.Image.fromarray(a).save(f,fmt)\n  # clear_output(wait = True)\n  # display(Image(data=f.getvalue()))\n  # --- write the image\n  # --- this is my stuff to write the simulation images to .jpg files\n  #scipy.misc.imsave (\"tensor_new.jpg\", a)\n  imageio.imwrite(\"tensor_new.jpg\", a)\n  # --- image = PIL.Image.open(\"tensor_new.jpg\")\n  # --- image.show()\n  # clear_output(wait=True)\n  # display(Image(data=f.getvalue()))\n  #\n \n# --- make print stmt print the whole array... (not just part of it...)\nnp.set_printoptions(threshold=np.nan)\n  \n# --- make interactive session for testing - can use regular session also\nsess = tf.InteractiveSession()\n# sess = tf.Session()\n\n# --- computational functions go here... once we get jpeg pic working\ndef make_kernel(a):\n  \"\"\"Transform a 2D array into a convolutional kernel \"\"\"  \n  a = np.asarray(a, dtype=np.float32)\n  a = a.reshape(list(a.shape) + [1,1])\n  return tf.constant(a, dtype=1)\n\n\ndef simple_conv(x, k):\n  \"\"\" A simplified 2D convolutional operation \"\"\"\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\n  print \"simple_conv x dtype is: \", x.dtype\n  print \" x is ....:\", x\n  print \"simple_conv k dtype is: \", k.dtype\n  print \" k is ....:\", k\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\n  print \"simple_conv y dtype is: \", y.dtype\n  print \" y is ....\", y\n  return y[0, :, :, 0]\n\n\ndef laplace(x):\n  \"\"\"Compute the 2D laplacian of an array \"\"\"\n  laplace_k = make_kernel([[0.5, 1.0, 0.5],\n                           [1.0, -6., 1.0],\n                           [0.5, 1.0, 0.5]])  \n  return simple_conv(x, laplace_k)\n\n\n\n# --- Define the PDE - the pond surface is a perfect 400x400 square\nprint \"\\nLaplace PDE Simulation Test \\n\"\nN = 400\nprint \"Surface square side is: \",N\n\n# --- list of display points...\ndispval = jump_range(0, 12500, 1000)\n# --- dispval has to be a list...\ndispval = list(dispval)\nprint \"We will look at these values: \",dispval\n\n# --- now, we create some \"raindrops\"\n# --- Initial Conditions -- some rain drops hit the pond\n# --- set everything to zero\nu_init = np.zeros([N, N], dtype=np.float32)\nut_init = np.zeros([N, N], dtype=np.float32)\n\n# Some material accretion occurs (raindrops hit pond) at random points\n# for n in range(40):\n#   a,b = np.random.randint(0, N, 2)\n#   u_init[a,b] = np.random.uniform()\n\n# --- not random.  Fixed &amp; same each run\nu_init[10,20]   = 1.4565\nu_init[12,100]  = 0.7522\nu_init[112,37]  = 1.21223\nu_init[230,139] = 0.9756\nu_init[301,205] = 1.7899\nu_init[372,347] = 0.4588\nu_init[74,193]  = 0.11987\nu_init[89,312]  = 1.1877\nu_init[178,287] = 1.5744\nu_init[197,276] = 0.9876\n\n\nu_init[101,21]  = 0.4565\nu_init[132,290] = 1.2522\nu_init[212,207] = 1.41223\nu_init[130,139] = 1.5672\nu_init[201,115] = 0.7899\nu_init[162,307] = 1.4588\nu_init[274,163] = 1.9187\nu_init[189,212] = 0.1877\nu_init[278,187] = 1.3744\nu_init[156,76]  = 1.9876\n\n\n# --- Create and Display the jpeg image...\n# proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\n# DisplayArray(u_init, rng=[-0.1, 0.1])\n\n# Parameters\n# eps -- time resolution\n# damping -- wave damping\neps = tf.placeholder(tf.float32, shape=())\ndamping = tf.placeholder(tf.float32, shape=())\n\n# --- Create vaiables for simulation state\nU  = tf.Variable(u_init)\nUt = tf.Variable(u_init)\n\n# --- Discretized PDE update rules\nU_  = U + eps * Ut\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\n\n# --- Operation to update the state\nstep = tf.group(\n  U.assign(U_),\n  Ut.assign(Ut_))\n\n# --- Run the simulation forward with a simple FOR loop.\n# --- Initialize state to initial conditions\ntf.global_variables_initializer().run(session=sess)\n\n# --- Run 12701 steps of PDE\nfor i in range(12701):\n  # Step simulation  (damping was 0.04, I made it negative .14)\n   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})\n# --- to see everything...\n#   with sess.as_default(): print \"U.eval()   .... \", U.eval()[20]  # --- ,\"   \", Ut.eval()\n# ------\n\n   if (i in dispval) :\n       print \"                                ------ Showing iteration:  \",i\n       sys.stdout.flush()\n       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\n       print \"                                ------ Within  iteration:  \",i\n       sys.stdout.flush()\n       print \"U.eval()[20]   ....... \"\n       with sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\n       print \"                                ------- End of iteration:  \",i\n       sys.stdout.flush()\n       continue\n#\n# --- to show each iteration...\n#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\nprint \"Done at: \",i\n\n# --- Ok, we are done...\nwith sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\nprint \"U.eval()[20]   ....... \"\nwith sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\nprint \"Done. ---  Square side size was: \",N\n\nwith sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])\nprint \"Last Image Written to file: tensor_new.jpg. Done.\"   \n#--------------- done ------------------\n</code></pre>", "body_text": "As promised, here is a more direct example of the operational difference noted between MacOS and Linux versions of TensorFlow 1.4.1.  I've removed all randomness from the initial conditions of the test program, and removed the need to use scipy, PIL/Pillow and matplotlib (and the TkAgg backend).   All we are basically doing here his calling TensorFlow routines: \"tf.expand_dims\" and \"tf.nn.depthwise_conv2d\" to set things up, \"tf.group\" to define the step, \"tf.global_variables_initializer\" to initialize variables, and \"step.run\" to iterate.\nRow 20 of the matrix \"U\" is displayed using U.eval.  This prints 400 numbers.  After only 1000 iterations, the Linux version of TensorFlow 1.4.1 shows the first number in row 20 of U as a value that is typically around 1.4 to 1.5.  The MacOS version (running on MacOS 10.10.5 (Yosemite)), typically shows a value around 0.336 to 0.337.  One can simply interupt the running Python program with control-c, and examine the 400 numbers displayed for iteration 1000, when the program displays the iteration=1000 information.\nThese differences remain essentially the same, with small floating-point numeric variations between runs, the source of which is unclear at this time. Each machine shows small variations in its results each time, after only 1000 iterations  (a few percentage points different).  This may be due to characteristic operation of the floating-point solid-state electronics.   But between platforms, the difference exceeds 300 percent, and this has to be seen as unacceptable.  From run to run, this magnitude of difference remains consistant.  So far, I have been unable to detect any specifc flaw in floating point operations on the Macbook Pro running under MacOS 10.10.5, nor on the HP box, which is running under CentOS Linux 7.4.\nTensorFlow is producing quite different results on two different (but architecturally similar) computers.\nThe test program, \"laptestnum.py\"  is attached below.\n#-------------------------------------------------------------------------------\n# Prgm: laptestnum.py\n#\n# --- all randomness at startup is removed.  Program begins with specified\n# --- input values that are exactly the same for each run.\n#\n# --- this is a stripped-down version of LapTest.py, just produces numbers,\n# --- and a final image to \"tensor_new.jpg\".  Does not require scipy.misc\n# --- does not require PIL/Pillow image processing library\n# --- does not use or require matplotlib or TkAgg backend\n# --- does not produce images while running - only outputs row 20 of matrix U.eval()\n# --- \n# --- one may interrupt program with ctrl-c after only 1000 iterations, and\n# --- note the dramatic difference between the Apple Mac (10.10.5 MacOS) and\n# --- Linux version.  \n#\n# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)\n# --- updated for TensorFlow 1.4.0 running on CentOS-7.4 & Python 2.7.14\n#     compiled (configured, actually) with the \"--enable-unicode=ucs4\" option\n#                                             (Python compile default is ucs2)\n#                                             (which caused TensorFlow 1.4 to)\n#                                             (fail to load. Building Python )\n#                                             (with ucs4, => pip can install )\n#                                             (TensorFlow 1.4.0 successfully.)\n\n# --- Import various libraries for simulation\nimport tensorflow as tf\nimport numpy as np\n# import scipy.misc\nimport imageio\n# import os\nimport sys\nimport subprocess\n# import PIL\n# import time    \n\n\n# --- Import for visualization and jpeg encoder  \n# import matplotlib\n# matplotlib.rcParams[\"backend\"]= 'TkAgg'\n# from matplotlib import pyplot as plt\n# from PIL import Image, ImageDraw\nfrom io import BytesIO\n#  from IPython.display import clear_output, Image, display\n\n#--- we need this to get a sane for-loop...\ndef jump_range(start, end, step):\n    while start <= end:\n        yield start\n        start += step\n\n# --- function for displaying state of the pond's surface as an image\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\n  global proc\n  # proc.kill() \n  # \"\"\"Display an array as a picture. \"\"\"\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\n  amod = np.clip(a, 0, 255)\n  a = np.uint8(amod)\n#  a = np.clip(a, 0, 255) \n#  a = np.uint8(a) \n#  np.clip(a, 0, 255, out=a )\n#  a = a.astype('uint8')\n  print \" \"\n  print \" ----------- This is a: => row 20  ------------\"\n  print a[20]\n  print \" ----------------------------------------------\"\n  f = BytesIO()\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\n  # PIL.Image.fromarray(a).save(f,fmt)\n  # --- clear_output(wait = True)  --- only for IPython\n  # display(Image(data=f.getvalue()))\n  # --- write the image\n  # --- write the simulation images to .jpg files\n  # scipy.misc.imsave(\"tensor.jpg\", a)\n  # pic = PIL.Image.open(\"tensor.jpg\")\n  # --- new approach... use subprocess, wait for time(2) then kill it\n  # proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\n  # time.sleep(0.5)\n  # pic.show()\n  # clear_output(wait=True)\n  # --- this line below doesn't work outside of the Jupyter environment...\n  # display(Image(data=f.getvalue()))\n  #\n  # pic.close()  <--- does not work to close image.  Just removes the pointer to image in memory\n    \ndef DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):\n  # \"\"\"Display an array as a picture to a file... \"\"\"\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\n  a = np.uint8(np.clip(a, 0, 255))\n  f = BytesIO()\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\n  # PIL.Image.fromarray(a).save(f,fmt)\n  # clear_output(wait = True)\n  # display(Image(data=f.getvalue()))\n  # --- write the image\n  # --- this is my stuff to write the simulation images to .jpg files\n  #scipy.misc.imsave (\"tensor_new.jpg\", a)\n  imageio.imwrite(\"tensor_new.jpg\", a)\n  # --- image = PIL.Image.open(\"tensor_new.jpg\")\n  # --- image.show()\n  # clear_output(wait=True)\n  # display(Image(data=f.getvalue()))\n  #\n \n# --- make print stmt print the whole array... (not just part of it...)\nnp.set_printoptions(threshold=np.nan)\n  \n# --- make interactive session for testing - can use regular session also\nsess = tf.InteractiveSession()\n# sess = tf.Session()\n\n# --- computational functions go here... once we get jpeg pic working\ndef make_kernel(a):\n  \"\"\"Transform a 2D array into a convolutional kernel \"\"\"  \n  a = np.asarray(a, dtype=np.float32)\n  a = a.reshape(list(a.shape) + [1,1])\n  return tf.constant(a, dtype=1)\n\n\ndef simple_conv(x, k):\n  \"\"\" A simplified 2D convolutional operation \"\"\"\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\n  print \"simple_conv x dtype is: \", x.dtype\n  print \" x is ....:\", x\n  print \"simple_conv k dtype is: \", k.dtype\n  print \" k is ....:\", k\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\n  print \"simple_conv y dtype is: \", y.dtype\n  print \" y is ....\", y\n  return y[0, :, :, 0]\n\n\ndef laplace(x):\n  \"\"\"Compute the 2D laplacian of an array \"\"\"\n  laplace_k = make_kernel([[0.5, 1.0, 0.5],\n                           [1.0, -6., 1.0],\n                           [0.5, 1.0, 0.5]])  \n  return simple_conv(x, laplace_k)\n\n\n\n# --- Define the PDE - the pond surface is a perfect 400x400 square\nprint \"\\nLaplace PDE Simulation Test \\n\"\nN = 400\nprint \"Surface square side is: \",N\n\n# --- list of display points...\ndispval = jump_range(0, 12500, 1000)\n# --- dispval has to be a list...\ndispval = list(dispval)\nprint \"We will look at these values: \",dispval\n\n# --- now, we create some \"raindrops\"\n# --- Initial Conditions -- some rain drops hit the pond\n# --- set everything to zero\nu_init = np.zeros([N, N], dtype=np.float32)\nut_init = np.zeros([N, N], dtype=np.float32)\n\n# Some material accretion occurs (raindrops hit pond) at random points\n# for n in range(40):\n#   a,b = np.random.randint(0, N, 2)\n#   u_init[a,b] = np.random.uniform()\n\n# --- not random.  Fixed & same each run\nu_init[10,20]   = 1.4565\nu_init[12,100]  = 0.7522\nu_init[112,37]  = 1.21223\nu_init[230,139] = 0.9756\nu_init[301,205] = 1.7899\nu_init[372,347] = 0.4588\nu_init[74,193]  = 0.11987\nu_init[89,312]  = 1.1877\nu_init[178,287] = 1.5744\nu_init[197,276] = 0.9876\n\n\nu_init[101,21]  = 0.4565\nu_init[132,290] = 1.2522\nu_init[212,207] = 1.41223\nu_init[130,139] = 1.5672\nu_init[201,115] = 0.7899\nu_init[162,307] = 1.4588\nu_init[274,163] = 1.9187\nu_init[189,212] = 0.1877\nu_init[278,187] = 1.3744\nu_init[156,76]  = 1.9876\n\n\n# --- Create and Display the jpeg image...\n# proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\n# DisplayArray(u_init, rng=[-0.1, 0.1])\n\n# Parameters\n# eps -- time resolution\n# damping -- wave damping\neps = tf.placeholder(tf.float32, shape=())\ndamping = tf.placeholder(tf.float32, shape=())\n\n# --- Create vaiables for simulation state\nU  = tf.Variable(u_init)\nUt = tf.Variable(u_init)\n\n# --- Discretized PDE update rules\nU_  = U + eps * Ut\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\n\n# --- Operation to update the state\nstep = tf.group(\n  U.assign(U_),\n  Ut.assign(Ut_))\n\n# --- Run the simulation forward with a simple FOR loop.\n# --- Initialize state to initial conditions\ntf.global_variables_initializer().run(session=sess)\n\n# --- Run 12701 steps of PDE\nfor i in range(12701):\n  # Step simulation  (damping was 0.04, I made it negative .14)\n   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})\n# --- to see everything...\n#   with sess.as_default(): print \"U.eval()   .... \", U.eval()[20]  # --- ,\"   \", Ut.eval()\n# ------\n\n   if (i in dispval) :\n       print \"                                ------ Showing iteration:  \",i\n       sys.stdout.flush()\n       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\n       print \"                                ------ Within  iteration:  \",i\n       sys.stdout.flush()\n       print \"U.eval()[20]   ....... \"\n       with sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\n       print \"                                ------- End of iteration:  \",i\n       sys.stdout.flush()\n       continue\n#\n# --- to show each iteration...\n#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\nprint \"Done at: \",i\n\n# --- Ok, we are done...\nwith sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\nprint \"U.eval()[20]   ....... \"\nwith sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\nprint \"Done. ---  Square side size was: \",N\n\nwith sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])\nprint \"Last Image Written to file: tensor_new.jpg. Done.\"   \n#--------------- done ------------------", "body": "As promised, here is a more direct example of the operational difference noted between MacOS and Linux versions of TensorFlow 1.4.1.  I've removed all randomness from the initial conditions of the test program, and removed the need to use scipy, PIL/Pillow and matplotlib (and the TkAgg backend).   All we are basically doing here his calling TensorFlow routines: \"tf.expand_dims\" and \"tf.nn.depthwise_conv2d\" to set things up, \"tf.group\" to define the step, \"tf.global_variables_initializer\" to initialize variables, and \"step.run\" to iterate.  \r\n\r\nRow 20 of the matrix \"U\" is displayed using U.eval.  This prints 400 numbers.  After only 1000 iterations, the Linux version of TensorFlow 1.4.1 shows the first number in row 20 of U as a value that is typically around 1.4 to 1.5.  The MacOS version (running on MacOS 10.10.5 (Yosemite)), typically shows a value around 0.336 to 0.337.  One can simply interupt the running Python program with control-c, and examine the 400 numbers displayed for iteration 1000, when the program displays the iteration=1000 information.  \r\n\r\nThese differences remain essentially the same, with small floating-point numeric variations between runs, the source of which is unclear at this time. Each machine shows small variations in its results each time, after only 1000 iterations  (a few percentage points different).  This may be due to characteristic operation of the floating-point solid-state electronics.   But between platforms, the difference exceeds 300 percent, and this has to be seen as unacceptable.  From run to run, this magnitude of difference remains consistant.  So far, I have been unable to detect any specifc flaw in floating point operations on the Macbook Pro running under MacOS 10.10.5, nor on the HP box, which is running under CentOS Linux 7.4.\r\n\r\nTensorFlow is producing quite different results on two different (but architecturally similar) computers.  \r\n\r\nThe test program, \"laptestnum.py\"  is attached below.\r\n\r\n```\r\n#-------------------------------------------------------------------------------\r\n# Prgm: laptestnum.py\r\n#\r\n# --- all randomness at startup is removed.  Program begins with specified\r\n# --- input values that are exactly the same for each run.\r\n#\r\n# --- this is a stripped-down version of LapTest.py, just produces numbers,\r\n# --- and a final image to \"tensor_new.jpg\".  Does not require scipy.misc\r\n# --- does not require PIL/Pillow image processing library\r\n# --- does not use or require matplotlib or TkAgg backend\r\n# --- does not produce images while running - only outputs row 20 of matrix U.eval()\r\n# --- \r\n# --- one may interrupt program with ctrl-c after only 1000 iterations, and\r\n# --- note the dramatic difference between the Apple Mac (10.10.5 MacOS) and\r\n# --- Linux version.  \r\n#\r\n# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)\r\n# --- updated for TensorFlow 1.4.0 running on CentOS-7.4 & Python 2.7.14\r\n#     compiled (configured, actually) with the \"--enable-unicode=ucs4\" option\r\n#                                             (Python compile default is ucs2)\r\n#                                             (which caused TensorFlow 1.4 to)\r\n#                                             (fail to load. Building Python )\r\n#                                             (with ucs4, => pip can install )\r\n#                                             (TensorFlow 1.4.0 successfully.)\r\n\r\n# --- Import various libraries for simulation\r\nimport tensorflow as tf\r\nimport numpy as np\r\n# import scipy.misc\r\nimport imageio\r\n# import os\r\nimport sys\r\nimport subprocess\r\n# import PIL\r\n# import time    \r\n\r\n\r\n# --- Import for visualization and jpeg encoder  \r\n# import matplotlib\r\n# matplotlib.rcParams[\"backend\"]= 'TkAgg'\r\n# from matplotlib import pyplot as plt\r\n# from PIL import Image, ImageDraw\r\nfrom io import BytesIO\r\n#  from IPython.display import clear_output, Image, display\r\n\r\n#--- we need this to get a sane for-loop...\r\ndef jump_range(start, end, step):\r\n    while start <= end:\r\n        yield start\r\n        start += step\r\n\r\n# --- function for displaying state of the pond's surface as an image\r\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\r\n  global proc\r\n  # proc.kill() \r\n  # \"\"\"Display an array as a picture. \"\"\"\r\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\r\n  amod = np.clip(a, 0, 255)\r\n  a = np.uint8(amod)\r\n#  a = np.clip(a, 0, 255) \r\n#  a = np.uint8(a) \r\n#  np.clip(a, 0, 255, out=a )\r\n#  a = a.astype('uint8')\r\n  print \" \"\r\n  print \" ----------- This is a: => row 20  ------------\"\r\n  print a[20]\r\n  print \" ----------------------------------------------\"\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  # PIL.Image.fromarray(a).save(f,fmt)\r\n  # --- clear_output(wait = True)  --- only for IPython\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- write the simulation images to .jpg files\r\n  # scipy.misc.imsave(\"tensor.jpg\", a)\r\n  # pic = PIL.Image.open(\"tensor.jpg\")\r\n  # --- new approach... use subprocess, wait for time(2) then kill it\r\n  # proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n  # time.sleep(0.5)\r\n  # pic.show()\r\n  # clear_output(wait=True)\r\n  # --- this line below doesn't work outside of the Jupyter environment...\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n  # pic.close()  <--- does not work to close image.  Just removes the pointer to image in memory\r\n    \r\ndef DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):\r\n  # \"\"\"Display an array as a picture to a file... \"\"\"\r\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\r\n  a = np.uint8(np.clip(a, 0, 255))\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  # PIL.Image.fromarray(a).save(f,fmt)\r\n  # clear_output(wait = True)\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- this is my stuff to write the simulation images to .jpg files\r\n  #scipy.misc.imsave (\"tensor_new.jpg\", a)\r\n  imageio.imwrite(\"tensor_new.jpg\", a)\r\n  # --- image = PIL.Image.open(\"tensor_new.jpg\")\r\n  # --- image.show()\r\n  # clear_output(wait=True)\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n \r\n# --- make print stmt print the whole array... (not just part of it...)\r\nnp.set_printoptions(threshold=np.nan)\r\n  \r\n# --- make interactive session for testing - can use regular session also\r\nsess = tf.InteractiveSession()\r\n# sess = tf.Session()\r\n\r\n# --- computational functions go here... once we get jpeg pic working\r\ndef make_kernel(a):\r\n  \"\"\"Transform a 2D array into a convolutional kernel \"\"\"  \r\n  a = np.asarray(a, dtype=np.float32)\r\n  a = a.reshape(list(a.shape) + [1,1])\r\n  return tf.constant(a, dtype=1)\r\n\r\n\r\ndef simple_conv(x, k):\r\n  \"\"\" A simplified 2D convolutional operation \"\"\"\r\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\r\n  print \"simple_conv x dtype is: \", x.dtype\r\n  print \" x is ....:\", x\r\n  print \"simple_conv k dtype is: \", k.dtype\r\n  print \" k is ....:\", k\r\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\r\n  print \"simple_conv y dtype is: \", y.dtype\r\n  print \" y is ....\", y\r\n  return y[0, :, :, 0]\r\n\r\n\r\ndef laplace(x):\r\n  \"\"\"Compute the 2D laplacian of an array \"\"\"\r\n  laplace_k = make_kernel([[0.5, 1.0, 0.5],\r\n                           [1.0, -6., 1.0],\r\n                           [0.5, 1.0, 0.5]])  \r\n  return simple_conv(x, laplace_k)\r\n\r\n\r\n\r\n# --- Define the PDE - the pond surface is a perfect 400x400 square\r\nprint \"\\nLaplace PDE Simulation Test \\n\"\r\nN = 400\r\nprint \"Surface square side is: \",N\r\n\r\n# --- list of display points...\r\ndispval = jump_range(0, 12500, 1000)\r\n# --- dispval has to be a list...\r\ndispval = list(dispval)\r\nprint \"We will look at these values: \",dispval\r\n\r\n# --- now, we create some \"raindrops\"\r\n# --- Initial Conditions -- some rain drops hit the pond\r\n# --- set everything to zero\r\nu_init = np.zeros([N, N], dtype=np.float32)\r\nut_init = np.zeros([N, N], dtype=np.float32)\r\n\r\n# Some material accretion occurs (raindrops hit pond) at random points\r\n# for n in range(40):\r\n#   a,b = np.random.randint(0, N, 2)\r\n#   u_init[a,b] = np.random.uniform()\r\n\r\n# --- not random.  Fixed & same each run\r\nu_init[10,20]   = 1.4565\r\nu_init[12,100]  = 0.7522\r\nu_init[112,37]  = 1.21223\r\nu_init[230,139] = 0.9756\r\nu_init[301,205] = 1.7899\r\nu_init[372,347] = 0.4588\r\nu_init[74,193]  = 0.11987\r\nu_init[89,312]  = 1.1877\r\nu_init[178,287] = 1.5744\r\nu_init[197,276] = 0.9876\r\n\r\n\r\nu_init[101,21]  = 0.4565\r\nu_init[132,290] = 1.2522\r\nu_init[212,207] = 1.41223\r\nu_init[130,139] = 1.5672\r\nu_init[201,115] = 0.7899\r\nu_init[162,307] = 1.4588\r\nu_init[274,163] = 1.9187\r\nu_init[189,212] = 0.1877\r\nu_init[278,187] = 1.3744\r\nu_init[156,76]  = 1.9876\r\n\r\n\r\n# --- Create and Display the jpeg image...\r\n# proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n# DisplayArray(u_init, rng=[-0.1, 0.1])\r\n\r\n# Parameters\r\n# eps -- time resolution\r\n# damping -- wave damping\r\neps = tf.placeholder(tf.float32, shape=())\r\ndamping = tf.placeholder(tf.float32, shape=())\r\n\r\n# --- Create vaiables for simulation state\r\nU  = tf.Variable(u_init)\r\nUt = tf.Variable(u_init)\r\n\r\n# --- Discretized PDE update rules\r\nU_  = U + eps * Ut\r\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\r\n\r\n# --- Operation to update the state\r\nstep = tf.group(\r\n  U.assign(U_),\r\n  Ut.assign(Ut_))\r\n\r\n# --- Run the simulation forward with a simple FOR loop.\r\n# --- Initialize state to initial conditions\r\ntf.global_variables_initializer().run(session=sess)\r\n\r\n# --- Run 12701 steps of PDE\r\nfor i in range(12701):\r\n  # Step simulation  (damping was 0.04, I made it negative .14)\r\n   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})\r\n# --- to see everything...\r\n#   with sess.as_default(): print \"U.eval()   .... \", U.eval()[20]  # --- ,\"   \", Ut.eval()\r\n# ------\r\n\r\n   if (i in dispval) :\r\n       print \"                                ------ Showing iteration:  \",i\r\n       sys.stdout.flush()\r\n       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\n       print \"                                ------ Within  iteration:  \",i\r\n       sys.stdout.flush()\r\n       print \"U.eval()[20]   ....... \"\r\n       with sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\r\n       print \"                                ------- End of iteration:  \",i\r\n       sys.stdout.flush()\r\n       continue\r\n#\r\n# --- to show each iteration...\r\n#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Done at: \",i\r\n\r\n# --- Ok, we are done...\r\nwith sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\nprint \"U.eval()[20]   ....... \"\r\nwith sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\r\nprint \"Done. ---  Square side size was: \",N\r\n\r\nwith sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Last Image Written to file: tensor_new.jpg. Done.\"   \r\n#--------------- done ------------------\r\n```\r\n"}