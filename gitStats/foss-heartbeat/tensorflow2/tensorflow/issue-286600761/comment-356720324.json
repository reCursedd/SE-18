{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/356720324", "html_url": "https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-356720324", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15933", "id": 356720324, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjcyMDMyNA==", "user": {"login": "Gemesys", "id": 16905336, "node_id": "MDQ6VXNlcjE2OTA1MzM2", "avatar_url": "https://avatars1.githubusercontent.com/u/16905336?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gemesys", "html_url": "https://github.com/Gemesys", "followers_url": "https://api.github.com/users/Gemesys/followers", "following_url": "https://api.github.com/users/Gemesys/following{/other_user}", "gists_url": "https://api.github.com/users/Gemesys/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gemesys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gemesys/subscriptions", "organizations_url": "https://api.github.com/users/Gemesys/orgs", "repos_url": "https://api.github.com/users/Gemesys/repos", "events_url": "https://api.github.com/users/Gemesys/events{/privacy}", "received_events_url": "https://api.github.com/users/Gemesys/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-10T20:04:27Z", "updated_at": "2018-01-10T20:04:27Z", "author_association": "NONE", "body_html": "<p>Thank-you so much for this, quaeler!  This is really helpful.  The behaviour on your 10.12.6 macos matches <em>exactly</em> what I am seeing on my Linux box, which seems to be very stable, and does not show any evidence of any other issue anywhere, so far.  I'm running Firefox 52.2 ESR, and a bunch of Tcl/Tk stuff, including an editor, some encryption stuff, and such.    It all works, and I have confidence in the configuration.  Your run Ubuntu was slightly different - but what you have provided here looks exactly like what I see, almost pixel-for-pixel.  (I've attached proper screen-shot image from my Linux machine.)  The simulation begins with  pesudo-random  values, but evolves always - despite changes in images size - to what you are showing here.  I ran a 1200x1200 image sequence yesterday, and it still looked the same.   I've downloaded and run some floating-point test/check software from here:  <a href=\"http://www.math.utah.edu/~beebe/software/ieee/\" rel=\"nofollow\">http://www.math.utah.edu/~beebe/software/ieee/</a><br>\nand the screen-shot of running fpshow.c shows the repesentation of floating-point constants on the left for the Linux-CentOS-7.4 box and on the right for the MacBook, running 10.10.5 macos.  (Centre is the info in the ieeeftn.h file, with explanations and indication of what is expected to be seen).   In running different sizes of the output image, I notice that the behaviour matches between the two machines up to an image of about 90x90.  Above that, the Mac blows up (image goes all white), ie. behaviour diverges.</p>\n<p>Looks like a memory or overflow problem.  The output of the \"fpshow.c\" program (provided below) shows that floating point representation between the Linux and Macbook  are the same, for the 64-bit words.  Linux side does show extranious data in next location, whereas Mac shows zeros, but that is an artifact of the fpshow.c program being written for 32-bit, I think. It's just showing next 64-bit memory location.  The 64-bit numeric stuff is same on both, as far as I can tell.  Both machines have 4 GB memory, for \"gcc --version\" Linux box reports: \" 4.8.5 20150623 (Red Hat 4.8.5-16)\", and the Mac reports: \"Apple LLVM version 7.0.2 (clang-700.1.01)  Target: x86_64-apple-darwin14.5.0, Thread model: posix\".</p>\n<p>I will try to make a more simple test case.  But what you have provided here, suggests there is a bug in the Apple's macos (10.10.5 - Yosemite) memory management or floating-point calculation operation.</p>\n<p>I also found an issue where a fellow reported  bizarre training results for a network.  Instead of a smooth curve of improvement (as the backprop progressed), he got these serious and strange discontiuous results - which yes, can happen if you are falling down a steep gradient in a new location on the error surface,  but his results were curious - looked almost like a hardware failure, but then the training would recover.   If there is a floating-point calculation issue, that only shows up in some cases, it might be the cause of this guy's strange training results.  (Like the early 1995 Intel FPU bug. It was only apparent sometimes, for some calculations.)</p>\n<p>But the fact that an upgraded version of the macos produces <em>exactly</em> the behaviour seen on my Linux box, suggests Apple's Yosemite is the culprit.  I won't upgrade the Mac, as I would like to determine what is happening here.  Results of the \"fpshow.c\" program (which \"ieeeftn.h\") from the above site (Univ. of Utah..), shown below.  Linux and Mac floating-point representation seem the same, as one would expect.  Also provide proper (not  just Android-phone image..) screen shot from my Linux box, showing expected behaviour, same as what you are seeing on your macOS 10.12.6.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/16905336/34789850-d18a46b6-f60d-11e7-8d87-41446dcb07a1.jpg\"><img src=\"https://user-images.githubusercontent.com/16905336/34789850-d18a46b6-f60d-11e7-8d87-41446dcb07a1.jpg\" alt=\"fpshow_results\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/16905336/34792871-7c62859a-f617-11e7-94ba-84d3666090c0.jpg\"><img src=\"https://user-images.githubusercontent.com/16905336/34792871-7c62859a-f617-11e7-94ba-84d3666090c0.jpg\" alt=\"laptestl_py_screenshot_2018-01-10 14-50-43\" style=\"max-width:100%;\"></a></p>", "body_text": "Thank-you so much for this, quaeler!  This is really helpful.  The behaviour on your 10.12.6 macos matches exactly what I am seeing on my Linux box, which seems to be very stable, and does not show any evidence of any other issue anywhere, so far.  I'm running Firefox 52.2 ESR, and a bunch of Tcl/Tk stuff, including an editor, some encryption stuff, and such.    It all works, and I have confidence in the configuration.  Your run Ubuntu was slightly different - but what you have provided here looks exactly like what I see, almost pixel-for-pixel.  (I've attached proper screen-shot image from my Linux machine.)  The simulation begins with  pesudo-random  values, but evolves always - despite changes in images size - to what you are showing here.  I ran a 1200x1200 image sequence yesterday, and it still looked the same.   I've downloaded and run some floating-point test/check software from here:  http://www.math.utah.edu/~beebe/software/ieee/\nand the screen-shot of running fpshow.c shows the repesentation of floating-point constants on the left for the Linux-CentOS-7.4 box and on the right for the MacBook, running 10.10.5 macos.  (Centre is the info in the ieeeftn.h file, with explanations and indication of what is expected to be seen).   In running different sizes of the output image, I notice that the behaviour matches between the two machines up to an image of about 90x90.  Above that, the Mac blows up (image goes all white), ie. behaviour diverges.\nLooks like a memory or overflow problem.  The output of the \"fpshow.c\" program (provided below) shows that floating point representation between the Linux and Macbook  are the same, for the 64-bit words.  Linux side does show extranious data in next location, whereas Mac shows zeros, but that is an artifact of the fpshow.c program being written for 32-bit, I think. It's just showing next 64-bit memory location.  The 64-bit numeric stuff is same on both, as far as I can tell.  Both machines have 4 GB memory, for \"gcc --version\" Linux box reports: \" 4.8.5 20150623 (Red Hat 4.8.5-16)\", and the Mac reports: \"Apple LLVM version 7.0.2 (clang-700.1.01)  Target: x86_64-apple-darwin14.5.0, Thread model: posix\".\nI will try to make a more simple test case.  But what you have provided here, suggests there is a bug in the Apple's macos (10.10.5 - Yosemite) memory management or floating-point calculation operation.\nI also found an issue where a fellow reported  bizarre training results for a network.  Instead of a smooth curve of improvement (as the backprop progressed), he got these serious and strange discontiuous results - which yes, can happen if you are falling down a steep gradient in a new location on the error surface,  but his results were curious - looked almost like a hardware failure, but then the training would recover.   If there is a floating-point calculation issue, that only shows up in some cases, it might be the cause of this guy's strange training results.  (Like the early 1995 Intel FPU bug. It was only apparent sometimes, for some calculations.)\nBut the fact that an upgraded version of the macos produces exactly the behaviour seen on my Linux box, suggests Apple's Yosemite is the culprit.  I won't upgrade the Mac, as I would like to determine what is happening here.  Results of the \"fpshow.c\" program (which \"ieeeftn.h\") from the above site (Univ. of Utah..), shown below.  Linux and Mac floating-point representation seem the same, as one would expect.  Also provide proper (not  just Android-phone image..) screen shot from my Linux box, showing expected behaviour, same as what you are seeing on your macOS 10.12.6.", "body": "Thank-you so much for this, quaeler!  This is really helpful.  The behaviour on your 10.12.6 macos matches *exactly* what I am seeing on my Linux box, which seems to be very stable, and does not show any evidence of any other issue anywhere, so far.  I'm running Firefox 52.2 ESR, and a bunch of Tcl/Tk stuff, including an editor, some encryption stuff, and such.    It all works, and I have confidence in the configuration.  Your run Ubuntu was slightly different - but what you have provided here looks exactly like what I see, almost pixel-for-pixel.  (I've attached proper screen-shot image from my Linux machine.)  The simulation begins with  pesudo-random  values, but evolves always - despite changes in images size - to what you are showing here.  I ran a 1200x1200 image sequence yesterday, and it still looked the same.   I've downloaded and run some floating-point test/check software from here:  http://www.math.utah.edu/~beebe/software/ieee/ \r\nand the screen-shot of running fpshow.c shows the repesentation of floating-point constants on the left for the Linux-CentOS-7.4 box and on the right for the MacBook, running 10.10.5 macos.  (Centre is the info in the ieeeftn.h file, with explanations and indication of what is expected to be seen).   In running different sizes of the output image, I notice that the behaviour matches between the two machines up to an image of about 90x90.  Above that, the Mac blows up (image goes all white), ie. behaviour diverges.   \r\n\r\nLooks like a memory or overflow problem.  The output of the \"fpshow.c\" program (provided below) shows that floating point representation between the Linux and Macbook  are the same, for the 64-bit words.  Linux side does show extranious data in next location, whereas Mac shows zeros, but that is an artifact of the fpshow.c program being written for 32-bit, I think. It's just showing next 64-bit memory location.  The 64-bit numeric stuff is same on both, as far as I can tell.  Both machines have 4 GB memory, for \"gcc --version\" Linux box reports: \" 4.8.5 20150623 (Red Hat 4.8.5-16)\", and the Mac reports: \"Apple LLVM version 7.0.2 (clang-700.1.01)  Target: x86_64-apple-darwin14.5.0, Thread model: posix\".   \r\n\r\nI will try to make a more simple test case.  But what you have provided here, suggests there is a bug in the Apple's macos (10.10.5 - Yosemite) memory management or floating-point calculation operation. \r\n\r\nI also found an issue where a fellow reported  bizarre training results for a network.  Instead of a smooth curve of improvement (as the backprop progressed), he got these serious and strange discontiuous results - which yes, can happen if you are falling down a steep gradient in a new location on the error surface,  but his results were curious - looked almost like a hardware failure, but then the training would recover.   If there is a floating-point calculation issue, that only shows up in some cases, it might be the cause of this guy's strange training results.  (Like the early 1995 Intel FPU bug. It was only apparent sometimes, for some calculations.)\r\n\r\nBut the fact that an upgraded version of the macos produces *exactly* the behaviour seen on my Linux box, suggests Apple's Yosemite is the culprit.  I won't upgrade the Mac, as I would like to determine what is happening here.  Results of the \"fpshow.c\" program (which \"ieeeftn.h\") from the above site (Univ. of Utah..), shown below.  Linux and Mac floating-point representation seem the same, as one would expect.  Also provide proper (not  just Android-phone image..) screen shot from my Linux box, showing expected behaviour, same as what you are seeing on your macOS 10.12.6. \r\n\r\n![fpshow_results](https://user-images.githubusercontent.com/16905336/34789850-d18a46b6-f60d-11e7-8d87-41446dcb07a1.jpg)\r\n![laptestl_py_screenshot_2018-01-10 14-50-43](https://user-images.githubusercontent.com/16905336/34792871-7c62859a-f617-11e7-94ba-84d3666090c0.jpg)\r\n"}