{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241869488", "html_url": "https://github.com/tensorflow/tensorflow/issues/3917#issuecomment-241869488", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3917", "id": 241869488, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTg2OTQ4OA==", "user": {"login": "cr145", "id": 21205758, "node_id": "MDQ6VXNlcjIxMjA1NzU4", "avatar_url": "https://avatars2.githubusercontent.com/u/21205758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cr145", "html_url": "https://github.com/cr145", "followers_url": "https://api.github.com/users/cr145/followers", "following_url": "https://api.github.com/users/cr145/following{/other_user}", "gists_url": "https://api.github.com/users/cr145/gists{/gist_id}", "starred_url": "https://api.github.com/users/cr145/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cr145/subscriptions", "organizations_url": "https://api.github.com/users/cr145/orgs", "repos_url": "https://api.github.com/users/cr145/repos", "events_url": "https://api.github.com/users/cr145/events{/privacy}", "received_events_url": "https://api.github.com/users/cr145/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-23T20:34:58Z", "updated_at": "2016-08-23T20:34:58Z", "author_association": "NONE", "body_html": "<p>I am getting the same error as well, although it only occurs about of the third of the time. The rest of the time the program exits normally, but shows nan for many of the output values.</p>\n<p><strong>gdb - on failure</strong></p>\n<pre><code>(gdb) r --use_gpu\nStarting program: /home/reale/.cache/bazel/_bazel_reale/b77777b530a2fcea5d78d328048dc62b/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\n[New Thread 0x7fffe1a36700 (LWP 26488)]\n[New Thread 0x7fffe1235700 (LWP 26489)]\n[New Thread 0x7fffe0a34700 (LWP 26490)]\n[New Thread 0x7fffe0233700 (LWP 26491)]\n[New Thread 0x7fffdfa32700 (LWP 26492)]\n[New Thread 0x7fffdf231700 (LWP 26493)]\n[New Thread 0x7fffdea30700 (LWP 26494)]\n[New Thread 0x7fffde22f700 (LWP 26495)]\n[New Thread 0x7fffdda2e700 (LWP 26496)]\n[New Thread 0x7fffdd22d700 (LWP 26497)]\n[New Thread 0x7fffdca2c700 (LWP 26498)]\n[New Thread 0x7fffcffff700 (LWP 26499)]\n[New Thread 0x7fffcf7fe700 (LWP 26500)]\n[New Thread 0x7fffceffd700 (LWP 26501)]\n[New Thread 0x7fffce7fc700 (LWP 26502)]\n[New Thread 0x7fffcdffb700 (LWP 26503)]\n[New Thread 0x7fffcd7fa700 (LWP 26504)]\n[New Thread 0x7fffccff9700 (LWP 26505)]\n[New Thread 0x7fffc7fff700 (LWP 26511)]\n[New Thread 0x7fffc77fe700 (LWP 26512)]\n[New Thread 0x7fffc6ffd700 (LWP 26513)]\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.54GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n[New Thread 0x7fffc67fc700 (LWP 26514)]\n[New Thread 0x7fffc5ffb700 (LWP 26515)]\n[New Thread 0x7fffc57fa700 (LWP 26516)]\n[New Thread 0x7fffc4ff9700 (LWP 26517)]\n[New Thread 0x7fffbffff700 (LWP 26518)]\n[New Thread 0x7fffbf7fe700 (LWP 26519)]\n[New Thread 0x7fffbd7fa700 (LWP 26523)]\n[New Thread 0x7fffbdffb700 (LWP 26521)]\n[New Thread 0x7fffbcff9700 (LWP 26524)]\n[New Thread 0x7fffbeffd700 (LWP 26520)]\n[New Thread 0x7fffb7fff700 (LWP 26525)]\n[New Thread 0x7fffbe7fc700 (LWP 26522)]\n[New Thread 0x7fffb67fc700 (LWP 26526)]\n[New Thread 0x7fffb5ffb700 (LWP 26528)]\n[New Thread 0x7fffb4ff9700 (LWP 26527)]\n[New Thread 0x7fffb77fe700 (LWP 26531)]\n[New Thread 0x7fffb6ffd700 (LWP 26529)]\n[New Thread 0x7fffb57fa700 (LWP 26530)]\n[New Thread 0x7fffaffff700 (LWP 26533)]\n[New Thread 0x7fffaf7fe700 (LWP 26532)]\n[New Thread 0x7fffaeffd700 (LWP 26534)]\n[New Thread 0x7fffae7fc700 (LWP 26535)]\n[New Thread 0x7fffadffb700 (LWP 26536)]\n[New Thread 0x7fffad7fa700 (LWP 26537)]\n[New Thread 0x7fffacff9700 (LWP 26538)]\n[New Thread 0x7fff99fff700 (LWP 26539)]\n[New Thread 0x7fff997fe700 (LWP 26540)]\n[New Thread 0x7fff98ffd700 (LWP 26541)]\n[New Thread 0x7fff937fe700 (LWP 26542)]\n[New Thread 0x7fff927fc700 (LWP 26546)]\n[New Thread 0x7fff84d5f700 (LWP 26549)]\n[New Thread 0x7fff90ff9700 (LWP 26547)]\n[New Thread 0x7fff917fa700 (LWP 26548)]\n[New Thread 0x7fff93fff700 (LWP 26543)]\n[New Thread 0x7fff91ffb700 (LWP 26545)]\n[New Thread 0x7fff83d5d700 (LWP 26551)]\n[New Thread 0x7fff92ffd700 (LWP 26544)]\n[New Thread 0x7fff8455e700 (LWP 26550)]\n[New Thread 0x7fff8355c700 (LWP 26552)]\n[New Thread 0x7fff7ed53700 (LWP 26559)]\n[New Thread 0x7fff7f554700 (LWP 26560)]\n[New Thread 0x7fff82d5b700 (LWP 26553)]\n[New Thread 0x7fff8255a700 (LWP 26554)]\n[New Thread 0x7fff81d59700 (LWP 26557)]\n[New Thread 0x7fff80d57700 (LWP 26555)]\n[New Thread 0x7fff81558700 (LWP 26558)]\n[New Thread 0x7fff80556700 (LWP 26556)]\n[New Thread 0x7fff7fd55700 (LWP 26561)]\n[New Thread 0x7fff7e552700 (LWP 26562)]\n[New Thread 0x7fff7bd4d700 (LWP 26567)]\n[New Thread 0x7fff7a54a700 (LWP 26570)]\n[New Thread 0x7fff7dd51700 (LWP 26563)]\n[New Thread 0x7fff7d550700 (LWP 26564)]\n[New Thread 0x7fff7b54c700 (LWP 26568)]\n[New Thread 0x7fff79d49700 (LWP 26571)]\n[New Thread 0x7fff7cd4f700 (LWP 26565)]\n[New Thread 0x7fff7ad4b700 (LWP 26569)]\n[New Thread 0x7fff7c54e700 (LWP 26566)]\n[New Thread 0x7fff79548700 (LWP 26572)]\n[New Thread 0x7fff75d41700 (LWP 26602)]\n[New Thread 0x7fff78d47700 (LWP 26573)]\n[New Thread 0x7fff78546700 (LWP 26599)]\n[New Thread 0x7fff75540700 (LWP 26600)]\n[New Thread 0x7fff76542700 (LWP 26597)]\n[New Thread 0x7fff77544700 (LWP 26598)]\n[New Thread 0x7fff77d45700 (LWP 26596)]\n[New Thread 0x7fff76d43700 (LWP 26574)]\n[New Thread 0x7fff74d3f700 (LWP 26601)]\n[New Thread 0x7fff73d3d700 (LWP 26604)]\n[New Thread 0x7fff7453e700 (LWP 26603)]\n[New Thread 0x7fff7353c700 (LWP 26605)]\n[New Thread 0x7fff70d37700 (LWP 26606)]\n[New Thread 0x7fff72d3b700 (LWP 26611)]\n[New Thread 0x7fff7253a700 (LWP 26608)]\n[New Thread 0x7fff71d39700 (LWP 26607)]\n[New Thread 0x7fff71538700 (LWP 26609)]\n[New Thread 0x7fff70536700 (LWP 26610)]\n[New Thread 0x7fff6fd35700 (LWP 26612)]\n[New Thread 0x7fff6f534700 (LWP 26613)]\n[New Thread 0x7fff6cd2f700 (LWP 26615)]\n[New Thread 0x7fff6ed33700 (LWP 26618)]\n[New Thread 0x7fff6e532700 (LWP 26617)]\n[New Thread 0x7fff6dd31700 (LWP 26614)]\n[New Thread 0x7fff6d530700 (LWP 26616)]\n[New Thread 0x7fff6c52e700 (LWP 26622)]\n[New Thread 0x7fff6ad2b700 (LWP 26619)]\n[New Thread 0x7fff6bd2d700 (LWP 26621)]\n[New Thread 0x7fff6b52c700 (LWP 26620)]\n[New Thread 0x7fff6a52a700 (LWP 26623)]\n[New Thread 0x7fff69d29700 (LWP 26624)]\n[New Thread 0x7fff69528700 (LWP 26631)]\n[New Thread 0x7fff68526700 (LWP 26628)]\n[New Thread 0x7fff66d23700 (LWP 26629)]\n[New Thread 0x7fff68d27700 (LWP 26625)]\n[New Thread 0x7fff66522700 (LWP 26627)]\n[New Thread 0x7fff65d21700 (LWP 26630)]\n[New Thread 0x7fff67d25700 (LWP 26632)]\n[New Thread 0x7fff67524700 (LWP 26626)]\n[New Thread 0x7fff65520700 (LWP 26633)]\n[New Thread 0x7fff64d1f700 (LWP 26634)]\n[New Thread 0x7fff6451e700 (LWP 26635)]\n[New Thread 0x7fff6351c700 (LWP 26636)]\n[New Thread 0x7fff63d1d700 (LWP 26637)]\n[New Thread 0x7fff62d1b700 (LWP 26638)]\n[New Thread 0x7fff6251a700 (LWP 26642)]\n[New Thread 0x7fff61d19700 (LWP 26641)]\n[New Thread 0x7fff61518700 (LWP 26639)]\n[New Thread 0x7fff60d17700 (LWP 26640)]\n[New Thread 0x7fff60516700 (LWP 26643)]\n[New Thread 0x7fff5d510700 (LWP 26652)]\n[New Thread 0x7fff5fd15700 (LWP 26644)]\n[New Thread 0x7fff5dd11700 (LWP 26648)]\n[New Thread 0x7fff5cd0f700 (LWP 26650)]\n[New Thread 0x7fff5f514700 (LWP 26645)]\n[New Thread 0x7fff5ed13700 (LWP 26646)]\n[New Thread 0x7fff5bd0d700 (LWP 26651)]\n[New Thread 0x7fff5c50e700 (LWP 26649)]\n[New Thread 0x7fff5e512700 (LWP 26647)]\n[New Thread 0x7fff5b50c700 (LWP 26653)]\n[New Thread 0x7fff5ad0b700 (LWP 26654)]\n[New Thread 0x7fff5a50a700 (LWP 26657)]\n[New Thread 0x7fff59d09700 (LWP 26656)]\n[New Thread 0x7fff59508700 (LWP 26655)]\n[New Thread 0x7fff58d07700 (LWP 26662)]\n[New Thread 0x7fff58506700 (LWP 26659)]\n[New Thread 0x7fff57504700 (LWP 26660)]\n[New Thread 0x7fff57d05700 (LWP 26661)]\n[New Thread 0x7fff56d03700 (LWP 26658)]\n[New Thread 0x7fff56502700 (LWP 26663)]\n\nThread 48 \"tutorials_examp\" received signal SIGFPE, Arithmetic exception.\n[Switching to Thread 0x7fff99fff700 (LWP 26539)]\n0x000055555605c320 in tensorflow::functor::CastFunctor&lt;Eigen::GpuDevice, float, int&gt;::operator()(Eigen::GpuDevice const&amp;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 1, 1, long&gt;, 16&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;int const, 1, 1, long&gt;, 16&gt;) ()\n</code></pre>\n<p><strong>last 20 lines from running outside gdb</strong></p>\n<pre><code>000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000146 x = [0.894449 -0.447170] y = [1.789007 -0.894449]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000008/000001 lambda = 2.000073 x = [0.894438 -0.447192] y = [1.788931 -0.894438]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000003/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000037 x = [0.894433 -0.447203] y = [1.788893 -0.894433]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n</code></pre>\n<p><strong>Environment</strong><br>\nUbuntu 16.04<br>\nGTX 1080<br>\nCUDA 8.0 RC + Patch<br>\ncudnn 5.1<br>\nbazel 0.3.1<br>\ngcc 5.4.0</p>", "body_text": "I am getting the same error as well, although it only occurs about of the third of the time. The rest of the time the program exits normally, but shows nan for many of the output values.\ngdb - on failure\n(gdb) r --use_gpu\nStarting program: /home/reale/.cache/bazel/_bazel_reale/b77777b530a2fcea5d78d328048dc62b/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\n[New Thread 0x7fffe1a36700 (LWP 26488)]\n[New Thread 0x7fffe1235700 (LWP 26489)]\n[New Thread 0x7fffe0a34700 (LWP 26490)]\n[New Thread 0x7fffe0233700 (LWP 26491)]\n[New Thread 0x7fffdfa32700 (LWP 26492)]\n[New Thread 0x7fffdf231700 (LWP 26493)]\n[New Thread 0x7fffdea30700 (LWP 26494)]\n[New Thread 0x7fffde22f700 (LWP 26495)]\n[New Thread 0x7fffdda2e700 (LWP 26496)]\n[New Thread 0x7fffdd22d700 (LWP 26497)]\n[New Thread 0x7fffdca2c700 (LWP 26498)]\n[New Thread 0x7fffcffff700 (LWP 26499)]\n[New Thread 0x7fffcf7fe700 (LWP 26500)]\n[New Thread 0x7fffceffd700 (LWP 26501)]\n[New Thread 0x7fffce7fc700 (LWP 26502)]\n[New Thread 0x7fffcdffb700 (LWP 26503)]\n[New Thread 0x7fffcd7fa700 (LWP 26504)]\n[New Thread 0x7fffccff9700 (LWP 26505)]\n[New Thread 0x7fffc7fff700 (LWP 26511)]\n[New Thread 0x7fffc77fe700 (LWP 26512)]\n[New Thread 0x7fffc6ffd700 (LWP 26513)]\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.54GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n[New Thread 0x7fffc67fc700 (LWP 26514)]\n[New Thread 0x7fffc5ffb700 (LWP 26515)]\n[New Thread 0x7fffc57fa700 (LWP 26516)]\n[New Thread 0x7fffc4ff9700 (LWP 26517)]\n[New Thread 0x7fffbffff700 (LWP 26518)]\n[New Thread 0x7fffbf7fe700 (LWP 26519)]\n[New Thread 0x7fffbd7fa700 (LWP 26523)]\n[New Thread 0x7fffbdffb700 (LWP 26521)]\n[New Thread 0x7fffbcff9700 (LWP 26524)]\n[New Thread 0x7fffbeffd700 (LWP 26520)]\n[New Thread 0x7fffb7fff700 (LWP 26525)]\n[New Thread 0x7fffbe7fc700 (LWP 26522)]\n[New Thread 0x7fffb67fc700 (LWP 26526)]\n[New Thread 0x7fffb5ffb700 (LWP 26528)]\n[New Thread 0x7fffb4ff9700 (LWP 26527)]\n[New Thread 0x7fffb77fe700 (LWP 26531)]\n[New Thread 0x7fffb6ffd700 (LWP 26529)]\n[New Thread 0x7fffb57fa700 (LWP 26530)]\n[New Thread 0x7fffaffff700 (LWP 26533)]\n[New Thread 0x7fffaf7fe700 (LWP 26532)]\n[New Thread 0x7fffaeffd700 (LWP 26534)]\n[New Thread 0x7fffae7fc700 (LWP 26535)]\n[New Thread 0x7fffadffb700 (LWP 26536)]\n[New Thread 0x7fffad7fa700 (LWP 26537)]\n[New Thread 0x7fffacff9700 (LWP 26538)]\n[New Thread 0x7fff99fff700 (LWP 26539)]\n[New Thread 0x7fff997fe700 (LWP 26540)]\n[New Thread 0x7fff98ffd700 (LWP 26541)]\n[New Thread 0x7fff937fe700 (LWP 26542)]\n[New Thread 0x7fff927fc700 (LWP 26546)]\n[New Thread 0x7fff84d5f700 (LWP 26549)]\n[New Thread 0x7fff90ff9700 (LWP 26547)]\n[New Thread 0x7fff917fa700 (LWP 26548)]\n[New Thread 0x7fff93fff700 (LWP 26543)]\n[New Thread 0x7fff91ffb700 (LWP 26545)]\n[New Thread 0x7fff83d5d700 (LWP 26551)]\n[New Thread 0x7fff92ffd700 (LWP 26544)]\n[New Thread 0x7fff8455e700 (LWP 26550)]\n[New Thread 0x7fff8355c700 (LWP 26552)]\n[New Thread 0x7fff7ed53700 (LWP 26559)]\n[New Thread 0x7fff7f554700 (LWP 26560)]\n[New Thread 0x7fff82d5b700 (LWP 26553)]\n[New Thread 0x7fff8255a700 (LWP 26554)]\n[New Thread 0x7fff81d59700 (LWP 26557)]\n[New Thread 0x7fff80d57700 (LWP 26555)]\n[New Thread 0x7fff81558700 (LWP 26558)]\n[New Thread 0x7fff80556700 (LWP 26556)]\n[New Thread 0x7fff7fd55700 (LWP 26561)]\n[New Thread 0x7fff7e552700 (LWP 26562)]\n[New Thread 0x7fff7bd4d700 (LWP 26567)]\n[New Thread 0x7fff7a54a700 (LWP 26570)]\n[New Thread 0x7fff7dd51700 (LWP 26563)]\n[New Thread 0x7fff7d550700 (LWP 26564)]\n[New Thread 0x7fff7b54c700 (LWP 26568)]\n[New Thread 0x7fff79d49700 (LWP 26571)]\n[New Thread 0x7fff7cd4f700 (LWP 26565)]\n[New Thread 0x7fff7ad4b700 (LWP 26569)]\n[New Thread 0x7fff7c54e700 (LWP 26566)]\n[New Thread 0x7fff79548700 (LWP 26572)]\n[New Thread 0x7fff75d41700 (LWP 26602)]\n[New Thread 0x7fff78d47700 (LWP 26573)]\n[New Thread 0x7fff78546700 (LWP 26599)]\n[New Thread 0x7fff75540700 (LWP 26600)]\n[New Thread 0x7fff76542700 (LWP 26597)]\n[New Thread 0x7fff77544700 (LWP 26598)]\n[New Thread 0x7fff77d45700 (LWP 26596)]\n[New Thread 0x7fff76d43700 (LWP 26574)]\n[New Thread 0x7fff74d3f700 (LWP 26601)]\n[New Thread 0x7fff73d3d700 (LWP 26604)]\n[New Thread 0x7fff7453e700 (LWP 26603)]\n[New Thread 0x7fff7353c700 (LWP 26605)]\n[New Thread 0x7fff70d37700 (LWP 26606)]\n[New Thread 0x7fff72d3b700 (LWP 26611)]\n[New Thread 0x7fff7253a700 (LWP 26608)]\n[New Thread 0x7fff71d39700 (LWP 26607)]\n[New Thread 0x7fff71538700 (LWP 26609)]\n[New Thread 0x7fff70536700 (LWP 26610)]\n[New Thread 0x7fff6fd35700 (LWP 26612)]\n[New Thread 0x7fff6f534700 (LWP 26613)]\n[New Thread 0x7fff6cd2f700 (LWP 26615)]\n[New Thread 0x7fff6ed33700 (LWP 26618)]\n[New Thread 0x7fff6e532700 (LWP 26617)]\n[New Thread 0x7fff6dd31700 (LWP 26614)]\n[New Thread 0x7fff6d530700 (LWP 26616)]\n[New Thread 0x7fff6c52e700 (LWP 26622)]\n[New Thread 0x7fff6ad2b700 (LWP 26619)]\n[New Thread 0x7fff6bd2d700 (LWP 26621)]\n[New Thread 0x7fff6b52c700 (LWP 26620)]\n[New Thread 0x7fff6a52a700 (LWP 26623)]\n[New Thread 0x7fff69d29700 (LWP 26624)]\n[New Thread 0x7fff69528700 (LWP 26631)]\n[New Thread 0x7fff68526700 (LWP 26628)]\n[New Thread 0x7fff66d23700 (LWP 26629)]\n[New Thread 0x7fff68d27700 (LWP 26625)]\n[New Thread 0x7fff66522700 (LWP 26627)]\n[New Thread 0x7fff65d21700 (LWP 26630)]\n[New Thread 0x7fff67d25700 (LWP 26632)]\n[New Thread 0x7fff67524700 (LWP 26626)]\n[New Thread 0x7fff65520700 (LWP 26633)]\n[New Thread 0x7fff64d1f700 (LWP 26634)]\n[New Thread 0x7fff6451e700 (LWP 26635)]\n[New Thread 0x7fff6351c700 (LWP 26636)]\n[New Thread 0x7fff63d1d700 (LWP 26637)]\n[New Thread 0x7fff62d1b700 (LWP 26638)]\n[New Thread 0x7fff6251a700 (LWP 26642)]\n[New Thread 0x7fff61d19700 (LWP 26641)]\n[New Thread 0x7fff61518700 (LWP 26639)]\n[New Thread 0x7fff60d17700 (LWP 26640)]\n[New Thread 0x7fff60516700 (LWP 26643)]\n[New Thread 0x7fff5d510700 (LWP 26652)]\n[New Thread 0x7fff5fd15700 (LWP 26644)]\n[New Thread 0x7fff5dd11700 (LWP 26648)]\n[New Thread 0x7fff5cd0f700 (LWP 26650)]\n[New Thread 0x7fff5f514700 (LWP 26645)]\n[New Thread 0x7fff5ed13700 (LWP 26646)]\n[New Thread 0x7fff5bd0d700 (LWP 26651)]\n[New Thread 0x7fff5c50e700 (LWP 26649)]\n[New Thread 0x7fff5e512700 (LWP 26647)]\n[New Thread 0x7fff5b50c700 (LWP 26653)]\n[New Thread 0x7fff5ad0b700 (LWP 26654)]\n[New Thread 0x7fff5a50a700 (LWP 26657)]\n[New Thread 0x7fff59d09700 (LWP 26656)]\n[New Thread 0x7fff59508700 (LWP 26655)]\n[New Thread 0x7fff58d07700 (LWP 26662)]\n[New Thread 0x7fff58506700 (LWP 26659)]\n[New Thread 0x7fff57504700 (LWP 26660)]\n[New Thread 0x7fff57d05700 (LWP 26661)]\n[New Thread 0x7fff56d03700 (LWP 26658)]\n[New Thread 0x7fff56502700 (LWP 26663)]\n\nThread 48 \"tutorials_examp\" received signal SIGFPE, Arithmetic exception.\n[Switching to Thread 0x7fff99fff700 (LWP 26539)]\n0x000055555605c320 in tensorflow::functor::CastFunctor<Eigen::GpuDevice, float, int>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16>) ()\n\nlast 20 lines from running outside gdb\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000146 x = [0.894449 -0.447170] y = [1.789007 -0.894449]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000008/000001 lambda = 2.000073 x = [0.894438 -0.447192] y = [1.788931 -0.894438]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000003/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000037 x = [0.894433 -0.447203] y = [1.788893 -0.894433]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n\nEnvironment\nUbuntu 16.04\nGTX 1080\nCUDA 8.0 RC + Patch\ncudnn 5.1\nbazel 0.3.1\ngcc 5.4.0", "body": "I am getting the same error as well, although it only occurs about of the third of the time. The rest of the time the program exits normally, but shows nan for many of the output values.\n\n**gdb - on failure**\n\n```\n(gdb) r --use_gpu\nStarting program: /home/reale/.cache/bazel/_bazel_reale/b77777b530a2fcea5d78d328048dc62b/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\n[New Thread 0x7fffe1a36700 (LWP 26488)]\n[New Thread 0x7fffe1235700 (LWP 26489)]\n[New Thread 0x7fffe0a34700 (LWP 26490)]\n[New Thread 0x7fffe0233700 (LWP 26491)]\n[New Thread 0x7fffdfa32700 (LWP 26492)]\n[New Thread 0x7fffdf231700 (LWP 26493)]\n[New Thread 0x7fffdea30700 (LWP 26494)]\n[New Thread 0x7fffde22f700 (LWP 26495)]\n[New Thread 0x7fffdda2e700 (LWP 26496)]\n[New Thread 0x7fffdd22d700 (LWP 26497)]\n[New Thread 0x7fffdca2c700 (LWP 26498)]\n[New Thread 0x7fffcffff700 (LWP 26499)]\n[New Thread 0x7fffcf7fe700 (LWP 26500)]\n[New Thread 0x7fffceffd700 (LWP 26501)]\n[New Thread 0x7fffce7fc700 (LWP 26502)]\n[New Thread 0x7fffcdffb700 (LWP 26503)]\n[New Thread 0x7fffcd7fa700 (LWP 26504)]\n[New Thread 0x7fffccff9700 (LWP 26505)]\n[New Thread 0x7fffc7fff700 (LWP 26511)]\n[New Thread 0x7fffc77fe700 (LWP 26512)]\n[New Thread 0x7fffc6ffd700 (LWP 26513)]\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.54GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n[New Thread 0x7fffc67fc700 (LWP 26514)]\n[New Thread 0x7fffc5ffb700 (LWP 26515)]\n[New Thread 0x7fffc57fa700 (LWP 26516)]\n[New Thread 0x7fffc4ff9700 (LWP 26517)]\n[New Thread 0x7fffbffff700 (LWP 26518)]\n[New Thread 0x7fffbf7fe700 (LWP 26519)]\n[New Thread 0x7fffbd7fa700 (LWP 26523)]\n[New Thread 0x7fffbdffb700 (LWP 26521)]\n[New Thread 0x7fffbcff9700 (LWP 26524)]\n[New Thread 0x7fffbeffd700 (LWP 26520)]\n[New Thread 0x7fffb7fff700 (LWP 26525)]\n[New Thread 0x7fffbe7fc700 (LWP 26522)]\n[New Thread 0x7fffb67fc700 (LWP 26526)]\n[New Thread 0x7fffb5ffb700 (LWP 26528)]\n[New Thread 0x7fffb4ff9700 (LWP 26527)]\n[New Thread 0x7fffb77fe700 (LWP 26531)]\n[New Thread 0x7fffb6ffd700 (LWP 26529)]\n[New Thread 0x7fffb57fa700 (LWP 26530)]\n[New Thread 0x7fffaffff700 (LWP 26533)]\n[New Thread 0x7fffaf7fe700 (LWP 26532)]\n[New Thread 0x7fffaeffd700 (LWP 26534)]\n[New Thread 0x7fffae7fc700 (LWP 26535)]\n[New Thread 0x7fffadffb700 (LWP 26536)]\n[New Thread 0x7fffad7fa700 (LWP 26537)]\n[New Thread 0x7fffacff9700 (LWP 26538)]\n[New Thread 0x7fff99fff700 (LWP 26539)]\n[New Thread 0x7fff997fe700 (LWP 26540)]\n[New Thread 0x7fff98ffd700 (LWP 26541)]\n[New Thread 0x7fff937fe700 (LWP 26542)]\n[New Thread 0x7fff927fc700 (LWP 26546)]\n[New Thread 0x7fff84d5f700 (LWP 26549)]\n[New Thread 0x7fff90ff9700 (LWP 26547)]\n[New Thread 0x7fff917fa700 (LWP 26548)]\n[New Thread 0x7fff93fff700 (LWP 26543)]\n[New Thread 0x7fff91ffb700 (LWP 26545)]\n[New Thread 0x7fff83d5d700 (LWP 26551)]\n[New Thread 0x7fff92ffd700 (LWP 26544)]\n[New Thread 0x7fff8455e700 (LWP 26550)]\n[New Thread 0x7fff8355c700 (LWP 26552)]\n[New Thread 0x7fff7ed53700 (LWP 26559)]\n[New Thread 0x7fff7f554700 (LWP 26560)]\n[New Thread 0x7fff82d5b700 (LWP 26553)]\n[New Thread 0x7fff8255a700 (LWP 26554)]\n[New Thread 0x7fff81d59700 (LWP 26557)]\n[New Thread 0x7fff80d57700 (LWP 26555)]\n[New Thread 0x7fff81558700 (LWP 26558)]\n[New Thread 0x7fff80556700 (LWP 26556)]\n[New Thread 0x7fff7fd55700 (LWP 26561)]\n[New Thread 0x7fff7e552700 (LWP 26562)]\n[New Thread 0x7fff7bd4d700 (LWP 26567)]\n[New Thread 0x7fff7a54a700 (LWP 26570)]\n[New Thread 0x7fff7dd51700 (LWP 26563)]\n[New Thread 0x7fff7d550700 (LWP 26564)]\n[New Thread 0x7fff7b54c700 (LWP 26568)]\n[New Thread 0x7fff79d49700 (LWP 26571)]\n[New Thread 0x7fff7cd4f700 (LWP 26565)]\n[New Thread 0x7fff7ad4b700 (LWP 26569)]\n[New Thread 0x7fff7c54e700 (LWP 26566)]\n[New Thread 0x7fff79548700 (LWP 26572)]\n[New Thread 0x7fff75d41700 (LWP 26602)]\n[New Thread 0x7fff78d47700 (LWP 26573)]\n[New Thread 0x7fff78546700 (LWP 26599)]\n[New Thread 0x7fff75540700 (LWP 26600)]\n[New Thread 0x7fff76542700 (LWP 26597)]\n[New Thread 0x7fff77544700 (LWP 26598)]\n[New Thread 0x7fff77d45700 (LWP 26596)]\n[New Thread 0x7fff76d43700 (LWP 26574)]\n[New Thread 0x7fff74d3f700 (LWP 26601)]\n[New Thread 0x7fff73d3d700 (LWP 26604)]\n[New Thread 0x7fff7453e700 (LWP 26603)]\n[New Thread 0x7fff7353c700 (LWP 26605)]\n[New Thread 0x7fff70d37700 (LWP 26606)]\n[New Thread 0x7fff72d3b700 (LWP 26611)]\n[New Thread 0x7fff7253a700 (LWP 26608)]\n[New Thread 0x7fff71d39700 (LWP 26607)]\n[New Thread 0x7fff71538700 (LWP 26609)]\n[New Thread 0x7fff70536700 (LWP 26610)]\n[New Thread 0x7fff6fd35700 (LWP 26612)]\n[New Thread 0x7fff6f534700 (LWP 26613)]\n[New Thread 0x7fff6cd2f700 (LWP 26615)]\n[New Thread 0x7fff6ed33700 (LWP 26618)]\n[New Thread 0x7fff6e532700 (LWP 26617)]\n[New Thread 0x7fff6dd31700 (LWP 26614)]\n[New Thread 0x7fff6d530700 (LWP 26616)]\n[New Thread 0x7fff6c52e700 (LWP 26622)]\n[New Thread 0x7fff6ad2b700 (LWP 26619)]\n[New Thread 0x7fff6bd2d700 (LWP 26621)]\n[New Thread 0x7fff6b52c700 (LWP 26620)]\n[New Thread 0x7fff6a52a700 (LWP 26623)]\n[New Thread 0x7fff69d29700 (LWP 26624)]\n[New Thread 0x7fff69528700 (LWP 26631)]\n[New Thread 0x7fff68526700 (LWP 26628)]\n[New Thread 0x7fff66d23700 (LWP 26629)]\n[New Thread 0x7fff68d27700 (LWP 26625)]\n[New Thread 0x7fff66522700 (LWP 26627)]\n[New Thread 0x7fff65d21700 (LWP 26630)]\n[New Thread 0x7fff67d25700 (LWP 26632)]\n[New Thread 0x7fff67524700 (LWP 26626)]\n[New Thread 0x7fff65520700 (LWP 26633)]\n[New Thread 0x7fff64d1f700 (LWP 26634)]\n[New Thread 0x7fff6451e700 (LWP 26635)]\n[New Thread 0x7fff6351c700 (LWP 26636)]\n[New Thread 0x7fff63d1d700 (LWP 26637)]\n[New Thread 0x7fff62d1b700 (LWP 26638)]\n[New Thread 0x7fff6251a700 (LWP 26642)]\n[New Thread 0x7fff61d19700 (LWP 26641)]\n[New Thread 0x7fff61518700 (LWP 26639)]\n[New Thread 0x7fff60d17700 (LWP 26640)]\n[New Thread 0x7fff60516700 (LWP 26643)]\n[New Thread 0x7fff5d510700 (LWP 26652)]\n[New Thread 0x7fff5fd15700 (LWP 26644)]\n[New Thread 0x7fff5dd11700 (LWP 26648)]\n[New Thread 0x7fff5cd0f700 (LWP 26650)]\n[New Thread 0x7fff5f514700 (LWP 26645)]\n[New Thread 0x7fff5ed13700 (LWP 26646)]\n[New Thread 0x7fff5bd0d700 (LWP 26651)]\n[New Thread 0x7fff5c50e700 (LWP 26649)]\n[New Thread 0x7fff5e512700 (LWP 26647)]\n[New Thread 0x7fff5b50c700 (LWP 26653)]\n[New Thread 0x7fff5ad0b700 (LWP 26654)]\n[New Thread 0x7fff5a50a700 (LWP 26657)]\n[New Thread 0x7fff59d09700 (LWP 26656)]\n[New Thread 0x7fff59508700 (LWP 26655)]\n[New Thread 0x7fff58d07700 (LWP 26662)]\n[New Thread 0x7fff58506700 (LWP 26659)]\n[New Thread 0x7fff57504700 (LWP 26660)]\n[New Thread 0x7fff57d05700 (LWP 26661)]\n[New Thread 0x7fff56d03700 (LWP 26658)]\n[New Thread 0x7fff56502700 (LWP 26663)]\n\nThread 48 \"tutorials_examp\" received signal SIGFPE, Arithmetic exception.\n[Switching to Thread 0x7fff99fff700 (LWP 26539)]\n0x000055555605c320 in tensorflow::functor::CastFunctor<Eigen::GpuDevice, float, int>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16>) ()\n```\n\n**last 20 lines from running outside gdb**\n\n```\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000146 x = [0.894449 -0.447170] y = [1.789007 -0.894449]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000008/000001 lambda = 2.000073 x = [0.894438 -0.447192] y = [1.788931 -0.894438]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000003/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000005/000008 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000008/000001 lambda = 2.000037 x = [0.894433 -0.447203] y = [1.788893 -0.894433]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000009/000002 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n000007/000004 lambda =      nan x = [     nan      nan] y = [     nan      nan]\n```\n\n**Environment**\nUbuntu 16.04\nGTX 1080\nCUDA 8.0 RC + Patch\ncudnn 5.1\nbazel 0.3.1\ngcc 5.4.0\n"}