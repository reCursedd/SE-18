{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/367154317", "html_url": "https://github.com/tensorflow/tensorflow/issues/16561#issuecomment-367154317", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16561", "id": 367154317, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzE1NDMxNw==", "user": {"login": "santoshchilkunda", "id": 24641339, "node_id": "MDQ6VXNlcjI0NjQxMzM5", "avatar_url": "https://avatars2.githubusercontent.com/u/24641339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/santoshchilkunda", "html_url": "https://github.com/santoshchilkunda", "followers_url": "https://api.github.com/users/santoshchilkunda/followers", "following_url": "https://api.github.com/users/santoshchilkunda/following{/other_user}", "gists_url": "https://api.github.com/users/santoshchilkunda/gists{/gist_id}", "starred_url": "https://api.github.com/users/santoshchilkunda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/santoshchilkunda/subscriptions", "organizations_url": "https://api.github.com/users/santoshchilkunda/orgs", "repos_url": "https://api.github.com/users/santoshchilkunda/repos", "events_url": "https://api.github.com/users/santoshchilkunda/events{/privacy}", "received_events_url": "https://api.github.com/users/santoshchilkunda/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-20T23:13:15Z", "updated_at": "2018-02-20T23:13:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a><br>\nThanks for looking into this.</p>\n<p>I am trying to read/parse the model, convert it to our internal format, and then run inference on it.</p>\n<p>As a workaround (to not being able to parse tflite), I set the output_format while running toco tool to TENSORFLOW_GRAPHDEF (i.e. both input and output formats are TENSORFLOW_GRAPHDEF). And then parse the generated protobuf.</p>\n<p>However, I see that protobuf is \"less\" optimized compared to tflite</p>\n<p>Following is the log when output_format is TENSORFLOW_GRAPHDEF:<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: <strong>141 operators, 260 arrays</strong> (0 quantized)<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 141 operators, 260 arrays (0 quantized)<br>\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).</p>\n<p>Following is the log when output_format is set to TFLITE:<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: <strong>84 operators, 203 arrays</strong> (0 quantized)<br>\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 84 operators, 203 arrays (0 quantized)<br>\nI tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 4014080 bytes, theoretical optimal value: 4014080 bytes.<br>\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).</p>\n<p>The number of operators after graph transformation is different (141 v/s 84) while the estimated count of arithmetic ops is same (3.01265 billion).<br>\nFrom a performance perspective, I am not completely sure if this means both the output formats are same or not.</p>", "body_text": "@aselle\nThanks for looking into this.\nI am trying to read/parse the model, convert it to our internal format, and then run inference on it.\nAs a workaround (to not being able to parse tflite), I set the output_format while running toco tool to TENSORFLOW_GRAPHDEF (i.e. both input and output formats are TENSORFLOW_GRAPHDEF). And then parse the generated protobuf.\nHowever, I see that protobuf is \"less\" optimized compared to tflite\nFollowing is the log when output_format is TENSORFLOW_GRAPHDEF:\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 141 operators, 260 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 141 operators, 260 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).\nFollowing is the log when output_format is set to TFLITE:\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 84 operators, 203 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 84 operators, 203 arrays (0 quantized)\nI tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 4014080 bytes, theoretical optimal value: 4014080 bytes.\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).\nThe number of operators after graph transformation is different (141 v/s 84) while the estimated count of arithmetic ops is same (3.01265 billion).\nFrom a performance perspective, I am not completely sure if this means both the output formats are same or not.", "body": "@aselle \r\nThanks for looking into this.\r\n\r\nI am trying to read/parse the model, convert it to our internal format, and then run inference on it.\r\n\r\nAs a workaround (to not being able to parse tflite), I set the output_format while running toco tool to TENSORFLOW_GRAPHDEF (i.e. both input and output formats are TENSORFLOW_GRAPHDEF). And then parse the generated protobuf.\r\n\r\nHowever, I see that protobuf is \"less\" optimized compared to tflite\r\n\r\nFollowing is the log when output_format is TENSORFLOW_GRAPHDEF:\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: **141 operators, 260 arrays** (0 quantized)\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 141 operators, 260 arrays (0 quantized)\r\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).\r\n\r\nFollowing is the log when output_format is set to TFLITE:\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 773 operators, 1072 arrays (0 quantized)\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: **84 operators, 203 arrays** (0 quantized)\r\nI tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 84 operators, 203 arrays (0 quantized)\r\nI tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 4014080 bytes, theoretical optimal value: 4014080 bytes.\r\nI tensorflow/contrib/lite/toco/toco_tooling.cc:273] Estimated count of arithmetic ops: 3.01265 billion (note that a multiply-add is counted as 2 ops).\r\n\r\nThe number of operators after graph transformation is different (141 v/s 84) while the estimated count of arithmetic ops is same (3.01265 billion).\r\nFrom a performance perspective, I am not completely sure if this means both the output formats are same or not.\r\n"}