{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305862180", "html_url": "https://github.com/tensorflow/tensorflow/issues/10256#issuecomment-305862180", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10256", "id": 305862180, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTg2MjE4MA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-02T17:41:41Z", "updated_at": "2017-06-02T17:41:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think the way <code>tf.train.string_input_producer()</code> is implemented with background threads and queue runners makes it tricky to avoid this happening. One thing we've been working on recently (and released in TensorFlow 1.2) is a new <code>Dataset</code> API that lets you do similar things without having to manage the threads. Here's what your program would look like with the new API:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ndata_dir <span class=\"pl-k\">=</span> <span class=\"pl-sr\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">\"</span>C:<span class=\"pl-cce\">\\.</span><span class=\"pl-c1\">..</span><span class=\"pl-pds\">\"</span></span>\nfilenames <span class=\"pl-k\">=</span> [os.path.join(data_dir, f) <span class=\"pl-k\">for</span> f <span class=\"pl-k\">in</span> os.listdir(data_dir)]\ndataset <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(tf.constant(filenames))\niterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\nnext_element <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(filenames)):\n        <span class=\"pl-c1\">print</span>(next_element.eval())</pre></div>\n<p>Note that there would no longer be any need to start queue runners, and the program should exit without errors.</p>", "body_text": "I think the way tf.train.string_input_producer() is implemented with background threads and queue runners makes it tricky to avoid this happening. One thing we've been working on recently (and released in TensorFlow 1.2) is a new Dataset API that lets you do similar things without having to manage the threads. Here's what your program would look like with the new API:\nimport os\nimport tensorflow as tf\n\ndata_dir = r\"C:\\...\"\nfilenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(filenames))\niterator = dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\n\nwith tf.Session() as sess:\n    for _ in range(len(filenames)):\n        print(next_element.eval())\nNote that there would no longer be any need to start queue runners, and the program should exit without errors.", "body": "I think the way `tf.train.string_input_producer()` is implemented with background threads and queue runners makes it tricky to avoid this happening. One thing we've been working on recently (and released in TensorFlow 1.2) is a new `Dataset` API that lets you do similar things without having to manage the threads. Here's what your program would look like with the new API:\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndata_dir = r\"C:\\...\"\r\nfilenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(filenames))\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    for _ in range(len(filenames)):\r\n        print(next_element.eval())\r\n```\r\n\r\nNote that there would no longer be any need to start queue runners, and the program should exit without errors."}