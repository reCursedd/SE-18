{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18195", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18195/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18195/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18195/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18195", "id": 310730673, "node_id": "MDU6SXNzdWUzMTA3MzA2NzM=", "number": 18195, "title": "Saving frozen model to tflite error", "user": {"login": "flankechen", "id": 4598153, "node_id": "MDQ6VXNlcjQ1OTgxNTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/4598153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flankechen", "html_url": "https://github.com/flankechen", "followers_url": "https://api.github.com/users/flankechen/followers", "following_url": "https://api.github.com/users/flankechen/following{/other_user}", "gists_url": "https://api.github.com/users/flankechen/gists{/gist_id}", "starred_url": "https://api.github.com/users/flankechen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flankechen/subscriptions", "organizations_url": "https://api.github.com/users/flankechen/orgs", "repos_url": "https://api.github.com/users/flankechen/repos", "events_url": "https://api.github.com/users/flankechen/events{/privacy}", "received_events_url": "https://api.github.com/users/flankechen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2018-04-03T07:52:49Z", "updated_at": "2018-07-16T08:33:40Z", "closed_at": "2018-07-16T08:33:40Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes, I write own model define, loss and training codes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary, pip install</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4.0</li>\n<li><strong>Python version</strong>:  2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.10.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 4.9.4</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 1060</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have train some customized model with tensorflow and trying to make it a tensorflow lite model for mobile apps. I success in freezing the model and viewing it in tensorboard. I get error when I trying to save it to a tensorflow lite file.</p>\n<p>my model defins like:</p>\n<pre><code>`def P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n    #define common param\n    with slim.arg_scope([slim.conv2d],\n                        activation_fn=prelu,\n                        weights_initializer=slim.xavier_initializer(),\n                        biases_initializer=tf.zeros_initializer(),\n                        weights_regularizer=slim.l2_regularizer(0.0005), \n                        padding='valid'):\n        print inputs.get_shape()\n        net = slim.conv2d(inputs, 28, 3, stride=1,scope='conv1')\n......\n        conv4_1 = slim.conv2d(net,num_outputs=2,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.softmax)\n        #conv4_1 = slim.conv2d(net,num_outputs=1,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.sigmoid)\n\n        print conv4_1.get_shape()\n        #batch*H*W*4\n        bbox_pred = slim.conv2d(net,num_outputs=4,kernel_size=[1,1],stride=1,scope='conv4_2',activation_fn=None)\n        print bbox_pred.get_shape()`\n</code></pre>\n<p>where conv4_1 and conv4_2 is the output layer.</p>\n<p>I freeze the model with:</p>\n<p><code>freeze_graph.freeze_graph('out_put_model/model.pb', '', False, model_path, 'Squeeze,Squeeze_1', '', '', 'out_put_model/frozen_model.pb', '', '')</code></p>\n<p>I use tensorboard to view the graph and even try to read them back and forward. it produces same result as reading from checkpoint.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4598153/38235205-d847d230-3752-11e8-98b4-8b9b235c517a.png\"><img src=\"https://user-images.githubusercontent.com/4598153/38235205-d847d230-3752-11e8-98b4-8b9b235c517a.png\" alt=\"screenshot from 2018-04-03 11 34 54\" style=\"max-width:100%;\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4598153/38235214-dc606a26-3752-11e8-926e-7193e1174e47.png\"><img src=\"https://user-images.githubusercontent.com/4598153/38235214-dc606a26-3752-11e8-926e-7193e1174e47.png\" alt=\"screenshot from 2018-04-03 11 23 06\" style=\"max-width:100%;\"></a></p>\n<p>Squeeze and Squeeze_1 is the output nodes. image_height, image_width, input_image is input nodes. all of the input nodes is not fixed shape, and resized in the graph.</p>\n<p>code of input placeholder like:</p>\n<pre><code>with graph.as_default():\n            #define tensor and op in graph(-1,1)\n            self.image_op = tf.placeholder(tf.float32, name='input_image')\n            self.width_op = tf.placeholder(tf.int32, name='image_width')\n            self.height_op = tf.placeholder(tf.int32, name='image_height')\n            image_reshape = tf.reshape(self.image_op, [1, self.height_op, self.width_op, 3])\n            #self.cls_prob batch*2\n            #self.bbox_pred batch*4\n            #construct model here\n            #self.cls_prob, self.bbox_pred = net_factory(image_reshape, training=False)\n            #contains landmark\n            self.cls_prob, self.bbox_pred, _ = net_factory(image_reshape, training=False)\n</code></pre>\n<p>I find the tensorflow 1.4.0 don't have tf lite module and checkout tensorflow master branch from github. and run bazel toco for a tflite model.</p>\n<p><code> bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --   --input_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb'    --output_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite'    --inference_type=FLOAT   --input_shape=None,None,None   --input_array=image_height,image_width,input_image   --output_array=Squeeze,Squeeze_1  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --dump_graphviz=/tmp</code></p>\n<p>but I got this error:</p>\n<pre><code>INFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\nINFO: Found 1 target...\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\n  bazel-bin/tensorflow/contrib/lite/toco/toco\nINFO: Elapsed time: 0.288s, Critical Path: 0.00s\nINFO: Build completed successfully, 1 total action\n\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb' '--output_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite' '--inference_type=FLOAT' '--input_shape=None,None,None' '--input_array=image_height,image_width,input_image' '--output_array=Squeeze,Squeeze_1' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--dump_graphviz=/tmp'\nERROR: Non-zero return code '1' from command: Process exited with status 1\n</code></pre>\n<p>what's the problem? is the input_array, input_shape, output_array parameter right?<br>\nThanks and any suggestion is welcome.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I write own model define, loss and training codes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\nTensorFlow installed from (source or binary): binary, pip install\nTensorFlow version (use command below): 1.4.0\nPython version:  2.7\nBazel version (if compiling from source): 0.10.0\nGCC/Compiler version (if compiling from source): 4.9.4\nCUDA/cuDNN version: 8.0\nGPU model and memory: GeForce GTX 1060\nExact command to reproduce:\n\nDescribe the problem\nI have train some customized model with tensorflow and trying to make it a tensorflow lite model for mobile apps. I success in freezing the model and viewing it in tensorboard. I get error when I trying to save it to a tensorflow lite file.\nmy model defins like:\n`def P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n    #define common param\n    with slim.arg_scope([slim.conv2d],\n                        activation_fn=prelu,\n                        weights_initializer=slim.xavier_initializer(),\n                        biases_initializer=tf.zeros_initializer(),\n                        weights_regularizer=slim.l2_regularizer(0.0005), \n                        padding='valid'):\n        print inputs.get_shape()\n        net = slim.conv2d(inputs, 28, 3, stride=1,scope='conv1')\n......\n        conv4_1 = slim.conv2d(net,num_outputs=2,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.softmax)\n        #conv4_1 = slim.conv2d(net,num_outputs=1,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.sigmoid)\n\n        print conv4_1.get_shape()\n        #batch*H*W*4\n        bbox_pred = slim.conv2d(net,num_outputs=4,kernel_size=[1,1],stride=1,scope='conv4_2',activation_fn=None)\n        print bbox_pred.get_shape()`\n\nwhere conv4_1 and conv4_2 is the output layer.\nI freeze the model with:\nfreeze_graph.freeze_graph('out_put_model/model.pb', '', False, model_path, 'Squeeze,Squeeze_1', '', '', 'out_put_model/frozen_model.pb', '', '')\nI use tensorboard to view the graph and even try to read them back and forward. it produces same result as reading from checkpoint.\n\n\nSqueeze and Squeeze_1 is the output nodes. image_height, image_width, input_image is input nodes. all of the input nodes is not fixed shape, and resized in the graph.\ncode of input placeholder like:\nwith graph.as_default():\n            #define tensor and op in graph(-1,1)\n            self.image_op = tf.placeholder(tf.float32, name='input_image')\n            self.width_op = tf.placeholder(tf.int32, name='image_width')\n            self.height_op = tf.placeholder(tf.int32, name='image_height')\n            image_reshape = tf.reshape(self.image_op, [1, self.height_op, self.width_op, 3])\n            #self.cls_prob batch*2\n            #self.bbox_pred batch*4\n            #construct model here\n            #self.cls_prob, self.bbox_pred = net_factory(image_reshape, training=False)\n            #contains landmark\n            self.cls_prob, self.bbox_pred, _ = net_factory(image_reshape, training=False)\n\nI find the tensorflow 1.4.0 don't have tf lite module and checkout tensorflow master branch from github. and run bazel toco for a tflite model.\n bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --   --input_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb'    --output_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite'    --inference_type=FLOAT   --input_shape=None,None,None   --input_array=image_height,image_width,input_image   --output_array=Squeeze,Squeeze_1  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --dump_graphviz=/tmp\nbut I got this error:\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\nINFO: Found 1 target...\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\n  bazel-bin/tensorflow/contrib/lite/toco/toco\nINFO: Elapsed time: 0.288s, Critical Path: 0.00s\nINFO: Build completed successfully, 1 total action\n\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb' '--output_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite' '--inference_type=FLOAT' '--input_shape=None,None,None' '--input_array=image_height,image_width,input_image' '--output_array=Squeeze,Squeeze_1' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--dump_graphviz=/tmp'\nERROR: Non-zero return code '1' from command: Process exited with status 1\n\nwhat's the problem? is the input_array, input_shape, output_array parameter right?\nThanks and any suggestion is welcome.", "body": "------------------------\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, I write own model define, loss and training codes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: binary, pip install\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.9.4\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce GTX 1060\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI have train some customized model with tensorflow and trying to make it a tensorflow lite model for mobile apps. I success in freezing the model and viewing it in tensorboard. I get error when I trying to save it to a tensorflow lite file.\r\n\r\nmy model defins like: \r\n\r\n```\r\n`def P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\r\n    #define common param\r\n    with slim.arg_scope([slim.conv2d],\r\n                        activation_fn=prelu,\r\n                        weights_initializer=slim.xavier_initializer(),\r\n                        biases_initializer=tf.zeros_initializer(),\r\n                        weights_regularizer=slim.l2_regularizer(0.0005), \r\n                        padding='valid'):\r\n        print inputs.get_shape()\r\n        net = slim.conv2d(inputs, 28, 3, stride=1,scope='conv1')\r\n......\r\n        conv4_1 = slim.conv2d(net,num_outputs=2,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.softmax)\r\n        #conv4_1 = slim.conv2d(net,num_outputs=1,kernel_size=[1,1],stride=1,scope='conv4_1',activation_fn=tf.nn.sigmoid)\r\n\r\n        print conv4_1.get_shape()\r\n        #batch*H*W*4\r\n        bbox_pred = slim.conv2d(net,num_outputs=4,kernel_size=[1,1],stride=1,scope='conv4_2',activation_fn=None)\r\n        print bbox_pred.get_shape()`\r\n```\r\n\r\nwhere conv4_1 and conv4_2 is the output layer.\r\n\r\nI freeze the model with:\r\n\r\n`freeze_graph.freeze_graph('out_put_model/model.pb', '', False, model_path, 'Squeeze,Squeeze_1', '', '', 'out_put_model/frozen_model.pb', '', '')`\r\n\r\nI use tensorboard to view the graph and even try to read them back and forward. it produces same result as reading from checkpoint.\r\n\r\n![screenshot from 2018-04-03 11 34 54](https://user-images.githubusercontent.com/4598153/38235205-d847d230-3752-11e8-98b4-8b9b235c517a.png)\r\n\r\n![screenshot from 2018-04-03 11 23 06](https://user-images.githubusercontent.com/4598153/38235214-dc606a26-3752-11e8-926e-7193e1174e47.png)\r\n\r\nSqueeze and Squeeze_1 is the output nodes. image_height, image_width, input_image is input nodes. all of the input nodes is not fixed shape, and resized in the graph.\r\n\r\ncode of input placeholder like:\r\n\r\n```\r\nwith graph.as_default():\r\n            #define tensor and op in graph(-1,1)\r\n            self.image_op = tf.placeholder(tf.float32, name='input_image')\r\n            self.width_op = tf.placeholder(tf.int32, name='image_width')\r\n            self.height_op = tf.placeholder(tf.int32, name='image_height')\r\n            image_reshape = tf.reshape(self.image_op, [1, self.height_op, self.width_op, 3])\r\n            #self.cls_prob batch*2\r\n            #self.bbox_pred batch*4\r\n            #construct model here\r\n            #self.cls_prob, self.bbox_pred = net_factory(image_reshape, training=False)\r\n            #contains landmark\r\n            self.cls_prob, self.bbox_pred, _ = net_factory(image_reshape, training=False)\r\n```\r\n\r\n\r\nI find the tensorflow 1.4.0 don't have tf lite module and checkout tensorflow master branch from github. and run bazel toco for a tflite model.\r\n\r\n` bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --   --input_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb'    --output_file='/home/sen/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite'    --inference_type=FLOAT   --input_shape=None,None,None   --input_array=image_height,image_width,input_image   --output_array=Squeeze,Squeeze_1  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --dump_graphviz=/tmp`\r\n\r\n\r\nbut I got this error:\r\n```\r\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 0.288s, Critical Path: 0.00s\r\nINFO: Build completed successfully, 1 total action\r\n\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/frozen_model.pb' '--output_file=/home/sensetime/mtcnn_cat/MTCNN-Tensorflow/test/out_put_model/pnet.tflite' '--inference_type=FLOAT' '--input_shape=None,None,None' '--input_array=image_height,image_width,input_image' '--output_array=Squeeze,Squeeze_1' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--dump_graphviz=/tmp'\r\nERROR: Non-zero return code '1' from command: Process exited with status 1\r\n```\r\n\r\nwhat's the problem? is the input_array, input_shape, output_array parameter right?\r\nThanks and any suggestion is welcome.\r\n\r\n\r\n\r\n\r\n"}