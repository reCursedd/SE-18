{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412148205", "html_url": "https://github.com/tensorflow/tensorflow/issues/21455#issuecomment-412148205", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21455", "id": 412148205, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjE0ODIwNQ==", "user": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-10T17:17:45Z", "updated_at": "2018-08-10T17:17:45Z", "author_association": "MEMBER", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=42184662\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/neuencer\">@neuencer</a> for the report. We are actively working on sequence feature columns, and it would be great to get more detail about your use-case as well.</p>\n<p>For the immediate term, the issue seems to be that sequence feature columns currently expect SparseTensors as inputs. (This matches the expected output if you are parsing your features from TFRecords.) For the above example, it works if you change just the first line and make <code>x</code> a SparseTensor:</p>\n<pre><code>x = tf.SparseTensor(\n    indices=[[0, 0]], values=tf.placeholder(tf.int32, [1], name='x_holder'),\n    dense_shape=[1, 1])\ncolumn = tf.feature_column.indicator_column(tf.contrib.feature_column.sequence_categorical_column_with_identity('x', 3))\ninput_layer, sequence_length = tf.contrib.feature_column.sequence_input_layer({'x': x}, [column])\n\nwith tf.Session() as sess:\n  print(sess.run(input_layer, feed_dict={'x_holder:0': [2]}))\n\n&gt;&gt;&gt; [[[ 0.  0.  1.]]]\n</code></pre>\n<p>For the short term, you can perhaps feed the expect input in as SparseTensors. But I understand that may seem unnatural-- can you tell us a little bit more about what your input data looks like, and how you want it to feed in to the sequence feature columns?</p>", "body_text": "Thanks @neuencer for the report. We are actively working on sequence feature columns, and it would be great to get more detail about your use-case as well.\nFor the immediate term, the issue seems to be that sequence feature columns currently expect SparseTensors as inputs. (This matches the expected output if you are parsing your features from TFRecords.) For the above example, it works if you change just the first line and make x a SparseTensor:\nx = tf.SparseTensor(\n    indices=[[0, 0]], values=tf.placeholder(tf.int32, [1], name='x_holder'),\n    dense_shape=[1, 1])\ncolumn = tf.feature_column.indicator_column(tf.contrib.feature_column.sequence_categorical_column_with_identity('x', 3))\ninput_layer, sequence_length = tf.contrib.feature_column.sequence_input_layer({'x': x}, [column])\n\nwith tf.Session() as sess:\n  print(sess.run(input_layer, feed_dict={'x_holder:0': [2]}))\n\n>>> [[[ 0.  0.  1.]]]\n\nFor the short term, you can perhaps feed the expect input in as SparseTensors. But I understand that may seem unnatural-- can you tell us a little bit more about what your input data looks like, and how you want it to feed in to the sequence feature columns?", "body": "Thanks @neuencer for the report. We are actively working on sequence feature columns, and it would be great to get more detail about your use-case as well.\r\n\r\nFor the immediate term, the issue seems to be that sequence feature columns currently expect SparseTensors as inputs. (This matches the expected output if you are parsing your features from TFRecords.) For the above example, it works if you change just the first line and make `x` a SparseTensor:\r\n\r\n```\r\nx = tf.SparseTensor(\r\n    indices=[[0, 0]], values=tf.placeholder(tf.int32, [1], name='x_holder'),\r\n    dense_shape=[1, 1])\r\ncolumn = tf.feature_column.indicator_column(tf.contrib.feature_column.sequence_categorical_column_with_identity('x', 3))\r\ninput_layer, sequence_length = tf.contrib.feature_column.sequence_input_layer({'x': x}, [column])\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(input_layer, feed_dict={'x_holder:0': [2]}))\r\n\r\n>>> [[[ 0.  0.  1.]]]\r\n```\r\n\r\nFor the short term, you can perhaps feed the expect input in as SparseTensors. But I understand that may seem unnatural-- can you tell us a little bit more about what your input data looks like, and how you want it to feed in to the sequence feature columns?"}