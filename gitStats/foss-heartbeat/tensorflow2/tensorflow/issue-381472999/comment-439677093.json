{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439677093", "html_url": "https://github.com/tensorflow/tensorflow/pull/23790#issuecomment-439677093", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23790", "id": 439677093, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTY3NzA5Mw==", "user": {"login": "chengmengli06", "id": 31561586, "node_id": "MDQ6VXNlcjMxNTYxNTg2", "avatar_url": "https://avatars2.githubusercontent.com/u/31561586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chengmengli06", "html_url": "https://github.com/chengmengli06", "followers_url": "https://api.github.com/users/chengmengli06/followers", "following_url": "https://api.github.com/users/chengmengli06/following{/other_user}", "gists_url": "https://api.github.com/users/chengmengli06/gists{/gist_id}", "starred_url": "https://api.github.com/users/chengmengli06/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chengmengli06/subscriptions", "organizations_url": "https://api.github.com/users/chengmengli06/orgs", "repos_url": "https://api.github.com/users/chengmengli06/repos", "events_url": "https://api.github.com/users/chengmengli06/events{/privacy}", "received_events_url": "https://api.github.com/users/chengmengli06/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-18T08:48:44Z", "updated_at": "2018-11-18T08:53:19Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3731025\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/allenlavoie\">@allenlavoie</a><br>\nThis modification does not affect tf.Saver(sharded=False), the sharded controls whether the model are saved in one file or multiple files. I test with both sharded = True and sharded = False, both settings work with the current modification.<br>\nAs for extra communication, shared file system also involves lots of communication. Moreover, pull parameters from sever is necessary for every iteration.<br>\nI experiment with two PS, the saving time does not increase significantly(13s vs 12s). Experiment with nvidia GPU M40, RFCN model, Resnet-50 backbone, pascal voc datasets, batch_size = 1.<br>\n** Two PS after modification:<br>\n[INFO] 2018-11-18 16:32:52,305 tf_logging.py:115 : Done running local_init_op.<br>\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.<br>\n[INFO] 2018-11-18 16:33:05,211 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.<br>\n** One PS before modification:<br>\n[INFO] 2018-10-23 11:57:29,569 tf_logging.py:115 : Done running local_init_op.<br>\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.<br>\n[INFO] 2018-10-23 11:57:41,622 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.</p>", "body_text": "@allenlavoie\nThis modification does not affect tf.Saver(sharded=False), the sharded controls whether the model are saved in one file or multiple files. I test with both sharded = True and sharded = False, both settings work with the current modification.\nAs for extra communication, shared file system also involves lots of communication. Moreover, pull parameters from sever is necessary for every iteration.\nI experiment with two PS, the saving time does not increase significantly(13s vs 12s). Experiment with nvidia GPU M40, RFCN model, Resnet-50 backbone, pascal voc datasets, batch_size = 1.\n** Two PS after modification:\n[INFO] 2018-11-18 16:32:52,305 tf_logging.py:115 : Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.\n[INFO] 2018-11-18 16:33:05,211 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.\n** One PS before modification:\n[INFO] 2018-10-23 11:57:29,569 tf_logging.py:115 : Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.\n[INFO] 2018-10-23 11:57:41,622 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.", "body": "@allenlavoie\r\n    This modification does not affect tf.Saver(sharded=False), the sharded controls whether the model are saved in one file or multiple files. I test with both sharded = True and sharded = False, both settings work with the current modification. \r\n    As for extra communication, shared file system also involves lots of communication. Moreover, pull parameters from sever is necessary for every iteration. \r\n    I experiment with two PS, the saving time does not increase significantly(13s vs 12s). Experiment with nvidia GPU M40, RFCN model, Resnet-50 backbone, pascal voc datasets, batch_size = 1.\r\n** Two PS after modification: \r\n[INFO] 2018-11-18 16:32:52,305 tf_logging.py:115 : Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.\r\n[INFO] 2018-11-18 16:33:05,211 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.\r\n** One PS before modification:\r\n[INFO] 2018-10-23 11:57:29,569 tf_logging.py:115 : Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.\r\n[INFO] 2018-10-23 11:57:41,622 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt."}