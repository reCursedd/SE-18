{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/368479005", "html_url": "https://github.com/tensorflow/tensorflow/issues/16374#issuecomment-368479005", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16374", "id": 368479005, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODQ3OTAwNQ==", "user": {"login": "SanthoshMKunthe", "id": 16397061, "node_id": "MDQ6VXNlcjE2Mzk3MDYx", "avatar_url": "https://avatars0.githubusercontent.com/u/16397061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SanthoshMKunthe", "html_url": "https://github.com/SanthoshMKunthe", "followers_url": "https://api.github.com/users/SanthoshMKunthe/followers", "following_url": "https://api.github.com/users/SanthoshMKunthe/following{/other_user}", "gists_url": "https://api.github.com/users/SanthoshMKunthe/gists{/gist_id}", "starred_url": "https://api.github.com/users/SanthoshMKunthe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SanthoshMKunthe/subscriptions", "organizations_url": "https://api.github.com/users/SanthoshMKunthe/orgs", "repos_url": "https://api.github.com/users/SanthoshMKunthe/repos", "events_url": "https://api.github.com/users/SanthoshMKunthe/events{/privacy}", "received_events_url": "https://api.github.com/users/SanthoshMKunthe/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-26T12:03:03Z", "updated_at": "2018-02-26T12:03:03Z", "author_association": "NONE", "body_html": "<p>Am geetting TOCO_CONVERT error. . .Kindlyhelp. . .</p>\n<p><strong>AttributeError: module 'tensorflow.contrib.lite.python.lite' has no attribute 'toco_convert'</strong><br>\n<em>see last two  lines for error causing code</em><br>\n//=================================<br>\nimport tensorflow  as tf<br>\nimport pandas as pd<br>\nimport numpy as np<br>\nimport seaborn as sns<br>\nimport matplotlib as lib</p>\n<p>from tensorflow.python.tools import freeze_graph<br>\nfrom tensorflow.python.tools import optimize_for_inference_lib</p>\n<p>print(tf.<strong>version</strong>)<br>\ndata=pd.read_csv('C:\\ml\\irisInAndroid\\iris.data',names=['f1','f2','f3','f4','f5'])</p>\n<p>s=np.asarray([1,0,0])<br>\nve=np.asarray([0,1,0])<br>\nvi=np.asarray([0,0,1])</p>\n<p>data['f5']=data['f5'].map({'Iris-setosa':s,'Iris-versicolor':ve,'Iris-virginica':vi})</p>\n<p>data=data.iloc[np.random.permutation(len(data))]</p>\n<p>print(data)</p>\n<p>data=data.reset_index(drop=True)</p>\n<p>trainFeats=data.ix[0:105,['f1','f2','f3','f4']]<br>\ntemp=data['f5']<br>\ntrainlabels=temp[0:106]</p>\n<p>y=tf.placeholder(tf.float32,shape=[None, 3])</p>\n<p>m=tf.Variable(tf.zeros([4,3]))<br>\nx=tf.placeholder(tf.float32,shape=[None,4],name=\"Input\")<br>\nc=tf.Variable(tf.zeros([3]))</p>\n<p>mxc = tf.nn.softmax((tf.matmul(x, m) + c) ,name=\"output\")</p>\n<p>loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(mxc), reduction_indices=[1]))</p>\n<p>train_step = tf.train.AdamOptimizer(0.01).minimize(loss)</p>\n<p>sess = tf.InteractiveSession()<br>\ninit = tf.initialize_all_variables()<br>\nsess.run(init)</p>\n<p>epoch=2000<br>\nfor step in range(epoch):<br>\nprint(sess.run([train_step,loss], feed_dict={x: trainFeats, y:[t for t in trainlabels.as_matrix()]}))</p>\n<p>testData=data.ix[130,['f1','f2','f3','f4']]<br>\ntestDataInFrormat=testData.reshape(1,4)<br>\nprint(sess.run(tf.argmax(mxc),feed_dict={x:testDataInFrormat}))</p>\n<p>tf.train.write_graph(sess.graph_def,'pbtxtFiles/','savegraph.pbtxt',as_text=True)</p>\n<p>tf.train.Saver().save(sess,'pbtxtFiles/model.ckpt')</p>\n<p>MODEL_NAME = 'iris'<br>\ninput_graph_path = 'pbtxtFiles/savegraph.pbtxt'<br>\ncheckpoint_path = 'pbtxtFiles/model.ckpt'<br>\ninput_saver_def_path = \"\"<br>\ninput_binary = False<br>\noutput_node_names = \"output\"<br>\nrestore_op_name = \"save/restore_all\"<br>\nfilename_tensor_name = \"save/Const:0\"<br>\noutput_frozen_graph_name = 'pbtxtFiles/frozen_model_'+MODEL_NAME+'.pb'<br>\noutput_optimized_graph_name = 'pbtxtFiles/optimized_inference_model_'+MODEL_NAME+'.pb'<br>\nclear_devices = True</p>\n<p>freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,<br>\ninput_binary, checkpoint_path, output_node_names,<br>\nrestore_op_name, filename_tensor_name,<br>\noutput_frozen_graph_name, clear_devices, \"\")</p>\n<p>output_graph_def = optimize_for_inference_lib.optimize_for_inference(<br>\nsess.graph_def,<br>\n[\"Input\"], # an array of the input node(s)<br>\n[\"output\"], # an array of output nodes<br>\ntf.float32.as_datatype_enum)</p>\n<p>tflite_model=tf.contrib.lite.toco_convert(sess.graph_def,[x],[mxc])<br>\nopen(\"wow.tflite\",\"w\").write(tflite_model)</p>\n<p>@Azureum <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3603839\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ushnish\">@ushnish</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28546240\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tensorflowbutler\">@tensorflowbutler</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=986732\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatianashp\">@tatianashp</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16542\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/d0k\">@d0k</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12026254\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/e-lin\">@e-lin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10869430\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fabriciojoc\">@fabriciojoc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10446514\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gaohuazuo\">@gaohuazuo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6428529\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/HaebinShin\">@HaebinShin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3298308\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/iamaziz\">@iamaziz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2585500\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/JacksonKontny\">@JacksonKontny</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31663267\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/k-w-w\">@k-w-w</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=550498\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lahwran\">@lahwran</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8291084\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/m-colombo\">@m-colombo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3139632\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/n3011\">@n3011</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604464\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/oahziur\">@oahziur</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7090837\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/paderijk\">@paderijk</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5977817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/qbx2\">@qbx2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9589037\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rachellim\">@rachellim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1284535\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/saeta\">@saeta</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5397898\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/t13m\">@t13m</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3142598\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ucdmkt\">@ucdmkt</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=65011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vade\">@vade</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=18343189\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wagonhelm\">@wagonhelm</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16719562\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiaoyaozhuzi\">@xiaoyaozhuzi</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5975590\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yacoder\">@yacoder</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2390222\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zackchase\">@zackchase</a><br>\nam getting .pb abd .ckpt</p>", "body_text": "Am geetting TOCO_CONVERT error. . .Kindlyhelp. . .\nAttributeError: module 'tensorflow.contrib.lite.python.lite' has no attribute 'toco_convert'\nsee last two  lines for error causing code\n//=================================\nimport tensorflow  as tf\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as lib\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\nprint(tf.version)\ndata=pd.read_csv('C:\\ml\\irisInAndroid\\iris.data',names=['f1','f2','f3','f4','f5'])\ns=np.asarray([1,0,0])\nve=np.asarray([0,1,0])\nvi=np.asarray([0,0,1])\ndata['f5']=data['f5'].map({'Iris-setosa':s,'Iris-versicolor':ve,'Iris-virginica':vi})\ndata=data.iloc[np.random.permutation(len(data))]\nprint(data)\ndata=data.reset_index(drop=True)\ntrainFeats=data.ix[0:105,['f1','f2','f3','f4']]\ntemp=data['f5']\ntrainlabels=temp[0:106]\ny=tf.placeholder(tf.float32,shape=[None, 3])\nm=tf.Variable(tf.zeros([4,3]))\nx=tf.placeholder(tf.float32,shape=[None,4],name=\"Input\")\nc=tf.Variable(tf.zeros([3]))\nmxc = tf.nn.softmax((tf.matmul(x, m) + c) ,name=\"output\")\nloss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(mxc), reduction_indices=[1]))\ntrain_step = tf.train.AdamOptimizer(0.01).minimize(loss)\nsess = tf.InteractiveSession()\ninit = tf.initialize_all_variables()\nsess.run(init)\nepoch=2000\nfor step in range(epoch):\nprint(sess.run([train_step,loss], feed_dict={x: trainFeats, y:[t for t in trainlabels.as_matrix()]}))\ntestData=data.ix[130,['f1','f2','f3','f4']]\ntestDataInFrormat=testData.reshape(1,4)\nprint(sess.run(tf.argmax(mxc),feed_dict={x:testDataInFrormat}))\ntf.train.write_graph(sess.graph_def,'pbtxtFiles/','savegraph.pbtxt',as_text=True)\ntf.train.Saver().save(sess,'pbtxtFiles/model.ckpt')\nMODEL_NAME = 'iris'\ninput_graph_path = 'pbtxtFiles/savegraph.pbtxt'\ncheckpoint_path = 'pbtxtFiles/model.ckpt'\ninput_saver_def_path = \"\"\ninput_binary = False\noutput_node_names = \"output\"\nrestore_op_name = \"save/restore_all\"\nfilename_tensor_name = \"save/Const:0\"\noutput_frozen_graph_name = 'pbtxtFiles/frozen_model_'+MODEL_NAME+'.pb'\noutput_optimized_graph_name = 'pbtxtFiles/optimized_inference_model_'+MODEL_NAME+'.pb'\nclear_devices = True\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\ninput_binary, checkpoint_path, output_node_names,\nrestore_op_name, filename_tensor_name,\noutput_frozen_graph_name, clear_devices, \"\")\noutput_graph_def = optimize_for_inference_lib.optimize_for_inference(\nsess.graph_def,\n[\"Input\"], # an array of the input node(s)\n[\"output\"], # an array of output nodes\ntf.float32.as_datatype_enum)\ntflite_model=tf.contrib.lite.toco_convert(sess.graph_def,[x],[mxc])\nopen(\"wow.tflite\",\"w\").write(tflite_model)\n@Azureum @ushnish @aselle @tensorflowbutler @tatianashp @d0k @e-lin @fabriciojoc @gaohuazuo @HaebinShin @iamaziz @JacksonKontny @k-w-w @lahwran @m-colombo @n3011 @oahziur @paderijk @qbx2 @rachellim @saeta @t13m @ucdmkt @vade @wagonhelm @xiaoyaozhuzi @yacoder @zackchase\nam getting .pb abd .ckpt", "body": "Am geetting TOCO_CONVERT error. . .Kindlyhelp. . .\r\n\r\n**AttributeError: module 'tensorflow.contrib.lite.python.lite' has no attribute 'toco_convert'**\r\n_see last two  lines for error causing code_\r\n//=================================\r\nimport tensorflow  as tf\r\nimport pandas as pd\r\nimport numpy as np\r\nimport seaborn as sns\r\nimport matplotlib as lib\r\n\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\n\r\n\r\nprint(tf.__version__)\r\ndata=pd.read_csv('C:\\ml\\irisInAndroid\\iris.data',names=['f1','f2','f3','f4','f5'])\r\n\r\ns=np.asarray([1,0,0])\r\nve=np.asarray([0,1,0])\r\nvi=np.asarray([0,0,1])\r\n\r\ndata['f5']=data['f5'].map({'Iris-setosa':s,'Iris-versicolor':ve,'Iris-virginica':vi})\r\n\r\n\r\ndata=data.iloc[np.random.permutation(len(data))]\r\n\r\nprint(data)\r\n\r\ndata=data.reset_index(drop=True)\r\n\r\ntrainFeats=data.ix[0:105,['f1','f2','f3','f4']]\r\ntemp=data['f5']\r\ntrainlabels=temp[0:106]\r\n\r\ny=tf.placeholder(tf.float32,shape=[None, 3])\r\n\r\nm=tf.Variable(tf.zeros([4,3]))\r\nx=tf.placeholder(tf.float32,shape=[None,4],name=\"Input\")\r\nc=tf.Variable(tf.zeros([3]))\r\n\r\nmxc = tf.nn.softmax((tf.matmul(x, m) + c) ,name=\"output\")\r\n\r\nloss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(mxc), reduction_indices=[1]))\r\n\r\ntrain_step = tf.train.AdamOptimizer(0.01).minimize(loss)\r\n\r\nsess = tf.InteractiveSession()\r\ninit = tf.initialize_all_variables()\r\nsess.run(init)\r\n\r\n\r\n\r\n\r\nepoch=2000\r\nfor step in range(epoch):\r\n  print(sess.run([train_step,loss], feed_dict={x: trainFeats, y:[t for t in trainlabels.as_matrix()]}))\r\n\r\ntestData=data.ix[130,['f1','f2','f3','f4']]\r\ntestDataInFrormat=testData.reshape(1,4)\r\nprint(sess.run(tf.argmax(mxc),feed_dict={x:testDataInFrormat}))\r\n\r\ntf.train.write_graph(sess.graph_def,'pbtxtFiles/','savegraph.pbtxt',as_text=True)\r\n\r\ntf.train.Saver().save(sess,'pbtxtFiles/model.ckpt')\r\n\r\nMODEL_NAME = 'iris'\r\ninput_graph_path = 'pbtxtFiles/savegraph.pbtxt'\r\ncheckpoint_path = 'pbtxtFiles/model.ckpt'\r\ninput_saver_def_path = \"\"\r\ninput_binary = False\r\noutput_node_names = \"output\"\r\nrestore_op_name = \"save/restore_all\"\r\nfilename_tensor_name = \"save/Const:0\"\r\noutput_frozen_graph_name = 'pbtxtFiles/frozen_model_'+MODEL_NAME+'.pb'\r\noutput_optimized_graph_name = 'pbtxtFiles/optimized_inference_model_'+MODEL_NAME+'.pb'\r\nclear_devices = True\r\n\r\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                          input_binary, checkpoint_path, output_node_names,\r\n                          restore_op_name, filename_tensor_name,\r\n                          output_frozen_graph_name, clear_devices, \"\")\r\n\r\n\r\noutput_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n        sess.graph_def,\r\n        [\"Input\"], # an array of the input node(s)\r\n        [\"output\"], # an array of output nodes\r\n        tf.float32.as_datatype_enum)\r\n\r\ntflite_model=tf.contrib.lite.toco_convert(sess.graph_def,[x],[mxc])\r\nopen(\"wow.tflite\",\"w\").write(tflite_model)\r\n\r\n@Azureum @ushnish @aselle @tensorflowbutler @tatianashp @d0k @e-lin @fabriciojoc @gaohuazuo @HaebinShin @iamaziz @JacksonKontny @k-w-w @lahwran @m-colombo @n3011 @oahziur @paderijk @qbx2 @rachellim @saeta @t13m @ucdmkt @vade @wagonhelm @xiaoyaozhuzi @yacoder @zackchase \r\nam getting .pb abd .ckpt"}