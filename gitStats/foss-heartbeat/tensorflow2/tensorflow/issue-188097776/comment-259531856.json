{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259531856", "html_url": "https://github.com/tensorflow/tensorflow/issues/5480#issuecomment-259531856", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5480", "id": 259531856, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTUzMTg1Ng==", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-09T21:29:00Z", "updated_at": "2016-11-09T21:29:00Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3645581\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/flx42\">@flx42</a> Use <strong>virtual</strong> machine Docker to isolate <strong>physical</strong> hardware GPU... ...</p>\n<p>Well, this is an interesting idea. I feel this mechanism is not very humanize. It is a detour. Tensor flow GPU version is build on CUDA. I think it is CUDA framework to decide how GPUs should be used, based on pass in parameter, like device ID assignment. I am not sure this is CUDA's issue or tensor flow's issue. Isolation should be a very fundamental job need to do. Is there any plan to support this natively? I do not know it belongs to whose job, NVidia or Google.</p>", "body_text": "@flx42 Use virtual machine Docker to isolate physical hardware GPU... ...\nWell, this is an interesting idea. I feel this mechanism is not very humanize. It is a detour. Tensor flow GPU version is build on CUDA. I think it is CUDA framework to decide how GPUs should be used, based on pass in parameter, like device ID assignment. I am not sure this is CUDA's issue or tensor flow's issue. Isolation should be a very fundamental job need to do. Is there any plan to support this natively? I do not know it belongs to whose job, NVidia or Google.", "body": "@flx42 Use **virtual** machine Docker to isolate **physical** hardware GPU... ...\n\nWell, this is an interesting idea. I feel this mechanism is not very humanize. It is a detour. Tensor flow GPU version is build on CUDA. I think it is CUDA framework to decide how GPUs should be used, based on pass in parameter, like device ID assignment. I am not sure this is CUDA's issue or tensor flow's issue. Isolation should be a very fundamental job need to do. Is there any plan to support this natively? I do not know it belongs to whose job, NVidia or Google.\n"}