{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259476694", "html_url": "https://github.com/tensorflow/tensorflow/issues/5480#issuecomment-259476694", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5480", "id": 259476694, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTQ3NjY5NA==", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-09T17:43:38Z", "updated_at": "2016-11-09T17:45:36Z", "author_association": "NONE", "body_html": "<p>I just use \"Nvidia X Server Settings\" tool to monitor GPU memory usage. I only start one app but all GPU memory on 4 GPUs are occupied. Is this make sense? If start only one small app which needs less than 12GB GPU memory, but tensor flow occupy all 4 GPUs, then <strong>tf.device('/gpu:0')</strong> become useless. This is very inefficient usage.</p>", "body_text": "I just use \"Nvidia X Server Settings\" tool to monitor GPU memory usage. I only start one app but all GPU memory on 4 GPUs are occupied. Is this make sense? If start only one small app which needs less than 12GB GPU memory, but tensor flow occupy all 4 GPUs, then tf.device('/gpu:0') become useless. This is very inefficient usage.", "body": "I just use \"Nvidia X Server Settings\" tool to monitor GPU memory usage. I only start one app but all GPU memory on 4 GPUs are occupied. Is this make sense? If start only one small app which needs less than 12GB GPU memory, but tensor flow occupy all 4 GPUs, then **tf.device('/gpu:0')** become useless. This is very inefficient usage. \n"}