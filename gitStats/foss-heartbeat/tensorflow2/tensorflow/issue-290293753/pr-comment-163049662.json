{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163049662", "pull_request_review_id": 90592158, "id": 163049662, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzA0OTY2Mg==", "diff_hunk": "@@ -0,0 +1,120 @@\n+\"\"\" Recurrent Neural Network.\n+A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n+This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n+Links:\n+    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n+    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n+\"\"\"\n+\n+from __future__ import print_function\n+\n+import tensorflow as tf\n+from tensorflow.contrib import rnn\n+\n+# Import MNIST data\n+from tensorflow.examples.tutorials.mnist import input_data\n+mnist = input_data.read_data_sets(\"/tmp/mnist_data/\", one_hot=True)\n+\n+'''\n+To classify images using a recurrent neural network, we consider every image\n+row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n+handle 28 sequences of 28 steps for every sample.\n+'''\n+\n+# Training Parameters\n+learning_rate = 0.001\n+training_steps = 10000\n+batch_size = 128\n+display_step = 200\n+\n+# Network Parameters\n+num_input = 28 # MNIST data input (img shape: 28*28)\n+num_step = 28 # step number\n+num_hidden_units = 128 # hidden layer num of features\n+num_classes = 10 # MNIST total classes (0-9 digits)\n+\n+# tf Graph input\n+X = tf.placeholder(\"float\", [None, num_step, num_input])\n+Y = tf.placeholder(\"float\", [None, num_classes])\n+\n+# Define weights\n+weights = {\n+    # (28, 128)\n+    'in': tf.Variable(tf.random_normal([num_input, num_hidden_units])),\n+    # (128, 10)\n+    'out': tf.Variable(tf.random_normal([num_hidden_units, num_classes]))\n+}\n+biases = {\n+    # (128, )\n+    'in': tf.Variable(tf.constant(0.1, shape=[num_hidden_units, ])),\n+    # (10, )\n+    'out': tf.Variable(tf.constant(0.1, shape=[num_classes, ]))\n+}\n+\n+\n+def RNN(x, weights, biases):\n+\n+    # Prepare data shape to match `rnn` function requirements\n+    # Current data input shape: (batch_size, num_step, n_input)\n+    # Required shape: 'num_step' tensors list of shape (batch_size, n_input)\n+    x = tf.reshape(x, [-1, num_input])\n+\n+    # Hidden layer ==> (128 batch, 28 steps, 128 hidden)\n+    x_in = tf.matmul(x, weights['in']) + biases['in']\n+    x_in = tf.reshape(x_in, [-1, num_step, num_hidden_units])\n+\n+    # Define a lstm cell with tensorflow\n+    lstm_cell = rnn.BasicLSTMCell(num_hidden_units, forget_bias=1.0, state_is_tuple=True)\n+\n+    # init zero state, lstm cell is consist of twp parts: (c_state, h_state)\n+    init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n+\n+    # Get lstm cell output\n+    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, initial_state=init_state, time_major=False, dtype=tf.float32)\n+\n+    # Linear activation, using rnn inner loop last output\n+    return tf.matmul(states[1], weights['out']) + biases['out']\n+\n+logits = RNN(X, weights, biases)\n+prediction = tf.nn.softmax(logits)\n+\n+# Define loss and optimizer\n+cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n+    logits=logits, labels=Y))\n+train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n+\n+# Evaluate model (with test logits, for dropout to be disabled)\n+correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n+accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n+\n+# Initialize the variables (i.e. assign their default value)\n+init = tf.global_variables_initializer()\n+\n+# Start training\n+with tf.Session() as sess:\n+\n+    # Run the initializer\n+    sess.run(init)\n+\n+    for step in range(1, training_steps+1):", "path": "tensorflow/examples/tutorials/mnist/mnist_rnn.py", "position": null, "original_position": 99, "commit_id": "7481d5f73a8275d24dfe672e39b4daecc2b7d0cd", "original_commit_id": "4adbc69b299ae67edeaccadd6e7e32074782bef4", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "body": "import `xrange` from `six` and use that.", "created_at": "2018-01-22T19:51:25Z", "updated_at": "2018-01-26T04:02:06Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16272#discussion_r163049662", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16272", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163049662"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16272#discussion_r163049662"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16272"}}, "body_html": "<p>import <code>xrange</code> from <code>six</code> and use that.</p>", "body_text": "import xrange from six and use that."}