{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163204517", "pull_request_review_id": 90777098, "id": 163204517, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzIwNDUxNw==", "diff_hunk": "@@ -0,0 +1,120 @@\n+\"\"\" Recurrent Neural Network.\n+A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n+This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n+Links:\n+    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n+    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n+\"\"\"\n+\n+from __future__ import print_function\n+\n+import tensorflow as tf\n+from tensorflow.contrib import rnn\n+\n+# Import MNIST data\n+from tensorflow.examples.tutorials.mnist import input_data\n+mnist = input_data.read_data_sets(\"/tmp/mnist_data/\", one_hot=True)\n+\n+'''\n+To classify images using a recurrent neural network, we consider every image\n+row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n+handle 28 sequences of 28 steps for every sample.\n+'''\n+\n+# Training Parameters\n+learning_rate = 0.001\n+training_steps = 10000\n+batch_size = 128\n+display_step = 200\n+\n+# Network Parameters\n+num_input = 28 # MNIST data input (img shape: 28*28)\n+num_step = 28 # step number\n+num_hidden_units = 128 # hidden layer num of features\n+num_classes = 10 # MNIST total classes (0-9 digits)\n+\n+# tf Graph input\n+X = tf.placeholder(\"float\", [None, num_step, num_input])\n+Y = tf.placeholder(\"float\", [None, num_classes])\n+\n+# Define weights\n+weights = {\n+    # (28, 128)\n+    'in': tf.Variable(tf.random_normal([num_input, num_hidden_units])),\n+    # (128, 10)\n+    'out': tf.Variable(tf.random_normal([num_hidden_units, num_classes]))\n+}\n+biases = {\n+    # (128, )\n+    'in': tf.Variable(tf.constant(0.1, shape=[num_hidden_units, ])),\n+    # (10, )\n+    'out': tf.Variable(tf.constant(0.1, shape=[num_classes, ]))\n+}\n+\n+\n+def RNN(x, weights, biases):\n+\n+    # Prepare data shape to match `rnn` function requirements\n+    # Current data input shape: (batch_size, num_step, n_input)\n+    # Required shape: 'num_step' tensors list of shape (batch_size, n_input)\n+    x = tf.reshape(x, [-1, num_input])\n+\n+    # Hidden layer ==> (128 batch, 28 steps, 128 hidden)\n+    x_in = tf.matmul(x, weights['in']) + biases['in']\n+    x_in = tf.reshape(x_in, [-1, num_step, num_hidden_units])\n+\n+    # Define a lstm cell with tensorflow\n+    lstm_cell = rnn.BasicLSTMCell(num_hidden_units, forget_bias=1.0, state_is_tuple=True)\n+\n+    # init zero state, lstm cell is consist of twp parts: (c_state, h_state)\n+    init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n+\n+    # Get lstm cell output\n+    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, initial_state=init_state, time_major=False, dtype=tf.float32)\n+\n+    # Linear activation, using rnn inner loop last output\n+    return tf.matmul(states[1], weights['out']) + biases['out']\n+\n+logits = RNN(X, weights, biases)\n+prediction = tf.nn.softmax(logits)\n+\n+# Define loss and optimizer\n+cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n+    logits=logits, labels=Y))\n+train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n+\n+# Evaluate model (with test logits, for dropout to be disabled)\n+correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n+accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n+\n+# Initialize the variables (i.e. assign their default value)\n+init = tf.global_variables_initializer()\n+\n+# Start training\n+with tf.Session() as sess:\n+\n+    # Run the initializer\n+    sess.run(init)\n+\n+    for step in range(1, training_steps+1):\n+        batch_x, batch_y = mnist.train.next_batch(batch_size)\n+        # Reshape data to get 28 seq of 28 elements\n+        batch_x = batch_x.reshape((batch_size, num_step, num_input))\n+        # Run optimization op (backprop)\n+        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n+        if step % display_step == 0 or step == 1:\n+            # Calculate batch loss and accuracy\n+            loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x,\n+                                                                 Y: batch_y})\n+            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n+                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n+                  \"{:.3f}\".format(acc))\n+\n+    print(\"Training Finished!\")\n+\n+    # Calculate accuracy for 128 mnist test images\n+    test_len = 128\n+    test_data = mnist.test.images[:test_len].reshape((-1, num_step, num_input))\n+    test_label = mnist.test.labels[:test_len]\n+    print(\"Testing Accuracy:\", \\\n+        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))", "path": "tensorflow/examples/tutorials/mnist/mnist_rnn.py", "position": null, "original_position": 120, "commit_id": "7481d5f73a8275d24dfe672e39b4daecc2b7d0cd", "original_commit_id": "4adbc69b299ae67edeaccadd6e7e32074782bef4", "user": {"login": "imsheridan", "id": 1680977, "node_id": "MDQ6VXNlcjE2ODA5Nzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1680977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/imsheridan", "html_url": "https://github.com/imsheridan", "followers_url": "https://api.github.com/users/imsheridan/followers", "following_url": "https://api.github.com/users/imsheridan/following{/other_user}", "gists_url": "https://api.github.com/users/imsheridan/gists{/gist_id}", "starred_url": "https://api.github.com/users/imsheridan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/imsheridan/subscriptions", "organizations_url": "https://api.github.com/users/imsheridan/orgs", "repos_url": "https://api.github.com/users/imsheridan/repos", "events_url": "https://api.github.com/users/imsheridan/events{/privacy}", "received_events_url": "https://api.github.com/users/imsheridan/received_events", "type": "User", "site_admin": false}, "body": "Thanks, added.", "created_at": "2018-01-23T10:43:45Z", "updated_at": "2018-01-26T04:02:06Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16272#discussion_r163204517", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16272", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163204517"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16272#discussion_r163204517"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16272"}}, "body_html": "<p>Thanks, added.</p>", "body_text": "Thanks, added.", "in_reply_to_id": 163048993}