{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/267047640", "html_url": "https://github.com/tensorflow/tensorflow/issues/6310#issuecomment-267047640", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6310", "id": 267047640, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NzA0NzY0MA==", "user": {"login": "zakizhou", "id": 19201532, "node_id": "MDQ6VXNlcjE5MjAxNTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/19201532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zakizhou", "html_url": "https://github.com/zakizhou", "followers_url": "https://api.github.com/users/zakizhou/followers", "following_url": "https://api.github.com/users/zakizhou/following{/other_user}", "gists_url": "https://api.github.com/users/zakizhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/zakizhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zakizhou/subscriptions", "organizations_url": "https://api.github.com/users/zakizhou/orgs", "repos_url": "https://api.github.com/users/zakizhou/repos", "events_url": "https://api.github.com/users/zakizhou/events{/privacy}", "received_events_url": "https://api.github.com/users/zakizhou/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-14T14:30:11Z", "updated_at": "2016-12-14T14:39:25Z", "author_association": "NONE", "body_html": "<p>From my understanding, you didn't catch how multi-gpus training works, imaging you want to train 10 epochs and you have 2 gpus, and then you manually set <code>num_epochs = 5</code>, both of your gpu will take 5 epochs training cocurrently and that's why your training time can be a half (neglecting network consumption). It's not like what you think about the multi-gpus training that splits a single batch to mini-batch. Back to you problem, a single gpu can only process 20 examples at a time, then you set it 80 so your gpu ran oom. The way to solve your problem is keeping  <code>batch_size = 20</code> and decreasing <code>num_epochs</code>(make sure you write code properly that collects gradients from all gpus to central cpu and do averaging gradients and updating of variables)</p>", "body_text": "From my understanding, you didn't catch how multi-gpus training works, imaging you want to train 10 epochs and you have 2 gpus, and then you manually set num_epochs = 5, both of your gpu will take 5 epochs training cocurrently and that's why your training time can be a half (neglecting network consumption). It's not like what you think about the multi-gpus training that splits a single batch to mini-batch. Back to you problem, a single gpu can only process 20 examples at a time, then you set it 80 so your gpu ran oom. The way to solve your problem is keeping  batch_size = 20 and decreasing num_epochs(make sure you write code properly that collects gradients from all gpus to central cpu and do averaging gradients and updating of variables)", "body": "From my understanding, you didn't catch how multi-gpus training works, imaging you want to train 10 epochs and you have 2 gpus, and then you manually set `num_epochs = 5`, both of your gpu will take 5 epochs training cocurrently and that's why your training time can be a half (neglecting network consumption). It's not like what you think about the multi-gpus training that splits a single batch to mini-batch. Back to you problem, a single gpu can only process 20 examples at a time, then you set it 80 so your gpu ran oom. The way to solve your problem is keeping  `batch_size = 20` and decreasing `num_epochs`(make sure you write code properly that collects gradients from all gpus to central cpu and do averaging gradients and updating of variables)"}