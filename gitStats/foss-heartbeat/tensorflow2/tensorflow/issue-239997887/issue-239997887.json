{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11218", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11218/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11218/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11218/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11218", "id": 239997887, "node_id": "MDU6SXNzdWUyMzk5OTc4ODc=", "number": 11218, "title": "ValueError: Shape (1, 5) must have rank at least 3", "user": {"login": "ruparelmetarya", "id": 29725216, "node_id": "MDQ6VXNlcjI5NzI1MjE2", "avatar_url": "https://avatars1.githubusercontent.com/u/29725216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruparelmetarya", "html_url": "https://github.com/ruparelmetarya", "followers_url": "https://api.github.com/users/ruparelmetarya/followers", "following_url": "https://api.github.com/users/ruparelmetarya/following{/other_user}", "gists_url": "https://api.github.com/users/ruparelmetarya/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruparelmetarya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruparelmetarya/subscriptions", "organizations_url": "https://api.github.com/users/ruparelmetarya/orgs", "repos_url": "https://api.github.com/users/ruparelmetarya/repos", "events_url": "https://api.github.com/users/ruparelmetarya/events{/privacy}", "received_events_url": "https://api.github.com/users/ruparelmetarya/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-07-02T08:53:34Z", "updated_at": "2017-07-02T09:17:29Z", "closed_at": "2017-07-02T09:17:29Z", "author_association": "NONE", "body_html": "<p>CODE I AM TRYING TO RUN :</p>\n<p>from <strong>future</strong> import print_function, division<br>\nimport numpy as np<br>\nimport tensorflow as tf<br>\nimport matplotlib.pyplot as plt</p>\n<p>num_epochs = 100<br>\ntotal_series_length = 50000<br>\ntruncated_backprop_length = 15<br>\nstate_size = 4<br>\nnum_classes = 2<br>\necho_step = 3<br>\nbatch_size = 5<br>\nnum_batches = total_series_length//batch_size//truncated_backprop_length</p>\n<p>def generateData():<br>\nx = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))<br>\ny = np.roll(x, echo_step)<br>\ny[0:echo_step] = 0</p>\n<pre><code>x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\ny = y.reshape((batch_size, -1))\n\nreturn (x, y)\n</code></pre>\n<p>batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])<br>\nbatchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])</p>\n<p>cell_state = tf.placeholder(tf.float32, [batch_size, state_size])<br>\nhidden_state = tf.placeholder(tf.float32, [batch_size, state_size])<br>\ninit_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)</p>\n<p>W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)<br>\nb2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)</p>\n<h1>unstack columns</h1>\n<p>inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)<br>\nlabels_series = tf.unstack(batchY_placeholder, axis=1)</p>\n<h1>Forward passes</h1>\n<p>cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)<br>\nstates_series, current_state = tf.nn.dynamic_rnn(cell, inputs_series, initial_state = init_state)</p>\n<p>logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition<br>\npredictions_series = [tf.nn.softmax(logits) for logits in logits_series]</p>\n<p>losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]<br>\ntotal_loss = tf.reduce_mean(losses)</p>\n<p>train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)</p>\n<p>def plot(loss_list, predictions_series, batchX, batchY):<br>\nplt.subplot(2, 3, 1)<br>\nplt.cla()<br>\nplt.plot(loss_list)</p>\n<pre><code>for batch_series_idx in range(5):\n    one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n    single_output_series = np.array([(1 if out[0] &lt; 0.5 else 0) for out in one_hot_output_series])\n\n    plt.subplot(2, 3, batch_series_idx + 2)\n    plt.cla()\n    plt.axis([0, truncated_backprop_length, 0, 2])\n    left_offset = range(truncated_backprop_length)\n    plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n    plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n    plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n\nplt.draw()\nplt.pause(0.0001)\n</code></pre>\n<p>with tf.Session() as sess:<br>\nsess.run(tf.initialize_all_variables())<br>\nplt.ion()<br>\nplt.figure()<br>\nplt.show()<br>\nloss_list = []</p>\n<pre><code>for epoch_idx in range(num_epochs):\n    x,y = generateData()\n    _current_cell_state = np.zeros((batch_size, state_size))\n    _current_hidden_state = np.zeros((batch_size, state_size))\n\n    print(\"New data, epoch\", epoch_idx)\n\n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * truncated_backprop_length\n        end_idx = start_idx + truncated_backprop_length\n\n        batchX = x[:,start_idx:end_idx]\n        batchY = y[:,start_idx:end_idx]\n\n        _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n            [total_loss, train_step, current_state, predictions_series],\n            feed_dict={\n                batchX_placeholder: batchX,\n                batchY_placeholder: batchY,\n                cell_state: _current_cell_state,\n                hidden_state: _current_hidden_state\n\n            })\n\n        _current_cell_state, _current_hidden_state = _current_state\n\n        loss_list.append(_total_loss)\n\n        if batch_idx%100 == 0:\n            print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n            plot(loss_list, _predictions_series, batchX, batchY)\n</code></pre>\n<p>plt.ioff()<br>\nplt.show()</p>\n<p>But I have the following error<br>\nValueError: Shape (1, 5) must have rank at least 3</p>", "body_text": "CODE I AM TRYING TO RUN :\nfrom future import print_function, division\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nnum_epochs = 100\ntotal_series_length = 50000\ntruncated_backprop_length = 15\nstate_size = 4\nnum_classes = 2\necho_step = 3\nbatch_size = 5\nnum_batches = total_series_length//batch_size//truncated_backprop_length\ndef generateData():\nx = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\ny = np.roll(x, echo_step)\ny[0:echo_step] = 0\nx = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\ny = y.reshape((batch_size, -1))\n\nreturn (x, y)\n\nbatchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\nbatchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\ncell_state = tf.placeholder(tf.float32, [batch_size, state_size])\nhidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\ninit_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\nW2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\nb2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\nunstack columns\ninputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\nlabels_series = tf.unstack(batchY_placeholder, axis=1)\nForward passes\ncell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\nstates_series, current_state = tf.nn.dynamic_rnn(cell, inputs_series, initial_state = init_state)\nlogits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\npredictions_series = [tf.nn.softmax(logits) for logits in logits_series]\nlosses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]\ntotal_loss = tf.reduce_mean(losses)\ntrain_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\ndef plot(loss_list, predictions_series, batchX, batchY):\nplt.subplot(2, 3, 1)\nplt.cla()\nplt.plot(loss_list)\nfor batch_series_idx in range(5):\n    one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n    single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n\n    plt.subplot(2, 3, batch_series_idx + 2)\n    plt.cla()\n    plt.axis([0, truncated_backprop_length, 0, 2])\n    left_offset = range(truncated_backprop_length)\n    plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n    plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n    plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n\nplt.draw()\nplt.pause(0.0001)\n\nwith tf.Session() as sess:\nsess.run(tf.initialize_all_variables())\nplt.ion()\nplt.figure()\nplt.show()\nloss_list = []\nfor epoch_idx in range(num_epochs):\n    x,y = generateData()\n    _current_cell_state = np.zeros((batch_size, state_size))\n    _current_hidden_state = np.zeros((batch_size, state_size))\n\n    print(\"New data, epoch\", epoch_idx)\n\n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * truncated_backprop_length\n        end_idx = start_idx + truncated_backprop_length\n\n        batchX = x[:,start_idx:end_idx]\n        batchY = y[:,start_idx:end_idx]\n\n        _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n            [total_loss, train_step, current_state, predictions_series],\n            feed_dict={\n                batchX_placeholder: batchX,\n                batchY_placeholder: batchY,\n                cell_state: _current_cell_state,\n                hidden_state: _current_hidden_state\n\n            })\n\n        _current_cell_state, _current_hidden_state = _current_state\n\n        loss_list.append(_total_loss)\n\n        if batch_idx%100 == 0:\n            print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n            plot(loss_list, _predictions_series, batchX, batchY)\n\nplt.ioff()\nplt.show()\nBut I have the following error\nValueError: Shape (1, 5) must have rank at least 3", "body": "CODE I AM TRYING TO RUN : \r\n\r\nfrom __future__ import print_function, division\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\nnum_epochs = 100\r\ntotal_series_length = 50000\r\ntruncated_backprop_length = 15\r\nstate_size = 4\r\nnum_classes = 2\r\necho_step = 3\r\nbatch_size = 5\r\nnum_batches = total_series_length//batch_size//truncated_backprop_length\r\n\r\ndef generateData():\r\n    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\r\n    y = np.roll(x, echo_step)\r\n    y[0:echo_step] = 0\r\n\r\n    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\r\n    y = y.reshape((batch_size, -1))\r\n\r\n    return (x, y)\r\n\r\nbatchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\r\nbatchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\r\n\r\ncell_state = tf.placeholder(tf.float32, [batch_size, state_size])\r\nhidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\r\ninit_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\r\n\r\nW2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\r\nb2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\r\n\r\n# unstack columns\r\ninputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\r\nlabels_series = tf.unstack(batchY_placeholder, axis=1)\r\n\r\n# Forward passes\r\ncell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\r\nstates_series, current_state = tf.nn.dynamic_rnn(cell, inputs_series, initial_state = init_state)\r\n\r\nlogits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\r\npredictions_series = [tf.nn.softmax(logits) for logits in logits_series]\r\n\r\nlosses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(logits_series,labels_series)]\r\ntotal_loss = tf.reduce_mean(losses)\r\n\r\ntrain_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\r\n\r\ndef plot(loss_list, predictions_series, batchX, batchY):\r\n    plt.subplot(2, 3, 1)\r\n    plt.cla()\r\n    plt.plot(loss_list)\r\n\r\n    for batch_series_idx in range(5):\r\n        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\r\n        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\r\n\r\n        plt.subplot(2, 3, batch_series_idx + 2)\r\n        plt.cla()\r\n        plt.axis([0, truncated_backprop_length, 0, 2])\r\n        left_offset = range(truncated_backprop_length)\r\n        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\r\n        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\r\n        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\r\n\r\n    plt.draw()\r\n    plt.pause(0.0001)\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.initialize_all_variables())\r\n    plt.ion()\r\n    plt.figure()\r\n    plt.show()\r\n    loss_list = []\r\n\r\n    for epoch_idx in range(num_epochs):\r\n        x,y = generateData()\r\n        _current_cell_state = np.zeros((batch_size, state_size))\r\n        _current_hidden_state = np.zeros((batch_size, state_size))\r\n\r\n        print(\"New data, epoch\", epoch_idx)\r\n\r\n        for batch_idx in range(num_batches):\r\n            start_idx = batch_idx * truncated_backprop_length\r\n            end_idx = start_idx + truncated_backprop_length\r\n\r\n            batchX = x[:,start_idx:end_idx]\r\n            batchY = y[:,start_idx:end_idx]\r\n\r\n            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\r\n                [total_loss, train_step, current_state, predictions_series],\r\n                feed_dict={\r\n                    batchX_placeholder: batchX,\r\n                    batchY_placeholder: batchY,\r\n                    cell_state: _current_cell_state,\r\n                    hidden_state: _current_hidden_state\r\n\r\n                })\r\n\r\n            _current_cell_state, _current_hidden_state = _current_state\r\n\r\n            loss_list.append(_total_loss)\r\n\r\n            if batch_idx%100 == 0:\r\n                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\r\n                plot(loss_list, _predictions_series, batchX, batchY)\r\n\r\nplt.ioff()\r\nplt.show()\r\n\r\n\r\n\r\nBut I have the following error \r\nValueError: Shape (1, 5) must have rank at least 3\r\n"}