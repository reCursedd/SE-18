{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16942", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16942/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16942/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16942/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16942", "id": 296277286, "node_id": "MDU6SXNzdWUyOTYyNzcyODY=", "number": 16942, "title": "wrapping op in while_loop makes it run faster, even with single iteration", "user": {"login": "apisutilis", "id": 2754832, "node_id": "MDQ6VXNlcjI3NTQ4MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2754832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apisutilis", "html_url": "https://github.com/apisutilis", "followers_url": "https://api.github.com/users/apisutilis/followers", "following_url": "https://api.github.com/users/apisutilis/following{/other_user}", "gists_url": "https://api.github.com/users/apisutilis/gists{/gist_id}", "starred_url": "https://api.github.com/users/apisutilis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apisutilis/subscriptions", "organizations_url": "https://api.github.com/users/apisutilis/orgs", "repos_url": "https://api.github.com/users/apisutilis/repos", "events_url": "https://api.github.com/users/apisutilis/events{/privacy}", "received_events_url": "https://api.github.com/users/apisutilis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-02-12T06:28:02Z", "updated_at": "2018-03-18T16:34:03Z", "closed_at": "2018-03-18T16:34:03Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.5.0-0-g37aa430 (1.5.0)</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.9.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.1, CuDNN 7</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 1050, 4042MiB</li>\n<li><strong>Exact command to reproduce</strong>: See below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am working on an object detector. I have one entry point to my code that detects objects in a single image, and another that reads in a batch of images. The batch version uses <code>tf.while_loop</code> to apply the same inference code to each image in the batch. I can't put all the images into a single tensor because they are all likely to be different dimensions, so I am using a <code>TensorArray</code>. The final results work as expected, but the timing behavior is odd.</p>\n<p>The first <code>sess.run</code> call in the loop over the dataset is always slower than the rest, presumably due to caching, memory allocation, etc. However, the first call in the non-batch version is WAY slower than the first call in the batch version. I distilled this down to the minimal examples below. The first version does a dot product in a straightforward way. On my machine, it takes about 13 seconds to run. The second version does the same dot product, but wrapped in a <code>while_loop</code> and writing the result to an intermediate <code>TensorArray</code> and then reading it out again. On my machine, it takes about 4 seconds to run. Presumably, version 2 has to do the same data copying, memory allocation, etc. as version 1, in addition to the overhead of the <code>while_loop</code> and <code>TensorArray</code> calls. So, the timing behavior is unexpected.</p>\n<p>Version 2 can even be modified to compute the same dot product 10 (or more) times, and it will still run faster. This behavior holds even if the loop body is modified to use a random vector every time, so I don't think it is due to caching. It also holds even if <code>parallel_iterations</code> is held to <code>1</code>, so I don't think it is due to parallelism. Is this a bug, or is something else going on under the hood?</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> version 1 (~13 seconds on my machine)</span>\ngraph <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> graph.as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    nums <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">200000000</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    dot_product <span class=\"pl-k\">=</span> tf.reduce_sum((nums<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span>) <span class=\"pl-k\">*</span> (nums<span class=\"pl-k\">-</span><span class=\"pl-c1\">5</span>))\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span>(sess.run(dot_product))</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> version 2 (~4 seconds on my machine)</span>\ngraph <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> graph.as_default(), tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    arr <span class=\"pl-k\">=</span> tf.TensorArray(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    nums <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">200000000</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    i <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>)\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">arr</span>):\n        arr <span class=\"pl-k\">=</span> arr.write(i, tf.reduce_sum((nums<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span>) <span class=\"pl-k\">*</span> (nums<span class=\"pl-k\">-</span><span class=\"pl-c1\">5</span>)))\n        <span class=\"pl-k\">return</span> i<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>, arr\n    i, arr <span class=\"pl-k\">=</span> tf.while_loop(\n        <span class=\"pl-v\">cond</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">x</span>: i <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">1</span>,\n        <span class=\"pl-v\">body</span><span class=\"pl-k\">=</span>body,\n        <span class=\"pl-v\">loop_vars</span><span class=\"pl-k\">=</span>[i, arr],\n        <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    dot_product <span class=\"pl-k\">=</span> arr.read(<span class=\"pl-c1\">0</span>)\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span>(sess.run(dot_product))</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): v1.5.0-0-g37aa430 (1.5.0)\nPython version: 3.5.2\nBazel version (if compiling from source): 0.9.0\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: CUDA 9.1, CuDNN 7\nGPU model and memory: GeForce GTX 1050, 4042MiB\nExact command to reproduce: See below\n\nDescribe the problem\nI am working on an object detector. I have one entry point to my code that detects objects in a single image, and another that reads in a batch of images. The batch version uses tf.while_loop to apply the same inference code to each image in the batch. I can't put all the images into a single tensor because they are all likely to be different dimensions, so I am using a TensorArray. The final results work as expected, but the timing behavior is odd.\nThe first sess.run call in the loop over the dataset is always slower than the rest, presumably due to caching, memory allocation, etc. However, the first call in the non-batch version is WAY slower than the first call in the batch version. I distilled this down to the minimal examples below. The first version does a dot product in a straightforward way. On my machine, it takes about 13 seconds to run. The second version does the same dot product, but wrapped in a while_loop and writing the result to an intermediate TensorArray and then reading it out again. On my machine, it takes about 4 seconds to run. Presumably, version 2 has to do the same data copying, memory allocation, etc. as version 1, in addition to the overhead of the while_loop and TensorArray calls. So, the timing behavior is unexpected.\nVersion 2 can even be modified to compute the same dot product 10 (or more) times, and it will still run faster. This behavior holds even if the loop body is modified to use a random vector every time, so I don't think it is due to caching. It also holds even if parallel_iterations is held to 1, so I don't think it is due to parallelism. Is this a bug, or is something else going on under the hood?\nSource code / logs\n# version 1 (~13 seconds on my machine)\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/gpu:0'):\n    nums = tf.range(200000000, dtype=tf.float32)\n    dot_product = tf.reduce_sum((nums/2) * (nums-5))\nwith tf.Session(graph=graph) as sess:\n    print(sess.run(dot_product))\n# version 2 (~4 seconds on my machine)\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/gpu:0'):\n    arr = tf.TensorArray(size=1, dtype=tf.float32)\n    nums = tf.range(200000000, dtype=tf.float32)\n    i = tf.constant(0)\n    def body(i, arr):\n        arr = arr.write(i, tf.reduce_sum((nums/2) * (nums-5)))\n        return i+1, arr\n    i, arr = tf.while_loop(\n        cond=lambda i, x: i < 1,\n        body=body,\n        loop_vars=[i, arr],\n        parallel_iterations=1)\n    dot_product = arr.read(0)\nwith tf.Session(graph=graph) as sess:\n    print(sess.run(dot_product))", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430 (1.5.0)\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 9.1, CuDNN 7\r\n- **GPU model and memory**: GeForce GTX 1050, 4042MiB\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\n\r\nI am working on an object detector. I have one entry point to my code that detects objects in a single image, and another that reads in a batch of images. The batch version uses `tf.while_loop` to apply the same inference code to each image in the batch. I can't put all the images into a single tensor because they are all likely to be different dimensions, so I am using a `TensorArray`. The final results work as expected, but the timing behavior is odd.\r\n\r\nThe first `sess.run` call in the loop over the dataset is always slower than the rest, presumably due to caching, memory allocation, etc. However, the first call in the non-batch version is WAY slower than the first call in the batch version. I distilled this down to the minimal examples below. The first version does a dot product in a straightforward way. On my machine, it takes about 13 seconds to run. The second version does the same dot product, but wrapped in a `while_loop` and writing the result to an intermediate `TensorArray` and then reading it out again. On my machine, it takes about 4 seconds to run. Presumably, version 2 has to do the same data copying, memory allocation, etc. as version 1, in addition to the overhead of the `while_loop` and `TensorArray` calls. So, the timing behavior is unexpected.\r\n\r\nVersion 2 can even be modified to compute the same dot product 10 (or more) times, and it will still run faster. This behavior holds even if the loop body is modified to use a random vector every time, so I don't think it is due to caching. It also holds even if `parallel_iterations` is held to `1`, so I don't think it is due to parallelism. Is this a bug, or is something else going on under the hood?\r\n\r\n### Source code / logs\r\n\r\n```python\r\n# version 1 (~13 seconds on my machine)\r\ngraph = tf.Graph()\r\nwith graph.as_default(), tf.device('/gpu:0'):\r\n    nums = tf.range(200000000, dtype=tf.float32)\r\n    dot_product = tf.reduce_sum((nums/2) * (nums-5))\r\nwith tf.Session(graph=graph) as sess:\r\n    print(sess.run(dot_product))\r\n```\r\n\r\n```python\r\n# version 2 (~4 seconds on my machine)\r\ngraph = tf.Graph()\r\nwith graph.as_default(), tf.device('/gpu:0'):\r\n    arr = tf.TensorArray(size=1, dtype=tf.float32)\r\n    nums = tf.range(200000000, dtype=tf.float32)\r\n    i = tf.constant(0)\r\n    def body(i, arr):\r\n        arr = arr.write(i, tf.reduce_sum((nums/2) * (nums-5)))\r\n        return i+1, arr\r\n    i, arr = tf.while_loop(\r\n        cond=lambda i, x: i < 1,\r\n        body=body,\r\n        loop_vars=[i, arr],\r\n        parallel_iterations=1)\r\n    dot_product = arr.read(0)\r\nwith tf.Session(graph=graph) as sess:\r\n    print(sess.run(dot_product))\r\n```\r\n"}