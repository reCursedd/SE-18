{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/365683126", "html_url": "https://github.com/tensorflow/tensorflow/issues/16942#issuecomment-365683126", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16942", "id": 365683126, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTY4MzEyNg==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T17:29:40Z", "updated_at": "2018-02-14T17:31:58Z", "author_association": "MEMBER", "body_html": "<p>The first <code>session.run</code> call being slower is almost certainly due to running the constant folder to optimize the graph.  When <code>session.run</code> is called for the first time on a set of feeds/fetches, the constant folder will run and parts of the graph will be replaced with a <code>tf.constant</code> node that has a protobuf containing the constant values.  Potential constants are always evaluated on the CPU device.  (Also, if the resulting value is larger than a certain threshold -- around 10s of MB iirc -- then it is discarded and the graph is left alone).</p>\n<p>It it likely that when the same expression is computed in a loop the constant folder doesn't consider it a candidate.</p>\n<p>In your code snippets above, you only time a single session.run call for each variant...   I would expect constant folding overheads (and many other overheads) to only affect the first execution of each graph.</p>\n<p>If you do a warmup <code>sess.run(dot_product)</code> call, then put a loop around multiple calls of <code>sess.run(dot_product)</code> and evaluate it repeatedly, do you still see the loop version running faster?   If so then this is worth looking into further!</p>\n<p>i.e. something like:</p>\n<pre><code>with tf.Session(graph=graph) as sess:\n   print(sess.run(dot_product))\n   t1 = default_timer()\n   for _ in xrange(10):\n       sess.run(dot_product)\n   print(\"time v1: {}\".format(default_timer() - t1))\n</code></pre>\n<p>(Note that if the size of <code>dot_product</code> was bigger than a scalar then I would also be concerned about repeatedly fetching the result...  you can use <code>session.run(dot_product.op)</code> when benchmarking)</p>", "body_text": "The first session.run call being slower is almost certainly due to running the constant folder to optimize the graph.  When session.run is called for the first time on a set of feeds/fetches, the constant folder will run and parts of the graph will be replaced with a tf.constant node that has a protobuf containing the constant values.  Potential constants are always evaluated on the CPU device.  (Also, if the resulting value is larger than a certain threshold -- around 10s of MB iirc -- then it is discarded and the graph is left alone).\nIt it likely that when the same expression is computed in a loop the constant folder doesn't consider it a candidate.\nIn your code snippets above, you only time a single session.run call for each variant...   I would expect constant folding overheads (and many other overheads) to only affect the first execution of each graph.\nIf you do a warmup sess.run(dot_product) call, then put a loop around multiple calls of sess.run(dot_product) and evaluate it repeatedly, do you still see the loop version running faster?   If so then this is worth looking into further!\ni.e. something like:\nwith tf.Session(graph=graph) as sess:\n   print(sess.run(dot_product))\n   t1 = default_timer()\n   for _ in xrange(10):\n       sess.run(dot_product)\n   print(\"time v1: {}\".format(default_timer() - t1))\n\n(Note that if the size of dot_product was bigger than a scalar then I would also be concerned about repeatedly fetching the result...  you can use session.run(dot_product.op) when benchmarking)", "body": "The first `session.run` call being slower is almost certainly due to running the constant folder to optimize the graph.  When `session.run` is called for the first time on a set of feeds/fetches, the constant folder will run and parts of the graph will be replaced with a `tf.constant` node that has a protobuf containing the constant values.  Potential constants are always evaluated on the CPU device.  (Also, if the resulting value is larger than a certain threshold -- around 10s of MB iirc -- then it is discarded and the graph is left alone).\r\n\r\nIt it likely that when the same expression is computed in a loop the constant folder doesn't consider it a candidate.\r\n\r\nIn your code snippets above, you only time a single session.run call for each variant...   I would expect constant folding overheads (and many other overheads) to only affect the first execution of each graph.  \r\n\r\nIf you do a warmup `sess.run(dot_product)` call, then put a loop around multiple calls of `sess.run(dot_product)` and evaluate it repeatedly, do you still see the loop version running faster?   If so then this is worth looking into further!\r\n\r\ni.e. something like:\r\n```\r\nwith tf.Session(graph=graph) as sess:\r\n   print(sess.run(dot_product))\r\n   t1 = default_timer()\r\n   for _ in xrange(10):\r\n       sess.run(dot_product)\r\n   print(\"time v1: {}\".format(default_timer() - t1))\r\n```\r\n(Note that if the size of `dot_product` was bigger than a scalar then I would also be concerned about repeatedly fetching the result...  you can use `session.run(dot_product.op)` when benchmarking)"}