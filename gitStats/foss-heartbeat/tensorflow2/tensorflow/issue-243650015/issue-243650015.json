{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11570", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11570/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11570/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11570/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11570", "id": 243650015, "node_id": "MDU6SXNzdWUyNDM2NTAwMTU=", "number": 11570, "title": "LSTM with Projection issue", "user": {"login": "xinq2016", "id": 20516775, "node_id": "MDQ6VXNlcjIwNTE2Nzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/20516775?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xinq2016", "html_url": "https://github.com/xinq2016", "followers_url": "https://api.github.com/users/xinq2016/followers", "following_url": "https://api.github.com/users/xinq2016/following{/other_user}", "gists_url": "https://api.github.com/users/xinq2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/xinq2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xinq2016/subscriptions", "organizations_url": "https://api.github.com/users/xinq2016/orgs", "repos_url": "https://api.github.com/users/xinq2016/repos", "events_url": "https://api.github.com/users/xinq2016/events{/privacy}", "received_events_url": "https://api.github.com/users/xinq2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-18T09:12:52Z", "updated_at": "2017-07-18T20:02:22Z", "closed_at": "2017-07-18T20:02:22Z", "author_association": "NONE", "body_html": "<p>I wanna build a multi-layer LSTM CTC network with projection in LSTM.</p>\n<pre><code>    cell = tf.nn.rnn_cell.LSTMCell(FLAGS.n_hidden, \n                                   initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=True), \n                                   num_proj = FLAGS.n_hidden/2, \n                                   state_is_tuple=True)\n    init_stat = cell.zero_state(FLAGS.batch_size, dtype=tf.float32)\n    _inputs = output_conv\n    for layer in range(FLAGS.recur_layer):\n        with tf.name_scope('LSTM_{}'.format(layer+1)) as scope: \n            outputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)\n            _inputs = tf.nn.relu(outputs)\n            tf.summary.histogram('LSTM_{}'.format(layer+1), _inputs)\n            _inputs = tf.contrib.layers.batch_norm(_inputs, center=True, scale=True, is_training=is_training, updates_collections=None)\n            tf.summary.histogram('LSTM_{}_bn'.format(layer+1), _inputs)\n    outputs = _inputs\n</code></pre>\n<p>the _inputs size is 1024, FLAGS.n_hidden=1024,<br>\nbut when I run it, there is an error:</p>\n<p>outputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn<br>\ndtype=dtype)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop<br>\nswap_memory=swap_memory)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop<br>\nresult = context.BuildLoop(cond, body, loop_vars, shape_invariants)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop<br>\npred, body, original_loop_vars, loop_vars, shape_invariants)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop<br>\nbody_result = body(*packed_vars_for_body)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step<br>\nskip_conditionals=True)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in _rnn_step<br>\nnew_output, new_state = call_cell()<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 708, in <br>\ncall_cell = lambda: cell(input_t, state)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in <strong>call</strong><br>\nreturn super(RNNCell, self).<strong>call</strong>(inputs, state)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 441, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 542, in call<br>\nlstm_matrix = _linear([inputs, m_prev], 4 * self._num_units, bias=True)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1017, in _linear<br>\ninitializer=kernel_initializer)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable<br>\nuse_resource=use_resource, custom_getter=custom_getter)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable<br>\nuse_resource=use_resource, custom_getter=custom_getter)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 360, in get_variable<br>\nvalidate_shape=validate_shape, use_resource=use_resource)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in _rnn_get_variable<br>\nvariable = getter(*args, **kwargs)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter<br>\nuse_resource=use_resource)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 669, in _get_single_variable<br>\nfound_var.get_shape()))<br>\nValueError: Trying to share variable rnn/lstm_cell/kernel, but specified shape (1024, 4096) and found shape (1536, 4096).</p>\n<p>How can I fix it?  Using the num_proj, is there any example of it?</p>\n<p>Many thanks<br>\nXin.q.</p>", "body_text": "I wanna build a multi-layer LSTM CTC network with projection in LSTM.\n    cell = tf.nn.rnn_cell.LSTMCell(FLAGS.n_hidden, \n                                   initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=True), \n                                   num_proj = FLAGS.n_hidden/2, \n                                   state_is_tuple=True)\n    init_stat = cell.zero_state(FLAGS.batch_size, dtype=tf.float32)\n    _inputs = output_conv\n    for layer in range(FLAGS.recur_layer):\n        with tf.name_scope('LSTM_{}'.format(layer+1)) as scope: \n            outputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)\n            _inputs = tf.nn.relu(outputs)\n            tf.summary.histogram('LSTM_{}'.format(layer+1), _inputs)\n            _inputs = tf.contrib.layers.batch_norm(_inputs, center=True, scale=True, is_training=is_training, updates_collections=None)\n            tf.summary.histogram('LSTM_{}_bn'.format(layer+1), _inputs)\n    outputs = _inputs\n\nthe _inputs size is 1024, FLAGS.n_hidden=1024,\nbut when I run it, there is an error:\noutputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\ndtype=dtype)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\nswap_memory=swap_memory)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\nresult = context.BuildLoop(cond, body, loop_vars, shape_invariants)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\npred, body, original_loop_vars, loop_vars, shape_invariants)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\nbody_result = body(*packed_vars_for_body)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\nskip_conditionals=True)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in _rnn_step\nnew_output, new_state = call_cell()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 708, in \ncall_cell = lambda: cell(input_t, state)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in call\nreturn super(RNNCell, self).call(inputs, state)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 441, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 542, in call\nlstm_matrix = _linear([inputs, m_prev], 4 * self._num_units, bias=True)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1017, in _linear\ninitializer=kernel_initializer)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\nuse_resource=use_resource, custom_getter=custom_getter)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\nuse_resource=use_resource, custom_getter=custom_getter)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 360, in get_variable\nvalidate_shape=validate_shape, use_resource=use_resource)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in _rnn_get_variable\nvariable = getter(*args, **kwargs)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\nuse_resource=use_resource)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 669, in _get_single_variable\nfound_var.get_shape()))\nValueError: Trying to share variable rnn/lstm_cell/kernel, but specified shape (1024, 4096) and found shape (1536, 4096).\nHow can I fix it?  Using the num_proj, is there any example of it?\nMany thanks\nXin.q.", "body": "I wanna build a multi-layer LSTM CTC network with projection in LSTM.\r\n\r\n        cell = tf.nn.rnn_cell.LSTMCell(FLAGS.n_hidden, \r\n                                       initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=True), \r\n                                       num_proj = FLAGS.n_hidden/2, \r\n                                       state_is_tuple=True)\r\n        init_stat = cell.zero_state(FLAGS.batch_size, dtype=tf.float32)\r\n        _inputs = output_conv\r\n        for layer in range(FLAGS.recur_layer):\r\n            with tf.name_scope('LSTM_{}'.format(layer+1)) as scope: \r\n                outputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)\r\n                _inputs = tf.nn.relu(outputs)\r\n                tf.summary.histogram('LSTM_{}'.format(layer+1), _inputs)\r\n                _inputs = tf.contrib.layers.batch_norm(_inputs, center=True, scale=True, is_training=is_training, updates_collections=None)\r\n                tf.summary.histogram('LSTM_{}_bn'.format(layer+1), _inputs)\r\n        outputs = _inputs\r\n\r\nthe _inputs size is 1024, FLAGS.n_hidden=1024,\r\nbut when I run it, there is an error:\r\n\r\n outputs, _ = tf.nn.dynamic_rnn(cell, _inputs, seq_len, initial_state=init_stat, dtype=tf.float32)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in _rnn_step\r\n    new_output, new_state = call_cell()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 708, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 441, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 542, in call\r\n    lstm_matrix = _linear([inputs, m_prev], 4 * self._num_units, bias=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1017, in _linear\r\n    initializer=kernel_initializer)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 360, in get_variable\r\n    validate_shape=validate_shape, use_resource=use_resource)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in _rnn_get_variable\r\n    variable = getter(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\r\n    use_resource=use_resource)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 669, in _get_single_variable\r\n    found_var.get_shape()))\r\nValueError: Trying to share variable rnn/lstm_cell/kernel, but specified shape (1024, 4096) and found shape (1536, 4096).\r\n\r\nHow can I fix it?  Using the num_proj, is there any example of it?\r\n\r\nMany thanks\r\nXin.q.\r\n"}