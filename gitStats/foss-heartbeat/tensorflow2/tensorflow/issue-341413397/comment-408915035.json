{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408915035", "html_url": "https://github.com/tensorflow/tensorflow/issues/20829#issuecomment-408915035", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20829", "id": 408915035, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODkxNTAzNQ==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-30T15:57:42Z", "updated_at": "2018-07-30T15:57:42Z", "author_association": "MEMBER", "body_html": "<p>It's not totally clear to me how you are calling this, but from what I gather, it looks like the last tensor is smaller. As you point out, you are using <code>allow_smaller_final_batch=True</code>, which is likely to produce this.</p>\n<p>Why not set that to <code>False</code>? I'm not sure how it's connected to feeding back the last state.</p>\n<p>Also, I don't exactly understand how you are going to process the continuous sequence unless you plan on truncating the gradient at each batch. (Just consider the initial state as a constant.)</p>", "body_text": "It's not totally clear to me how you are calling this, but from what I gather, it looks like the last tensor is smaller. As you point out, you are using allow_smaller_final_batch=True, which is likely to produce this.\nWhy not set that to False? I'm not sure how it's connected to feeding back the last state.\nAlso, I don't exactly understand how you are going to process the continuous sequence unless you plan on truncating the gradient at each batch. (Just consider the initial state as a constant.)", "body": "It's not totally clear to me how you are calling this, but from what I gather, it looks like the last tensor is smaller. As you point out, you are using `allow_smaller_final_batch=True`, which is likely to produce this.\r\n\r\nWhy not set that to `False`? I'm not sure how it's connected to feeding back the last state.\r\n\r\nAlso, I don't exactly understand how you are going to process the continuous sequence unless you plan on truncating the gradient at each batch. (Just consider the initial state as a constant.)"}