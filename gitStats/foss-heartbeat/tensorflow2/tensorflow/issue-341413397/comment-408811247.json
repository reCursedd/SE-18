{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/408811247", "html_url": "https://github.com/tensorflow/tensorflow/issues/20829#issuecomment-408811247", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20829", "id": 408811247, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODgxMTI0Nw==", "user": {"login": "amadupu", "id": 14251460, "node_id": "MDQ6VXNlcjE0MjUxNDYw", "avatar_url": "https://avatars3.githubusercontent.com/u/14251460?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amadupu", "html_url": "https://github.com/amadupu", "followers_url": "https://api.github.com/users/amadupu/followers", "following_url": "https://api.github.com/users/amadupu/following{/other_user}", "gists_url": "https://api.github.com/users/amadupu/gists{/gist_id}", "starred_url": "https://api.github.com/users/amadupu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amadupu/subscriptions", "organizations_url": "https://api.github.com/users/amadupu/orgs", "repos_url": "https://api.github.com/users/amadupu/repos", "events_url": "https://api.github.com/users/amadupu/events{/privacy}", "received_events_url": "https://api.github.com/users/amadupu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-30T09:57:11Z", "updated_at": "2018-07-30T15:48:52Z", "author_association": "NONE", "body_html": "<p>apologies for delayed response...please find the requested details as below</p>\n<p>OS: Windows,<br>\nIDE: Pycharm,<br>\nTensorflow Installed from: pip3<br>\nTensorflow Version: 1.9.0</p>\n<p>Requirement:</p>\n<p>Im trying to train an RNN model for a continous data. so after each batch processing i would like the prev state to be passed on to the next batch processing. The same is being achieved in the below code snippets</p>\n<pre><code>cell_size = 512\nbatch_size = 50\nnum_layers = 3\nfeature_size = 26\nback_propagation_steps = 600\n</code></pre>\n<p>Steps to Reproduce:</p>\n<ul>\n<li>Created dynamic_rnn processing as follows</li>\n</ul>\n<pre><code>outputs, self.final_state = tf.nn.dynamic_rnn(\n  cell_fw,self.rnn_inputs,sequence_length=self.steps,\n  initial_state=self.state_fw,time_major=False)\n</code></pre>\n<ul>\n<li>Reading data from input pipelines as follows</li>\n</ul>\n<pre><code>self.steps, self.xs , self.ys = tf.train.batch(\n  tensors=decoder.dequeue(self.is_classifier), batch_size=50,\n  dynamic_pad=True,  # &lt;---\n  allow_smaller_final_batch=True,  # &lt;---\n  name='batch_processor')\n</code></pre>\n<ul>\n<li>During Training Phase Feeding the last state as follows</li>\n</ul>\n<pre><code> _,loss,  accuracy, summary, final_state,     = \n  self.sess.run(\n    [self.train_step,self.loss, self.accuracy, self.summary, self.final_state,],\n    feed_dict)\nfeed_dict[self.state_fw] = final_state\n</code></pre>\n<ul>\n<li>Error during processing of the <strong>last smaller batch</strong></li>\n</ul>\n<pre><code>_Dimensions of inputs should match: shape[0] = [20,512] vs. shape[1] = [50,512]\n\t [[Node: rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/dropout/mul, rnn_layer/rnn/while/Identity_4, rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat/axis)]]_\n</code></pre>", "body_text": "apologies for delayed response...please find the requested details as below\nOS: Windows,\nIDE: Pycharm,\nTensorflow Installed from: pip3\nTensorflow Version: 1.9.0\nRequirement:\nIm trying to train an RNN model for a continous data. so after each batch processing i would like the prev state to be passed on to the next batch processing. The same is being achieved in the below code snippets\ncell_size = 512\nbatch_size = 50\nnum_layers = 3\nfeature_size = 26\nback_propagation_steps = 600\n\nSteps to Reproduce:\n\nCreated dynamic_rnn processing as follows\n\noutputs, self.final_state = tf.nn.dynamic_rnn(\n  cell_fw,self.rnn_inputs,sequence_length=self.steps,\n  initial_state=self.state_fw,time_major=False)\n\n\nReading data from input pipelines as follows\n\nself.steps, self.xs , self.ys = tf.train.batch(\n  tensors=decoder.dequeue(self.is_classifier), batch_size=50,\n  dynamic_pad=True,  # <---\n  allow_smaller_final_batch=True,  # <---\n  name='batch_processor')\n\n\nDuring Training Phase Feeding the last state as follows\n\n _,loss,  accuracy, summary, final_state,     = \n  self.sess.run(\n    [self.train_step,self.loss, self.accuracy, self.summary, self.final_state,],\n    feed_dict)\nfeed_dict[self.state_fw] = final_state\n\n\nError during processing of the last smaller batch\n\n_Dimensions of inputs should match: shape[0] = [20,512] vs. shape[1] = [50,512]\n\t [[Node: rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/dropout/mul, rnn_layer/rnn/while/Identity_4, rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat/axis)]]_", "body": "apologies for delayed response...please find the requested details as below\r\n\r\nOS: Windows, \r\nIDE: Pycharm, \r\nTensorflow Installed from: pip3\r\nTensorflow Version: 1.9.0\r\n\r\nRequirement:\r\n\r\nIm trying to train an RNN model for a continous data. so after each batch processing i would like the prev state to be passed on to the next batch processing. The same is being achieved in the below code snippets\r\n\r\n```\r\ncell_size = 512\r\nbatch_size = 50\r\nnum_layers = 3\r\nfeature_size = 26\r\nback_propagation_steps = 600\r\n```\r\n\r\nSteps to Reproduce:\r\n\r\n- Created dynamic_rnn processing as follows\r\n```\r\noutputs, self.final_state = tf.nn.dynamic_rnn(\r\n  cell_fw,self.rnn_inputs,sequence_length=self.steps,\r\n  initial_state=self.state_fw,time_major=False)\r\n```\r\n\r\n- Reading data from input pipelines as follows\r\n```\r\nself.steps, self.xs , self.ys = tf.train.batch(\r\n  tensors=decoder.dequeue(self.is_classifier), batch_size=50,\r\n  dynamic_pad=True,  # <---\r\n  allow_smaller_final_batch=True,  # <---\r\n  name='batch_processor')\r\n```\r\n\r\n- During Training Phase Feeding the last state as follows\r\n```\r\n _,loss,  accuracy, summary, final_state,     = \r\n  self.sess.run(\r\n    [self.train_step,self.loss, self.accuracy, self.summary, self.final_state,],\r\n    feed_dict)\r\nfeed_dict[self.state_fw] = final_state\r\n```\r\n\r\n\r\n- Error during processing of the **last smaller batch**\r\n```\r\n_Dimensions of inputs should match: shape[0] = [20,512] vs. shape[1] = [50,512]\r\n\t [[Node: rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/dropout/mul, rnn_layer/rnn/while/Identity_4, rnn_layer/rnn/while/rnn/multi_rnn_cell/cell_0/LSTMCell/concat/axis)]]_\r\n```\r\n\r\n"}