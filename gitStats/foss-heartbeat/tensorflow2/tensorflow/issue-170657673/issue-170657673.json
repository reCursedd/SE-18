{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3751", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3751/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3751/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3751/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3751", "id": 170657673, "node_id": "MDU6SXNzdWUxNzA2NTc2NzM=", "number": 3751, "title": "Grid3LSTMCell running out of memory ", "user": {"login": "KendallWeihe", "id": 3602993, "node_id": "MDQ6VXNlcjM2MDI5OTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3602993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KendallWeihe", "html_url": "https://github.com/KendallWeihe", "followers_url": "https://api.github.com/users/KendallWeihe/followers", "following_url": "https://api.github.com/users/KendallWeihe/following{/other_user}", "gists_url": "https://api.github.com/users/KendallWeihe/gists{/gist_id}", "starred_url": "https://api.github.com/users/KendallWeihe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KendallWeihe/subscriptions", "organizations_url": "https://api.github.com/users/KendallWeihe/orgs", "repos_url": "https://api.github.com/users/KendallWeihe/repos", "events_url": "https://api.github.com/users/KendallWeihe/events{/privacy}", "received_events_url": "https://api.github.com/users/KendallWeihe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-08-11T14:21:09Z", "updated_at": "2016-08-11T18:26:27Z", "closed_at": "2016-08-11T18:26:27Z", "author_association": "NONE", "body_html": "<p>Here are my specs:</p>\n<ul>\n<li>NVIDIA GTX 1070</li>\n<li>Tensorflow from source (bazel 0.3.0)</li>\n<li>CUDA 8.0</li>\n<li>Cudnn 5</li>\n</ul>\n<p>I am trying to implement a 3D Grid LSTM network. My network is actually a CNN-LSTM end-to-end system, but I know that the <code>Grid3LSTMCell</code> is what is causing the issue (I have tested without and it functions fine).</p>\n<p>Typically this would be an appropriate SO post, but I think I have exhausted my GPU options so maybe this is a bug in the <code>GridRNNCell</code> itself. I have included...</p>\n<pre><code># Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    #gpu_options = tf.GPUOptions()\n    #config = tf.ConfigProto(gpu_options=gpu_options)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n</code></pre>\n<p>I commented out <code>config.gpu_options.per_process_gpu_memory_fraction = 0.1</code> because I have tried including it. I have tried excluding <code>config.gpu_options.allow_growth</code> and including <code>config.gpu_options.per_process_gpu_memory_fraction = 0.1</code>. I have tried different fraction values. And I have tried including both GPU options</p>\n<p>I have also tried finalizing the graph before <code>sess.run()</code> by using <code>tf.get_default_graph().finalize()</code></p>\n<p>I should note that the RNN initialization step alone takes roughly 10 minutes to intialize -- <code>outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)</code>.</p>\n<p>I am able to run the network on a cropped image of size 20x20, but when I train the network on the full 396x396 image I get the following...</p>\n<pre><code> totalling 86.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 301086720 totalling 287.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 6.57GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \nLimit:                  7531433165\nInUse:                  7054675456\nMaxInUse:               7054689536\nNumAllocs:                  369387\nMaxAllocSize:            301086720\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 768.0KiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[384,512]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=140010 evicted_count=140000 eviction_rate=0.999929 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=150010 evicted_count=150000 eviction_rate=0.999933 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=160010 evicted_count=160000 eviction_rate=0.999938 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=170010 evicted_count=170000 eviction_rate=0.999941 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=180010 evicted_count=180000 eviction_rate=0.999944 and unsatisfied allocation rate=0\nTraceback (most recent call last):\n  File \"3D-CNN-LSTM-reg.py\", line 225, in &lt;module&gt;\n    keep_prob: dropout})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[396,128]\n     [[Node: opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](net/RNN/Grid3LSTMCell_537/split, opt/gradients/net/RNN/Grid3LSTMCell_537/concat_4_grad/tuple/control_dependency)]]\nCaused by op u'opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 191, in &lt;module&gt;\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 476, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 637, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1296, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'net/RNN/Grid3LSTMCell_537/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 176, in &lt;module&gt;\n    pred = conv_net(x, weights, biases, keep_prob)\n  File \"3D-CNN-LSTM-reg.py\", line 135, in conv_net\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 219, in rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in &lt;lambda&gt;\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py\", line 150, in __call__\n    c_prev[j] = math_ops.matmul(input_splits[i], input_project_c)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n</code></pre>\n<p>The full code is as follows...</p>\n<pre><code>\n#Kendall Weihe\n#This is a CNN that handles 3D data\n#Adjust network parameters below, also adjust data directory\n\nimport tensorflow as tf\nimport pdb\nimport numpy as np\nfrom numpy import genfromtxt\nfrom PIL import Image\nfrom tensorflow.python.ops import rnn, rnn_cell\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\nfrom tensorflow.tensorflow.scroll import scroll_data\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 1000000\nbatch_size = 3\ndisplay_step = 1\n\n# Network Parameters\nn_input_x = 396 # Input image x-dimension\nn_input_y = 396 # Input image y-dimension\nn_input_z = 5\nn_hidden = 128\nn_classes = 2 # Binary classification -- on a surface or not\nn_output = n_input_x * n_classes\n\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y])\ntemp_x = tf.placeholder(tf.float32, [1, n_input_z, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n# This function converts the ground truth data into a\n    #2 channel classification -- n_input_x x n_input_y x 2\n    # one layer for 0's and the other for 1's\ndef convert_to_2_channel(x):\n    #assume input has dimension (batch_size,x,y)\n    #output will have dimension (batch_size,x,y,2)\n    output = np.empty((batch_size, n_input_z, n_input_x, n_input_y, n_classes))\n    for i in range(batch_size):\n        for j in range(n_input_z):\n            for k in range(n_input_x):\n                for l in range(n_input_y):\n                    for m in range(n_classes):\n                        if m == 0:\n                            output[i][j][k][l][m] = x[i][j][k][l]\n                        else:\n                            output[i][j][k][l][m] = 1 - x[i][j][k][l]\n\n    return output\n\n\n# Create some wrappers for simplicity\ndef conv3d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv3d(x, W, strides=[1, strides, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\ndef maxpool3d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool3d(x, ksize=[1, k, k, k, 1], strides=[1, k, k, k, 1],\n                          padding='SAME')\n\ndef deconv3d(prev_layer, w, b, output_shape, strides):\n    # Deconv layer\n    deconv = tf.nn.conv3d_transpose(prev_layer, w, output_shape=output_shape, strides=strides, padding=\"VALID\")\n    deconv = tf.nn.bias_add(deconv, b)\n    deconv = tf.nn.relu(deconv)\n    return deconv\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[batch_size, n_input_z, n_input_x, n_input_y, 1])\n\n    with tf.name_scope(\"conv1\") as scope:\n    # Convolution Layer\n        conv1 = conv3d(x, weights['wc1'], biases['bc1'])\n        # Max Pooling (down-sampling)\n        #conv1 = tf.nn.local_response_normalization(conv1)\n        conv1 = maxpool3d(conv1, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv2\") as scope:\n        conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])\n        # Max Pooling (down-sampling)\n        # conv2 = tf.nn.local_response_normalization(conv2)\n        conv2 = maxpool3d(conv2, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv3\") as scope:\n        conv3 = conv3d(conv2, weights['wc3'], biases['bc3'])\n        # Max Pooling (down-sampling)\n        # conv3 = tf.nn.local_response_normalization(conv3)\n        conv3 = maxpool3d(conv3, k=2)\n\n    # pdb.set_trace()\n\n    temp_batch_size = tf.shape(x)[0] #batch_size shape\n    with tf.name_scope(\"deconv1\") as scope:\n        output_shape = [temp_batch_size, 2, n_input_x / 4, n_input_y / 4, 64]\n        strides = [1,2,2,2,1]\n        #conv4 = deconv3d(conv3, weights['wdc1'], biases['bdc1'], output_shape, strides)\n        # conv4 = tf.nn.local_response_normalization(conv4)\n        conv4 = tf.nn.conv3d_transpose(conv3, weights['wdc1'], output_shape=output_shape, strides=strides, padding=\"SAME\")\n        conv4 = tf.nn.bias_add(conv4, biases['bdc1'])\n        conv4 = tf.nn.relu(conv4)\n\n    with tf.name_scope(\"deconv2\") as scope:\n        output_shape = [temp_batch_size, 3, n_input_x / 2, n_input_y / 2, 32]\n        strides = [1,1,2,2,1]\n        conv5 = deconv3d(conv4, weights['wdc2'], biases['bdc2'], output_shape, strides)\n        # conv5 = tf.nn.local_response_normalization(conv5)\n\n    with tf.name_scope(\"deconv3\") as scope:\n        output_shape = [temp_batch_size, 5, n_input_x, n_input_y, 1]\n        #this time don't use ReLu -- since output layer\n        conv6 = tf.nn.conv3d_transpose(conv5, weights['wdc3'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n        x = tf.nn.bias_add(conv6, biases['bdc3'])\n        x = tf.reshape(x, [batch_size, n_input_z, n_input_x, n_input_y])\n        # conv6 = tf.nn.relu(conv6)\n\n    # pdb.set_trace()\n\n    x = tf.reshape(conv6, [batch_size * n_input_y * n_input_z, n_input_x])\n    x = tf.split(0, n_input_y * n_input_z, x)\n\n    lstm_cell = grid_rnn_cell.Grid3LSTMCell(n_hidden)\n\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n\n    output = []\n    for i in xrange(n_input_y * n_input_z):\n        output.append(tf.matmul(outputs[i], lstm_weights[i]) + lstm_biases[i])\n\n    return output\n\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1' : tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2' : tf.Variable(tf.random_normal([3, 5, 5, 32, 64])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc3' : tf.Variable(tf.random_normal([2, 5, 5, 64, 128])),\n\n    'wdc1' : tf.Variable(tf.random_normal([2, 2, 2, 64, 128])),\n\n    'wdc2' : tf.Variable(tf.random_normal([2, 2, 2, 32, 64])),\n\n    'wdc3' : tf.Variable(tf.random_normal([3, 2, 2, 1, 32])),\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bc3': tf.Variable(tf.random_normal([128])),\n    'bdc1': tf.Variable(tf.random_normal([64])),\n    'bdc2': tf.Variable(tf.random_normal([32])),\n    'bdc3': tf.Variable(tf.random_normal([n_input_z])),\n}\n\nlstm_weights = {}\nlstm_biases = {}\n\nfor i in xrange(n_input_y * n_input_z):\n    lstm_weights[i] = tf.Variable(tf.random_normal([n_hidden, n_output]))\n    lstm_biases[i] = tf.Variable(tf.random_normal([n_output]))\n\n# Construct model\nwith tf.name_scope(\"net\") as scope:\n    pred = conv_net(x, weights, biases, keep_prob)\n    # pdb.set_trace()\n    pred = tf.transpose(tf.pack(pred),[1,0,2])\n    pred = tf.reshape(pred, [-1, n_input_z, n_input_x, n_input_y, n_classes])\n\n    # Define loss and optimizer\n    # Reshape for cost function\n    temp_pred = tf.reshape(pred, [-1, 2])\n    temp_y = tf.reshape(y, [-1, 2])\n\nwith tf.name_scope(\"loss\") as scope:\n    # cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y))\n    cost = (tf.nn.sigmoid_cross_entropy_with_logits(temp_pred, temp_y))\n\nwith tf.name_scope(\"opt\") as scope:\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\nwith tf.name_scope(\"acc\") as scope:\n    # accuracy is the difference between prediction and ground truth matrices\n    correct_pred = tf.equal(0,tf.cast(tf.sub(tf.nn.sigmoid(temp_pred),temp_y), tf.int32))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    gpu_options = tf.GPUOptions()\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n    sess.run(init)\n    summary = tf.train.SummaryWriter('/tmp/logdir/', sess.graph) #initialize graph for tensorboard\n    step = 1\n1\n    # Import data\n    data = scroll_data.read_data('/home/volcart/Documents/Data/', 100, n_input_x, n_input_y)\n    # Keep training until reach max iterations\n    while step * batch_size &lt; training_iters:\n        batch_x, batch_y = data.train.next_batch(batch_size * n_input_z)\n        # Run optimization op (backprop)\n        batch_x = batch_x.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = batch_y.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = convert_to_2_channel(batch_y) # Converts the 3960x3960 ground truth to a 3960x3960x2 classification\n        batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                       keep_prob: dropout})\n\n        step = step + 1\n        if step % display_step == 0:\n            batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                              y: batch_y,\n                                                              keep_prob: 1.0})\n            print \"Step = \" + str(step) + \" Accuracy = \" + str(acc)\n            #print \"Loss = \" + str(loss)\n            # Save network\n            if step % 50 == 0:\n                save_path = \"/home/volcart/Documents/3D-CNN-LSTM-reg-model/3D-CNN-LSTM-seg-step-\" + str(step) + \"-model.ckpt\"\n                saver.save(sess, save_path)\n</code></pre>", "body_text": "Here are my specs:\n\nNVIDIA GTX 1070\nTensorflow from source (bazel 0.3.0)\nCUDA 8.0\nCudnn 5\n\nI am trying to implement a 3D Grid LSTM network. My network is actually a CNN-LSTM end-to-end system, but I know that the Grid3LSTMCell is what is causing the issue (I have tested without and it functions fine).\nTypically this would be an appropriate SO post, but I think I have exhausted my GPU options so maybe this is a bug in the GridRNNCell itself. I have included...\n# Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    #gpu_options = tf.GPUOptions()\n    #config = tf.ConfigProto(gpu_options=gpu_options)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n\nI commented out config.gpu_options.per_process_gpu_memory_fraction = 0.1 because I have tried including it. I have tried excluding config.gpu_options.allow_growth and including config.gpu_options.per_process_gpu_memory_fraction = 0.1. I have tried different fraction values. And I have tried including both GPU options\nI have also tried finalizing the graph before sess.run() by using tf.get_default_graph().finalize()\nI should note that the RNN initialization step alone takes roughly 10 minutes to intialize -- outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32).\nI am able to run the network on a cropped image of size 20x20, but when I train the network on the full 396x396 image I get the following...\n totalling 86.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 301086720 totalling 287.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 6.57GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \nLimit:                  7531433165\nInUse:                  7054675456\nMaxInUse:               7054689536\nNumAllocs:                  369387\nMaxAllocSize:            301086720\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 768.0KiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[384,512]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=140010 evicted_count=140000 eviction_rate=0.999929 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=150010 evicted_count=150000 eviction_rate=0.999933 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=160010 evicted_count=160000 eviction_rate=0.999938 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=170010 evicted_count=170000 eviction_rate=0.999941 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=180010 evicted_count=180000 eviction_rate=0.999944 and unsatisfied allocation rate=0\nTraceback (most recent call last):\n  File \"3D-CNN-LSTM-reg.py\", line 225, in <module>\n    keep_prob: dropout})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[396,128]\n     [[Node: opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](net/RNN/Grid3LSTMCell_537/split, opt/gradients/net/RNN/Grid3LSTMCell_537/concat_4_grad/tuple/control_dependency)]]\nCaused by op u'opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 191, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 476, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 637, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1296, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'net/RNN/Grid3LSTMCell_537/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 176, in <module>\n    pred = conv_net(x, weights, biases, keep_prob)\n  File \"3D-CNN-LSTM-reg.py\", line 135, in conv_net\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 219, in rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in <lambda>\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py\", line 150, in __call__\n    c_prev[j] = math_ops.matmul(input_splits[i], input_project_c)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n\nThe full code is as follows...\n\n#Kendall Weihe\n#This is a CNN that handles 3D data\n#Adjust network parameters below, also adjust data directory\n\nimport tensorflow as tf\nimport pdb\nimport numpy as np\nfrom numpy import genfromtxt\nfrom PIL import Image\nfrom tensorflow.python.ops import rnn, rnn_cell\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\nfrom tensorflow.tensorflow.scroll import scroll_data\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 1000000\nbatch_size = 3\ndisplay_step = 1\n\n# Network Parameters\nn_input_x = 396 # Input image x-dimension\nn_input_y = 396 # Input image y-dimension\nn_input_z = 5\nn_hidden = 128\nn_classes = 2 # Binary classification -- on a surface or not\nn_output = n_input_x * n_classes\n\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y])\ntemp_x = tf.placeholder(tf.float32, [1, n_input_z, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n# This function converts the ground truth data into a\n    #2 channel classification -- n_input_x x n_input_y x 2\n    # one layer for 0's and the other for 1's\ndef convert_to_2_channel(x):\n    #assume input has dimension (batch_size,x,y)\n    #output will have dimension (batch_size,x,y,2)\n    output = np.empty((batch_size, n_input_z, n_input_x, n_input_y, n_classes))\n    for i in range(batch_size):\n        for j in range(n_input_z):\n            for k in range(n_input_x):\n                for l in range(n_input_y):\n                    for m in range(n_classes):\n                        if m == 0:\n                            output[i][j][k][l][m] = x[i][j][k][l]\n                        else:\n                            output[i][j][k][l][m] = 1 - x[i][j][k][l]\n\n    return output\n\n\n# Create some wrappers for simplicity\ndef conv3d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv3d(x, W, strides=[1, strides, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\ndef maxpool3d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool3d(x, ksize=[1, k, k, k, 1], strides=[1, k, k, k, 1],\n                          padding='SAME')\n\ndef deconv3d(prev_layer, w, b, output_shape, strides):\n    # Deconv layer\n    deconv = tf.nn.conv3d_transpose(prev_layer, w, output_shape=output_shape, strides=strides, padding=\"VALID\")\n    deconv = tf.nn.bias_add(deconv, b)\n    deconv = tf.nn.relu(deconv)\n    return deconv\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[batch_size, n_input_z, n_input_x, n_input_y, 1])\n\n    with tf.name_scope(\"conv1\") as scope:\n    # Convolution Layer\n        conv1 = conv3d(x, weights['wc1'], biases['bc1'])\n        # Max Pooling (down-sampling)\n        #conv1 = tf.nn.local_response_normalization(conv1)\n        conv1 = maxpool3d(conv1, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv2\") as scope:\n        conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])\n        # Max Pooling (down-sampling)\n        # conv2 = tf.nn.local_response_normalization(conv2)\n        conv2 = maxpool3d(conv2, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv3\") as scope:\n        conv3 = conv3d(conv2, weights['wc3'], biases['bc3'])\n        # Max Pooling (down-sampling)\n        # conv3 = tf.nn.local_response_normalization(conv3)\n        conv3 = maxpool3d(conv3, k=2)\n\n    # pdb.set_trace()\n\n    temp_batch_size = tf.shape(x)[0] #batch_size shape\n    with tf.name_scope(\"deconv1\") as scope:\n        output_shape = [temp_batch_size, 2, n_input_x / 4, n_input_y / 4, 64]\n        strides = [1,2,2,2,1]\n        #conv4 = deconv3d(conv3, weights['wdc1'], biases['bdc1'], output_shape, strides)\n        # conv4 = tf.nn.local_response_normalization(conv4)\n        conv4 = tf.nn.conv3d_transpose(conv3, weights['wdc1'], output_shape=output_shape, strides=strides, padding=\"SAME\")\n        conv4 = tf.nn.bias_add(conv4, biases['bdc1'])\n        conv4 = tf.nn.relu(conv4)\n\n    with tf.name_scope(\"deconv2\") as scope:\n        output_shape = [temp_batch_size, 3, n_input_x / 2, n_input_y / 2, 32]\n        strides = [1,1,2,2,1]\n        conv5 = deconv3d(conv4, weights['wdc2'], biases['bdc2'], output_shape, strides)\n        # conv5 = tf.nn.local_response_normalization(conv5)\n\n    with tf.name_scope(\"deconv3\") as scope:\n        output_shape = [temp_batch_size, 5, n_input_x, n_input_y, 1]\n        #this time don't use ReLu -- since output layer\n        conv6 = tf.nn.conv3d_transpose(conv5, weights['wdc3'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n        x = tf.nn.bias_add(conv6, biases['bdc3'])\n        x = tf.reshape(x, [batch_size, n_input_z, n_input_x, n_input_y])\n        # conv6 = tf.nn.relu(conv6)\n\n    # pdb.set_trace()\n\n    x = tf.reshape(conv6, [batch_size * n_input_y * n_input_z, n_input_x])\n    x = tf.split(0, n_input_y * n_input_z, x)\n\n    lstm_cell = grid_rnn_cell.Grid3LSTMCell(n_hidden)\n\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n\n    output = []\n    for i in xrange(n_input_y * n_input_z):\n        output.append(tf.matmul(outputs[i], lstm_weights[i]) + lstm_biases[i])\n\n    return output\n\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1' : tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2' : tf.Variable(tf.random_normal([3, 5, 5, 32, 64])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc3' : tf.Variable(tf.random_normal([2, 5, 5, 64, 128])),\n\n    'wdc1' : tf.Variable(tf.random_normal([2, 2, 2, 64, 128])),\n\n    'wdc2' : tf.Variable(tf.random_normal([2, 2, 2, 32, 64])),\n\n    'wdc3' : tf.Variable(tf.random_normal([3, 2, 2, 1, 32])),\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bc3': tf.Variable(tf.random_normal([128])),\n    'bdc1': tf.Variable(tf.random_normal([64])),\n    'bdc2': tf.Variable(tf.random_normal([32])),\n    'bdc3': tf.Variable(tf.random_normal([n_input_z])),\n}\n\nlstm_weights = {}\nlstm_biases = {}\n\nfor i in xrange(n_input_y * n_input_z):\n    lstm_weights[i] = tf.Variable(tf.random_normal([n_hidden, n_output]))\n    lstm_biases[i] = tf.Variable(tf.random_normal([n_output]))\n\n# Construct model\nwith tf.name_scope(\"net\") as scope:\n    pred = conv_net(x, weights, biases, keep_prob)\n    # pdb.set_trace()\n    pred = tf.transpose(tf.pack(pred),[1,0,2])\n    pred = tf.reshape(pred, [-1, n_input_z, n_input_x, n_input_y, n_classes])\n\n    # Define loss and optimizer\n    # Reshape for cost function\n    temp_pred = tf.reshape(pred, [-1, 2])\n    temp_y = tf.reshape(y, [-1, 2])\n\nwith tf.name_scope(\"loss\") as scope:\n    # cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y))\n    cost = (tf.nn.sigmoid_cross_entropy_with_logits(temp_pred, temp_y))\n\nwith tf.name_scope(\"opt\") as scope:\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\nwith tf.name_scope(\"acc\") as scope:\n    # accuracy is the difference between prediction and ground truth matrices\n    correct_pred = tf.equal(0,tf.cast(tf.sub(tf.nn.sigmoid(temp_pred),temp_y), tf.int32))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    gpu_options = tf.GPUOptions()\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n    sess.run(init)\n    summary = tf.train.SummaryWriter('/tmp/logdir/', sess.graph) #initialize graph for tensorboard\n    step = 1\n1\n    # Import data\n    data = scroll_data.read_data('/home/volcart/Documents/Data/', 100, n_input_x, n_input_y)\n    # Keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = data.train.next_batch(batch_size * n_input_z)\n        # Run optimization op (backprop)\n        batch_x = batch_x.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = batch_y.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = convert_to_2_channel(batch_y) # Converts the 3960x3960 ground truth to a 3960x3960x2 classification\n        batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                       keep_prob: dropout})\n\n        step = step + 1\n        if step % display_step == 0:\n            batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                              y: batch_y,\n                                                              keep_prob: 1.0})\n            print \"Step = \" + str(step) + \" Accuracy = \" + str(acc)\n            #print \"Loss = \" + str(loss)\n            # Save network\n            if step % 50 == 0:\n                save_path = \"/home/volcart/Documents/3D-CNN-LSTM-reg-model/3D-CNN-LSTM-seg-step-\" + str(step) + \"-model.ckpt\"\n                saver.save(sess, save_path)", "body": "Here are my specs:\n- NVIDIA GTX 1070\n- Tensorflow from source (bazel 0.3.0)\n- CUDA 8.0\n- Cudnn 5\n\nI am trying to implement a 3D Grid LSTM network. My network is actually a CNN-LSTM end-to-end system, but I know that the `Grid3LSTMCell` is what is causing the issue (I have tested without and it functions fine). \n\nTypically this would be an appropriate SO post, but I think I have exhausted my GPU options so maybe this is a bug in the `GridRNNCell` itself. I have included... \n\n```\n# Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    #gpu_options = tf.GPUOptions()\n    #config = tf.ConfigProto(gpu_options=gpu_options)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n```\n\nI commented out `config.gpu_options.per_process_gpu_memory_fraction = 0.1` because I have tried including it. I have tried excluding `config.gpu_options.allow_growth` and including `config.gpu_options.per_process_gpu_memory_fraction = 0.1`. I have tried different fraction values. And I have tried including both GPU options\n\nI have also tried finalizing the graph before `sess.run()` by using `tf.get_default_graph().finalize()`\n\nI should note that the RNN initialization step alone takes roughly 10 minutes to intialize -- `outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)`.\n\nI am able to run the network on a cropped image of size 20x20, but when I train the network on the full 396x396 image I get the following...\n\n```\n totalling 86.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 301086720 totalling 287.14MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 6.57GiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \nLimit:                  7531433165\nInUse:                  7054675456\nMaxInUse:               7054689536\nNumAllocs:                  369387\nMaxAllocSize:            301086720\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 768.0KiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:940] Resource exhausted: OOM when allocating tensor with shape[384,512]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=140010 evicted_count=140000 eviction_rate=0.999929 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=150010 evicted_count=150000 eviction_rate=0.999933 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=160010 evicted_count=160000 eviction_rate=0.999938 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=170010 evicted_count=170000 eviction_rate=0.999941 and unsatisfied allocation rate=0\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=180010 evicted_count=180000 eviction_rate=0.999944 and unsatisfied allocation rate=0\nTraceback (most recent call last):\n  File \"3D-CNN-LSTM-reg.py\", line 225, in <module>\n    keep_prob: dropout})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 710, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 908, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 958, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 978, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[396,128]\n     [[Node: opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](net/RNN/Grid3LSTMCell_537/split, opt/gradients/net/RNN/Grid3LSTMCell_537/concat_4_grad/tuple/control_dependency)]]\nCaused by op u'opt/gradients/net/RNN/Grid3LSTMCell_537/MatMul_1_grad/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 191, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 476, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 637, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1296, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'net/RNN/Grid3LSTMCell_537/MatMul_1', defined at:\n  File \"3D-CNN-LSTM-reg.py\", line 176, in <module>\n    pred = conv_net(x, weights, biases, keep_prob)\n  File \"3D-CNN-LSTM-reg.py\", line 135, in conv_net\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 219, in rnn\n    (output, state) = call_cell()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 206, in <lambda>\n    call_cell = lambda: cell(input_, state)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py\", line 150, in __call__\n    c_prev[j] = math_ops.matmul(input_splits[i], input_project_c)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1352, in matmul\n    name=name)\n```\n\nThe full code is as follows...\n\n```\n\n#Kendall Weihe\n#This is a CNN that handles 3D data\n#Adjust network parameters below, also adjust data directory\n\nimport tensorflow as tf\nimport pdb\nimport numpy as np\nfrom numpy import genfromtxt\nfrom PIL import Image\nfrom tensorflow.python.ops import rnn, rnn_cell\nfrom tensorflow.contrib.grid_rnn.python.ops import grid_rnn_cell\nfrom tensorflow.tensorflow.scroll import scroll_data\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 1000000\nbatch_size = 3\ndisplay_step = 1\n\n# Network Parameters\nn_input_x = 396 # Input image x-dimension\nn_input_y = 396 # Input image y-dimension\nn_input_z = 5\nn_hidden = 128\nn_classes = 2 # Binary classification -- on a surface or not\nn_output = n_input_x * n_classes\n\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y])\ntemp_x = tf.placeholder(tf.float32, [1, n_input_z, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [batch_size, n_input_z, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n# This function converts the ground truth data into a\n    #2 channel classification -- n_input_x x n_input_y x 2\n    # one layer for 0's and the other for 1's\ndef convert_to_2_channel(x):\n    #assume input has dimension (batch_size,x,y)\n    #output will have dimension (batch_size,x,y,2)\n    output = np.empty((batch_size, n_input_z, n_input_x, n_input_y, n_classes))\n    for i in range(batch_size):\n        for j in range(n_input_z):\n            for k in range(n_input_x):\n                for l in range(n_input_y):\n                    for m in range(n_classes):\n                        if m == 0:\n                            output[i][j][k][l][m] = x[i][j][k][l]\n                        else:\n                            output[i][j][k][l][m] = 1 - x[i][j][k][l]\n\n    return output\n\n\n# Create some wrappers for simplicity\ndef conv3d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv3d(x, W, strides=[1, strides, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\ndef maxpool3d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool3d(x, ksize=[1, k, k, k, 1], strides=[1, k, k, k, 1],\n                          padding='SAME')\n\ndef deconv3d(prev_layer, w, b, output_shape, strides):\n    # Deconv layer\n    deconv = tf.nn.conv3d_transpose(prev_layer, w, output_shape=output_shape, strides=strides, padding=\"VALID\")\n    deconv = tf.nn.bias_add(deconv, b)\n    deconv = tf.nn.relu(deconv)\n    return deconv\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[batch_size, n_input_z, n_input_x, n_input_y, 1])\n\n    with tf.name_scope(\"conv1\") as scope:\n    # Convolution Layer\n        conv1 = conv3d(x, weights['wc1'], biases['bc1'])\n        # Max Pooling (down-sampling)\n        #conv1 = tf.nn.local_response_normalization(conv1)\n        conv1 = maxpool3d(conv1, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv2\") as scope:\n        conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])\n        # Max Pooling (down-sampling)\n        # conv2 = tf.nn.local_response_normalization(conv2)\n        conv2 = maxpool3d(conv2, k=2)\n\n    # Convolution Layer\n    with tf.name_scope(\"conv3\") as scope:\n        conv3 = conv3d(conv2, weights['wc3'], biases['bc3'])\n        # Max Pooling (down-sampling)\n        # conv3 = tf.nn.local_response_normalization(conv3)\n        conv3 = maxpool3d(conv3, k=2)\n\n    # pdb.set_trace()\n\n    temp_batch_size = tf.shape(x)[0] #batch_size shape\n    with tf.name_scope(\"deconv1\") as scope:\n        output_shape = [temp_batch_size, 2, n_input_x / 4, n_input_y / 4, 64]\n        strides = [1,2,2,2,1]\n        #conv4 = deconv3d(conv3, weights['wdc1'], biases['bdc1'], output_shape, strides)\n        # conv4 = tf.nn.local_response_normalization(conv4)\n        conv4 = tf.nn.conv3d_transpose(conv3, weights['wdc1'], output_shape=output_shape, strides=strides, padding=\"SAME\")\n        conv4 = tf.nn.bias_add(conv4, biases['bdc1'])\n        conv4 = tf.nn.relu(conv4)\n\n    with tf.name_scope(\"deconv2\") as scope:\n        output_shape = [temp_batch_size, 3, n_input_x / 2, n_input_y / 2, 32]\n        strides = [1,1,2,2,1]\n        conv5 = deconv3d(conv4, weights['wdc2'], biases['bdc2'], output_shape, strides)\n        # conv5 = tf.nn.local_response_normalization(conv5)\n\n    with tf.name_scope(\"deconv3\") as scope:\n        output_shape = [temp_batch_size, 5, n_input_x, n_input_y, 1]\n        #this time don't use ReLu -- since output layer\n        conv6 = tf.nn.conv3d_transpose(conv5, weights['wdc3'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n        x = tf.nn.bias_add(conv6, biases['bdc3'])\n        x = tf.reshape(x, [batch_size, n_input_z, n_input_x, n_input_y])\n        # conv6 = tf.nn.relu(conv6)\n\n    # pdb.set_trace()\n\n    x = tf.reshape(conv6, [batch_size * n_input_y * n_input_z, n_input_x])\n    x = tf.split(0, n_input_y * n_input_z, x)\n\n    lstm_cell = grid_rnn_cell.Grid3LSTMCell(n_hidden)\n\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n\n    output = []\n    for i in xrange(n_input_y * n_input_z):\n        output.append(tf.matmul(outputs[i], lstm_weights[i]) + lstm_biases[i])\n\n    return output\n\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1' : tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2' : tf.Variable(tf.random_normal([3, 5, 5, 32, 64])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc3' : tf.Variable(tf.random_normal([2, 5, 5, 64, 128])),\n\n    'wdc1' : tf.Variable(tf.random_normal([2, 2, 2, 64, 128])),\n\n    'wdc2' : tf.Variable(tf.random_normal([2, 2, 2, 32, 64])),\n\n    'wdc3' : tf.Variable(tf.random_normal([3, 2, 2, 1, 32])),\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bc3': tf.Variable(tf.random_normal([128])),\n    'bdc1': tf.Variable(tf.random_normal([64])),\n    'bdc2': tf.Variable(tf.random_normal([32])),\n    'bdc3': tf.Variable(tf.random_normal([n_input_z])),\n}\n\nlstm_weights = {}\nlstm_biases = {}\n\nfor i in xrange(n_input_y * n_input_z):\n    lstm_weights[i] = tf.Variable(tf.random_normal([n_hidden, n_output]))\n    lstm_biases[i] = tf.Variable(tf.random_normal([n_output]))\n\n# Construct model\nwith tf.name_scope(\"net\") as scope:\n    pred = conv_net(x, weights, biases, keep_prob)\n    # pdb.set_trace()\n    pred = tf.transpose(tf.pack(pred),[1,0,2])\n    pred = tf.reshape(pred, [-1, n_input_z, n_input_x, n_input_y, n_classes])\n\n    # Define loss and optimizer\n    # Reshape for cost function\n    temp_pred = tf.reshape(pred, [-1, 2])\n    temp_y = tf.reshape(y, [-1, 2])\n\nwith tf.name_scope(\"loss\") as scope:\n    # cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y))\n    cost = (tf.nn.sigmoid_cross_entropy_with_logits(temp_pred, temp_y))\n\nwith tf.name_scope(\"opt\") as scope:\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\nwith tf.name_scope(\"acc\") as scope:\n    # accuracy is the difference between prediction and ground truth matrices\n    correct_pred = tf.equal(0,tf.cast(tf.sub(tf.nn.sigmoid(temp_pred),temp_y), tf.int32))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\nwith tf.name_scope(\"initialize-and-config\") as scope:\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    gpu_options = tf.GPUOptions()\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    config.gpu_options.allow_growth = True\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.1\n\n# Launch the graph\nwith tf.Session(config=config) as sess:\n    sess.run(init)\n    summary = tf.train.SummaryWriter('/tmp/logdir/', sess.graph) #initialize graph for tensorboard\n    step = 1\n1\n    # Import data\n    data = scroll_data.read_data('/home/volcart/Documents/Data/', 100, n_input_x, n_input_y)\n    # Keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = data.train.next_batch(batch_size * n_input_z)\n        # Run optimization op (backprop)\n        batch_x = batch_x.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = batch_y.reshape((batch_size, n_input_z, n_input_x, n_input_y))\n        batch_y = convert_to_2_channel(batch_y) # Converts the 3960x3960 ground truth to a 3960x3960x2 classification\n        batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                       keep_prob: dropout})\n\n        step = step + 1\n        if step % display_step == 0:\n            batch_y = batch_y.reshape(batch_size, n_input_z, n_input_x, n_input_y, n_classes)\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                              y: batch_y,\n                                                              keep_prob: 1.0})\n            print \"Step = \" + str(step) + \" Accuracy = \" + str(acc)\n            #print \"Loss = \" + str(loss)\n            # Save network\n            if step % 50 == 0:\n                save_path = \"/home/volcart/Documents/3D-CNN-LSTM-reg-model/3D-CNN-LSTM-seg-step-\" + str(step) + \"-model.ckpt\"\n                saver.save(sess, save_path)\n```\n"}