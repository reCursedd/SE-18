{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19480", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19480/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19480/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19480/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19480", "id": 325464603, "node_id": "MDU6SXNzdWUzMjU0NjQ2MDM=", "number": 19480, "title": "Manually placing operations in eager execution raises FailedPreconditionError.", "user": {"login": "Noahyt", "id": 23128135, "node_id": "MDQ6VXNlcjIzMTI4MTM1", "avatar_url": "https://avatars1.githubusercontent.com/u/23128135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Noahyt", "html_url": "https://github.com/Noahyt", "followers_url": "https://api.github.com/users/Noahyt/followers", "following_url": "https://api.github.com/users/Noahyt/following{/other_user}", "gists_url": "https://api.github.com/users/Noahyt/gists{/gist_id}", "starred_url": "https://api.github.com/users/Noahyt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Noahyt/subscriptions", "organizations_url": "https://api.github.com/users/Noahyt/orgs", "repos_url": "https://api.github.com/users/Noahyt/repos", "events_url": "https://api.github.com/users/Noahyt/events{/privacy}", "received_events_url": "https://api.github.com/users/Noahyt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, {"login": "akshaym", "id": 122911, "node_id": "MDQ6VXNlcjEyMjkxMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/122911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshaym", "html_url": "https://github.com/akshaym", "followers_url": "https://api.github.com/users/akshaym/followers", "following_url": "https://api.github.com/users/akshaym/following{/other_user}", "gists_url": "https://api.github.com/users/akshaym/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshaym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshaym/subscriptions", "organizations_url": "https://api.github.com/users/akshaym/orgs", "repos_url": "https://api.github.com/users/akshaym/repos", "events_url": "https://api.github.com/users/akshaym/events{/privacy}", "received_events_url": "https://api.github.com/users/akshaym/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-22T21:10:42Z", "updated_at": "2018-06-05T23:13:42Z", "closed_at": "2018-06-05T23:13:42Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: tensorflow 1.6</li>\n<li><strong>Python version</strong>: python3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: V9.0.176</li>\n<li><strong>GPU model and memory</strong>:  NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a model that I believe was not automatically being placed onto an available GPU.</p>\n<p>I then placed this part of the computation inside a with_device() block.  This schematically looks like:</p>\n<pre><code># define some variables\nwith tf.device(\"/device:GPU:0\"):\n    with tfe.GradientTape(persistent=True) as tape:\n       # calculate loss based on variables\n\n</code></pre>\n<p>The error is thrown during the loss calculation step.</p>\n<h3>Source code / logs</h3>\n<p>2018-05-22 13:57:11.963021: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA<br>\n2018-05-22 13:57:12.324280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:<br>\nname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53<br>\npciBusID: 0000:04:00.0<br>\ntotalMemory: 15.78GiB freeMemory: 15.36GiB<br>\n2018-05-22 13:57:12.324584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0<br>\n2018-05-22 13:57:12.623548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14878 MB memory) -&gt; physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0)<br>\nTraceback (most recent call last):<br>\nFile \"tf_registration_continuous.py\", line 619, in <br>\ncProfile.run('main()', file)<br>\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 16, in run<br>\nreturn _pyprofile._Utils(Profile).run(statement, filename, sort)<br>\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/profile.py\", line 55, in run<br>\nprof.run(statement)<br>\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 95, in run<br>\nreturn self.runctx(cmd, dict, dict)<br>\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 100, in runctx<br>\nexec(cmd, globals, locals)<br>\nFile \"\", line 1, in <br>\nFile \"tf_registration_continuous.py\", line 615, in main<br>\naccuracy ,runtime, final_loss = run_registration(directory='output/' + hparams_run.name, hparams=hparams_run, dataset_path = dataset_path, save_figs=False)<br>\nFile \"tf_registration_continuous.py\", line 525, in run_registration<br>\nrm.register(save_summaries = save_figs, make_animation=save_figs)<br>\nFile \"tf_registration_continuous.py\", line 190, in register<br>\nnum_images_to_optimize_params= self.hparams.num_images_to_optimize_params<br>\nFile \"tf_registration_continuous.py\", line 105, in single_registration_step<br>\n_ = self.eif.warp(scale, num_images_for_loss_calculation)<br>\nFile \"/home/groups/bmacint/Ultrasound/timing/elastic_image_field.py\", line 118, in warp<br>\nfield_image.initialize_translation()<br>\nFile \"/home/groups/bmacint/Ultrasound/timing/field_image.py\", line 87, in initialize_translation<br>\nself.translation_warp_points = tf.tile(self.translation[tf.newaxis, tf.newaxis, :],<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 828, in _SliceHelperVar<br>\nreturn _slice_helper(var._AsTensor(), slice_spec, var)<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 741, in _AsTensor<br>\nreturn self.value()<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 572, in value<br>\nreturn self._read_variable_op()<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 655, in _read_variable_op<br>\nself._dtype)<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 304, in read_variable_op<br>\nattrs=_attrs, ctx=_ctx, name=name)<br>\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute<br>\nsix.raise_from(core._status_to_exception(e.code, message), None)<br>\nFile \"\", line 2, in raise_from<br>\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable 152 from Container: eager-execution-0/. This could mean that the variable was uninitialized. Invalid argument: Trying to access resource located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0 [Op:ReadVariableOp]</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): tensorflow 1.6\nPython version: python3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: V9.0.176\nGPU model and memory:  NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)\nExact command to reproduce:\n\nDescribe the problem\nI have a model that I believe was not automatically being placed onto an available GPU.\nI then placed this part of the computation inside a with_device() block.  This schematically looks like:\n# define some variables\nwith tf.device(\"/device:GPU:0\"):\n    with tfe.GradientTape(persistent=True) as tape:\n       # calculate loss based on variables\n\n\nThe error is thrown during the loss calculation step.\nSource code / logs\n2018-05-22 13:57:11.963021: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-05-22 13:57:12.324280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties:\nname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\npciBusID: 0000:04:00.0\ntotalMemory: 15.78GiB freeMemory: 15.36GiB\n2018-05-22 13:57:12.324584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-05-22 13:57:12.623548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14878 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0)\nTraceback (most recent call last):\nFile \"tf_registration_continuous.py\", line 619, in \ncProfile.run('main()', file)\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 16, in run\nreturn _pyprofile._Utils(Profile).run(statement, filename, sort)\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/profile.py\", line 55, in run\nprof.run(statement)\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 95, in run\nreturn self.runctx(cmd, dict, dict)\nFile \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 100, in runctx\nexec(cmd, globals, locals)\nFile \"\", line 1, in \nFile \"tf_registration_continuous.py\", line 615, in main\naccuracy ,runtime, final_loss = run_registration(directory='output/' + hparams_run.name, hparams=hparams_run, dataset_path = dataset_path, save_figs=False)\nFile \"tf_registration_continuous.py\", line 525, in run_registration\nrm.register(save_summaries = save_figs, make_animation=save_figs)\nFile \"tf_registration_continuous.py\", line 190, in register\nnum_images_to_optimize_params= self.hparams.num_images_to_optimize_params\nFile \"tf_registration_continuous.py\", line 105, in single_registration_step\n_ = self.eif.warp(scale, num_images_for_loss_calculation)\nFile \"/home/groups/bmacint/Ultrasound/timing/elastic_image_field.py\", line 118, in warp\nfield_image.initialize_translation()\nFile \"/home/groups/bmacint/Ultrasound/timing/field_image.py\", line 87, in initialize_translation\nself.translation_warp_points = tf.tile(self.translation[tf.newaxis, tf.newaxis, :],\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 828, in _SliceHelperVar\nreturn _slice_helper(var._AsTensor(), slice_spec, var)\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 741, in _AsTensor\nreturn self.value()\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 572, in value\nreturn self._read_variable_op()\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 655, in _read_variable_op\nself._dtype)\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 304, in read_variable_op\nattrs=_attrs, ctx=_ctx, name=name)\nFile \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\nsix.raise_from(core._status_to_exception(e.code, message), None)\nFile \"\", line 2, in raise_from\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable 152 from Container: eager-execution-0/. This could mean that the variable was uninitialized. Invalid argument: Trying to access resource located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0 [Op:ReadVariableOp]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: tensorflow 1.6\r\n- **Python version**: python3.6\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: V9.0.176\r\n- **GPU model and memory**:  NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)\r\n- **Exact command to reproduce**: \r\n\r\n\r\n\r\n### Describe the problem\r\nI have a model that I believe was not automatically being placed onto an available GPU.  \r\n\r\nI then placed this part of the computation inside a with_device() block.  This schematically looks like:\r\n\r\n ```\r\n# define some variables\r\nwith tf.device(\"/device:GPU:0\"):\r\n     with tfe.GradientTape(persistent=True) as tape:\r\n        # calculate loss based on variables\r\n\r\n```\r\n\r\nThe error is thrown during the loss calculation step.  \r\n\r\n### Source code / logs\r\n\r\n\r\n2018-05-22 13:57:11.963021: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-05-22 13:57:12.324280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \r\nname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 15.78GiB freeMemory: 15.36GiB\r\n2018-05-22 13:57:12.324584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-05-22 13:57:12.623548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14878 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0)\r\nTraceback (most recent call last):\r\n  File \"tf_registration_continuous.py\", line 619, in <module>\r\n    cProfile.run('main()', file)\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 16, in run\r\n    return _pyprofile._Utils(Profile).run(statement, filename, sort)\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/profile.py\", line 55, in run\r\n    prof.run(statement)\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 95, in run\r\n    return self.runctx(cmd, dict, dict)\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py\", line 100, in runctx\r\n    exec(cmd, globals, locals)\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tf_registration_continuous.py\", line 615, in main\r\n    accuracy ,runtime, final_loss = run_registration(directory='output/' + hparams_run.name, hparams=hparams_run, dataset_path = dataset_path, save_figs=False)\r\n  File \"tf_registration_continuous.py\", line 525, in run_registration\r\n    rm.register(save_summaries = save_figs, make_animation=save_figs)\r\n  File \"tf_registration_continuous.py\", line 190, in register\r\n    num_images_to_optimize_params= self.hparams.num_images_to_optimize_params\r\n  File \"tf_registration_continuous.py\", line 105, in single_registration_step\r\n    _ = self.eif.warp(scale, num_images_for_loss_calculation)\r\n  File \"/home/groups/bmacint/Ultrasound/timing/elastic_image_field.py\", line 118, in warp\r\n    field_image.initialize_translation()\r\n  File \"/home/groups/bmacint/Ultrasound/timing/field_image.py\", line 87, in initialize_translation\r\n    self.translation_warp_points = tf.tile(self.translation[tf.newaxis, tf.newaxis, :],\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 828, in _SliceHelperVar\r\n    return _slice_helper(var._AsTensor(), slice_spec, var)\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 741, in _AsTensor\r\n    return self.value()\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 572, in value\r\n    return self._read_variable_op()\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 655, in _read_variable_op\r\n    self._dtype)\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 304, in read_variable_op\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 2, in raise_from\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable 152 from Container: eager-execution-0/. This could mean that the variable was uninitialized. Invalid argument: Trying to access resource located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0 [Op:ReadVariableOp]\r\n\r\n"}