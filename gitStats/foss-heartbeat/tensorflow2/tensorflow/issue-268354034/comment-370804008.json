{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/370804008", "html_url": "https://github.com/tensorflow/tensorflow/issues/13969#issuecomment-370804008", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13969", "id": 370804008, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MDgwNDAwOA==", "user": {"login": "StphMe", "id": 37112607, "node_id": "MDQ6VXNlcjM3MTEyNjA3", "avatar_url": "https://avatars1.githubusercontent.com/u/37112607?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StphMe", "html_url": "https://github.com/StphMe", "followers_url": "https://api.github.com/users/StphMe/followers", "following_url": "https://api.github.com/users/StphMe/following{/other_user}", "gists_url": "https://api.github.com/users/StphMe/gists{/gist_id}", "starred_url": "https://api.github.com/users/StphMe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StphMe/subscriptions", "organizations_url": "https://api.github.com/users/StphMe/orgs", "repos_url": "https://api.github.com/users/StphMe/repos", "events_url": "https://api.github.com/users/StphMe/events{/privacy}", "received_events_url": "https://api.github.com/users/StphMe/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-06T14:45:09Z", "updated_at": "2018-03-06T14:45:09Z", "author_association": "NONE", "body_html": "<p>I encounter the same issue currently but not only for LSTMS.</p>\n<p>When you train an arbitrary convolutional network, that needs fixed image size inputs (i.e. it has a dense layer inside) with images from a <code>dataset</code> object, you can use the function <code>dataset.padded_batch</code> with <code>None</code> or <code>-1</code> at the corresponding places to pad your data with some constant values according to the biggest dimension in the batch. However the type of padding is not customizable. As described above, the values (i.e. zeros) are places on the right and the bottom of the image:</p>\n<p>A picture with<br>\n[[1,1,1,1]<br>\n[1,1,1,1]<br>\n[1,1,1,1]<br>\n[1,1,1,1]]</p>\n<p>padded by 2 would look like:<br>\n[[1,1,1,1,0,0]<br>\n[1,1,1,1,0,0]<br>\n[1,1,1,1,0,0]<br>\n[1,1,1,1,0,0]<br>\n[0,0,0,0,0,0]<br>\n[0,0,0,0,0,0]]</p>\n<p>The problem now is, that if you train a network with images padded like this, that net will learn eventually that the right and bottom part of the input is not very contributing to the classification or labeling of the image, so the weights referring to the receptive field of the black border will be more neglected by the net.<br>\nDuring inference time, we the classifier will be presented only with image without this border, which means, that we'll get worse accuracy if important image features lay on the right and bottom side of the picture.<br>\nThis effect could be minimized in 2 possible ways:<br>\n1.: Center padding.<br>\ni.e. creating a picture like this:<br>\n[[0,0,0,0,0,0]<br>\n[0,1,1,1,1,0]<br>\n[0,1,1,1,1,0]<br>\n[0,1,1,1,1,0]<br>\n[0,1,1,1,1,0]<br>\n[0,0,0,0,0,0]]<br>\nIn this \"<em>centered</em>\" padded image the receptive field of neurons will see more of the picture at the borders and therefore reduce the described effect.<br>\nNote: this is similar to the suggestion of <strong>jpuigcerver</strong> above.</p>\n<p>2.: Mirror padding<br>\nThe image is padded as before to the right and bottom if necessary. But the values are not constant but mirrored from the input image.<br>\ni.e for an input picture:<br>\n[[1,2,3,4]<br>\n[1,2,3,4]<br>\n[1,2,3,4]<br>\n[2,2,2,4]]<br>\nmirrored batch would create a picture like:<br>\n[[1,2,3,4,4,3]<br>\n[1,2,3,4,4,3]<br>\n[1,2,3,4,4,3]<br>\n[2,2,2,4,4,2]<br>\n[2,2,2,4,4,2]<br>\n[2,2,2,4,4,2]]</p>\n<p>I think these features would really help improving the output of the network when feeding it padded images.</p>\n<p>I would appreciate to reopen this issue.</p>", "body_text": "I encounter the same issue currently but not only for LSTMS.\nWhen you train an arbitrary convolutional network, that needs fixed image size inputs (i.e. it has a dense layer inside) with images from a dataset object, you can use the function dataset.padded_batch with None or -1 at the corresponding places to pad your data with some constant values according to the biggest dimension in the batch. However the type of padding is not customizable. As described above, the values (i.e. zeros) are places on the right and the bottom of the image:\nA picture with\n[[1,1,1,1]\n[1,1,1,1]\n[1,1,1,1]\n[1,1,1,1]]\npadded by 2 would look like:\n[[1,1,1,1,0,0]\n[1,1,1,1,0,0]\n[1,1,1,1,0,0]\n[1,1,1,1,0,0]\n[0,0,0,0,0,0]\n[0,0,0,0,0,0]]\nThe problem now is, that if you train a network with images padded like this, that net will learn eventually that the right and bottom part of the input is not very contributing to the classification or labeling of the image, so the weights referring to the receptive field of the black border will be more neglected by the net.\nDuring inference time, we the classifier will be presented only with image without this border, which means, that we'll get worse accuracy if important image features lay on the right and bottom side of the picture.\nThis effect could be minimized in 2 possible ways:\n1.: Center padding.\ni.e. creating a picture like this:\n[[0,0,0,0,0,0]\n[0,1,1,1,1,0]\n[0,1,1,1,1,0]\n[0,1,1,1,1,0]\n[0,1,1,1,1,0]\n[0,0,0,0,0,0]]\nIn this \"centered\" padded image the receptive field of neurons will see more of the picture at the borders and therefore reduce the described effect.\nNote: this is similar to the suggestion of jpuigcerver above.\n2.: Mirror padding\nThe image is padded as before to the right and bottom if necessary. But the values are not constant but mirrored from the input image.\ni.e for an input picture:\n[[1,2,3,4]\n[1,2,3,4]\n[1,2,3,4]\n[2,2,2,4]]\nmirrored batch would create a picture like:\n[[1,2,3,4,4,3]\n[1,2,3,4,4,3]\n[1,2,3,4,4,3]\n[2,2,2,4,4,2]\n[2,2,2,4,4,2]\n[2,2,2,4,4,2]]\nI think these features would really help improving the output of the network when feeding it padded images.\nI would appreciate to reopen this issue.", "body": "I encounter the same issue currently but not only for LSTMS.\r\n\r\nWhen you train an arbitrary convolutional network, that needs fixed image size inputs (i.e. it has a dense layer inside) with images from a `dataset` object, you can use the function `dataset.padded_batch` with `None` or `-1` at the corresponding places to pad your data with some constant values according to the biggest dimension in the batch. However the type of padding is not customizable. As described above, the values (i.e. zeros) are places on the right and the bottom of the image:\r\n\r\nA picture with \r\n[[1,1,1,1]\r\n [1,1,1,1]\r\n [1,1,1,1]\r\n [1,1,1,1]]\r\n\r\npadded by 2 would look like:\r\n[[1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [0,0,0,0,0,0]\r\n [0,0,0,0,0,0]]\r\n\r\nThe problem now is, that if you train a network with images padded like this, that net will learn eventually that the right and bottom part of the input is not very contributing to the classification or labeling of the image, so the weights referring to the receptive field of the black border will be more neglected by the net.\r\nDuring inference time, we the classifier will be presented only with image without this border, which means, that we'll get worse accuracy if important image features lay on the right and bottom side of the picture.\r\nThis effect could be minimized in 2 possible ways:\r\n1.: Center padding.\r\ni.e. creating a picture like this:\r\n[[0,0,0,0,0,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,0,0,0,0,0]]\r\nIn this \"_centered_\" padded image the receptive field of neurons will see more of the picture at the borders and therefore reduce the described effect.\r\nNote: this is similar to the suggestion of **jpuigcerver** above.\r\n\r\n2.: Mirror padding\r\nThe image is padded as before to the right and bottom if necessary. But the values are not constant but mirrored from the input image.\r\ni.e for an input picture:\r\n[[1,2,3,4]\r\n [1,2,3,4]\r\n [1,2,3,4]\r\n [2,2,2,4]]\r\nmirrored batch would create a picture like:\r\n[[1,2,3,4,4,3]\r\n [1,2,3,4,4,3]\r\n [1,2,3,4,4,3]\r\n [2,2,2,4,4,2]\r\n [2,2,2,4,4,2]\r\n [2,2,2,4,4,2]]\r\n\r\nI think these features would really help improving the output of the network when feeding it padded images.\r\n\r\nI would appreciate to reopen this issue."}