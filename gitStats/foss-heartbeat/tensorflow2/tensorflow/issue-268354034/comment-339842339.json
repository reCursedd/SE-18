{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339842339", "html_url": "https://github.com/tensorflow/tensorflow/issues/13969#issuecomment-339842339", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13969", "id": 339842339, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTg0MjMzOQ==", "user": {"login": "jpuigcerver", "id": 656080, "node_id": "MDQ6VXNlcjY1NjA4MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/656080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpuigcerver", "html_url": "https://github.com/jpuigcerver", "followers_url": "https://api.github.com/users/jpuigcerver/followers", "following_url": "https://api.github.com/users/jpuigcerver/following{/other_user}", "gists_url": "https://api.github.com/users/jpuigcerver/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpuigcerver/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpuigcerver/subscriptions", "organizations_url": "https://api.github.com/users/jpuigcerver/orgs", "repos_url": "https://api.github.com/users/jpuigcerver/repos", "events_url": "https://api.github.com/users/jpuigcerver/events{/privacy}", "received_events_url": "https://api.github.com/users/jpuigcerver/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-27T00:56:35Z", "updated_at": "2017-10-27T17:27:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Indeed, there are different ways of padding. I think that in most of cases, especially when your operations are able to deal with variable sizes within each batch, you are just fine with the current features of PaddedBatchDataset.</p>\n<p>However, when some of your operations assume that all the examples in the minibatch have the same shape (e.g. LSTM wrapper for cudnn's LSTM), it is very useful to align the examples to share the same center coordinates. This is actually the problem that I'm facing now.</p>\n<p>Some practical use cases:<br>\nA dataset containing three tensors of different sizes: <code>[ [1, 1, 1, 1], [2, 2], [3] ]</code></p>\n<ul>\n<li><strong>Current padding:</strong></li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>dataset.padded_batch(<span class=\"pl-c1\">2</span>, [<span class=\"pl-c1\">None</span>])</pre></div>\n<p>would produce:</p>\n<div class=\"highlight highlight-source-python\"><pre>[ [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>],\n  [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n  [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>] ]</pre></div>\n<ul>\n<li><strong>Centered padding:</strong></li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>dataset.padded_batch(<span class=\"pl-c1\">2</span>, [<span class=\"pl-c1\">None</span>], <span class=\"pl-v\">centered</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>would produce something like:</p>\n<div class=\"highlight highlight-source-python\"><pre>[ [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>],\n  [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>],\n  [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>] ]</pre></div>\n<p>Of course one can think of many other alignment strategies. For instance, aligning to the right. However, this can be generally implemented with the current padding and pre/post map() operations.</p>\n<p>However <em>relative</em> alignments (the centered case that I just showed is a special case of a relative alignment) cannot be implemented with the current API, but I can't think of any practical case where handling generic relative alignments would be useful.</p>\n<p>That's why I suggested to simply add a boolean flag to the PaddedBatchDataset class to deal with the centering. This will keep the API clean, and would cover most practical use cases that I can think of.</p>", "body_text": "Indeed, there are different ways of padding. I think that in most of cases, especially when your operations are able to deal with variable sizes within each batch, you are just fine with the current features of PaddedBatchDataset.\nHowever, when some of your operations assume that all the examples in the minibatch have the same shape (e.g. LSTM wrapper for cudnn's LSTM), it is very useful to align the examples to share the same center coordinates. This is actually the problem that I'm facing now.\nSome practical use cases:\nA dataset containing three tensors of different sizes: [ [1, 1, 1, 1], [2, 2], [3] ]\n\nCurrent padding:\n\ndataset.padded_batch(2, [None])\nwould produce:\n[ [1, 1, 1, 1],\n  [2, 2, 0, 0],\n  [3, 0, 0, 0] ]\n\nCentered padding:\n\ndataset.padded_batch(2, [None], centered=True)\nwould produce something like:\n[ [1, 1, 1, 1],\n  [0, 2, 2, 0],\n  [0, 3, 0, 0] ]\nOf course one can think of many other alignment strategies. For instance, aligning to the right. However, this can be generally implemented with the current padding and pre/post map() operations.\nHowever relative alignments (the centered case that I just showed is a special case of a relative alignment) cannot be implemented with the current API, but I can't think of any practical case where handling generic relative alignments would be useful.\nThat's why I suggested to simply add a boolean flag to the PaddedBatchDataset class to deal with the centering. This will keep the API clean, and would cover most practical use cases that I can think of.", "body": "Indeed, there are different ways of padding. I think that in most of cases, especially when your operations are able to deal with variable sizes within each batch, you are just fine with the current features of PaddedBatchDataset.\r\n\r\nHowever, when some of your operations assume that all the examples in the minibatch have the same shape (e.g. LSTM wrapper for cudnn's LSTM), it is very useful to align the examples to share the same center coordinates. This is actually the problem that I'm facing now.\r\n\r\nSome practical use cases:\r\nA dataset containing three tensors of different sizes: ```[ [1, 1, 1, 1], [2, 2], [3] ]```\r\n\r\n- **Current padding:**\r\n```python\r\ndataset.padded_batch(2, [None])\r\n```\r\nwould produce:\r\n```python\r\n[ [1, 1, 1, 1],\r\n  [2, 2, 0, 0],\r\n  [3, 0, 0, 0] ]\r\n```\r\n\r\n- **Centered padding:**\r\n```python\r\ndataset.padded_batch(2, [None], centered=True)\r\n```\r\nwould produce something like:\r\n```python\r\n[ [1, 1, 1, 1],\r\n  [0, 2, 2, 0],\r\n  [0, 3, 0, 0] ]\r\n```\r\nOf course one can think of many other alignment strategies. For instance, aligning to the right. However, this can be generally implemented with the current padding and pre/post map() operations.\r\n\r\nHowever *relative* alignments (the centered case that I just showed is a special case of a relative alignment) cannot be implemented with the current API, but I can't think of any practical case where handling generic relative alignments would be useful.\r\n\r\nThat's why I suggested to simply add a boolean flag to the PaddedBatchDataset class to deal with the centering. This will keep the API clean, and would cover most practical use cases that I can think of.\r\n"}