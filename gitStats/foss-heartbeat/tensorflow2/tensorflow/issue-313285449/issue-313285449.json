{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18415", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18415/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18415/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18415/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18415", "id": 313285449, "node_id": "MDU6SXNzdWUzMTMyODU0NDk=", "number": 18415, "title": "A bug related to conv2d_transpose and tf.cond", "user": {"login": "fengyang0317", "id": 7965501, "node_id": "MDQ6VXNlcjc5NjU1MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/7965501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fengyang0317", "html_url": "https://github.com/fengyang0317", "followers_url": "https://api.github.com/users/fengyang0317/followers", "following_url": "https://api.github.com/users/fengyang0317/following{/other_user}", "gists_url": "https://api.github.com/users/fengyang0317/gists{/gist_id}", "starred_url": "https://api.github.com/users/fengyang0317/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fengyang0317/subscriptions", "organizations_url": "https://api.github.com/users/fengyang0317/orgs", "repos_url": "https://api.github.com/users/fengyang0317/repos", "events_url": "https://api.github.com/users/fengyang0317/events{/privacy}", "received_events_url": "https://api.github.com/users/fengyang0317/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-11T11:35:18Z", "updated_at": "2018-11-22T18:55:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 7.0</li>\n<li><strong>GPU model and memory</strong>: GTX 980M / 4G</li>\n<li><strong>Exact command to reproduce</strong>: python the_following_code.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to implement a model named progressive GAN. I met some very weird problems. My problems could be reproduced by the following code. I believe it is a bug of tensorflow because removing any trivial tf.cond or removing conv2d_transpose will make the code work.</p>\n<pre><code>  File \"/home/yfeng23/test/tf/cond_test1.py\", line 38, in &lt;module&gt;\n    net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\n  File \"/home/yfeng23/test/tf/cond_test1.py\", line 12, in upscale2d\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2097152 values, but the requested shape has 524288\n\t [[Node: Upscale2D_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Upscale2D_1/Tile, Upscale2D_1/Reshape/shape)]]\n</code></pre>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n\ndef upscale2d(x, factor=2):\n  \"\"\"increase the resolution\"\"\"\n  with tf.variable_scope('Upscale2D'):\n    channels = x.shape[-1]\n    s = tf.shape(x)\n    x = tf.expand_dims(tf.expand_dims(x, axis=3), axis=2)\n    x = tf.tile(x, [1, 1, factor, 1, factor, 1])\n    x = tf.reshape(x, [s[0], s[1] * factor, s[2] * factor, channels])\n    return x\n\n\ndef to_rgb(x, lod, num_outputs):\n  \"\"\"generate image output\"\"\"\n  with tf.variable_scope('ToRGB_lod%d' % lod):\n    return slim.conv2d(x, num_outputs, 1, activation_fn=None)\n\n\nbatch_size = 16\nnum_outputs = 3\nnoise = tf.random_normal([batch_size, 128])\nwith slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n                    activation_fn=tf.nn.leaky_relu):\n  net = tf.expand_dims(tf.expand_dims(noise, 1), 1)\n  net = slim.conv2d_transpose(net, 512, kernel_size=4, padding='VALID')         # net.shape = [16, 4, 4, 512]\n  net0 = net\n  net_out = (net, tf.zeros([batch_size, 2, 2, 3]))                              # ([16, 4, 4, 512], [16, 2, 2, 3])\n\n  out = to_rgb(net_out[0], 1, num_outputs)                                      # out.shape = [16, 4, 4, 3]\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 8, 8, 512]\n  net_out = tf.cond(tf.less(0, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\n\n  with tf.control_dependencies([tf.assert_equal(tf.shape(net_out[0])[1], 8)]):\n    out = to_rgb(net_out[0], 2, num_outputs)                                    # out.shape = [16, 8, 8, 3]\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\n  net = slim.conv2d(net, 512, 3, scope='conv1')\n  #net_out = tf.cond(tf.less(3, 4), lambda: net_out, lambda: (net, out))\n  net_out = tf.cond(tf.less(3, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\n\n  out = to_rgb(net_out[0], 3, num_outputs)                                      # out.shape = [16, 8, 8, 3]\n  up_out = upscale2d(net_out[1])                                                # out_up.shape = [16, 8, 8, 3]\n  net = tf.cond(tf.equal(0.0, 0.0), lambda: out, lambda: up_out + out)\n\nloss = tf.reduce_mean(net)\ngrad0 = tf.gradients(loss, net0)[0]\ngrad1 = tf.gradients(loss, noise)[0]\nwith tf.Session() as sess:\n  sess.run(tf.global_variables_initializer())\n  print(sess.run(net).shape)\n  print(sess.run(grad0).shape)\n  print(sess.run(grad1).shape)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7.0\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 7.0\nGPU model and memory: GTX 980M / 4G\nExact command to reproduce: python the_following_code.py\n\nDescribe the problem\nI am trying to implement a model named progressive GAN. I met some very weird problems. My problems could be reproduced by the following code. I believe it is a bug of tensorflow because removing any trivial tf.cond or removing conv2d_transpose will make the code work.\n  File \"/home/yfeng23/test/tf/cond_test1.py\", line 38, in <module>\n    net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\n  File \"/home/yfeng23/test/tf/cond_test1.py\", line 12, in upscale2d\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2097152 values, but the requested shape has 524288\n\t [[Node: Upscale2D_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Upscale2D_1/Tile, Upscale2D_1/Reshape/shape)]]\n\nSource code / logs\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n\ndef upscale2d(x, factor=2):\n  \"\"\"increase the resolution\"\"\"\n  with tf.variable_scope('Upscale2D'):\n    channels = x.shape[-1]\n    s = tf.shape(x)\n    x = tf.expand_dims(tf.expand_dims(x, axis=3), axis=2)\n    x = tf.tile(x, [1, 1, factor, 1, factor, 1])\n    x = tf.reshape(x, [s[0], s[1] * factor, s[2] * factor, channels])\n    return x\n\n\ndef to_rgb(x, lod, num_outputs):\n  \"\"\"generate image output\"\"\"\n  with tf.variable_scope('ToRGB_lod%d' % lod):\n    return slim.conv2d(x, num_outputs, 1, activation_fn=None)\n\n\nbatch_size = 16\nnum_outputs = 3\nnoise = tf.random_normal([batch_size, 128])\nwith slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n                    activation_fn=tf.nn.leaky_relu):\n  net = tf.expand_dims(tf.expand_dims(noise, 1), 1)\n  net = slim.conv2d_transpose(net, 512, kernel_size=4, padding='VALID')         # net.shape = [16, 4, 4, 512]\n  net0 = net\n  net_out = (net, tf.zeros([batch_size, 2, 2, 3]))                              # ([16, 4, 4, 512], [16, 2, 2, 3])\n\n  out = to_rgb(net_out[0], 1, num_outputs)                                      # out.shape = [16, 4, 4, 3]\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 8, 8, 512]\n  net_out = tf.cond(tf.less(0, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\n\n  with tf.control_dependencies([tf.assert_equal(tf.shape(net_out[0])[1], 8)]):\n    out = to_rgb(net_out[0], 2, num_outputs)                                    # out.shape = [16, 8, 8, 3]\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\n  net = slim.conv2d(net, 512, 3, scope='conv1')\n  #net_out = tf.cond(tf.less(3, 4), lambda: net_out, lambda: (net, out))\n  net_out = tf.cond(tf.less(3, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\n\n  out = to_rgb(net_out[0], 3, num_outputs)                                      # out.shape = [16, 8, 8, 3]\n  up_out = upscale2d(net_out[1])                                                # out_up.shape = [16, 8, 8, 3]\n  net = tf.cond(tf.equal(0.0, 0.0), lambda: out, lambda: up_out + out)\n\nloss = tf.reduce_mean(net)\ngrad0 = tf.gradients(loss, net0)[0]\ngrad1 = tf.gradients(loss, noise)[0]\nwith tf.Session() as sess:\n  sess.run(tf.global_variables_initializer())\n  print(sess.run(net).shape)\n  print(sess.run(grad0).shape)\n  print(sess.run(grad1).shape)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 7.0\r\n- **GPU model and memory**: GTX 980M / 4G\r\n- **Exact command to reproduce**: python the_following_code.py\r\n\r\n### Describe the problem\r\nI am trying to implement a model named progressive GAN. I met some very weird problems. My problems could be reproduced by the following code. I believe it is a bug of tensorflow because removing any trivial tf.cond or removing conv2d_transpose will make the code work.\r\n\r\n\r\n```\r\n  File \"/home/yfeng23/test/tf/cond_test1.py\", line 38, in <module>\r\n    net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\r\n  File \"/home/yfeng23/test/tf/cond_test1.py\", line 12, in upscale2d\r\n\r\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2097152 values, but the requested shape has 524288\r\n\t [[Node: Upscale2D_1/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Upscale2D_1/Tile, Upscale2D_1/Reshape/shape)]]\r\n```\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\n\r\n\r\ndef upscale2d(x, factor=2):\r\n  \"\"\"increase the resolution\"\"\"\r\n  with tf.variable_scope('Upscale2D'):\r\n    channels = x.shape[-1]\r\n    s = tf.shape(x)\r\n    x = tf.expand_dims(tf.expand_dims(x, axis=3), axis=2)\r\n    x = tf.tile(x, [1, 1, factor, 1, factor, 1])\r\n    x = tf.reshape(x, [s[0], s[1] * factor, s[2] * factor, channels])\r\n    return x\r\n\r\n\r\ndef to_rgb(x, lod, num_outputs):\r\n  \"\"\"generate image output\"\"\"\r\n  with tf.variable_scope('ToRGB_lod%d' % lod):\r\n    return slim.conv2d(x, num_outputs, 1, activation_fn=None)\r\n\r\n\r\nbatch_size = 16\r\nnum_outputs = 3\r\nnoise = tf.random_normal([batch_size, 128])\r\nwith slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\r\n                    activation_fn=tf.nn.leaky_relu):\r\n  net = tf.expand_dims(tf.expand_dims(noise, 1), 1)\r\n  net = slim.conv2d_transpose(net, 512, kernel_size=4, padding='VALID')         # net.shape = [16, 4, 4, 512]\r\n  net0 = net\r\n  net_out = (net, tf.zeros([batch_size, 2, 2, 3]))                              # ([16, 4, 4, 512], [16, 2, 2, 3])\r\n\r\n  out = to_rgb(net_out[0], 1, num_outputs)                                      # out.shape = [16, 4, 4, 3]\r\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 8, 8, 512]\r\n  net_out = tf.cond(tf.less(0, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\r\n\r\n  with tf.control_dependencies([tf.assert_equal(tf.shape(net_out[0])[1], 8)]):\r\n    out = to_rgb(net_out[0], 2, num_outputs)                                    # out.shape = [16, 8, 8, 3]\r\n  net = upscale2d(net_out[0])                                                   # net.shape = [16, 16, 16, 512]\r\n  net = slim.conv2d(net, 512, 3, scope='conv1')\r\n  #net_out = tf.cond(tf.less(3, 4), lambda: net_out, lambda: (net, out))\r\n  net_out = tf.cond(tf.less(3, 1), lambda: (net, out), lambda: net_out)         # ([16, 8, 8, 512], [16, 4, 4, 3])\r\n\r\n  out = to_rgb(net_out[0], 3, num_outputs)                                      # out.shape = [16, 8, 8, 3]\r\n  up_out = upscale2d(net_out[1])                                                # out_up.shape = [16, 8, 8, 3]\r\n  net = tf.cond(tf.equal(0.0, 0.0), lambda: out, lambda: up_out + out)\r\n\r\nloss = tf.reduce_mean(net)\r\ngrad0 = tf.gradients(loss, net0)[0]\r\ngrad1 = tf.gradients(loss, noise)[0]\r\nwith tf.Session() as sess:\r\n  sess.run(tf.global_variables_initializer())\r\n  print(sess.run(net).shape)\r\n  print(sess.run(grad0).shape)\r\n  print(sess.run(grad1).shape)\r\n```\r\n"}