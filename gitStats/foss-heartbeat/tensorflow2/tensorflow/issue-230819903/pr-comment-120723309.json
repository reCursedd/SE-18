{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/120723309", "pull_request_review_id": 42710623, "id": 120723309, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMDcyMzMwOQ==", "diff_hunk": "@@ -2099,6 +2100,10 @@ def __init__(self,\n       file_pattern: File path to the dataset, possibly containing wildcards.\n         All matching files will be iterated over each epoch.\n       batch_size: How many records to return at a time.\n+      minibatches: None by default, otherwise specifies", "path": "tensorflow/python/ops/data_flow_ops.py", "position": null, "original_position": 12, "commit_id": "4af5ca8a59917f3f5c4d213719d468ac7990731c", "original_commit_id": "6d54315a47b65e5c57a0a7f8c24a413b03655bbe", "user": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "body": "There could still be a larger concept of batch size assuming there are multiple machines involved, which is why I think the least ambiguous option is to use batch size to describe either the largest or smallest grouping.\r\n\r\nPerhaps we can slip the issue by avoiding ML terminology all together, since really we're just trying to ask for N groups of size K.\r\n\r\nrecords_per_group\r\nnum_groups", "created_at": "2017-06-07T19:31:21Z", "updated_at": "2017-06-09T21:27:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/10143#discussion_r120723309", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10143", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/120723309"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/10143#discussion_r120723309"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10143"}}, "body_html": "<p>There could still be a larger concept of batch size assuming there are multiple machines involved, which is why I think the least ambiguous option is to use batch size to describe either the largest or smallest grouping.</p>\n<p>Perhaps we can slip the issue by avoiding ML terminology all together, since really we're just trying to ask for N groups of size K.</p>\n<p>records_per_group<br>\nnum_groups</p>", "body_text": "There could still be a larger concept of batch size assuming there are multiple machines involved, which is why I think the least ambiguous option is to use batch size to describe either the largest or smallest grouping.\nPerhaps we can slip the issue by avoiding ML terminology all together, since really we're just trying to ask for N groups of size K.\nrecords_per_group\nnum_groups", "in_reply_to_id": 120429426}