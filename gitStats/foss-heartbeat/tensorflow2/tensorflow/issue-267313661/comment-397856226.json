{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397856226", "html_url": "https://github.com/tensorflow/tensorflow/issues/13869#issuecomment-397856226", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13869", "id": 397856226, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Nzg1NjIyNg==", "user": {"login": "tahsmith", "id": 2762951, "node_id": "MDQ6VXNlcjI3NjI5NTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/2762951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tahsmith", "html_url": "https://github.com/tahsmith", "followers_url": "https://api.github.com/users/tahsmith/followers", "following_url": "https://api.github.com/users/tahsmith/following{/other_user}", "gists_url": "https://api.github.com/users/tahsmith/gists{/gist_id}", "starred_url": "https://api.github.com/users/tahsmith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tahsmith/subscriptions", "organizations_url": "https://api.github.com/users/tahsmith/orgs", "repos_url": "https://api.github.com/users/tahsmith/repos", "events_url": "https://api.github.com/users/tahsmith/events{/privacy}", "received_events_url": "https://api.github.com/users/tahsmith/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-17T05:40:54Z", "updated_at": "2018-06-17T05:44:20Z", "author_association": "NONE", "body_html": "<p>Hi all,</p>\n<p>I've run into this issue, also doing an autoencoder type task. I've reduced it to a simple case, below.</p>\n<p>This does not seem <em>just</em> about the batch count. In this example filter_width &lt; 4 and filter_stride &lt; 1 will still work.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ninput_width <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\nin_channels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\nout_channels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\nfilter_width <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\nfilter_stride <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\nn_samples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">65536</span>\n\nx <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, input_width, in_channels])\n\nx_2d <span class=\"pl-k\">=</span> tf.reshape(x, [tf.shape(x)[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">1</span>, input_width, in_channels])\n\nl1 <span class=\"pl-k\">=</span> tf.layers.conv2d(\n    x_2d,\n    out_channels,\n    [<span class=\"pl-c1\">1</span>, filter_width],\n    [<span class=\"pl-c1\">1</span>, filter_stride],\n    <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>\n)\n\nl2 <span class=\"pl-k\">=</span> tf.layers.conv2d_transpose(\n    l1,\n    in_channels,\n    [<span class=\"pl-c1\">1</span>, filter_width],\n    [<span class=\"pl-c1\">1</span>, filter_stride],\n    <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>\n)\n\ny <span class=\"pl-k\">=</span> tf.reshape(l2, [tf.shape(l2)[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, in_channels])\n\nx_samples <span class=\"pl-k\">=</span> np.random.randn(n_samples, input_width, <span class=\"pl-c1\">1</span>)\n\nminimise <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(tf.reduce_sum(tf.square(x <span class=\"pl-k\">-</span> y)))\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n    session.run(tf.global_variables_initializer())\n    session.run(minimise, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x: x_samples})\n</pre></div>", "body_text": "Hi all,\nI've run into this issue, also doing an autoencoder type task. I've reduced it to a simple case, below.\nThis does not seem just about the batch count. In this example filter_width < 4 and filter_stride < 1 will still work.\nimport tensorflow as tf\nimport numpy as np\n\ninput_width = 1000\nin_channels = 1\nout_channels = 1\nfilter_width = 5\nfilter_stride = 2\nn_samples = 65536\n\nx = tf.placeholder(tf.float32, [None, input_width, in_channels])\n\nx_2d = tf.reshape(x, [tf.shape(x)[0], 1, input_width, in_channels])\n\nl1 = tf.layers.conv2d(\n    x_2d,\n    out_channels,\n    [1, filter_width],\n    [1, filter_stride],\n    padding='same'\n)\n\nl2 = tf.layers.conv2d_transpose(\n    l1,\n    in_channels,\n    [1, filter_width],\n    [1, filter_stride],\n    padding='same'\n)\n\ny = tf.reshape(l2, [tf.shape(l2)[0], -1, in_channels])\n\nx_samples = np.random.randn(n_samples, input_width, 1)\n\nminimise = tf.train.AdamOptimizer().minimize(tf.reduce_sum(tf.square(x - y)))\n\nwith tf.Session() as session:\n    session.run(tf.global_variables_initializer())\n    session.run(minimise, feed_dict={x: x_samples})", "body": "Hi all,\r\n\r\nI've run into this issue, also doing an autoencoder type task. I've reduced it to a simple case, below.\r\n\r\nThis does not seem *just* about the batch count. In this example filter_width < 4 and filter_stride < 1 will still work.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninput_width = 1000\r\nin_channels = 1\r\nout_channels = 1\r\nfilter_width = 5\r\nfilter_stride = 2\r\nn_samples = 65536\r\n\r\nx = tf.placeholder(tf.float32, [None, input_width, in_channels])\r\n\r\nx_2d = tf.reshape(x, [tf.shape(x)[0], 1, input_width, in_channels])\r\n\r\nl1 = tf.layers.conv2d(\r\n    x_2d,\r\n    out_channels,\r\n    [1, filter_width],\r\n    [1, filter_stride],\r\n    padding='same'\r\n)\r\n\r\nl2 = tf.layers.conv2d_transpose(\r\n    l1,\r\n    in_channels,\r\n    [1, filter_width],\r\n    [1, filter_stride],\r\n    padding='same'\r\n)\r\n\r\ny = tf.reshape(l2, [tf.shape(l2)[0], -1, in_channels])\r\n\r\nx_samples = np.random.randn(n_samples, input_width, 1)\r\n\r\nminimise = tf.train.AdamOptimizer().minimize(tf.reduce_sum(tf.square(x - y)))\r\n\r\nwith tf.Session() as session:\r\n    session.run(tf.global_variables_initializer())\r\n    session.run(minimise, feed_dict={x: x_samples})\r\n\r\n```"}