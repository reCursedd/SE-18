{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/244048259", "html_url": "https://github.com/tensorflow/tensorflow/issues/4128#issuecomment-244048259", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4128", "id": 244048259, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NDA0ODI1OQ==", "user": {"login": "Hvass-Labs", "id": 13588114, "node_id": "MDQ6VXNlcjEzNTg4MTE0", "avatar_url": "https://avatars2.githubusercontent.com/u/13588114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hvass-Labs", "html_url": "https://github.com/Hvass-Labs", "followers_url": "https://api.github.com/users/Hvass-Labs/followers", "following_url": "https://api.github.com/users/Hvass-Labs/following{/other_user}", "gists_url": "https://api.github.com/users/Hvass-Labs/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hvass-Labs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hvass-Labs/subscriptions", "organizations_url": "https://api.github.com/users/Hvass-Labs/orgs", "repos_url": "https://api.github.com/users/Hvass-Labs/repos", "events_url": "https://api.github.com/users/Hvass-Labs/events{/privacy}", "received_events_url": "https://api.github.com/users/Hvass-Labs/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-01T11:12:16Z", "updated_at": "2016-09-01T11:12:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for the quick answer.</p>\n<p>(1) Just to clarify the question a bit. After having loaded the graph in my own code, if I print the softmax-tensor then the shape is (1, 1008):</p>\n<pre><code>print(graph.get_tensor_by_name('softmax:0'))\n</code></pre>\n<blockquote>\n<p>Tensor(\"softmax:0\", shape=(1, 1008), dtype=float32)</p>\n</blockquote>\n<p>But in the file <code>imagenet_2012_challenge_label_map_proto.pbtxt</code> the class-numbers range from 1 to 1000 (both inclusive). So there's apparently only 1000 possible classes in the data-set, but the softmax has 1008 output-classes. It seems strange to me and it must mean that we should ignore 8 of the classes from the softmax-ouput - but which ones?</p>\n<p>(2) I can't seem to find the image resizing in <code>classify_image.py</code> so I wonder if the resizing is done implicitly inside the TensorFlow graph that is being restored? It's also not clear what happens to the images; are they resized or cropped? using what algorithm? what if they're too small, are they then just padded?</p>\n<p>(3) Would it be possible to always have an Inception model compatible with the latest TensorFlow version and stored under e.g.:</p>\n<p><a href=\"http://download.tensorflow.org/models/image/imagenet/inception-latest.tgz\" rel=\"nofollow\">http://download.tensorflow.org/models/image/imagenet/inception-latest.tgz</a></p>\n<p>Then I won't need to make any changes to my code when it is updated, as it will just be downloaded automatically. Or what would be the best way of doing this?</p>\n<p>Thanks again.</p>", "body_text": "Thanks for the quick answer.\n(1) Just to clarify the question a bit. After having loaded the graph in my own code, if I print the softmax-tensor then the shape is (1, 1008):\nprint(graph.get_tensor_by_name('softmax:0'))\n\n\nTensor(\"softmax:0\", shape=(1, 1008), dtype=float32)\n\nBut in the file imagenet_2012_challenge_label_map_proto.pbtxt the class-numbers range from 1 to 1000 (both inclusive). So there's apparently only 1000 possible classes in the data-set, but the softmax has 1008 output-classes. It seems strange to me and it must mean that we should ignore 8 of the classes from the softmax-ouput - but which ones?\n(2) I can't seem to find the image resizing in classify_image.py so I wonder if the resizing is done implicitly inside the TensorFlow graph that is being restored? It's also not clear what happens to the images; are they resized or cropped? using what algorithm? what if they're too small, are they then just padded?\n(3) Would it be possible to always have an Inception model compatible with the latest TensorFlow version and stored under e.g.:\nhttp://download.tensorflow.org/models/image/imagenet/inception-latest.tgz\nThen I won't need to make any changes to my code when it is updated, as it will just be downloaded automatically. Or what would be the best way of doing this?\nThanks again.", "body": "Thanks for the quick answer.\n\n(1) Just to clarify the question a bit. After having loaded the graph in my own code, if I print the softmax-tensor then the shape is (1, 1008):\n\n```\nprint(graph.get_tensor_by_name('softmax:0'))\n```\n\n> Tensor(\"softmax:0\", shape=(1, 1008), dtype=float32)\n\nBut in the file `imagenet_2012_challenge_label_map_proto.pbtxt` the class-numbers range from 1 to 1000 (both inclusive). So there's apparently only 1000 possible classes in the data-set, but the softmax has 1008 output-classes. It seems strange to me and it must mean that we should ignore 8 of the classes from the softmax-ouput - but which ones?\n\n(2) I can't seem to find the image resizing in `classify_image.py` so I wonder if the resizing is done implicitly inside the TensorFlow graph that is being restored? It's also not clear what happens to the images; are they resized or cropped? using what algorithm? what if they're too small, are they then just padded?\n\n(3) Would it be possible to always have an Inception model compatible with the latest TensorFlow version and stored under e.g.:\n\nhttp://download.tensorflow.org/models/image/imagenet/inception-latest.tgz\n\nThen I won't need to make any changes to my code when it is updated, as it will just be downloaded automatically. Or what would be the best way of doing this?\n\nThanks again.\n"}