{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/246337587", "html_url": "https://github.com/tensorflow/tensorflow/issues/4128#issuecomment-246337587", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4128", "id": 246337587, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NjMzNzU4Nw==", "user": {"login": "Hvass-Labs", "id": 13588114, "node_id": "MDQ6VXNlcjEzNTg4MTE0", "avatar_url": "https://avatars2.githubusercontent.com/u/13588114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hvass-Labs", "html_url": "https://github.com/Hvass-Labs", "followers_url": "https://api.github.com/users/Hvass-Labs/followers", "following_url": "https://api.github.com/users/Hvass-Labs/following{/other_user}", "gists_url": "https://api.github.com/users/Hvass-Labs/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hvass-Labs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hvass-Labs/subscriptions", "organizations_url": "https://api.github.com/users/Hvass-Labs/orgs", "repos_url": "https://api.github.com/users/Hvass-Labs/repos", "events_url": "https://api.github.com/users/Hvass-Labs/events{/privacy}", "received_events_url": "https://api.github.com/users/Hvass-Labs/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-12T12:52:55Z", "updated_at": "2016-09-12T12:52:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I found out that the problem with the strange labels predicted by the Inception model is indeed the classes and their names in the ImageNet data-set. This can be seen from e.g. the \"bow-tie\" label which causes the Inception model to classify people wearing bow-ties as \"bow-tie\" rather than e.g. \"man wearing bow-tie\"</p>\n<p><a href=\"http://image-net.org/synset?wnid=n02883205#\" rel=\"nofollow\">http://image-net.org/synset?wnid=n02883205#</a></p>\n<p>One solution would be to use the neural networks for generating captions, e.g. \"Man wearing tall hat, bow-tie and purple jacket.\" But I haven't gotten around to caption-generation yet and I suspect it's quite a bit more complicated to implement.</p>\n<p>I would still argue that ImageNet's classes are not completely meaningful, and perhaps the team that made the Inception model could make a much better data-set from the vast amounts of data that google has available, so the Inception model would work much better out-of-the-box, without the need for re-training or more complicated caption-generation techniques.</p>\n<p>As mentioned above, the Inception model thinks that a picture of Elon Musk shows either a sweat-shirt (20% score) or an abaya (17% score). If you change the resolution of the image, then Inception thinks it shows either a sweat-shirt or a cowboy-boot. If you ask people on the street what they think of the state-of-the-art in AI and image recognition developed by the world's leading scientists and engineers at google, and it gives results like this, well ... people are going to be amused :-)</p>\n<p>Just a few thoughts.</p>", "body_text": "I found out that the problem with the strange labels predicted by the Inception model is indeed the classes and their names in the ImageNet data-set. This can be seen from e.g. the \"bow-tie\" label which causes the Inception model to classify people wearing bow-ties as \"bow-tie\" rather than e.g. \"man wearing bow-tie\"\nhttp://image-net.org/synset?wnid=n02883205#\nOne solution would be to use the neural networks for generating captions, e.g. \"Man wearing tall hat, bow-tie and purple jacket.\" But I haven't gotten around to caption-generation yet and I suspect it's quite a bit more complicated to implement.\nI would still argue that ImageNet's classes are not completely meaningful, and perhaps the team that made the Inception model could make a much better data-set from the vast amounts of data that google has available, so the Inception model would work much better out-of-the-box, without the need for re-training or more complicated caption-generation techniques.\nAs mentioned above, the Inception model thinks that a picture of Elon Musk shows either a sweat-shirt (20% score) or an abaya (17% score). If you change the resolution of the image, then Inception thinks it shows either a sweat-shirt or a cowboy-boot. If you ask people on the street what they think of the state-of-the-art in AI and image recognition developed by the world's leading scientists and engineers at google, and it gives results like this, well ... people are going to be amused :-)\nJust a few thoughts.", "body": "I found out that the problem with the strange labels predicted by the Inception model is indeed the classes and their names in the ImageNet data-set. This can be seen from e.g. the \"bow-tie\" label which causes the Inception model to classify people wearing bow-ties as \"bow-tie\" rather than e.g. \"man wearing bow-tie\"\n\nhttp://image-net.org/synset?wnid=n02883205#\n\nOne solution would be to use the neural networks for generating captions, e.g. \"Man wearing tall hat, bow-tie and purple jacket.\" But I haven't gotten around to caption-generation yet and I suspect it's quite a bit more complicated to implement.\n\nI would still argue that ImageNet's classes are not completely meaningful, and perhaps the team that made the Inception model could make a much better data-set from the vast amounts of data that google has available, so the Inception model would work much better out-of-the-box, without the need for re-training or more complicated caption-generation techniques.\n\nAs mentioned above, the Inception model thinks that a picture of Elon Musk shows either a sweat-shirt (20% score) or an abaya (17% score). If you change the resolution of the image, then Inception thinks it shows either a sweat-shirt or a cowboy-boot. If you ask people on the street what they think of the state-of-the-art in AI and image recognition developed by the world's leading scientists and engineers at google, and it gives results like this, well ... people are going to be amused :-)\n\nJust a few thoughts.\n"}