{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252393017", "html_url": "https://github.com/tensorflow/tensorflow/issues/4766#issuecomment-252393017", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4766", "id": 252393017, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjM5MzAxNw==", "user": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-08T01:13:11Z", "updated_at": "2016-10-08T01:13:11Z", "author_association": "MEMBER", "body_html": "<p>@civilmanxx I see.  Ignore the <code>--input_saver</code> for now; I'm not sure whether that would help with your problem.</p>\n<p>One thing to check is to see whether the checkpoint actually has a value for <code>InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1</code>.  You can use <code>inspect_checkpoint</code> to do this.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py</a></p>\n<p>You'd do something like this:</p>\n<pre><code>$ bazel build tensorflow/python/tools:inspect_checkpoint\n$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293\n</code></pre>\n<p>That will dump out the tensors that are saved in the checkpoint.  I'm suspecting your checkpoint will not contain <code>InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1</code>.</p>\n<p>But that doesn't fix your problem.  One thing you might try is rather than picking the first checkpoint that becomes available, pick the last one after things have run for a while.  I don't actually expect this to help, but there's an off-chance that this might work.</p>\n<p>Otherwise it's possible that you simply can't change the optimizer when fine-tuning.</p>\n<p>Let me know how the above works out.</p>", "body_text": "@civilmanxx I see.  Ignore the --input_saver for now; I'm not sure whether that would help with your problem.\nOne thing to check is to see whether the checkpoint actually has a value for InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1.  You can use inspect_checkpoint to do this.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py\nYou'd do something like this:\n$ bazel build tensorflow/python/tools:inspect_checkpoint\n$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293\n\nThat will dump out the tensors that are saved in the checkpoint.  I'm suspecting your checkpoint will not contain InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1.\nBut that doesn't fix your problem.  One thing you might try is rather than picking the first checkpoint that becomes available, pick the last one after things have run for a while.  I don't actually expect this to help, but there's an off-chance that this might work.\nOtherwise it's possible that you simply can't change the optimizer when fine-tuning.\nLet me know how the above works out.", "body": "@civilmanxx I see.  Ignore the `--input_saver` for now; I'm not sure whether that would help with your problem.\n\nOne thing to check is to see whether the checkpoint actually has a value for `InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1`.  You can use `inspect_checkpoint` to do this.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py\n\nYou'd do something like this:\n\n```\n$ bazel build tensorflow/python/tools:inspect_checkpoint\n$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293\n```\n\nThat will dump out the tensors that are saved in the checkpoint.  I'm suspecting your checkpoint will not contain `InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1`.\n\nBut that doesn't fix your problem.  One thing you might try is rather than picking the first checkpoint that becomes available, pick the last one after things have run for a while.  I don't actually expect this to help, but there's an off-chance that this might work.\n\nOtherwise it's possible that you simply can't change the optimizer when fine-tuning.\n\nLet me know how the above works out.\n"}