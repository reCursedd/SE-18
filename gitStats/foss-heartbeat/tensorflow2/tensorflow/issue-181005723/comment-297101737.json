{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/297101737", "html_url": "https://github.com/tensorflow/tensorflow/issues/4766#issuecomment-297101737", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4766", "id": 297101737, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzEwMTczNw==", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-25T17:15:51Z", "updated_at": "2017-04-25T17:50:09Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11551745\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SubhashKsr\">@SubhashKsr</a> if you want to get the node names of graph file, which is .pb file (not ckpt, there are different), use the following code:</p>\n<pre><code>for node in tf.get_default_graph().as_graph_def().node:\n       print (node.name)\n</code></pre>\n<p>as you see in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L261\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L261</a></p>\n<p>classify_image_graph_def.pb is the file for inception v3. you need to download inception5h.zip which contain inception v1 .pb file and replace v3 .pb file in the line 261. and can comment out the code for download section in .py file.</p>\n<p>for inception v1, the node names are:</p>\n<h1>input<br>\nconv2d0_w<br>\nconv2d0_b<br>\nconv2d1_w<br>\nconv2d1_b<br>\nconv2d2_w<br>\nconv2d2_b<br>\n...<br>\n...<br>\navgpool0/reshape/shape<br>\navgpool0/reshape          (  <em>here is the bottle neck tensor</em> )<br>\nsoftmax2_pre_activation/matmul<br>\nsoftmax2_pre_activation<br>\nsoftmax2<br>\noutput<br>\noutput1<br>\noutput2</h1>\n<p>The first node in inception v1 is 'input', then you need to use 'input:0' in your code.  'avgpool0/reshape:0' is the bottle neck tensor of V1, which is a 1024 * 1 array. V3's bottle neck tensor is 2048 * 1 array. bottle neck tensor is just N-1 Layer of the CNN model. we call it feature vector.</p>\n<p>V1 does not have a jpeg decode node as V3. For V1's first node  'input', it uses 224 * 224 * 3 * 1 array as input tensor directly. if you print out V3's  node names as below, you will see V3's first node is DecodeJpeg/contents, which means V3 can accept jpg file in any size as the input, then the following nodes will expand dims and resize image as a 299 * 299 * 3 * 1 tensor. The 'Mul' in V3 is equivalent 'input' in V1.<br>\nI hope my explanation can help you to find out how to change the retain.py for V1. It is not hard.</p>\n<p>DecodeJpeg/contents<br>\nDecodeJpeg<br>\nCast<br>\nExpandDims/dim<br>\nExpandDims<br>\nResizeBilinear/size<br>\nResizeBilinear<br>\nSub/y<br>\nSub<br>\nMul/y<br>\nMul</p>", "body_text": "@SubhashKsr if you want to get the node names of graph file, which is .pb file (not ckpt, there are different), use the following code:\nfor node in tf.get_default_graph().as_graph_def().node:\n       print (node.name)\n\nas you see in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L261\nclassify_image_graph_def.pb is the file for inception v3. you need to download inception5h.zip which contain inception v1 .pb file and replace v3 .pb file in the line 261. and can comment out the code for download section in .py file.\nfor inception v1, the node names are:\ninput\nconv2d0_w\nconv2d0_b\nconv2d1_w\nconv2d1_b\nconv2d2_w\nconv2d2_b\n...\n...\navgpool0/reshape/shape\navgpool0/reshape          (  here is the bottle neck tensor )\nsoftmax2_pre_activation/matmul\nsoftmax2_pre_activation\nsoftmax2\noutput\noutput1\noutput2\nThe first node in inception v1 is 'input', then you need to use 'input:0' in your code.  'avgpool0/reshape:0' is the bottle neck tensor of V1, which is a 1024 * 1 array. V3's bottle neck tensor is 2048 * 1 array. bottle neck tensor is just N-1 Layer of the CNN model. we call it feature vector.\nV1 does not have a jpeg decode node as V3. For V1's first node  'input', it uses 224 * 224 * 3 * 1 array as input tensor directly. if you print out V3's  node names as below, you will see V3's first node is DecodeJpeg/contents, which means V3 can accept jpg file in any size as the input, then the following nodes will expand dims and resize image as a 299 * 299 * 3 * 1 tensor. The 'Mul' in V3 is equivalent 'input' in V1.\nI hope my explanation can help you to find out how to change the retain.py for V1. It is not hard.\nDecodeJpeg/contents\nDecodeJpeg\nCast\nExpandDims/dim\nExpandDims\nResizeBilinear/size\nResizeBilinear\nSub/y\nSub\nMul/y\nMul", "body": "@SubhashKsr if you want to get the node names of graph file, which is .pb file (not ckpt, there are different), use the following code:\r\n\r\n```\r\nfor node in tf.get_default_graph().as_graph_def().node:\r\n       print (node.name)\r\n```\r\n\r\nas you see in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L261\r\n\r\nclassify_image_graph_def.pb is the file for inception v3. you need to download inception5h.zip which contain inception v1 .pb file and replace v3 .pb file in the line 261. and can comment out the code for download section in .py file.\r\n\r\nfor inception v1, the node names are:\r\n\r\ninput\r\nconv2d0_w\r\nconv2d0_b\r\nconv2d1_w\r\nconv2d1_b\r\nconv2d2_w\r\nconv2d2_b\r\n...\r\n...\r\navgpool0/reshape/shape\r\navgpool0/reshape          (  _here is the bottle neck tensor_ )\r\nsoftmax2_pre_activation/matmul\r\nsoftmax2_pre_activation\r\nsoftmax2\r\noutput\r\noutput1\r\noutput2\r\n============\r\nThe first node in inception v1 is 'input', then you need to use 'input:0' in your code.  'avgpool0/reshape:0' is the bottle neck tensor of V1, which is a 1024 * 1 array. V3's bottle neck tensor is 2048 * 1 array. bottle neck tensor is just N-1 Layer of the CNN model. we call it feature vector.\r\n\r\nV1 does not have a jpeg decode node as V3. For V1's first node  'input', it uses 224 * 224 * 3 * 1 array as input tensor directly. if you print out V3's  node names as below, you will see V3's first node is DecodeJpeg/contents, which means V3 can accept jpg file in any size as the input, then the following nodes will expand dims and resize image as a 299 * 299 * 3 * 1 tensor. The 'Mul' in V3 is equivalent 'input' in V1.\r\nI hope my explanation can help you to find out how to change the retain.py for V1. It is not hard.\r\n\r\nDecodeJpeg/contents\r\nDecodeJpeg\r\nCast\r\nExpandDims/dim\r\nExpandDims\r\nResizeBilinear/size\r\nResizeBilinear\r\nSub/y\r\nSub\r\nMul/y\r\nMul\r\n\r\n\r\n\r\n"}