{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15680", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15680/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15680/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15680/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/15680", "id": 284836879, "node_id": "MDExOlB1bGxSZXF1ZXN0MTYwMzMwODE4", "number": 15680, "title": "Improve doc of TFRecordDataset, shuffle ahead of map", "user": {"login": "yjmade", "id": 1754190, "node_id": "MDQ6VXNlcjE3NTQxOTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1754190?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yjmade", "html_url": "https://github.com/yjmade", "followers_url": "https://api.github.com/users/yjmade/followers", "following_url": "https://api.github.com/users/yjmade/following{/other_user}", "gists_url": "https://api.github.com/users/yjmade/gists{/gist_id}", "starred_url": "https://api.github.com/users/yjmade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yjmade/subscriptions", "organizations_url": "https://api.github.com/users/yjmade/orgs", "repos_url": "https://api.github.com/users/yjmade/repos", "events_url": "https://api.github.com/users/yjmade/events{/privacy}", "received_events_url": "https://api.github.com/users/yjmade/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-28T03:56:00Z", "updated_at": "2017-12-28T19:34:39Z", "closed_at": "2017-12-28T19:34:39Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15680", "html_url": "https://github.com/tensorflow/tensorflow/pull/15680", "diff_url": "https://github.com/tensorflow/tensorflow/pull/15680.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/15680.patch"}, "body_html": "<p>In the origin document, the code to demonstrate TFRecordDataset do <code>dataset.map(parser)</code> then do <code>dataset.shuffle(10000)</code>.<br>\nThis code use a high number of buffer size (10000), and since <code>map</code> do ahead of <code>shuffle</code>, means when the first time this dataset yield one result it will need to run <code>map</code> over 10000 items and this can take a lot of time.<br>\nSo, instead we can do <code>shuffle</code> ahead of <code>map</code>, since the item of <code>TFRecordDataset</code> is one <code>Example</code> raw data, <code>shuffle</code> ahead will not compromise the randomness and then the <code>map(parser)</code> only need to process one batch of items at a time. Which results much faster startup.</p>", "body_text": "In the origin document, the code to demonstrate TFRecordDataset do dataset.map(parser) then do dataset.shuffle(10000).\nThis code use a high number of buffer size (10000), and since map do ahead of shuffle, means when the first time this dataset yield one result it will need to run map over 10000 items and this can take a lot of time.\nSo, instead we can do shuffle ahead of map, since the item of TFRecordDataset is one Example raw data, shuffle ahead will not compromise the randomness and then the map(parser) only need to process one batch of items at a time. Which results much faster startup.", "body": "In the origin document, the code to demonstrate TFRecordDataset do `dataset.map(parser)` then do `dataset.shuffle(10000)`.\r\nThis code use a high number of buffer size (10000), and since `map` do ahead of `shuffle`, means when the first time this dataset yield one result it will need to run `map` over 10000 items and this can take a lot of time.\r\nSo, instead we can do `shuffle` ahead of `map`, since the item of `TFRecordDataset` is one `Example` raw data, `shuffle` ahead will not compromise the randomness and then the `map(parser)` only need to process one batch of items at a time. Which results much faster startup.\r\n"}