{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16737", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16737/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16737/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16737/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16737", "id": 294155009, "node_id": "MDU6SXNzdWUyOTQxNTUwMDk=", "number": 16737, "title": "Discrepancies between GPU and CPU in floating-point operations", "user": {"login": "rdinse", "id": 9957215, "node_id": "MDQ6VXNlcjk5NTcyMTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/9957215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdinse", "html_url": "https://github.com/rdinse", "followers_url": "https://api.github.com/users/rdinse/followers", "following_url": "https://api.github.com/users/rdinse/following{/other_user}", "gists_url": "https://api.github.com/users/rdinse/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdinse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdinse/subscriptions", "organizations_url": "https://api.github.com/users/rdinse/orgs", "repos_url": "https://api.github.com/users/rdinse/repos", "events_url": "https://api.github.com/users/rdinse/events{/privacy}", "received_events_url": "https://api.github.com/users/rdinse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-03T23:40:30Z", "updated_at": "2018-02-05T11:40:28Z", "closed_at": "2018-02-05T11:40:28Z", "author_association": "NONE", "body_html": "<pre><code>bs = 32\ndim = 1024\n\ntf.reset_default_graph()\nwith tf.device(\"/cpu:0\"):\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\n  print(probs)\n  logits = tf.log(probs / (1e-10 + 1 - probs))\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n  print(s.run([logits]))\n\ntf.reset_default_graph()\nwith tf.device(\"/gpu:0\"):\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\n  print(probs)\n  logits = tf.log(probs / (1e-10 + 1 - probs))\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n  print(s.run([logits]))\n</code></pre>\n<p>Running this graph on GPU results in positive infinities, whereas on CPU these tensor entries evaluate to ~88.72284. I could not quite figure out which operation is responsible for the difference. In both cases TensorFlow reports <code>probs</code> as <code>float32</code>. The difference does not occur when replacing <code>probs</code> with a <code>tf.ones</code> tensor in <code>float32</code> format.</p>", "body_text": "bs = 32\ndim = 1024\n\ntf.reset_default_graph()\nwith tf.device(\"/cpu:0\"):\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\n  print(probs)\n  logits = tf.log(probs / (1e-10 + 1 - probs))\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n  print(s.run([logits]))\n\ntf.reset_default_graph()\nwith tf.device(\"/gpu:0\"):\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\n  print(probs)\n  logits = tf.log(probs / (1e-10 + 1 - probs))\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n  print(s.run([logits]))\n\nRunning this graph on GPU results in positive infinities, whereas on CPU these tensor entries evaluate to ~88.72284. I could not quite figure out which operation is responsible for the difference. In both cases TensorFlow reports probs as float32. The difference does not occur when replacing probs with a tf.ones tensor in float32 format.", "body": "```\r\nbs = 32\r\ndim = 1024\r\n\r\ntf.reset_default_graph()\r\nwith tf.device(\"/cpu:0\"):\r\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\r\n  print(probs)\r\n  logits = tf.log(probs / (1e-10 + 1 - probs))\r\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n  print(s.run([logits]))\r\n\r\ntf.reset_default_graph()\r\nwith tf.device(\"/gpu:0\"):\r\n  probs = tf.where(tf.greater(tf.random_normal((bs, dim)), 0.), tf.ones((bs, dim)), tf.zeros((bs, dim)))\r\n  print(probs)\r\n  logits = tf.log(probs / (1e-10 + 1 - probs))\r\n  s = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n  print(s.run([logits]))\r\n```\r\n\r\nRunning this graph on GPU results in positive infinities, whereas on CPU these tensor entries evaluate to ~88.72284. I could not quite figure out which operation is responsible for the difference. In both cases TensorFlow reports `probs` as `float32`. The difference does not occur when replacing `probs` with a `tf.ones` tensor in `float32` format."}