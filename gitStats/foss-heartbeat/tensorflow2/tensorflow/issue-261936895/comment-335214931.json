{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335214931", "html_url": "https://github.com/tensorflow/tensorflow/issues/13434#issuecomment-335214931", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13434", "id": 335214931, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTIxNDkzMQ==", "user": {"login": "ybsave", "id": 26417094, "node_id": "MDQ6VXNlcjI2NDE3MDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26417094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybsave", "html_url": "https://github.com/ybsave", "followers_url": "https://api.github.com/users/ybsave/followers", "following_url": "https://api.github.com/users/ybsave/following{/other_user}", "gists_url": "https://api.github.com/users/ybsave/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybsave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybsave/subscriptions", "organizations_url": "https://api.github.com/users/ybsave/orgs", "repos_url": "https://api.github.com/users/ybsave/repos", "events_url": "https://api.github.com/users/ybsave/events{/privacy}", "received_events_url": "https://api.github.com/users/ybsave/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-09T16:47:27Z", "updated_at": "2017-10-09T16:50:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16018\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/asimshankar\">@asimshankar</a> Thanks for your explanation. The codes I used are exactly the same as in <a href=\"https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py\">https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py</a>.</p>\n<p>I only modified the \"resnet_model_fn\" for only a few lines (I labeled below).</p>\n<pre><code>def resnet_model_fn(features, labels, mode):\n  \"\"\" Our model_fn for ResNet to be used with our Estimator.\"\"\"\n  tf.summary.image('images', features, max_outputs=6)\n\n  with tf.device('/cpu:0'):    #modified by me\n\tall_cross_entropy = []   #modified by me\n\twith tf.device('/gpu:0'):  #modified by me\n\t  logits = network(\n\t\tinputs=features, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n\t  \n\t  predictions = {\n\t\t'classes': tf.argmax(logits, axis=1),\n\t\t'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n\t  }\n\n\t  if mode == tf.estimator.ModeKeys.PREDICT:\n\t\treturn tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n\t  # Calculate loss, which includes softmax cross entropy and L2 regularization.\n\t  cross_entropy = tf.losses.softmax_cross_entropy(\n\t\tlogits=logits, onehot_labels=labels)\n\n\t  all_cross_entropy.append(cross_entropy)   #modified by me\n\n\ttotal_entropy = tf.add_n(all_cross_entropy)  #modified by me\n\t# Create a tensor named cross_entropy for logging purposes.\n\ttf.identity(total_entropy, name='cross_entropy')  #modified by me\n\ttf.summary.scalar('cross_entropy', total_entropy)  #modified by me\n\n\t# Add weight decay to the loss. We perform weight decay on all trainable\n\t# variables, which includes batch norm beta and gamma variables.\n\treg_loss = FLAGS.weight_decay * tf.add_n(\n\t  [tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n\ttf.summary.scalar('reg_loss', reg_loss)\n\n\tloss = total_entropy + reg_loss  #modified by me\n\ttf.summary.scalar('total_loss', loss)\n\n\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t  global_step = tf.train.get_or_create_global_step()\n\n\t  # Multiply the learning rate by 0.1 at 30, 60, 120, and 150 epochs.\n\t  boundaries = [\n\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\n\t  values = [\n\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\n\t  learning_rate = tf.train.piecewise_constant(\n\t\ttf.cast(global_step, tf.int32), boundaries, values)\n\n\t  # Create a tensor named learning_rate for logging purposes.\n\t  tf.identity(learning_rate, name='learning_rate')\n\t  tf.summary.scalar('learning_rate', learning_rate)\n\n\t  optimizer = tf.train.MomentumOptimizer(\n\t\tlearning_rate=learning_rate,\n\t\tmomentum=_MOMENTUM)\n\t  \n\t  # Batch norm requires update_ops to be added as a train_op dependency.\n\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\t  with tf.control_dependencies(update_ops):\n\t\ttrain_op = optimizer.minimize(loss, global_step)\n\telse:\n\t  train_op = None\n\n\taccuracy = tf.metrics.accuracy(\n\t  tf.argmax(labels, axis=1), predictions['classes'])\n\tmetrics = {'accuracy': accuracy}\n\n\t# Create a tensor named train_accuracy for logging purposes.\n\ttf.identity(accuracy[1], name='train_accuracy')\n\ttf.summary.scalar('train_accuracy', accuracy[1])\n\n\treturn tf.estimator.EstimatorSpec(\n\t  mode=mode,\n\t  predictions=predictions,\n\t  loss=loss,\n\t  train_op=train_op,\n\t  eval_metric_ops=metrics)\n</code></pre>\n<p>However, the error still shows:<br>\nTraceback (most recent call last):<br>\nFile \"imagenet_main_multi-gpu.py\", line 396, in <br>\ntf.app.run()<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run<br>\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))<br>\nFile \"imagenet_main_multi-gpu.py\", line 385, in main<br>\nhooks=[logging_hook])<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train<br>\nloss = self._train_model(input_fn=input_fn, hooks=hooks)<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model<br>\n_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run<br>\nrun_metadata=run_metadata)<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run<br>\nrun_metadata=run_metadata)<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run<br>\nreturn self._sess.run(*args, **kwargs)<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run<br>\nrun_metadata=run_metadata))<br>\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run<br>\nraise NanLossDuringTrainingError<br>\ntensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training.</p>\n<p>If I remove my added cpu, gpu appointment, the codes have no problem to run. Is it possibly because some communications problem between CPU &amp; GPU? What should I do for correct one?</p>\n<p>I tried hardly to search for examples (multi-GPU using Estimator); however, I can only find how to distribute different layers of network at <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/multiple_gpu.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/multiple_gpu.py</a>. But I cannot find any example of splitting data into multi-GPU using Estimator. Would you please give me some help? Thank you so much.</p>", "body_text": "@asimshankar Thanks for your explanation. The codes I used are exactly the same as in https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py.\nI only modified the \"resnet_model_fn\" for only a few lines (I labeled below).\ndef resnet_model_fn(features, labels, mode):\n  \"\"\" Our model_fn for ResNet to be used with our Estimator.\"\"\"\n  tf.summary.image('images', features, max_outputs=6)\n\n  with tf.device('/cpu:0'):    #modified by me\n\tall_cross_entropy = []   #modified by me\n\twith tf.device('/gpu:0'):  #modified by me\n\t  logits = network(\n\t\tinputs=features, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n\t  \n\t  predictions = {\n\t\t'classes': tf.argmax(logits, axis=1),\n\t\t'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n\t  }\n\n\t  if mode == tf.estimator.ModeKeys.PREDICT:\n\t\treturn tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n\t  # Calculate loss, which includes softmax cross entropy and L2 regularization.\n\t  cross_entropy = tf.losses.softmax_cross_entropy(\n\t\tlogits=logits, onehot_labels=labels)\n\n\t  all_cross_entropy.append(cross_entropy)   #modified by me\n\n\ttotal_entropy = tf.add_n(all_cross_entropy)  #modified by me\n\t# Create a tensor named cross_entropy for logging purposes.\n\ttf.identity(total_entropy, name='cross_entropy')  #modified by me\n\ttf.summary.scalar('cross_entropy', total_entropy)  #modified by me\n\n\t# Add weight decay to the loss. We perform weight decay on all trainable\n\t# variables, which includes batch norm beta and gamma variables.\n\treg_loss = FLAGS.weight_decay * tf.add_n(\n\t  [tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n\ttf.summary.scalar('reg_loss', reg_loss)\n\n\tloss = total_entropy + reg_loss  #modified by me\n\ttf.summary.scalar('total_loss', loss)\n\n\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t  global_step = tf.train.get_or_create_global_step()\n\n\t  # Multiply the learning rate by 0.1 at 30, 60, 120, and 150 epochs.\n\t  boundaries = [\n\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\n\t  values = [\n\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\n\t  learning_rate = tf.train.piecewise_constant(\n\t\ttf.cast(global_step, tf.int32), boundaries, values)\n\n\t  # Create a tensor named learning_rate for logging purposes.\n\t  tf.identity(learning_rate, name='learning_rate')\n\t  tf.summary.scalar('learning_rate', learning_rate)\n\n\t  optimizer = tf.train.MomentumOptimizer(\n\t\tlearning_rate=learning_rate,\n\t\tmomentum=_MOMENTUM)\n\t  \n\t  # Batch norm requires update_ops to be added as a train_op dependency.\n\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\t  with tf.control_dependencies(update_ops):\n\t\ttrain_op = optimizer.minimize(loss, global_step)\n\telse:\n\t  train_op = None\n\n\taccuracy = tf.metrics.accuracy(\n\t  tf.argmax(labels, axis=1), predictions['classes'])\n\tmetrics = {'accuracy': accuracy}\n\n\t# Create a tensor named train_accuracy for logging purposes.\n\ttf.identity(accuracy[1], name='train_accuracy')\n\ttf.summary.scalar('train_accuracy', accuracy[1])\n\n\treturn tf.estimator.EstimatorSpec(\n\t  mode=mode,\n\t  predictions=predictions,\n\t  loss=loss,\n\t  train_op=train_op,\n\t  eval_metric_ops=metrics)\n\nHowever, the error still shows:\nTraceback (most recent call last):\nFile \"imagenet_main_multi-gpu.py\", line 396, in \ntf.app.run()\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n_sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile \"imagenet_main_multi-gpu.py\", line 385, in main\nhooks=[logging_hook])\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\nloss = self._train_model(input_fn=input_fn, hooks=hooks)\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model\n_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run\nrun_metadata=run_metadata)\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run\nrun_metadata=run_metadata)\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run\nreturn self._sess.run(*args, **kwargs)\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run\nrun_metadata=run_metadata))\nFile \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run\nraise NanLossDuringTrainingError\ntensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training.\nIf I remove my added cpu, gpu appointment, the codes have no problem to run. Is it possibly because some communications problem between CPU & GPU? What should I do for correct one?\nI tried hardly to search for examples (multi-GPU using Estimator); however, I can only find how to distribute different layers of network at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/multiple_gpu.py. But I cannot find any example of splitting data into multi-GPU using Estimator. Would you please give me some help? Thank you so much.", "body": "@asimshankar Thanks for your explanation. The codes I used are exactly the same as in https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py.\r\n\r\nI only modified the \"resnet_model_fn\" for only a few lines (I labeled below).\r\n\r\n\tdef resnet_model_fn(features, labels, mode):\r\n\t  \"\"\" Our model_fn for ResNet to be used with our Estimator.\"\"\"\r\n\t  tf.summary.image('images', features, max_outputs=6)\r\n\r\n\t  with tf.device('/cpu:0'):    #modified by me\r\n\t\tall_cross_entropy = []   #modified by me\r\n\t\twith tf.device('/gpu:0'):  #modified by me\r\n\t\t  logits = network(\r\n\t\t\tinputs=features, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n\t\t  \r\n\t\t  predictions = {\r\n\t\t\t'classes': tf.argmax(logits, axis=1),\r\n\t\t\t'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\r\n\t\t  }\r\n\r\n\t\t  if mode == tf.estimator.ModeKeys.PREDICT:\r\n\t\t\treturn tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n\t\t  # Calculate loss, which includes softmax cross entropy and L2 regularization.\r\n\t\t  cross_entropy = tf.losses.softmax_cross_entropy(\r\n\t\t\tlogits=logits, onehot_labels=labels)\r\n\r\n\t\t  all_cross_entropy.append(cross_entropy)   #modified by me\r\n\r\n\t\ttotal_entropy = tf.add_n(all_cross_entropy)  #modified by me\r\n\t\t# Create a tensor named cross_entropy for logging purposes.\r\n\t\ttf.identity(total_entropy, name='cross_entropy')  #modified by me\r\n\t\ttf.summary.scalar('cross_entropy', total_entropy)  #modified by me\r\n\r\n\t\t# Add weight decay to the loss. We perform weight decay on all trainable\r\n\t\t# variables, which includes batch norm beta and gamma variables.\r\n\t\treg_loss = FLAGS.weight_decay * tf.add_n(\r\n\t\t  [tf.nn.l2_loss(v) for v in tf.trainable_variables()])\r\n\t\ttf.summary.scalar('reg_loss', reg_loss)\r\n\r\n\t\tloss = total_entropy + reg_loss  #modified by me\r\n\t\ttf.summary.scalar('total_loss', loss)\r\n\r\n\t\tif mode == tf.estimator.ModeKeys.TRAIN:\r\n\t\t  global_step = tf.train.get_or_create_global_step()\r\n\r\n\t\t  # Multiply the learning rate by 0.1 at 30, 60, 120, and 150 epochs.\r\n\t\t  boundaries = [\r\n\t\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\r\n\t\t  values = [\r\n\t\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\r\n\t\t  learning_rate = tf.train.piecewise_constant(\r\n\t\t\ttf.cast(global_step, tf.int32), boundaries, values)\r\n\r\n\t\t  # Create a tensor named learning_rate for logging purposes.\r\n\t\t  tf.identity(learning_rate, name='learning_rate')\r\n\t\t  tf.summary.scalar('learning_rate', learning_rate)\r\n\r\n\t\t  optimizer = tf.train.MomentumOptimizer(\r\n\t\t\tlearning_rate=learning_rate,\r\n\t\t\tmomentum=_MOMENTUM)\r\n\t\t  \r\n\t\t  # Batch norm requires update_ops to be added as a train_op dependency.\r\n\t\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n\t\t  with tf.control_dependencies(update_ops):\r\n\t\t\ttrain_op = optimizer.minimize(loss, global_step)\r\n\t\telse:\r\n\t\t  train_op = None\r\n\r\n\t\taccuracy = tf.metrics.accuracy(\r\n\t\t  tf.argmax(labels, axis=1), predictions['classes'])\r\n\t\tmetrics = {'accuracy': accuracy}\r\n\r\n\t\t# Create a tensor named train_accuracy for logging purposes.\r\n\t\ttf.identity(accuracy[1], name='train_accuracy')\r\n\t\ttf.summary.scalar('train_accuracy', accuracy[1])\r\n\r\n\t\treturn tf.estimator.EstimatorSpec(\r\n\t\t  mode=mode,\r\n\t\t  predictions=predictions,\r\n\t\t  loss=loss,\r\n\t\t  train_op=train_op,\r\n\t\t  eval_metric_ops=metrics)\r\n\r\nHowever, the error still shows:\r\n\tTraceback (most recent call last):\r\n\t  File \"imagenet_main_multi-gpu.py\", line 396, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"imagenet_main_multi-gpu.py\", line 385, in main\r\n\t\thooks=[logging_hook])\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\r\n\t\tloss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model\r\n\t\t_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run\r\n\t\trun_metadata=run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run\r\n\t\trun_metadata=run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run\r\n\t\treturn self._sess.run(*args, **kwargs)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run\r\n\t\trun_metadata=run_metadata))\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run\r\n\t\traise NanLossDuringTrainingError\r\n\ttensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training.\r\n\r\nIf I remove my added cpu, gpu appointment, the codes have no problem to run. Is it possibly because some communications problem between CPU & GPU? What should I do for correct one?\r\n\r\nI tried hardly to search for examples (multi-GPU using Estimator); however, I can only find how to distribute different layers of network at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/multiple_gpu.py. But I cannot find any example of splitting data into multi-GPU using Estimator. Would you please give me some help? Thank you so much."}