{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/334824429", "html_url": "https://github.com/tensorflow/tensorflow/issues/13434#issuecomment-334824429", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13434", "id": 334824429, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDgyNDQyOQ==", "user": {"login": "ybsave", "id": 26417094, "node_id": "MDQ6VXNlcjI2NDE3MDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26417094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybsave", "html_url": "https://github.com/ybsave", "followers_url": "https://api.github.com/users/ybsave/followers", "following_url": "https://api.github.com/users/ybsave/following{/other_user}", "gists_url": "https://api.github.com/users/ybsave/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybsave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybsave/subscriptions", "organizations_url": "https://api.github.com/users/ybsave/orgs", "repos_url": "https://api.github.com/users/ybsave/repos", "events_url": "https://api.github.com/users/ybsave/events{/privacy}", "received_events_url": "https://api.github.com/users/ybsave/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-06T17:46:44Z", "updated_at": "2017-10-07T00:04:34Z", "author_association": "NONE", "body_html": "<p>I have tried to distributed the data batch on two GPUs and there is NaN loss error now. Would there be any possible cause for this? It runs well before (using one GPU only). But now even I set the _DEVICE_LIST to one GPU only, it still produce the NaN loss error.</p>\n<p>My modified codes are:</p>\n<pre><code>def imagenet_model_fn(features, labels, mode):\n  tf.summary.image('images', features, max_outputs=6)\n\n  with tf.device('/cpu:0'):\n\tsplit_batch = tf.split(features, len(_DEVICE_LIST))\n\tsplit_labels = tf.split(labels, len(_DEVICE_LIST))\n\n\tall_predictions = {\n\t  'classes': [],\n\t  'probabilities': []\n\t}\n\tall_cross_entropy = []\n\tall_reg_loss = []\n\n\twith tf.variable_scope(tf.get_variable_scope()):\n\t  for dev_idx, (device, device_features, device_labels) in enumerate(zip(\n\t\t_DEVICE_LIST, split_batch, split_labels)):\n\t\twith tf.device(device):\n\t\t  with tf.name_scope('device_%d' % dev_idx):\n\t\t\tlogits = network(inputs=device_features,\n\t\t\t\t\t\t\t is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n\n\t\t\ttf.get_variable_scope().reuse_variables()\n\t\t\tall_predictions['classes'].append(tf.argmax(logits, axis=1))\n\t\t\tall_predictions['probabilities'].append(tf.nn.softmax(logits))\n\t\t\t\n\t\t\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t\t\t# Calculate loss, which includes softmax cross entropy and L2 regularization.\n\t\t\t  cross_entropy = tf.losses.softmax_cross_entropy(\n\t\t\t\tlogits=logits, onehot_labels=device_labels)\n\t\t\t  reg_loss = FLAGS.weight_decay * tf.add_n(\n\t\t\t\t[tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n\t\t  \n\t\t\t  all_cross_entropy.append(cross_entropy)\n\t\t\t  all_reg_loss.append(reg_loss)\n\n  \n\tall_predictions['classes'] = tf.reshape(all_predictions['classes'], [-1])\n\tall_predictions['probabilities'] = tf.reshape(\n\t  all_predictions['probabilities'], [-1])\n\n\ttotal_cross_entropy = tf.add_n(all_cross_entropy)\n\ttotal_reg_loss = tf.add_n(all_reg_loss)\n\ttotal_loss = total_cross_entropy + total_reg_loss\n\n\ttf.identity(total_cross_entropy, name='cross_entropy')\n\ttf.summary.scalar('cross_entropy', total_cross_entropy)\n\ttf.summary.scalar('reg_loss', total_reg_loss)\n\ttf.summary.scalar('total_loss', total_loss)\n\n\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t  global_step = tf.train.get_or_create_global_step()\n\t  boundaries = [\n\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\n\t  values = [\n\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\n\t  learning_rate = tf.train.piecewise_constant(\n\t\ttf.cast(global_step, tf.int32), boundaries, values)\n\n\t  tf.identity(learning_rate, name='learning_rate')\n\t  tf.summary.scalar('learning_rate', learning_rate)\n\n\t  optimizer = tf.train.MomentumOptimizer(\n\t\tlearning_rate=learning_rate,\n\t\tmomentum=_MOMENTUM)\n\n\t# Batch norm requires update_ops to be added as a train_op dependency.\n\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\t  with tf.control_dependencies(update_ops):\n\t\ttrain_op = optimizer.minimize(total_loss, global_step)\n\telse:\n\t  train_op = None\n\n\treturn tf.estimator.EstimatorSpec(\n\t  mode=mode,\n\t  predictions=all_predictions,\n\t  loss=total_loss,\n\t  train_op=train_op)\n</code></pre>\n<p>The error message is:</p>\n<pre><code>INFO:tensorflow:Saving checkpoints for 1 into F:\\projects\\DeepLearning\\TensorFlow\\Models\\ImageNet\\resnet_101_imagenet_augmented\\temp\\model.ckpt.\nINFO:tensorflow:learning_rate = 0.003125, cross_entropy = 14.394\nINFO:tensorflow:loss = 30.0782, step = 1\nERROR:tensorflow:Model diverged with loss = NaN.\nTraceback (most recent call last):\n  File \"imagenet_main.py\", line 321, in &lt;module&gt;\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"imagenet_main.py\", line 310, in main\n\thooks=[logging_hook])\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\n\tloss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model\n\t_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run\n\trun_metadata=run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run\n\trun_metadata=run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run\n\treturn self._sess.run(*args, **kwargs)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run\n\trun_metadata=run_metadata))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run\n\traise NanLossDuringTrainingError\ntensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training.\n</code></pre>", "body_text": "I have tried to distributed the data batch on two GPUs and there is NaN loss error now. Would there be any possible cause for this? It runs well before (using one GPU only). But now even I set the _DEVICE_LIST to one GPU only, it still produce the NaN loss error.\nMy modified codes are:\ndef imagenet_model_fn(features, labels, mode):\n  tf.summary.image('images', features, max_outputs=6)\n\n  with tf.device('/cpu:0'):\n\tsplit_batch = tf.split(features, len(_DEVICE_LIST))\n\tsplit_labels = tf.split(labels, len(_DEVICE_LIST))\n\n\tall_predictions = {\n\t  'classes': [],\n\t  'probabilities': []\n\t}\n\tall_cross_entropy = []\n\tall_reg_loss = []\n\n\twith tf.variable_scope(tf.get_variable_scope()):\n\t  for dev_idx, (device, device_features, device_labels) in enumerate(zip(\n\t\t_DEVICE_LIST, split_batch, split_labels)):\n\t\twith tf.device(device):\n\t\t  with tf.name_scope('device_%d' % dev_idx):\n\t\t\tlogits = network(inputs=device_features,\n\t\t\t\t\t\t\t is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n\n\t\t\ttf.get_variable_scope().reuse_variables()\n\t\t\tall_predictions['classes'].append(tf.argmax(logits, axis=1))\n\t\t\tall_predictions['probabilities'].append(tf.nn.softmax(logits))\n\t\t\t\n\t\t\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t\t\t# Calculate loss, which includes softmax cross entropy and L2 regularization.\n\t\t\t  cross_entropy = tf.losses.softmax_cross_entropy(\n\t\t\t\tlogits=logits, onehot_labels=device_labels)\n\t\t\t  reg_loss = FLAGS.weight_decay * tf.add_n(\n\t\t\t\t[tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n\t\t  \n\t\t\t  all_cross_entropy.append(cross_entropy)\n\t\t\t  all_reg_loss.append(reg_loss)\n\n  \n\tall_predictions['classes'] = tf.reshape(all_predictions['classes'], [-1])\n\tall_predictions['probabilities'] = tf.reshape(\n\t  all_predictions['probabilities'], [-1])\n\n\ttotal_cross_entropy = tf.add_n(all_cross_entropy)\n\ttotal_reg_loss = tf.add_n(all_reg_loss)\n\ttotal_loss = total_cross_entropy + total_reg_loss\n\n\ttf.identity(total_cross_entropy, name='cross_entropy')\n\ttf.summary.scalar('cross_entropy', total_cross_entropy)\n\ttf.summary.scalar('reg_loss', total_reg_loss)\n\ttf.summary.scalar('total_loss', total_loss)\n\n\tif mode == tf.estimator.ModeKeys.TRAIN:\n\t  global_step = tf.train.get_or_create_global_step()\n\t  boundaries = [\n\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\n\t  values = [\n\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\n\t  learning_rate = tf.train.piecewise_constant(\n\t\ttf.cast(global_step, tf.int32), boundaries, values)\n\n\t  tf.identity(learning_rate, name='learning_rate')\n\t  tf.summary.scalar('learning_rate', learning_rate)\n\n\t  optimizer = tf.train.MomentumOptimizer(\n\t\tlearning_rate=learning_rate,\n\t\tmomentum=_MOMENTUM)\n\n\t# Batch norm requires update_ops to be added as a train_op dependency.\n\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\t  with tf.control_dependencies(update_ops):\n\t\ttrain_op = optimizer.minimize(total_loss, global_step)\n\telse:\n\t  train_op = None\n\n\treturn tf.estimator.EstimatorSpec(\n\t  mode=mode,\n\t  predictions=all_predictions,\n\t  loss=total_loss,\n\t  train_op=train_op)\n\nThe error message is:\nINFO:tensorflow:Saving checkpoints for 1 into F:\\projects\\DeepLearning\\TensorFlow\\Models\\ImageNet\\resnet_101_imagenet_augmented\\temp\\model.ckpt.\nINFO:tensorflow:learning_rate = 0.003125, cross_entropy = 14.394\nINFO:tensorflow:loss = 30.0782, step = 1\nERROR:tensorflow:Model diverged with loss = NaN.\nTraceback (most recent call last):\n  File \"imagenet_main.py\", line 321, in <module>\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"imagenet_main.py\", line 310, in main\n\thooks=[logging_hook])\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\n\tloss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model\n\t_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run\n\trun_metadata=run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run\n\trun_metadata=run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run\n\treturn self._sess.run(*args, **kwargs)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run\n\trun_metadata=run_metadata))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run\n\traise NanLossDuringTrainingError\ntensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training.", "body": "I have tried to distributed the data batch on two GPUs and there is NaN loss error now. Would there be any possible cause for this? It runs well before (using one GPU only). But now even I set the _DEVICE_LIST to one GPU only, it still produce the NaN loss error. \r\n\r\nMy modified codes are:\r\n\r\n\tdef imagenet_model_fn(features, labels, mode):\r\n\t  tf.summary.image('images', features, max_outputs=6)\r\n\r\n\t  with tf.device('/cpu:0'):\r\n\t\tsplit_batch = tf.split(features, len(_DEVICE_LIST))\r\n\t\tsplit_labels = tf.split(labels, len(_DEVICE_LIST))\r\n\r\n\t\tall_predictions = {\r\n\t\t  'classes': [],\r\n\t\t  'probabilities': []\r\n\t\t}\r\n\t\tall_cross_entropy = []\r\n\t\tall_reg_loss = []\r\n\r\n\t\twith tf.variable_scope(tf.get_variable_scope()):\r\n\t\t  for dev_idx, (device, device_features, device_labels) in enumerate(zip(\r\n\t\t\t_DEVICE_LIST, split_batch, split_labels)):\r\n\t\t\twith tf.device(device):\r\n\t\t\t  with tf.name_scope('device_%d' % dev_idx):\r\n\t\t\t\tlogits = network(inputs=device_features,\r\n\t\t\t\t\t\t\t\t is_training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n\r\n\t\t\t\ttf.get_variable_scope().reuse_variables()\r\n\t\t\t\tall_predictions['classes'].append(tf.argmax(logits, axis=1))\r\n\t\t\t\tall_predictions['probabilities'].append(tf.nn.softmax(logits))\r\n\t\t\t\t\r\n\t\t\t\tif mode == tf.estimator.ModeKeys.TRAIN:\r\n\t\t\t\t# Calculate loss, which includes softmax cross entropy and L2 regularization.\r\n\t\t\t\t  cross_entropy = tf.losses.softmax_cross_entropy(\r\n\t\t\t\t\tlogits=logits, onehot_labels=device_labels)\r\n\t\t\t\t  reg_loss = FLAGS.weight_decay * tf.add_n(\r\n\t\t\t\t\t[tf.nn.l2_loss(v) for v in tf.trainable_variables()])\r\n\t\t\t  \r\n\t\t\t\t  all_cross_entropy.append(cross_entropy)\r\n\t\t\t\t  all_reg_loss.append(reg_loss)\r\n\r\n\t  \r\n\t\tall_predictions['classes'] = tf.reshape(all_predictions['classes'], [-1])\r\n\t\tall_predictions['probabilities'] = tf.reshape(\r\n\t\t  all_predictions['probabilities'], [-1])\r\n\r\n\t\ttotal_cross_entropy = tf.add_n(all_cross_entropy)\r\n\t\ttotal_reg_loss = tf.add_n(all_reg_loss)\r\n\t\ttotal_loss = total_cross_entropy + total_reg_loss\r\n\r\n\t\ttf.identity(total_cross_entropy, name='cross_entropy')\r\n\t\ttf.summary.scalar('cross_entropy', total_cross_entropy)\r\n\t\ttf.summary.scalar('reg_loss', total_reg_loss)\r\n\t\ttf.summary.scalar('total_loss', total_loss)\r\n\r\n\t\tif mode == tf.estimator.ModeKeys.TRAIN:\r\n\t\t  global_step = tf.train.get_or_create_global_step()\r\n\t\t  boundaries = [\r\n\t\t\tint(batches_per_epoch * epoch) for epoch in [30, 60, 120, 150]]\r\n\t\t  values = [\r\n\t\t\t_INITIAL_LEARNING_RATE * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\r\n\t\t  learning_rate = tf.train.piecewise_constant(\r\n\t\t\ttf.cast(global_step, tf.int32), boundaries, values)\r\n\r\n\t\t  tf.identity(learning_rate, name='learning_rate')\r\n\t\t  tf.summary.scalar('learning_rate', learning_rate)\r\n\r\n\t\t  optimizer = tf.train.MomentumOptimizer(\r\n\t\t\tlearning_rate=learning_rate,\r\n\t\t\tmomentum=_MOMENTUM)\r\n\r\n\t\t# Batch norm requires update_ops to be added as a train_op dependency.\r\n\t\t  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n\t\t  with tf.control_dependencies(update_ops):\r\n\t\t\ttrain_op = optimizer.minimize(total_loss, global_step)\r\n\t\telse:\r\n\t\t  train_op = None\r\n\r\n\t\treturn tf.estimator.EstimatorSpec(\r\n\t\t  mode=mode,\r\n\t\t  predictions=all_predictions,\r\n\t\t  loss=total_loss,\r\n\t\t  train_op=train_op)\r\n\r\nThe error message is:\r\n\r\n\tINFO:tensorflow:Saving checkpoints for 1 into F:\\projects\\DeepLearning\\TensorFlow\\Models\\ImageNet\\resnet_101_imagenet_augmented\\temp\\model.ckpt.\r\n\tINFO:tensorflow:learning_rate = 0.003125, cross_entropy = 14.394\r\n\tINFO:tensorflow:loss = 30.0782, step = 1\r\n\tERROR:tensorflow:Model diverged with loss = NaN.\r\n\tTraceback (most recent call last):\r\n\t  File \"imagenet_main.py\", line 321, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"imagenet_main.py\", line 310, in main\r\n\t\thooks=[logging_hook])\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 241, in train\r\n\t\tloss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 686, in _train_model\r\n\t\t_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 518, in run\r\n\t\trun_metadata=run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 862, in run\r\n\t\trun_metadata=run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 818, in run\r\n\t\treturn self._sess.run(*args, **kwargs)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 980, in run\r\n\t\trun_metadata=run_metadata))\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 551, in after_run\r\n\t\traise NanLossDuringTrainingError\r\n\ttensorflow.python.training.basic_session_run_hooks.NanLossDuringTrainingError: NaN loss during training."}