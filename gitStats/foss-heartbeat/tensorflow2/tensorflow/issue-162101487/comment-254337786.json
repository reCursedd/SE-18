{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/254337786", "html_url": "https://github.com/tensorflow/tensorflow/issues/3024#issuecomment-254337786", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3024", "id": 254337786, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NDMzNzc4Ng==", "user": {"login": "holyseven", "id": 13829174, "node_id": "MDQ6VXNlcjEzODI5MTc0", "avatar_url": "https://avatars3.githubusercontent.com/u/13829174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/holyseven", "html_url": "https://github.com/holyseven", "followers_url": "https://api.github.com/users/holyseven/followers", "following_url": "https://api.github.com/users/holyseven/following{/other_user}", "gists_url": "https://api.github.com/users/holyseven/gists{/gist_id}", "starred_url": "https://api.github.com/users/holyseven/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/holyseven/subscriptions", "organizations_url": "https://api.github.com/users/holyseven/orgs", "repos_url": "https://api.github.com/users/holyseven/repos", "events_url": "https://api.github.com/users/holyseven/events{/privacy}", "received_events_url": "https://api.github.com/users/holyseven/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-17T21:21:26Z", "updated_at": "2016-10-17T21:22:03Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> Thanks. I think I get the first point of yours and I finally understand the \"queue\" of tensorflow.</p>\n<p>As for the second point, I don't modify the graph and I use nvidia-smi for checking GPU memory, it doesn't change at all. When I said \"slower and slower\", maybe it's a little exaggerated. After several thousand iterations, it takes around 1.5 times more than at begging but it doesn't become slower after that. Although it's acceptable, it takes less time for the first thousand iterations. I think it's strange.</p>", "body_text": "@yaroslavvb Thanks. I think I get the first point of yours and I finally understand the \"queue\" of tensorflow.\nAs for the second point, I don't modify the graph and I use nvidia-smi for checking GPU memory, it doesn't change at all. When I said \"slower and slower\", maybe it's a little exaggerated. After several thousand iterations, it takes around 1.5 times more than at begging but it doesn't become slower after that. Although it's acceptable, it takes less time for the first thousand iterations. I think it's strange.", "body": "@yaroslavvb Thanks. I think I get the first point of yours and I finally understand the \"queue\" of tensorflow. \n\nAs for the second point, I don't modify the graph and I use nvidia-smi for checking GPU memory, it doesn't change at all. When I said \"slower and slower\", maybe it's a little exaggerated. After several thousand iterations, it takes around 1.5 times more than at begging but it doesn't become slower after that. Although it's acceptable, it takes less time for the first thousand iterations. I think it's strange.\n"}