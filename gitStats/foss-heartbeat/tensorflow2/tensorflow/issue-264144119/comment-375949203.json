{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/375949203", "html_url": "https://github.com/tensorflow/tensorflow/issues/13603#issuecomment-375949203", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13603", "id": 375949203, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NTk0OTIwMw==", "user": {"login": "shamanDevel", "id": 1770337, "node_id": "MDQ6VXNlcjE3NzAzMzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1770337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shamanDevel", "html_url": "https://github.com/shamanDevel", "followers_url": "https://api.github.com/users/shamanDevel/followers", "following_url": "https://api.github.com/users/shamanDevel/following{/other_user}", "gists_url": "https://api.github.com/users/shamanDevel/gists{/gist_id}", "starred_url": "https://api.github.com/users/shamanDevel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shamanDevel/subscriptions", "organizations_url": "https://api.github.com/users/shamanDevel/orgs", "repos_url": "https://api.github.com/users/shamanDevel/repos", "events_url": "https://api.github.com/users/shamanDevel/events{/privacy}", "received_events_url": "https://api.github.com/users/shamanDevel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-25T06:41:48Z", "updated_at": "2018-03-25T06:41:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello,<br>\nI'm back from a long vacation and I'd like to add my piece to the discussion:</p>\n<ul>\n<li>Yes, matrix decompositions are very often slower on the GPU than on the CPU. These are simply problems that are hard to parallelize on the GPU architecture.</li>\n<li>Yes, Eigen without MKL (that's what TF uses on the CPU) is slower than numpy with MKL</li>\n</ul>\n<p>I would vote for keeping the GPU version of the SVD, because for some CPU-GPU configurations and problem sizes, it is indeed faster. That was the case for me when I proposed the Pull Request.<br>\nIs it possible to declare the CPU version as the default one and only use the GPU version if explicitly requested? If I'm not wrong, TF uses always the GPU version if available and if nothing else is specified.</p>", "body_text": "Hello,\nI'm back from a long vacation and I'd like to add my piece to the discussion:\n\nYes, matrix decompositions are very often slower on the GPU than on the CPU. These are simply problems that are hard to parallelize on the GPU architecture.\nYes, Eigen without MKL (that's what TF uses on the CPU) is slower than numpy with MKL\n\nI would vote for keeping the GPU version of the SVD, because for some CPU-GPU configurations and problem sizes, it is indeed faster. That was the case for me when I proposed the Pull Request.\nIs it possible to declare the CPU version as the default one and only use the GPU version if explicitly requested? If I'm not wrong, TF uses always the GPU version if available and if nothing else is specified.", "body": "Hello,\r\nI'm back from a long vacation and I'd like to add my piece to the discussion:\r\n\r\n- Yes, matrix decompositions are very often slower on the GPU than on the CPU. These are simply problems that are hard to parallelize on the GPU architecture. \r\n- Yes, Eigen without MKL (that's what TF uses on the CPU) is slower than numpy with MKL\r\n\r\nI would vote for keeping the GPU version of the SVD, because for some CPU-GPU configurations and problem sizes, it is indeed faster. That was the case for me when I proposed the Pull Request.\r\nIs it possible to declare the CPU version as the default one and only use the GPU version if explicitly requested? If I'm not wrong, TF uses always the GPU version if available and if nothing else is specified."}