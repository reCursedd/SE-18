{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22529", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22529/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22529/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22529/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22529", "id": 363964683, "node_id": "MDU6SXNzdWUzNjM5NjQ2ODM=", "number": 22529, "title": "Feature request: Make contrib.receptive_field extensible", "user": {"login": "jvlmdr", "id": 224198, "node_id": "MDQ6VXNlcjIyNDE5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/224198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvlmdr", "html_url": "https://github.com/jvlmdr", "followers_url": "https://api.github.com/users/jvlmdr/followers", "following_url": "https://api.github.com/users/jvlmdr/following{/other_user}", "gists_url": "https://api.github.com/users/jvlmdr/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvlmdr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvlmdr/subscriptions", "organizations_url": "https://api.github.com/users/jvlmdr/orgs", "repos_url": "https://api.github.com/users/jvlmdr/repos", "events_url": "https://api.github.com/users/jvlmdr/events{/privacy}", "received_events_url": "https://api.github.com/users/jvlmdr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-09-26T10:40:04Z", "updated_at": "2018-10-13T17:08:07Z", "closed_at": "2018-10-13T17:08:07Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8.0</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>For the problem I am working on, I need to compute a cross-correlation where the filters are a function of some inputs, i.e. <code>c_i = conv2d(f(a_i), g(b_i))</code> for the <code>i</code>-th example <code>(a_i, b_i)</code> in the batch. After doing this, the receptive field of <code>c</code> with respect to <code>a</code> is still well-defined.</p>\n<p>I can think of several ways to implement this, but none of them are compatible with <code>receptive_field</code>!</p>\n<p>For example, I usually use <code>reshape</code>-<code>depthwise_conv2d</code>-<code>reshape</code>-<code>sum</code> to transform a batch of <code>B</code> convolutions with <code>C</code> channels into a batch of <code>1</code> depthwise-convolution with <code>B*C</code> channels, then sum over the <code>C</code> channels at the end. Another way to do it would be using <code>tf.map_fn</code>. However, neither of these will work with <code>compute_receptive_field_from_graph_def</code>.</p>\n<p>I understand that it would be very difficult to support edge cases like this. However, it breaks the workflow a bit to keep track of every place where the graph is incompatible with <code>receptive_field</code> and perform the composition manually here.</p>\n<p>Perhaps it would be possible to add a manual override parameter to <code>compute_receptive_field_from_graph_def</code> that allows a user to manually specify the receptive field from one node to another, instead of using the graph?</p>\n<p>Another way could be to support custom layers, either by checking if the custom layer has a receptive field method, or allowing users to register custom layers with the <code>receptive_field</code> module. However, this would require me to write my own layer for the \"dynamic\" convolution described above, which is not currently necessary.</p>\n<p>I'm open to suggestions!</p>", "body_text": "System information\n\nTensorFlow version (use command below): 1.8.0\n\nDescribe the problem\nFor the problem I am working on, I need to compute a cross-correlation where the filters are a function of some inputs, i.e. c_i = conv2d(f(a_i), g(b_i)) for the i-th example (a_i, b_i) in the batch. After doing this, the receptive field of c with respect to a is still well-defined.\nI can think of several ways to implement this, but none of them are compatible with receptive_field!\nFor example, I usually use reshape-depthwise_conv2d-reshape-sum to transform a batch of B convolutions with C channels into a batch of 1 depthwise-convolution with B*C channels, then sum over the C channels at the end. Another way to do it would be using tf.map_fn. However, neither of these will work with compute_receptive_field_from_graph_def.\nI understand that it would be very difficult to support edge cases like this. However, it breaks the workflow a bit to keep track of every place where the graph is incompatible with receptive_field and perform the composition manually here.\nPerhaps it would be possible to add a manual override parameter to compute_receptive_field_from_graph_def that allows a user to manually specify the receptive field from one node to another, instead of using the graph?\nAnother way could be to support custom layers, either by checking if the custom layer has a receptive field method, or allowing users to register custom layers with the receptive_field module. However, this would require me to write my own layer for the \"dynamic\" convolution described above, which is not currently necessary.\nI'm open to suggestions!", "body": "### System information\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n\r\n### Describe the problem\r\n\r\nFor the problem I am working on, I need to compute a cross-correlation where the filters are a function of some inputs, i.e. `c_i = conv2d(f(a_i), g(b_i))` for the `i`-th example `(a_i, b_i)` in the batch. After doing this, the receptive field of `c` with respect to `a` is still well-defined.\r\n\r\nI can think of several ways to implement this, but none of them are compatible with `receptive_field`!\r\n\r\nFor example, I usually use `reshape`-`depthwise_conv2d`-`reshape`-`sum` to transform a batch of `B` convolutions with `C` channels into a batch of `1` depthwise-convolution with `B*C` channels, then sum over the `C` channels at the end. Another way to do it would be using `tf.map_fn`. However, neither of these will work with `compute_receptive_field_from_graph_def`.\r\n\r\nI understand that it would be very difficult to support edge cases like this. However, it breaks the workflow a bit to keep track of every place where the graph is incompatible with `receptive_field` and perform the composition manually here.\r\n\r\nPerhaps it would be possible to add a manual override parameter to `compute_receptive_field_from_graph_def` that allows a user to manually specify the receptive field from one node to another, instead of using the graph?\r\n\r\nAnother way could be to support custom layers, either by checking if the custom layer has a receptive field method, or allowing users to register custom layers with the `receptive_field` module. However, this would require me to write my own layer for the \"dynamic\" convolution described above, which is not currently necessary.\r\n\r\nI'm open to suggestions!"}