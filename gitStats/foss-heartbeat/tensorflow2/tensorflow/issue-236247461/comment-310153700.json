{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310153700", "html_url": "https://github.com/tensorflow/tensorflow/issues/10736#issuecomment-310153700", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10736", "id": 310153700, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDE1MzcwMA==", "user": {"login": "woodshop", "id": 4654379, "node_id": "MDQ6VXNlcjQ2NTQzNzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4654379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woodshop", "html_url": "https://github.com/woodshop", "followers_url": "https://api.github.com/users/woodshop/followers", "following_url": "https://api.github.com/users/woodshop/following{/other_user}", "gists_url": "https://api.github.com/users/woodshop/gists{/gist_id}", "starred_url": "https://api.github.com/users/woodshop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woodshop/subscriptions", "organizations_url": "https://api.github.com/users/woodshop/orgs", "repos_url": "https://api.github.com/users/woodshop/repos", "events_url": "https://api.github.com/users/woodshop/events{/privacy}", "received_events_url": "https://api.github.com/users/woodshop/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-21T17:43:35Z", "updated_at": "2017-06-21T17:43:35Z", "author_association": "NONE", "body_html": "<p>I have the following workaround, which doesn't require rewriting any TF code.</p>\n<p>The callable<code>dynamic_decode</code> returns <code>final_outputs</code>, <code>final_state</code>, and <code>final_sequence_lengths</code>. The output argument <code>final_outputs</code> itself is an instance of <code>BasicDecoderOutput</code>, which is essentially a named tuple having the elements <code>[rnn_output, sample_id]</code>. If no operations in your graph depend on <code>sample_id</code>, and if the input argument <code>impute_finished </code> to <code>dynamic_decode</code> is set to <code>False</code> (the default), then no errors will be raised.</p>\n<p>I.e., following the example code above, one could write:</p>\n<div class=\"highlight highlight-source-python\"><pre>    decoded <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n        decoder,\n        <span class=\"pl-v\">impute_finished</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    final_outputs, final_state, final_sequence_lengths <span class=\"pl-k\">=</span> decoded\n    decoded <span class=\"pl-k\">=</span> [[final_outputs[<span class=\"pl-c1\">0</span>]], final_state, final_sequence_lengths]\n\n    run_ops <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>decoded<span class=\"pl-pds\">'</span></span>: decoded}</pre></div>\n<p>Of course, this assumes that <code>impute_finished</code> and <code>sample_id</code> are not necessary to your task. Otherwise, you'll probably have to modify <code>ScheduledOutputTrainingHelper.sample</code></p>", "body_text": "I have the following workaround, which doesn't require rewriting any TF code.\nThe callabledynamic_decode returns final_outputs, final_state, and final_sequence_lengths. The output argument final_outputs itself is an instance of BasicDecoderOutput, which is essentially a named tuple having the elements [rnn_output, sample_id]. If no operations in your graph depend on sample_id, and if the input argument impute_finished  to dynamic_decode is set to False (the default), then no errors will be raised.\nI.e., following the example code above, one could write:\n    decoded = tf.contrib.seq2seq.dynamic_decode(\n        decoder,\n        impute_finished=False)\n    final_outputs, final_state, final_sequence_lengths = decoded\n    decoded = [[final_outputs[0]], final_state, final_sequence_lengths]\n\n    run_ops = {'decoded': decoded}\nOf course, this assumes that impute_finished and sample_id are not necessary to your task. Otherwise, you'll probably have to modify ScheduledOutputTrainingHelper.sample", "body": "I have the following workaround, which doesn't require rewriting any TF code.\r\n \r\nThe callable`dynamic_decode` returns `final_outputs`, `final_state`, and `final_sequence_lengths`. The output argument `final_outputs` itself is an instance of `BasicDecoderOutput`, which is essentially a named tuple having the elements `[rnn_output, sample_id]`. If no operations in your graph depend on `sample_id`, and if the input argument `impute_finished ` to `dynamic_decode` is set to `False` (the default), then no errors will be raised.\r\n\r\nI.e., following the example code above, one could write:\r\n```python\r\n    decoded = tf.contrib.seq2seq.dynamic_decode(\r\n        decoder,\r\n        impute_finished=False)\r\n    final_outputs, final_state, final_sequence_lengths = decoded\r\n    decoded = [[final_outputs[0]], final_state, final_sequence_lengths]\r\n\r\n    run_ops = {'decoded': decoded}\r\n```\r\nOf course, this assumes that `impute_finished` and `sample_id` are not necessary to your task. Otherwise, you'll probably have to modify `ScheduledOutputTrainingHelper.sample`"}