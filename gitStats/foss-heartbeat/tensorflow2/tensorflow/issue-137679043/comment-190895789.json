{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/190895789", "html_url": "https://github.com/tensorflow/tensorflow/issues/1347#issuecomment-190895789", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1347", "id": 190895789, "node_id": "MDEyOklzc3VlQ29tbWVudDE5MDg5NTc4OQ==", "user": {"login": "ponythewhite", "id": 585524, "node_id": "MDQ6VXNlcjU4NTUyNA==", "avatar_url": "https://avatars3.githubusercontent.com/u/585524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ponythewhite", "html_url": "https://github.com/ponythewhite", "followers_url": "https://api.github.com/users/ponythewhite/followers", "following_url": "https://api.github.com/users/ponythewhite/following{/other_user}", "gists_url": "https://api.github.com/users/ponythewhite/gists{/gist_id}", "starred_url": "https://api.github.com/users/ponythewhite/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ponythewhite/subscriptions", "organizations_url": "https://api.github.com/users/ponythewhite/orgs", "repos_url": "https://api.github.com/users/ponythewhite/repos", "events_url": "https://api.github.com/users/ponythewhite/events{/privacy}", "received_events_url": "https://api.github.com/users/ponythewhite/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-01T20:48:33Z", "updated_at": "2016-03-01T20:48:33Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nvocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1337</span>\nembedding_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\nQmax <span class=\"pl-k\">=</span> <span class=\"pl-c1\">19</span>\nTmax <span class=\"pl-k\">=</span> <span class=\"pl-c1\">17</span>\n\nW <span class=\"pl-k\">=</span> tf.Variable(\n    tf.random_uniform([vocab_size, embedding_size], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>) ,<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>W<span class=\"pl-pds\">\"</span></span>)\n\n_x <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>int32<span class=\"pl-pds\">\"</span></span>, [batch_size, Qmax<span class=\"pl-k\">+</span>Tmax])\n\nE <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(W, _x)\n\nA <span class=\"pl-k\">=</span> tf.reduce_mean(tf.slice(E, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, Qmax, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]), [<span class=\"pl-c1\">1</span>])\nB <span class=\"pl-k\">=</span> tf.reduce_mean(tf.slice(E, [<span class=\"pl-c1\">0</span>, Qmax, <span class=\"pl-c1\">0</span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, Tmax, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]), [<span class=\"pl-c1\">1</span>])\n\ncost <span class=\"pl-k\">=</span> tf.reduce_mean(tf.add(A, B))\n\noptimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.001</span>).minimize(cost)</pre></div>\n<p>Seems to be a functional workaround.</p>", "body_text": "import tensorflow as tf\n\nvocab_size = 1337\nembedding_size = 100\nbatch_size = 512\nQmax = 19\nTmax = 17\n\nW = tf.Variable(\n    tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0) ,name=\"W\")\n\n_x = tf.placeholder(\"int32\", [batch_size, Qmax+Tmax])\n\nE = tf.nn.embedding_lookup(W, _x)\n\nA = tf.reduce_mean(tf.slice(E, [0, 0, 0], [-1, Qmax, -1]), [1])\nB = tf.reduce_mean(tf.slice(E, [0, Qmax, 0], [-1, Tmax, -1]), [1])\n\ncost = tf.reduce_mean(tf.add(A, B))\n\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\nSeems to be a functional workaround.", "body": "``` python\nimport tensorflow as tf\n\nvocab_size = 1337\nembedding_size = 100\nbatch_size = 512\nQmax = 19\nTmax = 17\n\nW = tf.Variable(\n    tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0) ,name=\"W\")\n\n_x = tf.placeholder(\"int32\", [batch_size, Qmax+Tmax])\n\nE = tf.nn.embedding_lookup(W, _x)\n\nA = tf.reduce_mean(tf.slice(E, [0, 0, 0], [-1, Qmax, -1]), [1])\nB = tf.reduce_mean(tf.slice(E, [0, Qmax, 0], [-1, Tmax, -1]), [1])\n\ncost = tf.reduce_mean(tf.add(A, B))\n\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n```\n\nSeems to be a functional workaround.\n"}