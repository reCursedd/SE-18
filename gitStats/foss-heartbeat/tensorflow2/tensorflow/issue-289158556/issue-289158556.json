{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16179", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16179/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16179/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16179/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16179", "id": 289158556, "node_id": "MDU6SXNzdWUyODkxNTg1NTY=", "number": 16179, "title": "ProfilerHook and loading libcupti.so cause Ubuntu to completely freeze", "user": {"login": "iliTheFallen", "id": 8805234, "node_id": "MDQ6VXNlcjg4MDUyMzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8805234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iliTheFallen", "html_url": "https://github.com/iliTheFallen", "followers_url": "https://api.github.com/users/iliTheFallen/followers", "following_url": "https://api.github.com/users/iliTheFallen/following{/other_user}", "gists_url": "https://api.github.com/users/iliTheFallen/gists{/gist_id}", "starred_url": "https://api.github.com/users/iliTheFallen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iliTheFallen/subscriptions", "organizations_url": "https://api.github.com/users/iliTheFallen/orgs", "repos_url": "https://api.github.com/users/iliTheFallen/repos", "events_url": "https://api.github.com/users/iliTheFallen/events{/privacy}", "received_events_url": "https://api.github.com/users/iliTheFallen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2018-01-17T06:43:45Z", "updated_at": "2018-06-10T18:50:10Z", "closed_at": "2018-06-10T18:33:00Z", "author_association": "NONE", "body_html": "<ol>\n<li>OS Platform and Distribution: Ubuntu 14.04 LTE</li>\n<li>TensorFlow version: 1.14</li>\n<li>Bazel version: 0.9.0</li>\n<li>CUDA/cuDNN version: 8.0/7.0.5</li>\n<li>GPU model and memory: GeForce GTX1060 - 6070MB</li>\n<li>Exact command to reproduce: python3.4 -m music_modeling<br>\n--</li>\n</ol>\n<p>I added \"ProfilerHook\" to Estimator for recording GPU memory consumption; but it always causes my Ubuntu to freeze indefinitely and Ubuntu never makes away with it.</p>\n<p>Here is the source code:</p>\n<pre><code>import tensorflow as tf\n\nfrom tensorflow.python.layers.core import dense\nfrom tensorflow.python import debug as tf_debug\n\nfrom data.music_data_reader import MusicDataReader\nfrom model.tf_msa_rnn import dynamic_msa_rnn\n\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string(\"mode\", tf.estimator.ModeKeys.TRAIN,\n                           \"\"\"\"Is training or testing mode\"\"\")\ntf.app.flags.DEFINE_string(\"model_dir\", './msa_model',\n                           \"\"\"\"Directory in where checkpoints are stored\"\"\")\ntf.app.flags.DEFINE_integer(\"batch_size\", 20,\n                            \"\"\"Number of samples in a batch\"\"\")\ntf.app.flags.DEFINE_integer(\"num_epochs\", 100,\n                            \"\"\"\"How many times the whole training set has to be fed into network\"\"\")\ntf.app.flags.DEFINE_string(\"log_directory\", './log_dir',\n                           \"\"\"\"Directory in where logs and checkpoints are stored\"\"\")\n# *************************************\n# *************************************Configuration options for the network\n# *************************************\ntf.app.flags.DEFINE_integer(\"num_units\", 30,\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\ntf.app.flags.DEFINE_integer(\"num_msa_feats\", 10,\n                            \"\"\"\"# of MS features to be learned\"\"\")\ntf.app.flags.DEFINE_integer(\"signal_len\", 100,\n                            \"\"\"\"Length of the signal at a time to be processed by \n                                multi-scale analyzer\n                            \"\"\")\ntf.app.flags.DEFINE_integer(\"dim_pitch\", 88,\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\n# *************************************\n# *************************************Configuration options for dataset\n# *************************************\ntf.app.flags.DEFINE_string(\"dir_path\",\n                           './music_samples/MuseData',\n                           \"\"\"\"Absolute path to the music files for reading training/testing samples\"\"\")\ntf.app.flags.DEFINE_integer(\"pitch_low\",\n                            21,\n                            \"\"\"\"Low pitch value\"\"\")\ntf.app.flags.DEFINE_integer(\"pitch_high\",\n                            109,\n                            \"\"\"\"High pitch value\"\"\")\ntf.app.flags.DEFINE_float(\"dt\",\n                          0.3,\n                          \"\"\"\"Not sure yet...\"\"\")\n\n\ndef loss_fn(y_pred, y_true):\n    '''\n\n    :param y_pred: Logits predicted by the model\n    :param y_true: Correct values corresponding each prediction\n    :return:\n    '''\n\n    y_pred = tf.log(tf.nn.softmax(y_pred, name=\"probs_tensor\"))  # [BSxMTxOS] -- Probabilities\n    p_trun = y_pred[:, 0:-1, ...]  # x'[1], x'[2], ..., x'[N-1]\n    t_trun = y_true[:, 1:, ...]  # x[1], x[2], ..., x[N-1]\n    loss = tf.reduce_sum(p_trun*t_trun, axis=2)  # [BSxMT] -- Dot product between 3rd dimensions\n    loss = tf.reduce_mean(loss, name=\"piano_roll_loss\")  # loss function -- returns a scalar\n    tf.summary.scalar(\"loss_fn\", loss)  # Add summary for the loss\n    loss = tf.Print(loss, [loss], \"Loss: \")\n    return loss\n\n\ndef model_fn(features,\n             mode=tf.estimator.ModeKeys.TRAIN,\n             params=None):\n\n    print(\"Creating Model...\")\n    input_ph = tf.reshape(features['input_ph'], [FLAGS.batch_size, params['max_seq'], FLAGS.dim_pitch])\n    seq_len_ph = tf.reshape(features['seq_len_ph'], [FLAGS.batch_size])\n    outputs, state = dynamic_msa_rnn(FLAGS.batch_size,\n                                     input_ph,\n                                     seq_len_ph,\n                                     params['max_seq'],\n                                     FLAGS.signal_len,\n                                     [20, 10],  # Number of filters per layer\n                                     [11, 13],  # Kernel size for each layer\n                                     [3],  # Pooling size for each layer\n                                     FLAGS.num_msa_feats,\n                                     FLAGS.num_units,\n                                     activation=tf.nn.tanh,\n                                     initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]\n    # Create fully connected layer to generate output for piano keys\n    outs = dense(outputs,\n                 FLAGS.dim_pitch,\n                 kernel_initializer=tf.glorot_normal_initializer())  # BSxMTxID\n    loss = loss_fn(outs, features['input_ph'])\n    print(\"Creating Estimator Spec for %s ...\" % mode)\n    # For training\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer()\n        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode,\n                                          loss=loss,\n                                          train_op=train_op)\n    # For evaluation\n    eval_metric_ops = {\n        \"accuracy\": tf.metrics.accuracy(\n            labels=tf.argmax(features['input_ph'][:, 1:, ...], axis=-1),\n            predictions=tf.argmax(outs[:, 0:-1, ...], axis=-1)\n        )\n    }\n    return tf.estimator.EstimatorSpec(mode=mode,\n                                      loss=loss,\n                                      eval_metric_ops=eval_metric_ops)\n\n\ndef do_train(tr_data, vl_data):\n\n    # Create Estimator\n    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n    sess_conf.gpu_options.allow_growth = True\n    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook\n                                    save_checkpoints_steps=100,  # CheckpointSaverHook\n                                    log_step_count_steps=10,  # SummarySaverHook\n                                    session_config=sess_conf)\n    music_classifier = tf.estimator.Estimator(model_fn,\n                                              config=config,\n                                              params={'max_seq': tr_data.max_seq})\n    # Prepare input data\n    tr_input_fn = tf.estimator.inputs.numpy_input_fn(\n        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},\n        batch_size=FLAGS.batch_size,\n        num_epochs=FLAGS.num_epochs,\n        num_threads=1,\n        shuffle=True\n    )\n    # Extra Hooks\n    logging_hook = tf.train.LoggingTensorHook(\n        tensors={'probabilities': 'probs_tensor'},\n        every_n_secs=60\n    )\n    # debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter=\"MainThread$\", dump_root=\"./dump\")\n    profiler_hook = tf.train.ProfilerHook(save_steps=1,\n                                          output_dir=\"./profile\",\n                                          show_dataflow=False,\n                                          show_memory=True)\n    # Train\n    music_classifier.train(tr_input_fn, hooks=[profiler_hook])\n    print(\"Training is over...\")\n\n\ndef do_test(te_data):\n\n    print(\"Start testing...\")\n\n\ndef main(_):\n\n    if FLAGS.mode == tf.estimator.ModeKeys.TRAIN:\n        tr_data = MusicDataReader(FLAGS.dir_path,\n                                  'train',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt)\n        vl_data = MusicDataReader(FLAGS.dir_path,\n                                  'valid',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt)\n        print(\"Number of training samples: %d\" % tr_data.data_num)\n        print(\"Number of validation samples: %d\" % vl_data.data_num)\n        do_train(tr_data, vl_data)\n    else:\n        te_data = MusicDataReader(FLAGS.dir_path,\n                                  'test',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt,)\n        print(\"Number of testing samples: %d\" % te_data.data_num)\n        do_test(te_data)\n\n\nif __name__ == \"__main__\":\n    tf.app.run(main=main)\n</code></pre>\n<p>I cannot attach the output of my console for it is impossible due to the indefinite freezing of my Ubuntu. All I can say is that it tells me that it loads <strong>libcupti.so</strong> and computes a step of training process. Then, everything totally messes up.</p>\n<p>Thank you for your support in advance.</p>", "body_text": "OS Platform and Distribution: Ubuntu 14.04 LTE\nTensorFlow version: 1.14\nBazel version: 0.9.0\nCUDA/cuDNN version: 8.0/7.0.5\nGPU model and memory: GeForce GTX1060 - 6070MB\nExact command to reproduce: python3.4 -m music_modeling\n--\n\nI added \"ProfilerHook\" to Estimator for recording GPU memory consumption; but it always causes my Ubuntu to freeze indefinitely and Ubuntu never makes away with it.\nHere is the source code:\nimport tensorflow as tf\n\nfrom tensorflow.python.layers.core import dense\nfrom tensorflow.python import debug as tf_debug\n\nfrom data.music_data_reader import MusicDataReader\nfrom model.tf_msa_rnn import dynamic_msa_rnn\n\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string(\"mode\", tf.estimator.ModeKeys.TRAIN,\n                           \"\"\"\"Is training or testing mode\"\"\")\ntf.app.flags.DEFINE_string(\"model_dir\", './msa_model',\n                           \"\"\"\"Directory in where checkpoints are stored\"\"\")\ntf.app.flags.DEFINE_integer(\"batch_size\", 20,\n                            \"\"\"Number of samples in a batch\"\"\")\ntf.app.flags.DEFINE_integer(\"num_epochs\", 100,\n                            \"\"\"\"How many times the whole training set has to be fed into network\"\"\")\ntf.app.flags.DEFINE_string(\"log_directory\", './log_dir',\n                           \"\"\"\"Directory in where logs and checkpoints are stored\"\"\")\n# *************************************\n# *************************************Configuration options for the network\n# *************************************\ntf.app.flags.DEFINE_integer(\"num_units\", 30,\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\ntf.app.flags.DEFINE_integer(\"num_msa_feats\", 10,\n                            \"\"\"\"# of MS features to be learned\"\"\")\ntf.app.flags.DEFINE_integer(\"signal_len\", 100,\n                            \"\"\"\"Length of the signal at a time to be processed by \n                                multi-scale analyzer\n                            \"\"\")\ntf.app.flags.DEFINE_integer(\"dim_pitch\", 88,\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\n# *************************************\n# *************************************Configuration options for dataset\n# *************************************\ntf.app.flags.DEFINE_string(\"dir_path\",\n                           './music_samples/MuseData',\n                           \"\"\"\"Absolute path to the music files for reading training/testing samples\"\"\")\ntf.app.flags.DEFINE_integer(\"pitch_low\",\n                            21,\n                            \"\"\"\"Low pitch value\"\"\")\ntf.app.flags.DEFINE_integer(\"pitch_high\",\n                            109,\n                            \"\"\"\"High pitch value\"\"\")\ntf.app.flags.DEFINE_float(\"dt\",\n                          0.3,\n                          \"\"\"\"Not sure yet...\"\"\")\n\n\ndef loss_fn(y_pred, y_true):\n    '''\n\n    :param y_pred: Logits predicted by the model\n    :param y_true: Correct values corresponding each prediction\n    :return:\n    '''\n\n    y_pred = tf.log(tf.nn.softmax(y_pred, name=\"probs_tensor\"))  # [BSxMTxOS] -- Probabilities\n    p_trun = y_pred[:, 0:-1, ...]  # x'[1], x'[2], ..., x'[N-1]\n    t_trun = y_true[:, 1:, ...]  # x[1], x[2], ..., x[N-1]\n    loss = tf.reduce_sum(p_trun*t_trun, axis=2)  # [BSxMT] -- Dot product between 3rd dimensions\n    loss = tf.reduce_mean(loss, name=\"piano_roll_loss\")  # loss function -- returns a scalar\n    tf.summary.scalar(\"loss_fn\", loss)  # Add summary for the loss\n    loss = tf.Print(loss, [loss], \"Loss: \")\n    return loss\n\n\ndef model_fn(features,\n             mode=tf.estimator.ModeKeys.TRAIN,\n             params=None):\n\n    print(\"Creating Model...\")\n    input_ph = tf.reshape(features['input_ph'], [FLAGS.batch_size, params['max_seq'], FLAGS.dim_pitch])\n    seq_len_ph = tf.reshape(features['seq_len_ph'], [FLAGS.batch_size])\n    outputs, state = dynamic_msa_rnn(FLAGS.batch_size,\n                                     input_ph,\n                                     seq_len_ph,\n                                     params['max_seq'],\n                                     FLAGS.signal_len,\n                                     [20, 10],  # Number of filters per layer\n                                     [11, 13],  # Kernel size for each layer\n                                     [3],  # Pooling size for each layer\n                                     FLAGS.num_msa_feats,\n                                     FLAGS.num_units,\n                                     activation=tf.nn.tanh,\n                                     initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]\n    # Create fully connected layer to generate output for piano keys\n    outs = dense(outputs,\n                 FLAGS.dim_pitch,\n                 kernel_initializer=tf.glorot_normal_initializer())  # BSxMTxID\n    loss = loss_fn(outs, features['input_ph'])\n    print(\"Creating Estimator Spec for %s ...\" % mode)\n    # For training\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer()\n        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode,\n                                          loss=loss,\n                                          train_op=train_op)\n    # For evaluation\n    eval_metric_ops = {\n        \"accuracy\": tf.metrics.accuracy(\n            labels=tf.argmax(features['input_ph'][:, 1:, ...], axis=-1),\n            predictions=tf.argmax(outs[:, 0:-1, ...], axis=-1)\n        )\n    }\n    return tf.estimator.EstimatorSpec(mode=mode,\n                                      loss=loss,\n                                      eval_metric_ops=eval_metric_ops)\n\n\ndef do_train(tr_data, vl_data):\n\n    # Create Estimator\n    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n    sess_conf.gpu_options.allow_growth = True\n    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook\n                                    save_checkpoints_steps=100,  # CheckpointSaverHook\n                                    log_step_count_steps=10,  # SummarySaverHook\n                                    session_config=sess_conf)\n    music_classifier = tf.estimator.Estimator(model_fn,\n                                              config=config,\n                                              params={'max_seq': tr_data.max_seq})\n    # Prepare input data\n    tr_input_fn = tf.estimator.inputs.numpy_input_fn(\n        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},\n        batch_size=FLAGS.batch_size,\n        num_epochs=FLAGS.num_epochs,\n        num_threads=1,\n        shuffle=True\n    )\n    # Extra Hooks\n    logging_hook = tf.train.LoggingTensorHook(\n        tensors={'probabilities': 'probs_tensor'},\n        every_n_secs=60\n    )\n    # debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter=\"MainThread$\", dump_root=\"./dump\")\n    profiler_hook = tf.train.ProfilerHook(save_steps=1,\n                                          output_dir=\"./profile\",\n                                          show_dataflow=False,\n                                          show_memory=True)\n    # Train\n    music_classifier.train(tr_input_fn, hooks=[profiler_hook])\n    print(\"Training is over...\")\n\n\ndef do_test(te_data):\n\n    print(\"Start testing...\")\n\n\ndef main(_):\n\n    if FLAGS.mode == tf.estimator.ModeKeys.TRAIN:\n        tr_data = MusicDataReader(FLAGS.dir_path,\n                                  'train',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt)\n        vl_data = MusicDataReader(FLAGS.dir_path,\n                                  'valid',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt)\n        print(\"Number of training samples: %d\" % tr_data.data_num)\n        print(\"Number of validation samples: %d\" % vl_data.data_num)\n        do_train(tr_data, vl_data)\n    else:\n        te_data = MusicDataReader(FLAGS.dir_path,\n                                  'test',\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\n                                  FLAGS.dt,)\n        print(\"Number of testing samples: %d\" % te_data.data_num)\n        do_test(te_data)\n\n\nif __name__ == \"__main__\":\n    tf.app.run(main=main)\n\nI cannot attach the output of my console for it is impossible due to the indefinite freezing of my Ubuntu. All I can say is that it tells me that it loads libcupti.so and computes a step of training process. Then, everything totally messes up.\nThank you for your support in advance.", "body": "1. OS Platform and Distribution: Ubuntu 14.04 LTE\r\n2. TensorFlow version: 1.14\r\n3. Bazel version: 0.9.0\r\n4. CUDA/cuDNN version: 8.0/7.0.5\r\n5. GPU model and memory: GeForce GTX1060 - 6070MB\r\n6. Exact command to reproduce: python3.4 -m music_modeling \r\n--\r\n\r\nI added \"ProfilerHook\" to Estimator for recording GPU memory consumption; but it always causes my Ubuntu to freeze indefinitely and Ubuntu never makes away with it.\r\n\r\nHere is the source code:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python.layers.core import dense\r\nfrom tensorflow.python import debug as tf_debug\r\n\r\nfrom data.music_data_reader import MusicDataReader\r\nfrom model.tf_msa_rnn import dynamic_msa_rnn\r\n\r\n\r\nFLAGS = tf.app.flags.FLAGS\r\ntf.app.flags.DEFINE_string(\"mode\", tf.estimator.ModeKeys.TRAIN,\r\n                           \"\"\"\"Is training or testing mode\"\"\")\r\ntf.app.flags.DEFINE_string(\"model_dir\", './msa_model',\r\n                           \"\"\"\"Directory in where checkpoints are stored\"\"\")\r\ntf.app.flags.DEFINE_integer(\"batch_size\", 20,\r\n                            \"\"\"Number of samples in a batch\"\"\")\r\ntf.app.flags.DEFINE_integer(\"num_epochs\", 100,\r\n                            \"\"\"\"How many times the whole training set has to be fed into network\"\"\")\r\ntf.app.flags.DEFINE_string(\"log_directory\", './log_dir',\r\n                           \"\"\"\"Directory in where logs and checkpoints are stored\"\"\")\r\n# *************************************\r\n# *************************************Configuration options for the network\r\n# *************************************\r\ntf.app.flags.DEFINE_integer(\"num_units\", 30,\r\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\r\ntf.app.flags.DEFINE_integer(\"num_msa_feats\", 10,\r\n                            \"\"\"\"# of MS features to be learned\"\"\")\r\ntf.app.flags.DEFINE_integer(\"signal_len\", 100,\r\n                            \"\"\"\"Length of the signal at a time to be processed by \r\n                                multi-scale analyzer\r\n                            \"\"\")\r\ntf.app.flags.DEFINE_integer(\"dim_pitch\", 88,\r\n                            \"\"\"\"# of hidden units in an LSTM cell\"\"\")\r\n# *************************************\r\n# *************************************Configuration options for dataset\r\n# *************************************\r\ntf.app.flags.DEFINE_string(\"dir_path\",\r\n                           './music_samples/MuseData',\r\n                           \"\"\"\"Absolute path to the music files for reading training/testing samples\"\"\")\r\ntf.app.flags.DEFINE_integer(\"pitch_low\",\r\n                            21,\r\n                            \"\"\"\"Low pitch value\"\"\")\r\ntf.app.flags.DEFINE_integer(\"pitch_high\",\r\n                            109,\r\n                            \"\"\"\"High pitch value\"\"\")\r\ntf.app.flags.DEFINE_float(\"dt\",\r\n                          0.3,\r\n                          \"\"\"\"Not sure yet...\"\"\")\r\n\r\n\r\ndef loss_fn(y_pred, y_true):\r\n    '''\r\n\r\n    :param y_pred: Logits predicted by the model\r\n    :param y_true: Correct values corresponding each prediction\r\n    :return:\r\n    '''\r\n\r\n    y_pred = tf.log(tf.nn.softmax(y_pred, name=\"probs_tensor\"))  # [BSxMTxOS] -- Probabilities\r\n    p_trun = y_pred[:, 0:-1, ...]  # x'[1], x'[2], ..., x'[N-1]\r\n    t_trun = y_true[:, 1:, ...]  # x[1], x[2], ..., x[N-1]\r\n    loss = tf.reduce_sum(p_trun*t_trun, axis=2)  # [BSxMT] -- Dot product between 3rd dimensions\r\n    loss = tf.reduce_mean(loss, name=\"piano_roll_loss\")  # loss function -- returns a scalar\r\n    tf.summary.scalar(\"loss_fn\", loss)  # Add summary for the loss\r\n    loss = tf.Print(loss, [loss], \"Loss: \")\r\n    return loss\r\n\r\n\r\ndef model_fn(features,\r\n             mode=tf.estimator.ModeKeys.TRAIN,\r\n             params=None):\r\n\r\n    print(\"Creating Model...\")\r\n    input_ph = tf.reshape(features['input_ph'], [FLAGS.batch_size, params['max_seq'], FLAGS.dim_pitch])\r\n    seq_len_ph = tf.reshape(features['seq_len_ph'], [FLAGS.batch_size])\r\n    outputs, state = dynamic_msa_rnn(FLAGS.batch_size,\r\n                                     input_ph,\r\n                                     seq_len_ph,\r\n                                     params['max_seq'],\r\n                                     FLAGS.signal_len,\r\n                                     [20, 10],  # Number of filters per layer\r\n                                     [11, 13],  # Kernel size for each layer\r\n                                     [3],  # Pooling size for each layer\r\n                                     FLAGS.num_msa_feats,\r\n                                     FLAGS.num_units,\r\n                                     activation=tf.nn.tanh,\r\n                                     initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]\r\n    # Create fully connected layer to generate output for piano keys\r\n    outs = dense(outputs,\r\n                 FLAGS.dim_pitch,\r\n                 kernel_initializer=tf.glorot_normal_initializer())  # BSxMTxID\r\n    loss = loss_fn(outs, features['input_ph'])\r\n    print(\"Creating Estimator Spec for %s ...\" % mode)\r\n    # For training\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.AdamOptimizer()\r\n        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode=mode,\r\n                                          loss=loss,\r\n                                          train_op=train_op)\r\n    # For evaluation\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(\r\n            labels=tf.argmax(features['input_ph'][:, 1:, ...], axis=-1),\r\n            predictions=tf.argmax(outs[:, 0:-1, ...], axis=-1)\r\n        )\r\n    }\r\n    return tf.estimator.EstimatorSpec(mode=mode,\r\n                                      loss=loss,\r\n                                      eval_metric_ops=eval_metric_ops)\r\n\r\n\r\ndef do_train(tr_data, vl_data):\r\n\r\n    # Create Estimator\r\n    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\r\n    sess_conf.gpu_options.allow_growth = True\r\n    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook\r\n                                    save_checkpoints_steps=100,  # CheckpointSaverHook\r\n                                    log_step_count_steps=10,  # SummarySaverHook\r\n                                    session_config=sess_conf)\r\n    music_classifier = tf.estimator.Estimator(model_fn,\r\n                                              config=config,\r\n                                              params={'max_seq': tr_data.max_seq})\r\n    # Prepare input data\r\n    tr_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},\r\n        batch_size=FLAGS.batch_size,\r\n        num_epochs=FLAGS.num_epochs,\r\n        num_threads=1,\r\n        shuffle=True\r\n    )\r\n    # Extra Hooks\r\n    logging_hook = tf.train.LoggingTensorHook(\r\n        tensors={'probabilities': 'probs_tensor'},\r\n        every_n_secs=60\r\n    )\r\n    # debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter=\"MainThread$\", dump_root=\"./dump\")\r\n    profiler_hook = tf.train.ProfilerHook(save_steps=1,\r\n                                          output_dir=\"./profile\",\r\n                                          show_dataflow=False,\r\n                                          show_memory=True)\r\n    # Train\r\n    music_classifier.train(tr_input_fn, hooks=[profiler_hook])\r\n    print(\"Training is over...\")\r\n\r\n\r\ndef do_test(te_data):\r\n\r\n    print(\"Start testing...\")\r\n\r\n\r\ndef main(_):\r\n\r\n    if FLAGS.mode == tf.estimator.ModeKeys.TRAIN:\r\n        tr_data = MusicDataReader(FLAGS.dir_path,\r\n                                  'train',\r\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\r\n                                  FLAGS.dt)\r\n        vl_data = MusicDataReader(FLAGS.dir_path,\r\n                                  'valid',\r\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\r\n                                  FLAGS.dt)\r\n        print(\"Number of training samples: %d\" % tr_data.data_num)\r\n        print(\"Number of validation samples: %d\" % vl_data.data_num)\r\n        do_train(tr_data, vl_data)\r\n    else:\r\n        te_data = MusicDataReader(FLAGS.dir_path,\r\n                                  'test',\r\n                                  (FLAGS.pitch_low, FLAGS.pitch_high),\r\n                                  FLAGS.dt,)\r\n        print(\"Number of testing samples: %d\" % te_data.data_num)\r\n        do_test(te_data)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run(main=main)\r\n```\r\nI cannot attach the output of my console for it is impossible due to the indefinite freezing of my Ubuntu. All I can say is that it tells me that it loads **libcupti.so** and computes a step of training process. Then, everything totally messes up.\r\n\r\nThank you for your support in advance."}