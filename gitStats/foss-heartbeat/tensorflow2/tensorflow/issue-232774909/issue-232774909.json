{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10362", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10362/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10362/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10362/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10362", "id": 232774909, "node_id": "MDU6SXNzdWUyMzI3NzQ5MDk=", "number": 10362, "title": "dataset.output_shapes returns demension(none) after batching", "user": {"login": "HaroldZ", "id": 14771013, "node_id": "MDQ6VXNlcjE0NzcxMDEz", "avatar_url": "https://avatars2.githubusercontent.com/u/14771013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HaroldZ", "html_url": "https://github.com/HaroldZ", "followers_url": "https://api.github.com/users/HaroldZ/followers", "following_url": "https://api.github.com/users/HaroldZ/following{/other_user}", "gists_url": "https://api.github.com/users/HaroldZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/HaroldZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HaroldZ/subscriptions", "organizations_url": "https://api.github.com/users/HaroldZ/orgs", "repos_url": "https://api.github.com/users/HaroldZ/repos", "events_url": "https://api.github.com/users/HaroldZ/events{/privacy}", "received_events_url": "https://api.github.com/users/HaroldZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-01T06:09:27Z", "updated_at": "2017-06-02T01:07:33Z", "closed_at": "2017-06-02T01:07:33Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.2.0-rc0</li>\n<li><strong>CUDA/cuDNN version</strong>:8.0</li>\n<li><strong>GPU model and memory</strong>:GTX 1080 8G</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm using the Dataset API for input pipelines in tensorflow r1.2<br>\nI build my own dataset and batch it with batch size = 128 and then input it into RNN.<br>\nbut the dataset.output_shape returns dimension(none) in the first dimension, so the RNN raises a error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"untitled1.py\", line 188, in &lt;module&gt;\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"untitled1.py\", line 121, in main\n    run_training()\n  File \"untitled1.py\", line 57, in run_training\n    is_training=True)\n  File \"/home/harold/huawei/ConvLSTM/ConvLSTM.py\", line 216, in inference\n    initial_state=initial_state)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 566, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 636, in _dynamic_rnn_loop\n    \"Input size (depth of inputs) must be accessible via shape inference,\"\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n</code></pre>\n<p>I think this error is caused by the shape of input, the first dimension should be batch size but not none.</p>\n<h3>Source code / logs</h3>\n<pre><code>origin_dataset = Dataset.BetweenS_Dataset(FLAGS.data_path)\ntrain_dataset = origin_dataset.train_dataset\ntest_dataset = origin_dataset.test_dataset\nshuffle_train_dataset = train_dataset.shuffle(buffer_size=10000)\nshuffle_batch_train_dataset = shuffle_train_dataset.batch(128)\nbatch_test_dataset = test_dataset.batch(FLAGS.batch_size)\n\niterator = tf.contrib.data.Iterator.from_structure(\n                           shuffle_batch_train_dataset.output_types,\n                            shuffle_batch_train_dataset.output_shapes)\n(images, labels) = iterator.get_next()\n\ntraining_init_op = iterator.make_initializer(shuffle_batch_train_dataset)\ntest_init_op = iterator.make_initializer(batch_test_dataset)\n\nprint(shuffle_batch_test_dataset.output_shapes)\n</code></pre>\n<p>I print output_shapes and it gives:<br>\n<code>(TensorShape([Dimension(None), Dimension(36), Dimension(100)]), TensorShape([Dimension(None)]))</code></p>\n<p>I suppose that it should be 128, because I have batched dataset:<br>\n<code>(TensorShape([Dimension(128), Dimension(36), Dimension(100)]), TensorShape([Dimension(128)]))</code></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.2.0-rc0\nCUDA/cuDNN version:8.0\nGPU model and memory:GTX 1080 8G\n\nDescribe the problem\nI'm using the Dataset API for input pipelines in tensorflow r1.2\nI build my own dataset and batch it with batch size = 128 and then input it into RNN.\nbut the dataset.output_shape returns dimension(none) in the first dimension, so the RNN raises a error:\nTraceback (most recent call last):\n  File \"untitled1.py\", line 188, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"untitled1.py\", line 121, in main\n    run_training()\n  File \"untitled1.py\", line 57, in run_training\n    is_training=True)\n  File \"/home/harold/huawei/ConvLSTM/ConvLSTM.py\", line 216, in inference\n    initial_state=initial_state)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 566, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 636, in _dynamic_rnn_loop\n    \"Input size (depth of inputs) must be accessible via shape inference,\"\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n\nI think this error is caused by the shape of input, the first dimension should be batch size but not none.\nSource code / logs\norigin_dataset = Dataset.BetweenS_Dataset(FLAGS.data_path)\ntrain_dataset = origin_dataset.train_dataset\ntest_dataset = origin_dataset.test_dataset\nshuffle_train_dataset = train_dataset.shuffle(buffer_size=10000)\nshuffle_batch_train_dataset = shuffle_train_dataset.batch(128)\nbatch_test_dataset = test_dataset.batch(FLAGS.batch_size)\n\niterator = tf.contrib.data.Iterator.from_structure(\n                           shuffle_batch_train_dataset.output_types,\n                            shuffle_batch_train_dataset.output_shapes)\n(images, labels) = iterator.get_next()\n\ntraining_init_op = iterator.make_initializer(shuffle_batch_train_dataset)\ntest_init_op = iterator.make_initializer(batch_test_dataset)\n\nprint(shuffle_batch_test_dataset.output_shapes)\n\nI print output_shapes and it gives:\n(TensorShape([Dimension(None), Dimension(36), Dimension(100)]), TensorShape([Dimension(None)]))\nI suppose that it should be 128, because I have batched dataset:\n(TensorShape([Dimension(128), Dimension(36), Dimension(100)]), TensorShape([Dimension(128)]))", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.2.0-rc0\r\n- **CUDA/cuDNN version**:8.0\r\n- **GPU model and memory**:GTX 1080 8G\r\n\r\n### Describe the problem\r\nI'm using the Dataset API for input pipelines in tensorflow r1.2\r\nI build my own dataset and batch it with batch size = 128 and then input it into RNN.\r\nbut the dataset.output_shape returns dimension(none) in the first dimension, so the RNN raises a error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"untitled1.py\", line 188, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"untitled1.py\", line 121, in main\r\n    run_training()\r\n  File \"untitled1.py\", line 57, in run_training\r\n    is_training=True)\r\n  File \"/home/harold/huawei/ConvLSTM/ConvLSTM.py\", line 216, in inference\r\n    initial_state=initial_state)\r\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 566, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/home/harold/anaconda2/envs/tensorflow_py2.7/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 636, in _dynamic_rnn_loop\r\n    \"Input size (depth of inputs) must be accessible via shape inference,\"\r\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\r\n```\r\nI think this error is caused by the shape of input, the first dimension should be batch size but not none.\r\n\r\n### Source code / logs\r\n```\r\norigin_dataset = Dataset.BetweenS_Dataset(FLAGS.data_path)\r\ntrain_dataset = origin_dataset.train_dataset\r\ntest_dataset = origin_dataset.test_dataset\r\nshuffle_train_dataset = train_dataset.shuffle(buffer_size=10000)\r\nshuffle_batch_train_dataset = shuffle_train_dataset.batch(128)\r\nbatch_test_dataset = test_dataset.batch(FLAGS.batch_size)\r\n\r\niterator = tf.contrib.data.Iterator.from_structure(\r\n                           shuffle_batch_train_dataset.output_types,\r\n                            shuffle_batch_train_dataset.output_shapes)\r\n(images, labels) = iterator.get_next()\r\n\r\ntraining_init_op = iterator.make_initializer(shuffle_batch_train_dataset)\r\ntest_init_op = iterator.make_initializer(batch_test_dataset)\r\n\r\nprint(shuffle_batch_test_dataset.output_shapes)\r\n```\r\nI print output_shapes and it gives:\r\n`(TensorShape([Dimension(None), Dimension(36), Dimension(100)]), TensorShape([Dimension(None)]))`\r\n\r\nI suppose that it should be 128, because I have batched dataset:\r\n`(TensorShape([Dimension(128), Dimension(36), Dimension(100)]), TensorShape([Dimension(128)]))`"}