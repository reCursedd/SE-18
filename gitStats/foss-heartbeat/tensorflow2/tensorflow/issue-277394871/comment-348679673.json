{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/348679673", "html_url": "https://github.com/tensorflow/tensorflow/issues/14942#issuecomment-348679673", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14942", "id": 348679673, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODY3OTY3Mw==", "user": {"login": "derekhh", "id": 1497445, "node_id": "MDQ6VXNlcjE0OTc0NDU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1497445?v=4", "gravatar_id": "", "url": "https://api.github.com/users/derekhh", "html_url": "https://github.com/derekhh", "followers_url": "https://api.github.com/users/derekhh/followers", "following_url": "https://api.github.com/users/derekhh/following{/other_user}", "gists_url": "https://api.github.com/users/derekhh/gists{/gist_id}", "starred_url": "https://api.github.com/users/derekhh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/derekhh/subscriptions", "organizations_url": "https://api.github.com/users/derekhh/orgs", "repos_url": "https://api.github.com/users/derekhh/repos", "events_url": "https://api.github.com/users/derekhh/events{/privacy}", "received_events_url": "https://api.github.com/users/derekhh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-02T09:21:10Z", "updated_at": "2017-12-02T09:21:10Z", "author_association": "NONE", "body_html": "<p>I've seen a similar issue:</p>\n<p>My code snippet to test on tf1.3:</p>\n<pre><code>def parser(record, split_name, imagenet_mean):\n    assert (split_name == 'train' or split_name == 'train_dev')\n    keys_to_features = {\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n        'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n        'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n    image = tf.image.decode_jpeg(parsed['image/encoded'])\n    image.set_shape([180, 180, 3])\n    image = tf.cast(image, tf.float32)\n    image = tf.subtract(image, imagenet_mean)\n    image = tf.expand_dims(image, axis=0)\n    image = tf.image.resize_bicubic(image, [224, 224])\n    image = tf.squeeze(image)\n    if split_name == 'train':\n        image = tf.image.random_flip_left_right(image)\n    label = parsed['image/class/class_id']\n    product_id = parsed['image/product_id']\n    return image, label, product_id\n\n\ndef get_dataset(file_patterns, split_name):\n    assert (split_name == 'train' or split_name == 'train_dev')\n    imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])\n    d = tf.contrib.data.Dataset.list_files(file_patterns)\n    # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files\n    # with no duplicate or missing ones.\n    d = d.shuffle(buffer_size=NUM_SHARDS)\n    # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.\n    d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)\n    d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)\n    d = d.batch(BATCH_SIZE)\n    return d\n\n\ndef main():\n    config = tf.ConfigProto()\n    config.gpu_options.visible_device_list = '0'\n    with tf.Graph().as_default() as g:\n        with tf.device('/cpu:0'):\n            train_set = get_dataset(TRAIN_ON_RAM, 'train')\n            train_iter = train_set.make_one_shot_iterator()\n            images, labels, product_ids = train_iter.get_next()\n    with tf.Session(graph=g, config=config) as sess:\n        for _ in tqdm(range(1000)):\n            sess.run(images)\n</code></pre>\n<p>For tf1.4, I simply changed <code>tf.contrib.data</code> to <code>tf.data</code>, <code>num_threads</code> into <code>num_parallel_calls</code> and <code>output_buffer_size</code> to <code>prefetch</code>. Then I've seen a very significant performance drop:</p>\n<p>On TF 1.3 I get:</p>\n<pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [03:14&lt;00:00,  5.14it/s]\n</code></pre>\n<p>On TF 1.4 I get:</p>\n<pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [05:28&lt;00:00,  3.05it/s]\n</code></pre>", "body_text": "I've seen a similar issue:\nMy code snippet to test on tf1.3:\ndef parser(record, split_name, imagenet_mean):\n    assert (split_name == 'train' or split_name == 'train_dev')\n    keys_to_features = {\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n        'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n        'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n    }\n    parsed = tf.parse_single_example(record, keys_to_features)\n    image = tf.image.decode_jpeg(parsed['image/encoded'])\n    image.set_shape([180, 180, 3])\n    image = tf.cast(image, tf.float32)\n    image = tf.subtract(image, imagenet_mean)\n    image = tf.expand_dims(image, axis=0)\n    image = tf.image.resize_bicubic(image, [224, 224])\n    image = tf.squeeze(image)\n    if split_name == 'train':\n        image = tf.image.random_flip_left_right(image)\n    label = parsed['image/class/class_id']\n    product_id = parsed['image/product_id']\n    return image, label, product_id\n\n\ndef get_dataset(file_patterns, split_name):\n    assert (split_name == 'train' or split_name == 'train_dev')\n    imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])\n    d = tf.contrib.data.Dataset.list_files(file_patterns)\n    # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files\n    # with no duplicate or missing ones.\n    d = d.shuffle(buffer_size=NUM_SHARDS)\n    # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.\n    d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)\n    d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)\n    d = d.batch(BATCH_SIZE)\n    return d\n\n\ndef main():\n    config = tf.ConfigProto()\n    config.gpu_options.visible_device_list = '0'\n    with tf.Graph().as_default() as g:\n        with tf.device('/cpu:0'):\n            train_set = get_dataset(TRAIN_ON_RAM, 'train')\n            train_iter = train_set.make_one_shot_iterator()\n            images, labels, product_ids = train_iter.get_next()\n    with tf.Session(graph=g, config=config) as sess:\n        for _ in tqdm(range(1000)):\n            sess.run(images)\n\nFor tf1.4, I simply changed tf.contrib.data to tf.data, num_threads into num_parallel_calls and output_buffer_size to prefetch. Then I've seen a very significant performance drop:\nOn TF 1.3 I get:\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [03:14<00:00,  5.14it/s]\n\nOn TF 1.4 I get:\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [05:28<00:00,  3.05it/s]", "body": "I've seen a similar issue:\r\n\r\nMy code snippet to test on tf1.3:\r\n\r\n```\r\ndef parser(record, split_name, imagenet_mean):\r\n    assert (split_name == 'train' or split_name == 'train_dev')\r\n    keys_to_features = {\r\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\r\n        'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\r\n        'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\r\n    }\r\n    parsed = tf.parse_single_example(record, keys_to_features)\r\n    image = tf.image.decode_jpeg(parsed['image/encoded'])\r\n    image.set_shape([180, 180, 3])\r\n    image = tf.cast(image, tf.float32)\r\n    image = tf.subtract(image, imagenet_mean)\r\n    image = tf.expand_dims(image, axis=0)\r\n    image = tf.image.resize_bicubic(image, [224, 224])\r\n    image = tf.squeeze(image)\r\n    if split_name == 'train':\r\n        image = tf.image.random_flip_left_right(image)\r\n    label = parsed['image/class/class_id']\r\n    product_id = parsed['image/product_id']\r\n    return image, label, product_id\r\n\r\n\r\ndef get_dataset(file_patterns, split_name):\r\n    assert (split_name == 'train' or split_name == 'train_dev')\r\n    imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])\r\n    d = tf.contrib.data.Dataset.list_files(file_patterns)\r\n    # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files\r\n    # with no duplicate or missing ones.\r\n    d = d.shuffle(buffer_size=NUM_SHARDS)\r\n    # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.\r\n    d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)\r\n    d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)\r\n    d = d.batch(BATCH_SIZE)\r\n    return d\r\n\r\n\r\ndef main():\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.visible_device_list = '0'\r\n    with tf.Graph().as_default() as g:\r\n        with tf.device('/cpu:0'):\r\n            train_set = get_dataset(TRAIN_ON_RAM, 'train')\r\n            train_iter = train_set.make_one_shot_iterator()\r\n            images, labels, product_ids = train_iter.get_next()\r\n    with tf.Session(graph=g, config=config) as sess:\r\n        for _ in tqdm(range(1000)):\r\n            sess.run(images)\r\n```\r\n\r\nFor tf1.4, I simply changed `tf.contrib.data` to `tf.data`, `num_threads` into `num_parallel_calls` and `output_buffer_size` to `prefetch`. Then I've seen a very significant performance drop:\r\n\r\nOn TF 1.3 I get:\r\n\r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [03:14<00:00,  5.14it/s]\r\n```\r\n\r\nOn TF 1.4 I get:\r\n\r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [05:28<00:00,  3.05it/s]\r\n```"}