{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347726727", "html_url": "https://github.com/tensorflow/tensorflow/issues/14942#issuecomment-347726727", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14942", "id": 347726727, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzcyNjcyNw==", "user": {"login": "WenmuZhou", "id": 12406017, "node_id": "MDQ6VXNlcjEyNDA2MDE3", "avatar_url": "https://avatars2.githubusercontent.com/u/12406017?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WenmuZhou", "html_url": "https://github.com/WenmuZhou", "followers_url": "https://api.github.com/users/WenmuZhou/followers", "following_url": "https://api.github.com/users/WenmuZhou/following{/other_user}", "gists_url": "https://api.github.com/users/WenmuZhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/WenmuZhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WenmuZhou/subscriptions", "organizations_url": "https://api.github.com/users/WenmuZhou/orgs", "repos_url": "https://api.github.com/users/WenmuZhou/repos", "events_url": "https://api.github.com/users/WenmuZhou/events{/privacy}", "received_events_url": "https://api.github.com/users/WenmuZhou/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T01:54:25Z", "updated_at": "2017-11-30T01:42:55Z", "author_association": "NONE", "body_html": "<p>here is the time of input_fn between 1.3 and 1.4<br>\nthe script is</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> -*- coding: utf-8 -*-</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> @Time    : 2017/11/29 8:43</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> @Author  : zhoujun</span>\n<span class=\"pl-k\">from</span> src.data_handler <span class=\"pl-k\">import</span> data_loader, input_fn\n<span class=\"pl-k\">from</span> src.config <span class=\"pl-k\">import</span> Params, Alphabet\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    parameters <span class=\"pl-k\">=</span> Params(<span class=\"pl-v\">eval_batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>,\n                        <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">304</span>),\n                        <span class=\"pl-v\">digits_only</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                        <span class=\"pl-v\">alphabet</span><span class=\"pl-k\">=</span>Alphabet.<span class=\"pl-c1\">CHINESECHAR_LETTERS_DIGITS_EXTENDED</span>,\n                        <span class=\"pl-v\">alphabet_decoding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>,\n                        <span class=\"pl-v\">image_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n                        <span class=\"pl-v\">csv_delimiter</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span> <span class=\"pl-pds\">'</span></span>,\n                        )\n\n    featureBatch, labelBatch <span class=\"pl-k\">=</span> input_fn(<span class=\"pl-v\">csv_filename</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>E:/val1.csv<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>parameters,\n                                        <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>parameters.eval_batch_size,\n                                        <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    global_init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n    loacl_init <span class=\"pl-k\">=</span> tf.local_variables_initializer()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(global_init)\n        sess.run(loacl_init)\n        coord <span class=\"pl-k\">=</span> tf.train.Coordinator()\n        threads <span class=\"pl-k\">=</span> tf.train.start_queue_runners(<span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess, <span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord)\n\n        start <span class=\"pl-k\">=</span> time.time()\n        example, label <span class=\"pl-k\">=</span> sess.run([featureBatch, labelBatch])\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>time: <span class=\"pl-pds\">'</span></span>,time.time()<span class=\"pl-k\">-</span>start)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">len</span>(label))\n        coord.request_stop()\n        coord.join(threads)</pre></div>\n<p><code>input_fn</code> is extracted from <code>data_loader</code> function</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>(<span class=\"pl-smi\">csv_filename</span>: <span class=\"pl-c1\">str</span>, <span class=\"pl-smi\">params</span>: Params, <span class=\"pl-smi\">batch_size</span>: <span class=\"pl-c1\">int</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>, <span class=\"pl-smi\">data_augmentation</span>: <span class=\"pl-c1\">bool</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>,\n                <span class=\"pl-smi\">num_epochs</span>: <span class=\"pl-c1\">int</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Choose case one csv file or list of csv files</span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(csv_filename, <span class=\"pl-c1\">list</span>):\n        filename_queue <span class=\"pl-k\">=</span> tf.train.string_input_producer([csv_filename], <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span>num_epochs,\n                                                        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>filename_queue<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(csv_filename, <span class=\"pl-c1\">list</span>):\n        filename_queue <span class=\"pl-k\">=</span> tf.train.string_input_producer(csv_filename, <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span>num_epochs, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>filename_queue<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Skip lines that have already been processed</span>\n    reader <span class=\"pl-k\">=</span> tf.TextLineReader(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>CSV_Reader<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">skip_header_lines</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    key, value <span class=\"pl-k\">=</span> reader.read(filename_queue, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>file_reading_op<span class=\"pl-pds\">'</span></span>)\n\n    default_line <span class=\"pl-k\">=</span> [[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>None<span class=\"pl-pds\">'</span></span>], [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>None<span class=\"pl-pds\">'</span></span>]]\n    path, label <span class=\"pl-k\">=</span> tf.decode_csv(value, <span class=\"pl-v\">record_defaults</span><span class=\"pl-k\">=</span>default_line, <span class=\"pl-v\">field_delim</span><span class=\"pl-k\">=</span>params.csv_delimiter,\n                                <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>csv_reading_op<span class=\"pl-pds\">'</span></span>)\n\n    image, img_width <span class=\"pl-k\">=</span> image_reading(path, <span class=\"pl-v\">resized_size</span><span class=\"pl-k\">=</span>params.input_shape, <span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>params,\n                                     <span class=\"pl-v\">data_augmentation</span><span class=\"pl-k\">=</span>data_augmentation, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    to_batch <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>images<span class=\"pl-pds\">'</span></span>: image, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>images_widths<span class=\"pl-pds\">'</span></span>: img_width, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>filenames<span class=\"pl-pds\">'</span></span>: path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels<span class=\"pl-pds\">'</span></span>: label}\n    prepared_batch <span class=\"pl-k\">=</span> tf.train.shuffle_batch(to_batch,\n                                            <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size,\n                                            <span class=\"pl-v\">min_after_dequeue</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">500</span>,\n                                            <span class=\"pl-v\">num_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">15</span>, <span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4000</span>,\n                                            <span class=\"pl-v\">allow_smaller_final_batch</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                                            <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>prepared_batch_queue<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">return</span> prepared_batch, prepared_batch.get(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels<span class=\"pl-pds\">'</span></span>)</pre></div>\n<p>tf 1.3 log</p>\n<div class=\"highlight highlight-source-shell\"><pre>time:  0.4531559944152832\n128</pre></div>\n<p>tf 1.4 log</p>\n<div class=\"highlight highlight-source-shell\"><pre>time:  0.5000338554382324\n128</pre></div>", "body_text": "here is the time of input_fn between 1.3 and 1.4\nthe script is\n# -*- coding: utf-8 -*-\n# @Time    : 2017/11/29 8:43\n# @Author  : zhoujun\nfrom src.data_handler import data_loader, input_fn\nfrom src.config import Params, Alphabet\nimport tensorflow as tf\nimport time\n\nif __name__ == '__main__':\n    parameters = Params(eval_batch_size=128,\n                        input_shape=(32, 304),\n                        digits_only=False,\n                        alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\n                        alphabet_decoding='same',\n                        image_channels=1,\n                        csv_delimiter=' ',\n                        )\n\n    featureBatch, labelBatch = input_fn(csv_filename='E:/val1.csv', params=parameters,\n                                        batch_size=parameters.eval_batch_size,\n                                        num_epochs=1)\n\n    global_init = tf.global_variables_initializer()\n    loacl_init = tf.local_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(global_init)\n        sess.run(loacl_init)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        start = time.time()\n        example, label = sess.run([featureBatch, labelBatch])\n        print('time: ',time.time()-start)\n        print(len(label))\n        coord.request_stop()\n        coord.join(threads)\ninput_fn is extracted from data_loader function\ndef input_fn(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\n                num_epochs: int = None):\n    # Choose case one csv file or list of csv files\n    if not isinstance(csv_filename, list):\n        filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\n                                                        name='filename_queue')\n    elif isinstance(csv_filename, list):\n        filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\n\n    # Skip lines that have already been processed\n    reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\n    key, value = reader.read(filename_queue, name='file_reading_op')\n\n    default_line = [['None'], ['None']]\n    path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\n                                name='csv_reading_op')\n\n    image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\n                                     data_augmentation=data_augmentation, padding=True)\n\n    to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\n    prepared_batch = tf.train.shuffle_batch(to_batch,\n                                            batch_size=batch_size,\n                                            min_after_dequeue=500,\n                                            num_threads=15, capacity=4000,\n                                            allow_smaller_final_batch=False,\n                                            name='prepared_batch_queue')\n    return prepared_batch, prepared_batch.get('labels')\ntf 1.3 log\ntime:  0.4531559944152832\n128\ntf 1.4 log\ntime:  0.5000338554382324\n128", "body": "here is the time of input_fn between 1.3 and 1.4\r\nthe script is \r\n```python\r\n# -*- coding: utf-8 -*-\r\n# @Time    : 2017/11/29 8:43\r\n# @Author  : zhoujun\r\nfrom src.data_handler import data_loader, input_fn\r\nfrom src.config import Params, Alphabet\r\nimport tensorflow as tf\r\nimport time\r\n\r\nif __name__ == '__main__':\r\n    parameters = Params(eval_batch_size=128,\r\n                        input_shape=(32, 304),\r\n                        digits_only=False,\r\n                        alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\r\n                        alphabet_decoding='same',\r\n                        image_channels=1,\r\n                        csv_delimiter=' ',\r\n                        )\r\n\r\n    featureBatch, labelBatch = input_fn(csv_filename='E:/val1.csv', params=parameters,\r\n                                        batch_size=parameters.eval_batch_size,\r\n                                        num_epochs=1)\r\n\r\n    global_init = tf.global_variables_initializer()\r\n    loacl_init = tf.local_variables_initializer()\r\n    with tf.Session() as sess:\r\n        sess.run(global_init)\r\n        sess.run(loacl_init)\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        start = time.time()\r\n        example, label = sess.run([featureBatch, labelBatch])\r\n        print('time: ',time.time()-start)\r\n        print(len(label))\r\n        coord.request_stop()\r\n        coord.join(threads)\r\n```\r\n`input_fn` is extracted from `data_loader` function\r\n```python\r\ndef input_fn(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\r\n                num_epochs: int = None):\r\n    # Choose case one csv file or list of csv files\r\n    if not isinstance(csv_filename, list):\r\n        filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\r\n                                                        name='filename_queue')\r\n    elif isinstance(csv_filename, list):\r\n        filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\r\n\r\n    # Skip lines that have already been processed\r\n    reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\r\n    key, value = reader.read(filename_queue, name='file_reading_op')\r\n\r\n    default_line = [['None'], ['None']]\r\n    path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\r\n                                name='csv_reading_op')\r\n\r\n    image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\r\n                                     data_augmentation=data_augmentation, padding=True)\r\n\r\n    to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\r\n    prepared_batch = tf.train.shuffle_batch(to_batch,\r\n                                            batch_size=batch_size,\r\n                                            min_after_dequeue=500,\r\n                                            num_threads=15, capacity=4000,\r\n                                            allow_smaller_final_batch=False,\r\n                                            name='prepared_batch_queue')\r\n    return prepared_batch, prepared_batch.get('labels')\r\n```\r\ntf 1.3 log\r\n```sh\r\ntime:  0.4531559944152832\r\n128\r\n```\r\ntf 1.4 log\r\n```sh\r\ntime:  0.5000338554382324\r\n128\r\n```"}