{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257636159", "html_url": "https://github.com/tensorflow/tensorflow/issues/5323#issuecomment-257636159", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5323", "id": 257636159, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzYzNjE1OQ==", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-01T17:41:04Z", "updated_at": "2016-11-01T17:41:04Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> might have more insight, but I have a few things.</p>\n<ol>\n<li>This is a great question to ask on StackOverflow, because you can ask \"how do people deal with caching data and/or memoizing? do you use explicit memoization?\"</li>\n<li>A concrete example of what kind of data you are memoizing might make it clearer exactly what you want.</li>\n<li>Dataflow and traditional memoization are pretty much at odds in the current architecture, since you really have no way to have a function that causes upstream dependencies to run. You need to be able to schedule a static computation. Perhaps you mean memoization in the sense of if you see the same input, you have an internal cache per node.</li>\n</ol>", "body_text": "@vrv might have more insight, but I have a few things.\n\nThis is a great question to ask on StackOverflow, because you can ask \"how do people deal with caching data and/or memoizing? do you use explicit memoization?\"\nA concrete example of what kind of data you are memoizing might make it clearer exactly what you want.\nDataflow and traditional memoization are pretty much at odds in the current architecture, since you really have no way to have a function that causes upstream dependencies to run. You need to be able to schedule a static computation. Perhaps you mean memoization in the sense of if you see the same input, you have an internal cache per node.", "body": "@vrv might have more insight, but I have a few things.\n1. This is a great question to ask on StackOverflow, because you can ask \"how do people deal with caching data and/or memoizing? do you use explicit memoization?\"\n2. A concrete example of what kind of data you are memoizing might make it clearer exactly what you want.\n3. Dataflow and traditional memoization are pretty much at odds in the current architecture, since you really have no way to have a function that causes upstream dependencies to run. You need to be able to schedule a static computation. Perhaps you mean memoization in the sense of if you see the same input, you have an internal cache per node.\n"}