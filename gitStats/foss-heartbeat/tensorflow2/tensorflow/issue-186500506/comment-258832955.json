{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/258832955", "html_url": "https://github.com/tensorflow/tensorflow/issues/5323#issuecomment-258832955", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5323", "id": 258832955, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODgzMjk1NQ==", "user": {"login": "egpbos", "id": 6146598, "node_id": "MDQ6VXNlcjYxNDY1OTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/6146598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/egpbos", "html_url": "https://github.com/egpbos", "followers_url": "https://api.github.com/users/egpbos/followers", "following_url": "https://api.github.com/users/egpbos/following{/other_user}", "gists_url": "https://api.github.com/users/egpbos/gists{/gist_id}", "starred_url": "https://api.github.com/users/egpbos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/egpbos/subscriptions", "organizations_url": "https://api.github.com/users/egpbos/orgs", "repos_url": "https://api.github.com/users/egpbos/repos", "events_url": "https://api.github.com/users/egpbos/events{/privacy}", "received_events_url": "https://api.github.com/users/egpbos/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-07T13:18:21Z", "updated_at": "2016-11-07T13:18:31Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>memoization in the sense of if you see the same input, you have an internal cache per node.</p>\n</blockquote>\n<p>Yes, that's what I mean. It seems to me that implementing such functionality would be a lot more expensive when done at the Python level than at the C++ level.</p>\n<blockquote>\n<p>Note that partial_run is also supported at the C++ interface, though I'd like to see proof that it would be 'superior'. :)</p>\n</blockquote>\n<p>See above, by \"c++ implementation\" I meant the implementation of memoization in C++ vs in Python, not the partial_run implementation :)</p>", "body_text": "memoization in the sense of if you see the same input, you have an internal cache per node.\n\nYes, that's what I mean. It seems to me that implementing such functionality would be a lot more expensive when done at the Python level than at the C++ level.\n\nNote that partial_run is also supported at the C++ interface, though I'd like to see proof that it would be 'superior'. :)\n\nSee above, by \"c++ implementation\" I meant the implementation of memoization in C++ vs in Python, not the partial_run implementation :)", "body": "> memoization in the sense of if you see the same input, you have an internal cache per node.\n\nYes, that's what I mean. It seems to me that implementing such functionality would be a lot more expensive when done at the Python level than at the C++ level.\n\n> Note that partial_run is also supported at the C++ interface, though I'd like to see proof that it would be 'superior'. :)\n\nSee above, by \"c++ implementation\" I meant the implementation of memoization in C++ vs in Python, not the partial_run implementation :)\n"}