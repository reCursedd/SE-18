{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402408229", "html_url": "https://github.com/tensorflow/tensorflow/issues/20375#issuecomment-402408229", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20375", "id": 402408229, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjQwODIyOQ==", "user": {"login": "phizaz", "id": 451667, "node_id": "MDQ6VXNlcjQ1MTY2Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/451667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phizaz", "html_url": "https://github.com/phizaz", "followers_url": "https://api.github.com/users/phizaz/followers", "following_url": "https://api.github.com/users/phizaz/following{/other_user}", "gists_url": "https://api.github.com/users/phizaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/phizaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phizaz/subscriptions", "organizations_url": "https://api.github.com/users/phizaz/orgs", "repos_url": "https://api.github.com/users/phizaz/repos", "events_url": "https://api.github.com/users/phizaz/events{/privacy}", "received_events_url": "https://api.github.com/users/phizaz/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-04T08:41:38Z", "updated_at": "2018-07-04T08:41:38Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19293677\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ispirmustafa\">@ispirmustafa</a> Saving in plain text is very slow in my case. Not that my network is huge but rather my dataset is included in the graph. This is unfortunate case for in-memory datasets like MNIST, Cifar10. When I use <code>tf.data.Dataset.from_tensor_slices(....)</code>, I guess, that whole dataset is included in the graph saved in the <code>graph.pbtxt</code> as well. Since, I cannot avoid this behavior saving in another format that is very much faster seems to be a good mitigation for me. Also, providing this support seems trivial to my naive eyes.</p>", "body_text": "@ispirmustafa Saving in plain text is very slow in my case. Not that my network is huge but rather my dataset is included in the graph. This is unfortunate case for in-memory datasets like MNIST, Cifar10. When I use tf.data.Dataset.from_tensor_slices(....), I guess, that whole dataset is included in the graph saved in the graph.pbtxt as well. Since, I cannot avoid this behavior saving in another format that is very much faster seems to be a good mitigation for me. Also, providing this support seems trivial to my naive eyes.", "body": "@ispirmustafa Saving in plain text is very slow in my case. Not that my network is huge but rather my dataset is included in the graph. This is unfortunate case for in-memory datasets like MNIST, Cifar10. When I use `tf.data.Dataset.from_tensor_slices(....)`, I guess, that whole dataset is included in the graph saved in the `graph.pbtxt` as well. Since, I cannot avoid this behavior saving in another format that is very much faster seems to be a good mitigation for me. Also, providing this support seems trivial to my naive eyes. "}