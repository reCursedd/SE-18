{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/334907858", "html_url": "https://github.com/tensorflow/tensorflow/issues/13426#issuecomment-334907858", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13426", "id": 334907858, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDkwNzg1OA==", "user": {"login": "daj", "id": 739125, "node_id": "MDQ6VXNlcjczOTEyNQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/739125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daj", "html_url": "https://github.com/daj", "followers_url": "https://api.github.com/users/daj/followers", "following_url": "https://api.github.com/users/daj/following{/other_user}", "gists_url": "https://api.github.com/users/daj/gists{/gist_id}", "starred_url": "https://api.github.com/users/daj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daj/subscriptions", "organizations_url": "https://api.github.com/users/daj/orgs", "repos_url": "https://api.github.com/users/daj/repos", "events_url": "https://api.github.com/users/daj/events{/privacy}", "received_events_url": "https://api.github.com/users/daj/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-07T03:44:14Z", "updated_at": "2017-10-08T14:29:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks, that was the problem!  I keep forgetting that the <code>gcr.io/tensorflow/tensorflow</code> Docker images don't have all the necessary configuration already in place for Android builds.</p>\n<p>I have now successfully reduced libtensorflow_inference.so from 9.7MB to 2.5MB for the arm64-v8a architecture.  I've documented this process <a href=\"https://medium.com/@daj/how-to-shrink-the-tensorflow-android-inference-library-cb698facf758\" rel=\"nofollow\">in this Medium article</a> and <a href=\"https://github.com/daj/AndroidTensorFlowMNISTExample/commit/6e1b15ff6d3182be0e665c0456f356ffc2f62514\">this commit</a>.</p>\n<p>I have a couple of ideas for improvements:</p>\n<ol>\n<li>Please can you maintain a Docker image with the SDK+NDK+WORKSPACE configuration already in place?</li>\n</ol>\n<ul>\n<li>I think any Android developer using a TensorFlow model will need to optimize libtensorflow_inference.so using selective registration to reduce their binary size.  A pre-built Docker image would be very useful for them (and probably easier to document).</li>\n<li>As an example, I created my own Docker container here (though this is probably too big):<br>\n<a href=\"https://hub.docker.com/r/danjarvis/tensorflow-android/\" rel=\"nofollow\">https://hub.docker.com/r/danjarvis/tensorflow-android/</a>  Tag 1.3.0 contains print_selective_registration_header pre-built.</li>\n</ul>\n<ol start=\"2\">\n<li>Please can we improve the error messages when the SDK/NDK/WORKSPACE are missing?  I imagine many developers will make the same mistake as me. :-)</li>\n</ol>\n<p>For either of these, I'd be happy to attempt a pull request if you could give me some pointers of where to start. Thanks!</p>", "body_text": "Thanks, that was the problem!  I keep forgetting that the gcr.io/tensorflow/tensorflow Docker images don't have all the necessary configuration already in place for Android builds.\nI have now successfully reduced libtensorflow_inference.so from 9.7MB to 2.5MB for the arm64-v8a architecture.  I've documented this process in this Medium article and this commit.\nI have a couple of ideas for improvements:\n\nPlease can you maintain a Docker image with the SDK+NDK+WORKSPACE configuration already in place?\n\n\nI think any Android developer using a TensorFlow model will need to optimize libtensorflow_inference.so using selective registration to reduce their binary size.  A pre-built Docker image would be very useful for them (and probably easier to document).\nAs an example, I created my own Docker container here (though this is probably too big):\nhttps://hub.docker.com/r/danjarvis/tensorflow-android/  Tag 1.3.0 contains print_selective_registration_header pre-built.\n\n\nPlease can we improve the error messages when the SDK/NDK/WORKSPACE are missing?  I imagine many developers will make the same mistake as me. :-)\n\nFor either of these, I'd be happy to attempt a pull request if you could give me some pointers of where to start. Thanks!", "body": "Thanks, that was the problem!  I keep forgetting that the `gcr.io/tensorflow/tensorflow` Docker images don't have all the necessary configuration already in place for Android builds.\r\n\r\nI have now successfully reduced libtensorflow_inference.so from 9.7MB to 2.5MB for the arm64-v8a architecture.  I've documented this process [in this Medium article](https://medium.com/@daj/how-to-shrink-the-tensorflow-android-inference-library-cb698facf758) and [this commit](https://github.com/daj/AndroidTensorFlowMNISTExample/commit/6e1b15ff6d3182be0e665c0456f356ffc2f62514).\r\n\r\nI have a couple of ideas for improvements:\r\n\r\n1) Please can you maintain a Docker image with the SDK+NDK+WORKSPACE configuration already in place?  \r\n  - I think any Android developer using a TensorFlow model will need to optimize libtensorflow_inference.so using selective registration to reduce their binary size.  A pre-built Docker image would be very useful for them (and probably easier to document).\r\n  - As an example, I created my own Docker container here (though this is probably too big):\r\nhttps://hub.docker.com/r/danjarvis/tensorflow-android/  Tag 1.3.0 contains print_selective_registration_header pre-built.\r\n\r\n2) Please can we improve the error messages when the SDK/NDK/WORKSPACE are missing?  I imagine many developers will make the same mistake as me. :-)\r\n\r\nFor either of these, I'd be happy to attempt a pull request if you could give me some pointers of where to start. Thanks!\r\n\r\n\r\n"}