{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13426", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13426/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13426/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13426/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13426", "id": 261879377, "node_id": "MDU6SXNzdWUyNjE4NzkzNzc=", "number": 13426, "title": "//tensorflow/contrib/android:libtensorflow_inference.so build fails when compiling @protobuf//:protobuf", "user": {"login": "daj", "id": 739125, "node_id": "MDQ6VXNlcjczOTEyNQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/739125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daj", "html_url": "https://github.com/daj", "followers_url": "https://api.github.com/users/daj/followers", "following_url": "https://api.github.com/users/daj/following{/other_user}", "gists_url": "https://api.github.com/users/daj/gists{/gist_id}", "starred_url": "https://api.github.com/users/daj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daj/subscriptions", "organizations_url": "https://api.github.com/users/daj/orgs", "repos_url": "https://api.github.com/users/daj/repos", "events_url": "https://api.github.com/users/daj/events{/privacy}", "received_events_url": "https://api.github.com/users/daj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2017-09-30T23:20:48Z", "updated_at": "2018-03-27T19:40:13Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Docker image gcr.io/tensorflow/tensorflow:1.3.0-devel</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3.0</li>\n<li><strong>Python version</strong>: Python 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.0</li>\n</ul>\n<p>Output from <code>tf_env_collect.sh</code> is at the end of this report.</p>\n<h3>Describe the problem</h3>\n<p>I'm trying to follow the instructions in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py#L15\">print_selective_registration_header.py</a> to create a smaller TensorFlow binary size.</p>\n<p>Part of those instructions involves building <code> //tensorflow/contrib/android:libtensorflow_inference.so</code>, but that build fails every time.</p>\n<p>I'm doing this in the <code>gcr.io/tensorflow/tensorflow:1.3.0-devel</code> Docker container (not sure if this is appropriate because I can't find documentation explaining what each container is for).  I tried to use the <code>1.3.0</code> container, but that doesn't contain the TensorFlow repo or <code>git</code>.</p>\n<h3>Source code / logs</h3>\n<p>Here are the steps I took (the first steps succeeded so I have not included their output):</p>\n<pre><code>$ docker run -it -v $HOME/TF:/TF gcr.io/tensorflow/tensorflow:1.3.0-devel bash\n\n# bazel build tensorflow/python/tools:print_selective_registration_header\n\n# bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=/TF/mnist_model_graph.pb &gt; ops_to_register.h\n\n# bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\nINFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n&lt;snip repeated warning&gt;\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nINFO: Found 1 target...\nERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/BUILD:133:1: C++ compilation of rule '@protobuf//:protobuf' failed: false failed: error executing command \n  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow &amp;&amp; \\\n  exec env - \\\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\n    PWD=/proc/self/cwd \\\n    PYTHON_BIN_PATH=/usr/bin/python \\\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\n    TF_NEED_CUDA=0 \\\n    TF_NEED_OPENCL=0 \\\n  /bin/false -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/io/printer.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\nINFO: Elapsed time: 202.538s, Critical Path: 11.70s\n</code></pre>\n<p>I also tried (with the same result):</p>\n<ul>\n<li><code>bazel clean</code> before the failing build step.</li>\n<li>Removing the ops_to_register.h file and the <code>--copt</code> parameters.</li>\n</ul>\n<p>Here's my full environment info (which shows an error when running pywrap_tensorflow_internal):</p>\n<pre><code># cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nYes\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.4.0)\ntensorflow (1.3.0)\ntensorflow-tensorboard (0.1.2)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n  File \"tensorflow/__init__.py\", line 24, in &lt;module&gt;\n    from tensorflow.python import *\n  File \"tensorflow/python/__init__.py\", line 49, in &lt;module&gt;\n    from tensorflow.python import pywrap_tensorflow\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 52, in &lt;module&gt;\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 41, in &lt;module&gt;\n    from tensorflow.python.pywrap_tensorflow_internal import *\nImportError: No module named pywrap_tensorflow_internal\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\n./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker image gcr.io/tensorflow/tensorflow:1.3.0-devel\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.3.0\nPython version: Python 2.7.12\nBazel version (if compiling from source): 0.5.0\n\nOutput from tf_env_collect.sh is at the end of this report.\nDescribe the problem\nI'm trying to follow the instructions in print_selective_registration_header.py to create a smaller TensorFlow binary size.\nPart of those instructions involves building  //tensorflow/contrib/android:libtensorflow_inference.so, but that build fails every time.\nI'm doing this in the gcr.io/tensorflow/tensorflow:1.3.0-devel Docker container (not sure if this is appropriate because I can't find documentation explaining what each container is for).  I tried to use the 1.3.0 container, but that doesn't contain the TensorFlow repo or git.\nSource code / logs\nHere are the steps I took (the first steps succeeded so I have not included their output):\n$ docker run -it -v $HOME/TF:/TF gcr.io/tensorflow/tensorflow:1.3.0-devel bash\n\n# bazel build tensorflow/python/tools:print_selective_registration_header\n\n# bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=/TF/mnist_model_graph.pb > ops_to_register.h\n\n# bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\nINFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n<snip repeated warning>\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nINFO: Found 1 target...\nERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/BUILD:133:1: C++ compilation of rule '@protobuf//:protobuf' failed: false failed: error executing command \n  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\n    PWD=/proc/self/cwd \\\n    PYTHON_BIN_PATH=/usr/bin/python \\\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\n    TF_NEED_CUDA=0 \\\n    TF_NEED_OPENCL=0 \\\n  /bin/false -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/io/printer.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\nINFO: Elapsed time: 202.538s, Critical Path: 11.70s\n\nI also tried (with the same result):\n\nbazel clean before the failing build step.\nRemoving the ops_to_register.h file and the --copt parameters.\n\nHere's my full environment info (which shows an error when running pywrap_tensorflow_internal):\n# cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nYes\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.4.0)\ntensorflow (1.3.0)\ntensorflow-tensorboard (0.1.2)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"tensorflow/__init__.py\", line 24, in <module>\n    from tensorflow.python import *\n  File \"tensorflow/python/__init__.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\nImportError: No module named pywrap_tensorflow_internal\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\n./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker image gcr.io/tensorflow/tensorflow:1.3.0-devel\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: Python 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.5.0\r\n\r\nOutput from `tf_env_collect.sh` is at the end of this report.\r\n\r\n### Describe the problem\r\nI'm trying to follow the instructions in [print_selective_registration_header.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py#L15) to create a smaller TensorFlow binary size.\r\n\r\nPart of those instructions involves building ` //tensorflow/contrib/android:libtensorflow_inference.so`, but that build fails every time.\r\n\r\nI'm doing this in the `gcr.io/tensorflow/tensorflow:1.3.0-devel` Docker container (not sure if this is appropriate because I can't find documentation explaining what each container is for).  I tried to use the `1.3.0` container, but that doesn't contain the TensorFlow repo or `git`.\r\n\r\n### Source code / logs\r\n\r\nHere are the steps I took (the first steps succeeded so I have not included their output):\r\n```\r\n$ docker run -it -v $HOME/TF:/TF gcr.io/tensorflow/tensorflow:1.3.0-devel bash\r\n\r\n# bazel build tensorflow/python/tools:print_selective_registration_header\r\n\r\n# bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=/TF/mnist_model_graph.pb > ops_to_register.h\r\n\r\n# bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\r\nINFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch\r\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\n<snip repeated warning>\r\nWARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/BUILD:133:1: C++ compilation of rule '@protobuf//:protobuf' failed: false failed: error executing command \r\n  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  /bin/false -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/io/printer.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 202.538s, Critical Path: 11.70s\r\n```\r\nI also tried (with the same result):\r\n - `bazel clean` before the failing build step.\r\n - Removing the ops_to_register.h file and the `--copt` parameters.\r\n\r\nHere's my full environment info (which shows an error when running pywrap_tensorflow_internal):\r\n```\r\n# cat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.4.0)\r\ntensorflow (1.3.0)\r\ntensorflow-tensorboard (0.1.2)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\nImportError: No module named pywrap_tensorflow_internal\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```"}