{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17199", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17199/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17199/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17199/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17199", "id": 299477052, "node_id": "MDU6SXNzdWUyOTk0NzcwNTI=", "number": 17199, "title": "Error raised incorrectly in CheckInputFromValidContext", "user": {"login": "iganichev", "id": 9123400, "node_id": "MDQ6VXNlcjkxMjM0MDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9123400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iganichev", "html_url": "https://github.com/iganichev", "followers_url": "https://api.github.com/users/iganichev/followers", "following_url": "https://api.github.com/users/iganichev/following{/other_user}", "gists_url": "https://api.github.com/users/iganichev/gists{/gist_id}", "starred_url": "https://api.github.com/users/iganichev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iganichev/subscriptions", "organizations_url": "https://api.github.com/users/iganichev/orgs", "repos_url": "https://api.github.com/users/iganichev/repos", "events_url": "https://api.github.com/users/iganichev/events{/privacy}", "received_events_url": "https://api.github.com/users/iganichev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-02-22T19:25:58Z", "updated_at": "2018-06-13T08:55:22Z", "closed_at": "2018-04-09T14:35:49Z", "author_association": "MEMBER", "body_html": "<p>Happens in TF 1.5.</p>\n<p><strong>Error message and logs:</strong><br>\nINFO:tensorflow:Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop.</p>\n<p>gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc while context: None<br>\ntransducer_training/while/rnn/strided_slice while context: transducer_training/while/while_context</p>\n<p>Traceback for gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc:<br>\nFile \"./loop_error.py\", line 219, in <br>\nmodel = Model(cons_manager=constants_manager)<br>\nFile \"./loop_error.py\", line 44, in <strong>init</strong><br>\nself.targets, self.train_op, self.loss = self.build_training_step()<br>\nFile \"./loop_error.py\", line 211, in build_training_step<br>\ntrain_op = tf.train.AdamOptimizer().minimize(loss)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize<br>\ngrad_loss=grad_loss)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients<br>\ncolocate_gradients_with_ops=colocate_gradients_with_ops)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients<br>\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile<br>\nreturn grad_fn()  # Exit early<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in <br>\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad<br>\nreturn (None, array_ops.where(c, grad, zeros),<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where<br>\nreturn gen_math_ops._select(condition=condition, x=x, y=y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select<br>\n\"Select\", condition=condition, t=x, e=y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in <strong>init</strong><br>\nself._control_flow_context.AddOp(self)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp<br>\nself._AddOpInternal(op)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal<br>\nreal_x = self.AddValue(x)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue<br>\nreal_val = grad_ctxt.grad_state.GetRealValue(val)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue<br>\nhistory_value = cur_grad_state.AddForwardAccumulator(cur_value)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator<br>\nname=\"f_acc\")<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2<br>\nstack_name=stack_name, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>Traceback for transducer_training/while/rnn/strided_slice:<br>\nFile \"./loop_error.py\", line 219, in <br>\nmodel = Model(cons_manager=constants_manager)<br>\nFile \"./loop_error.py\", line 42, in <strong>init</strong><br>\nself.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()<br>\nFile \"./loop_error.py\", line 183, in build_full_transducer<br>\ntf.while_loop(cond, body, init_state, parallel_iterations=1)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2934, in while_loop<br>\nresult = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2720, in BuildLoop<br>\npred, body, original_loop_vars, loop_vars, shape_invariants)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2662, in _BuildLoop<br>\nbody_result = body(*packed_vars_for_body)<br>\nFile \"./loop_error.py\", line 119, in body<br>\ndtype=tf.float32, initial_state=encoder_hidden_state_t)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 629, in dynamic_rnn<br>\ndtype=dtype)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 688, in _dynamic_rnn_loop<br>\ntime_steps = input_shape[0]<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 573, in _slice_helper<br>\nname=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 737, in strided_slice<br>\nshrink_axis_mask=shrink_axis_mask)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5501, in strided_slice<br>\nname=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>Traceback (most recent call last):<br>\nFile \"./loop_error.py\", line 219, in <br>\nmodel = Model(cons_manager=constants_manager)<br>\nFile \"./loop_error.py\", line 44, in <strong>init</strong><br>\nself.targets, self.train_op, self.loss = self.build_training_step()<br>\nFile \"./loop_error.py\", line 211, in build_training_step<br>\ntrain_op = tf.train.AdamOptimizer().minimize(loss)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize<br>\ngrad_loss=grad_loss)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients<br>\ncolocate_gradients_with_ops=colocate_gradients_with_ops)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients<br>\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile<br>\nreturn grad_fn()  # Exit early<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in <br>\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad<br>\nreturn (None, array_ops.where(c, grad, zeros),<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where<br>\nreturn gen_math_ops._select(condition=condition, x=x, y=y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select<br>\n\"Select\", condition=condition, t=x, e=y, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in <strong>init</strong><br>\nself._control_flow_context.AddOp(self)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp<br>\nself._AddOpInternal(op)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal<br>\nreal_x = self.AddValue(x)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue<br>\nreal_val = grad_ctxt.grad_state.GetRealValue(val)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue<br>\nhistory_value = cur_grad_state.AddForwardAccumulator(cur_value)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator<br>\nname=\"f_acc\")<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2<br>\nstack_name=stack_name, name=name)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1672, in <strong>init</strong><br>\ncontrol_flow_util.CheckInputFromValidContext(self, input_tensor.op)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_util.py\", line 200, in CheckInputFromValidContext<br>\nraise ValueError(error_msg + \" See info log for more details.\")<br>\nValueError: Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop. See info log for more details.</p>\n<p><strong>Code to reproduce:</strong></p>\n<pre><code>import logging\nimport tensorflow as tf\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\nfrom tensorflow.python.layers import core as layers_core\n\nlogging.getLogger().setLevel(logging.DEBUG)\n# NOTE: Time major\n\n# ---------------- Constants Manager ----------------------------\nclass ConstantsManager(object):\n    def __init__(self, input_dimensions, input_embedding_size, inputs_embedded, encoder_hidden_units,\n                 transducer_hidden_units, vocab_ids, input_block_size, beam_width):\n        assert transducer_hidden_units == encoder_hidden_units, 'Encoder and transducer have to have the same amount' \\\n                                                                'of hidden units'\n        self.input_dimensions = input_dimensions\n        self.vocab_ids = vocab_ids\n        self.E_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('E_SYMBOL')\n        self.GO_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('GO_SYMBOL')\n        self.vocab_size = len(self.vocab_ids)\n        self.input_embedding_size = input_embedding_size\n        self.inputs_embedded = inputs_embedded\n        self.encoder_hidden_units = encoder_hidden_units\n        self.transducer_hidden_units = transducer_hidden_units\n        self.input_block_size = input_block_size\n        self.beam_width = beam_width\n        self.batch_size = 1  # Cannot be increased, see paper\n        self.log_prob_init_value = 0\n\n# ----------------- Model ---------------------------------------\n\n\nclass Model(object):\n    def __init__(self, cons_manager):\n        self.var_list = []\n        self.cons_manager = cons_manager\n        self.max_blocks, self.inputs_full_raw, self.transducer_list_outputs, self.start_block, self.encoder_hidden_init,\\\n            self.trans_hidden_init, self.logits, self.encoder_hidden_state_new, \\\n            self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\n\n        self.targets, self.train_op, self.loss = self.build_training_step()\n\n    def build_full_transducer(self):\n        with tf.variable_scope('transducer_training'):\n\n            embeddings = tf.Variable(tf.random_uniform([self.cons_manager.vocab_size,\n                                                        self.cons_manager.input_embedding_size], -1.0, 1.0),\n                                     dtype=tf.float32,\n                                     name='embedding')\n            # Inputs\n            max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # total amount of blocks to go through\n            if self.cons_manager.inputs_embedded is True:\n                input_type = tf.float32\n            else:\n                input_type = tf.int32\n            inputs_full_raw = tf.placeholder(shape=(None, self.cons_manager.batch_size,\n                                                    self.cons_manager.input_dimensions), dtype=input_type,\n                                             name='inputs_full_raw')  # shape [max_time, 1, input_dims]\n            transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\n                                                     name='transducer_list_outputs')  # amount to output per block\n            start_block = tf.placeholder(dtype=tf.int32, name='transducer_start_block')  # where to start the input\n\n            encoder_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.encoder_hidden_units), dtype=tf.float32,\n                                                 name='encoder_hidden_init')\n            trans_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.transducer_hidden_units), dtype=tf.float32,\n                                               name='trans_hidden_init')\n\n            # Temporary constants, maybe changed during inference\n            end_symbol = tf.get_variable(name='end_symbol',\n                                         initializer=tf.constant_initializer(self.cons_manager.vocab_size),\n                                         shape=(), dtype=tf.int32)\n\n            # Turn inputs into tensor which is easily readable#\n\n            inputs_full = tf.reshape(inputs_full_raw, shape=[-1, self.cons_manager.input_block_size,\n                                                             self.cons_manager.batch_size,\n                                                             self.cons_manager.input_dimensions])\n\n            # Outputs\n            outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\n\n            init_state = (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\n\n            # Initiate cells, NOTE: if there is a future error, put these back inside the body function\n            encoder_cell = tf.contrib.rnn.LSTMCell(num_units=self.cons_manager.encoder_hidden_units)\n            transducer_cell = tf.contrib.rnn.LSTMCell(self.cons_manager.transducer_hidden_units)\n\n            def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\n                return current_block &lt; start_block + max_blocks\n\n            def body(current_block, outputs_int, encoder_hidden, trans_hidden):\n\n                # --------------------- ENCODER ----------------------------------------------------------------------\n                encoder_inputs = inputs_full[current_block]\n                encoder_inputs_length = [tf.shape(encoder_inputs)[0]]\n                encoder_hidden_state = encoder_hidden\n\n                if self.cons_manager.inputs_embedded is True:\n                    encoder_inputs_embedded = encoder_inputs\n                else:\n                    encoder_inputs = tf.reshape(encoder_inputs, shape=[-1, self.cons_manager.batch_size])\n                    encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n\n                # Build model\n\n                # Build previous state\n                encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\n                encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n                #   encoder_outputs: [max_time, batch_size, num_units]\n                encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\n                    encoder_cell, encoder_inputs_embedded,\n                    sequence_length=encoder_inputs_length, time_major=True,\n                    dtype=tf.float32, initial_state=encoder_hidden_state_t)\n\n                # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\n                encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\n                encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new,\n                                                      shape=[2, -1, self.cons_manager.encoder_hidden_units])\n\n                # --------------------- TRANSDUCER --------------------------------------------------------------------\n                encoder_raw_outputs = encoder_outputs\n                # Save/load the state as one tensor, use encoder state as init if this is the first block\n                trans_hidden_state = tf.cond(current_block &gt; 0, lambda: trans_hidden, lambda: encoder_hidden_state_new)\n                transducer_amount_outputs = transducer_list_outputs[current_block - start_block]\n\n                # Model building\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    embedding=embeddings,\n                    start_tokens=tf.tile([self.cons_manager.GO_SYMBOL],\n                                         [self.cons_manager.batch_size]),  # TODO: check if this looks good\n                    end_token=end_symbol)  # vocab size, so that it doesn't prematurely end the decoding\n\n                attention_states = tf.transpose(encoder_raw_outputs,\n                                                [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\n\n                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n                    self.cons_manager.encoder_hidden_units, attention_states)\n\n                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n                    transducer_cell,\n                    attention_mechanism,\n                    attention_layer_size=self.cons_manager.transducer_hidden_units)\n\n                projection_layer = layers_core.Dense(self.cons_manager.vocab_size, use_bias=False)\n\n                # Build previous state\n                trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\n                trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n\n                decoder = tf.contrib.seq2seq.BasicDecoder(\n                    decoder_cell, helper,\n                    decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\n                    output_layer=projection_layer)\n\n                outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                            output_time_major=True,\n                                                                                            maximum_iterations=transducer_amount_outputs)\n                logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\n                decoder_prediction = outputs.sample_id  # For debugging\n\n                # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\n                transducer_hidden_state_new = tf.concat(\n                    [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\n                    axis=0)\n                transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\n                                                         shape=[2, -1, self.cons_manager.transducer_hidden_units])\n\n\n                # Note the outputs\n                outputs_int = outputs_int.write(current_block - start_block, logits)\n\n                return current_block + 1, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\n\n            _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new = \\\n                tf.while_loop(cond, body, init_state, parallel_iterations=1)\n\n            # Process outputs\n            outputs = outputs_final.concat()\n            logits = tf.reshape(\n                outputs,\n                shape=(-1, 1, self.cons_manager.vocab_size))  # And now its [max_output_time, batch_size, vocab]\n\n            # For loading the model later on\n            logits = tf.identity(logits, name='logits')\n            encoder_hidden_state_new = tf.identity(encoder_hidden_state_new, name='encoder_hidden_state_new')\n            transducer_hidden_state_new = tf.identity(transducer_hidden_state_new, name='transducer_hidden_state_new')\n\n        train_saver = tf.train.Saver()  # For now save everything\n\n        return max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\n            trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\n\n    def build_training_step(self):\n        targets = tf.placeholder(shape=(None,), dtype=tf.int32, name='targets')\n        targets_one_hot = tf.one_hot(targets, depth=self.cons_manager.vocab_size, dtype=tf.float32)\n\n        targets_one_hot = tf.Print(targets_one_hot, [targets], message='Targets: ', summarize=10)\n        targets_one_hot = tf.Print(targets_one_hot, [tf.argmax(self.logits, axis=2)], message='Argmax: ', summarize=10)\n\n        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot,\n                                                                         logits=self.logits)\n        loss = tf.reduce_mean(stepwise_cross_entropy)\n\n        # ERROR happens in this line\n        train_op = tf.train.AdamOptimizer().minimize(loss)\n        train_op = None\n        return targets, train_op, loss\n\n\nconstants_manager = ConstantsManager(input_dimensions=1, input_embedding_size=11, inputs_embedded=False,\n                                     encoder_hidden_units=100, transducer_hidden_units=100, vocab_ids=[0, 1, 2],\n                                     input_block_size=1, beam_width=5)\nmodel = Model(cons_manager=constants_manager)\n\nwith tf.Session() as sess:\n    writer = tf.summary.FileWriter(\"/tmp/graph\", sess.graph_def)\n    sess.run(tf.global_variables_initializer())\n    writer.flush()\n    writer.close()\n</code></pre>\n<p><strong>Picture of the graph and offending tensor (in red)</strong></p>\n<p>The <code>rnn</code> box is in a while loop itself.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9123400/36559487-0d147680-17c3-11e8-9ae9-d2dca5950579.jpeg\"><img src=\"https://user-images.githubusercontent.com/9123400/36559487-0d147680-17c3-11e8-9ae9-d2dca5950579.jpeg\" alt=\"graph\" style=\"max-width:100%;\"></a></p>", "body_text": "Happens in TF 1.5.\nError message and logs:\nINFO:tensorflow:Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop.\ngradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc while context: None\ntransducer_training/while/rnn/strided_slice while context: transducer_training/while/while_context\nTraceback for gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc:\nFile \"./loop_error.py\", line 219, in \nmodel = Model(cons_manager=constants_manager)\nFile \"./loop_error.py\", line 44, in init\nself.targets, self.train_op, self.loss = self.build_training_step()\nFile \"./loop_error.py\", line 211, in build_training_step\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize\ngrad_loss=grad_loss)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients\ncolocate_gradients_with_ops=colocate_gradients_with_ops)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile\nreturn grad_fn()  # Exit early\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in \ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad\nreturn (None, array_ops.where(c, grad, zeros),\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where\nreturn gen_math_ops._select(condition=condition, x=x, y=y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select\n\"Select\", condition=condition, t=x, e=y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in init\nself._control_flow_context.AddOp(self)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp\nself._AddOpInternal(op)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal\nreal_x = self.AddValue(x)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue\nreal_val = grad_ctxt.grad_state.GetRealValue(val)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue\nhistory_value = cur_grad_state.AddForwardAccumulator(cur_value)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator\nname=\"f_acc\")\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2\nstack_name=stack_name, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nTraceback for transducer_training/while/rnn/strided_slice:\nFile \"./loop_error.py\", line 219, in \nmodel = Model(cons_manager=constants_manager)\nFile \"./loop_error.py\", line 42, in init\nself.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\nFile \"./loop_error.py\", line 183, in build_full_transducer\ntf.while_loop(cond, body, init_state, parallel_iterations=1)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2934, in while_loop\nresult = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2720, in BuildLoop\npred, body, original_loop_vars, loop_vars, shape_invariants)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2662, in _BuildLoop\nbody_result = body(*packed_vars_for_body)\nFile \"./loop_error.py\", line 119, in body\ndtype=tf.float32, initial_state=encoder_hidden_state_t)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 629, in dynamic_rnn\ndtype=dtype)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 688, in _dynamic_rnn_loop\ntime_steps = input_shape[0]\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 573, in _slice_helper\nname=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 737, in strided_slice\nshrink_axis_mask=shrink_axis_mask)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5501, in strided_slice\nname=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nTraceback (most recent call last):\nFile \"./loop_error.py\", line 219, in \nmodel = Model(cons_manager=constants_manager)\nFile \"./loop_error.py\", line 44, in init\nself.targets, self.train_op, self.loss = self.build_training_step()\nFile \"./loop_error.py\", line 211, in build_training_step\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize\ngrad_loss=grad_loss)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients\ncolocate_gradients_with_ops=colocate_gradients_with_ops)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile\nreturn grad_fn()  # Exit early\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in \ngrad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad\nreturn (None, array_ops.where(c, grad, zeros),\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where\nreturn gen_math_ops._select(condition=condition, x=x, y=y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select\n\"Select\", condition=condition, t=x, e=y, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in init\nself._control_flow_context.AddOp(self)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp\nself._AddOpInternal(op)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal\nreal_x = self.AddValue(x)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue\nreal_val = grad_ctxt.grad_state.GetRealValue(val)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue\nhistory_value = cur_grad_state.AddForwardAccumulator(cur_value)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator\nname=\"f_acc\")\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2\nstack_name=stack_name, name=name)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1672, in init\ncontrol_flow_util.CheckInputFromValidContext(self, input_tensor.op)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_util.py\", line 200, in CheckInputFromValidContext\nraise ValueError(error_msg + \" See info log for more details.\")\nValueError: Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop. See info log for more details.\nCode to reproduce:\nimport logging\nimport tensorflow as tf\nfrom tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\nfrom tensorflow.python.layers import core as layers_core\n\nlogging.getLogger().setLevel(logging.DEBUG)\n# NOTE: Time major\n\n# ---------------- Constants Manager ----------------------------\nclass ConstantsManager(object):\n    def __init__(self, input_dimensions, input_embedding_size, inputs_embedded, encoder_hidden_units,\n                 transducer_hidden_units, vocab_ids, input_block_size, beam_width):\n        assert transducer_hidden_units == encoder_hidden_units, 'Encoder and transducer have to have the same amount' \\\n                                                                'of hidden units'\n        self.input_dimensions = input_dimensions\n        self.vocab_ids = vocab_ids\n        self.E_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('E_SYMBOL')\n        self.GO_SYMBOL = len(self.vocab_ids)\n        self.vocab_ids.append('GO_SYMBOL')\n        self.vocab_size = len(self.vocab_ids)\n        self.input_embedding_size = input_embedding_size\n        self.inputs_embedded = inputs_embedded\n        self.encoder_hidden_units = encoder_hidden_units\n        self.transducer_hidden_units = transducer_hidden_units\n        self.input_block_size = input_block_size\n        self.beam_width = beam_width\n        self.batch_size = 1  # Cannot be increased, see paper\n        self.log_prob_init_value = 0\n\n# ----------------- Model ---------------------------------------\n\n\nclass Model(object):\n    def __init__(self, cons_manager):\n        self.var_list = []\n        self.cons_manager = cons_manager\n        self.max_blocks, self.inputs_full_raw, self.transducer_list_outputs, self.start_block, self.encoder_hidden_init,\\\n            self.trans_hidden_init, self.logits, self.encoder_hidden_state_new, \\\n            self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\n\n        self.targets, self.train_op, self.loss = self.build_training_step()\n\n    def build_full_transducer(self):\n        with tf.variable_scope('transducer_training'):\n\n            embeddings = tf.Variable(tf.random_uniform([self.cons_manager.vocab_size,\n                                                        self.cons_manager.input_embedding_size], -1.0, 1.0),\n                                     dtype=tf.float32,\n                                     name='embedding')\n            # Inputs\n            max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # total amount of blocks to go through\n            if self.cons_manager.inputs_embedded is True:\n                input_type = tf.float32\n            else:\n                input_type = tf.int32\n            inputs_full_raw = tf.placeholder(shape=(None, self.cons_manager.batch_size,\n                                                    self.cons_manager.input_dimensions), dtype=input_type,\n                                             name='inputs_full_raw')  # shape [max_time, 1, input_dims]\n            transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\n                                                     name='transducer_list_outputs')  # amount to output per block\n            start_block = tf.placeholder(dtype=tf.int32, name='transducer_start_block')  # where to start the input\n\n            encoder_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.encoder_hidden_units), dtype=tf.float32,\n                                                 name='encoder_hidden_init')\n            trans_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.transducer_hidden_units), dtype=tf.float32,\n                                               name='trans_hidden_init')\n\n            # Temporary constants, maybe changed during inference\n            end_symbol = tf.get_variable(name='end_symbol',\n                                         initializer=tf.constant_initializer(self.cons_manager.vocab_size),\n                                         shape=(), dtype=tf.int32)\n\n            # Turn inputs into tensor which is easily readable#\n\n            inputs_full = tf.reshape(inputs_full_raw, shape=[-1, self.cons_manager.input_block_size,\n                                                             self.cons_manager.batch_size,\n                                                             self.cons_manager.input_dimensions])\n\n            # Outputs\n            outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\n\n            init_state = (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\n\n            # Initiate cells, NOTE: if there is a future error, put these back inside the body function\n            encoder_cell = tf.contrib.rnn.LSTMCell(num_units=self.cons_manager.encoder_hidden_units)\n            transducer_cell = tf.contrib.rnn.LSTMCell(self.cons_manager.transducer_hidden_units)\n\n            def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\n                return current_block < start_block + max_blocks\n\n            def body(current_block, outputs_int, encoder_hidden, trans_hidden):\n\n                # --------------------- ENCODER ----------------------------------------------------------------------\n                encoder_inputs = inputs_full[current_block]\n                encoder_inputs_length = [tf.shape(encoder_inputs)[0]]\n                encoder_hidden_state = encoder_hidden\n\n                if self.cons_manager.inputs_embedded is True:\n                    encoder_inputs_embedded = encoder_inputs\n                else:\n                    encoder_inputs = tf.reshape(encoder_inputs, shape=[-1, self.cons_manager.batch_size])\n                    encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n\n                # Build model\n\n                # Build previous state\n                encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\n                encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, self.cons_manager.encoder_hidden_units])\n                encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n\n                #   encoder_outputs: [max_time, batch_size, num_units]\n                encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\n                    encoder_cell, encoder_inputs_embedded,\n                    sequence_length=encoder_inputs_length, time_major=True,\n                    dtype=tf.float32, initial_state=encoder_hidden_state_t)\n\n                # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\n                encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\n                encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new,\n                                                      shape=[2, -1, self.cons_manager.encoder_hidden_units])\n\n                # --------------------- TRANSDUCER --------------------------------------------------------------------\n                encoder_raw_outputs = encoder_outputs\n                # Save/load the state as one tensor, use encoder state as init if this is the first block\n                trans_hidden_state = tf.cond(current_block > 0, lambda: trans_hidden, lambda: encoder_hidden_state_new)\n                transducer_amount_outputs = transducer_list_outputs[current_block - start_block]\n\n                # Model building\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    embedding=embeddings,\n                    start_tokens=tf.tile([self.cons_manager.GO_SYMBOL],\n                                         [self.cons_manager.batch_size]),  # TODO: check if this looks good\n                    end_token=end_symbol)  # vocab size, so that it doesn't prematurely end the decoding\n\n                attention_states = tf.transpose(encoder_raw_outputs,\n                                                [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\n\n                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n                    self.cons_manager.encoder_hidden_units, attention_states)\n\n                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n                    transducer_cell,\n                    attention_mechanism,\n                    attention_layer_size=self.cons_manager.transducer_hidden_units)\n\n                projection_layer = layers_core.Dense(self.cons_manager.vocab_size, use_bias=False)\n\n                # Build previous state\n                trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\n                trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, self.cons_manager.transducer_hidden_units])\n                trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n\n                decoder = tf.contrib.seq2seq.BasicDecoder(\n                    decoder_cell, helper,\n                    decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\n                    output_layer=projection_layer)\n\n                outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                            output_time_major=True,\n                                                                                            maximum_iterations=transducer_amount_outputs)\n                logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\n                decoder_prediction = outputs.sample_id  # For debugging\n\n                # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\n                transducer_hidden_state_new = tf.concat(\n                    [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\n                    axis=0)\n                transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\n                                                         shape=[2, -1, self.cons_manager.transducer_hidden_units])\n\n\n                # Note the outputs\n                outputs_int = outputs_int.write(current_block - start_block, logits)\n\n                return current_block + 1, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\n\n            _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new = \\\n                tf.while_loop(cond, body, init_state, parallel_iterations=1)\n\n            # Process outputs\n            outputs = outputs_final.concat()\n            logits = tf.reshape(\n                outputs,\n                shape=(-1, 1, self.cons_manager.vocab_size))  # And now its [max_output_time, batch_size, vocab]\n\n            # For loading the model later on\n            logits = tf.identity(logits, name='logits')\n            encoder_hidden_state_new = tf.identity(encoder_hidden_state_new, name='encoder_hidden_state_new')\n            transducer_hidden_state_new = tf.identity(transducer_hidden_state_new, name='transducer_hidden_state_new')\n\n        train_saver = tf.train.Saver()  # For now save everything\n\n        return max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\n            trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\n\n    def build_training_step(self):\n        targets = tf.placeholder(shape=(None,), dtype=tf.int32, name='targets')\n        targets_one_hot = tf.one_hot(targets, depth=self.cons_manager.vocab_size, dtype=tf.float32)\n\n        targets_one_hot = tf.Print(targets_one_hot, [targets], message='Targets: ', summarize=10)\n        targets_one_hot = tf.Print(targets_one_hot, [tf.argmax(self.logits, axis=2)], message='Argmax: ', summarize=10)\n\n        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot,\n                                                                         logits=self.logits)\n        loss = tf.reduce_mean(stepwise_cross_entropy)\n\n        # ERROR happens in this line\n        train_op = tf.train.AdamOptimizer().minimize(loss)\n        train_op = None\n        return targets, train_op, loss\n\n\nconstants_manager = ConstantsManager(input_dimensions=1, input_embedding_size=11, inputs_embedded=False,\n                                     encoder_hidden_units=100, transducer_hidden_units=100, vocab_ids=[0, 1, 2],\n                                     input_block_size=1, beam_width=5)\nmodel = Model(cons_manager=constants_manager)\n\nwith tf.Session() as sess:\n    writer = tf.summary.FileWriter(\"/tmp/graph\", sess.graph_def)\n    sess.run(tf.global_variables_initializer())\n    writer.flush()\n    writer.close()\n\nPicture of the graph and offending tensor (in red)\nThe rnn box is in a while loop itself.", "body": "Happens in TF 1.5.\r\n\r\n**Error message and logs:**\r\nINFO:tensorflow:Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop.\r\n\r\ngradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc while context: None\r\ntransducer_training/while/rnn/strided_slice while context: transducer_training/while/while_context\r\n\r\nTraceback for gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc:\r\n  File \"./loop_error.py\", line 219, in <module>\r\n    model = Model(cons_manager=constants_manager)\r\n  File \"./loop_error.py\", line 44, in __init__\r\n    self.targets, self.train_op, self.loss = self.build_training_step()\r\n  File \"./loop_error.py\", line 211, in build_training_step\r\n    train_op = tf.train.AdamOptimizer().minimize(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad\r\n    return (None, array_ops.where(c, grad, zeros),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where\r\n    return gen_math_ops._select(condition=condition, x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select\r\n    \"Select\", condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in __init__\r\n    self._control_flow_context.AddOp(self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp\r\n    self._AddOpInternal(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal\r\n    real_x = self.AddValue(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue\r\n    real_val = grad_ctxt.grad_state.GetRealValue(val)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue\r\n    history_value = cur_grad_state.AddForwardAccumulator(cur_value)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator\r\n    name=\"f_acc\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2\r\n    stack_name=stack_name, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nTraceback for transducer_training/while/rnn/strided_slice:\r\n  File \"./loop_error.py\", line 219, in <module>\r\n    model = Model(cons_manager=constants_manager)\r\n  File \"./loop_error.py\", line 42, in __init__\r\n    self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\r\n  File \"./loop_error.py\", line 183, in build_full_transducer\r\n    tf.while_loop(cond, body, init_state, parallel_iterations=1)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2934, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2720, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2662, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"./loop_error.py\", line 119, in body\r\n    dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 629, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 688, in _dynamic_rnn_loop\r\n    time_steps = input_shape[0]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 573, in _slice_helper\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 737, in strided_slice\r\n    shrink_axis_mask=shrink_axis_mask)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5501, in strided_slice\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./loop_error.py\", line 219, in <module>\r\n    model = Model(cons_manager=constants_manager)\r\n  File \"./loop_error.py\", line 44, in __init__\r\n    self.targets, self.train_op, self.loss = self.build_training_step()\r\n  File \"./loop_error.py\", line 211, in build_training_step\r\n    train_op = tf.train.AdamOptimizer().minimize(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 949, in _SelectGrad\r\n    return (None, array_ops.where(c, grad, zeros),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2540, in where\r\n    return gen_math_ops._select(condition=condition, x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4043, in _select\r\n    \"Select\", condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1674, in __init__\r\n    self._control_flow_context.AddOp(self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2251, in AddOp\r\n    self._AddOpInternal(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2274, in _AddOpInternal\r\n    real_x = self.AddValue(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2207, in AddValue\r\n    real_val = grad_ctxt.grad_state.GetRealValue(val)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1050, in GetRealValue\r\n    history_value = cur_grad_state.AddForwardAccumulator(cur_value)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 908, in AddForwardAccumulator\r\n    name=\"f_acc\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3578, in _stack_v2\r\n    stack_name=stack_name, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1672, in __init__\r\n    control_flow_util.CheckInputFromValidContext(self, input_tensor.op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_util.py\", line 200, in CheckInputFromValidContext\r\n    raise ValueError(error_msg + \" See info log for more details.\")\r\nValueError: Cannot use 'transducer_training/while/rnn/strided_slice' as input to 'gradients/transducer_training/while/rnn/while/Select_1_grad/Select/f_acc' because 'transducer_training/while/rnn/strided_slice' is in a while loop. See info log for more details.\r\n\r\n\r\n\r\n\r\n**Code to reproduce:**\r\n\r\n\r\n    import logging\r\n    import tensorflow as tf\r\n    from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\r\n    from tensorflow.python.layers import core as layers_core\r\n    \r\n    logging.getLogger().setLevel(logging.DEBUG)\r\n    # NOTE: Time major\r\n    \r\n    # ---------------- Constants Manager ----------------------------\r\n    class ConstantsManager(object):\r\n        def __init__(self, input_dimensions, input_embedding_size, inputs_embedded, encoder_hidden_units,\r\n                     transducer_hidden_units, vocab_ids, input_block_size, beam_width):\r\n            assert transducer_hidden_units == encoder_hidden_units, 'Encoder and transducer have to have the same amount' \\\r\n                                                                    'of hidden units'\r\n            self.input_dimensions = input_dimensions\r\n            self.vocab_ids = vocab_ids\r\n            self.E_SYMBOL = len(self.vocab_ids)\r\n            self.vocab_ids.append('E_SYMBOL')\r\n            self.GO_SYMBOL = len(self.vocab_ids)\r\n            self.vocab_ids.append('GO_SYMBOL')\r\n            self.vocab_size = len(self.vocab_ids)\r\n            self.input_embedding_size = input_embedding_size\r\n            self.inputs_embedded = inputs_embedded\r\n            self.encoder_hidden_units = encoder_hidden_units\r\n            self.transducer_hidden_units = transducer_hidden_units\r\n            self.input_block_size = input_block_size\r\n            self.beam_width = beam_width\r\n            self.batch_size = 1  # Cannot be increased, see paper\r\n            self.log_prob_init_value = 0\r\n    \r\n    # ----------------- Model ---------------------------------------\r\n    \r\n    \r\n    class Model(object):\r\n        def __init__(self, cons_manager):\r\n            self.var_list = []\r\n            self.cons_manager = cons_manager\r\n            self.max_blocks, self.inputs_full_raw, self.transducer_list_outputs, self.start_block, self.encoder_hidden_init,\\\r\n                self.trans_hidden_init, self.logits, self.encoder_hidden_state_new, \\\r\n                self.transducer_hidden_state_new, self.train_saver = self.build_full_transducer()\r\n    \r\n            self.targets, self.train_op, self.loss = self.build_training_step()\r\n    \r\n        def build_full_transducer(self):\r\n            with tf.variable_scope('transducer_training'):\r\n    \r\n                embeddings = tf.Variable(tf.random_uniform([self.cons_manager.vocab_size,\r\n                                                            self.cons_manager.input_embedding_size], -1.0, 1.0),\r\n                                         dtype=tf.float32,\r\n                                         name='embedding')\r\n                # Inputs\r\n                max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')  # total amount of blocks to go through\r\n                if self.cons_manager.inputs_embedded is True:\r\n                    input_type = tf.float32\r\n                else:\r\n                    input_type = tf.int32\r\n                inputs_full_raw = tf.placeholder(shape=(None, self.cons_manager.batch_size,\r\n                                                        self.cons_manager.input_dimensions), dtype=input_type,\r\n                                                 name='inputs_full_raw')  # shape [max_time, 1, input_dims]\r\n                transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\r\n                                                         name='transducer_list_outputs')  # amount to output per block\r\n                start_block = tf.placeholder(dtype=tf.int32, name='transducer_start_block')  # where to start the input\r\n    \r\n                encoder_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.encoder_hidden_units), dtype=tf.float32,\r\n                                                     name='encoder_hidden_init')\r\n                trans_hidden_init = tf.placeholder(shape=(2, 1, self.cons_manager.transducer_hidden_units), dtype=tf.float32,\r\n                                                   name='trans_hidden_init')\r\n    \r\n                # Temporary constants, maybe changed during inference\r\n                end_symbol = tf.get_variable(name='end_symbol',\r\n                                             initializer=tf.constant_initializer(self.cons_manager.vocab_size),\r\n                                             shape=(), dtype=tf.int32)\r\n    \r\n                # Turn inputs into tensor which is easily readable#\r\n    \r\n                inputs_full = tf.reshape(inputs_full_raw, shape=[-1, self.cons_manager.input_block_size,\r\n                                                                 self.cons_manager.batch_size,\r\n                                                                 self.cons_manager.input_dimensions])\r\n    \r\n                # Outputs\r\n                outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\r\n    \r\n                init_state = (start_block, outputs_ta, encoder_hidden_init, trans_hidden_init)\r\n    \r\n                # Initiate cells, NOTE: if there is a future error, put these back inside the body function\r\n                encoder_cell = tf.contrib.rnn.LSTMCell(num_units=self.cons_manager.encoder_hidden_units)\r\n                transducer_cell = tf.contrib.rnn.LSTMCell(self.cons_manager.transducer_hidden_units)\r\n    \r\n                def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n                    return current_block < start_block + max_blocks\r\n    \r\n                def body(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n    \r\n                    # --------------------- ENCODER ----------------------------------------------------------------------\r\n                    encoder_inputs = inputs_full[current_block]\r\n                    encoder_inputs_length = [tf.shape(encoder_inputs)[0]]\r\n                    encoder_hidden_state = encoder_hidden\r\n    \r\n                    if self.cons_manager.inputs_embedded is True:\r\n                        encoder_inputs_embedded = encoder_inputs\r\n                    else:\r\n                        encoder_inputs = tf.reshape(encoder_inputs, shape=[-1, self.cons_manager.batch_size])\r\n                        encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\r\n    \r\n                    # Build model\r\n    \r\n                    # Build previous state\r\n                    encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\r\n                    encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, self.cons_manager.encoder_hidden_units])\r\n                    encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, self.cons_manager.encoder_hidden_units])\r\n                    encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\r\n    \r\n                    #   encoder_outputs: [max_time, batch_size, num_units]\r\n                    encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\r\n                        encoder_cell, encoder_inputs_embedded,\r\n                        sequence_length=encoder_inputs_length, time_major=True,\r\n                        dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n    \r\n                    # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\r\n                    encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\r\n                    encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new,\r\n                                                          shape=[2, -1, self.cons_manager.encoder_hidden_units])\r\n    \r\n                    # --------------------- TRANSDUCER --------------------------------------------------------------------\r\n                    encoder_raw_outputs = encoder_outputs\r\n                    # Save/load the state as one tensor, use encoder state as init if this is the first block\r\n                    trans_hidden_state = tf.cond(current_block > 0, lambda: trans_hidden, lambda: encoder_hidden_state_new)\r\n                    transducer_amount_outputs = transducer_list_outputs[current_block - start_block]\r\n    \r\n                    # Model building\r\n                    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\r\n                        embedding=embeddings,\r\n                        start_tokens=tf.tile([self.cons_manager.GO_SYMBOL],\r\n                                             [self.cons_manager.batch_size]),  # TODO: check if this looks good\r\n                        end_token=end_symbol)  # vocab size, so that it doesn't prematurely end the decoding\r\n    \r\n                    attention_states = tf.transpose(encoder_raw_outputs,\r\n                                                    [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\n    \r\n                    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n                        self.cons_manager.encoder_hidden_units, attention_states)\r\n    \r\n                    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n                        transducer_cell,\r\n                        attention_mechanism,\r\n                        attention_layer_size=self.cons_manager.transducer_hidden_units)\r\n    \r\n                    projection_layer = layers_core.Dense(self.cons_manager.vocab_size, use_bias=False)\r\n    \r\n                    # Build previous state\r\n                    trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\r\n                    trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, self.cons_manager.transducer_hidden_units])\r\n                    trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, self.cons_manager.transducer_hidden_units])\r\n                    trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\r\n    \r\n                    decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                        decoder_cell, helper,\r\n                        decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\r\n                        output_layer=projection_layer)\r\n    \r\n                    outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\r\n                                                                                                output_time_major=True,\r\n                                                                                                maximum_iterations=transducer_amount_outputs)\r\n                    logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\r\n                    decoder_prediction = outputs.sample_id  # For debugging\r\n    \r\n                    # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\r\n                    transducer_hidden_state_new = tf.concat(\r\n                        [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\r\n                        axis=0)\r\n                    transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\r\n                                                             shape=[2, -1, self.cons_manager.transducer_hidden_units])\r\n    \r\n    \r\n                    # Note the outputs\r\n                    outputs_int = outputs_int.write(current_block - start_block, logits)\r\n    \r\n                    return current_block + 1, outputs_int, encoder_hidden_state_new, transducer_hidden_state_new\r\n    \r\n                _, outputs_final, encoder_hidden_state_new, transducer_hidden_state_new = \\\r\n                    tf.while_loop(cond, body, init_state, parallel_iterations=1)\r\n    \r\n                # Process outputs\r\n                outputs = outputs_final.concat()\r\n                logits = tf.reshape(\r\n                    outputs,\r\n                    shape=(-1, 1, self.cons_manager.vocab_size))  # And now its [max_output_time, batch_size, vocab]\r\n    \r\n                # For loading the model later on\r\n                logits = tf.identity(logits, name='logits')\r\n                encoder_hidden_state_new = tf.identity(encoder_hidden_state_new, name='encoder_hidden_state_new')\r\n                transducer_hidden_state_new = tf.identity(transducer_hidden_state_new, name='transducer_hidden_state_new')\r\n    \r\n            train_saver = tf.train.Saver()  # For now save everything\r\n    \r\n            return max_blocks, inputs_full_raw, transducer_list_outputs, start_block, encoder_hidden_init,\\\r\n                trans_hidden_init, logits, encoder_hidden_state_new, transducer_hidden_state_new, train_saver\r\n    \r\n        def build_training_step(self):\r\n            targets = tf.placeholder(shape=(None,), dtype=tf.int32, name='targets')\r\n            targets_one_hot = tf.one_hot(targets, depth=self.cons_manager.vocab_size, dtype=tf.float32)\r\n    \r\n            targets_one_hot = tf.Print(targets_one_hot, [targets], message='Targets: ', summarize=10)\r\n            targets_one_hot = tf.Print(targets_one_hot, [tf.argmax(self.logits, axis=2)], message='Argmax: ', summarize=10)\r\n    \r\n            stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot,\r\n                                                                             logits=self.logits)\r\n            loss = tf.reduce_mean(stepwise_cross_entropy)\r\n    \r\n            # ERROR happens in this line\r\n            train_op = tf.train.AdamOptimizer().minimize(loss)\r\n            train_op = None\r\n            return targets, train_op, loss\r\n    \r\n    \r\n    constants_manager = ConstantsManager(input_dimensions=1, input_embedding_size=11, inputs_embedded=False,\r\n                                         encoder_hidden_units=100, transducer_hidden_units=100, vocab_ids=[0, 1, 2],\r\n                                         input_block_size=1, beam_width=5)\r\n    model = Model(cons_manager=constants_manager)\r\n    \r\n    with tf.Session() as sess:\r\n        writer = tf.summary.FileWriter(\"/tmp/graph\", sess.graph_def)\r\n        sess.run(tf.global_variables_initializer())\r\n        writer.flush()\r\n        writer.close()\r\n\r\n\r\n\r\n**Picture of the graph and offending tensor (in red)**\r\n\r\nThe `rnn` box is in a while loop itself.\r\n\r\n![graph](https://user-images.githubusercontent.com/9123400/36559487-0d147680-17c3-11e8-9ae9-d2dca5950579.jpeg)\r\n"}