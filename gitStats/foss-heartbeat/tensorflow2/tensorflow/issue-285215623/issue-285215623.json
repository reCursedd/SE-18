{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15737", "id": 285215623, "node_id": "MDU6SXNzdWUyODUyMTU2MjM=", "number": 15737, "title": "AttentionWrapper zero_state(batch_size, tf.float32).clone(cell_state=encoder_state) fails when batch size is 1", "user": {"login": "nikita68", "id": 15629332, "node_id": "MDQ6VXNlcjE1NjI5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15629332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikita68", "html_url": "https://github.com/nikita68", "followers_url": "https://api.github.com/users/nikita68/followers", "following_url": "https://api.github.com/users/nikita68/following{/other_user}", "gists_url": "https://api.github.com/users/nikita68/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikita68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikita68/subscriptions", "organizations_url": "https://api.github.com/users/nikita68/orgs", "repos_url": "https://api.github.com/users/nikita68/repos", "events_url": "https://api.github.com/users/nikita68/events{/privacy}", "received_events_url": "https://api.github.com/users/nikita68/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, {"login": "oahziur", "id": 4604464, "node_id": "MDQ6VXNlcjQ2MDQ0NjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4604464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oahziur", "html_url": "https://github.com/oahziur", "followers_url": "https://api.github.com/users/oahziur/followers", "following_url": "https://api.github.com/users/oahziur/following{/other_user}", "gists_url": "https://api.github.com/users/oahziur/gists{/gist_id}", "starred_url": "https://api.github.com/users/oahziur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oahziur/subscriptions", "organizations_url": "https://api.github.com/users/oahziur/orgs", "repos_url": "https://api.github.com/users/oahziur/repos", "events_url": "https://api.github.com/users/oahziur/events{/privacy}", "received_events_url": "https://api.github.com/users/oahziur/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-12-30T18:04:33Z", "updated_at": "2018-01-31T04:18:08Z", "closed_at": "2018-01-12T02:46:30Z", "author_association": "NONE", "body_html": "<p>Hello!<br>\nI believe to have found a small bug when using the <code>zero_state(batch_size, tf.float32).clone(cell_state=encoder_state)</code> command. When batch size is 1, the error <code>ValueError: The shape for decoder/while/Merge_5:0 is not an invariant for the loop. It enters the loop with shape (1, 512), but has shape (?, 512) after one iteration. Provide shape invariants using either the shape_invariants argument of tf.while_loop or set_shape() on the loop variables.</code> is thrown. This error does not occur when batch size is 2 or larger. The error also doesn't occur if I remove the .clone command.<br>\nI tried investigating where the error is, but couldn't find the cause. I'm using this in context of trying to build a neural transducer, but also get the same error for basic seq2seq:<br>\n(Based on the NMT tutorial)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> .... Encoder, constants etc...</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Decoder</span>\nhelper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>) \n\nattention_states <span class=\"pl-k\">=</span> tf.transpose(encoder_outputs, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> attention_states: [batch_size, max_time, num_units]</span>\nattention_mechanism <span class=\"pl-k\">=</span> tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    <span class=\"pl-v\">memory_sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length)\ndecoder_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    <span class=\"pl-v\">attention_layer_size</span><span class=\"pl-k\">=</span>decoder_hidden_units)\n\nprojection_layer <span class=\"pl-k\">=</span> layers_core.Dense(\n    vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n\ndecoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(<span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>encoder_state),\n    <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>projection_layer)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Training ----</span>\noutputs, last_state, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder, <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nlogits <span class=\"pl-k\">=</span> outputs.rnn_output\ndecoder_prediction <span class=\"pl-k\">=</span> outputs.sample_id</pre></div>\n<p>TF Version: ('v1.4.0-19-ga52c8d9', '1.4.1')<br>\nSystem details:</p>\n<pre><code>== cat /etc/issue ===============================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"17.10 (Artful Aardvark)\"\nVERSION_ID=\"17.10\"\nVERSION_CODENAME=artful\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.5.1)\ntensorflow (1.4.1)\ntensorflow-tensorboard (0.4.0rc3)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.4.1\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntf.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n</code></pre>\n<p>I believe this is an important issue, as often times when experimenting with new seq2seq models I start off with trying to get it to work for a batch size of 1.</p>\n<p>Thanks!<br>\nNikita</p>", "body_text": "Hello!\nI believe to have found a small bug when using the zero_state(batch_size, tf.float32).clone(cell_state=encoder_state) command. When batch size is 1, the error ValueError: The shape for decoder/while/Merge_5:0 is not an invariant for the loop. It enters the loop with shape (1, 512), but has shape (?, 512) after one iteration. Provide shape invariants using either the shape_invariants argument of tf.while_loop or set_shape() on the loop variables. is thrown. This error does not occur when batch size is 2 or larger. The error also doesn't occur if I remove the .clone command.\nI tried investigating where the error is, but couldn't find the cause. I'm using this in context of trying to build a neural transducer, but also get the same error for basic seq2seq:\n(Based on the NMT tutorial)\n# .... Encoder, constants etc...\n# Decoder\nhelper = tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, time_major=True) \n\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    memory_sequence_length=encoder_inputs_length)\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    attention_layer_size=decoder_hidden_units)\n\nprojection_layer = layers_core.Dense(\n    vocab_size, use_bias=False)\n\n\ndecoder = tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\n    output_layer=projection_layer)\n\n# ---- Training ----\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\nlogits = outputs.rnn_output\ndecoder_prediction = outputs.sample_id\nTF Version: ('v1.4.0-19-ga52c8d9', '1.4.1')\nSystem details:\n== cat /etc/issue ===============================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"17.10 (Artful Aardvark)\"\nVERSION_ID=\"17.10\"\nVERSION_CODENAME=artful\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.5.1)\ntensorflow (1.4.1)\ntensorflow-tensorboard (0.4.0rc3)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.4.1\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntf.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n\nI believe this is an important issue, as often times when experimenting with new seq2seq models I start off with trying to get it to work for a batch size of 1.\nThanks!\nNikita", "body": "Hello!\r\nI believe to have found a small bug when using the `zero_state(batch_size, tf.float32).clone(cell_state=encoder_state)` command. When batch size is 1, the error `ValueError: The shape for decoder/while/Merge_5:0 is not an invariant for the loop. It enters the loop with shape (1, 512), but has shape (?, 512) after one iteration. Provide shape invariants using either the shape_invariants argument of tf.while_loop or set_shape() on the loop variables.` is thrown. This error does not occur when batch size is 2 or larger. The error also doesn't occur if I remove the .clone command. \r\nI tried investigating where the error is, but couldn't find the cause. I'm using this in context of trying to build a neural transducer, but also get the same error for basic seq2seq:\r\n(Based on the NMT tutorial)\r\n\r\n```python\r\n# .... Encoder, constants etc...\r\n# Decoder\r\nhelper = tf.contrib.seq2seq.TrainingHelper(\r\n    decoder_inputs_embedded, decoder_full_length, time_major=True) \r\n\r\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n    encoder_hidden_units, attention_states,\r\n    memory_sequence_length=encoder_inputs_length)\r\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\r\n    attention_mechanism,\r\n    attention_layer_size=decoder_hidden_units)\r\n\r\nprojection_layer = layers_core.Dense(\r\n    vocab_size, use_bias=False)\r\n\r\n\r\ndecoder = tf.contrib.seq2seq.BasicDecoder(\r\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\r\n    output_layer=projection_layer)\r\n\r\n# ---- Training ----\r\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\r\nlogits = outputs.rnn_output\r\ndecoder_prediction = outputs.sample_id\r\n```\r\n\r\n\r\nTF Version: ('v1.4.0-19-ga52c8d9', '1.4.1')\r\nSystem details:\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"17.10 (Artful Aardvark)\"\r\nVERSION_ID=\"17.10\"\r\nVERSION_CODENAME=artful\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.1)\r\ntensorflow (1.4.1)\r\ntensorflow-tensorboard (0.4.0rc3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.1\r\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\r\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\nI believe this is an important issue, as often times when experimenting with new seq2seq models I start off with trying to get it to work for a batch size of 1.\r\n\r\nThanks!\r\nNikita"}