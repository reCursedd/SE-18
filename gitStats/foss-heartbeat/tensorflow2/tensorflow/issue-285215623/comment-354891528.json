{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354891528", "html_url": "https://github.com/tensorflow/tensorflow/issues/15737#issuecomment-354891528", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737", "id": 354891528, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDg5MTUyOA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-02T22:24:53Z", "updated_at": "2018-01-02T22:24:53Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Do we need to, in general, have a static batch size for the encoder?  We\nshouldn't require that.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, Jan 2, 2018 at 2:22 PM, Rui Zhao ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/nikita68\">@nikita68</a> &lt;<a href=\"https://github.com/nikita68\">https://github.com/nikita68</a>&gt;\n\n I think you need to make sure the the encoder_state has a static\n batch_size which means you need to set your placeholder's batch dimension\n as batch_size instead of None.\n\n or\n\n you can just use a tensor as the zero_states' batch size instead of a\n constant.\n\n For example:\n\n decoder_init_state = decoder_cell.zero_state(tf.size(decoder_full_length), tf.float32).clone(cell_state=encoder_state)\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"285215623\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/15737\" href=\"https://github.com/tensorflow/tensorflow/issues/15737#issuecomment-354890871\">#15737 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim3AgdSckSYq6WP3jROttKBbKWOsLks5tGqwQgaJpZM4RPqFa\">https://github.com/notifications/unsubscribe-auth/ABtim3AgdSckSYq6WP3jROttKBbKWOsLks5tGqwQgaJpZM4RPqFa</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Do we need to, in general, have a static batch size for the encoder?  We\nshouldn't require that.\n\u2026\nOn Tue, Jan 2, 2018 at 2:22 PM, Rui Zhao ***@***.***> wrote:\n @nikita68 <https://github.com/nikita68>\n\n I think you need to make sure the the encoder_state has a static\n batch_size which means you need to set your placeholder's batch dimension\n as batch_size instead of None.\n\n or\n\n you can just use a tensor as the zero_states' batch size instead of a\n constant.\n\n For example:\n\n decoder_init_state = decoder_cell.zero_state(tf.size(decoder_full_length), tf.float32).clone(cell_state=encoder_state)\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#15737 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim3AgdSckSYq6WP3jROttKBbKWOsLks5tGqwQgaJpZM4RPqFa>\n .", "body": "Do we need to, in general, have a static batch size for the encoder?  We\nshouldn't require that.\n\nOn Tue, Jan 2, 2018 at 2:22 PM, Rui Zhao <notifications@github.com> wrote:\n\n> @nikita68 <https://github.com/nikita68>\n>\n> I think you need to make sure the the encoder_state has a static\n> batch_size which means you need to set your placeholder's batch dimension\n> as batch_size instead of None.\n>\n> or\n>\n> you can just use a tensor as the zero_states' batch size instead of a\n> constant.\n>\n> For example:\n>\n> decoder_init_state = decoder_cell.zero_state(tf.size(decoder_full_length), tf.float32).clone(cell_state=encoder_state)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15737#issuecomment-354890871>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim3AgdSckSYq6WP3jROttKBbKWOsLks5tGqwQgaJpZM4RPqFa>\n> .\n>\n"}