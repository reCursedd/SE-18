{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354665524", "html_url": "https://github.com/tensorflow/tensorflow/issues/15737#issuecomment-354665524", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15737", "id": 354665524, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDY2NTUyNA==", "user": {"login": "nikita68", "id": 15629332, "node_id": "MDQ6VXNlcjE1NjI5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15629332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikita68", "html_url": "https://github.com/nikita68", "followers_url": "https://api.github.com/users/nikita68/followers", "following_url": "https://api.github.com/users/nikita68/following{/other_user}", "gists_url": "https://api.github.com/users/nikita68/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikita68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikita68/subscriptions", "organizations_url": "https://api.github.com/users/nikita68/orgs", "repos_url": "https://api.github.com/users/nikita68/repos", "events_url": "https://api.github.com/users/nikita68/events{/privacy}", "received_events_url": "https://api.github.com/users/nikita68/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-01T17:38:25Z", "updated_at": "2018-01-01T17:42:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a><br>\nI've made two very hacky standalone code samples and I found out that this error only occurs when using placeholders:</p>\n<p>This example fails only when the clone method is called:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> -- Constants ---</span>\nvocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\ninput_dimensions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\ninput_embedding_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">50</span>\nencoder_hidden_units <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\ndecoder_hidden_units <span class=\"pl-k\">=</span> encoder_hidden_units\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\ntime_to_sim_input <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Build model ----</span>\nencoder_inputs <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, input_dimensions), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs<span class=\"pl-pds\">'</span></span>)\nencoder_inputs_length <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs_length<span class=\"pl-pds\">'</span></span>)\ndecoder_targets <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>decoder_targets<span class=\"pl-pds\">'</span></span>)\ndecoder_target_length <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>decoder_target_length<span class=\"pl-pds\">'</span></span>)\ndecoder_inputs <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>decoder_inputs<span class=\"pl-pds\">'</span></span>)\ndecoder_full_length <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>decoder_full_length<span class=\"pl-pds\">'</span></span>)\n\n\nembeddings <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nencoder_inputs_embedded <span class=\"pl-k\">=</span> encoder_inputs\ndecoder_inputs_embedded <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(embeddings, decoder_inputs)\ndecoder_inputs_embedded <span class=\"pl-k\">=</span> tf.transpose(decoder_inputs_embedded, <span class=\"pl-v\">perm</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Make it time major again</span>\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Encoder ------</span>\nencoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run Dynamic RNN</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_outputs: [max_time, batch_size, num_units]</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_state: [batch_size, num_units]</span>\nencoder_outputs, encoder_state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n    encoder_cell, encoder_inputs_embedded,\n    <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Decoder -----</span>\nhelper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\nattention_states <span class=\"pl-k\">=</span> tf.transpose(encoder_outputs, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> attention_states: [batch_size, max_time, num_units]</span>\nattention_mechanism <span class=\"pl-k\">=</span> tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    <span class=\"pl-v\">memory_sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length)\ndecoder_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    <span class=\"pl-v\">attention_layer_size</span><span class=\"pl-k\">=</span>decoder_hidden_units)\n\nprojection_layer <span class=\"pl-k\">=</span> layers_core.Dense(\n    vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ------------------------- CLONE --------------------------</span>\ndecoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(<span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>encoder_state),\n    <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>projection_layer)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Training ----</span>\noutputs, last_state, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder, <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nlogits <span class=\"pl-k\">=</span> outputs.rnn_output\ndecoder_prediction <span class=\"pl-k\">=</span> outputs.sample_id\n\n\ntargets_one_hot <span class=\"pl-k\">=</span> tf.one_hot(decoder_targets, <span class=\"pl-v\">depth</span><span class=\"pl-k\">=</span>vocab_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nstepwise_cross_entropy <span class=\"pl-k\">=</span> tf.nn.softmax_cross_entropy_with_logits(<span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>targets_one_hot, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits)\nloss <span class=\"pl-k\">=</span> tf.reduce_mean(stepwise_cross_entropy)\ntrain_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(loss)\n\ninit <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Loader -----</span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">next_batch</span>(<span class=\"pl-smi\">amount</span><span class=\"pl-k\">=</span>batch_size):\n\n    e_in <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(batch_size, time_to_sim_input, input_dimensions))\n    e_in_length <span class=\"pl-k\">=</span> [time_to_sim_input]\n    d_targets <span class=\"pl-k\">=</span> np.asarray([[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>]])\n    d_targets_length <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">len</span>(np.asarray([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>]))]\n    offset_din <span class=\"pl-k\">=</span> np.asarray([[<span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>]])\n\n    <span class=\"pl-k\">return</span> {\n        encoder_inputs: np.transpose(e_in, <span class=\"pl-v\">axes</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>]),\n        encoder_inputs_length: e_in_length,\n        decoder_targets: np.transpose(d_targets),\n        decoder_target_length: d_targets_length,\n        decoder_inputs: offset_din,\n        decoder_full_length: np.asarray([<span class=\"pl-c1\">len</span>(np.asarray([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>]))] <span class=\"pl-k\">*</span> amount),\n    }\n\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(init)\n    losses <span class=\"pl-k\">=</span> []\n\n    feed <span class=\"pl-k\">=</span> next_batch()\n    _, l, predict <span class=\"pl-k\">=</span> sess.run([train_op, loss, decoder_prediction], feed)\n    losses.append(l)\n\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Finished<span class=\"pl-pds\">'</span></span>\n</pre></div>\n<p>And this example is fine, but doesn't use placeholders:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> -- Constants ---</span>\nvocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> PAD = 8, EOS = 9</span>\ninput_dimensions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\ninput_embedding_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">50</span>\nencoder_hidden_units <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\ndecoder_hidden_units <span class=\"pl-k\">=</span> encoder_hidden_units\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\ntime_to_sim_input <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Build model ----</span>\n\nencoder_inputs <span class=\"pl-k\">=</span> tf.random_uniform(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(time_to_sim_input, batch_size, input_dimensions))\nencoder_inputs_length <span class=\"pl-k\">=</span> tf.constant(time_to_sim_input, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size,))\ndecoder_targets <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">5</span>, batch_size))\ndecoder_targets_length <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">4</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size,))\ndecoder_inputs <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>], <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size, <span class=\"pl-c1\">5</span>))\ndecoder_full_length <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">5</span>] <span class=\"pl-k\">*</span> batch_size, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size,))\n\nembeddings <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nencoder_inputs_embedded <span class=\"pl-k\">=</span> encoder_inputs\ndecoder_inputs_embedded <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(embeddings, decoder_inputs)\ndecoder_inputs_embedded <span class=\"pl-k\">=</span> tf.transpose(decoder_inputs_embedded, <span class=\"pl-v\">perm</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Make it time major again</span>\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Encoder ------</span>\nencoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Run Dynamic RNN</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_outputs: [max_time, batch_size, num_units]</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_state: [batch_size, num_units]</span>\nencoder_outputs, encoder_state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n    encoder_cell, encoder_inputs_embedded,\n    <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Decoder -----</span>\nhelper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\nattention_states <span class=\"pl-k\">=</span> tf.transpose(encoder_outputs, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> attention_states: [batch_size, max_time, num_units]</span>\nattention_mechanism <span class=\"pl-k\">=</span> tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    <span class=\"pl-v\">memory_sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length)\ndecoder_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    <span class=\"pl-v\">attention_layer_size</span><span class=\"pl-k\">=</span>decoder_hidden_units)\n\nprojection_layer <span class=\"pl-k\">=</span> layers_core.Dense(\n    vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ------------------------- CLONE --------------------------</span>\ndecoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(<span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>encoder_state),\n    <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>projection_layer)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Training ----</span>\noutputs, last_state, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder, <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nlogits <span class=\"pl-k\">=</span> outputs.rnn_output\ndecoder_prediction <span class=\"pl-k\">=</span> outputs.sample_id\n\n\ntargets_one_hot <span class=\"pl-k\">=</span> tf.one_hot(decoder_targets, <span class=\"pl-v\">depth</span><span class=\"pl-k\">=</span>vocab_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nstepwise_cross_entropy <span class=\"pl-k\">=</span> tf.nn.softmax_cross_entropy_with_logits(<span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>targets_one_hot, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits)\nloss <span class=\"pl-k\">=</span> tf.reduce_mean(stepwise_cross_entropy)\ntrain_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(loss)\n\ninit <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ---- Loader -----</span>\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(init)\n    losses <span class=\"pl-k\">=</span> []\n\n    _, l, predict <span class=\"pl-k\">=</span> sess.run([train_op, loss, decoder_prediction])\n    losses.append(l)\n\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Finished<span class=\"pl-pds\">'</span></span>\n</pre></div>", "body_text": "@ebrevdo\nI've made two very hacky standalone code samples and I found out that this error only occurs when using placeholders:\nThis example fails only when the clone method is called:\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.layers import core as layers_core\n\n# -- Constants ---\nvocab_size = 10\ninput_dimensions = 20\ninput_embedding_size = 50\nencoder_hidden_units = 512\ndecoder_hidden_units = encoder_hidden_units\nbatch_size = 1\ntime_to_sim_input = 5\n\n# ---- Build model ----\nencoder_inputs = tf.placeholder(shape=(None, None, input_dimensions), dtype=tf.float32, name='encoder_inputs')\nencoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\ndecoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\ndecoder_target_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_target_length')\ndecoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\ndecoder_full_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_full_length')\n\n\nembeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\nencoder_inputs_embedded = encoder_inputs\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\ndecoder_inputs_embedded = tf.transpose(decoder_inputs_embedded, perm=[1, 0, 2])  # Make it time major again\n\n\n# ---- Encoder ------\nencoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n# Run Dynamic RNN\n#   encoder_outputs: [max_time, batch_size, num_units]\n#   encoder_state: [batch_size, num_units]\nencoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n    encoder_cell, encoder_inputs_embedded,\n    sequence_length=encoder_inputs_length, time_major=True,\n    dtype=tf.float32)\n\n\n# ---- Decoder -----\nhelper = tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, time_major=True)\n\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    memory_sequence_length=encoder_inputs_length)\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    attention_layer_size=decoder_hidden_units)\n\nprojection_layer = layers_core.Dense(\n    vocab_size, use_bias=False)\n\n\n# ------------------------- CLONE --------------------------\ndecoder = tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\n    output_layer=projection_layer)\n\n# ---- Training ----\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\nlogits = outputs.rnn_output\ndecoder_prediction = outputs.sample_id\n\n\ntargets_one_hot = tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32)\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot, logits=logits)\nloss = tf.reduce_mean(stepwise_cross_entropy)\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.global_variables_initializer()\n\n\n# ---- Loader -----\n\n\ndef next_batch(amount=batch_size):\n\n    e_in = np.random.uniform(-1.0, 1.0, size=(batch_size, time_to_sim_input, input_dimensions))\n    e_in_length = [time_to_sim_input]\n    d_targets = np.asarray([[1, 2, 3, 4, 5]])\n    d_targets_length = [len(np.asarray([1, 2, 3, 4, 5]))]\n    offset_din = np.asarray([[9, 1, 2, 3, 4, 5]])\n\n    return {\n        encoder_inputs: np.transpose(e_in, axes=[1, 0, 2]),\n        encoder_inputs_length: e_in_length,\n        decoder_targets: np.transpose(d_targets),\n        decoder_target_length: d_targets_length,\n        decoder_inputs: offset_din,\n        decoder_full_length: np.asarray([len(np.asarray([1, 2, 3, 4, 5]))] * amount),\n    }\n\n\nwith tf.Session() as sess:\n    sess.run(init)\n    losses = []\n\n    feed = next_batch()\n    _, l, predict = sess.run([train_op, loss, decoder_prediction], feed)\n    losses.append(l)\n\n    print 'Finished'\n\nAnd this example is fine, but doesn't use placeholders:\nimport tensorflow as tf\nfrom tensorflow.python.layers import core as layers_core\n\n# -- Constants ---\nvocab_size = 10  # PAD = 8, EOS = 9\ninput_dimensions = 20\ninput_embedding_size = 50\nencoder_hidden_units = 512\ndecoder_hidden_units = encoder_hidden_units\nbatch_size = 1\ntime_to_sim_input = 8\n\n# ---- Build model ----\n\nencoder_inputs = tf.random_uniform(shape=(time_to_sim_input, batch_size, input_dimensions))\nencoder_inputs_length = tf.constant(time_to_sim_input, shape=(batch_size,))\ndecoder_targets = tf.constant([1, 2, 3, 4, 5], shape=(5, batch_size))\ndecoder_targets_length = tf.constant(4, shape=(batch_size,))\ndecoder_inputs = tf.constant([9, 1, 2, 3, 4], shape=(batch_size, 5))\ndecoder_full_length = tf.constant([5] * batch_size, shape=(batch_size,))\n\nembeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\nencoder_inputs_embedded = encoder_inputs\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\ndecoder_inputs_embedded = tf.transpose(decoder_inputs_embedded, perm=[1, 0, 2])  # Make it time major again\n\n\n# ---- Encoder ------\nencoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n\n# Run Dynamic RNN\n#   encoder_outputs: [max_time, batch_size, num_units]\n#   encoder_state: [batch_size, num_units]\nencoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n    encoder_cell, encoder_inputs_embedded,\n    sequence_length=encoder_inputs_length, time_major=True,\n    dtype=tf.float32)\n\n# ---- Decoder -----\nhelper = tf.contrib.seq2seq.TrainingHelper(\n    decoder_inputs_embedded, decoder_full_length, time_major=True)\n\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\n    encoder_hidden_units, attention_states,\n    memory_sequence_length=encoder_inputs_length)\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\n    attention_mechanism,\n    attention_layer_size=decoder_hidden_units)\n\nprojection_layer = layers_core.Dense(\n    vocab_size, use_bias=False)\n\n# ------------------------- CLONE --------------------------\ndecoder = tf.contrib.seq2seq.BasicDecoder(\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\n    output_layer=projection_layer)\n\n# ---- Training ----\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\nlogits = outputs.rnn_output\ndecoder_prediction = outputs.sample_id\n\n\ntargets_one_hot = tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32)\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot, logits=logits)\nloss = tf.reduce_mean(stepwise_cross_entropy)\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.global_variables_initializer()\n\n\n# ---- Loader -----\n\nwith tf.Session() as sess:\n    sess.run(init)\n    losses = []\n\n    _, l, predict = sess.run([train_op, loss, decoder_prediction])\n    losses.append(l)\n\n    print 'Finished'", "body": "@ebrevdo \r\nI've made two very hacky standalone code samples and I found out that this error only occurs when using placeholders:\r\n\r\nThis example fails only when the clone method is called:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.layers import core as layers_core\r\n\r\n# -- Constants ---\r\nvocab_size = 10\r\ninput_dimensions = 20\r\ninput_embedding_size = 50\r\nencoder_hidden_units = 512\r\ndecoder_hidden_units = encoder_hidden_units\r\nbatch_size = 1\r\ntime_to_sim_input = 5\r\n\r\n# ---- Build model ----\r\nencoder_inputs = tf.placeholder(shape=(None, None, input_dimensions), dtype=tf.float32, name='encoder_inputs')\r\nencoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\r\ndecoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\r\ndecoder_target_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_target_length')\r\ndecoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\r\ndecoder_full_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_full_length')\r\n\r\n\r\nembeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\r\nencoder_inputs_embedded = encoder_inputs\r\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\r\ndecoder_inputs_embedded = tf.transpose(decoder_inputs_embedded, perm=[1, 0, 2])  # Make it time major again\r\n\r\n\r\n# ---- Encoder ------\r\nencoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\r\n\r\n# Run Dynamic RNN\r\n#   encoder_outputs: [max_time, batch_size, num_units]\r\n#   encoder_state: [batch_size, num_units]\r\nencoder_outputs, encoder_state = tf.nn.dynamic_rnn(\r\n    encoder_cell, encoder_inputs_embedded,\r\n    sequence_length=encoder_inputs_length, time_major=True,\r\n    dtype=tf.float32)\r\n\r\n\r\n# ---- Decoder -----\r\nhelper = tf.contrib.seq2seq.TrainingHelper(\r\n    decoder_inputs_embedded, decoder_full_length, time_major=True)\r\n\r\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n    encoder_hidden_units, attention_states,\r\n    memory_sequence_length=encoder_inputs_length)\r\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\r\n    attention_mechanism,\r\n    attention_layer_size=decoder_hidden_units)\r\n\r\nprojection_layer = layers_core.Dense(\r\n    vocab_size, use_bias=False)\r\n\r\n\r\n# ------------------------- CLONE --------------------------\r\ndecoder = tf.contrib.seq2seq.BasicDecoder(\r\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\r\n    output_layer=projection_layer)\r\n\r\n# ---- Training ----\r\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\r\nlogits = outputs.rnn_output\r\ndecoder_prediction = outputs.sample_id\r\n\r\n\r\ntargets_one_hot = tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32)\r\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot, logits=logits)\r\nloss = tf.reduce_mean(stepwise_cross_entropy)\r\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\n\r\n# ---- Loader -----\r\n\r\n\r\ndef next_batch(amount=batch_size):\r\n\r\n    e_in = np.random.uniform(-1.0, 1.0, size=(batch_size, time_to_sim_input, input_dimensions))\r\n    e_in_length = [time_to_sim_input]\r\n    d_targets = np.asarray([[1, 2, 3, 4, 5]])\r\n    d_targets_length = [len(np.asarray([1, 2, 3, 4, 5]))]\r\n    offset_din = np.asarray([[9, 1, 2, 3, 4, 5]])\r\n\r\n    return {\r\n        encoder_inputs: np.transpose(e_in, axes=[1, 0, 2]),\r\n        encoder_inputs_length: e_in_length,\r\n        decoder_targets: np.transpose(d_targets),\r\n        decoder_target_length: d_targets_length,\r\n        decoder_inputs: offset_din,\r\n        decoder_full_length: np.asarray([len(np.asarray([1, 2, 3, 4, 5]))] * amount),\r\n    }\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    losses = []\r\n\r\n    feed = next_batch()\r\n    _, l, predict = sess.run([train_op, loss, decoder_prediction], feed)\r\n    losses.append(l)\r\n\r\n    print 'Finished'\r\n\r\n```\r\n\r\nAnd this example is fine, but doesn't use placeholders:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.layers import core as layers_core\r\n\r\n# -- Constants ---\r\nvocab_size = 10  # PAD = 8, EOS = 9\r\ninput_dimensions = 20\r\ninput_embedding_size = 50\r\nencoder_hidden_units = 512\r\ndecoder_hidden_units = encoder_hidden_units\r\nbatch_size = 1\r\ntime_to_sim_input = 8\r\n\r\n# ---- Build model ----\r\n\r\nencoder_inputs = tf.random_uniform(shape=(time_to_sim_input, batch_size, input_dimensions))\r\nencoder_inputs_length = tf.constant(time_to_sim_input, shape=(batch_size,))\r\ndecoder_targets = tf.constant([1, 2, 3, 4, 5], shape=(5, batch_size))\r\ndecoder_targets_length = tf.constant(4, shape=(batch_size,))\r\ndecoder_inputs = tf.constant([9, 1, 2, 3, 4], shape=(batch_size, 5))\r\ndecoder_full_length = tf.constant([5] * batch_size, shape=(batch_size,))\r\n\r\nembeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\r\nencoder_inputs_embedded = encoder_inputs\r\ndecoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\r\ndecoder_inputs_embedded = tf.transpose(decoder_inputs_embedded, perm=[1, 0, 2])  # Make it time major again\r\n\r\n\r\n# ---- Encoder ------\r\nencoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\r\n\r\n# Run Dynamic RNN\r\n#   encoder_outputs: [max_time, batch_size, num_units]\r\n#   encoder_state: [batch_size, num_units]\r\nencoder_outputs, encoder_state = tf.nn.dynamic_rnn(\r\n    encoder_cell, encoder_inputs_embedded,\r\n    sequence_length=encoder_inputs_length, time_major=True,\r\n    dtype=tf.float32)\r\n\r\n# ---- Decoder -----\r\nhelper = tf.contrib.seq2seq.TrainingHelper(\r\n    decoder_inputs_embedded, decoder_full_length, time_major=True)\r\n\r\nattention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\nattention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n    encoder_hidden_units, attention_states,\r\n    memory_sequence_length=encoder_inputs_length)\r\ndecoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n    tf.contrib.rnn.LSTMCell(decoder_hidden_units),\r\n    attention_mechanism,\r\n    attention_layer_size=decoder_hidden_units)\r\n\r\nprojection_layer = layers_core.Dense(\r\n    vocab_size, use_bias=False)\r\n\r\n# ------------------------- CLONE --------------------------\r\ndecoder = tf.contrib.seq2seq.BasicDecoder(\r\n    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\r\n    output_layer=projection_layer)\r\n\r\n# ---- Training ----\r\noutputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)\r\nlogits = outputs.rnn_output\r\ndecoder_prediction = outputs.sample_id\r\n\r\n\r\ntargets_one_hot = tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32)\r\nstepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets_one_hot, logits=logits)\r\nloss = tf.reduce_mean(stepwise_cross_entropy)\r\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\n\r\n# ---- Loader -----\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    losses = []\r\n\r\n    _, l, predict = sess.run([train_op, loss, decoder_prediction])\r\n    losses.append(l)\r\n\r\n    print 'Finished'\r\n\r\n```"}