{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75749577", "pull_request_review_id": null, "id": 75749577, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc1NzQ5NTc3", "diff_hunk": "@@ -661,6 +663,109 @@ def _make_tf_features(self, input_feat):\n       freq_inputs.append(cur_input)\n     return freq_inputs\n \n+class ESNCell(rnn_cell.RNNCell):\n+  \"\"\"Echo State Network Cell.\n+\n+    Based on http://www.faculty.jacobs-university.de/hjaeger/pubs/EchoStatesTechRep.pdf\n+    It doesn't consider output feedback, specifically it models just the reservoir.\n+\n+    Here a practical guide to use Echo State Networks:\n+    http://minds.jacobs-university.de/sites/default/files/uploads/papers/PracticalESN.pdf\n+\n+    Since at the moment TF doesn't provide a way to compute spectral radius\n+    of a matrix the echo state property necessary condition `max(eig(W)) < 1` is approximated\n+    scaling the norm 2 of the reservoir matrix which is an upper bound of the spectral radius.\n+    See https://en.wikipedia.org/wiki/Matrix_norm#Induced_norm\n+\n+  \"\"\"\n+\n+  def __init__(self, num_units, wr2_scale=0.7, connectivity=0.1, leaky=1.0, activation=math_ops.tanh,\n+               win_init=init_ops.random_normal_initializer(),\n+               wr_init=init_ops.random_normal_initializer(),\n+               bias_init=init_ops.random_normal_initializer()):\n+    \"\"\"Initialize the Echo State Network Cell.\n+\n+    Args:\n+      num_units: Int or 0-D Int Tensor, the number of units in the reservoir\n+      wr2_scale: desired norm2 of reservoir weight matrix.\n+        `wr2_scale < 1` is a sufficient condition for echo state property.\n+      connectivity: connection probability between two reservoir units\n+      leaky: leaky parameter\n+      activation: activation function\n+      win_init: initializer for input weights\n+      wr_init: used to initialize reservoir weights before applying connectivity mask and scaling\n+      bias_init: initializer for biases\n+    \"\"\"\n+    self._num_units = num_units\n+    self._leaky = leaky\n+    self._activation = activation\n+\n+    def _wr_initializer(shape, dtype):\n+      wr = wr_init(shape, dtype=dtype)\n+\n+      connectivity_mask = \\\n+        math_ops.cast(\n+          math_ops.less_equal(\n+            random_ops.random_uniform(shape),\n+            connectivity),\n+          dtype)\n+\n+      wr = math_ops.mul(wr, connectivity_mask)\n+\n+      wr_norm2 = math_ops.sqrt(\n+        math_ops.reduce_sum(\n+          math_ops.square(wr)))\n+\n+      is_norm_0 = math_ops.cast(math_ops.equal(wr_norm2, 0), dtype)\n+\n+      wr = wr * wr2_scale / (wr_norm2 + 1 * is_norm_0)\n+\n+      return wr\n+\n+    self._win_initializer = win_init\n+    self._bias_initializer = bias_init\n+    self._wr_initializer = _wr_initializer\n+\n+  @property\n+  def output_size(self):\n+    return self._num_units\n+\n+  @property\n+  def state_size(self):\n+    return self._num_units\n+\n+  def __call__(self, inputs, state, scope=None):\n+    \"\"\" Run one step of ESN Cell\n+\n+        Args:\n+          inputs: `2-D Tensor` with shape `[batch_size x input_size]`.\n+          state: `2-D Tensor` with shape `[batch_size x self.state_size]`.\n+          scope: VariableScope for the created subgraph; defaults to class `ESNCell`.\n+\n+        Returns:\n+          A tuple `(output, new_state)`, computed as\n+          `output = new_state = (1 - leaky) * state + leaky * activation(Win * input + Wr * state + B)`.\n+\n+        Raises:\n+          ValueError: if `inputs` or `state` tensor size mismatch the previously provided dimension.\n+          \"\"\"\n+\n+    input_size = inputs.get_shape().as_list()[1]\n+    dtype = inputs.dtype\n+\n+    with vs.variable_scope(scope or type(self).__name__):  # \"ESNCell\"\n+\n+      win = vs.get_variable(\"InputMatrix\", [input_size, self._num_units], dtype=dtype,", "path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "position": 107, "original_position": 107, "commit_id": "26549078d2ecc775cedeb9c8875490aa55488f01", "original_commit_id": "f9c78e0f29d53a5635847a653a073d26dc010a50", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "it is often leads to faster computation e.g. on GPUs to create a single matrix, e.g., InputMatrix equivalent to concatenating ReservoirMatrix, perform a single matmul, and then split the results.\n\nAlso here you should probably just use contrib.layers.linear instead of calling the matmul + get_variable yourself.\n", "created_at": "2016-08-22T20:14:27Z", "updated_at": "2016-08-29T14:26:49Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3604#discussion_r75749577", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3604", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75749577"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3604#discussion_r75749577"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3604"}}, "body_html": "<p>it is often leads to faster computation e.g. on GPUs to create a single matrix, e.g., InputMatrix equivalent to concatenating ReservoirMatrix, perform a single matmul, and then split the results.</p>\n<p>Also here you should probably just use contrib.layers.linear instead of calling the matmul + get_variable yourself.</p>", "body_text": "it is often leads to faster computation e.g. on GPUs to create a single matrix, e.g., InputMatrix equivalent to concatenating ReservoirMatrix, perform a single matmul, and then split the results.\nAlso here you should probably just use contrib.layers.linear instead of calling the matmul + get_variable yourself."}