{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6466", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6466/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6466/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6466/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6466", "id": 197303947, "node_id": "MDU6SXNzdWUxOTczMDM5NDc=", "number": 6466, "title": "CudnnLSTM dropout takes no effect", "user": {"login": "robotnc", "id": 18507467, "node_id": "MDQ6VXNlcjE4NTA3NDY3", "avatar_url": "https://avatars1.githubusercontent.com/u/18507467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robotnc", "html_url": "https://github.com/robotnc", "followers_url": "https://api.github.com/users/robotnc/followers", "following_url": "https://api.github.com/users/robotnc/following{/other_user}", "gists_url": "https://api.github.com/users/robotnc/gists{/gist_id}", "starred_url": "https://api.github.com/users/robotnc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robotnc/subscriptions", "organizations_url": "https://api.github.com/users/robotnc/orgs", "repos_url": "https://api.github.com/users/robotnc/repos", "events_url": "https://api.github.com/users/robotnc/events{/privacy}", "received_events_url": "https://api.github.com/users/robotnc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2016-12-23T02:33:57Z", "updated_at": "2017-10-26T00:58:54Z", "closed_at": "2017-10-26T00:58:54Z", "author_association": "NONE", "body_html": "<p>My environment is: Tensorflow 0.11.0rc2, in unbuntu 16.04, cuda8.0, cudnn5.1, GPU is GTX1080.</p>\n<p>I am using the CudnnLSTM from tensorflow.contrib.cudnn_rnn package. I found that the dropout setting in CudnnLSTM seems take no effect, and I checked that there is no test for dropout in op unit test. So I write a simple code to test it, the code is below:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib.cudnn_rnn import CudnnLSTM\n\nclass Cudnn_model():\n  def __init__(self,dropout):\n    self.model = CudnnLSTM(\n        num_layers = 1,\n        num_units = 8,\n        input_size = 8,\n        input_mode = \"skip_input\",\n        direction = \"unidirectional\",\n        dropout = dropout,\n        )\n\n    params_size_t = self.model.params_size()\n    self.params = tf.Variable(tf.ones([params_size_t]), validate_shape=False)\n\n  def run_step(self,rnn_inputs):\n    outputs, output_h, output_c = self.model(\n                input_data = rnn_inputs,\n                input_h = tf.zeros([1,1,8]),\n                input_c = tf.zeros([1,1,8]),\n                params = self.params,\n                is_training= True\n               )\n    self.outputs = outputs\n    return outputs\n\ndef main():\n\ninputs = tf.pack([[[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0]]])\nm1 = Cudnn_model(dropout = 0.0)\noutput1 = m1.run_step(inputs)\nm2 = Cudnn_model(dropout = 0.5)\noutput2 = m2.run_step(inputs)\noutput3 = tf.nn.dropout(output1,0.5)\noutput4 = m1.run_step(tf.nn.dropout(inputs,0.5))\n\nconfig = tf.ConfigProto(allow_soft_placement=True)\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\nsess.run(tf.initialize_all_variables())\n\nfor i in range(5):\n    out1,out2,out3,out4 = sess.run([output1,output2,output3,output4])\n    print \" ----- Try time %d -----\" % i\n    print \"cndnn_dropout=0 : \", out1\n    print \"cudnn_dropout=0.5 : \", out2\n    print \"tf_out_dropout=0.5 : \", out3\n    print \"tf_in_dropout=0.5 : \", out4\nreturn\n</code></pre>\n<p>And the result is\uff1a</p>\n<pre><code>----- Try time 0 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 1.2165668   0.          0.          0.          0.          1.52103424\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.6082834 ]]]\n\n ----- Try time 1 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.  0.  0.  0.  0.  0.  0.  0.]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.6082834 ]]]\n\n ----- Try time 2 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 1.2165668   0.          0.          1.50730526  1.51733613  1.52103424\n1.52239561  0.        ]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.761594  ]]]\n\n ----- Try time 3 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.          0.          1.48019314  0.          0.          0.\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.76154053  0.6082834\n0.76159316  0.761594  ]]]\n\n ----- Try time 4 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.          1.40755069  0.          1.50730526  1.51733613  0.\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.75866807  0.76119781  0.6082834   0.76158684\n0.76159316  0.6082834 ]]]\n</code></pre>\n<p>From the result I see that the cudnn_dropout = 0.5 takes no effect, the result is always same with cudnn_dropout = 0.0.</p>", "body_text": "My environment is: Tensorflow 0.11.0rc2, in unbuntu 16.04, cuda8.0, cudnn5.1, GPU is GTX1080.\nI am using the CudnnLSTM from tensorflow.contrib.cudnn_rnn package. I found that the dropout setting in CudnnLSTM seems take no effect, and I checked that there is no test for dropout in op unit test. So I write a simple code to test it, the code is below:\nimport tensorflow as tf\nfrom tensorflow.contrib.cudnn_rnn import CudnnLSTM\n\nclass Cudnn_model():\n  def __init__(self,dropout):\n    self.model = CudnnLSTM(\n        num_layers = 1,\n        num_units = 8,\n        input_size = 8,\n        input_mode = \"skip_input\",\n        direction = \"unidirectional\",\n        dropout = dropout,\n        )\n\n    params_size_t = self.model.params_size()\n    self.params = tf.Variable(tf.ones([params_size_t]), validate_shape=False)\n\n  def run_step(self,rnn_inputs):\n    outputs, output_h, output_c = self.model(\n                input_data = rnn_inputs,\n                input_h = tf.zeros([1,1,8]),\n                input_c = tf.zeros([1,1,8]),\n                params = self.params,\n                is_training= True\n               )\n    self.outputs = outputs\n    return outputs\n\ndef main():\n\ninputs = tf.pack([[[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0]]])\nm1 = Cudnn_model(dropout = 0.0)\noutput1 = m1.run_step(inputs)\nm2 = Cudnn_model(dropout = 0.5)\noutput2 = m2.run_step(inputs)\noutput3 = tf.nn.dropout(output1,0.5)\noutput4 = m1.run_step(tf.nn.dropout(inputs,0.5))\n\nconfig = tf.ConfigProto(allow_soft_placement=True)\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\nsess.run(tf.initialize_all_variables())\n\nfor i in range(5):\n    out1,out2,out3,out4 = sess.run([output1,output2,output3,output4])\n    print \" ----- Try time %d -----\" % i\n    print \"cndnn_dropout=0 : \", out1\n    print \"cudnn_dropout=0.5 : \", out2\n    print \"tf_out_dropout=0.5 : \", out3\n    print \"tf_in_dropout=0.5 : \", out4\nreturn\n\nAnd the result is\uff1a\n----- Try time 0 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 1.2165668   0.          0.          0.          0.          1.52103424\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.6082834 ]]]\n\n ----- Try time 1 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.  0.  0.  0.  0.  0.  0.  0.]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.6082834 ]]]\n\n ----- Try time 2 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 1.2165668   0.          0.          1.50730526  1.51733613  1.52103424\n1.52239561  0.        ]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\n0.6082834   0.761594  ]]]\n\n ----- Try time 3 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.          0.          1.48019314  0.          0.          0.\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.76154053  0.6082834\n0.76159316  0.761594  ]]]\n\n ----- Try time 4 -----\ncndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ncudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\n0.76119781  0.76144838]]]\ntf_out_dropout=0.5 [[[ 0.          1.40755069  0.          1.50730526  1.51733613  0.\n1.52239561  1.52289677]]]\ntf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.75866807  0.76119781  0.6082834   0.76158684\n0.76159316  0.6082834 ]]]\n\nFrom the result I see that the cudnn_dropout = 0.5 takes no effect, the result is always same with cudnn_dropout = 0.0.", "body": "My environment is: Tensorflow 0.11.0rc2, in unbuntu 16.04, cuda8.0, cudnn5.1, GPU is GTX1080.\r\n\r\nI am using the CudnnLSTM from tensorflow.contrib.cudnn_rnn package. I found that the dropout setting in CudnnLSTM seems take no effect, and I checked that there is no test for dropout in op unit test. So I write a simple code to test it, the code is below:\r\n \r\n    import tensorflow as tf\r\n    from tensorflow.contrib.cudnn_rnn import CudnnLSTM\r\n\r\n    class Cudnn_model():\r\n      def __init__(self,dropout):\r\n        self.model = CudnnLSTM(\r\n            num_layers = 1,\r\n            num_units = 8,\r\n            input_size = 8,\r\n            input_mode = \"skip_input\",\r\n            direction = \"unidirectional\",\r\n            dropout = dropout,\r\n            )\r\n\r\n        params_size_t = self.model.params_size()\r\n        self.params = tf.Variable(tf.ones([params_size_t]), validate_shape=False)\r\n\r\n      def run_step(self,rnn_inputs):\r\n        outputs, output_h, output_c = self.model(\r\n                    input_data = rnn_inputs,\r\n                    input_h = tf.zeros([1,1,8]),\r\n                    input_c = tf.zeros([1,1,8]),\r\n                    params = self.params,\r\n                    is_training= True\r\n                   )\r\n        self.outputs = outputs\r\n        return outputs\r\n\r\n    def main():\r\n\r\n    inputs = tf.pack([[[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0]]])\r\n    m1 = Cudnn_model(dropout = 0.0)\r\n    output1 = m1.run_step(inputs)\r\n    m2 = Cudnn_model(dropout = 0.5)\r\n    output2 = m2.run_step(inputs)\r\n    output3 = tf.nn.dropout(output1,0.5)\r\n    output4 = m1.run_step(tf.nn.dropout(inputs,0.5))\r\n\r\n    config = tf.ConfigProto(allow_soft_placement=True)\r\n    config.gpu_options.allow_growth = True\r\n    sess = tf.Session(config=config)\r\n    sess.run(tf.initialize_all_variables())\r\n\r\n    for i in range(5):\r\n        out1,out2,out3,out4 = sess.run([output1,output2,output3,output4])\r\n        print \" ----- Try time %d -----\" % i\r\n        print \"cndnn_dropout=0 : \", out1\r\n        print \"cudnn_dropout=0.5 : \", out2\r\n        print \"tf_out_dropout=0.5 : \", out3\r\n        print \"tf_in_dropout=0.5 : \", out4\r\n    return\r\n\r\nAnd the result is\uff1a\r\n\r\n    ----- Try time 0 -----\r\n    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    tf_out_dropout=0.5 [[[ 1.2165668   0.          0.          0.          0.          1.52103424\r\n    1.52239561  1.52289677]]]\r\n    tf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.6082834   0.76158684\r\n    0.6082834   0.6082834 ]]]\r\n\r\n     ----- Try time 1 -----\r\n    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    tf_out_dropout=0.5 [[[ 0.  0.  0.  0.  0.  0.  0.  0.]]]\r\n    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\r\n    0.6082834   0.6082834 ]]]\r\n\r\n     ----- Try time 2 -----\r\n    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    tf_out_dropout=0.5 [[[ 1.2165668   0.          0.          1.50730526  1.51733613  1.52103424\r\n    1.52239561  0.        ]]]\r\n    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684\r\n    0.6082834   0.761594  ]]]\r\n\r\n     ----- Try time 3 -----\r\n    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    tf_out_dropout=0.5 [[[ 0.          0.          1.48019314  0.          0.          0.\r\n    1.52239561  1.52289677]]]\r\n    tf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.76154053  0.6082834\r\n    0.76159316  0.761594  ]]]\r\n\r\n     ----- Try time 4 -----\r\n    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712\r\n    0.76119781  0.76144838]]]\r\n    tf_out_dropout=0.5 [[[ 0.          1.40755069  0.          1.50730526  1.51733613  0.\r\n    1.52239561  1.52289677]]]\r\n    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.75866807  0.76119781  0.6082834   0.76158684\r\n    0.76159316  0.6082834 ]]]\r\n\r\nFrom the result I see that the cudnn_dropout = 0.5 takes no effect, the result is always same with cudnn_dropout = 0.0. "}