{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/279768993", "html_url": "https://github.com/tensorflow/tensorflow/issues/533#issuecomment-279768993", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/533", "id": 279768993, "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTc2ODk5Mw==", "user": {"login": "gpapan", "id": 6232317, "node_id": "MDQ6VXNlcjYyMzIzMTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6232317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpapan", "html_url": "https://github.com/gpapan", "followers_url": "https://api.github.com/users/gpapan/followers", "following_url": "https://api.github.com/users/gpapan/following{/other_user}", "gists_url": "https://api.github.com/users/gpapan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpapan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpapan/subscriptions", "organizations_url": "https://api.github.com/users/gpapan/orgs", "repos_url": "https://api.github.com/users/gpapan/repos", "events_url": "https://api.github.com/users/gpapan/events{/privacy}", "received_events_url": "https://api.github.com/users/gpapan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-14T17:04:01Z", "updated_at": "2017-02-14T17:04:01Z", "author_association": "NONE", "body_html": "<p>I did the gpu implementation for bilinear interpolation. The Cuda kernel can get faster (e.g., have each thread compute multiple channels reusing the indexing arithmetic). However, I find the quoted \"(about 2 seconds for resizing 375 x 667 to 1280 x 1280, same as on CPU)\" too large. What is the benchmark used? Are we certain that the gpu path is activated? Which gpu? What is the depth of the tensors? Does this cover forward only or both forward and backward? In any case, I think writing a benchmark suite is the first step that we should accomplish.</p>", "body_text": "I did the gpu implementation for bilinear interpolation. The Cuda kernel can get faster (e.g., have each thread compute multiple channels reusing the indexing arithmetic). However, I find the quoted \"(about 2 seconds for resizing 375 x 667 to 1280 x 1280, same as on CPU)\" too large. What is the benchmark used? Are we certain that the gpu path is activated? Which gpu? What is the depth of the tensors? Does this cover forward only or both forward and backward? In any case, I think writing a benchmark suite is the first step that we should accomplish.", "body": "I did the gpu implementation for bilinear interpolation. The Cuda kernel can get faster (e.g., have each thread compute multiple channels reusing the indexing arithmetic). However, I find the quoted \"(about 2 seconds for resizing 375 x 667 to 1280 x 1280, same as on CPU)\" too large. What is the benchmark used? Are we certain that the gpu path is activated? Which gpu? What is the depth of the tensors? Does this cover forward only or both forward and backward? In any case, I think writing a benchmark suite is the first step that we should accomplish. "}