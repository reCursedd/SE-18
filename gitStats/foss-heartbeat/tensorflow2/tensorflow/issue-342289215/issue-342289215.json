{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20920", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20920/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20920/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20920/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20920", "id": 342289215, "node_id": "MDU6SXNzdWUzNDIyODkyMTU=", "number": 20920, "title": "[ Interpreter.runForMultipleInputsOutputs ] Error When running  SSD-Mobilenet-v1 model in tensorflow-lite. ", "user": {"login": "AbdelfettahBentaleb", "id": 14340321, "node_id": "MDQ6VXNlcjE0MzQwMzIx", "avatar_url": "https://avatars0.githubusercontent.com/u/14340321?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AbdelfettahBentaleb", "html_url": "https://github.com/AbdelfettahBentaleb", "followers_url": "https://api.github.com/users/AbdelfettahBentaleb/followers", "following_url": "https://api.github.com/users/AbdelfettahBentaleb/following{/other_user}", "gists_url": "https://api.github.com/users/AbdelfettahBentaleb/gists{/gist_id}", "starred_url": "https://api.github.com/users/AbdelfettahBentaleb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AbdelfettahBentaleb/subscriptions", "organizations_url": "https://api.github.com/users/AbdelfettahBentaleb/orgs", "repos_url": "https://api.github.com/users/AbdelfettahBentaleb/repos", "events_url": "https://api.github.com/users/AbdelfettahBentaleb/events{/privacy}", "received_events_url": "https://api.github.com/users/AbdelfettahBentaleb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, {"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-18T11:31:10Z", "updated_at": "2018-10-02T23:25:39Z", "closed_at": "2018-07-18T15:42:49Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3376817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewharp\">@andrewharp</a> I tried your cutosm inference class TFLiteObjectDetectionAPIModel.java in <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android\">tensorflow/contrib/lite/examples/android</a> , and i use it with your ssd mobilenet v1 tflite mobilenet_ssd_tflite_v1.zip but it seems i have a problem when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); ( in function recognizeImage(final Bitmap bitmap) ) . it throws this exception</p>\n<pre><code>07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\n        at android.os.Handler.handleCallback(Handler.java:739)\n        at android.os.Handler.dispatchMessage(Handler.java:95)\n        at android.os.Looper.loop(Looper.java:159)\n        at android.os.HandlerThread.run(HandlerThread.java:61)\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 &lt;bottom of call stack&gt; \n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\n</code></pre>\n<p>the error said that the length of outputs array is bigger than the length of inputs array<br>\nin this condition line in the Interpreter.java</p>\n<pre><code>public void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map&lt;Integer, Object&gt; outputs) {\n        if (this.wrapper == null) {\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\n        } else {\n            Tensor[] tensors = this.wrapper.run(inputs);\n            if (outputs != null &amp;&amp; tensors != null &amp;&amp; outputs.size() &lt;= tensors.length) {\n                int size = tensors.length;\n                //...\n            }} else {\n                throw new IllegalArgumentException(\"Output error: Outputs do not match with model outputs.\");\n}\n</code></pre>\n<p>This is my inputs array :</p>\n<pre><code>d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\nd.imgData.order(ByteOrder.nativeOrder());\n//...\n imgData.rewind();\n        for (int i = 0; i &lt; inputSize; ++i) {\n            for (int j = 0; j &lt; inputSize; ++j) {\n                int pixelValue = intValues[i * inputSize + j];\n                if (isModelQuantized) {\n                    // Quantized model\n                    imgData.put((byte) ((pixelValue &gt;&gt; 16) &amp; 0xFF));\n                    imgData.put((byte) ((pixelValue &gt;&gt; 8) &amp; 0xFF));\n                    imgData.put((byte) (pixelValue &amp; 0xFF));\n                } else { // Float model\n                    imgData.putFloat((((pixelValue &gt;&gt; 16) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat((((pixelValue &gt;&gt; 8) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat(((pixelValue &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n} \n\n</code></pre>\n<pre><code>Object[] inputArray = {imgData};\n</code></pre>\n<p>And this  the outputs arrays :</p>\n<pre><code>// Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        outputLocations = new float[1][NUM_DETECTIONS][4];\n        outputClasses = new float[1][NUM_DETECTIONS];\n        outputScores = new float[1][NUM_DETECTIONS];\n        numDetections = new float[1];\n//...\n        Map&lt;Integer, Object&gt; outputMap = new HashMap&lt;&gt;();\n        outputMap.put(0, outputLocations);\n        outputMap.put(1, outputScores);\n        outputMap.put(2, numDetections);\n        outputMap.put(3, outputClasses);\n        Trace.endSection();\n</code></pre>\n<p>And the Inference :</p>\n<pre><code>// Run the inference call.\n        Trace.beginSection(\"run\");\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length)); // inputArray has length of 1\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size())); // outputMap has length of 4\n\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\n        Trace.endSection();\n</code></pre>\n<p>I didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .<br>\nthank you for Help</p>", "body_text": "@andrewharp I tried your cutosm inference class TFLiteObjectDetectionAPIModel.java in tensorflow/contrib/lite/examples/android , and i use it with your ssd mobilenet v1 tflite mobilenet_ssd_tflite_v1.zip but it seems i have a problem when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); ( in function recognizeImage(final Bitmap bitmap) ) . it throws this exception\n07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\n        at android.os.Handler.handleCallback(Handler.java:739)\n        at android.os.Handler.dispatchMessage(Handler.java:95)\n        at android.os.Looper.loop(Looper.java:159)\n        at android.os.HandlerThread.run(HandlerThread.java:61)\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 <bottom of call stack> \n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\n\nthe error said that the length of outputs array is bigger than the length of inputs array\nin this condition line in the Interpreter.java\npublic void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map<Integer, Object> outputs) {\n        if (this.wrapper == null) {\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\n        } else {\n            Tensor[] tensors = this.wrapper.run(inputs);\n            if (outputs != null && tensors != null && outputs.size() <= tensors.length) {\n                int size = tensors.length;\n                //...\n            }} else {\n                throw new IllegalArgumentException(\"Output error: Outputs do not match with model outputs.\");\n}\n\nThis is my inputs array :\nd.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\nd.imgData.order(ByteOrder.nativeOrder());\n//...\n imgData.rewind();\n        for (int i = 0; i < inputSize; ++i) {\n            for (int j = 0; j < inputSize; ++j) {\n                int pixelValue = intValues[i * inputSize + j];\n                if (isModelQuantized) {\n                    // Quantized model\n                    imgData.put((byte) ((pixelValue >> 16) & 0xFF));\n                    imgData.put((byte) ((pixelValue >> 8) & 0xFF));\n                    imgData.put((byte) (pixelValue & 0xFF));\n                } else { // Float model\n                    imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n                    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\n} \n\n\nObject[] inputArray = {imgData};\n\nAnd this  the outputs arrays :\n// Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        outputLocations = new float[1][NUM_DETECTIONS][4];\n        outputClasses = new float[1][NUM_DETECTIONS];\n        outputScores = new float[1][NUM_DETECTIONS];\n        numDetections = new float[1];\n//...\n        Map<Integer, Object> outputMap = new HashMap<>();\n        outputMap.put(0, outputLocations);\n        outputMap.put(1, outputScores);\n        outputMap.put(2, numDetections);\n        outputMap.put(3, outputClasses);\n        Trace.endSection();\n\nAnd the Inference :\n// Run the inference call.\n        Trace.beginSection(\"run\");\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length)); // inputArray has length of 1\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size())); // outputMap has length of 4\n\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\n        Trace.endSection();\n\nI didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .\nthank you for Help", "body": "@andrewharp I tried your cutosm inference class TFLiteObjectDetectionAPIModel.java in [tensorflow/contrib/lite/examples/android](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android) , and i use it with your ssd mobilenet v1 tflite mobilenet_ssd_tflite_v1.zip but it seems i have a problem when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); ( in function recognizeImage(final Bitmap bitmap) ) . it throws this exception\r\n\r\n```\r\n07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\r\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\r\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\r\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\r\n        at android.os.Handler.handleCallback(Handler.java:739)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:159)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 <bottom of call stack> \r\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\r\n```\r\n\r\nthe error said that the length of outputs array is bigger than the length of inputs array\r\nin this condition line in the Interpreter.java\r\n\r\n``` \r\npublic void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map<Integer, Object> outputs) {\r\n        if (this.wrapper == null) {\r\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\r\n        } else {\r\n            Tensor[] tensors = this.wrapper.run(inputs);\r\n            if (outputs != null && tensors != null && outputs.size() <= tensors.length) {\r\n                int size = tensors.length;\r\n                //...\r\n            }} else {\r\n                throw new IllegalArgumentException(\"Output error: Outputs do not match with model outputs.\");\r\n}\r\n```\r\nThis is my inputs array : \r\n\r\n```\r\nd.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\r\nd.imgData.order(ByteOrder.nativeOrder());\r\n//...\r\n imgData.rewind();\r\n        for (int i = 0; i < inputSize; ++i) {\r\n            for (int j = 0; j < inputSize; ++j) {\r\n                int pixelValue = intValues[i * inputSize + j];\r\n                if (isModelQuantized) {\r\n                    // Quantized model\r\n                    imgData.put((byte) ((pixelValue >> 16) & 0xFF));\r\n                    imgData.put((byte) ((pixelValue >> 8) & 0xFF));\r\n                    imgData.put((byte) (pixelValue & 0xFF));\r\n                } else { // Float model\r\n                    imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n                    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n                    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n} \r\n\r\n```\r\n\r\n```\r\nObject[] inputArray = {imgData};\r\n```\r\n\r\nAnd this  the outputs arrays :\r\n\r\n```\r\n// Copy the input data into TensorFlow.\r\n        Trace.beginSection(\"feed\");\r\n        outputLocations = new float[1][NUM_DETECTIONS][4];\r\n        outputClasses = new float[1][NUM_DETECTIONS];\r\n        outputScores = new float[1][NUM_DETECTIONS];\r\n        numDetections = new float[1];\r\n//...\r\n        Map<Integer, Object> outputMap = new HashMap<>();\r\n        outputMap.put(0, outputLocations);\r\n        outputMap.put(1, outputScores);\r\n        outputMap.put(2, numDetections);\r\n        outputMap.put(3, outputClasses);\r\n        Trace.endSection();\r\n```\r\n\r\nAnd the Inference :\r\n```\r\n// Run the inference call.\r\n        Trace.beginSection(\"run\");\r\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length)); // inputArray has length of 1\r\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size())); // outputMap has length of 4\r\n\r\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n        Trace.endSection();\r\n```\r\n\r\nI didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .\r\nthank you for Help\r\n"}