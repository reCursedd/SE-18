{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366372216", "html_url": "https://github.com/tensorflow/tensorflow/issues/17064#issuecomment-366372216", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17064", "id": 366372216, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjM3MjIxNg==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-16T22:06:21Z", "updated_at": "2018-02-16T22:06:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The Tensor in C++ backend is mostly used for reference counting. So your \"cheating\" code looks reasonable for what it does. I agree that wrapping it in a helper function and localize the hackiness might make the overall codebase look better.</p>\n<p>One potential problem is pointer alignment. But currently TF has very largely alignment by default, so this is not a problem.</p>\n<p>However, I agree with Josh that it might not be very performant if your kernel doesn't not use it wisely. With your example,</p>\n<p>struct A {<br>\nint a;<br>\nint b;<br>\n};</p>\n<p>And your custom kernel reads:</p>\n<p>A* v1 = ....<br>\nint a = v1-&gt;a;</p>\n<p>The reading pattern for that coalesce much worse across Cuda threads than if it is struct of arrays. So you have to be very careful. That's why most Cuda kernels in TensorFlow uses structs of arrays anyway.</p>", "body_text": "The Tensor in C++ backend is mostly used for reference counting. So your \"cheating\" code looks reasonable for what it does. I agree that wrapping it in a helper function and localize the hackiness might make the overall codebase look better.\nOne potential problem is pointer alignment. But currently TF has very largely alignment by default, so this is not a problem.\nHowever, I agree with Josh that it might not be very performant if your kernel doesn't not use it wisely. With your example,\nstruct A {\nint a;\nint b;\n};\nAnd your custom kernel reads:\nA* v1 = ....\nint a = v1->a;\nThe reading pattern for that coalesce much worse across Cuda threads than if it is struct of arrays. So you have to be very careful. That's why most Cuda kernels in TensorFlow uses structs of arrays anyway.", "body": "The Tensor in C++ backend is mostly used for reference counting. So your \"cheating\" code looks reasonable for what it does. I agree that wrapping it in a helper function and localize the hackiness might make the overall codebase look better. \r\n\r\nOne potential problem is pointer alignment. But currently TF has very largely alignment by default, so this is not a problem. \r\n\r\nHowever, I agree with Josh that it might not be very performant if your kernel doesn't not use it wisely. With your example, \r\n\r\nstruct A {\r\n    int a;\r\n    int b;\r\n};\r\n\r\nAnd your custom kernel reads: \r\n\r\nA* v1 = ....\r\nint a = v1->a; \r\n\r\nThe reading pattern for that coalesce much worse across Cuda threads than if it is struct of arrays. So you have to be very careful. That's why most Cuda kernels in TensorFlow uses structs of arrays anyway.\r\n"}