{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366330164", "html_url": "https://github.com/tensorflow/tensorflow/issues/17064#issuecomment-366330164", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17064", "id": 366330164, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjMzMDE2NA==", "user": {"login": "MiguelMonteiro", "id": 29569659, "node_id": "MDQ6VXNlcjI5NTY5NjU5", "avatar_url": "https://avatars3.githubusercontent.com/u/29569659?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MiguelMonteiro", "html_url": "https://github.com/MiguelMonteiro", "followers_url": "https://api.github.com/users/MiguelMonteiro/followers", "following_url": "https://api.github.com/users/MiguelMonteiro/following{/other_user}", "gists_url": "https://api.github.com/users/MiguelMonteiro/gists{/gist_id}", "starred_url": "https://api.github.com/users/MiguelMonteiro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MiguelMonteiro/subscriptions", "organizations_url": "https://api.github.com/users/MiguelMonteiro/orgs", "repos_url": "https://api.github.com/users/MiguelMonteiro/repos", "events_url": "https://api.github.com/users/MiguelMonteiro/events{/privacy}", "received_events_url": "https://api.github.com/users/MiguelMonteiro/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-16T19:08:58Z", "updated_at": "2018-02-16T19:08:58Z", "author_association": "NONE", "body_html": "<p>The goal is indeed to allocate memory on the device.<br>\nThe situation is when you need an array of structs. For instance, when you want to replace the following CUDA code:</p>\n<pre><code>struct A {\nint a;\nint b;\nfloat c;\n};\n\nA* a;\nint n = 10; // number of elements in the array\ncudaMalloc((void**)&amp;a, n * sizeof(A));\n</code></pre>\n<p>It's true that I could allocate three separate tensors but if the structure is more complex this quickly becomes a hassle plus I lose a lot of readability in the code the natural \"belongingness\" of things to classes/structs.</p>\n<p>In addition, using the CUDA API directly becomes a problem since Tensorflow allocates most of the GPU memory even if it is not going to use it (this is my understanding not 100% sure).</p>", "body_text": "The goal is indeed to allocate memory on the device.\nThe situation is when you need an array of structs. For instance, when you want to replace the following CUDA code:\nstruct A {\nint a;\nint b;\nfloat c;\n};\n\nA* a;\nint n = 10; // number of elements in the array\ncudaMalloc((void**)&a, n * sizeof(A));\n\nIt's true that I could allocate three separate tensors but if the structure is more complex this quickly becomes a hassle plus I lose a lot of readability in the code the natural \"belongingness\" of things to classes/structs.\nIn addition, using the CUDA API directly becomes a problem since Tensorflow allocates most of the GPU memory even if it is not going to use it (this is my understanding not 100% sure).", "body": "The goal is indeed to allocate memory on the device.\r\nThe situation is when you need an array of structs. For instance, when you want to replace the following CUDA code:\r\n```\r\nstruct A {\r\nint a;\r\nint b;\r\nfloat c;\r\n};\r\n\r\nA* a;\r\nint n = 10; // number of elements in the array\r\ncudaMalloc((void**)&a, n * sizeof(A));\r\n```\r\nIt's true that I could allocate three separate tensors but if the structure is more complex this quickly becomes a hassle plus I lose a lot of readability in the code the natural \"belongingness\" of things to classes/structs.\r\n\r\nIn addition, using the CUDA API directly becomes a problem since Tensorflow allocates most of the GPU memory even if it is not going to use it (this is my understanding not 100% sure)."}