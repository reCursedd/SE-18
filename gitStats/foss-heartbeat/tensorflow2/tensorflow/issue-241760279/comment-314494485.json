{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/314494485", "html_url": "https://github.com/tensorflow/tensorflow/issues/11411#issuecomment-314494485", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11411", "id": 314494485, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNDQ5NDQ4NQ==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-11T16:11:19Z", "updated_at": "2017-07-11T16:13:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If you are in doubt, you could try my own GPU Direct patch <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"241518747\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11392\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/11392/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/11392\">#11392</a> which is theoretically of the lowest latency. It does neither memory copy nor serialization. Btw if your computation is not that complicated, you should avoid using GPU; copying data from/to GPU adds nontrivial overhead in your communication pipeline.</p>", "body_text": "If you are in doubt, you could try my own GPU Direct patch #11392 which is theoretically of the lowest latency. It does neither memory copy nor serialization. Btw if your computation is not that complicated, you should avoid using GPU; copying data from/to GPU adds nontrivial overhead in your communication pipeline.", "body": "If you are in doubt, you could try my own GPU Direct patch #11392 which is theoretically of the lowest latency. It does neither memory copy nor serialization. Btw if your computation is not that complicated, you should avoid using GPU; copying data from/to GPU adds nontrivial overhead in your communication pipeline."}