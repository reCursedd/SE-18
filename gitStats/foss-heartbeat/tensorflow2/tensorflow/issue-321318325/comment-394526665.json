{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/394526665", "html_url": "https://github.com/tensorflow/tensorflow/issues/19159#issuecomment-394526665", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19159", "id": 394526665, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDUyNjY2NQ==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-04T22:58:21Z", "updated_at": "2018-06-04T22:58:21Z", "author_association": "MEMBER", "body_html": "<p>Re 2: The warning is just a warning -- it means that whatever you're doing on the way from the embedding lookup to the underlying variables might requires a dense gradient. If that is the case, then that may be inefficient. It does not mean that it is necessarily inefficient. You can check the graph to see whether in your case you actually instantiate a large dense gradient. We're open to changing the warning to be clearer.</p>\n<p>Re 1: We would prefer not to add a new function for this. If this is a critical use case (I am not sure it is, would deterministic, but pseudorandom sampling be enough?) then we should extend the interface of the existing method to support it.</p>", "body_text": "Re 2: The warning is just a warning -- it means that whatever you're doing on the way from the embedding lookup to the underlying variables might requires a dense gradient. If that is the case, then that may be inefficient. It does not mean that it is necessarily inefficient. You can check the graph to see whether in your case you actually instantiate a large dense gradient. We're open to changing the warning to be clearer.\nRe 1: We would prefer not to add a new function for this. If this is a critical use case (I am not sure it is, would deterministic, but pseudorandom sampling be enough?) then we should extend the interface of the existing method to support it.", "body": "Re 2: The warning is just a warning -- it means that whatever you're doing on the way from the embedding lookup to the underlying variables might requires a dense gradient. If that is the case, then that may be inefficient. It does not mean that it is necessarily inefficient. You can check the graph to see whether in your case you actually instantiate a large dense gradient. We're open to changing the warning to be clearer.\r\n\r\nRe 1: We would prefer not to add a new function for this. If this is a critical use case (I am not sure it is, would deterministic, but pseudorandom sampling be enough?) then we should extend the interface of the existing method to support it."}