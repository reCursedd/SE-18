{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233476741", "html_url": "https://github.com/tensorflow/tensorflow/pull/1665#issuecomment-233476741", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1665", "id": 233476741, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzQ3Njc0MQ==", "user": {"login": "jstaker7", "id": 1364252, "node_id": "MDQ6VXNlcjEzNjQyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1364252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jstaker7", "html_url": "https://github.com/jstaker7", "followers_url": "https://api.github.com/users/jstaker7/followers", "following_url": "https://api.github.com/users/jstaker7/following{/other_user}", "gists_url": "https://api.github.com/users/jstaker7/gists{/gist_id}", "starred_url": "https://api.github.com/users/jstaker7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jstaker7/subscriptions", "organizations_url": "https://api.github.com/users/jstaker7/orgs", "repos_url": "https://api.github.com/users/jstaker7/repos", "events_url": "https://api.github.com/users/jstaker7/events{/privacy}", "received_events_url": "https://api.github.com/users/jstaker7/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-18T22:20:24Z", "updated_at": "2016-07-18T22:24:50Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1087992\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/phvu\">@phvu</a>,</p>\n<p>Thanks very much for your work. I'm a little confused as to how this can be applied generally. For example, in the paper a 3-LSTM network was applied to image patches of the MNIST dataset where each patch is c * m units long (which is equal to the depth dimension). So we have a 3D grid of c * m vectors. But in your implementation of <code>__call__</code>, we are expecting a tensor of size batch * c * m * num_dims. For MNIST, shouldn't it support b * c * m * dim1_size * dim2_size ? This would require input_dims to be something like <code>[1, 2]</code> (where dim 0 is batch); but I don't see any tests covering cases besides input_dim=0. Am I missing something?</p>", "body_text": "Hi @phvu,\nThanks very much for your work. I'm a little confused as to how this can be applied generally. For example, in the paper a 3-LSTM network was applied to image patches of the MNIST dataset where each patch is c * m units long (which is equal to the depth dimension). So we have a 3D grid of c * m vectors. But in your implementation of __call__, we are expecting a tensor of size batch * c * m * num_dims. For MNIST, shouldn't it support b * c * m * dim1_size * dim2_size ? This would require input_dims to be something like [1, 2] (where dim 0 is batch); but I don't see any tests covering cases besides input_dim=0. Am I missing something?", "body": "Hi @phvu,\n\nThanks very much for your work. I'm a little confused as to how this can be applied generally. For example, in the paper a 3-LSTM network was applied to image patches of the MNIST dataset where each patch is c \\* m units long (which is equal to the depth dimension). So we have a 3D grid of c \\* m vectors. But in your implementation of `__call__`, we are expecting a tensor of size batch \\* c \\* m \\* num_dims. For MNIST, shouldn't it support b \\* c \\* m \\* dim1_size \\* dim2_size ? This would require input_dims to be something like `[1, 2]` (where dim 0 is batch); but I don't see any tests covering cases besides input_dim=0. Am I missing something?\n"}