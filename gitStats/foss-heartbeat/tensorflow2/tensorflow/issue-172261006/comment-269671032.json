{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269671032", "html_url": "https://github.com/tensorflow/tensorflow/issues/3937#issuecomment-269671032", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3937", "id": 269671032, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTY3MTAzMg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-29T18:22:51Z", "updated_at": "2016-12-29T18:24:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=206013\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rasmusbergpalm\">@rasmusbergpalm</a> the reason you are seeing this error is because gradient is because of how gradient of <code>pow</code> is implemented in <a href=\"https://github.com/tensorflow/tensorflow/blob/64edd34ce69b4a8033af5d217cb8894105297d8a/tensorflow/python/ops/math_grad.py#L686\">math_grad.py</a></p>\n<p>There's this line</p>\n<p><code>log_x = array_ops.where(x &gt; 0, math_ops.log(x), array_ops.zeros_like(x))</code></p>\n<p>So what happens is that <code>check_numerics</code> adds a a numeric check to both branches, so there's an infinity produced during evaluation of your graph, but presumably you don't care about it because it doesn't affect your result.</p>\n<p>Not sure there's an easy general solution here -- both branches of select are evaluated here, so if there are side-effects, then then this infinity may make its way into final result. IE, you could have control dependencies or something like this.</p>\n<p><code>log_x = array_ops.where(x &gt; 0, y.assign(math_ops.log(x)), z.assign(array_ops.zeros_like(x)))</code></p>\n<p>In this case the one branch's value is assigned to <code>log_x</code>, but the second branch is still evaluated, so z is updated and infinity there could be important.</p>\n<p>Perhaps the way to fix it would be to have a fused implementation of gradient of <code>Pow</code> op</p>", "body_text": "@rasmusbergpalm the reason you are seeing this error is because gradient is because of how gradient of pow is implemented in math_grad.py\nThere's this line\nlog_x = array_ops.where(x > 0, math_ops.log(x), array_ops.zeros_like(x))\nSo what happens is that check_numerics adds a a numeric check to both branches, so there's an infinity produced during evaluation of your graph, but presumably you don't care about it because it doesn't affect your result.\nNot sure there's an easy general solution here -- both branches of select are evaluated here, so if there are side-effects, then then this infinity may make its way into final result. IE, you could have control dependencies or something like this.\nlog_x = array_ops.where(x > 0, y.assign(math_ops.log(x)), z.assign(array_ops.zeros_like(x)))\nIn this case the one branch's value is assigned to log_x, but the second branch is still evaluated, so z is updated and infinity there could be important.\nPerhaps the way to fix it would be to have a fused implementation of gradient of Pow op", "body": "@rasmusbergpalm the reason you are seeing this error is because gradient is because of how gradient of `pow` is implemented in [math_grad.py](https://github.com/tensorflow/tensorflow/blob/64edd34ce69b4a8033af5d217cb8894105297d8a/tensorflow/python/ops/math_grad.py#L686)\r\n\r\nThere's this line\r\n\r\n`log_x = array_ops.where(x > 0, math_ops.log(x), array_ops.zeros_like(x))`\r\n\r\nSo what happens is that `check_numerics` adds a a numeric check to both branches, so there's an infinity produced during evaluation of your graph, but presumably you don't care about it because it doesn't affect your result.\r\n\r\nNot sure there's an easy general solution here -- both branches of select are evaluated here, so if there are side-effects, then then this infinity may make its way into final result. IE, you could have control dependencies or something like this.\r\n\r\n`log_x = array_ops.where(x > 0, y.assign(math_ops.log(x)), z.assign(array_ops.zeros_like(x)))`\r\n\r\nIn this case the one branch's value is assigned to `log_x`, but the second branch is still evaluated, so z is updated and infinity there could be important.\r\n\r\nPerhaps the way to fix it would be to have a fused implementation of gradient of `Pow` op"}