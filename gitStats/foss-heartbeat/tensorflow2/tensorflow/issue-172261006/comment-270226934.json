{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/270226934", "html_url": "https://github.com/tensorflow/tensorflow/issues/3937#issuecomment-270226934", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3937", "id": 270226934, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MDIyNjkzNA==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-03T21:16:19Z", "updated_at": "2017-01-03T21:16:19Z", "author_association": "MEMBER", "body_html": "<p>It's pretty hard to come up with a generic 'magically debug my big hairy numeric algorithm' solution when internally code is written to produce and mask numeric errors.  It's even harder to do this without destroying performance on GPU.</p>\n<p>At one point in distant history, I remember reading the code of an inception model which only added explicit CheckNumerics ops just before writing gradients back to the model variables (hence preventing state corruption).</p>\n<p>If somebody has spare time on their hands, here is what I would do:<br>\na) Change the <code>ApplyGradients</code> method of the <code>Optimizer</code> class to add <code>CheckNumerics</code> ops.<br>\nb) Wrap training steps in an exception handler which catches any NaN exceptions, and uses the model checkpoint code to write the equivalent of a 'core dump'.<br>\nc) Use the TF debugger code, partial evaluation or just explicit feed/fetch to reload the checkpoint and then repeatedly execute the step to examine the values of (all) intermediate tensors in the graph.</p>\n<p>This technique relies on deterministic execution, so wouldn't work if there were Queues or any other stateful ops in the graph, and would rely on feeding the same training data.</p>", "body_text": "It's pretty hard to come up with a generic 'magically debug my big hairy numeric algorithm' solution when internally code is written to produce and mask numeric errors.  It's even harder to do this without destroying performance on GPU.\nAt one point in distant history, I remember reading the code of an inception model which only added explicit CheckNumerics ops just before writing gradients back to the model variables (hence preventing state corruption).\nIf somebody has spare time on their hands, here is what I would do:\na) Change the ApplyGradients method of the Optimizer class to add CheckNumerics ops.\nb) Wrap training steps in an exception handler which catches any NaN exceptions, and uses the model checkpoint code to write the equivalent of a 'core dump'.\nc) Use the TF debugger code, partial evaluation or just explicit feed/fetch to reload the checkpoint and then repeatedly execute the step to examine the values of (all) intermediate tensors in the graph.\nThis technique relies on deterministic execution, so wouldn't work if there were Queues or any other stateful ops in the graph, and would rely on feeding the same training data.", "body": "It's pretty hard to come up with a generic 'magically debug my big hairy numeric algorithm' solution when internally code is written to produce and mask numeric errors.  It's even harder to do this without destroying performance on GPU.\r\n\r\nAt one point in distant history, I remember reading the code of an inception model which only added explicit CheckNumerics ops just before writing gradients back to the model variables (hence preventing state corruption).   \r\n\r\nIf somebody has spare time on their hands, here is what I would do:\r\na) Change the `ApplyGradients` method of the `Optimizer` class to add `CheckNumerics` ops.\r\nb) Wrap training steps in an exception handler which catches any NaN exceptions, and uses the model checkpoint code to write the equivalent of a 'core dump'. \r\nc) Use the TF debugger code, partial evaluation or just explicit feed/fetch to reload the checkpoint and then repeatedly execute the step to examine the values of (all) intermediate tensors in the graph.\r\n\r\nThis technique relies on deterministic execution, so wouldn't work if there were Queues or any other stateful ops in the graph, and would rely on feeding the same training data.\r\n"}