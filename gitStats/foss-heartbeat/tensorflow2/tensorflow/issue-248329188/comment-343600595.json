{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/343600595", "html_url": "https://github.com/tensorflow/tensorflow/issues/12071#issuecomment-343600595", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12071", "id": 343600595, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MzYwMDU5NQ==", "user": {"login": "shashankneocfc", "id": 9520969, "node_id": "MDQ6VXNlcjk1MjA5Njk=", "avatar_url": "https://avatars3.githubusercontent.com/u/9520969?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashankneocfc", "html_url": "https://github.com/shashankneocfc", "followers_url": "https://api.github.com/users/shashankneocfc/followers", "following_url": "https://api.github.com/users/shashankneocfc/following{/other_user}", "gists_url": "https://api.github.com/users/shashankneocfc/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashankneocfc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashankneocfc/subscriptions", "organizations_url": "https://api.github.com/users/shashankneocfc/orgs", "repos_url": "https://api.github.com/users/shashankneocfc/repos", "events_url": "https://api.github.com/users/shashankneocfc/events{/privacy}", "received_events_url": "https://api.github.com/users/shashankneocfc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-10T22:10:31Z", "updated_at": "2017-11-10T22:14:10Z", "author_association": "NONE", "body_html": "<p>+1 I'm also facing this issue while computing eucledian norm for the paper :  <a href=\"https://arxiv.org/abs/1703.03130\" rel=\"nofollow\">A Structured Self-attentive Sentence Embedding</a></p>\n<p>Edit : Pytorch applied a fix for it. May be tf can do the same <a href=\"https://github.com/pytorch/pytorch/pull/2775/files\">https://github.com/pytorch/pytorch/pull/2775/files</a></p>", "body_text": "+1 I'm also facing this issue while computing eucledian norm for the paper :  A Structured Self-attentive Sentence Embedding\nEdit : Pytorch applied a fix for it. May be tf can do the same https://github.com/pytorch/pytorch/pull/2775/files", "body": "+1 I'm also facing this issue while computing eucledian norm for the paper :  [A Structured Self-attentive Sentence Embedding](https://arxiv.org/abs/1703.03130)\r\n\r\nEdit : Pytorch applied a fix for it. May be tf can do the same https://github.com/pytorch/pytorch/pull/2775/files"}