{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422947372", "html_url": "https://github.com/tensorflow/tensorflow/issues/12071#issuecomment-422947372", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12071", "id": 422947372, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjk0NzM3Mg==", "user": {"login": "gsutanto", "id": 7176092, "node_id": "MDQ6VXNlcjcxNzYwOTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/7176092?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gsutanto", "html_url": "https://github.com/gsutanto", "followers_url": "https://api.github.com/users/gsutanto/followers", "following_url": "https://api.github.com/users/gsutanto/following{/other_user}", "gists_url": "https://api.github.com/users/gsutanto/gists{/gist_id}", "starred_url": "https://api.github.com/users/gsutanto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gsutanto/subscriptions", "organizations_url": "https://api.github.com/users/gsutanto/orgs", "repos_url": "https://api.github.com/users/gsutanto/repos", "events_url": "https://api.github.com/users/gsutanto/events{/privacy}", "received_events_url": "https://api.github.com/users/gsutanto/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T20:30:04Z", "updated_at": "2018-09-19T20:36:00Z", "author_association": "NONE", "body_html": "<p>Hi, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6918743\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dust0x\">@dust0x</a> if you work on a batch of data, it would be something like:</p>\n<pre><code>from tensorflow.python.framework import function\nimport numpy as np\nimport tensorflow as tf\n\n@function.Defun(tf.float32, tf.float32)\ndef norm_grad(x, dy):\n    return dy*(x/(tf.norm(x, ord=2)+1.0e-19))\n\n@function.Defun(tf.float32, grad_func=norm_grad)\ndef norm(x):\n    return tf.norm(x, ord=2)\n\ndef norm_axis1(X):\n    return tf.map_fn(lambda x: norm(x), X)\n\nX = tf.placeholder(tf.float32, shape=(4,3))\nZ = norm_axis1(X)\nvar_grad = tf.gradients(Z, [X])\nnorm_var_grad = norm_axis1(var_grad[0])\n\nwith tf.Session() as sess:\n    X_ = np.array([\n        [0,0,0],\n        [1.,1.,1.],\n        [0.,0.,0.],\n        [2.,2.,2.]\n    ], dtype=np.float32)\n    \n    [Z_val, Z_grad, norm_Z_grad] = sess.run([Z, var_grad, norm_var_grad], feed_dict={X: X_})\n    \n    print \"Z_val = \", Z_val\n    print \"Z_grad = \", Z_grad\n    print \"norm_Z_grad = \", norm_Z_grad\n</code></pre>\n<p>(say if X_ were NxM=4x3; each row is a feature vector of size 3 that you would like to compute norm() on, and there are N=4 samples; there might be a better way to do this, if anyone knows, please post your code here; in terms of TensorFlow, I believe it will automatically use the newly defined norm gradient in any cost functions you are using it; please let me know if my understanding is incorrect...)</p>", "body_text": "Hi, @dust0x if you work on a batch of data, it would be something like:\nfrom tensorflow.python.framework import function\nimport numpy as np\nimport tensorflow as tf\n\n@function.Defun(tf.float32, tf.float32)\ndef norm_grad(x, dy):\n    return dy*(x/(tf.norm(x, ord=2)+1.0e-19))\n\n@function.Defun(tf.float32, grad_func=norm_grad)\ndef norm(x):\n    return tf.norm(x, ord=2)\n\ndef norm_axis1(X):\n    return tf.map_fn(lambda x: norm(x), X)\n\nX = tf.placeholder(tf.float32, shape=(4,3))\nZ = norm_axis1(X)\nvar_grad = tf.gradients(Z, [X])\nnorm_var_grad = norm_axis1(var_grad[0])\n\nwith tf.Session() as sess:\n    X_ = np.array([\n        [0,0,0],\n        [1.,1.,1.],\n        [0.,0.,0.],\n        [2.,2.,2.]\n    ], dtype=np.float32)\n    \n    [Z_val, Z_grad, norm_Z_grad] = sess.run([Z, var_grad, norm_var_grad], feed_dict={X: X_})\n    \n    print \"Z_val = \", Z_val\n    print \"Z_grad = \", Z_grad\n    print \"norm_Z_grad = \", norm_Z_grad\n\n(say if X_ were NxM=4x3; each row is a feature vector of size 3 that you would like to compute norm() on, and there are N=4 samples; there might be a better way to do this, if anyone knows, please post your code here; in terms of TensorFlow, I believe it will automatically use the newly defined norm gradient in any cost functions you are using it; please let me know if my understanding is incorrect...)", "body": "Hi, @dust0x if you work on a batch of data, it would be something like:\r\n```\r\nfrom tensorflow.python.framework import function\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@function.Defun(tf.float32, tf.float32)\r\ndef norm_grad(x, dy):\r\n    return dy*(x/(tf.norm(x, ord=2)+1.0e-19))\r\n\r\n@function.Defun(tf.float32, grad_func=norm_grad)\r\ndef norm(x):\r\n    return tf.norm(x, ord=2)\r\n\r\ndef norm_axis1(X):\r\n    return tf.map_fn(lambda x: norm(x), X)\r\n\r\nX = tf.placeholder(tf.float32, shape=(4,3))\r\nZ = norm_axis1(X)\r\nvar_grad = tf.gradients(Z, [X])\r\nnorm_var_grad = norm_axis1(var_grad[0])\r\n\r\nwith tf.Session() as sess:\r\n    X_ = np.array([\r\n        [0,0,0],\r\n        [1.,1.,1.],\r\n        [0.,0.,0.],\r\n        [2.,2.,2.]\r\n    ], dtype=np.float32)\r\n    \r\n    [Z_val, Z_grad, norm_Z_grad] = sess.run([Z, var_grad, norm_var_grad], feed_dict={X: X_})\r\n    \r\n    print \"Z_val = \", Z_val\r\n    print \"Z_grad = \", Z_grad\r\n    print \"norm_Z_grad = \", norm_Z_grad\r\n```\r\n(say if X_ were NxM=4x3; each row is a feature vector of size 3 that you would like to compute norm() on, and there are N=4 samples; there might be a better way to do this, if anyone knows, please post your code here; in terms of TensorFlow, I believe it will automatically use the newly defined norm gradient in any cost functions you are using it; please let me know if my understanding is incorrect...)"}