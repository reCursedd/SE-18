{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/423071771", "html_url": "https://github.com/tensorflow/tensorflow/issues/12071#issuecomment-423071771", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12071", "id": 423071771, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzA3MTc3MQ==", "user": {"login": "dust0x", "id": 6918743, "node_id": "MDQ6VXNlcjY5MTg3NDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6918743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dust0x", "html_url": "https://github.com/dust0x", "followers_url": "https://api.github.com/users/dust0x/followers", "following_url": "https://api.github.com/users/dust0x/following{/other_user}", "gists_url": "https://api.github.com/users/dust0x/gists{/gist_id}", "starred_url": "https://api.github.com/users/dust0x/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dust0x/subscriptions", "organizations_url": "https://api.github.com/users/dust0x/orgs", "repos_url": "https://api.github.com/users/dust0x/repos", "events_url": "https://api.github.com/users/dust0x/events{/privacy}", "received_events_url": "https://api.github.com/users/dust0x/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-20T07:29:43Z", "updated_at": "2018-09-20T07:29:43Z", "author_association": "NONE", "body_html": "<p>Thanks again, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7176092\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gsutanto\">@gsutanto</a>. Luckily for me, the input to the norm only needs to be fed once in my case and so I don't (yet) have to worry about batch computations. The way I am currently solving this is by simply calling the forced gradient of norm in the same session as the optimizer and if what you say is correct \u2014 nothing seems to have broken so far, so it must be \u2014 this should work just fine.</p>", "body_text": "Thanks again, @gsutanto. Luckily for me, the input to the norm only needs to be fed once in my case and so I don't (yet) have to worry about batch computations. The way I am currently solving this is by simply calling the forced gradient of norm in the same session as the optimizer and if what you say is correct \u2014 nothing seems to have broken so far, so it must be \u2014 this should work just fine.", "body": "Thanks again, @gsutanto. Luckily for me, the input to the norm only needs to be fed once in my case and so I don't (yet) have to worry about batch computations. The way I am currently solving this is by simply calling the forced gradient of norm in the same session as the optimizer and if what you say is correct \u2014 nothing seems to have broken so far, so it must be \u2014 this should work just fine.\r\n"}