{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10401", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10401/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10401/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10401/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/10401", "id": 233245447, "node_id": "MDExOlB1bGxSZXF1ZXN0MTIzNzYxNjU3", "number": 10401, "title": "Fix unbatch for Datasets with multiple elements", "user": {"login": "drasmuss", "id": 1952220, "node_id": "MDQ6VXNlcjE5NTIyMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1952220?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drasmuss", "html_url": "https://github.com/drasmuss", "followers_url": "https://api.github.com/users/drasmuss/followers", "following_url": "https://api.github.com/users/drasmuss/following{/other_user}", "gists_url": "https://api.github.com/users/drasmuss/gists{/gist_id}", "starred_url": "https://api.github.com/users/drasmuss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drasmuss/subscriptions", "organizations_url": "https://api.github.com/users/drasmuss/orgs", "repos_url": "https://api.github.com/users/drasmuss/repos", "events_url": "https://api.github.com/users/drasmuss/events{/privacy}", "received_events_url": "https://api.github.com/users/drasmuss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2017-06-02T17:11:33Z", "updated_at": "2017-06-06T23:56:31Z", "closed_at": "2017-06-06T23:56:31Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10401", "html_url": "https://github.com/tensorflow/tensorflow/pull/10401", "diff_url": "https://github.com/tensorflow/tensorflow/pull/10401.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/10401.patch"}, "body_html": "<p>The current implementation of <code>Dataset.unbatch</code> gives an error for datasets with multiple data elements, e.g.</p>\n<div class=\"highlight highlight-source-python\"><pre>data <span class=\"pl-k\">=</span> [tf.range(<span class=\"pl-c1\">10</span>) <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>)]\ndata <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(data)\ndata <span class=\"pl-k\">=</span> data.batch(<span class=\"pl-c1\">2</span>)\ndata <span class=\"pl-k\">=</span> data.unbatch()</pre></div>\n<p>the <code>data.unbatch()</code> call gives error</p>\n<pre><code>TypeError: from_tensor_slices() takes 1 positional argument but 3 were given\n</code></pre>\n<p>This is because <code>unbatch</code> tries to call <code>map</code> with <code>Dataset.from_tensor_slices</code> as the function.  The map function is expected to take multiple arguments as input, where each argument is one part of the data structure.  However, <code>Dataset.from_tensor_slices</code> expects the whole data structure to be passed as the first argument.</p>\n<p>This fix changes <code>unbatch</code> so that <code>Datset.from_tensor_slices</code> is called correctly.</p>\n<p>However, this does have one undesirable consequence, which is that datasets without structure are converted to lists of length one, e.g.</p>\n<div class=\"highlight highlight-source-python\"><pre>data <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">10</span>)\ndata0 <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.from_tensor_slices(data)\n<span class=\"pl-c1\">print</span>(data0.output_shapes)\ndata1 <span class=\"pl-k\">=</span> data0.batch(<span class=\"pl-c1\">2</span>)\ndata2 <span class=\"pl-k\">=</span> data1.unbatch()\n<span class=\"pl-c1\">print</span>(data2.output_shapes)</pre></div>\n<p>Ideally we'd expect <code>data0</code> to be equivalent to <code>data2</code>.  But <code>data0</code> will produce scalars, and <code>data2</code> will produce elements with shape <code>(1,)</code>.</p>\n<p>I don't think there's any way around this, because there is no way within the <code>map</code> function to tell if the function was called with a single element as input, or a list with length one.  Both will just appear as a single argument to the <code>map</code> function.</p>\n<p>So a more thorough fix might require changing how <code>Dataset.map</code> works, but in the meantime this behaviour seemed the best option.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> might be able to comment on whether that larger change would be worthwhile (or if he sees a better fix for this issue).</p>", "body_text": "The current implementation of Dataset.unbatch gives an error for datasets with multiple data elements, e.g.\ndata = [tf.range(10) for _ in range(3)]\ndata = tf.contrib.data.Dataset.from_tensor_slices(data)\ndata = data.batch(2)\ndata = data.unbatch()\nthe data.unbatch() call gives error\nTypeError: from_tensor_slices() takes 1 positional argument but 3 were given\n\nThis is because unbatch tries to call map with Dataset.from_tensor_slices as the function.  The map function is expected to take multiple arguments as input, where each argument is one part of the data structure.  However, Dataset.from_tensor_slices expects the whole data structure to be passed as the first argument.\nThis fix changes unbatch so that Datset.from_tensor_slices is called correctly.\nHowever, this does have one undesirable consequence, which is that datasets without structure are converted to lists of length one, e.g.\ndata = tf.range(10)\ndata0 = tf.contrib.data.Dataset.from_tensor_slices(data)\nprint(data0.output_shapes)\ndata1 = data0.batch(2)\ndata2 = data1.unbatch()\nprint(data2.output_shapes)\nIdeally we'd expect data0 to be equivalent to data2.  But data0 will produce scalars, and data2 will produce elements with shape (1,).\nI don't think there's any way around this, because there is no way within the map function to tell if the function was called with a single element as input, or a list with length one.  Both will just appear as a single argument to the map function.\nSo a more thorough fix might require changing how Dataset.map works, but in the meantime this behaviour seemed the best option.  @mrry might be able to comment on whether that larger change would be worthwhile (or if he sees a better fix for this issue).", "body": "The current implementation of `Dataset.unbatch` gives an error for datasets with multiple data elements, e.g.\r\n\r\n``` python\r\ndata = [tf.range(10) for _ in range(3)]\r\ndata = tf.contrib.data.Dataset.from_tensor_slices(data)\r\ndata = data.batch(2)\r\ndata = data.unbatch()\r\n```\r\nthe `data.unbatch()` call gives error\r\n```\r\nTypeError: from_tensor_slices() takes 1 positional argument but 3 were given\r\n```\r\n\r\nThis is because `unbatch` tries to call `map` with `Dataset.from_tensor_slices` as the function.  The map function is expected to take multiple arguments as input, where each argument is one part of the data structure.  However, `Dataset.from_tensor_slices` expects the whole data structure to be passed as the first argument.\r\n\r\nThis fix changes `unbatch` so that `Datset.from_tensor_slices` is called correctly.\r\n\r\nHowever, this does have one undesirable consequence, which is that datasets without structure are converted to lists of length one, e.g.\r\n```python \r\ndata = tf.range(10)\r\ndata0 = tf.contrib.data.Dataset.from_tensor_slices(data)\r\nprint(data0.output_shapes)\r\ndata1 = data0.batch(2)\r\ndata2 = data1.unbatch()\r\nprint(data2.output_shapes)\r\n```\r\nIdeally we'd expect `data0` to be equivalent to `data2`.  But `data0` will produce scalars, and `data2` will produce elements with shape `(1,)`.\r\n\r\nI don't think there's any way around this, because there is no way within the `map` function to tell if the function was called with a single element as input, or a list with length one.  Both will just appear as a single argument to the `map` function.\r\n\r\nSo a more thorough fix might require changing how `Dataset.map` works, but in the meantime this behaviour seemed the best option.  @mrry might be able to comment on whether that larger change would be worthwhile (or if he sees a better fix for this issue)."}