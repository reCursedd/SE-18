{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7542", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7542/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7542/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7542/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7542", "id": 207940753, "node_id": "MDU6SXNzdWUyMDc5NDA3NTM=", "number": 7542, "title": "./configure in interactive mode does not create working config for build", "user": {"login": "dchirikov", "id": 6017800, "node_id": "MDQ6VXNlcjYwMTc4MDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6017800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dchirikov", "html_url": "https://github.com/dchirikov", "followers_url": "https://api.github.com/users/dchirikov/followers", "following_url": "https://api.github.com/users/dchirikov/following{/other_user}", "gists_url": "https://api.github.com/users/dchirikov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dchirikov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dchirikov/subscriptions", "organizations_url": "https://api.github.com/users/dchirikov/orgs", "repos_url": "https://api.github.com/users/dchirikov/repos", "events_url": "https://api.github.com/users/dchirikov/events{/privacy}", "received_events_url": "https://api.github.com/users/dchirikov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, {"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 30, "created_at": "2017-02-15T21:55:49Z", "updated_at": "2017-04-03T20:58:54Z", "closed_at": "2017-04-03T20:58:54Z", "author_association": "NONE", "body_html": "<h1>Description</h1>\n<p>Hi,<br>\nI encounter following issue. If user runs ./configure script interactively filling blanks it is not possible to build TF with CUDA support. BUT if user exports corresponding env variables before of after ./configure, bazel can happily build binaries.</p>\n<h1>Environment</h1>\n<pre><code>$ cat /etc/redhat-release \nCentOS Linux release 7.3.1611 (AltArch)\n\n$ uname -a\nLinux power004.cluster 3.10.0-514.6.1.el7.ppc64le #1 SMP Thu Jan 19 14:34:54 GMT 2017 ppc64le ppc64le ppc64le GNU/Linux\n\n$ ls -l /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcud*\n-rw-r--r-- 1 root root 559800 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root     19 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.54\n-rwxr-xr-x 1 root root 476024 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0.54\n-rw-r--r-- 1 root root 966166 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart_static.a\n\n$ git rev-parse HEAD\n16485a3fb5ffcbaa244e55c388e43279d2770982\n\n$ bazel version\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nBuild label: 0.4.4- (@non-git)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Feb 9 23:48:24 2017 (1486684104)\nBuild timestamp: 1486684104\nBuild timestamp as int: 1486684104\n</code></pre>\n<h1>Steps to reproduce</h1>\n<pre><code>$ git clone https://github.com/tensorflow/tensorflow.git\n$ cd tensorflow\n$ git checkout r1.0\n$ export TEST_TMPDIR=/local/cvsupport\n$ ./configure\n</code></pre>\n<p>Fill blanks</p>\n<pre><code>Please specify the location of python. [Default is /bin/python]: /usr/bin/python3.4\nPlease specify optimization flags to use during compilation [Default is -march=native]: -march=native\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \njemalloc enabled on Linux\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/lib/python3.4/site-packages\n  /usr/lib64/python3.4/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.4/site-packages]\n/usr/lib64/python3.4/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]: /usr/bin/gcc\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.10\nPlease specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0]: /trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.0\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n..............\nINFO: All external dependencies fetched successfully.\nConfiguration finished\n</code></pre>\n<p>Attempt to build:</p>\n<pre><code>$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\n                error_gpu_disabled()\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\n                fail(\"ERROR: Building with --config=c...\")\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\nINFO: Elapsed time: 1.572s\n</code></pre>\n<h1>Working method</h1>\n<pre><code>$ cat ../build_vars.sh \nexport TEST_TMPDIR=/local/cvsupport\nexport PYTHON_BIN_PATH=/usr/bin/python3.4\nexport PYTHON_LIB_PATH=/usr/lib64/python3.4/site-packages\nexport TF_NEED_JEMALLOC=1\nexport TF_NEED_GCP=0\nexport TF_NEED_HDFS=0\nexport TF_NEED_OPENCL=0\nexport TF_NEED_CUDA=1\nexport TF_ENABLE_XLA=0\nexport CC_OPT_FLAGS=\"-march=native\"\nexport TF_CUDA_VERSION=8.0\nexport TF_CUDNN_VERSION=5.1.10\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc\nexport CUDA_TOOLKIT_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/${TF_CUDA_VERSION}\nexport CUDNN_INSTALL_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/${TF_CUDA_VERSION}\n\n$ source ../build_vars.sh\n$ ./configure\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<p>Experimenting with omitting different variables seems like only following vars are sufficient.<br>\n<code>TF_NEED_CUDA</code>, <code>TF_CUDA_VERSION</code>, <code>CUDA_TOOLKIT_PATH</code>, <code>CUDNN_INSTALL_PATH</code>, <code>GCC_HOST_COMPILER_PATH</code></p>", "body_text": "Description\nHi,\nI encounter following issue. If user runs ./configure script interactively filling blanks it is not possible to build TF with CUDA support. BUT if user exports corresponding env variables before of after ./configure, bazel can happily build binaries.\nEnvironment\n$ cat /etc/redhat-release \nCentOS Linux release 7.3.1611 (AltArch)\n\n$ uname -a\nLinux power004.cluster 3.10.0-514.6.1.el7.ppc64le #1 SMP Thu Jan 19 14:34:54 GMT 2017 ppc64le ppc64le ppc64le GNU/Linux\n\n$ ls -l /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcud*\n-rw-r--r-- 1 root root 559800 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root     19 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.54\n-rwxr-xr-x 1 root root 476024 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0.54\n-rw-r--r-- 1 root root 966166 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart_static.a\n\n$ git rev-parse HEAD\n16485a3fb5ffcbaa244e55c388e43279d2770982\n\n$ bazel version\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nBuild label: 0.4.4- (@non-git)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Feb 9 23:48:24 2017 (1486684104)\nBuild timestamp: 1486684104\nBuild timestamp as int: 1486684104\n\nSteps to reproduce\n$ git clone https://github.com/tensorflow/tensorflow.git\n$ cd tensorflow\n$ git checkout r1.0\n$ export TEST_TMPDIR=/local/cvsupport\n$ ./configure\n\nFill blanks\nPlease specify the location of python. [Default is /bin/python]: /usr/bin/python3.4\nPlease specify optimization flags to use during compilation [Default is -march=native]: -march=native\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \njemalloc enabled on Linux\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \nNo XLA support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/lib/python3.4/site-packages\n  /usr/lib64/python3.4/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.4/site-packages]\n/usr/lib64/python3.4/site-packages\nDo you wish to build TensorFlow with OpenCL support? [y/N] \nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]: /usr/bin/gcc\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.10\nPlease specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0]: /trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: 6.0\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n..............\nINFO: All external dependencies fetched successfully.\nConfiguration finished\n\nAttempt to build:\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\n................\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\n                error_gpu_disabled()\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\n                fail(\"ERROR: Building with --config=c...\")\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\nINFO: Elapsed time: 1.572s\n\nWorking method\n$ cat ../build_vars.sh \nexport TEST_TMPDIR=/local/cvsupport\nexport PYTHON_BIN_PATH=/usr/bin/python3.4\nexport PYTHON_LIB_PATH=/usr/lib64/python3.4/site-packages\nexport TF_NEED_JEMALLOC=1\nexport TF_NEED_GCP=0\nexport TF_NEED_HDFS=0\nexport TF_NEED_OPENCL=0\nexport TF_NEED_CUDA=1\nexport TF_ENABLE_XLA=0\nexport CC_OPT_FLAGS=\"-march=native\"\nexport TF_CUDA_VERSION=8.0\nexport TF_CUDNN_VERSION=5.1.10\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc\nexport CUDA_TOOLKIT_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/${TF_CUDA_VERSION}\nexport CUDNN_INSTALL_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/${TF_CUDA_VERSION}\n\n$ source ../build_vars.sh\n$ ./configure\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nExperimenting with omitting different variables seems like only following vars are sufficient.\nTF_NEED_CUDA, TF_CUDA_VERSION, CUDA_TOOLKIT_PATH, CUDNN_INSTALL_PATH, GCC_HOST_COMPILER_PATH", "body": "# Description\r\nHi,\r\nI encounter following issue. If user runs ./configure script interactively filling blanks it is not possible to build TF with CUDA support. BUT if user exports corresponding env variables before of after ./configure, bazel can happily build binaries.\r\n\r\n# Environment\r\n```\r\n$ cat /etc/redhat-release \r\nCentOS Linux release 7.3.1611 (AltArch)\r\n\r\n$ uname -a\r\nLinux power004.cluster 3.10.0-514.6.1.el7.ppc64le #1 SMP Thu Jan 19 14:34:54 GMT 2017 ppc64le ppc64le ppc64le GNU/Linux\r\n\r\n$ ls -l /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root 559800 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.54\r\n-rwxr-xr-x 1 root root 476024 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0.54\r\n-rw-r--r-- 1 root root 966166 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart_static.a\r\n\r\n$ git rev-parse HEAD\r\n16485a3fb5ffcbaa244e55c388e43279d2770982\r\n\r\n$ bazel version\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nBuild label: 0.4.4- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 9 23:48:24 2017 (1486684104)\r\nBuild timestamp: 1486684104\r\nBuild timestamp as int: 1486684104\r\n```\r\n\r\n# Steps to reproduce\r\n```\r\n$ git clone https://github.com/tensorflow/tensorflow.git\r\n$ cd tensorflow\r\n$ git checkout r1.0\r\n$ export TEST_TMPDIR=/local/cvsupport\r\n$ ./configure\r\n```\r\nFill blanks\r\n```\r\nPlease specify the location of python. [Default is /bin/python]: /usr/bin/python3.4\r\nPlease specify optimization flags to use during compilation [Default is -march=native]: -march=native\r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \r\njemalloc enabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/lib/python3.4/site-packages\r\n  /usr/lib64/python3.4/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.4/site-packages]\r\n/usr/lib64/python3.4/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]: /usr/bin/gcc\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.10\r\nPlease specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0]: /trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.0\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n..............\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n```\r\nAttempt to build:\r\n```\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 1.572s\r\n```\r\n\r\n# Working method\r\n```\r\n$ cat ../build_vars.sh \r\nexport TEST_TMPDIR=/local/cvsupport\r\nexport PYTHON_BIN_PATH=/usr/bin/python3.4\r\nexport PYTHON_LIB_PATH=/usr/lib64/python3.4/site-packages\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_CUDA=1\r\nexport TF_ENABLE_XLA=0\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\nexport TF_CUDA_VERSION=8.0\r\nexport TF_CUDNN_VERSION=5.1.10\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\r\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc\r\nexport CUDA_TOOLKIT_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/${TF_CUDA_VERSION}\r\nexport CUDNN_INSTALL_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/${TF_CUDA_VERSION}\r\n\r\n$ source ../build_vars.sh\r\n$ ./configure\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nExperimenting with omitting different variables seems like only following vars are sufficient.\r\n`TF_NEED_CUDA`, `TF_CUDA_VERSION`, `CUDA_TOOLKIT_PATH`, `CUDNN_INSTALL_PATH`, `GCC_HOST_COMPILER_PATH`"}