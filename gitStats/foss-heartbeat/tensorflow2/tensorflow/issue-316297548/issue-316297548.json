{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18735", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18735/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18735/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18735/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18735", "id": 316297548, "node_id": "MDU6SXNzdWUzMTYyOTc1NDg=", "number": 18735, "title": "tensorflow/core/framework/allocator.cc:101] Allocation of X exceeds 10% of system memory.", "user": {"login": "augustosds3", "id": 12502292, "node_id": "MDQ6VXNlcjEyNTAyMjky", "avatar_url": "https://avatars2.githubusercontent.com/u/12502292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/augustosds3", "html_url": "https://github.com/augustosds3", "followers_url": "https://api.github.com/users/augustosds3/followers", "following_url": "https://api.github.com/users/augustosds3/following{/other_user}", "gists_url": "https://api.github.com/users/augustosds3/gists{/gist_id}", "starred_url": "https://api.github.com/users/augustosds3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/augustosds3/subscriptions", "organizations_url": "https://api.github.com/users/augustosds3/orgs", "repos_url": "https://api.github.com/users/augustosds3/repos", "events_url": "https://api.github.com/users/augustosds3/events{/privacy}", "received_events_url": "https://api.github.com/users/augustosds3/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-04-20T14:47:55Z", "updated_at": "2018-04-20T14:48:47Z", "closed_at": "2018-04-20T14:48:47Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0</li>\n<li><strong>Python version</strong>: Python 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: no</li>\n<li><strong>GPU model and memory</strong>: no</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>My server has 32gb of RAM, but tensorflow uses only 10% of that memory.<br>\nIt returns the message:<br>\n&lt;&lt;tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.&gt;&gt;</p>\n<p>Is it possible to increase this percentage?</p>\n<h3>Source code / logs</h3>\n<h3>SOURCE CODE:</h3>\n<p>import keras<br>\nfrom keras import regularizers<br>\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, add<br>\nfrom keras.models import Model<br>\nfrom keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape<br>\nfrom keras.regularizers import l2<br>\nfrom keras.utils import np_utils<br>\nfrom keras.callbacks import TensorBoard<br>\nfrom sklearn.model_selection import train_test_split<br>\nimport numpy as np<br>\nimport h5py<br>\nimport time</p>\n<p>file_train = 'features/files_train_test/train_inceptionv3_doc2vec.npy'<br>\nfile_test = 'features/files_train_test/test_inceptionv3_doc2vec.npy'<br>\nx_train = np.load(file_train)<br>\nx_test = np.load(file_test)</p>\n<p>print('shape train: ',x_train.shape,'shape test: ', x_test.shape)<br>\nprint('size train: ', len(x_train), 'size test: ', len(x_test))<br>\nprint('prod train: ',np.prod(x_train.shape[1:]), 'prod test: ', np.prod(x_test.shape[1:]))</p>\n<p>x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))<br>\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</p>\n<p>print('shape train: ',x_train.shape,'shape test: ', x_test.shape)</p>\n<p>epochs = 10<br>\nbatch_size = 32<br>\ninput_size = x_train.shape[1]<br>\noutput_size = x_train.shape[1]<br>\nhidden_size = x_train.shape[1]<br>\nfile_name = 'features/files_reduce/sparse/autoencoder_inceptionv3_doc2vec_'</p>\n<p>x = Input(shape=(input_size,))<br>\nh = Dense(hidden_size, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)<br>\nr = Dense(output_size, activation='sigmoid')(h)<br>\nautoencoder = Model(inputs=x, outputs=r)<br>\nautoencoder.compile(optimizer='adam', loss='mse')<br>\nautoencoder.summary()<br>\nautoencoder.fit(x_train<br>\n,x_train<br>\n,batch_size=batch_size<br>\n,epochs=epochs<br>\n,verbose=1<br>\n,validation_data=(x_test, x_test))</p>\n<p>autoencoder.save(file_name+name_full)<br>\nprint('Save encode' + file_name+name_full)</p>\n<p>===============================================================================<br>\nOUTPUT:</p>\n<p>Using TensorFlow backend.<br>\nshape train:  (21248, 49452) shape test:  (5313, 49452)<br>\nsize train:  21248 size test:  5313<br>\nprod train:  49452 prod test:  49452<br>\nshape train:  (21248, 49452) shape test:  (5313, 49452)</p>\n<p>Layer (type)                      | Output Shape              | Param</p>\n<hr>\n<p>input_1 (InputLayer)         | (None, 49452)             | 0<br>\ndense_1 (Dense)              | (None, 49452)             | 2445549756<br>\ndense_2 (Dense)              | (None, 49452)             | 2445549756</p>\n<hr>\n<p>Total params: 4,891,099,512<br>\nTrainable params: 4,891,099,512<br>\nNon-trainable params: 0</p>\n<p>Train on 21248 samples, validate on 5313 samples<br>\nEpoch 1/10<br>\n2018-04-20 11:22:08.069764: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.<br>\n2018-04-20 11:22:12.089390: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.7.0\nPython version: Python 3.5.2\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: no\nGPU model and memory: no\nExact command to reproduce:\n\nDescribe the problem\nMy server has 32gb of RAM, but tensorflow uses only 10% of that memory.\nIt returns the message:\n<<tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.>>\nIs it possible to increase this percentage?\nSource code / logs\nSOURCE CODE:\nimport keras\nfrom keras import regularizers\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, add\nfrom keras.models import Model\nfrom keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape\nfrom keras.regularizers import l2\nfrom keras.utils import np_utils\nfrom keras.callbacks import TensorBoard\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport h5py\nimport time\nfile_train = 'features/files_train_test/train_inceptionv3_doc2vec.npy'\nfile_test = 'features/files_train_test/test_inceptionv3_doc2vec.npy'\nx_train = np.load(file_train)\nx_test = np.load(file_test)\nprint('shape train: ',x_train.shape,'shape test: ', x_test.shape)\nprint('size train: ', len(x_train), 'size test: ', len(x_test))\nprint('prod train: ',np.prod(x_train.shape[1:]), 'prod test: ', np.prod(x_test.shape[1:]))\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint('shape train: ',x_train.shape,'shape test: ', x_test.shape)\nepochs = 10\nbatch_size = 32\ninput_size = x_train.shape[1]\noutput_size = x_train.shape[1]\nhidden_size = x_train.shape[1]\nfile_name = 'features/files_reduce/sparse/autoencoder_inceptionv3_doc2vec_'\nx = Input(shape=(input_size,))\nh = Dense(hidden_size, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)\nr = Dense(output_size, activation='sigmoid')(h)\nautoencoder = Model(inputs=x, outputs=r)\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.summary()\nautoencoder.fit(x_train\n,x_train\n,batch_size=batch_size\n,epochs=epochs\n,verbose=1\n,validation_data=(x_test, x_test))\nautoencoder.save(file_name+name_full)\nprint('Save encode' + file_name+name_full)\n===============================================================================\nOUTPUT:\nUsing TensorFlow backend.\nshape train:  (21248, 49452) shape test:  (5313, 49452)\nsize train:  21248 size test:  5313\nprod train:  49452 prod test:  49452\nshape train:  (21248, 49452) shape test:  (5313, 49452)\nLayer (type)                      | Output Shape              | Param\n\ninput_1 (InputLayer)         | (None, 49452)             | 0\ndense_1 (Dense)              | (None, 49452)             | 2445549756\ndense_2 (Dense)              | (None, 49452)             | 2445549756\n\nTotal params: 4,891,099,512\nTrainable params: 4,891,099,512\nNon-trainable params: 0\nTrain on 21248 samples, validate on 5313 samples\nEpoch 1/10\n2018-04-20 11:22:08.069764: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.\n2018-04-20 11:22:12.089390: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nMy server has 32gb of RAM, but tensorflow uses only 10% of that memory.\r\nIt returns the message:\r\n<<tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.>>\r\n\r\nIs it possible to increase this percentage?\r\n\r\n### Source code / logs\r\n### SOURCE CODE:\r\nimport keras\r\nfrom keras import regularizers\r\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, add\r\nfrom keras.models import Model\r\nfrom keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape\r\nfrom keras.regularizers import l2\r\nfrom keras.utils import np_utils\r\nfrom keras.callbacks import TensorBoard\r\nfrom sklearn.model_selection import train_test_split\r\nimport numpy as np\r\nimport h5py\r\nimport time\r\n\r\nfile_train = 'features/files_train_test/train_inceptionv3_doc2vec.npy'\r\nfile_test = 'features/files_train_test/test_inceptionv3_doc2vec.npy'\r\nx_train = np.load(file_train)\r\nx_test = np.load(file_test)\r\n\r\nprint('shape train: ',x_train.shape,'shape test: ', x_test.shape)\r\nprint('size train: ', len(x_train), 'size test: ', len(x_test))\r\nprint('prod train: ',np.prod(x_train.shape[1:]), 'prod test: ', np.prod(x_test.shape[1:]))\r\n\r\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\r\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\r\n\r\nprint('shape train: ',x_train.shape,'shape test: ', x_test.shape)\r\n\r\nepochs = 10\r\nbatch_size = 32\r\ninput_size = x_train.shape[1]\r\noutput_size = x_train.shape[1]\r\nhidden_size = x_train.shape[1]\r\nfile_name = 'features/files_reduce/sparse/autoencoder_inceptionv3_doc2vec_'\r\n\r\nx = Input(shape=(input_size,))\r\nh = Dense(hidden_size, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)\r\nr = Dense(output_size, activation='sigmoid')(h)\r\nautoencoder = Model(inputs=x, outputs=r)\r\nautoencoder.compile(optimizer='adam', loss='mse')\r\nautoencoder.summary()\r\nautoencoder.fit(x_train\r\n                ,x_train\r\n                ,batch_size=batch_size\r\n                ,epochs=epochs\r\n                ,verbose=1\r\n                ,validation_data=(x_test, x_test))\r\n\r\nautoencoder.save(file_name+name_full)\r\nprint('Save encode' + file_name+name_full)\r\n\r\n===============================================================================\r\nOUTPUT: \r\n\r\nUsing TensorFlow backend.\r\nshape train:  (21248, 49452) shape test:  (5313, 49452)\r\nsize train:  21248 size test:  5313\r\nprod train:  49452 prod test:  49452\r\nshape train:  (21248, 49452) shape test:  (5313, 49452)\r\n\r\nLayer (type)                      | Output Shape              | Param    \r\n- - - - - - - - - - - - - - - -  - - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - -\r\ninput_1 (InputLayer)         | (None, 49452)             | 0         \r\ndense_1 (Dense)              | (None, 49452)             | 2445549756\r\ndense_2 (Dense)              | (None, 49452)             | 2445549756\r\n- - - - - - - - - - - - - - - -  - - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - -\r\n\r\nTotal params: 4,891,099,512\r\nTrainable params: 4,891,099,512\r\nNon-trainable params: 0\r\n\r\nTrain on 21248 samples, validate on 5313 samples\r\nEpoch 1/10\r\n2018-04-20 11:22:08.069764: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.\r\n2018-04-20 11:22:12.089390: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory."}