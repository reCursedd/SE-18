{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164340493", "html_url": "https://github.com/tensorflow/tensorflow/issues/387#issuecomment-164340493", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/387", "id": 164340493, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDM0MDQ5Mw==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-14T04:32:57Z", "updated_at": "2015-12-14T04:32:57Z", "author_association": "MEMBER", "body_html": "<p>A lot of the functionality of tensorflow is written in python, and will<br>\nmigrate only slowly down to C++.</p>\n<p>The GraphDef proto should only change slowly (and with the best guarantees<br>\nfor compatibility), so writing protos directly will require the least<br>\nvelocity of change to keep things working. If your main goal is to run<br>\nexisting graphs from R (that's unlikely to be the case, but that's the<br>\nsituation for node.js or Java where the main focus is on running<br>\npre-trained models), then this would be sufficient.</p>\n<p>On the other hand, the API will be significantly less powerful if you cut<br>\naway the python layer entirely. Mainly this is because the gradients and<br>\nshape inference layers are written in python, but also some ops are python<br>\nfunctions that combine kernels into more complex ops (image_ops is a good<br>\nexample). This makes <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115896656\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3\">#3</a> look much better than it otherwise would, even<br>\nthough the API is changing faster than the GraphDef is.</p>\n<p>On Sun, Dec 13, 2015 at 4:27 AM JJ Allaire <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> <a href=\"https://github.com/girving\">https://github.com/girving</a> Interested in your guidance on the<br>\nvarious ways to pursue R bindings. Read your comment here providing the lay<br>\nof the land for Rust (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"119750224\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/388\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/388/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/388\">#388</a> (comment)<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"119750224\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/388\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/388/hovercard?comment_id=161019498&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/388#issuecomment-161019498\">#388 (comment)</a>).<br>\nWe obviously can pursue SWIG bindings to the existing C++ classes and then<br>\npickup additional functionality from the C++ layer once more of the<br>\nfeatures from the python layer are moved there.</p>\n<p>However, we're most interested in creating idiomatic bindings for R and to<br>\nget this exactly right are in no way deterred by the fact that it may take<br>\na lot of effort (much of which is duplicated). I can think of a few ways to<br>\napproach creating these bindings:</p>\n<ol>\n<li></li>\n</ol>\n<p>Create a wrapper for sessions / invocation using the C API then create<br>\nthe graph definition bindings by going directly to proto. This possibility<br>\nseems to be anticipated/encouraged here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor_c_api.h#L55-L59\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor_c_api.h#L55-L59</a><br>\n2.</p>\n<p>Call the C++ layer via SWIG bindings.<br>\n3.</p>\n<p>Call python directly from R using e.g. boost::python or pybind11.<br>\nAssuming that NumPy arrays can be marshaled to from R arrays with no<br>\ncopying I'm assuming this would have no performance problems since the<br>\npython code is just defining a graph.</p>\n<p>To me the first option has the greatest appeal because there would be no<br>\nimpedance problems associated with translating idiomatic R into graphs,<br>\nwe'd just figure out the right syntax and express it as a graph definition<br>\nrather than contorting it through the C++ layer. The comment above seems to<br>\nimply that this would be an effective path, but I haven't spent enough time<br>\nlooking to know whether this would be a monumental amount of work that<br>\nwould be constantly challenged to keep up or just something to grind<br>\nthrough once (not deterred at all by having to spend on the order of<br>\nhundreds of hours in the initial effort). I also like the idea of using the<br>\nC API because those entry points could be loaded dynamically, meaning that<br>\nthe R bindings could be built separately and made available on CRAN and<br>\ncould work with any installed version of TensorFlow.</p>\n<p>We could also combine the creation of proto-based idiomatic R bindings<br>\nwith another binding that parrots the python API. This would allow R users<br>\nto easily translate and use python or C++ API based examples but at the<br>\nsame time have a first class R binding that makes maximum sense to R users.</p>\n<p>Your thoughts and feedback very much appreciated!</p>\n<p>\u2014<br>\nReply to this email directly or view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"119730326\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/387\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/387/hovercard?comment_id=164253513&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/387#issuecomment-164253513\">#387 (comment)</a><br>\n.</p>\n</blockquote>", "body_text": "A lot of the functionality of tensorflow is written in python, and will\nmigrate only slowly down to C++.\nThe GraphDef proto should only change slowly (and with the best guarantees\nfor compatibility), so writing protos directly will require the least\nvelocity of change to keep things working. If your main goal is to run\nexisting graphs from R (that's unlikely to be the case, but that's the\nsituation for node.js or Java where the main focus is on running\npre-trained models), then this would be sufficient.\nOn the other hand, the API will be significantly less powerful if you cut\naway the python layer entirely. Mainly this is because the gradients and\nshape inference layers are written in python, but also some ops are python\nfunctions that combine kernels into more complex ops (image_ops is a good\nexample). This makes #3 look much better than it otherwise would, even\nthough the API is changing faster than the GraphDef is.\nOn Sun, Dec 13, 2015 at 4:27 AM JJ Allaire notifications@github.com wrote:\n\n@girving https://github.com/girving Interested in your guidance on the\nvarious ways to pursue R bindings. Read your comment here providing the lay\nof the land for Rust (#388 (comment)\n#388 (comment)).\nWe obviously can pursue SWIG bindings to the existing C++ classes and then\npickup additional functionality from the C++ layer once more of the\nfeatures from the python layer are moved there.\nHowever, we're most interested in creating idiomatic bindings for R and to\nget this exactly right are in no way deterred by the fact that it may take\na lot of effort (much of which is duplicated). I can think of a few ways to\napproach creating these bindings:\n\n\n\nCreate a wrapper for sessions / invocation using the C API then create\nthe graph definition bindings by going directly to proto. This possibility\nseems to be anticipated/encouraged here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor_c_api.h#L55-L59\n2.\nCall the C++ layer via SWIG bindings.\n3.\nCall python directly from R using e.g. boost::python or pybind11.\nAssuming that NumPy arrays can be marshaled to from R arrays with no\ncopying I'm assuming this would have no performance problems since the\npython code is just defining a graph.\nTo me the first option has the greatest appeal because there would be no\nimpedance problems associated with translating idiomatic R into graphs,\nwe'd just figure out the right syntax and express it as a graph definition\nrather than contorting it through the C++ layer. The comment above seems to\nimply that this would be an effective path, but I haven't spent enough time\nlooking to know whether this would be a monumental amount of work that\nwould be constantly challenged to keep up or just something to grind\nthrough once (not deterred at all by having to spend on the order of\nhundreds of hours in the initial effort). I also like the idea of using the\nC API because those entry points could be loaded dynamically, meaning that\nthe R bindings could be built separately and made available on CRAN and\ncould work with any installed version of TensorFlow.\nWe could also combine the creation of proto-based idiomatic R bindings\nwith another binding that parrots the python API. This would allow R users\nto easily translate and use python or C++ API based examples but at the\nsame time have a first class R binding that makes maximum sense to R users.\nYour thoughts and feedback very much appreciated!\n\u2014\nReply to this email directly or view it on GitHub\n#387 (comment)\n.", "body": "A lot of the functionality of tensorflow is written in python, and will\nmigrate only slowly down to C++.\n\nThe GraphDef proto should only change slowly (and with the best guarantees\nfor compatibility), so writing protos directly will require the least\nvelocity of change to keep things working. If your main goal is to run\nexisting graphs from R (that's unlikely to be the case, but that's the\nsituation for node.js or Java where the main focus is on running\npre-trained models), then this would be sufficient.\n\nOn the other hand, the API will be significantly less powerful if you cut\naway the python layer entirely. Mainly this is because the gradients and\nshape inference layers are written in python, but also some ops are python\nfunctions that combine kernels into more complex ops (image_ops is a good\nexample). This makes #3 look much better than it otherwise would, even\nthough the API is changing faster than the GraphDef is.\n\nOn Sun, Dec 13, 2015 at 4:27 AM JJ Allaire notifications@github.com wrote:\n\n> @girving https://github.com/girving Interested in your guidance on the\n> various ways to pursue R bindings. Read your comment here providing the lay\n> of the land for Rust (#388 (comment)\n> https://github.com/tensorflow/tensorflow/issues/388#issuecomment-161019498).\n> We obviously can pursue SWIG bindings to the existing C++ classes and then\n> pickup additional functionality from the C++ layer once more of the\n> features from the python layer are moved there.\n> \n> However, we're most interested in creating idiomatic bindings for R and to\n> get this exactly right are in no way deterred by the fact that it may take\n> a lot of effort (much of which is duplicated). I can think of a few ways to\n> approach creating these bindings:\n> \n>    1.\n> \n>    Create a wrapper for sessions / invocation using the C API then create\n>    the graph definition bindings by going directly to proto. This possibility\n>    seems to be anticipated/encouraged here:\n>    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor_c_api.h#L55-L59\n>    2.\n> \n>    Call the C++ layer via SWIG bindings.\n>    3.\n> \n>    Call python directly from R using e.g. boost::python or pybind11.\n>    Assuming that NumPy arrays can be marshaled to from R arrays with no\n>    copying I'm assuming this would have no performance problems since the\n>    python code is just defining a graph.\n> \n> To me the first option has the greatest appeal because there would be no\n> impedance problems associated with translating idiomatic R into graphs,\n> we'd just figure out the right syntax and express it as a graph definition\n> rather than contorting it through the C++ layer. The comment above seems to\n> imply that this would be an effective path, but I haven't spent enough time\n> looking to know whether this would be a monumental amount of work that\n> would be constantly challenged to keep up or just something to grind\n> through once (not deterred at all by having to spend on the order of\n> hundreds of hours in the initial effort). I also like the idea of using the\n> C API because those entry points could be loaded dynamically, meaning that\n> the R bindings could be built separately and made available on CRAN and\n> could work with any installed version of TensorFlow.\n> \n> We could also combine the creation of proto-based idiomatic R bindings\n> with another binding that parrots the python API. This would allow R users\n> to easily translate and use python or C++ API based examples but at the\n> same time have a first class R binding that makes maximum sense to R users.\n> \n> Your thoughts and feedback very much appreciated!\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/387#issuecomment-164253513\n> .\n"}