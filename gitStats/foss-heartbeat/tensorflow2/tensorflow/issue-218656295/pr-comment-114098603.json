{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114098603", "pull_request_review_id": 35539606, "id": 114098603, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNDA5ODYwMw==", "diff_hunk": "@@ -1859,3 +1859,115 @@ def __call__(self, inputs, state, scope=None):\n       new_state = core_rnn_cell.LSTMStateTuple(new_c, new_h)\n \n       return new_h, new_state\n+\n+class BasicConvLSTMCell(core_rnn_cell.RNNCell):\n+  \"\"\"Basic Convolutional LSTM recurrent network cell.\n+\n+  https://arxiv.org/pdf/1506.04214v1.pdf\n+  \"\"\"\n+\n+  def __init__(self,\n+               shape,\n+               filter_size,\n+               num_features,\n+               forget_bias=1.0,\n+               activation=math_ops.tanh,\n+               reuse=None):\n+    \"\"\"Initialize the basic Conv LSTM cell.\n+    Args:\n+      shape: int tuple thats the height and width of the cell\n+      filter_size: int tuple thats the height and width of the filter\n+      num_features: int thats the depth of the cell \n+      forget_bias: float, The bias added to forget gates (see above).\n+      input_size: Deprecated and unused.\n+      state_is_tuple: If True, accepted and returned states are 2-tuples of\n+        the `c_state` and `m_state`.  If False, they are concatenated\n+        along the column axis.  The latter behavior will soon be deprecated.\n+      activation: Activation function of the inner states.\n+    \"\"\"\n+    self._shape = shape \n+    self._filter_size = filter_size\n+    self._num_features = num_features \n+    self._forget_bias = forget_bias\n+    self._reuse = reuse\n+    self._activation = activation\n+\n+  @property\n+  def state_size(self):\n+    return core_rnn_cell.LSTMStateTuple(self._shape, self._shape)\n+\n+  @property\n+  def output_size(self):\n+    return self._shape\n+\n+  def zero_state(self, batch_size, dtype):\n+    shape = self._shape \n+    num_features = self._num_features\n+    zero_c = array_ops.zeros([batch_size, shape[0], shape[1], num_features], dtype=dtype)\n+    zero_h = array_ops.zeros([batch_size, shape[0], shape[1], num_features], dtype=dtype)\n+    zero_state = core_rnn_cell.LSTMStateTuple(zero_c, zero_h)\n+    return zero_state\n+\n+  def __call__(self, inputs, state, scope=None):\n+    \"\"\"Long short-term memory cell (LSTM).\"\"\"\n+    with vs.variable_scope(scope or \"conv_lstm_cell\", reuse=self._reuse):  # \"BasicLSTMCell\"\n+      # Parameters of gates are concatenated into one multiply for efficiency.\n+      (c, h) = state\n+\n+      concat = _conv_linear([inputs, h], self._filter_size, self._num_features * 4, True)", "path": "tensorflow/contrib/rnn/python/ops/rnn_cell.py", "position": null, "original_position": 59, "commit_id": "a884a920d776b48310a79cf82fa7813fe24451df", "original_commit_id": "3e99f7440f86bfd5536cededb298d7e768439497", "user": {"login": "loliverhennigh", "id": 4978408, "node_id": "MDQ6VXNlcjQ5Nzg0MDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/4978408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loliverhennigh", "html_url": "https://github.com/loliverhennigh", "followers_url": "https://api.github.com/users/loliverhennigh/followers", "following_url": "https://api.github.com/users/loliverhennigh/following{/other_user}", "gists_url": "https://api.github.com/users/loliverhennigh/gists{/gist_id}", "starred_url": "https://api.github.com/users/loliverhennigh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loliverhennigh/subscriptions", "organizations_url": "https://api.github.com/users/loliverhennigh/orgs", "repos_url": "https://api.github.com/users/loliverhennigh/repos", "events_url": "https://api.github.com/users/loliverhennigh/events{/privacy}", "received_events_url": "https://api.github.com/users/loliverhennigh/received_events", "type": "User", "site_admin": false}, "body": "I do not believe this is a issue. The gates will still be created. In the tensorflow/contrib/rnn/python/kernel_tests/rnn_cell_test.py test I wrote, the filter size is set to 1 with no issues", "created_at": "2017-05-01T04:57:31Z", "updated_at": "2017-08-07T15:19:17Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8891#discussion_r114098603", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8891", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/114098603"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8891#discussion_r114098603"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8891"}}, "body_html": "<p>I do not believe this is a issue. The gates will still be created. In the tensorflow/contrib/rnn/python/kernel_tests/rnn_cell_test.py test I wrote, the filter size is set to 1 with no issues</p>", "body_text": "I do not believe this is a issue. The gates will still be created. In the tensorflow/contrib/rnn/python/kernel_tests/rnn_cell_test.py test I wrote, the filter size is set to 1 with no issues", "in_reply_to_id": 110925057}