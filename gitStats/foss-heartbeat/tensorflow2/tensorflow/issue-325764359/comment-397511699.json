{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397511699", "html_url": "https://github.com/tensorflow/tensorflow/issues/19501#issuecomment-397511699", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19501", "id": 397511699, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzUxMTY5OQ==", "user": {"login": "anj-s", "id": 32556631, "node_id": "MDQ6VXNlcjMyNTU2NjMx", "avatar_url": "https://avatars1.githubusercontent.com/u/32556631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anj-s", "html_url": "https://github.com/anj-s", "followers_url": "https://api.github.com/users/anj-s/followers", "following_url": "https://api.github.com/users/anj-s/following{/other_user}", "gists_url": "https://api.github.com/users/anj-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/anj-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anj-s/subscriptions", "organizations_url": "https://api.github.com/users/anj-s/orgs", "repos_url": "https://api.github.com/users/anj-s/repos", "events_url": "https://api.github.com/users/anj-s/events{/privacy}", "received_events_url": "https://api.github.com/users/anj-s/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-15T04:41:51Z", "updated_at": "2018-06-15T04:41:51Z", "author_association": "MEMBER", "body_html": "<p>If you want to run your model across multiple machines you need to use Estimator's train_and_evaluate API.  train_and_evaluate uses a between graph async parameter server approach.</p>\n<p>If you want to train your model across multiple GPUs you can use the new <a href=\"https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/distribute/DistributionStrategy\" rel=\"nofollow\">DistributionStrategy APIs</a>. Use model_to_estimator to convert your keras model to an estimator instance and use train as you have above.</p>", "body_text": "If you want to run your model across multiple machines you need to use Estimator's train_and_evaluate API.  train_and_evaluate uses a between graph async parameter server approach.\nIf you want to train your model across multiple GPUs you can use the new DistributionStrategy APIs. Use model_to_estimator to convert your keras model to an estimator instance and use train as you have above.", "body": "If you want to run your model across multiple machines you need to use Estimator's train_and_evaluate API.  train_and_evaluate uses a between graph async parameter server approach.\r\n\r\nIf you want to train your model across multiple GPUs you can use the new [DistributionStrategy APIs](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/distribute/DistributionStrategy). Use model_to_estimator to convert your keras model to an estimator instance and use train as you have above. "}