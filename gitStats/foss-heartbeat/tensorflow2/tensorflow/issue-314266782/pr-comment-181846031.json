{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181846031", "pull_request_review_id": 112526748, "id": 181846031, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTg0NjAzMQ==", "diff_hunk": "@@ -0,0 +1,179 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Script to test TF-TensorRT integration.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import numpy as np\n+import warnings\n+\n+from tensorflow.contrib import tensorrt as trt\n+from tensorflow.core.protobuf import config_pb2 as cpb2\n+from tensorflow.python.client import session as csess\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.framework import constant_op as cop\n+from tensorflow.python.framework import dtypes as dtypes\n+from tensorflow.python.framework import importer as importer\n+from tensorflow.python.framework import ops as ops\n+from tensorflow.python.ops import array_ops as aops\n+from tensorflow.python.ops import nn as nn\n+from tensorflow.python.ops import nn_ops as nn_ops\n+from tensorflow.python.platform import googletest\n+from tensorflow.python.platform import test\n+\n+\n+@test_util.with_c_api\n+class IntegrationTest(test_util.TensorFlowTestCase):\n+\n+  def setUp(self):\n+    \"\"\" Setup method \"\"\"\n+    super(IntegrationTest, self).setUp()\n+    warnings.simplefilter('always')\n+    inp_dims = (100, 24, 24, 2)\n+    self._input = np.random.random_sample(inp_dims)\n+    self._original_graph = self.get_simple_graph_def()\n+    self._gpu_options = cpb2.GPUOptions(\n+        per_process_gpu_memory_fraction=0.50)\n+    self._config = cpb2.ConfigProto(gpu_options=self._gpu_options)\n+    self._reference = self.run_graph(self._original_graph, self._input)\n+\n+  def get_simple_graph_def(self):\n+    \"\"\"Create a simple graph and return its graph_def.\"\"\"\n+    g = ops.Graph()\n+    with g.as_default():\n+      a = aops.placeholder(\n+          dtype=dtypes.float32, shape=(None, 24, 24, 2), name=\"input\")\n+      e = cop.constant(\n+          [[[[1., 0.5, 4., 6., 0.5, 1.], [1., 0.5, 1., 1., 0.5, 1.]]]],\n+          name=\"weights\",\n+          dtype=dtypes.float32)\n+      conv = nn.conv2d(\n+          input=a,\n+          filter=e,\n+          strides=[1, 2, 2, 1],\n+          padding=\"SAME\",\n+          name=\"conv\")\n+      b = cop.constant(\n+          [4., 1.5, 2., 3., 5., 7.], name=\"bias\", dtype=dtypes.float32)\n+      t = nn.bias_add(conv, b, name=\"biasAdd\")\n+      relu = nn.relu(t, \"relu\")\n+      idty = aops.identity(relu, \"ID\")\n+      v = nn_ops.max_pool(\n+          idty, [1, 2, 2, 1], [1, 2, 2, 1], \"VALID\", name=\"max_pool\")\n+      aops.squeeze(v, name=\"output\")\n+    return g.as_graph_def()\n+\n+  def run_graph(self, gdef, dumm_inp):\n+    \"\"\"Run given graphdef once.\"\"\"\n+    ops.reset_default_graph()\n+    g = ops.Graph()\n+    with g.as_default():\n+      inp, out = importer.import_graph_def(\n+          graph_def=gdef, return_elements=[\"input\", \"output\"])\n+      inp = inp.outputs[0]\n+      out = out.outputs[0]\n+    with self.test_session(\n+        graph=g, config=self._config, use_gpu=True,\n+        force_gpu=True) as sess:\n+      val = sess.run(out, {inp: dumm_inp})\n+    return val\n+\n+  # Use real data that is representative of the inference dataset\n+  # for calibration. For this test script it is random data.\n+  def run_calibration(self, gdef, dumm_inp):\n+    \"\"\"Run given calibration graph multiple times.\"\"\"\n+    ops.reset_default_graph()\n+    g = ops.Graph()\n+    with g.as_default():\n+      inp, out = importer.import_graph_def(\n+          graph_def=gdef, return_elements=[\"input\", \"output\"])\n+      inp = inp.outputs[0]\n+      out = out.outputs[0]\n+      # run over real calibration data here, we are mimicking a calibration set of\n+      # 30 different batches. Use as much calibration data as you want\n+    with self.test_session(\n+        graph=g, config=self._config, use_gpu=True,\n+        force_gpu=True) as sess:\n+      for _ in range(30):\n+        val = sess.run(out, {inp: dumm_inp})\n+    return val\n+\n+  def get_trt_graph(self, mode):\n+    \"\"\"  return trt converted graph \"\"\"\n+    if mode == \"FP32\":\n+      return trt.create_inference_graph(\n+          input_graph_def=self._original_graph,\n+          outputs=[\"output\"],\n+          max_batch_size=self._input.shape[0],\n+          max_workspace_size_bytes=1 << 25,\n+          precision_mode=\n+          \"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n+          minimum_segment_size=2  # minimum number of nodes in an engine\n+          )\n+    elif mode == \"FP16\":\n+      return trt.create_inference_graph(\n+          input_graph_def=self._original_graph,\n+          outputs=[\"output\"],\n+          max_batch_size=self._input.shape[0],\n+          max_workspace_size_bytes=1 << 25,\n+          precision_mode=\n+          \"FP16\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n+          minimum_segment_size=2  # minimum number of nodes in an engine\n+          )\n+    elif mode == \"INT8\":\n+      return trt.create_inference_graph(\n+          input_graph_def=self._original_graph,\n+          outputs=[\"output\"],\n+          max_batch_size=self._input.shape[0],\n+          max_workspace_size_bytes=1 << 25,\n+          precision_mode=\n+          \"INT8\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\n+          minimum_segment_size=2  # minimum number of nodes in an engine\n+          )\n+\n+    return None\n+\n+  def testFP32(self):\n+    \"\"\" Test FP32 conversion. Results should be identical to native case \"\"\"\n+    trt_graph = self.get_trt_graph(\"FP32\")\n+    result = self.run_graph(trt_graph, self._input)\n+    self.assertAllEqual(self._reference, result)\n+    result1 = self.run_graph(trt_graph, self._input)\n+    self.assertAllEqual(result1, result)\n+\n+  def testFP16(self):\n+    \"\"\" Test FP16 conversion. Results may be different from native case \"\"\"\n+    trt_graph = self.get_trt_graph(\"FP16\")\n+    result = self.run_graph(trt_graph, self._input)\n+    self.assertAllClose(self._reference, result,rtol=1.e-03)", "path": "tensorflow/contrib/tensorrt/test/test_integration.py", "position": null, "original_position": 162, "commit_id": "35e1198ffcaf1724da7f8cad545edaa4cd02b4ae", "original_commit_id": "9fb54c30efdcf38ef83c2709a8619a5bf20f2434", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "nit: add an space before `rtol=xx`. Please run the formatter to fix all potential linter errors.", "created_at": "2018-04-16T18:45:44Z", "updated_at": "2018-04-17T23:34:33Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18509#discussion_r181846031", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18509", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/181846031"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18509#discussion_r181846031"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18509"}}, "body_html": "<p>nit: add an space before <code>rtol=xx</code>. Please run the formatter to fix all potential linter errors.</p>", "body_text": "nit: add an space before rtol=xx. Please run the formatter to fix all potential linter errors."}