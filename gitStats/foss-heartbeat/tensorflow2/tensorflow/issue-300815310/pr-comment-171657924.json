{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171657924", "pull_request_review_id": 100499654, "id": 171657924, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTY1NzkyNA==", "diff_hunk": "@@ -0,0 +1,167 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/contrib/tensorrt/kernels/trt_calib_op.h\"\n+#include \"tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.h\"\n+#include \"tensorflow/contrib/tensorrt/resources/trt_resource_manager.h\"\n+#include \"tensorflow/contrib/tensorrt/resources/trt_resources.h\"\n+#include \"tensorflow/core/framework/node_def.pb.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+\n+#if GOOGLE_CUDA\n+#if GOOGLE_TENSORRT\n+#include \"cuda_runtime_api.h\"\n+#include \"tensorrt/include/NvInfer.h\"\n+\n+namespace tensorflow {\n+namespace trt {\n+TRTCalibOp::TRTCalibOp(OpKernelConstruction* context) : OpKernel(context) {\n+  OP_REQUIRES_OK(context, context->GetAttr(\"segment_nodes\", &segment_nodes_));\n+  OP_REQUIRES_OK(context, context->GetAttr(\"input_names\", &input_names_));\n+  OP_REQUIRES_OK(context, context->GetAttr(\"resource_name\", &resource_name_));\n+};\n+\n+void TRTCalibOp::Compute(tensorflow::OpKernelContext* ctx) {\n+  auto trt_rm = tensorflow::trt::TRTResourceManager::instance();\n+  auto res_mgr = trt_rm->getManager(\"TRTCalibOps\");\n+  tensorflow::trt::TRTCalibrationResource* calib_res = nullptr;\n+  auto status = res_mgr->Lookup(resource_name_, resource_name_, &calib_res);\n+\n+  if (!status.ok()) {\n+    ctx->SetStatus(status);\n+    return;\n+  }\n+  int num_inputs = ctx->num_inputs();\n+  // first run instantiate calibrator\n+  if (calib_res->calibrator_ == nullptr) {\n+    dev_tensors_.resize(num_inputs);\n+    int batch_size = ctx->input(0).dim_size(0);\n+    VLOG(1) << \" Constructing calibrator\";\n+    for (int i = 0; i < num_inputs; i++) {\n+      // allocate workspace on device for inputs\n+      const tensorflow::Tensor& t = ctx->input(i);\n+      OP_REQUIRES_OK(ctx,\n+                     ctx->allocate_persistent(t.dtype(), t.shape(),\n+                                              &dev_tensors_.at(i), nullptr));\n+      const auto device_tensor = dev_tensors_.at(i).AccessTensor(ctx);\n+      CHECK_EQ(t.TotalBytes(), device_tensor->TotalBytes());\n+      void* device_address = nullptr;\n+      {\n+        auto tensor_type = device_tensor->dtype();\n+        switch (tensor_type) {\n+          case tensorflow::DT_FLOAT: {\n+            device_address = (void*)device_tensor\n+                                 ->flat<tensorflow::EnumToDataType<\n+                                     tensorflow::DT_FLOAT>::Type>()\n+                                 .data();", "path": "tensorflow/contrib/tensorrt/kernels/trt_calib_op.cc", "position": null, "original_position": 71, "commit_id": "5e5671e692db0533dfec66d63b8e7c8d06bc4942", "original_commit_id": "feb6a619d29f1760f1b46408181c0ded2055677c", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Actually Tensor are contiguous, and flat() is used to return the pointer to the underlying buffer. What I was saying is that [TensorProto::tensor_content](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor.proto#L36) is not contiguous internally (although it is externally) so we need to copy it out. Sorry for the confusion.", "created_at": "2018-03-01T18:55:47Z", "updated_at": "2018-03-01T22:59:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171657924", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171657924"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171657924"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309"}}, "body_html": "<p>Actually Tensor are contiguous, and flat() is used to return the pointer to the underlying buffer. What I was saying is that <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor.proto#L36\">TensorProto::tensor_content</a> is not contiguous internally (although it is externally) so we need to copy it out. Sorry for the confusion.</p>", "body_text": "Actually Tensor are contiguous, and flat() is used to return the pointer to the underlying buffer. What I was saying is that TensorProto::tensor_content is not contiguous internally (although it is externally) so we need to copy it out. Sorry for the confusion.", "in_reply_to_id": 171611265}