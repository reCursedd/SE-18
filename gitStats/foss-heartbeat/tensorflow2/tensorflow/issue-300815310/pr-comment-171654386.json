{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171654386", "pull_request_review_id": 100499654, "id": 171654386, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTY1NDM4Ng==", "diff_hunk": "@@ -0,0 +1,112 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.h\"\n+\n+#include <atomic>\n+#include <chrono>\n+#include <unordered_map>\n+\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+#if GOOGLE_CUDA\n+#if GOOGLE_TENSORRT\n+#include \"cuda_runtime_api.h\"\n+\n+namespace tensorflow {\n+namespace trt {\n+\n+// set the batch size before constructing the thread to execute engine\n+int TRTInt8Calibrator::getBatchSize() const { return batch_size_; }\n+\n+TRTInt8Calibrator::TRTInt8Calibrator(\n+    const std::unordered_map<string, std::pair<void*, size_t>>& dev_buffers,\n+    int batch_size, string engine_name)\n+    : batch_size_(batch_size),\n+      done_(false),\n+      dev_buffers_(dev_buffers),\n+      calib_running_(false),\n+      engine_name_(engine_name) {}\n+\n+bool TRTInt8Calibrator::setBatch(\n+    const std::unordered_map<string, void*>& data) {\n+  if (done_) return false;\n+  while (calib_running_.load(\n+      std::memory_order_acquire)) {  // wait while calibration is running\n+    tensorflow::mutex_lock l(cond_mtx_);\n+    cond_.wait_for(l, std::chrono::milliseconds(50));", "path": "tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.cc", "position": 54, "original_position": 49, "commit_id": "5e5671e692db0533dfec66d63b8e7c8d06bc4942", "original_commit_id": "75873b4baca1b6220e857cde5cd95e08c522793b", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Will this become obsolete in future PRs? If not, I think there are a few improvements we can make to make the logic clear, less error-prone, and easier to maintain in the future:\r\n\r\n1. we only need a wait() in setBatch\r\n2. the mutex_lock should be outside of the loop, as otherwise the logic is identical (as safe as) without the mutex (see below)\r\n3. done_ needs to be protected by the mutex\r\n4. we should not miss the first batch, even though this may be statistically ok, but it's functionally incorrect. I think we can use this condition_variable to fix that.\r\n\r\nMy another argument is that using atomic words (aka lock-free) instead of mutex is error-prone and make the code harder to maintain. I think the current approach is identical to the code snippet below which doesn't use mutex/condition-var:\r\n```\r\nconstructor() {\r\n  calib_running_ = false;\r\n  done_ = false;\r\n}\r\nsetBatch() {\r\n  if (done_) return false;\r\n  while (calib_running_.load(acquire)) {\r\n    sleep(50ms);\r\n    if (done_) return false;\r\n  }\r\n  // set the batch\r\n  calib_running_.store(true, release);\r\n}\r\ngetBatch() {\r\n  calib_running_.store(false, release);\r\n  while (!calib_running_.load(acquire)) {\r\n    sleep(50ms);\r\n    if (done_) return false;\r\n  }\r\n  if (done_) return false;\r\n  // get the batch\r\n}\r\nsetDone() {\r\n  done_ = true;\r\n}\r\n```\r\nI think we can fix all the issues mentioned above by doing:\r\n```\r\nconstructor() {\r\n  // All these variables are protected by the same mutex.\r\n  batch_is_set_ = false;\r\n  calib_running_ = false;\r\n  done_ = false;\r\n}\r\nsetBatch() {\r\n  mutex_lock l(cond_mtx_);\r\n  while ((calib_running_ || batch_is_set_) && !done_) {\r\n    cond_.wait(l);\r\n  }\r\n  if (done_) return false;\r\n  CHECK(!calib_running_ && !batch_is_set_);\r\n  // set the batch\r\n  batch_is_set_ = true;\r\n  cond_.notify_all();\r\n}\r\ngetBatch() {\r\n  mutex_lock l(cond_mtx_);\r\n  calib_running_ = false;\r\n  cond_.notify_all();  // Set the batch if !batch_is_set_\r\n  while (!batch_is_set_ && !done_) {\r\n    cond_.wait(l);\r\n  }\r\n  if (done_) return false;\r\n  CHECK(!calib_running_ && batch_is_set_);\r\n  // get the batch\r\n  batch_is_set_ = false;\r\n  calib_running_ = true;\r\n}\r\nsetDone() {\r\n  mutex_lock l(cond_mtx_);\r\n  done_ = true;\r\n  cond_.notify_all();\r\n}\r\n```\r\nPlease take a look @samikama. Thanks :)", "created_at": "2018-03-01T18:44:31Z", "updated_at": "2018-03-01T22:59:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171654386", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171654386"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171654386"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309"}}, "body_html": "<p>Will this become obsolete in future PRs? If not, I think there are a few improvements we can make to make the logic clear, less error-prone, and easier to maintain in the future:</p>\n<ol>\n<li>we only need a wait() in setBatch</li>\n<li>the mutex_lock should be outside of the loop, as otherwise the logic is identical (as safe as) without the mutex (see below)</li>\n<li>done_ needs to be protected by the mutex</li>\n<li>we should not miss the first batch, even though this may be statistically ok, but it's functionally incorrect. I think we can use this condition_variable to fix that.</li>\n</ol>\n<p>My another argument is that using atomic words (aka lock-free) instead of mutex is error-prone and make the code harder to maintain. I think the current approach is identical to the code snippet below which doesn't use mutex/condition-var:</p>\n<pre><code>constructor() {\n  calib_running_ = false;\n  done_ = false;\n}\nsetBatch() {\n  if (done_) return false;\n  while (calib_running_.load(acquire)) {\n    sleep(50ms);\n    if (done_) return false;\n  }\n  // set the batch\n  calib_running_.store(true, release);\n}\ngetBatch() {\n  calib_running_.store(false, release);\n  while (!calib_running_.load(acquire)) {\n    sleep(50ms);\n    if (done_) return false;\n  }\n  if (done_) return false;\n  // get the batch\n}\nsetDone() {\n  done_ = true;\n}\n</code></pre>\n<p>I think we can fix all the issues mentioned above by doing:</p>\n<pre><code>constructor() {\n  // All these variables are protected by the same mutex.\n  batch_is_set_ = false;\n  calib_running_ = false;\n  done_ = false;\n}\nsetBatch() {\n  mutex_lock l(cond_mtx_);\n  while ((calib_running_ || batch_is_set_) &amp;&amp; !done_) {\n    cond_.wait(l);\n  }\n  if (done_) return false;\n  CHECK(!calib_running_ &amp;&amp; !batch_is_set_);\n  // set the batch\n  batch_is_set_ = true;\n  cond_.notify_all();\n}\ngetBatch() {\n  mutex_lock l(cond_mtx_);\n  calib_running_ = false;\n  cond_.notify_all();  // Set the batch if !batch_is_set_\n  while (!batch_is_set_ &amp;&amp; !done_) {\n    cond_.wait(l);\n  }\n  if (done_) return false;\n  CHECK(!calib_running_ &amp;&amp; batch_is_set_);\n  // get the batch\n  batch_is_set_ = false;\n  calib_running_ = true;\n}\nsetDone() {\n  mutex_lock l(cond_mtx_);\n  done_ = true;\n  cond_.notify_all();\n}\n</code></pre>\n<p>Please take a look <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10539540\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/samikama\">@samikama</a>. Thanks :)</p>", "body_text": "Will this become obsolete in future PRs? If not, I think there are a few improvements we can make to make the logic clear, less error-prone, and easier to maintain in the future:\n\nwe only need a wait() in setBatch\nthe mutex_lock should be outside of the loop, as otherwise the logic is identical (as safe as) without the mutex (see below)\ndone_ needs to be protected by the mutex\nwe should not miss the first batch, even though this may be statistically ok, but it's functionally incorrect. I think we can use this condition_variable to fix that.\n\nMy another argument is that using atomic words (aka lock-free) instead of mutex is error-prone and make the code harder to maintain. I think the current approach is identical to the code snippet below which doesn't use mutex/condition-var:\nconstructor() {\n  calib_running_ = false;\n  done_ = false;\n}\nsetBatch() {\n  if (done_) return false;\n  while (calib_running_.load(acquire)) {\n    sleep(50ms);\n    if (done_) return false;\n  }\n  // set the batch\n  calib_running_.store(true, release);\n}\ngetBatch() {\n  calib_running_.store(false, release);\n  while (!calib_running_.load(acquire)) {\n    sleep(50ms);\n    if (done_) return false;\n  }\n  if (done_) return false;\n  // get the batch\n}\nsetDone() {\n  done_ = true;\n}\n\nI think we can fix all the issues mentioned above by doing:\nconstructor() {\n  // All these variables are protected by the same mutex.\n  batch_is_set_ = false;\n  calib_running_ = false;\n  done_ = false;\n}\nsetBatch() {\n  mutex_lock l(cond_mtx_);\n  while ((calib_running_ || batch_is_set_) && !done_) {\n    cond_.wait(l);\n  }\n  if (done_) return false;\n  CHECK(!calib_running_ && !batch_is_set_);\n  // set the batch\n  batch_is_set_ = true;\n  cond_.notify_all();\n}\ngetBatch() {\n  mutex_lock l(cond_mtx_);\n  calib_running_ = false;\n  cond_.notify_all();  // Set the batch if !batch_is_set_\n  while (!batch_is_set_ && !done_) {\n    cond_.wait(l);\n  }\n  if (done_) return false;\n  CHECK(!calib_running_ && batch_is_set_);\n  // get the batch\n  batch_is_set_ = false;\n  calib_running_ = true;\n}\nsetDone() {\n  mutex_lock l(cond_mtx_);\n  done_ = true;\n  cond_.notify_all();\n}\n\nPlease take a look @samikama. Thanks :)"}