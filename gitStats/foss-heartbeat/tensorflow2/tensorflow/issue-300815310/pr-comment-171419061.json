{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171419061", "pull_request_review_id": 100268882, "id": 171419061, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTQxOTA2MQ==", "diff_hunk": "@@ -0,0 +1,104 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/contrib/tensorrt/resources/TRTInt8Calibrator.h\"\n+\n+#include <atomic>\n+#include <chrono>\n+#include <unordered_map>\n+#include \"cuda_runtime_api.h\"\n+\n+#include \"tensorflow/core/platform/logging.h\"\n+\n+namespace tensorflow {\n+namespace trt {\n+// set the batch size before constructing the thread to execute engine\n+int TRTInt8Calibrator::getBatchSize() const { return batch_size_; }\n+\n+TRTInt8Calibrator::TRTInt8Calibrator(\n+    const std::unordered_map<string, std::pair<void*, size_t>>& dev_buffers,\n+    int batch_size, string engineName)\n+    : batch_size_(batch_size),\n+      done_(false),\n+      dev_buffers_(dev_buffers),\n+      calib_running_(false),\n+      engine_name_(engineName) {}\n+\n+bool TRTInt8Calibrator::setBatch(\n+    const std::unordered_map<string, void*>& data) {\n+  if (done_) return false;\n+  while (calib_running_.load(\n+      std::memory_order_acquire)) {  // wait while calibration is running\n+    tensorflow::mutex_lock l(cond_mtx_);\n+    cond_.wait_for(l, std::chrono::milliseconds(50));\n+    if (done_) return false;\n+  }\n+  VLOG(1) << \"Set Batch Waiting finished\";\n+  for (const auto it : data) {\n+    auto devptr = dev_buffers_.find(it.first);\n+    if (devptr == dev_buffers_.end()) {\n+      LOG(FATAL) << \"FATAL \" << engine_name_ << \" input name '\" << it.first\n+                 << \"' does not match with the buffer names\";\n+    }\n+    const auto& d = devptr->second;\n+\n+    auto status =\n+        cudaMemcpy(d.first, it.second, d.second, cudaMemcpyDeviceToDevice);\n+    if (status != cudaSuccess) {\n+      LOG(FATAL) << \"cudaMemcpy \" << engine_name_ << \" for '\" << it.first\n+                 << \"' failed with \" << status;\n+    }\n+  }\n+  calib_running_.store(true, std::memory_order_release);  // release builder\n+  cond_.notify_all();\n+  return true;\n+}\n+\n+bool TRTInt8Calibrator::getBatch(void** bindings, const char** names,\n+                                 int nbBindings) {\n+  calib_running_.store(false, std::memory_order_release);  // wait for new batch", "path": "tensorflow/contrib/tensorrt/resources/TRTInt8Calibrator.cc", "position": null, "original_position": 71, "commit_id": "5e5671e692db0533dfec66d63b8e7c8d06bc4942", "original_commit_id": "811c5ebd9510d723217363fffcb258126bec3ea2", "user": {"login": "samikama", "id": 10539540, "node_id": "MDQ6VXNlcjEwNTM5NTQw", "avatar_url": "https://avatars0.githubusercontent.com/u/10539540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samikama", "html_url": "https://github.com/samikama", "followers_url": "https://api.github.com/users/samikama/followers", "following_url": "https://api.github.com/users/samikama/following{/other_user}", "gists_url": "https://api.github.com/users/samikama/gists{/gist_id}", "starred_url": "https://api.github.com/users/samikama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samikama/subscriptions", "organizations_url": "https://api.github.com/users/samikama/orgs", "repos_url": "https://api.github.com/users/samikama/repos", "events_url": "https://api.github.com/users/samikama/events{/privacy}", "received_events_url": "https://api.github.com/users/samikama/received_events", "type": "User", "site_admin": false}, "body": "setBatch should be called before the getBatch(). In anycase, getBatch() call sleeps until a batch is ready to be consumed.", "created_at": "2018-02-28T23:23:09Z", "updated_at": "2018-03-01T22:59:18Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171419061", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/171419061"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17309#discussion_r171419061"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17309"}}, "body_html": "<p>setBatch should be called before the getBatch(). In anycase, getBatch() call sleeps until a batch is ready to be consumed.</p>", "body_text": "setBatch should be called before the getBatch(). In anycase, getBatch() call sleeps until a batch is ready to be consumed.", "in_reply_to_id": 171320783}