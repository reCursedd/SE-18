{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422871786", "html_url": "https://github.com/tensorflow/tensorflow/issues/20369#issuecomment-422871786", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20369", "id": 422871786, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjg3MTc4Ng==", "user": {"login": "lissyx", "id": 1645737, "node_id": "MDQ6VXNlcjE2NDU3Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1645737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lissyx", "html_url": "https://github.com/lissyx", "followers_url": "https://api.github.com/users/lissyx/followers", "following_url": "https://api.github.com/users/lissyx/following{/other_user}", "gists_url": "https://api.github.com/users/lissyx/gists{/gist_id}", "starred_url": "https://api.github.com/users/lissyx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lissyx/subscriptions", "organizations_url": "https://api.github.com/users/lissyx/orgs", "repos_url": "https://api.github.com/users/lissyx/repos", "events_url": "https://api.github.com/users/lissyx/events{/privacy}", "received_events_url": "https://api.github.com/users/lissyx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T16:37:02Z", "updated_at": "2018-09-19T16:37:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13089297\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/robieta\">@robieta</a> Updating our codebase, I'm hitting a similar issue with current tensorflow master:</p>\n<pre><code>         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [16] values: 0 1 2...&gt;, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nError running session: Not found: No registered 'Const' OpKernel for GPU devices compatible with node {{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [16] values: 0 1 2...&gt;, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\n         (OpKernel was found, but attributes didn't match)\n        .  Registered:  device='GPU'; dtype in [DT_VARIANT]\n  device='GPU'; dtype in [DT_BOOL]\n  device='GPU'; dtype in [DT_COMPLEX128]\n  device='GPU'; dtype in [DT_COMPLEX64]\n  device='GPU'; dtype in [DT_UINT64]\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_QINT32]\n  device='GPU'; dtype in [DT_UINT32]\n  device='GPU'; dtype in [DT_QUINT16]\n  device='GPU'; dtype in [DT_QINT16]\n  device='GPU'; dtype in [DT_INT16]\n  device='GPU'; dtype in [DT_UINT16]\n  device='GPU'; dtype in [DT_QINT8]\n  device='GPU'; dtype in [DT_INT8]\n  device='GPU'; dtype in [DT_UINT8]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_BFLOAT16]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [16] values: 0 1 2...&gt;, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n</code></pre>\n<p>This is happening when trying to run inference from <code>libdeepspeech.so</code>, which links TensorFlow. However, the same code would work well with something based on TensorFlow r1.6. So it looks like something changed on that side, since. I could not find any evidence / documentation related.</p>", "body_text": "@zheng-xq @robieta Updating our codebase, I'm hitting a similar issue with current tensorflow master:\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nError running session: Not found: No registered 'Const' OpKernel for GPU devices compatible with node {{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\n         (OpKernel was found, but attributes didn't match)\n        .  Registered:  device='GPU'; dtype in [DT_VARIANT]\n  device='GPU'; dtype in [DT_BOOL]\n  device='GPU'; dtype in [DT_COMPLEX128]\n  device='GPU'; dtype in [DT_COMPLEX64]\n  device='GPU'; dtype in [DT_UINT64]\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_QINT32]\n  device='GPU'; dtype in [DT_UINT32]\n  device='GPU'; dtype in [DT_QUINT16]\n  device='GPU'; dtype in [DT_QINT16]\n  device='GPU'; dtype in [DT_INT16]\n  device='GPU'; dtype in [DT_UINT16]\n  device='GPU'; dtype in [DT_QINT8]\n  device='GPU'; dtype in [DT_INT8]\n  device='GPU'; dtype in [DT_UINT8]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_BFLOAT16]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nThis is happening when trying to run inference from libdeepspeech.so, which links TensorFlow. However, the same code would work well with something based on TensorFlow r1.6. So it looks like something changed on that side, since. I could not find any evidence / documentation related.", "body": "@zheng-xq @robieta Updating our codebase, I'm hitting a similar issue with current tensorflow master:\r\n```\r\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\nError running session: Not found: No registered 'Const' OpKernel for GPU devices compatible with node {{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n         (OpKernel was found, but attributes didn't match)\r\n        .  Registered:  device='GPU'; dtype in [DT_VARIANT]\r\n  device='GPU'; dtype in [DT_BOOL]\r\n  device='GPU'; dtype in [DT_COMPLEX128]\r\n  device='GPU'; dtype in [DT_COMPLEX64]\r\n  device='GPU'; dtype in [DT_UINT64]\r\n  device='GPU'; dtype in [DT_INT64]\r\n  device='GPU'; dtype in [DT_QINT32]\r\n  device='GPU'; dtype in [DT_UINT32]\r\n  device='GPU'; dtype in [DT_QUINT16]\r\n  device='GPU'; dtype in [DT_QINT16]\r\n  device='GPU'; dtype in [DT_INT16]\r\n  device='GPU'; dtype in [DT_UINT16]\r\n  device='GPU'; dtype in [DT_QINT8]\r\n  device='GPU'; dtype in [DT_INT8]\r\n  device='GPU'; dtype in [DT_UINT8]\r\n  device='GPU'; dtype in [DT_DOUBLE]\r\n  device='GPU'; dtype in [DT_FLOAT]\r\n  device='GPU'; dtype in [DT_BFLOAT16]\r\n  device='GPU'; dtype in [DT_HALF]\r\n  device='CPU'\r\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n```\r\n\r\nThis is happening when trying to run inference from `libdeepspeech.so`, which links TensorFlow. However, the same code would work well with something based on TensorFlow r1.6. So it looks like something changed on that side, since. I could not find any evidence / documentation related."}