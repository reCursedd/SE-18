{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/219869001", "html_url": "https://github.com/tensorflow/tensorflow/issues/2121#issuecomment-219869001", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2121", "id": 219869001, "node_id": "MDEyOklzc3VlQ29tbWVudDIxOTg2OTAwMQ==", "user": {"login": "liuyipei", "id": 4404828, "node_id": "MDQ6VXNlcjQ0MDQ4Mjg=", "avatar_url": "https://avatars0.githubusercontent.com/u/4404828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuyipei", "html_url": "https://github.com/liuyipei", "followers_url": "https://api.github.com/users/liuyipei/followers", "following_url": "https://api.github.com/users/liuyipei/following{/other_user}", "gists_url": "https://api.github.com/users/liuyipei/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuyipei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuyipei/subscriptions", "organizations_url": "https://api.github.com/users/liuyipei/orgs", "repos_url": "https://api.github.com/users/liuyipei/repos", "events_url": "https://api.github.com/users/liuyipei/events{/privacy}", "received_events_url": "https://api.github.com/users/liuyipei/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-17T22:07:38Z", "updated_at": "2016-05-17T22:22:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have the same issue as well. I use a similar set up to OP (but ubuntu 14.04 on 2 Titan X). I have been trying to run <code>https://github.com/tensorflow/models/tree/master/inception</code>.</p>\n<p>Originally, I would run into an unhandled <code>CUDA_ERROR_LAUNCH_TIMEOUT</code> a few hours in</p>\n<pre><code>E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n</code></pre>\n<p><code>CUDA_ERROR_LAUNCH_TIMEOUT</code> is the result of watchdog killing a compute thread that took too long.</p>\n<p>To address this, I disabled watchdog by adding <code>options \"Interactive\" \"0\"</code> to my devices in <code>xorg.conf</code>.<br>\nThis results in behavior mentioned by the OP when I tried to run <code>https://github.com/tensorflow/models/tree/master/inception</code></p>\n<p>When I came back in the morning, one of the gpus is at 100% with all its memory in use while the other appears idle. Another thing I noted was that the 100% used GPU was at a much lower temperature (45C)  than when tensorflow is operating normally (80C). Also, my GUI was not responsive, though I could ssh in.</p>\n<p>As for reproducibility, it happened to me two out of two times, 7:30 in and 7:50 in respectively, running at ~49 examples/second.</p>", "body_text": "I have the same issue as well. I use a similar set up to OP (but ubuntu 14.04 on 2 Titan X). I have been trying to run https://github.com/tensorflow/models/tree/master/inception.\nOriginally, I would run into an unhandled CUDA_ERROR_LAUNCH_TIMEOUT a few hours in\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n\nCUDA_ERROR_LAUNCH_TIMEOUT is the result of watchdog killing a compute thread that took too long.\nTo address this, I disabled watchdog by adding options \"Interactive\" \"0\" to my devices in xorg.conf.\nThis results in behavior mentioned by the OP when I tried to run https://github.com/tensorflow/models/tree/master/inception\nWhen I came back in the morning, one of the gpus is at 100% with all its memory in use while the other appears idle. Another thing I noted was that the 100% used GPU was at a much lower temperature (45C)  than when tensorflow is operating normally (80C). Also, my GUI was not responsive, though I could ssh in.\nAs for reproducibility, it happened to me two out of two times, 7:30 in and 7:50 in respectively, running at ~49 examples/second.", "body": "I have the same issue as well. I use a similar set up to OP (but ubuntu 14.04 on 2 Titan X). I have been trying to run `https://github.com/tensorflow/models/tree/master/inception`.\n\nOriginally, I would run into an unhandled `CUDA_ERROR_LAUNCH_TIMEOUT` a few hours in\n\n```\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n```\n\n`CUDA_ERROR_LAUNCH_TIMEOUT` is the result of watchdog killing a compute thread that took too long. \n\nTo address this, I disabled watchdog by adding `options \"Interactive\" \"0\"` to my devices in `xorg.conf`.\nThis results in behavior mentioned by the OP when I tried to run `https://github.com/tensorflow/models/tree/master/inception`\n\nWhen I came back in the morning, one of the gpus is at 100% with all its memory in use while the other appears idle. Another thing I noted was that the 100% used GPU was at a much lower temperature (45C)  than when tensorflow is operating normally (80C). Also, my GUI was not responsive, though I could ssh in.\n\nAs for reproducibility, it happened to me two out of two times, 7:30 in and 7:50 in respectively, running at ~49 examples/second.\n"}