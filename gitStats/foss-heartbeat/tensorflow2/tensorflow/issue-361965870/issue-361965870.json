{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22398", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22398/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22398/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22398/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22398", "id": 361965870, "node_id": "MDU6SXNzdWUzNjE5NjU4NzA=", "number": 22398, "title": "CUDA implementation of BiasAddGrad op is non-determinstic", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097547538, "node_id": "MDU6TGFiZWwxMDk3NTQ3NTM4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:gpu", "name": "comp:gpu", "color": "0052cc", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-09-19T23:37:32Z", "updated_at": "2018-11-10T19:02:08Z", "closed_at": "2018-10-25T23:47:07Z", "author_association": "NONE", "body_html": "<p>I'm running TensorFlow 1.5.0 on a K80 GPU on Python 2.7</p>\n<p>Failing test case:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n<span class=\"pl-k\">import</span> hashlib\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nnp.random.randn(<span class=\"pl-c1\">2018</span>)\ntf.set_random_seed(<span class=\"pl-c1\">2018</span>)\n\nX <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">1024</span>, <span class=\"pl-c1\">50</span>).astype(np.float32)\nb <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>bias<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">50</span>])\nz <span class=\"pl-k\">=</span> tf.nn.bias_add(X, b)\n\ngrad <span class=\"pl-k\">=</span> tf.gradients(z<span class=\"pl-k\">*</span>z, b)[<span class=\"pl-c1\">0</span>]\n\ninit_op <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(init_op)\n\n    run1 <span class=\"pl-k\">=</span> sess.run(grad)\n    run2 <span class=\"pl-k\">=</span> sess.run(grad)\n\n    <span class=\"pl-c1\">print</span>(np.all(run1 <span class=\"pl-k\">==</span> run2))\n    <span class=\"pl-c1\">print</span>(np.max(np.abs(run1 <span class=\"pl-k\">-</span> run2)))\n\n    dohash <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">X</span>: hashlib.md5(X.tostring()).hexdigest()\n    <span class=\"pl-c1\">print</span>(dohash(run1))\n    <span class=\"pl-c1\">print</span>(dohash(run2))</pre></div>\n<p>Outputs</p>\n<pre><code>False\n6.10352e-05\nb489a1d659518b2ae9213f5a21e35df2\n187a57d563468e59ba5f9d9cf51ca5cb\n</code></pre>\n<p>This bug still exists in master, because the code in master uses the unsafe CUDA atomic floating point add in several places. See <a href=\"https://github.com/tensorflow/tensorflow/blob/abc55107eb7a03fe3d83f95fd5e1b8e4def90826/tensorflow/core/kernels/bias_op_gpu.cu.cc\">https://github.com/tensorflow/tensorflow/blob/abc55107eb7a03fe3d83f95fd5e1b8e4def90826/tensorflow/core/kernels/bias_op_gpu.cu.cc</a><br>\nIf TensorFlow will be ever be fully determinstic, atomic floating point add should never be used (it is inherently non-determinstic due to non-associativity of floating point).</p>\n<p>Notably, Keras's <code>Dense</code> layer uses <code>bias_add</code>, so all networks that use this layer are non-reproducible. This is relevant to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"147792887\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/2280\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/2280/hovercard\" href=\"https://github.com/keras-team/keras/issues/2280\">keras-team/keras#2280</a> .</p>\n<p>This can currently be avoided by using <code>tf.add</code> instead of <code>tf.nn.bias_add</code> at a slightly performance hit. The correct fix would be refactor the <code>BiasAddGrad</code> op to use a (deterministic) reduction tree.</p>\n<p>edit with issue template fields:<br>\nHave I written custom code: Python test case, see above<br>\nOS Platform and Distribution: RHEL 7.5 (Linux)<br>\nTensorFlow installed from: source<br>\nTensorFlow version: 1.5.0<br>\nBazel version: unknown<br>\nCUDA/cuDNN version: CUDA 8.0.61, cuDNN v6<br>\nGPU model and memory: Nvidia K80, 12GB memory<br>\nExact command to reproduce: run the above script<br>\nMobile device: NA</p>", "body_text": "I'm running TensorFlow 1.5.0 on a K80 GPU on Python 2.7\nFailing test case:\nfrom __future__ import print_function\nimport hashlib\nimport numpy as np\nimport tensorflow as tf\n\nnp.random.randn(2018)\ntf.set_random_seed(2018)\n\nX = np.random.randn(1024, 50).astype(np.float32)\nb = tf.get_variable('bias', [50])\nz = tf.nn.bias_add(X, b)\n\ngrad = tf.gradients(z*z, b)[0]\n\ninit_op = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n\n    run1 = sess.run(grad)\n    run2 = sess.run(grad)\n\n    print(np.all(run1 == run2))\n    print(np.max(np.abs(run1 - run2)))\n\n    dohash = lambda X: hashlib.md5(X.tostring()).hexdigest()\n    print(dohash(run1))\n    print(dohash(run2))\nOutputs\nFalse\n6.10352e-05\nb489a1d659518b2ae9213f5a21e35df2\n187a57d563468e59ba5f9d9cf51ca5cb\n\nThis bug still exists in master, because the code in master uses the unsafe CUDA atomic floating point add in several places. See https://github.com/tensorflow/tensorflow/blob/abc55107eb7a03fe3d83f95fd5e1b8e4def90826/tensorflow/core/kernels/bias_op_gpu.cu.cc\nIf TensorFlow will be ever be fully determinstic, atomic floating point add should never be used (it is inherently non-determinstic due to non-associativity of floating point).\nNotably, Keras's Dense layer uses bias_add, so all networks that use this layer are non-reproducible. This is relevant to keras-team/keras#2280 .\nThis can currently be avoided by using tf.add instead of tf.nn.bias_add at a slightly performance hit. The correct fix would be refactor the BiasAddGrad op to use a (deterministic) reduction tree.\nedit with issue template fields:\nHave I written custom code: Python test case, see above\nOS Platform and Distribution: RHEL 7.5 (Linux)\nTensorFlow installed from: source\nTensorFlow version: 1.5.0\nBazel version: unknown\nCUDA/cuDNN version: CUDA 8.0.61, cuDNN v6\nGPU model and memory: Nvidia K80, 12GB memory\nExact command to reproduce: run the above script\nMobile device: NA", "body": "I'm running TensorFlow 1.5.0 on a K80 GPU on Python 2.7\r\n\r\nFailing test case:\r\n```python\r\nfrom __future__ import print_function\r\nimport hashlib\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nnp.random.randn(2018)\r\ntf.set_random_seed(2018)\r\n\r\nX = np.random.randn(1024, 50).astype(np.float32)\r\nb = tf.get_variable('bias', [50])\r\nz = tf.nn.bias_add(X, b)\r\n\r\ngrad = tf.gradients(z*z, b)[0]\r\n\r\ninit_op = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n\r\n    run1 = sess.run(grad)\r\n    run2 = sess.run(grad)\r\n\r\n    print(np.all(run1 == run2))\r\n    print(np.max(np.abs(run1 - run2)))\r\n\r\n    dohash = lambda X: hashlib.md5(X.tostring()).hexdigest()\r\n    print(dohash(run1))\r\n    print(dohash(run2))\r\n```\r\n\r\nOutputs\r\n```\r\nFalse\r\n6.10352e-05\r\nb489a1d659518b2ae9213f5a21e35df2\r\n187a57d563468e59ba5f9d9cf51ca5cb\r\n```\r\n\r\nThis bug still exists in master, because the code in master uses the unsafe CUDA atomic floating point add in several places. See https://github.com/tensorflow/tensorflow/blob/abc55107eb7a03fe3d83f95fd5e1b8e4def90826/tensorflow/core/kernels/bias_op_gpu.cu.cc \r\nIf TensorFlow will be ever be fully determinstic, atomic floating point add should never be used (it is inherently non-determinstic due to non-associativity of floating point).\r\n\r\nNotably, Keras's `Dense` layer uses `bias_add`, so all networks that use this layer are non-reproducible. This is relevant to https://github.com/keras-team/keras/issues/2280 .\r\n\r\n This can currently be avoided by using `tf.add` instead of `tf.nn.bias_add` at a slightly performance hit. The correct fix would be refactor the `BiasAddGrad` op to use a (deterministic) reduction tree.\r\n\r\nedit with issue template fields:\r\nHave I written custom code: Python test case, see above\r\nOS Platform and Distribution: RHEL 7.5 (Linux)\r\nTensorFlow installed from: source\r\nTensorFlow version: 1.5.0\r\nBazel version: unknown\r\nCUDA/cuDNN version: CUDA 8.0.61, cuDNN v6\r\nGPU model and memory: Nvidia K80, 12GB memory\r\nExact command to reproduce: run the above script\r\nMobile device: NA"}