{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111676542", "pull_request_review_id": 32937467, "id": 111676542, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMTY3NjU0Mg==", "diff_hunk": "@@ -97,9 +84,141 @@ class FFTGPUBase : public OpKernel {\n   virtual bool IsForward() const = 0;\n   virtual bool IsReal() const = 0;\n \n- private:\n+  // The function that actually computes the FFT.\n+  virtual void DoFFT(OpKernelContext* ctx, const Tensor& in, uint64* fft_shape,\n+                     Tensor* out) = 0;\n+};\n+\n+typedef Eigen::ThreadPoolDevice CPUDevice;\n+\n+template <typename Device, typename TInput, typename TOutput,\n+          int FFTResultType, int FFTDir, int FFTRank>\n+struct FFTFunctor {\n+  void operator()(const Device& d,\n+                  typename TTypes<TOutput, FFTRank + 1>::Tensor output,\n+                  typename TTypes<TInput, FFTRank + 1>::Tensor input) {\n+    // Create the axes (which are always trailing).\n+    auto axes = Eigen::ArrayXi::LinSpaced(FFTRank, 1, FFTRank);\n+    // Evaluate the fft on the specified device.\n+    output.device(d) = input.template fft<FFTResultType, FFTDir>(axes);\n+  }\n+};\n+\n+template <bool Forward, bool _Real, int FFTRank>\n+class FFTCPU : public FFTBase {\n+ public:\n+  using FFTBase::FFTBase;\n+ protected:\n+  int Rank() const override { return FFTRank; }\n+  bool IsForward() const override { return Forward; }\n+  bool IsReal() const override { return _Real; }\n+\n+  void DoFFT(OpKernelContext* ctx, const Tensor& in, uint64* fft_shape,\n+             Tensor* out) override {\n+    if (!IsReal()) {\n+      auto input = ((Tensor) in).flat_inner_dims<complex64, FFTRank + 1>();\n+\n+      // Apply the functor.\n+      FFTFunctor<CPUDevice, complex64, complex64, Eigen::BothParts,\n+                Forward ? Eigen::FFT_FORWARD : Eigen::FFT_REVERSE,\n+                FFTRank> functor;\n+      functor(ctx->eigen_device<CPUDevice>(),\n+              out->flat_inner_dims<complex64, FFTRank + 1>(), input);\n+    }\n+    else {\n+      if (IsForward()) {\n+        auto input = ((Tensor) in).flat_inner_dims<float, FFTRank + 1>();\n+        // Create a temporary placeholder for the full FFT.\n+        Tensor temp;\n+        OP_REQUIRES_OK(ctx,ctx->allocate_temp(\n+          DataTypeToEnum<complex64>::v(), in.shape(), &temp\n+        ));\n+        auto full_fft = temp.flat_inner_dims<complex64, FFTRank + 1>();\n+        // Apply the functor.\n+        FFTFunctor<CPUDevice, float, complex64, Eigen::BothParts,\n+                  Eigen::FFT_FORWARD, FFTRank> functor;\n+        functor(ctx->eigen_device<CPUDevice>(), full_fft, input);\n+        // Create zero indices for slicing.\n+        Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> startIndices;\n+        // Convert output to tensor and get tensor size for slicing.\n+        auto output = out->flat_inner_dims<complex64, FFTRank + 1>();\n+        auto sizes = output.dimensions();\n+        // Slice the full FFT to get the non-negative frequency components only.\n+        output.slice(startIndices, sizes) =\n+          full_fft.slice(startIndices, sizes);\n+      }\n+      else {\n+        auto input = ((Tensor) in).flat_inner_dims<complex64, FFTRank + 1>();\n+        // The first dimension contains the zero-frequency component which we\n+        // do not want to duplicate. So we reconstruct the complex signal by\n+        // (1) slicing from the second element, (2) reversing the order,\n+        // (3) taking the complex conjugate, (4) concatenating with the original\n+        // input. Note that for an even input length, the last element is the\n+        // Nyquist frequency which we also do not want to duplicate.\n+        Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> startIndices;\n+        startIndices[FFTRank] = 1;\n+        auto sizes = input.dimensions();\n+        if (sizes[FFTRank] % 2 == 0) {\n+          sizes[FFTRank] -= 1;\n+        }\n+        auto cc = input.slice(startIndices, sizes).conjugate()\n+          .reverse(FFTRank);\n+        auto full_fft = input.concatenate(cc, FFTRank);\n+\n+        // Evaluate the IFFT\n+        auto output = out->flat_inner_dims<float, FFTRank + 1>();\n+        FFTFunctor<CPUDevice, complex64, float, Eigen::RealPart,\n+                  Eigen::FFT_REVERSE, FFTRank> functor;\n+        functor(ctx->eigen_device<CPUDevice>(), output, full_fft);", "path": "tensorflow/core/kernels/fft_ops.cc", "position": null, "original_position": 126, "commit_id": "e6da919d85a75ba32258b3e578d8dbe0dd49188e", "original_commit_id": "cfce2b036ea33aeb2742fb4219e75c2652dad3c7", "user": {"login": "rryan", "id": 26527, "node_id": "MDQ6VXNlcjI2NTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/26527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rryan", "html_url": "https://github.com/rryan", "followers_url": "https://api.github.com/users/rryan/followers", "following_url": "https://api.github.com/users/rryan/following{/other_user}", "gists_url": "https://api.github.com/users/rryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/rryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rryan/subscriptions", "organizations_url": "https://api.github.com/users/rryan/orgs", "repos_url": "https://api.github.com/users/rryan/repos", "events_url": "https://api.github.com/users/rryan/events{/privacy}", "received_events_url": "https://api.github.com/users/rryan/received_events", "type": "User", "site_admin": false}, "body": "Hm, after reading TensorFFT a bit, I'm not sure if its [TensorTraits](https://bitbucket.org/eigen/eigen/src/f3a22f35b0444e03a1f65941800b9a2283de1398/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?fileviewer=file-view-default#TensorFFT.h-62) are defined properly. It does not define `Scalar`, only `RealScalar`, `ComplexScalar`, `InputScalar` and `OutputScalar`. So the inherited traits `traits<XprType>` defines `Scalar`. `XprType` is `Tensor<float>` in this case, so `Scalar` is `float`. Using [TensorConversion](https://bitbucket.org/eigen/eigen/src/f3a22f35b0444e03a1f65941800b9a2283de1398/unsupported/Eigen/CXX11/src/Tensor/TensorConversion.h?at=default&fileviewer=file-view-default#TensorConversion.h-27) as an example (since I'm not familiar enough with Eigen to know what this is supposed to be), it looks like it defines `Scalar` as the type casted to.\r\n\r\n@benoitsteiner / @rmlarsen?", "created_at": "2017-04-16T01:56:45Z", "updated_at": "2017-05-17T11:28:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9029#discussion_r111676542", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9029", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111676542"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9029#discussion_r111676542"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9029"}}, "body_html": "<p>Hm, after reading TensorFFT a bit, I'm not sure if its <a href=\"https://bitbucket.org/eigen/eigen/src/f3a22f35b0444e03a1f65941800b9a2283de1398/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?fileviewer=file-view-default#TensorFFT.h-62\" rel=\"nofollow\">TensorTraits</a> are defined properly. It does not define <code>Scalar</code>, only <code>RealScalar</code>, <code>ComplexScalar</code>, <code>InputScalar</code> and <code>OutputScalar</code>. So the inherited traits <code>traits&lt;XprType&gt;</code> defines <code>Scalar</code>. <code>XprType</code> is <code>Tensor&lt;float&gt;</code> in this case, so <code>Scalar</code> is <code>float</code>. Using <a href=\"https://bitbucket.org/eigen/eigen/src/f3a22f35b0444e03a1f65941800b9a2283de1398/unsupported/Eigen/CXX11/src/Tensor/TensorConversion.h?at=default&amp;fileviewer=file-view-default#TensorConversion.h-27\" rel=\"nofollow\">TensorConversion</a> as an example (since I'm not familiar enough with Eigen to know what this is supposed to be), it looks like it defines <code>Scalar</code> as the type casted to.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6969686\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benoitsteiner\">@benoitsteiner</a> / <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16907534\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rmlarsen\">@rmlarsen</a>?</p>", "body_text": "Hm, after reading TensorFFT a bit, I'm not sure if its TensorTraits are defined properly. It does not define Scalar, only RealScalar, ComplexScalar, InputScalar and OutputScalar. So the inherited traits traits<XprType> defines Scalar. XprType is Tensor<float> in this case, so Scalar is float. Using TensorConversion as an example (since I'm not familiar enough with Eigen to know what this is supposed to be), it looks like it defines Scalar as the type casted to.\n@benoitsteiner / @rmlarsen?", "in_reply_to_id": 111649584}