{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291899613", "html_url": "https://github.com/tensorflow/tensorflow/issues/8911#issuecomment-291899613", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8911", "id": 291899613, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTg5OTYxMw==", "user": {"login": "AshishBora", "id": 4586769, "node_id": "MDQ6VXNlcjQ1ODY3Njk=", "avatar_url": "https://avatars0.githubusercontent.com/u/4586769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AshishBora", "html_url": "https://github.com/AshishBora", "followers_url": "https://api.github.com/users/AshishBora/followers", "following_url": "https://api.github.com/users/AshishBora/following{/other_user}", "gists_url": "https://api.github.com/users/AshishBora/gists{/gist_id}", "starred_url": "https://api.github.com/users/AshishBora/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AshishBora/subscriptions", "organizations_url": "https://api.github.com/users/AshishBora/orgs", "repos_url": "https://api.github.com/users/AshishBora/repos", "events_url": "https://api.github.com/users/AshishBora/events{/privacy}", "received_events_url": "https://api.github.com/users/AshishBora/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T15:31:44Z", "updated_at": "2017-04-05T15:31:44Z", "author_association": "NONE", "body_html": "<p>The path norm computes a sum of products over edge paths. Thus we should be multiplying individual weights, not the L2 norm of weight matrices. So I think <a href=\"https://github.com/siryog90/tensorflow/commit/1d46853fc81ebf3c8f816e26055b574924ac26ff\">this</a> implementation is not computing the path norm correctly.</p>\n<p>For example, the path norm will never have interaction terms between two edges in consecutive layers that are not incident at the same neuron. But multiplying L2 norm of weights introduces those terms.</p>\n<p>One way to compute the <code>Lp</code>-PathNorm can be this:</p>\n<ul>\n<li>construct new weight matrices <code>W' = tf.pow(tf.abs(W), p)</code>.</li>\n<li>Use these in the same network architecture as the original.</li>\n<li>Give all ones tensor as input and pass it through the network to get some output.</li>\n<li>Compute the sum of all outputs and take that raise to <code>1/p</code>. This is the <code>Lp</code>-PathNorm.</li>\n</ul>", "body_text": "The path norm computes a sum of products over edge paths. Thus we should be multiplying individual weights, not the L2 norm of weight matrices. So I think this implementation is not computing the path norm correctly.\nFor example, the path norm will never have interaction terms between two edges in consecutive layers that are not incident at the same neuron. But multiplying L2 norm of weights introduces those terms.\nOne way to compute the Lp-PathNorm can be this:\n\nconstruct new weight matrices W' = tf.pow(tf.abs(W), p).\nUse these in the same network architecture as the original.\nGive all ones tensor as input and pass it through the network to get some output.\nCompute the sum of all outputs and take that raise to 1/p. This is the Lp-PathNorm.", "body": "The path norm computes a sum of products over edge paths. Thus we should be multiplying individual weights, not the L2 norm of weight matrices. So I think [this](https://github.com/siryog90/tensorflow/commit/1d46853fc81ebf3c8f816e26055b574924ac26ff) implementation is not computing the path norm correctly.\r\n\r\nFor example, the path norm will never have interaction terms between two edges in consecutive layers that are not incident at the same neuron. But multiplying L2 norm of weights introduces those terms.\r\n\r\nOne way to compute the `Lp`-PathNorm can be this: \r\n\r\n- construct new weight matrices `W' = tf.pow(tf.abs(W), p)`.\r\n- Use these in the same network architecture as the original.\r\n- Give all ones tensor as input and pass it through the network to get some output.\r\n- Compute the sum of all outputs and take that raise to `1/p`. This is the `Lp`-PathNorm."}