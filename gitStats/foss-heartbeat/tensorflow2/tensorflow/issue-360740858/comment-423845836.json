{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/423845836", "html_url": "https://github.com/tensorflow/tensorflow/pull/22308#issuecomment-423845836", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22308", "id": 423845836, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzg0NTgzNg==", "user": {"login": "bstriner", "id": 12462956, "node_id": "MDQ6VXNlcjEyNDYyOTU2", "avatar_url": "https://avatars3.githubusercontent.com/u/12462956?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bstriner", "html_url": "https://github.com/bstriner", "followers_url": "https://api.github.com/users/bstriner/followers", "following_url": "https://api.github.com/users/bstriner/following{/other_user}", "gists_url": "https://api.github.com/users/bstriner/gists{/gist_id}", "starred_url": "https://api.github.com/users/bstriner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bstriner/subscriptions", "organizations_url": "https://api.github.com/users/bstriner/orgs", "repos_url": "https://api.github.com/users/bstriner/repos", "events_url": "https://api.github.com/users/bstriner/events{/privacy}", "received_events_url": "https://api.github.com/users/bstriner/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-23T20:33:48Z", "updated_at": "2018-09-23T20:33:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've been training a lot over the weekend and everything seems to be working right. I'm thinking about dropping the packing kernels entirely. It seems like I can get the correct indices with existing operations by doing the below. Might be faster or slower than the custom kernel but definitely easier to write and maintain. Using the fact that boolean_mask seems to take things in deterministic row-major order.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">sequence_indices</span>(<span class=\"pl-smi\">sorted_sequence_lengths</span>, <span class=\"pl-smi\">batch_order</span>):\n    mg <span class=\"pl-k\">=</span> tf.meshgrid(tf.range(sorted_sequence_lengths[<span class=\"pl-c1\">0</span>]), batch_order, <span class=\"pl-v\">indexing</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>ij<span class=\"pl-pds\">'</span></span>)\n    mg <span class=\"pl-k\">=</span> tf.stack(mg, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    mask <span class=\"pl-k\">=</span> tf.transpose(tf.sequence_mask(<span class=\"pl-v\">lengths</span><span class=\"pl-k\">=</span>sorted_sequence_lengths, <span class=\"pl-v\">maxlen</span><span class=\"pl-k\">=</span>l), (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>))\n    idx <span class=\"pl-k\">=</span> tf.boolean_mask(mg, mask)\n    <span class=\"pl-k\">return</span> idx</pre></div>\n<p>The LSTM itself seems to be about right. The only improvement might be caching the descriptors somehow. Should be able to reuse the forward descriptors for the backward pass instead of regenerating but I'm not sure exactly where that would go and how much of an improvement that would actually make.</p>", "body_text": "I've been training a lot over the weekend and everything seems to be working right. I'm thinking about dropping the packing kernels entirely. It seems like I can get the correct indices with existing operations by doing the below. Might be faster or slower than the custom kernel but definitely easier to write and maintain. Using the fact that boolean_mask seems to take things in deterministic row-major order.\ndef sequence_indices(sorted_sequence_lengths, batch_order):\n    mg = tf.meshgrid(tf.range(sorted_sequence_lengths[0]), batch_order, indexing='ij')\n    mg = tf.stack(mg, axis=-1)\n    mask = tf.transpose(tf.sequence_mask(lengths=sorted_sequence_lengths, maxlen=l), (1, 0))\n    idx = tf.boolean_mask(mg, mask)\n    return idx\nThe LSTM itself seems to be about right. The only improvement might be caching the descriptors somehow. Should be able to reuse the forward descriptors for the backward pass instead of regenerating but I'm not sure exactly where that would go and how much of an improvement that would actually make.", "body": "I've been training a lot over the weekend and everything seems to be working right. I'm thinking about dropping the packing kernels entirely. It seems like I can get the correct indices with existing operations by doing the below. Might be faster or slower than the custom kernel but definitely easier to write and maintain. Using the fact that boolean_mask seems to take things in deterministic row-major order.\r\n\r\n```python\r\ndef sequence_indices(sorted_sequence_lengths, batch_order):\r\n    mg = tf.meshgrid(tf.range(sorted_sequence_lengths[0]), batch_order, indexing='ij')\r\n    mg = tf.stack(mg, axis=-1)\r\n    mask = tf.transpose(tf.sequence_mask(lengths=sorted_sequence_lengths, maxlen=l), (1, 0))\r\n    idx = tf.boolean_mask(mg, mask)\r\n    return idx\r\n```\r\n\r\nThe LSTM itself seems to be about right. The only improvement might be caching the descriptors somehow. Should be able to reuse the forward descriptors for the backward pass instead of regenerating but I'm not sure exactly where that would go and how much of an improvement that would actually make."}