{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/228233917", "html_url": "https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-228233917", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2940", "id": 228233917, "node_id": "MDEyOklzc3VlQ29tbWVudDIyODIzMzkxNw==", "user": {"login": "Velkan", "id": 3774188, "node_id": "MDQ6VXNlcjM3NzQxODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3774188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Velkan", "html_url": "https://github.com/Velkan", "followers_url": "https://api.github.com/users/Velkan/followers", "following_url": "https://api.github.com/users/Velkan/following{/other_user}", "gists_url": "https://api.github.com/users/Velkan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Velkan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Velkan/subscriptions", "organizations_url": "https://api.github.com/users/Velkan/orgs", "repos_url": "https://api.github.com/users/Velkan/repos", "events_url": "https://api.github.com/users/Velkan/events{/privacy}", "received_events_url": "https://api.github.com/users/Velkan/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-24T01:33:35Z", "updated_at": "2016-06-24T01:33:35Z", "author_association": "NONE", "body_html": "<p>Hi peter:</p>\n<p>I actually pass the build process.</p>\n<p>Maybe you want set a cuda capability during the tensorflow configuration?<br>\nWhen it like:<br>\n'Please specify a list of comma-separated Cuda compute capabilities you<br>\nwant to build with.'<br>\nEnter '3.0' for the gt 650m.</p>\n<p>And your error log said:<br>\n'Use --verbose_failures to see the command lines of failed build steps.'<br>\nMaybe you can get some details by doing that?</p>\n<p>And make sure your source code is updated. I got a wired error once by<br>\nusing a old version of the source and solved it by clone from the master.</p>\n<p>On Fri, Jun 24, 2016, 3:04 AM peterswang <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p>I ran into a similar issue with Python 2.7.11 on OS X 10.11.5 + MBP.</p>\n<p>$ ./configure<br>\nPlease specify the location of python. [Default is /usr/local/bin/python]:<br>\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] N<br>\nNo Google Cloud Platform support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with GPU support? [y/N] y<br>\nGPU support will be enabled for TensorFlow<br>\nPlease specify which gcc nvcc should use as the host compiler. [Default is<br>\n/usr/bin/gcc]:<br>\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave<br>\nempty to use system default]: 7.5<br>\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to<br>\nREADME.md for more details. [Default is /usr/local/cuda]:<br>\nPlease specify the Cudnn version you want to use. [Leave empty to use<br>\nsystem default]: 5<br>\nPlease specify the location where cuDNN 5 library is installed. Refer to<br>\nREADME.md for more details. [Default is /usr/local/cuda]:<br>\nPlease specify a list of comma-separated Cuda compute capabilities you<br>\nwant to build with.<br>\nYou can find the compute capability of your device at:<br>\n<a href=\"https://developer.nvidia.com/cuda-gpus\" rel=\"nofollow\">https://developer.nvidia.com/cuda-gpus</a>.<br>\nPlease note that each additional compute capability significantly<br>\nincreases your build time and binary size.</p>\n<p>Setting up Cuda include<br>\nSetting up Cuda lib<br>\nSetting up Cuda bin<br>\nSetting up Cuda nvvm<br>\nSetting up CUPTI include<br>\nSetting up CUPTI lib64<br>\nConfiguration finished<br>\n$ bazel build -c opt --config=cuda<br>\n//tensorflow/tools/pip_package:build_pip_package<br>\n.......<br>\n.......<br>\n1 warning generated.<br>\nINFO: From Linking tensorflow/python/_pywrap_tensorflow.so [for host]:<br>\nclang: warning: argument unused during compilation: '-pthread'<br>\nld: warning: option -noall_load is obsolete and being ignored<br>\nINFO: From Linking tensorflow/python/_pywrap_tensorflow.so:<br>\nclang: warning: argument unused during compilation: '-pthread'<br>\nld: warning: option -noall_load is obsolete and being ignored<br>\nERROR:<br>\n/Users/peter_wang/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1:<br>\nExecuting genrule //tensorflow/contrib/session_bundle/example:half_plus_two<br>\nfailed: bash failed: error executing command /bin/bash -c ... (remaining 1<br>\nargument(s) skipped):<br>\ncom.google.devtools.build.lib.shell.BadExitStatusException: Process exited<br>\nwith status 245.<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA<br>\nlibrary libcublas.7.5.dylib locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA<br>\nlibrary libcudnn.5.dylib locally<br>\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA<br>\nlibrary libcufft.7.5.dylib locally<br>\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build<br>\nUse --verbose_failures to see the command lines of failed build steps.<br>\nINFO: Elapsed time: 1826.337s, Critical Path: 1821.08s</p>\n<p>To verify CUDA install:<br>\n$ ./bin/x86_64/darwin/release/deviceQuery<br>\n./bin/x86_64/darwin/release/deviceQuery Starting...</p>\n<p>CUDA Device Query (Runtime API) version (CUDART static linking)</p>\n<p>Detected 1 CUDA Capable device(s)</p>\n<p>Device 0: \"GeForce GT 650M\"<br>\nCUDA Driver Version / Runtime Version 7.5 / 7.5<br>\nCUDA Capability Major/Minor version number: 3.0<br>\nTotal amount of global memory: 512 MBytes (536543232 bytes)<br>\n( 2) Multiprocessors, (192) CUDA Cores/MP: 384 CUDA Cores<br>\nGPU Max Clock rate: 405 MHz (0.41 GHz)<br>\nMemory Clock rate: 2000 Mhz<br>\nMemory Bus Width: 128-bit<br>\nL2 Cache Size: 262144 bytes<br>\nMaximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536),<br>\n3D=(4096, 4096, 4096)<br>\nMaximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers<br>\nMaximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048<br>\nlayers<br>\nTotal amount of constant memory: 65536 bytes<br>\nTotal amount of shared memory per block: 49152 bytes<br>\nTotal number of registers available per block: 65536<br>\nWarp size: 32<br>\nMaximum number of threads per multiprocessor: 2048<br>\nMaximum number of threads per block: 1024<br>\nMax dimension size of a thread block (x,y,z): (1024, 1024, 64)<br>\nMax dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)<br>\nMaximum memory pitch: 2147483647 bytes<br>\nTexture alignment: 512 bytes<br>\nConcurrent copy and kernel execution: Yes with 1 copy engine(s)<br>\nRun time limit on kernels: Yes<br>\nIntegrated GPU sharing Host Memory: No<br>\nSupport host page-locked memory mapping: Yes<br>\nAlignment requirement for Surfaces: Yes<br>\nDevice has ECC support: Disabled<br>\nDevice supports Unified Addressing (UVA): Yes<br>\nDevice PCI Domain ID / Bus ID / location ID: 0 / 1 / 0<br>\nCompute Mode:<br>\n&lt; Default (multiple host threads can use ::cudaSetDevice() with device<br>\nsimultaneously) &gt;</p>\n<p>deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime<br>\nVersion = 7.5, NumDevs = 1, Device0 = GeForce GT 650M<br>\nResult = PASS</p>\n<p>\u2014<br>\nYou are receiving this because you commented.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160993548\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2940\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2940/hovercard?comment_id=228151515&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-228151515\">#2940 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe/ADmW7AoIow1wLqEj_Jk1rli5ifANu3Zlks5qOtjUgaJpZM4I4z4H\">https://github.com/notifications/unsubscribe/ADmW7AoIow1wLqEj_Jk1rli5ifANu3Zlks5qOtjUgaJpZM4I4z4H</a><br>\n.</p>\n</blockquote>", "body_text": "Hi peter:\nI actually pass the build process.\nMaybe you want set a cuda capability during the tensorflow configuration?\nWhen it like:\n'Please specify a list of comma-separated Cuda compute capabilities you\nwant to build with.'\nEnter '3.0' for the gt 650m.\nAnd your error log said:\n'Use --verbose_failures to see the command lines of failed build steps.'\nMaybe you can get some details by doing that?\nAnd make sure your source code is updated. I got a wired error once by\nusing a old version of the source and solved it by clone from the master.\nOn Fri, Jun 24, 2016, 3:04 AM peterswang notifications@github.com wrote:\n\nI ran into a similar issue with Python 2.7.11 on OS X 10.11.5 + MBP.\n$ ./configure\nPlease specify the location of python. [Default is /usr/local/bin/python]:\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] N\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with GPU support? [y/N] y\nGPU support will be enabled for TensorFlow\nPlease specify which gcc nvcc should use as the host compiler. [Default is\n/usr/bin/gcc]:\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave\nempty to use system default]: 7.5\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to\nREADME.md for more details. [Default is /usr/local/cuda]:\nPlease specify the Cudnn version you want to use. [Leave empty to use\nsystem default]: 5\nPlease specify the location where cuDNN 5 library is installed. Refer to\nREADME.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you\nwant to build with.\nYou can find the compute capability of your device at:\nhttps://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly\nincreases your build time and binary size.\nSetting up Cuda include\nSetting up Cuda lib\nSetting up Cuda bin\nSetting up Cuda nvvm\nSetting up CUPTI include\nSetting up CUPTI lib64\nConfiguration finished\n$ bazel build -c opt --config=cuda\n//tensorflow/tools/pip_package:build_pip_package\n.......\n.......\n1 warning generated.\nINFO: From Linking tensorflow/python/_pywrap_tensorflow.so [for host]:\nclang: warning: argument unused during compilation: '-pthread'\nld: warning: option -noall_load is obsolete and being ignored\nINFO: From Linking tensorflow/python/_pywrap_tensorflow.so:\nclang: warning: argument unused during compilation: '-pthread'\nld: warning: option -noall_load is obsolete and being ignored\nERROR:\n/Users/peter_wang/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1:\nExecuting genrule //tensorflow/contrib/session_bundle/example:half_plus_two\nfailed: bash failed: error executing command /bin/bash -c ... (remaining 1\nargument(s) skipped):\ncom.google.devtools.build.lib.shell.BadExitStatusException: Process exited\nwith status 245.\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\nlibrary libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\nlibrary libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\nlibrary libcufft.7.5.dylib locally\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 1826.337s, Critical Path: 1821.08s\nTo verify CUDA install:\n$ ./bin/x86_64/darwin/release/deviceQuery\n./bin/x86_64/darwin/release/deviceQuery Starting...\nCUDA Device Query (Runtime API) version (CUDART static linking)\nDetected 1 CUDA Capable device(s)\nDevice 0: \"GeForce GT 650M\"\nCUDA Driver Version / Runtime Version 7.5 / 7.5\nCUDA Capability Major/Minor version number: 3.0\nTotal amount of global memory: 512 MBytes (536543232 bytes)\n( 2) Multiprocessors, (192) CUDA Cores/MP: 384 CUDA Cores\nGPU Max Clock rate: 405 MHz (0.41 GHz)\nMemory Clock rate: 2000 Mhz\nMemory Bus Width: 128-bit\nL2 Cache Size: 262144 bytes\nMaximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536),\n3D=(4096, 4096, 4096)\nMaximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers\nMaximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048\nlayers\nTotal amount of constant memory: 65536 bytes\nTotal amount of shared memory per block: 49152 bytes\nTotal number of registers available per block: 65536\nWarp size: 32\nMaximum number of threads per multiprocessor: 2048\nMaximum number of threads per block: 1024\nMax dimension size of a thread block (x,y,z): (1024, 1024, 64)\nMax dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)\nMaximum memory pitch: 2147483647 bytes\nTexture alignment: 512 bytes\nConcurrent copy and kernel execution: Yes with 1 copy engine(s)\nRun time limit on kernels: Yes\nIntegrated GPU sharing Host Memory: No\nSupport host page-locked memory mapping: Yes\nAlignment requirement for Surfaces: Yes\nDevice has ECC support: Disabled\nDevice supports Unified Addressing (UVA): Yes\nDevice PCI Domain ID / Bus ID / location ID: 0 / 1 / 0\nCompute Mode:\n< Default (multiple host threads can use ::cudaSetDevice() with device\nsimultaneously) >\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime\nVersion = 7.5, NumDevs = 1, Device0 = GeForce GT 650M\nResult = PASS\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\n#2940 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ADmW7AoIow1wLqEj_Jk1rli5ifANu3Zlks5qOtjUgaJpZM4I4z4H\n.", "body": "Hi peter:\n\nI actually pass the build process.\n\nMaybe you want set a cuda capability during the tensorflow configuration?\nWhen it like:\n'Please specify a list of comma-separated Cuda compute capabilities you\nwant to build with.'\nEnter '3.0' for the gt 650m.\n\nAnd your error log said:\n'Use --verbose_failures to see the command lines of failed build steps.'\nMaybe you can get some details by doing that?\n\nAnd make sure your source code is updated. I got a wired error once by\nusing a old version of the source and solved it by clone from the master.\n\nOn Fri, Jun 24, 2016, 3:04 AM peterswang notifications@github.com wrote:\n\n> I ran into a similar issue with Python 2.7.11 on OS X 10.11.5 + MBP.\n> \n> $ ./configure\n> Please specify the location of python. [Default is /usr/local/bin/python]:\n> Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N\n> No Google Cloud Platform support will be enabled for TensorFlow\n> Do you wish to build TensorFlow with GPU support? [y/N] y\n> GPU support will be enabled for TensorFlow\n> Please specify which gcc nvcc should use as the host compiler. [Default is\n> /usr/bin/gcc]:\n> Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave\n> empty to use system default]: 7.5\n> Please specify the location where CUDA 7.5 toolkit is installed. Refer to\n> README.md for more details. [Default is /usr/local/cuda]:\n> Please specify the Cudnn version you want to use. [Leave empty to use\n> system default]: 5\n> Please specify the location where cuDNN 5 library is installed. Refer to\n> README.md for more details. [Default is /usr/local/cuda]:\n> Please specify a list of comma-separated Cuda compute capabilities you\n> want to build with.\n> You can find the compute capability of your device at:\n> https://developer.nvidia.com/cuda-gpus.\n> Please note that each additional compute capability significantly\n> increases your build time and binary size.\n> \n> Setting up Cuda include\n> Setting up Cuda lib\n> Setting up Cuda bin\n> Setting up Cuda nvvm\n> Setting up CUPTI include\n> Setting up CUPTI lib64\n> Configuration finished\n> $ bazel build -c opt --config=cuda\n> //tensorflow/tools/pip_package:build_pip_package\n> .......\n> .......\n> 1 warning generated.\n> INFO: From Linking tensorflow/python/_pywrap_tensorflow.so [for host]:\n> clang: warning: argument unused during compilation: '-pthread'\n> ld: warning: option -noall_load is obsolete and being ignored\n> INFO: From Linking tensorflow/python/_pywrap_tensorflow.so:\n> clang: warning: argument unused during compilation: '-pthread'\n> ld: warning: option -noall_load is obsolete and being ignored\n> ERROR:\n> /Users/peter_wang/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1:\n> Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two\n> failed: bash failed: error executing command /bin/bash -c ... (remaining 1\n> argument(s) skipped):\n> com.google.devtools.build.lib.shell.BadExitStatusException: Process exited\n> with status 245.\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcublas.7.5.dylib locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcudnn.5.dylib locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcufft.7.5.dylib locally\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\n> Use --verbose_failures to see the command lines of failed build steps.\n> INFO: Elapsed time: 1826.337s, Critical Path: 1821.08s\n> \n> To verify CUDA install:\n> $ ./bin/x86_64/darwin/release/deviceQuery\n> ./bin/x86_64/darwin/release/deviceQuery Starting...\n> \n> CUDA Device Query (Runtime API) version (CUDART static linking)\n> \n> Detected 1 CUDA Capable device(s)\n> \n> Device 0: \"GeForce GT 650M\"\n> CUDA Driver Version / Runtime Version 7.5 / 7.5\n> CUDA Capability Major/Minor version number: 3.0\n> Total amount of global memory: 512 MBytes (536543232 bytes)\n> ( 2) Multiprocessors, (192) CUDA Cores/MP: 384 CUDA Cores\n> GPU Max Clock rate: 405 MHz (0.41 GHz)\n> Memory Clock rate: 2000 Mhz\n> Memory Bus Width: 128-bit\n> L2 Cache Size: 262144 bytes\n> Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536),\n> 3D=(4096, 4096, 4096)\n> Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers\n> Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048\n> layers\n> Total amount of constant memory: 65536 bytes\n> Total amount of shared memory per block: 49152 bytes\n> Total number of registers available per block: 65536\n> Warp size: 32\n> Maximum number of threads per multiprocessor: 2048\n> Maximum number of threads per block: 1024\n> Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n> Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)\n> Maximum memory pitch: 2147483647 bytes\n> Texture alignment: 512 bytes\n> Concurrent copy and kernel execution: Yes with 1 copy engine(s)\n> Run time limit on kernels: Yes\n> Integrated GPU sharing Host Memory: No\n> Support host page-locked memory mapping: Yes\n> Alignment requirement for Surfaces: Yes\n> Device has ECC support: Disabled\n> Device supports Unified Addressing (UVA): Yes\n> Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0\n> Compute Mode:\n> < Default (multiple host threads can use ::cudaSetDevice() with device\n> simultaneously) >\n> \n> deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime\n> Version = 7.5, NumDevs = 1, Device0 = GeForce GT 650M\n> Result = PASS\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-228151515,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ADmW7AoIow1wLqEj_Jk1rli5ifANu3Zlks5qOtjUgaJpZM4I4z4H\n> .\n"}