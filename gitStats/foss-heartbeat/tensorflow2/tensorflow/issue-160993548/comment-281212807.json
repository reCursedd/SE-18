{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281212807", "html_url": "https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-281212807", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2940", "id": 281212807, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTIxMjgwNw==", "user": {"login": "hbfs", "id": 2048786, "node_id": "MDQ6VXNlcjIwNDg3ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/2048786?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hbfs", "html_url": "https://github.com/hbfs", "followers_url": "https://api.github.com/users/hbfs/followers", "following_url": "https://api.github.com/users/hbfs/following{/other_user}", "gists_url": "https://api.github.com/users/hbfs/gists{/gist_id}", "starred_url": "https://api.github.com/users/hbfs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hbfs/subscriptions", "organizations_url": "https://api.github.com/users/hbfs/orgs", "repos_url": "https://api.github.com/users/hbfs/repos", "events_url": "https://api.github.com/users/hbfs/events{/privacy}", "received_events_url": "https://api.github.com/users/hbfs/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-21T00:32:38Z", "updated_at": "2017-02-22T18:25:50Z", "author_association": "NONE", "body_html": "<p>Here's a successful 10.11.6 build. Mainly for my own documentation, it has been simplified and Just Works\u2122 :</p>\n<h2>Pre-requisites:</h2>\n<p>OS X 10.11.6<br>\nhomebrew 1.1.8<br>\nPython 2.7.11<br>\npip 9.0.1</p>\n<p>Download and install directly from nVIDIA:</p>\n<ol>\n<li>Install CUDA-8.0</li>\n<li>Install cuDNN-5.1<br>\na. Copy files to <code>/Developer/NVIDIA/CUDA-8.0/{lib,include}</code><br>\nb. Symlink <code>ln -s /Developer/NVIDIA/CUDA-8.0/lib/cudnn* /usr/local/cuda/lib/</code><br>\nc. Create symlink for libcuda.1.dylib<br>\n<code>ln -s /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib</code></li>\n</ol>\n<h3>Test CUDA install</h3>\n<p>Copy <code>/Developer/NVIDIA/CUDA-8.0/samples</code> to your working directory<br>\ncd <code>$CUDA_SAMPLE_DIR/</code><br>\na. To make all the samples: <code>make -j&lt;# of threads&gt;</code><br>\nb. To make only the deviceQueryDrv Utility, cd to <code>1_Utilities/deviceQueryDrv</code> and type <code>make -j&lt;# of threads&gt;</code><br>\n<code>$CUDA_SAMPLE_DIR/bin/x86_64/darwin/release/deviceQueryDrv</code></p>\n<p>expected output (for my GTX 960 4GB, yours will vary depending on your GPU):</p>\n<pre><code>\u00bb bin/x86_64/darwin/release/deviceQueryDrv\nbin/x86_64/darwin/release/deviceQueryDrv Starting...\n\nCUDA Device Query (Driver API) statically linked version\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 960\"\n  CUDA Driver Version:                           8.0\n  CUDA Capability Major/Minor version number:    5.2\n  Total amount of global memory:                 4096 MBytes (4294770688 bytes)\n  ( 8) Multiprocessors, (128) CUDA Cores/MP:     1024 CUDA Cores\n  GPU Max Clock rate:                            1291 MHz (1.29 GHz)\n  Memory Clock rate:                             3505 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 1048576 bytes\n  Max Texture Dimension Sizes                    1D=(65536) 2D=(65536, 65536) 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\n  Texture alignment:                             512 bytes\n  Maximum memory pitch:                          2147483647 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Concurrent kernel execution:                   Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\nResult = PASS\n</code></pre>\n<h2>Other software installs</h2>\n<p>You might have to install <code>bazel</code>.</p>\n<p>I recommend <code>brew install bazel</code>.</p>\n<p><code>brew</code> while not perfect, simplifies your life. It is a simple to use package manager for OS X with a variety of packages available and maintained.</p>\n<h2>Install Tensorflow</h2>\n<ol start=\"3\">\n<li>Automagically install GPU version <code>pip install tensorflow-gpu</code></li>\n</ol>\n<h2>Test</h2>\n<p>tensorflow-test.py:</p>\n<pre><code>import tensorflow as tf\n\n# Creates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n\n# Runs the op.\nprint sess.run(c)\n</code></pre>\n<p>expected output (the final result should be the same, the only differences being the GPU used and amount of free GPU RAM):</p>\n<pre><code>\u00bb python ./tensorflow-test.py\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GeForce GTX 960\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\npciBusID 0000:04:00.0\nTotal memory: 4.00GiB\nFree memory: 921.46MiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\na: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n</code></pre>\n<h2>Enjoy your tensorflow install and make something insanely great.</h2>\n<h3>Feedback</h3>\n<p>If this worked or more importantly, didnt work, let me know and I'll try to keep it updated.</p>", "body_text": "Here's a successful 10.11.6 build. Mainly for my own documentation, it has been simplified and Just Works\u2122 :\nPre-requisites:\nOS X 10.11.6\nhomebrew 1.1.8\nPython 2.7.11\npip 9.0.1\nDownload and install directly from nVIDIA:\n\nInstall CUDA-8.0\nInstall cuDNN-5.1\na. Copy files to /Developer/NVIDIA/CUDA-8.0/{lib,include}\nb. Symlink ln -s /Developer/NVIDIA/CUDA-8.0/lib/cudnn* /usr/local/cuda/lib/\nc. Create symlink for libcuda.1.dylib\nln -s /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib\n\nTest CUDA install\nCopy /Developer/NVIDIA/CUDA-8.0/samples to your working directory\ncd $CUDA_SAMPLE_DIR/\na. To make all the samples: make -j<# of threads>\nb. To make only the deviceQueryDrv Utility, cd to 1_Utilities/deviceQueryDrv and type make -j<# of threads>\n$CUDA_SAMPLE_DIR/bin/x86_64/darwin/release/deviceQueryDrv\nexpected output (for my GTX 960 4GB, yours will vary depending on your GPU):\n\u00bb bin/x86_64/darwin/release/deviceQueryDrv\nbin/x86_64/darwin/release/deviceQueryDrv Starting...\n\nCUDA Device Query (Driver API) statically linked version\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 960\"\n  CUDA Driver Version:                           8.0\n  CUDA Capability Major/Minor version number:    5.2\n  Total amount of global memory:                 4096 MBytes (4294770688 bytes)\n  ( 8) Multiprocessors, (128) CUDA Cores/MP:     1024 CUDA Cores\n  GPU Max Clock rate:                            1291 MHz (1.29 GHz)\n  Memory Clock rate:                             3505 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 1048576 bytes\n  Max Texture Dimension Sizes                    1D=(65536) 2D=(65536, 65536) 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\n  Texture alignment:                             512 bytes\n  Maximum memory pitch:                          2147483647 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Concurrent kernel execution:                   Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\nResult = PASS\n\nOther software installs\nYou might have to install bazel.\nI recommend brew install bazel.\nbrew while not perfect, simplifies your life. It is a simple to use package manager for OS X with a variety of packages available and maintained.\nInstall Tensorflow\n\nAutomagically install GPU version pip install tensorflow-gpu\n\nTest\ntensorflow-test.py:\nimport tensorflow as tf\n\n# Creates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n\n# Runs the op.\nprint sess.run(c)\n\nexpected output (the final result should be the same, the only differences being the GPU used and amount of free GPU RAM):\n\u00bb python ./tensorflow-test.py\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\nname: GeForce GTX 960\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\npciBusID 0000:04:00.0\nTotal memory: 4.00GiB\nFree memory: 921.46MiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\n\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\na: (Const): /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\n[[ 22.  28.]\n [ 49.  64.]]\n\nEnjoy your tensorflow install and make something insanely great.\nFeedback\nIf this worked or more importantly, didnt work, let me know and I'll try to keep it updated.", "body": "Here's a successful 10.11.6 build. Mainly for my own documentation, it has been simplified and Just Works&trade; :\r\n\r\n## Pre-requisites: \r\nOS X 10.11.6\r\nhomebrew 1.1.8\r\nPython 2.7.11\r\npip 9.0.1\r\n\r\nDownload and install directly from nVIDIA:\r\n1. Install CUDA-8.0\r\n2. Install cuDNN-5.1\r\n     a. Copy files to `/Developer/NVIDIA/CUDA-8.0/{lib,include}`\r\n     b. Symlink `ln -s /Developer/NVIDIA/CUDA-8.0/lib/cudnn* /usr/local/cuda/lib/`\r\n     c. Create symlink for libcuda.1.dylib\r\n   `ln -s /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib`\r\n\r\n### Test CUDA install\r\n\r\nCopy `/Developer/NVIDIA/CUDA-8.0/samples` to your working directory\r\ncd `$CUDA_SAMPLE_DIR/`\r\n     a. To make all the samples: `make -j<# of threads>`\r\n     b. To make only the deviceQueryDrv Utility, cd to `1_Utilities/deviceQueryDrv` and type `make -j<# of threads>`\r\n`$CUDA_SAMPLE_DIR/bin/x86_64/darwin/release/deviceQueryDrv`\r\n\r\nexpected output (for my GTX 960 4GB, yours will vary depending on your GPU):\r\n```\r\n\u00bb bin/x86_64/darwin/release/deviceQueryDrv\r\nbin/x86_64/darwin/release/deviceQueryDrv Starting...\r\n\r\nCUDA Device Query (Driver API) statically linked version\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 960\"\r\n  CUDA Driver Version:                           8.0\r\n  CUDA Capability Major/Minor version number:    5.2\r\n  Total amount of global memory:                 4096 MBytes (4294770688 bytes)\r\n  ( 8) Multiprocessors, (128) CUDA Cores/MP:     1024 CUDA Cores\r\n  GPU Max Clock rate:                            1291 MHz (1.29 GHz)\r\n  Memory Clock rate:                             3505 Mhz\r\n  Memory Bus Width:                              128-bit\r\n  L2 Cache Size:                                 1048576 bytes\r\n  Max Texture Dimension Sizes                    1D=(65536) 2D=(65536, 65536) 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\r\n  Texture alignment:                             512 bytes\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Concurrent kernel execution:                   Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\nResult = PASS\r\n```\r\n\r\n## Other software installs\r\nYou might have to install `bazel`. \r\n\r\nI recommend `brew install bazel`. \r\n\r\n`brew` while not perfect, simplifies your life. It is a simple to use package manager for OS X with a variety of packages available and maintained.\r\n\r\n## Install Tensorflow\r\n\r\n3. Automagically install GPU version `pip install tensorflow-gpu`\r\n\r\n## Test\r\n\r\ntensorflow-test.py:\r\n```\r\nimport tensorflow as tf\r\n\r\n# Creates a graph.\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n\r\n# Creates a session with log_device_placement set to True.\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n\r\n# Runs the op.\r\nprint sess.run(c)\r\n```\r\n\r\nexpected output (the final result should be the same, the only differences being the GPU used and amount of free GPU RAM):\r\n```\r\n\u00bb python ./tensorflow-test.py\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] OS X does not support NUMA - returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 960\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\r\npciBusID 0000:04:00.0\r\nTotal memory: 4.00GiB\r\nFree memory: 921.46MiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\r\nI tensorflow/core/common_runtime/direct_session.cc:255] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 960, pci bus id: 0000:04:00.0\r\n\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] b: (Const)/job:localhost/replica:0/task:0/gpu:0\r\na: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] a: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\n## Enjoy your tensorflow install and make something insanely great. \r\n\r\n### Feedback\r\nIf this worked or more importantly, didnt work, let me know and I'll try to keep it updated."}