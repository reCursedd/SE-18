{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5125", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5125/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5125/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5125/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5125", "id": 184580371, "node_id": "MDU6SXNzdWUxODQ1ODAzNzE=", "number": 5125, "title": "InvalidArgumentError : input must be 4-dimensional[100,100,3]", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-10-21T22:05:19Z", "updated_at": "2016-10-22T00:12:10Z", "closed_at": "2016-10-22T00:12:10Z", "author_association": "NONE", "body_html": "<p>I am trying to use inception V1 model to predict single image. The example on the tensor flow website uses inception V3, which needs 1.7s-1.9s on a single Tian X GPU. This is not fast.</p>\n<p>I use the following python code to test V3 performance, which by changing <strong>classify_image.py</strong></p>\n<pre><code> #... above code is for load graph and read image\n\nt1=time.time()\n\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax:0') \npredictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data}) \npredictions= np.squeeze(fpredictions)\n\ndelta=time.time()-t1\nprint(delta)\n</code></pre>\n<p>I think the major reason is V3 has 42 layers, which is too large.</p>\n<p>However, when i change the above code for V1 model. I meet errors. First I get the node names from V1 model .pb file as below:<br>\n<strong>input<br>\nconv2d0_w<br>\nconv2d0_b<br>\nconv2d1_w</strong><br>\n...<br>\n...<br>\n...<br>\n<strong>softmax2<br>\noutput<br>\noutput1<br>\noutput2</strong></p>\n<p>So the entry point of V1 model is <strong>input</strong>. The entry point of V3 is <strong>DecodeJpeg/contents</strong>, which accept image buffer from <strong>tf.gfile.FastGFile(image, 'rb').read()</strong> function directly. But V1 does not. So i use the code below to get the image and return as an array.</p>\n<p><strong>image_data</strong>=<strong>cv2</strong>.imread(image)</p>\n<p>Now the code for V1 model become for prediction become</p>\n<pre><code>softmax_tensor = sess.graph.get_tensor_by_name('softmax2:0')\npredictions = sess.run(softmax_tensor, {'input:0': image_data})\n</code></pre>\n<p>However, I get error below when i run the code.</p>\n<p>InvalidArgumentError (see above for traceback): <strong>input must be 4-dimensional</strong>[100,100,3]<br>\n[[Node: conv2d0_pre_relu/conv = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_0, conv2d0_w)]]</p>\n<p>It says it need a 4-dimensional input. My image array has width, height and channel only. So how can i create a 4D tensor from a single image for V1 model as input data?</p>", "body_text": "I am trying to use inception V1 model to predict single image. The example on the tensor flow website uses inception V3, which needs 1.7s-1.9s on a single Tian X GPU. This is not fast.\nI use the following python code to test V3 performance, which by changing classify_image.py\n #... above code is for load graph and read image\n\nt1=time.time()\n\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax:0') \npredictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data}) \npredictions= np.squeeze(fpredictions)\n\ndelta=time.time()-t1\nprint(delta)\n\nI think the major reason is V3 has 42 layers, which is too large.\nHowever, when i change the above code for V1 model. I meet errors. First I get the node names from V1 model .pb file as below:\ninput\nconv2d0_w\nconv2d0_b\nconv2d1_w\n...\n...\n...\nsoftmax2\noutput\noutput1\noutput2\nSo the entry point of V1 model is input. The entry point of V3 is DecodeJpeg/contents, which accept image buffer from tf.gfile.FastGFile(image, 'rb').read() function directly. But V1 does not. So i use the code below to get the image and return as an array.\nimage_data=cv2.imread(image)\nNow the code for V1 model become for prediction become\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax2:0')\npredictions = sess.run(softmax_tensor, {'input:0': image_data})\n\nHowever, I get error below when i run the code.\nInvalidArgumentError (see above for traceback): input must be 4-dimensional[100,100,3]\n[[Node: conv2d0_pre_relu/conv = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_0, conv2d0_w)]]\nIt says it need a 4-dimensional input. My image array has width, height and channel only. So how can i create a 4D tensor from a single image for V1 model as input data?", "body": "I am trying to use inception V1 model to predict single image. The example on the tensor flow website uses inception V3, which needs 1.7s-1.9s on a single Tian X GPU. This is not fast. \n\nI use the following python code to test V3 performance, which by changing **classify_image.py**\n\n```\n #... above code is for load graph and read image\n\nt1=time.time()\n\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax:0') \npredictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data}) \npredictions= np.squeeze(fpredictions)\n\ndelta=time.time()-t1\nprint(delta)\n```\n\nI think the major reason is V3 has 42 layers, which is too large. \n\nHowever, when i change the above code for V1 model. I meet errors. First I get the node names from V1 model .pb file as below:\n**input\nconv2d0_w\nconv2d0_b\nconv2d1_w**\n...\n...\n...\n**softmax2\noutput\noutput1\noutput2**\n\nSo the entry point of V1 model is **input**. The entry point of V3 is **DecodeJpeg/contents**, which accept image buffer from **tf.gfile.FastGFile(image, 'rb').read()** function directly. But V1 does not. So i use the code below to get the image and return as an array.\n\n**image_data**=**cv2**.imread(image)  \n\nNow the code for V1 model become for prediction become\n\n```\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax2:0')\npredictions = sess.run(softmax_tensor, {'input:0': image_data})\n```\n\nHowever, I get error below when i run the code.\n\nInvalidArgumentError (see above for traceback): **input must be 4-dimensional**[100,100,3]\n     [[Node: conv2d0_pre_relu/conv = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_0, conv2d0_w)]]\n\nIt says it need a 4-dimensional input. My image array has width, height and channel only. So how can i create a 4D tensor from a single image for V1 model as input data?\n"}