{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412166145", "html_url": "https://github.com/tensorflow/tensorflow/issues/21492#issuecomment-412166145", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492", "id": 412166145, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjE2NjE0NQ==", "user": {"login": "xiejw", "id": 1184671, "node_id": "MDQ6VXNlcjExODQ2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1184671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiejw", "html_url": "https://github.com/xiejw", "followers_url": "https://api.github.com/users/xiejw/followers", "following_url": "https://api.github.com/users/xiejw/following{/other_user}", "gists_url": "https://api.github.com/users/xiejw/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiejw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiejw/subscriptions", "organizations_url": "https://api.github.com/users/xiejw/orgs", "repos_url": "https://api.github.com/users/xiejw/repos", "events_url": "https://api.github.com/users/xiejw/events{/privacy}", "received_events_url": "https://api.github.com/users/xiejw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-10T18:24:18Z", "updated_at": "2018-08-10T18:24:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a wrong argument to understand the sleep logic in the code.</p>\n<ol>\n<li>std server starts before the sleeping. All workers (including chief) will try to find each other first.</li>\n<li>The time.sleep after that is \"delay starting\". It is part of the machine learning, not related to distributed cluster management. It is the best practice for between-graph execution. For multiple worker training scenario, it is recommended to have few workers sending the gradients to update the initial variables. More workers should join later. This produces better model quality.</li>\n</ol>", "body_text": "This is a wrong argument to understand the sleep logic in the code.\n\nstd server starts before the sleeping. All workers (including chief) will try to find each other first.\nThe time.sleep after that is \"delay starting\". It is part of the machine learning, not related to distributed cluster management. It is the best practice for between-graph execution. For multiple worker training scenario, it is recommended to have few workers sending the gradients to update the initial variables. More workers should join later. This produces better model quality.", "body": "This is a wrong argument to understand the sleep logic in the code. \r\n\r\n1. std server starts before the sleeping. All workers (including chief) will try to find each other first.\r\n2. The time.sleep after that is \"delay starting\". It is part of the machine learning, not related to distributed cluster management. It is the best practice for between-graph execution. For multiple worker training scenario, it is recommended to have few workers sending the gradients to update the initial variables. More workers should join later. This produces better model quality. "}