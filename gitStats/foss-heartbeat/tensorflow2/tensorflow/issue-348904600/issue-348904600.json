{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21492", "id": 348904600, "node_id": "MDU6SXNzdWUzNDg5MDQ2MDA=", "number": 21492, "title": "Public API to preempt tf.train.Server", "user": {"login": "superbobry", "id": 185856, "node_id": "MDQ6VXNlcjE4NTg1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/185856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/superbobry", "html_url": "https://github.com/superbobry", "followers_url": "https://api.github.com/users/superbobry/followers", "following_url": "https://api.github.com/users/superbobry/following{/other_user}", "gists_url": "https://api.github.com/users/superbobry/gists{/gist_id}", "starred_url": "https://api.github.com/users/superbobry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/superbobry/subscriptions", "organizations_url": "https://api.github.com/users/superbobry/orgs", "repos_url": "https://api.github.com/users/superbobry/repos", "events_url": "https://api.github.com/users/superbobry/events{/privacy}", "received_events_url": "https://api.github.com/users/superbobry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-08-08T21:49:12Z", "updated_at": "2018-11-20T07:54:35Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: N/A</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: N/A</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.9.0-0-g25c197e023 1.9.0</li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><code>tf.train_and_evaluate</code> uses <code>time.sleep</code> to (optimistically) synchronize the startup of chief/worker nodes in the distributed mode (see <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/training.py#L753\">estimator/training.py</a>). The implicit assumption in this logic is that by the time the worker is spawned, the chief has already started its <code>tf.train.Server</code>, i.e. the scheduler should be aware of the assumption and should schedule and initialize the chief first. This might not be easily achievable on general purpose systems like YARN.</p>\n<p>One possible solution to this is to synchronize the chief/worker tasks on a barrier, and then preemptively start the server right after the barrier, but prior to calling <code>train_and_evaluate</code>. This does not eliminate the race condition entirely but makes it much less likely in practice. The only problem here is that <code>train_and_evaluate</code> does not provide a documented way to account for preempted servers. The undocumented way is:</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/2b4fd1c2b7a37367e61bbae3d27d194a894cb7bb/tensorflow/python/estimator/training.py#L747-L748\">tensorflow/tensorflow/python/estimator/training.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 747 to 748\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/2b4fd1c2b7a37367e61bbae3d27d194a894cb7bb\">2b4fd1c</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L747\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"747\"></td>\n          <td id=\"LC747\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> _is_google_env(): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L748\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"748\"></td>\n          <td id=\"LC748\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-c1\">self</span>._start_std_server(config) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>I was wondering if it would be possible to make this part of the <code>train_and_evaluate</code> contract public or, alternatively, address the issue in another way?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.9.0-0-g25c197e023 1.9.0\nPython version: N/A\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nDescribe the problem\ntf.train_and_evaluate uses time.sleep to (optimistically) synchronize the startup of chief/worker nodes in the distributed mode (see estimator/training.py). The implicit assumption in this logic is that by the time the worker is spawned, the chief has already started its tf.train.Server, i.e. the scheduler should be aware of the assumption and should schedule and initialize the chief first. This might not be easily achievable on general purpose systems like YARN.\nOne possible solution to this is to synchronize the chief/worker tasks on a barrier, and then preemptively start the server right after the barrier, but prior to calling train_and_evaluate. This does not eliminate the race condition entirely but makes it much less likely in practice. The only problem here is that train_and_evaluate does not provide a documented way to account for preempted servers. The undocumented way is:\n\n  \n    \n      tensorflow/tensorflow/python/estimator/training.py\n    \n    \n        Lines 747 to 748\n      in\n      2b4fd1c\n    \n    \n    \n    \n\n        \n          \n           if not _is_google_env(): \n        \n\n        \n          \n             self._start_std_server(config) \n        \n    \n  \n\n\nI was wondering if it would be possible to make this part of the train_and_evaluate contract public or, alternatively, address the issue in another way?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.9.0-0-g25c197e023 1.9.0\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\n`tf.train_and_evaluate` uses `time.sleep` to (optimistically) synchronize the startup of chief/worker nodes in the distributed mode (see [estimator/training.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/training.py#L753)). The implicit assumption in this logic is that by the time the worker is spawned, the chief has already started its `tf.train.Server`, i.e. the scheduler should be aware of the assumption and should schedule and initialize the chief first. This might not be easily achievable on general purpose systems like YARN.\r\n\r\nOne possible solution to this is to synchronize the chief/worker tasks on a barrier, and then preemptively start the server right after the barrier, but prior to calling `train_and_evaluate`. This does not eliminate the race condition entirely but makes it much less likely in practice. The only problem here is that `train_and_evaluate` does not provide a documented way to account for preempted servers. The undocumented way is:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2b4fd1c2b7a37367e61bbae3d27d194a894cb7bb/tensorflow/python/estimator/training.py#L747-L748\r\n\r\nI was wondering if it would be possible to make this part of the `train_and_evaluate` contract public or, alternatively, address the issue in another way?"}