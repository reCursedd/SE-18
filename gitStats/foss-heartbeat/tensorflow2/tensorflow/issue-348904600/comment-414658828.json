{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/414658828", "html_url": "https://github.com/tensorflow/tensorflow/issues/21492#issuecomment-414658828", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21492", "id": 414658828, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNDY1ODgyOA==", "user": {"login": "superbobry", "id": 185856, "node_id": "MDQ6VXNlcjE4NTg1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/185856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/superbobry", "html_url": "https://github.com/superbobry", "followers_url": "https://api.github.com/users/superbobry/followers", "following_url": "https://api.github.com/users/superbobry/following{/other_user}", "gists_url": "https://api.github.com/users/superbobry/gists{/gist_id}", "starred_url": "https://api.github.com/users/superbobry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/superbobry/subscriptions", "organizations_url": "https://api.github.com/users/superbobry/orgs", "repos_url": "https://api.github.com/users/superbobry/repos", "events_url": "https://api.github.com/users/superbobry/events{/privacy}", "received_events_url": "https://api.github.com/users/superbobry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-21T12:37:25Z", "updated_at": "2018-08-21T12:37:25Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1184671\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiejw\">@xiejw</a> the problem with YARN is that it does not manage the network, i.e. there is no way to reserve a port prior to submitting an application. One possible solution to this is to</p>\n<ol>\n<li>Spawn a Python process in each YARN container.</li>\n<li>Bind to port 0.</li>\n<li>Communicate the port assigned by the OS to all other containers and aggregate a cluster spec</li>\n<li>Export the spec in <code>TF_CONFIG</code> and start training.</li>\n</ol>\n<p>which roughly translates to</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> socket.socket(socket.<span class=\"pl-c1\">AF_INET</span>, socket.<span class=\"pl-c1\">SOCK_STREAM</span>) <span class=\"pl-k\">as</span> sock:\n    sock.bind((<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0</span>))\n    ipaddr, port <span class=\"pl-k\">=</span> sock.getsockname()\n    cluster_spec <span class=\"pl-k\">=</span> broadcast_addr_and_aggregate_spec(<span class=\"pl-s\">f</span><span class=\"pl-pds\">\"</span><span class=\"pl-c1\">{</span>ipaddr<span class=\"pl-c1\">}</span><span class=\"pl-s\">:</span><span class=\"pl-c1\">{</span>port<span class=\"pl-c1\">}</span><span class=\"pl-pds\">\"</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> export TF_CONFIG</span>\ntf.estimator.train_and_evaluate(<span class=\"pl-c1\">...</span>)</pre></div>\n<p>Note that this implementation has a race condition between closing <code>sock</code> and binding a <code>tf.train.Server</code> to the reserved port. This means that a task from another distributed TF training running on the same YARN node could hijack the port, and effectively talk to a completely unrelated task. The window of opportunity for the race condition to occur is undefined and depends on the implementation of <code>train_and_evaluate</code>.</p>\n<p>I see multiple potential ways of getting rid of the race condition by slightly modifying the existing Python/C++ API of <code>tf.train.Server</code>:</p>\n<ul>\n<li>Add an API to spawn a server using an existing FD. The gRPC backend seems to already support this (see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"155142789\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/grpc/grpc/issues/6610\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/grpc/grpc/pull/6610/hovercard\" href=\"https://github.com/grpc/grpc/pull/6610\">grpc/grpc#6610</a>).</li>\n<li>Allow <code>SO_REUSEPORT</code> when creating a server. Currently the option is <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc#L191\">explicitly disabled</a>.</li>\n</ul>", "body_text": "@xiejw the problem with YARN is that it does not manage the network, i.e. there is no way to reserve a port prior to submitting an application. One possible solution to this is to\n\nSpawn a Python process in each YARN container.\nBind to port 0.\nCommunicate the port assigned by the OS to all other containers and aggregate a cluster spec\nExport the spec in TF_CONFIG and start training.\n\nwhich roughly translates to\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n    sock.bind((\"\", 0))\n    ipaddr, port = sock.getsockname()\n    cluster_spec = broadcast_addr_and_aggregate_spec(f\"{ipaddr}:{port}\")\n\n# export TF_CONFIG\ntf.estimator.train_and_evaluate(...)\nNote that this implementation has a race condition between closing sock and binding a tf.train.Server to the reserved port. This means that a task from another distributed TF training running on the same YARN node could hijack the port, and effectively talk to a completely unrelated task. The window of opportunity for the race condition to occur is undefined and depends on the implementation of train_and_evaluate.\nI see multiple potential ways of getting rid of the race condition by slightly modifying the existing Python/C++ API of tf.train.Server:\n\nAdd an API to spawn a server using an existing FD. The gRPC backend seems to already support this (see grpc/grpc#6610).\nAllow SO_REUSEPORT when creating a server. Currently the option is explicitly disabled.", "body": "@xiejw the problem with YARN is that it does not manage the network, i.e. there is no way to reserve a port prior to submitting an application. One possible solution to this is to\r\n\r\n1. Spawn a Python process in each YARN container.\r\n2. Bind to port 0.\r\n3. Communicate the port assigned by the OS to all other containers and aggregate a cluster spec\r\n4. Export the spec in `TF_CONFIG` and start training.\r\n\r\nwhich roughly translates to\r\n\r\n```python\r\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\r\n    sock.bind((\"\", 0))\r\n    ipaddr, port = sock.getsockname()\r\n    cluster_spec = broadcast_addr_and_aggregate_spec(f\"{ipaddr}:{port}\")\r\n\r\n# export TF_CONFIG\r\ntf.estimator.train_and_evaluate(...)\r\n```\r\n\r\nNote that this implementation has a race condition between closing `sock` and binding a `tf.train.Server` to the reserved port. This means that a task from another distributed TF training running on the same YARN node could hijack the port, and effectively talk to a completely unrelated task. The window of opportunity for the race condition to occur is undefined and depends on the implementation of `train_and_evaluate`. \r\n\r\nI see multiple potential ways of getting rid of the race condition by slightly modifying the existing Python/C++ API of `tf.train.Server`:\r\n\r\n* Add an API to spawn a server using an existing FD. The gRPC backend seems to already support this (see grpc/grpc#6610). \r\n* Allow `SO_REUSEPORT` when creating a server. Currently the option is [explicitly disabled](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc#L191)."}