{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21328", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21328/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21328/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21328/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21328", "id": 346895915, "node_id": "MDU6SXNzdWUzNDY4OTU5MTU=", "number": 21328, "title": "FusedBatchNorm of TF 1.9 doesn't work fine ", "user": {"login": "haifenghan", "id": 4157827, "node_id": "MDQ6VXNlcjQxNTc4Mjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4157827?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haifenghan", "html_url": "https://github.com/haifenghan", "followers_url": "https://api.github.com/users/haifenghan/followers", "following_url": "https://api.github.com/users/haifenghan/following{/other_user}", "gists_url": "https://api.github.com/users/haifenghan/gists{/gist_id}", "starred_url": "https://api.github.com/users/haifenghan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haifenghan/subscriptions", "organizations_url": "https://api.github.com/users/haifenghan/orgs", "repos_url": "https://api.github.com/users/haifenghan/repos", "events_url": "https://api.github.com/users/haifenghan/events{/privacy}", "received_events_url": "https://api.github.com/users/haifenghan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-08-02T07:42:34Z", "updated_at": "2018-11-15T19:03:18Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>After importing the frozen model <a href=\"https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz\" rel=\"nofollow\">mobilenet_v2_1.0_224</a>, I find there are 4 outputs of FusedBatchNorm operation and I can't eval() other 3 tensors:</p>\n<h3>System information</h3>\n<ul>\n<li>**Ubuntu 18.04 desktop</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary(pip)</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 2.7.15rc1</li>\n<li><strong>CUDA/cuDNN version</strong>: CPU only</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>ipdb&gt; batch_norm = tf.get_default_graph().get_operation_by_name('MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm')                  \nipdb&gt; batch_norm.outputs\n[&lt;tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:0' shape=(1, 112, 112, 32) dtype=float32&gt;, &lt;tf.Tensor 'MobilenetV2/expan\nded_conv/depthwise/BatchNorm/FusedBatchNorm:1' shape=(32,) dtype=float32&gt;, &lt;tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNor\nm:2' shape=(32,) dtype=float32&gt;, &lt;tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:3' shape=(32,) dtype=float32&gt;, &lt;tf.Tenso\nr 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:4' shape=(32,) dtype=float32&gt;]                                                   \nipdb&gt; batch_norm.outputs[1].eval()\nOptimizing fused batch norm node name: \"MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm\"                                            \nop: \"FusedBatchNorm\"\ninput: \"MobilenetV2/expanded_conv/depthwise/depthwise\"\ninput: \"Const_198\"                                                                                                                               \ninput: \"Const_37\"\ninput: \"Const_138\"\ninput: \"Const_120\"\ndevice: \"/job:localhost/replica:0/task:0/device:CPU:0\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"data_format\"\n  value {\n    s: \"NHWC\"\n  }\n}\nattr {\n  key: \"epsilon\"\n  value {\n    f: 0.001\n  }\n}\nattr {\n  key: \"is_training\"\n  value {\n    b: false\n  }\n}\n\n*** InvalidArgumentError: FetchOutputs MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:1: output index too large, must be &lt; 1\n\n</code></pre>\n<p>BTW, TensorFlow 1.8 works fine.</p>", "body_text": "After importing the frozen model mobilenet_v2_1.0_224, I find there are 4 outputs of FusedBatchNorm operation and I can't eval() other 3 tensors:\nSystem information\n\n**Ubuntu 18.04 desktop\nTensorFlow installed from (source or binary): binary(pip)\nTensorFlow version (use command below): 1.9\nPython version: 2.7.15rc1\nCUDA/cuDNN version: CPU only\nExact command to reproduce:\n\nipdb> batch_norm = tf.get_default_graph().get_operation_by_name('MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm')                  \nipdb> batch_norm.outputs\n[<tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:0' shape=(1, 112, 112, 32) dtype=float32>, <tf.Tensor 'MobilenetV2/expan\nded_conv/depthwise/BatchNorm/FusedBatchNorm:1' shape=(32,) dtype=float32>, <tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNor\nm:2' shape=(32,) dtype=float32>, <tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:3' shape=(32,) dtype=float32>, <tf.Tenso\nr 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:4' shape=(32,) dtype=float32>]                                                   \nipdb> batch_norm.outputs[1].eval()\nOptimizing fused batch norm node name: \"MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm\"                                            \nop: \"FusedBatchNorm\"\ninput: \"MobilenetV2/expanded_conv/depthwise/depthwise\"\ninput: \"Const_198\"                                                                                                                               \ninput: \"Const_37\"\ninput: \"Const_138\"\ninput: \"Const_120\"\ndevice: \"/job:localhost/replica:0/task:0/device:CPU:0\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"data_format\"\n  value {\n    s: \"NHWC\"\n  }\n}\nattr {\n  key: \"epsilon\"\n  value {\n    f: 0.001\n  }\n}\nattr {\n  key: \"is_training\"\n  value {\n    b: false\n  }\n}\n\n*** InvalidArgumentError: FetchOutputs MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:1: output index too large, must be < 1\n\n\nBTW, TensorFlow 1.8 works fine.", "body": "After importing the frozen model [mobilenet_v2_1.0_224](https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz), I find there are 4 outputs of FusedBatchNorm operation and I can't eval() other 3 tensors:\r\n\r\n### System information\r\n- **Ubuntu 18.04 desktop\r\n- **TensorFlow installed from (source or binary)**: binary(pip)\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 2.7.15rc1\r\n- **CUDA/cuDNN version**: CPU only\r\n- **Exact command to reproduce**:\r\n```\r\nipdb> batch_norm = tf.get_default_graph().get_operation_by_name('MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm')                  \r\nipdb> batch_norm.outputs\r\n[<tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:0' shape=(1, 112, 112, 32) dtype=float32>, <tf.Tensor 'MobilenetV2/expan\r\nded_conv/depthwise/BatchNorm/FusedBatchNorm:1' shape=(32,) dtype=float32>, <tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNor\r\nm:2' shape=(32,) dtype=float32>, <tf.Tensor 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:3' shape=(32,) dtype=float32>, <tf.Tenso\r\nr 'MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:4' shape=(32,) dtype=float32>]                                                   \r\nipdb> batch_norm.outputs[1].eval()\r\nOptimizing fused batch norm node name: \"MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm\"                                            \r\nop: \"FusedBatchNorm\"\r\ninput: \"MobilenetV2/expanded_conv/depthwise/depthwise\"\r\ninput: \"Const_198\"                                                                                                                               \r\ninput: \"Const_37\"\r\ninput: \"Const_138\"\r\ninput: \"Const_120\"\r\ndevice: \"/job:localhost/replica:0/task:0/device:CPU:0\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"data_format\"\r\n  value {\r\n    s: \"NHWC\"\r\n  }\r\n}\r\nattr {\r\n  key: \"epsilon\"\r\n  value {\r\n    f: 0.001\r\n  }\r\n}\r\nattr {\r\n  key: \"is_training\"\r\n  value {\r\n    b: false\r\n  }\r\n}\r\n\r\n*** InvalidArgumentError: FetchOutputs MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm:1: output index too large, must be < 1\r\n\r\n```\r\n\r\nBTW, TensorFlow 1.8 works fine."}