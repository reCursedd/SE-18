{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/413346347", "html_url": "https://github.com/tensorflow/tensorflow/issues/21328#issuecomment-413346347", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21328", "id": 413346347, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzM0NjM0Nw==", "user": {"login": "marksandler2", "id": 6980056, "node_id": "MDQ6VXNlcjY5ODAwNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/6980056?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marksandler2", "html_url": "https://github.com/marksandler2", "followers_url": "https://api.github.com/users/marksandler2/followers", "following_url": "https://api.github.com/users/marksandler2/following{/other_user}", "gists_url": "https://api.github.com/users/marksandler2/gists{/gist_id}", "starred_url": "https://api.github.com/users/marksandler2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marksandler2/subscriptions", "organizations_url": "https://api.github.com/users/marksandler2/orgs", "repos_url": "https://api.github.com/users/marksandler2/repos", "events_url": "https://api.github.com/users/marksandler2/events{/privacy}", "received_events_url": "https://api.github.com/users/marksandler2/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-15T21:38:51Z", "updated_at": "2018-08-15T21:38:51Z", "author_association": "NONE", "body_html": "<p>See my comment above.</p>\n<p>There is no second-and-third output in FusedBatchNorm operator when created in evaluation mode (which is what frozen proto contains).<br>\nSo you get out-of-range error because there is no such node,  this is working as expected.</p>\n<p>If you want to create network in training mode you need to use the python code and restore from checkpoint. But even then it is unclear what yo uare trying to do.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> nets.mobilenet <span class=\"pl-k\">import</span> mobilenet_v2\n\ntf.reset_default_graph()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> For simplicity we just decode jpeg inside tensorflow.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> But one can provide any input obviously.</span>\nfile_input <span class=\"pl-k\">=</span> tf.placeholder(tf.string, ())\n\nimage <span class=\"pl-k\">=</span> tf.image.decode_jpeg(tf.read_file(file_input))\n\nimages <span class=\"pl-k\">=</span> tf.expand_dims(image, <span class=\"pl-c1\">0</span>)\nimages <span class=\"pl-k\">=</span> tf.cast(images, tf.float32) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">128</span>.  <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\nimages.set_shape((<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">3</span>))\nimages <span class=\"pl-k\">=</span> tf.image.resize_images(images, (<span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Note: arg_scope is optional for inference.</span>\n<span class=\"pl-k\">with</span> tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(<span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)):\n  logits, endpoints <span class=\"pl-k\">=</span> mobilenet_v2.mobilenet(images)\n  \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Restore using exponential moving average since it produces (1.5-2%) higher </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> accuracy</span>\nema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-c1\">0.999</span>)\n<span class=\"pl-c1\">vars</span> <span class=\"pl-k\">=</span> ema.variables_to_restore()\n\nsaver <span class=\"pl-k\">=</span> tf.train.Saver(<span class=\"pl-c1\">vars</span>)  \n<span class=\"pl-k\">from</span> IPython <span class=\"pl-k\">import</span> display\n<span class=\"pl-k\">import</span> pylab\n<span class=\"pl-k\">from</span> datasets <span class=\"pl-k\">import</span> imagenet\n<span class=\"pl-k\">import</span> <span class=\"pl-c1\">PIL</span>\ndisplay.display(display.Image(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>panda.jpg<span class=\"pl-pds\">'</span></span>))\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  saver.restore(sess,  checkpoint)\n  x <span class=\"pl-k\">=</span> endpoints[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Predictions<span class=\"pl-pds\">'</span></span>].eval(<span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{file_input: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>panda.jpg<span class=\"pl-pds\">'</span></span>})\nlabel_map <span class=\"pl-k\">=</span> imagenet.create_readable_names_for_imagenet_labels()  \n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Top 1 prediction: <span class=\"pl-pds\">\"</span></span>, x.argmax(),label_map[x.argmax()], x.max())\n\n</pre></div>\n<p>If you need further help, please explain what are you trying to do.</p>", "body_text": "See my comment above.\nThere is no second-and-third output in FusedBatchNorm operator when created in evaluation mode (which is what frozen proto contains).\nSo you get out-of-range error because there is no such node,  this is working as expected.\nIf you want to create network in training mode you need to use the python code and restore from checkpoint. But even then it is unclear what yo uare trying to do.\nimport tensorflow as tf\nfrom nets.mobilenet import mobilenet_v2\n\ntf.reset_default_graph()\n\n# For simplicity we just decode jpeg inside tensorflow.\n# But one can provide any input obviously.\nfile_input = tf.placeholder(tf.string, ())\n\nimage = tf.image.decode_jpeg(tf.read_file(file_input))\n\nimages = tf.expand_dims(image, 0)\nimages = tf.cast(images, tf.float32) / 128.  - 1\nimages.set_shape((None, None, None, 3))\nimages = tf.image.resize_images(images, (224, 224))\n\n# Note: arg_scope is optional for inference.\nwith tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):\n  logits, endpoints = mobilenet_v2.mobilenet(images)\n  \n# Restore using exponential moving average since it produces (1.5-2%) higher \n# accuracy\nema = tf.train.ExponentialMovingAverage(0.999)\nvars = ema.variables_to_restore()\n\nsaver = tf.train.Saver(vars)  \nfrom IPython import display\nimport pylab\nfrom datasets import imagenet\nimport PIL\ndisplay.display(display.Image('panda.jpg'))\n\nwith tf.Session() as sess:\n  saver.restore(sess,  checkpoint)\n  x = endpoints['Predictions'].eval(feed_dict={file_input: 'panda.jpg'})\nlabel_map = imagenet.create_readable_names_for_imagenet_labels()  \nprint(\"Top 1 prediction: \", x.argmax(),label_map[x.argmax()], x.max())\n\n\nIf you need further help, please explain what are you trying to do.", "body": "See my comment above.\r\n\r\nThere is no second-and-third output in FusedBatchNorm operator when created in evaluation mode (which is what frozen proto contains).  \r\nSo you get out-of-range error because there is no such node,  this is working as expected. \r\n\r\nIf you want to create network in training mode you need to use the python code and restore from checkpoint. But even then it is unclear what yo uare trying to do. \r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom nets.mobilenet import mobilenet_v2\r\n\r\ntf.reset_default_graph()\r\n\r\n# For simplicity we just decode jpeg inside tensorflow.\r\n# But one can provide any input obviously.\r\nfile_input = tf.placeholder(tf.string, ())\r\n\r\nimage = tf.image.decode_jpeg(tf.read_file(file_input))\r\n\r\nimages = tf.expand_dims(image, 0)\r\nimages = tf.cast(images, tf.float32) / 128.  - 1\r\nimages.set_shape((None, None, None, 3))\r\nimages = tf.image.resize_images(images, (224, 224))\r\n\r\n# Note: arg_scope is optional for inference.\r\nwith tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):\r\n  logits, endpoints = mobilenet_v2.mobilenet(images)\r\n  \r\n# Restore using exponential moving average since it produces (1.5-2%) higher \r\n# accuracy\r\nema = tf.train.ExponentialMovingAverage(0.999)\r\nvars = ema.variables_to_restore()\r\n\r\nsaver = tf.train.Saver(vars)  \r\nfrom IPython import display\r\nimport pylab\r\nfrom datasets import imagenet\r\nimport PIL\r\ndisplay.display(display.Image('panda.jpg'))\r\n\r\nwith tf.Session() as sess:\r\n  saver.restore(sess,  checkpoint)\r\n  x = endpoints['Predictions'].eval(feed_dict={file_input: 'panda.jpg'})\r\nlabel_map = imagenet.create_readable_names_for_imagenet_labels()  \r\nprint(\"Top 1 prediction: \", x.argmax(),label_map[x.argmax()], x.max())\r\n\r\n\r\n```\r\n\r\n\r\n\r\nIf you need further help, please explain what are you trying to do. "}