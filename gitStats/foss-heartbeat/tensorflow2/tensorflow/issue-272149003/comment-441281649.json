{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/441281649", "html_url": "https://github.com/tensorflow/tensorflow/issues/14357#issuecomment-441281649", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14357", "id": 441281649, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTI4MTY0OQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-23T16:32:05Z", "updated_at": "2018-11-23T16:32:05Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">+Francois Chollet &lt;fchollet@google.com&gt; the keras batchnorm layer needs an\noption to work via control dependencies.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Nov 23, 2018, 12:02 AM Joshua Chia ***@***.*** wrote:\n\n    1.\n\n    How is the workaround with tf.contrib.layers.batch_norm using\n    updates_collection=None supposed to work exactly? Does it update the\n    batch norm stats with the input iff is_training is True? If it updates\n    the batch norm stats on every input, even when is_training is False,\n    then it's a poor workaround. I can't tell the exact behavior from reading\n    the docs, with just says \"one can set updates_collections=None to force the\n    updates in place\".\n    2.\n\n    I have a similar problem using a modified version\n    &lt;<a href=\"https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4\">https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4</a>&gt; of\n    the <a class=\"user-mention\" href=\"https://github.com/naktinis\">@naktinis</a> &lt;<a href=\"https://github.com/naktinis&gt;'s\">https://github.com/naktinis&gt;'s</a> gist\n    &lt;<a href=\"https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528\">https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528</a>&gt;\n    using Keras layers. I was able to make the problem go away by applying the\n    tf.contrib.layers.batch_norm workaround. So, is the official\n    prescription to never use a recurrent layer followed by a batch norm layers\n    other than a tf.contrib.layers.batch_norm with updates_collections=None?\n    Is it OK to mix Keras layers with non-Keras layers like those from\n    tf.contrib.layers? However, isn't tf.contrib going away with TF 2.0? How\n    should the current problem be addressed then?\n\n \u2014\n You are receiving this because you modified the open/close state.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"272149003\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14357\" href=\"https://github.com/tensorflow/tensorflow/issues/14357#issuecomment-441174532\">#14357 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim8vrBaoFIjuk2SvWF10cr6a7zPOhks5ux6ukgaJpZM4QWKkb\">https://github.com/notifications/unsubscribe-auth/ABtim8vrBaoFIjuk2SvWF10cr6a7zPOhks5ux6ukgaJpZM4QWKkb</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "+Francois Chollet <fchollet@google.com> the keras batchnorm layer needs an\noption to work via control dependencies.\n\u2026\nOn Fri, Nov 23, 2018, 12:02 AM Joshua Chia ***@***.*** wrote:\n\n    1.\n\n    How is the workaround with tf.contrib.layers.batch_norm using\n    updates_collection=None supposed to work exactly? Does it update the\n    batch norm stats with the input iff is_training is True? If it updates\n    the batch norm stats on every input, even when is_training is False,\n    then it's a poor workaround. I can't tell the exact behavior from reading\n    the docs, with just says \"one can set updates_collections=None to force the\n    updates in place\".\n    2.\n\n    I have a similar problem using a modified version\n    <https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4> of\n    the @naktinis <https://github.com/naktinis>'s gist\n    <https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528>\n    using Keras layers. I was able to make the problem go away by applying the\n    tf.contrib.layers.batch_norm workaround. So, is the official\n    prescription to never use a recurrent layer followed by a batch norm layers\n    other than a tf.contrib.layers.batch_norm with updates_collections=None?\n    Is it OK to mix Keras layers with non-Keras layers like those from\n    tf.contrib.layers? However, isn't tf.contrib going away with TF 2.0? How\n    should the current problem be addressed then?\n\n \u2014\n You are receiving this because you modified the open/close state.\n Reply to this email directly, view it on GitHub\n <#14357 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim8vrBaoFIjuk2SvWF10cr6a7zPOhks5ux6ukgaJpZM4QWKkb>\n .", "body": "+Francois Chollet <fchollet@google.com> the keras batchnorm layer needs an\noption to work via control dependencies.\n\nOn Fri, Nov 23, 2018, 12:02 AM Joshua Chia <notifications@github.com wrote:\n\n>\n>    1.\n>\n>    How is the workaround with tf.contrib.layers.batch_norm using\n>    updates_collection=None supposed to work exactly? Does it update the\n>    batch norm stats with the input iff is_training is True? If it updates\n>    the batch norm stats on every input, even when is_training is False,\n>    then it's a poor workaround. I can't tell the exact behavior from reading\n>    the docs, with just says \"one can set updates_collections=None to force the\n>    updates in place\".\n>    2.\n>\n>    I have a similar problem using a modified version\n>    <https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4> of\n>    the @naktinis <https://github.com/naktinis>'s gist\n>    <https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528>\n>    using Keras layers. I was able to make the problem go away by applying the\n>    tf.contrib.layers.batch_norm workaround. So, is the official\n>    prescription to never use a recurrent layer followed by a batch norm layers\n>    other than a tf.contrib.layers.batch_norm with updates_collections=None?\n>    Is it OK to mix Keras layers with non-Keras layers like those from\n>    tf.contrib.layers? However, isn't tf.contrib going away with TF 2.0? How\n>    should the current problem be addressed then?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14357#issuecomment-441174532>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8vrBaoFIjuk2SvWF10cr6a7zPOhks5ux6ukgaJpZM4QWKkb>\n> .\n>\n"}