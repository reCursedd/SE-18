{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19174", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19174/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19174/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19174/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19174", "id": 321458594, "node_id": "MDU6SXNzdWUzMjE0NTg1OTQ=", "number": 19174, "title": "GPU not used and failed call to cuInit: CUDA_ERROR_NO_DEVICE", "user": {"login": "PumayHui", "id": 28421690, "node_id": "MDQ6VXNlcjI4NDIxNjkw", "avatar_url": "https://avatars2.githubusercontent.com/u/28421690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PumayHui", "html_url": "https://github.com/PumayHui", "followers_url": "https://api.github.com/users/PumayHui/followers", "following_url": "https://api.github.com/users/PumayHui/following{/other_user}", "gists_url": "https://api.github.com/users/PumayHui/gists{/gist_id}", "starred_url": "https://api.github.com/users/PumayHui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PumayHui/subscriptions", "organizations_url": "https://api.github.com/users/PumayHui/orgs", "repos_url": "https://api.github.com/users/PumayHui/repos", "events_url": "https://api.github.com/users/PumayHui/events{/privacy}", "received_events_url": "https://api.github.com/users/PumayHui/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-09T07:22:25Z", "updated_at": "2018-06-25T19:01:17Z", "closed_at": "2018-06-25T19:01:17Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.4.0</li>\n<li><strong>Python version</strong>: 2.7.14</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:8.0/6.0</li>\n<li><strong>GPU model and memory</strong>:GeForce GTX 1080 Ti - 12GB</li>\n<li><strong>NVIDIA driver</strong>: 390.48</li>\n</ul>\n<p>Hi, when I test tensorflow in my machine, run such code :</p>\n<pre><code>import tensorflow as tf\nimport os\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\nsess = tf.Session()\nprint (sess.run(c))\nsess.close()\n</code></pre>\n<p>And output are as follow:</p>\n<pre><code>2018-05-09 14:01:26.787648: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787669: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787676: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787679: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.788347: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\n2018-05-09 14:01:26.788365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: axadl-System-Product-Name\n2018-05-09 14:01:26.788369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: axadl-System-Product-Name\n2018-05-09 14:01:26.788387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got \"1\"\n2018-05-09 14:01:26.788403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  390.48  Thu Mar 22 00:42:57 PDT 2018\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) \n\"\"\"\n2018-05-09 14:01:26.788413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 390.48.0\n[[22. 28.]\n [49. 64.]]\n</code></pre>\n<p>And I input \"nvidia-smi\":<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/28421690/39800867-e1919820-539b-11e8-8403-ea41e672f010.png\"><img src=\"https://user-images.githubusercontent.com/28421690/39800867-e1919820-539b-11e8-8403-ea41e672f010.png\" alt=\"default\" style=\"max-width:100%;\"></a><br>\nAnd I input \"nvcc -V\":<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/28421690/39800880-f265c450-539b-11e8-9f34-2ba41e1bc653.png\"><img src=\"https://user-images.githubusercontent.com/28421690/39800880-f265c450-539b-11e8-9f34-2ba41e1bc653.png\" alt=\"default\" style=\"max-width:100%;\"></a><br>\nThen I test cuda \"sudo ./1_Utilities/deviceQuery/deviceQuery\":</p>\n<pre><code>./1_Utilities/deviceQuery/deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1080 Ti\"\n  CUDA Driver Version / Runtime Version          9.1 / 8.0\n  CUDA Capability Major/Minor version number:    6.1\n  Total amount of global memory:                 11170 MBytes (11713052672 bytes)\n  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores\n  GPU Max Clock rate:                            1683 MHz (1.68 GHz)\n  Memory Clock rate:                             5505 Mhz\n  Memory Bus Width:                              352-bit\n  L2 Cache Size:                                 2883584 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.1, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080 Ti\nResult = PASS\n</code></pre>\n<p>In addition, I have tried <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"117323604\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/255\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/255/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/255\">#255</a>, but it still occur mistakes as above.<br>\nCan anyone help me?<br>\nThanks so much!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.4.0\nPython version: 2.7.14\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:8.0/6.0\nGPU model and memory:GeForce GTX 1080 Ti - 12GB\nNVIDIA driver: 390.48\n\nHi, when I test tensorflow in my machine, run such code :\nimport tensorflow as tf\nimport os\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\nsess = tf.Session()\nprint (sess.run(c))\nsess.close()\n\nAnd output are as follow:\n2018-05-09 14:01:26.787648: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787669: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787676: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.787679: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2018-05-09 14:01:26.788347: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\n2018-05-09 14:01:26.788365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: axadl-System-Product-Name\n2018-05-09 14:01:26.788369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: axadl-System-Product-Name\n2018-05-09 14:01:26.788387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got \"1\"\n2018-05-09 14:01:26.788403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  390.48  Thu Mar 22 00:42:57 PDT 2018\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) \n\"\"\"\n2018-05-09 14:01:26.788413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 390.48.0\n[[22. 28.]\n [49. 64.]]\n\nAnd I input \"nvidia-smi\":\n\nAnd I input \"nvcc -V\":\n\nThen I test cuda \"sudo ./1_Utilities/deviceQuery/deviceQuery\":\n./1_Utilities/deviceQuery/deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1080 Ti\"\n  CUDA Driver Version / Runtime Version          9.1 / 8.0\n  CUDA Capability Major/Minor version number:    6.1\n  Total amount of global memory:                 11170 MBytes (11713052672 bytes)\n  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores\n  GPU Max Clock rate:                            1683 MHz (1.68 GHz)\n  Memory Clock rate:                             5505 Mhz\n  Memory Bus Width:                              352-bit\n  L2 Cache Size:                                 2883584 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.1, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080 Ti\nResult = PASS\n\nIn addition, I have tried #255, but it still occur mistakes as above.\nCan anyone help me?\nThanks so much!", "body": "-----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.4.0\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:8.0/6.0\r\n- **GPU model and memory**:GeForce GTX 1080 Ti - 12GB\r\n- **NVIDIA driver**: 390.48\r\n\r\nHi, when I test tensorflow in my machine, run such code : \r\n```\r\nimport tensorflow as tf\r\nimport os\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\r\nsess = tf.Session()\r\nprint (sess.run(c))\r\nsess.close()\r\n```\r\nAnd output are as follow:\r\n```\r\n2018-05-09 14:01:26.787648: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2018-05-09 14:01:26.787669: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2018-05-09 14:01:26.787673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2018-05-09 14:01:26.787676: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2018-05-09 14:01:26.787679: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2018-05-09 14:01:26.788347: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n2018-05-09 14:01:26.788365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: axadl-System-Product-Name\r\n2018-05-09 14:01:26.788369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: axadl-System-Product-Name\r\n2018-05-09 14:01:26.788387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got \"1\"\r\n2018-05-09 14:01:26.788403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  390.48  Thu Mar 22 00:42:57 PDT 2018\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) \r\n\"\"\"\r\n2018-05-09 14:01:26.788413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 390.48.0\r\n[[22. 28.]\r\n [49. 64.]]\r\n```\r\n\r\nAnd I input \"nvidia-smi\":\r\n![default](https://user-images.githubusercontent.com/28421690/39800867-e1919820-539b-11e8-8403-ea41e672f010.png)\r\nAnd I input \"nvcc -V\":\r\n![default](https://user-images.githubusercontent.com/28421690/39800880-f265c450-539b-11e8-9f34-2ba41e1bc653.png)\r\nThen I test cuda \"sudo ./1_Utilities/deviceQuery/deviceQuery\": \r\n```\r\n./1_Utilities/deviceQuery/deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 1080 Ti\"\r\n  CUDA Driver Version / Runtime Version          9.1 / 8.0\r\n  CUDA Capability Major/Minor version number:    6.1\r\n  Total amount of global memory:                 11170 MBytes (11713052672 bytes)\r\n  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores\r\n  GPU Max Clock rate:                            1683 MHz (1.68 GHz)\r\n  Memory Clock rate:                             5505 Mhz\r\n  Memory Bus Width:                              352-bit\r\n  L2 Cache Size:                                 2883584 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.1, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080 Ti\r\nResult = PASS\r\n```\r\n\r\nIn addition, I have tried https://github.com/tensorflow/tensorflow/issues/255, but it still occur mistakes as above.\r\nCan anyone help me?\r\nThanks so much!"}