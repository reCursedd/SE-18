{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15694", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15694/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15694/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15694/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15694", "id": 284919902, "node_id": "MDU6SXNzdWUyODQ5MTk5MDI=", "number": 15694, "title": "Latency of simple tf.data.Dataset transformations is higher than raw Python", "user": {"login": "Anjum48", "id": 13783303, "node_id": "MDQ6VXNlcjEzNzgzMzAz", "avatar_url": "https://avatars1.githubusercontent.com/u/13783303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Anjum48", "html_url": "https://github.com/Anjum48", "followers_url": "https://api.github.com/users/Anjum48/followers", "following_url": "https://api.github.com/users/Anjum48/following{/other_user}", "gists_url": "https://api.github.com/users/Anjum48/gists{/gist_id}", "starred_url": "https://api.github.com/users/Anjum48/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Anjum48/subscriptions", "organizations_url": "https://api.github.com/users/Anjum48/orgs", "repos_url": "https://api.github.com/users/Anjum48/repos", "events_url": "https://api.github.com/users/Anjum48/events{/privacy}", "received_events_url": "https://api.github.com/users/Anjum48/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-12-28T13:58:01Z", "updated_at": "2018-07-02T23:23:42Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip install tensorflow (CPU only)</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-rc1-11-g130a514 1.4.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to improve performance by moving to <code>tf.data.Datasets</code> to manage epochs and minibatches (particularly I/O performance on a GPU when I come to scaling up). However I'm finding that this is much slower than just using nested <code>for</code> loops in Python.</p>\n<h3>Source code / logs</h3>\n<p>Here's an example using a dataset with 10,000 numbers, 10 epochs and a minibatch size of 100:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> time <span class=\"pl-k\">import</span> time\n\n<span class=\"pl-c1\">MINI_BATCH</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n<span class=\"pl-c1\">EPOCHS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Dataset consisting of 10000 random numbers</span>\nraw_data <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">10000</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Raw Python implementation</span>\nstart <span class=\"pl-k\">=</span> time()\nsplit_data <span class=\"pl-k\">=</span> np.split(raw_data, <span class=\"pl-c1\">10000</span> <span class=\"pl-k\">//</span> <span class=\"pl-c1\">MINI_BATCH</span>)\n\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">EPOCHS</span>):\n    <span class=\"pl-k\">for</span> i, batch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(split_data):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Do stuff with batch data</span>\n        x <span class=\"pl-k\">=</span> batch <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Raw Python done in<span class=\"pl-pds\">\"</span></span>, time() <span class=\"pl-k\">-</span> start)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> TensorFlow implementation</span>\nstart <span class=\"pl-k\">=</span> time()\ndataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(raw_data)\ndataset <span class=\"pl-k\">=</span> dataset.repeat(<span class=\"pl-c1\">EPOCHS</span>)\ndataset <span class=\"pl-k\">=</span> dataset.batch(<span class=\"pl-c1\">MINI_BATCH</span>)\niterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\nnext_chunk <span class=\"pl-k\">=</span> iterator.get_next()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        <span class=\"pl-k\">try</span>:\n            batch <span class=\"pl-k\">=</span> sess.run(next_chunk)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Do stuff with batch data</span>\n            x <span class=\"pl-k\">=</span> batch <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span>\n        <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError:\n            <span class=\"pl-k\">break</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>TensorFlow done in<span class=\"pl-pds\">\"</span></span>, time() <span class=\"pl-k\">-</span> start)\n</pre></div>\n<p>Output:</p>\n<pre><code>Raw Python done in 0.0011773109436035156\nTensorFlow done in 0.14212393760681152\n</code></pre>\n<p>Does anyone know why this might be the case?</p>\n<p>I'm guessing that most of the overhead is in the evaluation of <code>iterator.get_next()</code> on every loop. If this is not supposed to be evaluated it would be useful to have some examples of how it should be used without using <code>sess.run</code> each time.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): pip install tensorflow (CPU only)\nTensorFlow version (use command below): v1.4.0-rc1-11-g130a514 1.4.0\nPython version: 3.5.2\n\nDescribe the problem\nI'm trying to improve performance by moving to tf.data.Datasets to manage epochs and minibatches (particularly I/O performance on a GPU when I come to scaling up). However I'm finding that this is much slower than just using nested for loops in Python.\nSource code / logs\nHere's an example using a dataset with 10,000 numbers, 10 epochs and a minibatch size of 100:\nimport tensorflow as tf\nimport numpy as np\nfrom time import time\n\nMINI_BATCH = 100\nEPOCHS = 10\n\n# Dataset consisting of 10000 random numbers\nraw_data = np.random.randn(10000)\n\n# Raw Python implementation\nstart = time()\nsplit_data = np.split(raw_data, 10000 // MINI_BATCH)\n\nfor _ in range(EPOCHS):\n    for i, batch in enumerate(split_data):\n        # Do stuff with batch data\n        x = batch * 2\nprint(\"Raw Python done in\", time() - start)\n\n\n# TensorFlow implementation\nstart = time()\ndataset = tf.data.Dataset.from_tensor_slices(raw_data)\ndataset = dataset.repeat(EPOCHS)\ndataset = dataset.batch(MINI_BATCH)\niterator = dataset.make_one_shot_iterator()\nnext_chunk = iterator.get_next()\n\nwith tf.Session() as sess:\n    while True:\n        try:\n            batch = sess.run(next_chunk)\n            # Do stuff with batch data\n            x = batch * 2\n        except tf.errors.OutOfRangeError:\n            break\nprint(\"TensorFlow done in\", time() - start)\n\nOutput:\nRaw Python done in 0.0011773109436035156\nTensorFlow done in 0.14212393760681152\n\nDoes anyone know why this might be the case?\nI'm guessing that most of the overhead is in the evaluation of iterator.get_next() on every loop. If this is not supposed to be evaluated it would be useful to have some examples of how it should be used without using sess.run each time.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow (CPU only)\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.5.2\r\n\r\n### Describe the problem\r\nI'm trying to improve performance by moving to `tf.data.Datasets` to manage epochs and minibatches (particularly I/O performance on a GPU when I come to scaling up). However I'm finding that this is much slower than just using nested `for` loops in Python.\r\n\r\n### Source code / logs\r\nHere's an example using a dataset with 10,000 numbers, 10 epochs and a minibatch size of 100:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom time import time\r\n\r\nMINI_BATCH = 100\r\nEPOCHS = 10\r\n\r\n# Dataset consisting of 10000 random numbers\r\nraw_data = np.random.randn(10000)\r\n\r\n# Raw Python implementation\r\nstart = time()\r\nsplit_data = np.split(raw_data, 10000 // MINI_BATCH)\r\n\r\nfor _ in range(EPOCHS):\r\n    for i, batch in enumerate(split_data):\r\n        # Do stuff with batch data\r\n        x = batch * 2\r\nprint(\"Raw Python done in\", time() - start)\r\n\r\n\r\n# TensorFlow implementation\r\nstart = time()\r\ndataset = tf.data.Dataset.from_tensor_slices(raw_data)\r\ndataset = dataset.repeat(EPOCHS)\r\ndataset = dataset.batch(MINI_BATCH)\r\niterator = dataset.make_one_shot_iterator()\r\nnext_chunk = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    while True:\r\n        try:\r\n            batch = sess.run(next_chunk)\r\n            # Do stuff with batch data\r\n            x = batch * 2\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\nprint(\"TensorFlow done in\", time() - start)\r\n\r\n```\r\nOutput:\r\n```\r\nRaw Python done in 0.0011773109436035156\r\nTensorFlow done in 0.14212393760681152\r\n```\r\n\r\nDoes anyone know why this might be the case? \r\n\r\nI'm guessing that most of the overhead is in the evaluation of `iterator.get_next()` on every loop. If this is not supposed to be evaluated it would be useful to have some examples of how it should be used without using `sess.run` each time.\r\n"}