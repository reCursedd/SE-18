{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1341", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1341/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1341/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1341/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1341", "id": 137501705, "node_id": "MDU6SXNzdWUxMzc1MDE3MDU=", "number": 1341, "title": "cifar10_eval.py stop problem", "user": {"login": "j-pong", "id": 8243267, "node_id": "MDQ6VXNlcjgyNDMyNjc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8243267?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-pong", "html_url": "https://github.com/j-pong", "followers_url": "https://api.github.com/users/j-pong/followers", "following_url": "https://api.github.com/users/j-pong/following{/other_user}", "gists_url": "https://api.github.com/users/j-pong/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-pong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-pong/subscriptions", "organizations_url": "https://api.github.com/users/j-pong/orgs", "repos_url": "https://api.github.com/users/j-pong/repos", "events_url": "https://api.github.com/users/j-pong/events{/privacy}", "received_events_url": "https://api.github.com/users/j-pong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-03-01T07:54:47Z", "updated_at": "2016-03-08T01:07:53Z", "closed_at": "2016-03-08T01:07:53Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04.4 LTS</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.<br>\n: tensorflow-0.7.1-cp27-none-linux_x86_64.whl</li>\n<li>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".<br>\n: 0.7.1</li>\n</ol>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>cd git/tensorflow/tensorflow/models/image/cifar10/</li>\n<li>python cifar10_eval.py</li>\n</ol>\n<p>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally<br>\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX 980 Ti<br>\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.3545<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 6.00GiB<br>\nFree memory: 5.56GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB</p>\n<p>and stop this line.</p>\n<p>but sometimes not stop this line when run same as above. and</p>\n<p>==========check3.25==========<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.27GiB bytes.<br>\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x857ab6000<br>\n==========check3.5==========<br>\n==========check3.75==========<br>\n==========check3.25==========</p>\n<p>.<br>\n.<br>\n.</p>\n<p>==========check3.25==========<br>\n==========check3.5==========<br>\n==========check3.75==========<br>\n2016-03-01 15:41:09.935657: precision @ 1 = 0.801<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb37405e7b0 Compute status: Cancelled: Enqueue operation was cancelled<br>\n[[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]<br>\nI tensorflow/core/kernels/queue_base.cc:286] Skipping cancelled enqueue attempt<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb350035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36403ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3223f5240 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb35c03ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb338035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36c00c600 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb354035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb340035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb34c035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3480095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33000c470 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb370011050 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb328010190 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3600095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb358035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33c05b3b0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.<br>\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]</p>\n<h3>What have you tried?</h3>\n<ol>\n<li>Add some instruction for checking stop point.</li>\n</ol>\n<p>cifar10_eval.py</p>\n<p>def eval_once(saver, summary_writer, top_k_op, summary_op):</p>\n<pre><code># Start the queue runners.\ncoord = tf.train.Coordinator()\ntry:\n  threads = []\n  for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n    threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n                                     start=True))\n  num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n  true_count = 0  # Counts the number of correct predictions.\n  total_sample_count = num_iter * FLAGS.batch_size\n  step = 0\n  while step &lt; num_iter and not coord.should_stop():\n    print(\"==========check3.25==========\")\n    predictions = sess.run([top_k_op])\n    print(\"==========check3.5==========\")\n    true_count += np.sum(predictions)\n    step += 1\n    print(\"==========check3.75==========\")\n\n  # Compute precision @ 1.\n  precision = true_count / total_sample_count\n  print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n\n  summary = tf.Summary()\n  summary.ParseFromString(sess.run(summary_op))\n  summary.value.add(tag='Precision @ 1', simple_value=precision)\n  summary_writer.add_summary(summary, global_step)\nexcept Exception as e:  # pylint: disable=broad-except\n  coord.request_stop(e)\n\ncoord.request_stop()\ncoord.join(threads, stop_grace_period_secs=10)\n</code></pre>\n<p>look like <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"119755298\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/389\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/389/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/389\">#389</a> issue but different. and many time stop</p>\n<p>predictions = sess.run([top_k_op])</p>\n<p>this line.</p>", "body_text": "Environment info\nOperating System: Ubuntu 14.04.4 LTS\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\n: tensorflow-0.7.1-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\n: 0.7.1\n\nSteps to reproduce\n\ncd git/tensorflow/tensorflow/models/image/cifar10/\npython cifar10_eval.py\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.3545\npciBusID 0000:01:00.0\nTotal memory: 6.00GiB\nFree memory: 5.56GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\nand stop this line.\nbut sometimes not stop this line when run same as above. and\n==========check3.25==========\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.27GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x857ab6000\n==========check3.5==========\n==========check3.75==========\n==========check3.25==========\n.\n.\n.\n==========check3.25==========\n==========check3.5==========\n==========check3.75==========\n2016-03-01 15:41:09.935657: precision @ 1 = 0.801\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb37405e7b0 Compute status: Cancelled: Enqueue operation was cancelled\n[[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\nI tensorflow/core/kernels/queue_base.cc:286] Skipping cancelled enqueue attempt\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb350035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36403ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3223f5240 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb35c03ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb338035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36c00c600 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb354035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb340035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb34c035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3480095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33000c470 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb370011050 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb328010190 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3600095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb358035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33c05b3b0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n[[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nWhat have you tried?\n\nAdd some instruction for checking stop point.\n\ncifar10_eval.py\ndef eval_once(saver, summary_writer, top_k_op, summary_op):\n# Start the queue runners.\ncoord = tf.train.Coordinator()\ntry:\n  threads = []\n  for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n    threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n                                     start=True))\n  num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n  true_count = 0  # Counts the number of correct predictions.\n  total_sample_count = num_iter * FLAGS.batch_size\n  step = 0\n  while step < num_iter and not coord.should_stop():\n    print(\"==========check3.25==========\")\n    predictions = sess.run([top_k_op])\n    print(\"==========check3.5==========\")\n    true_count += np.sum(predictions)\n    step += 1\n    print(\"==========check3.75==========\")\n\n  # Compute precision @ 1.\n  precision = true_count / total_sample_count\n  print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n\n  summary = tf.Summary()\n  summary.ParseFromString(sess.run(summary_op))\n  summary.value.add(tag='Precision @ 1', simple_value=precision)\n  summary_writer.add_summary(summary, global_step)\nexcept Exception as e:  # pylint: disable=broad-except\n  coord.request_stop(e)\n\ncoord.request_stop()\ncoord.join(threads, stop_grace_period_secs=10)\n\nlook like #389 issue but different. and many time stop\npredictions = sess.run([top_k_op])\nthis line.", "body": "### Environment info\n\nOperating System: Ubuntu 14.04.4 LTS\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   : tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   : 0.7.1\n### Steps to reproduce\n1. cd git/tensorflow/tensorflow/models/image/cifar10/\n2. python cifar10_eval.py\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.3545\npciBusID 0000:01:00.0\nTotal memory: 6.00GiB\nFree memory: 5.56GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\n\nand stop this line.\n\nbut sometimes not stop this line when run same as above. and\n\n==========check3.25==========\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.27GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x857ab6000\n==========check3.5==========\n==========check3.75==========\n==========check3.25==========\n\n.\n.\n.\n\n==========check3.25==========\n==========check3.5==========\n==========check3.75==========\n2016-03-01 15:41:09.935657: precision @ 1 = 0.801\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb37405e7b0 Compute status: Cancelled: Enqueue operation was cancelled\n     [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\nI tensorflow/core/kernels/queue_base.cc:286] Skipping cancelled enqueue attempt\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb350035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36403ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3223f5240 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb35c03ada0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb338035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb36c00c600 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb354035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb340035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb34c035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3480095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33000c470 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb370011050 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb328010190 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb3600095e0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb358035000 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x7fb33c05b3b0 Compute status: Aborted: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed.\n     [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueue[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, Div/_206, Cast/_208)]]\n### What have you tried?\n1.  Add some instruction for checking stop point.\n\ncifar10_eval.py\n\ndef eval_once(saver, summary_writer, top_k_op, summary_op):\n\n```\n# Start the queue runners.\ncoord = tf.train.Coordinator()\ntry:\n  threads = []\n  for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n    threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n                                     start=True))\n  num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n  true_count = 0  # Counts the number of correct predictions.\n  total_sample_count = num_iter * FLAGS.batch_size\n  step = 0\n  while step < num_iter and not coord.should_stop():\n    print(\"==========check3.25==========\")\n    predictions = sess.run([top_k_op])\n    print(\"==========check3.5==========\")\n    true_count += np.sum(predictions)\n    step += 1\n    print(\"==========check3.75==========\")\n\n  # Compute precision @ 1.\n  precision = true_count / total_sample_count\n  print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n\n  summary = tf.Summary()\n  summary.ParseFromString(sess.run(summary_op))\n  summary.value.add(tag='Precision @ 1', simple_value=precision)\n  summary_writer.add_summary(summary, global_step)\nexcept Exception as e:  # pylint: disable=broad-except\n  coord.request_stop(e)\n\ncoord.request_stop()\ncoord.join(threads, stop_grace_period_secs=10)\n```\n\nlook like #389 issue but different. and many time stop \n\npredictions = sess.run([top_k_op])\n\nthis line. \n"}