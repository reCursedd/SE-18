{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13516", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13516/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13516/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13516/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13516", "id": 263321006, "node_id": "MDU6SXNzdWUyNjMzMjEwMDY=", "number": 13516, "title": "When using placeholder in MonitoredTrainingSession, summary called at first and not feed placeholder error", "user": {"login": "fumihwh", "id": 6838753, "node_id": "MDQ6VXNlcjY4Mzg3NTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6838753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fumihwh", "html_url": "https://github.com/fumihwh", "followers_url": "https://api.github.com/users/fumihwh/followers", "following_url": "https://api.github.com/users/fumihwh/following{/other_user}", "gists_url": "https://api.github.com/users/fumihwh/gists{/gist_id}", "starred_url": "https://api.github.com/users/fumihwh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fumihwh/subscriptions", "organizations_url": "https://api.github.com/users/fumihwh/orgs", "repos_url": "https://api.github.com/users/fumihwh/repos", "events_url": "https://api.github.com/users/fumihwh/events{/privacy}", "received_events_url": "https://api.github.com/users/fumihwh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-10-06T02:39:09Z", "updated_at": "2018-11-09T07:52:23Z", "closed_at": "2017-10-07T19:31:58Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<p>== cat /etc/issue ===============================================<br>\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.3)<br>\nprotobuf (3.4.0)<br>\ntensorflow-gpu (1.3.0)<br>\ntensorflow-tensorboard (0.1.5)</p>\n<p>== check for virtualenv =========================================<br>\nTrue</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.3.0<br>\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee<br>\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH :/usr/local/cuda-8.0/lib64<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nFri Oct  6 11:16:46 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX TIT...  Off  | 0000:01:00.0     Off |                  N/A |<br>\n|  0%   54C    P0    52W / 250W |      0MiB / 12205MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|  No running processes found                                                 |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7</p>\n<h3>Describe the problem</h3>\n<p>I am using MonitoredTrainingSession. With both <code>tf.summary.scalar('test', d)</code> in graph and <code>checkpoint_dir='/temp',</code> as param, the error occurs. I assume it tries to summary all at the first and run <code>tf.summary.scalar('test', d)</code>. But I just want to run <code>a</code> and <code>b</code> to get the value, not activate any things relate to placeholder <code>h</code>. For people who will ask why you can't just feed a int, code of real I want to do is at last.<br>\nI think this is a bug, or I do it in a wrong way?</p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\n    \nwith tf.Graph().as_default():\n    global_step = tf.contrib.framework.get_or_create_global_step()\n\n    a = tf.constant(1, dtype=tf.int64)\n    b = tf.constant(2, dtype=tf.int64)\n    c = tf.add(a, b)\n\n    h = tf.placeholder(tf.int64)\n    d = tf.multiply(c, h)\n    tf.summary.scalar('test', d)\n\n    with tf.train.MonitoredTrainingSession(\n            checkpoint_dir='/temp',\n    ) as sess:\n        a_val, b_val = sess.run([a, b])\n</code></pre>\n<pre><code>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int64\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT64, shape=&lt;unknown&gt;, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: Const/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16_Const\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\n</code></pre>\n<p><strong>Code I real want to do</strong></p>\n<pre><code>import tensorflow as tf\n\nwith tf.Graph().as_default():\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    dataset_train = tf.contrib.data.Dataset.range(10)\n    dataset_val = tf.contrib.data.Dataset.range(90, 100)\n\n    iter_train_handle = dataset_train.make_one_shot_iterator().string_handle()\n    iter_val_handle = dataset_val.make_one_shot_iterator().string_handle()\n\n    handle = tf.placeholder(tf.string, shape=[])\n    iterator = tf.contrib.data.Iterator.from_string_handle(\n        handle, dataset_train.output_types, dataset_train.output_shapes)\n    next_batch = iterator.get_next()\n    tf.summary.scalar('test', next_batch)\n\n    with tf.train.MonitoredTrainingSession(\n            checkpoint_dir='/temp',\n    ) as sess:\n        handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\n        for step in range(10):\n            print('train', sess.run(next_batch, feed_dict={handle: handle_train}))\n            if step % 3 == 0:\n                print('val', sess.run(next_batch, feed_dict={handle: handle_val}))\n</code></pre>", "body_text": "System information\n== cat /etc/issue ===============================================\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.4.0)\ntensorflow-gpu (1.3.0)\ntensorflow-tensorboard (0.1.5)\n== check for virtualenv =========================================\nTrue\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH :/usr/local/cuda-8.0/lib64\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nFri Oct  6 11:16:46 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:01:00.0     Off |                  N/A |\n|  0%   54C    P0    52W / 250W |      0MiB / 12205MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\nDescribe the problem\nI am using MonitoredTrainingSession. With both tf.summary.scalar('test', d) in graph and checkpoint_dir='/temp', as param, the error occurs. I assume it tries to summary all at the first and run tf.summary.scalar('test', d). But I just want to run a and b to get the value, not activate any things relate to placeholder h. For people who will ask why you can't just feed a int, code of real I want to do is at last.\nI think this is a bug, or I do it in a wrong way?\nSource code / logs\nimport tensorflow as tf\n    \nwith tf.Graph().as_default():\n    global_step = tf.contrib.framework.get_or_create_global_step()\n\n    a = tf.constant(1, dtype=tf.int64)\n    b = tf.constant(2, dtype=tf.int64)\n    c = tf.add(a, b)\n\n    h = tf.placeholder(tf.int64)\n    d = tf.multiply(c, h)\n    tf.summary.scalar('test', d)\n\n    with tf.train.MonitoredTrainingSession(\n            checkpoint_dir='/temp',\n    ) as sess:\n        a_val, b_val = sess.run([a, b])\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int64\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT64, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: Const/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16_Const\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\n\nCode I real want to do\nimport tensorflow as tf\n\nwith tf.Graph().as_default():\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    dataset_train = tf.contrib.data.Dataset.range(10)\n    dataset_val = tf.contrib.data.Dataset.range(90, 100)\n\n    iter_train_handle = dataset_train.make_one_shot_iterator().string_handle()\n    iter_val_handle = dataset_val.make_one_shot_iterator().string_handle()\n\n    handle = tf.placeholder(tf.string, shape=[])\n    iterator = tf.contrib.data.Iterator.from_string_handle(\n        handle, dataset_train.output_types, dataset_train.output_shapes)\n    next_batch = iterator.get_next()\n    tf.summary.scalar('test', next_batch)\n\n    with tf.train.MonitoredTrainingSession(\n            checkpoint_dir='/temp',\n    ) as sess:\n        handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\n        for step in range(10):\n            print('train', sess.run(next_batch, feed_dict={handle: handle_train}))\n            if step % 3 == 0:\n                print('val', sess.run(next_batch, feed_dict={handle: handle_val}))", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.4.0)\r\ntensorflow-gpu (1.3.0)\r\ntensorflow-tensorboard (0.1.5)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda-8.0/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Oct  6 11:16:46 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX TIT...  Off  | 0000:01:00.0     Off |                  N/A |\r\n|  0%   54C    P0    52W / 250W |      0MiB / 12205MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n\r\n\r\n### Describe the problem\r\nI am using MonitoredTrainingSession. With both `tf.summary.scalar('test', d)` in graph and `checkpoint_dir='/temp',` as param, the error occurs. I assume it tries to summary all at the first and run `tf.summary.scalar('test', d)`. But I just want to run `a` and `b` to get the value, not activate any things relate to placeholder `h`. For people who will ask why you can't just feed a int, code of real I want to do is at last.\r\nI think this is a bug, or I do it in a wrong way?\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n    \r\nwith tf.Graph().as_default():\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n\r\n    a = tf.constant(1, dtype=tf.int64)\r\n    b = tf.constant(2, dtype=tf.int64)\r\n    c = tf.add(a, b)\r\n\r\n    h = tf.placeholder(tf.int64)\r\n    d = tf.multiply(c, h)\r\n    tf.summary.scalar('test', d)\r\n\r\n    with tf.train.MonitoredTrainingSession(\r\n            checkpoint_dir='/temp',\r\n    ) as sess:\r\n        a_val, b_val = sess.run([a, b])\r\n```\r\n```\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int64\r\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT64, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\t [[Node: Const/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16_Const\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n```\r\n\r\n\r\n**Code I real want to do**\r\n```\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n    dataset_train = tf.contrib.data.Dataset.range(10)\r\n    dataset_val = tf.contrib.data.Dataset.range(90, 100)\r\n\r\n    iter_train_handle = dataset_train.make_one_shot_iterator().string_handle()\r\n    iter_val_handle = dataset_val.make_one_shot_iterator().string_handle()\r\n\r\n    handle = tf.placeholder(tf.string, shape=[])\r\n    iterator = tf.contrib.data.Iterator.from_string_handle(\r\n        handle, dataset_train.output_types, dataset_train.output_shapes)\r\n    next_batch = iterator.get_next()\r\n    tf.summary.scalar('test', next_batch)\r\n\r\n    with tf.train.MonitoredTrainingSession(\r\n            checkpoint_dir='/temp',\r\n    ) as sess:\r\n        handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\r\n        for step in range(10):\r\n            print('train', sess.run(next_batch, feed_dict={handle: handle_train}))\r\n            if step % 3 == 0:\r\n                print('val', sess.run(next_batch, feed_dict={handle: handle_val}))\r\n```"}