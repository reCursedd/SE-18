{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/152582888", "pull_request_review_id": 78465588, "id": 152582888, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MjU4Mjg4OA==", "diff_hunk": "@@ -810,7 +810,8 @@ def _time_step(time, output_ta_t, state):\n \n   # Unpack final output if not using output tuples.\n   if in_graph_mode:\n-    final_outputs = tuple(ta.stack() for ta in output_final_ta)\n+    final_outputs = tuple(\n+        ta.gather(range(time_steps)) for ta in output_final_ta)", "path": "tensorflow/python/ops/rnn.py", "position": 6, "original_position": 6, "commit_id": "b2adc9b661b650f6f896f8e3c3808bea0cee6fd9", "original_commit_id": "b2adc9b661b650f6f896f8e3c3808bea0cee6fd9", "user": {"login": "DavidNorman", "id": 606831, "node_id": "MDQ6VXNlcjYwNjgzMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/606831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidNorman", "html_url": "https://github.com/DavidNorman", "followers_url": "https://api.github.com/users/DavidNorman/followers", "following_url": "https://api.github.com/users/DavidNorman/following{/other_user}", "gists_url": "https://api.github.com/users/DavidNorman/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidNorman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidNorman/subscriptions", "organizations_url": "https://api.github.com/users/DavidNorman/orgs", "repos_url": "https://api.github.com/users/DavidNorman/repos", "events_url": "https://api.github.com/users/DavidNorman/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidNorman/received_events", "type": "User", "site_admin": false}, "body": "Can you explain why it is not?  The time steps parameter (graph compile time) is both the size of the output tensor array and the loop counter.  It comes from the shape of the input sequence, which is known.\r\n\r\nI'm not suggesting that you take this change, if there is an alternative XLA compatible dynamic_rnn in the pipeline.  Just curious why it isn't static.\r\n", "created_at": "2017-11-22T14:39:07Z", "updated_at": "2017-11-22T14:39:08Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14653#discussion_r152582888", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14653", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/152582888"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14653#discussion_r152582888"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14653"}}, "body_html": "<p>Can you explain why it is not?  The time steps parameter (graph compile time) is both the size of the output tensor array and the loop counter.  It comes from the shape of the input sequence, which is known.</p>\n<p>I'm not suggesting that you take this change, if there is an alternative XLA compatible dynamic_rnn in the pipeline.  Just curious why it isn't static.</p>", "body_text": "Can you explain why it is not?  The time steps parameter (graph compile time) is both the size of the output tensor array and the loop counter.  It comes from the shape of the input sequence, which is known.\nI'm not suggesting that you take this change, if there is an alternative XLA compatible dynamic_rnn in the pipeline.  Just curious why it isn't static.", "in_reply_to_id": 152346945}