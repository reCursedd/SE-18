{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6329", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6329/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6329/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6329/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6329", "id": 195754945, "node_id": "MDU6SXNzdWUxOTU3NTQ5NDU=", "number": 6329, "title": "ValueError: Variable d_h0_conv/w/Adam/ does not exist", "user": {"login": "zhangqianhui", "id": 7938702, "node_id": "MDQ6VXNlcjc5Mzg3MDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/7938702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangqianhui", "html_url": "https://github.com/zhangqianhui", "followers_url": "https://api.github.com/users/zhangqianhui/followers", "following_url": "https://api.github.com/users/zhangqianhui/following{/other_user}", "gists_url": "https://api.github.com/users/zhangqianhui/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangqianhui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangqianhui/subscriptions", "organizations_url": "https://api.github.com/users/zhangqianhui/orgs", "repos_url": "https://api.github.com/users/zhangqianhui/repos", "events_url": "https://api.github.com/users/zhangqianhui/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangqianhui/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-12-15T09:24:40Z", "updated_at": "2017-03-13T00:05:17Z", "closed_at": "2016-12-15T18:05:19Z", "author_association": "NONE", "body_html": "<p>I got a error:</p>\n<p><code>ValueError: Variable d_h0_conv/w/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?</code></p>\n<p>this is DCGAN's code<br>\n<a href=\"https://github.com/carpedm20/DCGAN-tensorflow\">dcgan-tensorflow</a></p>\n<p>And my tensorflow version is 0.12<br>\nmy ubuntu : 14.04</p>\n<p>code detail:</p>\n<p>con2d code</p>\n<p>`def conv2d(input_, output_dim,<br>\nk_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,<br>\nname=\"conv2d\"):<br>\nwith tf.variable_scope(name):</p>\n<pre><code>    w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n                        initializer=tf.truncated_normal_initializer(stddev=stddev))\n    conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n\n    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n    conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n\n    return conv`\n</code></pre>\n<p>Optimizer:</p>\n<p><code>d_optim = tf.train.AdamOptimizer(config.learning_rate ,  beta1=config.beta1).minimize(self.d_loss , var_list=self.d_vars) g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \\ .minimize(self.g_loss, var_list=self.g_vars)</code></p>\n<p>Thanks, Now I need help!</p>", "body_text": "I got a error:\nValueError: Variable d_h0_conv/w/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\nthis is DCGAN's code\ndcgan-tensorflow\nAnd my tensorflow version is 0.12\nmy ubuntu : 14.04\ncode detail:\ncon2d code\n`def conv2d(input_, output_dim,\nk_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\nname=\"conv2d\"):\nwith tf.variable_scope(name):\n    w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n                        initializer=tf.truncated_normal_initializer(stddev=stddev))\n    conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n\n    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n    conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n\n    return conv`\n\nOptimizer:\nd_optim = tf.train.AdamOptimizer(config.learning_rate ,  beta1=config.beta1).minimize(self.d_loss , var_list=self.d_vars) g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \\ .minimize(self.g_loss, var_list=self.g_vars)\nThanks, Now I need help!", "body": "I got a error:\r\n\r\n`\r\nValueError: Variable d_h0_conv/w/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n`\r\n\r\nthis is DCGAN's code \r\n[dcgan-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)\r\n\r\nAnd my tensorflow version is 0.12\r\nmy ubuntu : 14.04\r\n\r\ncode detail:\r\n\r\ncon2d code\r\n\r\n`def conv2d(input_, output_dim, \r\n           k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\r\n           name=\"conv2d\"):\r\n    with tf.variable_scope(name):\r\n\r\n\r\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\r\n                            initializer=tf.truncated_normal_initializer(stddev=stddev))\r\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\r\n\r\n        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\r\n        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\r\n\r\n        return conv`\r\n\r\nOptimizer:\r\n\r\n`\r\n        d_optim = tf.train.AdamOptimizer(config.learning_rate ,  beta1=config.beta1).minimize(self.d_loss , var_list=self.d_vars)\r\n        g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \\\r\n                          .minimize(self.g_loss, var_list=self.g_vars)\r\n`\r\n\r\nThanks, Now I need help!\r\n"}