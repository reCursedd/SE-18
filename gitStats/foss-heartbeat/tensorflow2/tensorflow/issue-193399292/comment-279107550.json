{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/279107550", "html_url": "https://github.com/tensorflow/tensorflow/issues/6072#issuecomment-279107550", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6072", "id": 279107550, "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTEwNzU1MA==", "user": {"login": "boche", "id": 7852469, "node_id": "MDQ6VXNlcjc4NTI0Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/7852469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boche", "html_url": "https://github.com/boche", "followers_url": "https://api.github.com/users/boche/followers", "following_url": "https://api.github.com/users/boche/following{/other_user}", "gists_url": "https://api.github.com/users/boche/gists{/gist_id}", "starred_url": "https://api.github.com/users/boche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boche/subscriptions", "organizations_url": "https://api.github.com/users/boche/orgs", "repos_url": "https://api.github.com/users/boche/repos", "events_url": "https://api.github.com/users/boche/events{/privacy}", "received_events_url": "https://api.github.com/users/boche/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-11T01:07:24Z", "updated_at": "2017-02-11T01:07:24Z", "author_association": "NONE", "body_html": "<p>Also I found a bug <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1034716\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhangyaobit\">@zhangyaobit</a>. I am using params_to_canonical to export parameters.</p>\n<p>When my model is bidirectional, I always have this mistake</p>\n<blockquote>\n<p>F tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:550] Check failed: size == width * height Params size mismatch. Expected 100, got 1290</p>\n</blockquote>\n<p>Here my input size is 129, num_units is 10. But when I switch my model to unidirectional, there is no such mistake.</p>\n<p>I think the bug is in line 548.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L548-L550\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L548-L550</a></p>\n<p>The logic of this line is to use input_size as width for the first half parameters (W matrix), and num_units as width for the second half parameters (R matrix). But in bidirectional case, the param is probably not organized in the order of first W and then R, for example it can be W^f_x, R^f_x, W^b_x, R^b_x (f: forward, b: backward, x: stand for different gates).</p>", "body_text": "Also I found a bug @zhangyaobit. I am using params_to_canonical to export parameters.\nWhen my model is bidirectional, I always have this mistake\n\nF tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:550] Check failed: size == width * height Params size mismatch. Expected 100, got 1290\n\nHere my input size is 129, num_units is 10. But when I switch my model to unidirectional, there is no such mistake.\nI think the bug is in line 548.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L548-L550\nThe logic of this line is to use input_size as width for the first half parameters (W matrix), and num_units as width for the second half parameters (R matrix). But in bidirectional case, the param is probably not organized in the order of first W and then R, for example it can be W^f_x, R^f_x, W^b_x, R^b_x (f: forward, b: backward, x: stand for different gates).", "body": "Also I found a bug @zhangyaobit. I am using params_to_canonical to export parameters.\r\n\r\nWhen my model is bidirectional, I always have this mistake\r\n\r\n> F tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:550] Check failed: size == width * height Params size mismatch. Expected 100, got 1290\r\n\r\nHere my input size is 129, num_units is 10. But when I switch my model to unidirectional, there is no such mistake.\r\n\r\nI think the bug is in line 548.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L548-L550\r\n\r\nThe logic of this line is to use input_size as width for the first half parameters (W matrix), and num_units as width for the second half parameters (R matrix). But in bidirectional case, the param is probably not organized in the order of first W and then R, for example it can be W^f_x, R^f_x, W^b_x, R^b_x (f: forward, b: backward, x: stand for different gates)."}