{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/278540373", "html_url": "https://github.com/tensorflow/tensorflow/issues/6072#issuecomment-278540373", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6072", "id": 278540373, "node_id": "MDEyOklzc3VlQ29tbWVudDI3ODU0MDM3Mw==", "user": {"login": "boche", "id": 7852469, "node_id": "MDQ6VXNlcjc4NTI0Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/7852469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boche", "html_url": "https://github.com/boche", "followers_url": "https://api.github.com/users/boche/followers", "following_url": "https://api.github.com/users/boche/following{/other_user}", "gists_url": "https://api.github.com/users/boche/gists{/gist_id}", "starred_url": "https://api.github.com/users/boche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boche/subscriptions", "organizations_url": "https://api.github.com/users/boche/orgs", "repos_url": "https://api.github.com/users/boche/repos", "events_url": "https://api.github.com/users/boche/events{/privacy}", "received_events_url": "https://api.github.com/users/boche/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-09T03:55:05Z", "updated_at": "2017-02-09T03:55:05Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1034716\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhangyaobit\">@zhangyaobit</a><br>\nIf unidirectional, one layer has 8 matrices ordered like W_i,W_f,W_c,W_o,R_i,R_f,R_c,R_o.<br>\nIf bidirectional, one layer will then have 16 matrices right, since we have a forward matrix and a backward matrix for each W_x or R_x, so my question is how are these 16 matrices ordered?</p>\n<p>It can be appended like W^f_i, ...,R^f_o, W^b_i, ..., R^b_o<br>\nor interleaved as W^f_i, W^b_i, ..., R^f_o, R^b_o<br>\n^f: stand for forward matrix, ^b stand for backward matrix</p>\n<p>I am not sure which way is it organized (appending form, interleaving form, or some other form), and which direction is put first (forward first or backward first). Hope this clarifies my question.</p>", "body_text": "@zhangyaobit\nIf unidirectional, one layer has 8 matrices ordered like W_i,W_f,W_c,W_o,R_i,R_f,R_c,R_o.\nIf bidirectional, one layer will then have 16 matrices right, since we have a forward matrix and a backward matrix for each W_x or R_x, so my question is how are these 16 matrices ordered?\nIt can be appended like W^f_i, ...,R^f_o, W^b_i, ..., R^b_o\nor interleaved as W^f_i, W^b_i, ..., R^f_o, R^b_o\n^f: stand for forward matrix, ^b stand for backward matrix\nI am not sure which way is it organized (appending form, interleaving form, or some other form), and which direction is put first (forward first or backward first). Hope this clarifies my question.", "body": "@zhangyaobit \r\nIf unidirectional, one layer has 8 matrices ordered like W_i,W_f,W_c,W_o,R_i,R_f,R_c,R_o.\r\nIf bidirectional, one layer will then have 16 matrices right, since we have a forward matrix and a backward matrix for each W_x or R_x, so my question is how are these 16 matrices ordered?\r\n\r\nIt can be appended like W^f_i, ...,R^f_o, W^b_i, ..., R^b_o\r\nor interleaved as W^f_i, W^b_i, ..., R^f_o, R^b_o\r\n^f: stand for forward matrix, ^b stand for backward matrix\r\n\r\nI am not sure which way is it organized (appending form, interleaving form, or some other form), and which direction is put first (forward first or backward first). Hope this clarifies my question."}