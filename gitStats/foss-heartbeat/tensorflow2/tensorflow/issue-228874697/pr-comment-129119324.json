{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129119324", "pull_request_review_id": 51859597, "id": 129119324, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyOTExOTMyNA==", "diff_hunk": "@@ -0,0 +1,315 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// Implements quantized eight-bit versions of the deconvolution operations.\n+//\n+// Deconvolution operation defined in this file is similar to the\n+// 'conv2d_transpose' op in TensorFlow.\n+// Currently only a reference implementation is supported.\n+//\n+// TODO: use gemmlowp to optimise the performance\n+\n+#include <algorithm>\n+#include <vector>\n+\n+#define EIGEN_USE_THREADS\n+\n+#define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n+#include \"public/gemmlowp.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/kernels/conv_ops.h\"\n+#include \"tensorflow/core/kernels/meta_support.h\"\n+#include \"tensorflow/core/kernels/ops_util.h\"\n+#include \"tensorflow/core/kernels/quantization_utils.h\"\n+#include \"tensorflow/core/kernels/reference_gemm.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+\n+namespace tensorflow {\n+\n+// Similar to the ReferenceConvFunctor defined in quantized_conv_ops.cc,\n+// this ReferenceDeconvFunctor implements the deconvolution operation in\n+// the simplest way.\n+// As there is no backpropagation function designed for quantized convolution,\n+// this function implements the deconvolution operation by **definition**.\n+// Reference: https://youtu.be/Sb3b0ocD8mI?t=20m00s\n+// \n+// TODO: add some detailed explanation of the algorithm.\n+template <class T1, class T2, class T3>\n+class ReferenceDeconvFunctor {\n+  public:\n+    void operator() (OpKernelContext* context,\n+                     const T1* input_data,\n+                     int input_batches,\n+                     int input_height,\n+                     int input_width,\n+                     int input_depth,\n+                     int input_offset,\n+                     const T2* filter_data,\n+                     int filter_height,\n+                     int filter_width,\n+                     int filter_depth,\n+                     int filter_offset,\n+                     int stride,\n+                     Padding padding,\n+                     T3* output_data,\n+                     int output_height,\n+                     int output_width,\n+                     int output_shift,\n+                     int output_offset,\n+                     int output_mult)\n+  {\n+    // TODO: add support for padding\n+    \n+    int output_depth = filter_depth;\n+    // Just copied from quantized_conv_ops\n+    int filter_left_offset =\n+      ((input_width - 1) * stride + filter_width - output_width + 1) / 2;\n+    int filter_top_offset =\n+      ((input_height - 1) * stride + filter_height - output_height + 1) / 2;\n+    // LOG(INFO) << filter_left_offset;\n+    // LOG(INFO) << filter_top_offset;\n+\n+    for (int batch = 0; batch < input_batches; batch ++) {\n+\n+      // for each channel in the output (which is the input of the conv2d)\n+      for (int c = 0; c < output_depth; c ++) {\n+\n+        // we know that output_data is initialized as an array with zeros\n+        // h and w are the coordinate for an element in the gradient of output (input_data)\n+        for (int h = 0; h < input_height; h ++) {\n+          for (int w = 0; w < input_width; w ++) {\n+            // x and y are the coordinate of the center of the kernel that \n+            // outputs the element at (h, w)\n+            int x = filter_height / 2 + h * stride - filter_top_offset;\n+            int y = filter_width / 2 + w * stride - filter_left_offset;\n+\n+            for (int kx = 0; kx < filter_height; kx ++) {\n+              for (int ky = 0; ky < filter_width; ky ++) {\n+                int ox = x + kx - filter_height / 2;\n+                int oy = y + ky - filter_width / 2;\n+\n+                T3 total = 0;\n+                for (int f = 0; f < input_depth; f++) {\n+                  const T1 input_value = input_data[\n+                    (batch * input_height * input_width * input_depth) +\n+                    (h * input_width * input_depth) +\n+                    (w * input_depth) +\n+                    (f)\n+                  ];\n+\n+                  const T2 filter_value = filter_data[\n+                    (kx * filter_width * output_depth * input_depth) +\n+                    (ky * output_depth * input_depth) +\n+                    (c * input_depth) +\n+                    (f)\n+                  ];\n+\n+                  total += input_value * filter_value;\n+                }\n+                \n+                output_data[\n+                  (batch * output_height * output_width * output_depth) +\n+                  (ox * output_width * output_depth) +\n+                  (oy * output_depth) +\n+                  (c)\n+                ] += total;\n+\n+              }\n+            }\n+\n+\n+          }\n+\n+        }\n+      }\n+    }\n+\n+  }\n+};\n+\n+template <class T1, class T2, class T3,\n+         template <class TF1, class TF2, class TF3> class ConvTransFunctor>\n+class QuantizedDeconv2DOp: public OpKernel {\n+  public:\n+    explicit QuantizedDeconv2DOp(OpKernelConstruction *context)\n+      : OpKernel(context) {\n+      //\n+      // Assertions for Attr\n+\n+      // Assertions for strides\n+      OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &strides_));\n+      OP_REQUIRES(context, strides_.size() == 4,\n+                  errors::InvalidArgument(\"Sliding window strides field must specify 4 dimensions\"));\n+      OP_REQUIRES(context, strides_[1] == strides_[2],\n+                  errors::InvalidArgument(\"Current implementation only supports equal strides in the row and column dimensions\"));\n+      //OP_REQUIRES(context, (strides_[1] == 1) & (strides_[2] == 1),\n+      //            errors::InvalidArgument(\"Current implementation doesn't support stride larger than 1\"));\n+      OP_REQUIRES(context, (strides_[0] == 1) | (strides_[3] == 1),\n+                  errors::InvalidArgument(\"Current implementation doesn't support stride in batch or depth dimension\"));\n+      OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n+      OP_REQUIRES(context, padding_ == VALID,\n+                  errors::InvalidArgument(\"Only VALID padding is supported in the current implementation\"));\n+\n+      // These checkers are copied from the Conv2DFastBackpropInputOp\n+      // See: conv_grad_input_ops.cc\n+      // TODO: Assertions for data_format\n+      // Currently QuantizedConv2DTransposeOp doesn't support this parameter, could be implemented with\n+      // GetConvnetDataFormatAttrString()\n+\n+      // The following checkers are set for the current implementation,\n+      // which are much stricter than the expected final release.\n+      // TODO: Remove these checkers when they are ready\n+\n+      // Stride can only be 1 at the moment\n+      // OP_REQUIRES(context, strides_[1] == 1,", "path": "tensorflow/core/kernels/quantized_deconv_ops.cc", "position": null, "original_position": 178, "commit_id": "c7d00791c02ee604429425d0ad49941aa4defdec", "original_commit_id": "3d50e2ef0f823b3c2e7dc5070734fe418d4ce32b", "user": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "body": "Can you clarify whether this is still true? If not, remove the commented-out code, otherwise make it active.", "created_at": "2017-07-24T18:39:34Z", "updated_at": "2017-11-11T00:13:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9924#discussion_r129119324", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9924", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/129119324"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9924#discussion_r129119324"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9924"}}, "body_html": "<p>Can you clarify whether this is still true? If not, remove the commented-out code, otherwise make it active.</p>", "body_text": "Can you clarify whether this is still true? If not, remove the commented-out code, otherwise make it active."}