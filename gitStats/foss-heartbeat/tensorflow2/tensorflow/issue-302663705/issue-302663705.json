{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17476", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17476/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17476/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17476/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17476", "id": 302663705, "node_id": "MDU6SXNzdWUzMDI2NjM3MDU=", "number": 17476, "title": "SVD gradient is unstable for non-unique singular values", "user": {"login": "christian-rauch", "id": 8226248, "node_id": "MDQ6VXNlcjgyMjYyNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/8226248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/christian-rauch", "html_url": "https://github.com/christian-rauch", "followers_url": "https://api.github.com/users/christian-rauch/followers", "following_url": "https://api.github.com/users/christian-rauch/following{/other_user}", "gists_url": "https://api.github.com/users/christian-rauch/gists{/gist_id}", "starred_url": "https://api.github.com/users/christian-rauch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/christian-rauch/subscriptions", "organizations_url": "https://api.github.com/users/christian-rauch/orgs", "repos_url": "https://api.github.com/users/christian-rauch/repos", "events_url": "https://api.github.com/users/christian-rauch/events{/privacy}", "received_events_url": "https://api.github.com/users/christian-rauch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-03-06T11:27:37Z", "updated_at": "2018-03-07T12:33:55Z", "closed_at": "2018-03-07T12:33:55Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.5.0-10-g5b10b34', '1.5.0')</li>\n<li><strong>Python version</strong>: Python 2.7.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 4.8.5</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0 / 6.0</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 970 4GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The gradient of SVD becomes <code>nan</code> when singular values are not unique.</p>\n<p>From the code<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/c6a12c77a50778e28de3590f4618bc2b62f3ecab/tensorflow/python/ops/linalg_grad.py#L332-L342\">tensorflow/tensorflow/python/ops/linalg_grad.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 332 to 342\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/c6a12c77a50778e28de3590f4618bc2b62f3ecab\">c6a12c7</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L332\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"332\"></td>\n          <td id=\"LC332\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> NOTICE: Because of the term involving f, the gradient becomes</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L333\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"333\"></td>\n          <td id=\"LC333\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> infinite (or NaN in practice) when singular values are not unique.</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L334\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"334\"></td>\n          <td id=\"LC334\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Mathematically this should not be surprising, since for (k-fold)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L335\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"335\"></td>\n          <td id=\"LC335\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> degenerate singular values, the corresponding singular vectors are</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L336\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"336\"></td>\n          <td id=\"LC336\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> only defined up a (k-dimensional) subspace. In practice, this can</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L337\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"337\"></td>\n          <td id=\"LC337\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> lead to numerical instability when singular values are close but not</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L338\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"338\"></td>\n          <td id=\"LC338\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c\"><span class=\"pl-c\">#</span> exactly equal.</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L339\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"339\"></td>\n          <td id=\"LC339\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> f <span class=\"pl-k\">=</span> array_ops.matrix_set_diag( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L340\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"340\"></td>\n          <td id=\"LC340\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     math_ops.reciprocal( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L341\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"341\"></td>\n          <td id=\"LC341\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         array_ops.expand_dims(s2, <span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>) <span class=\"pl-k\">-</span> array_ops.expand_dims(s2, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)), </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L342\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"342\"></td>\n          <td id=\"LC342\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     array_ops.zeros_like(s)) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n<br>\nit is clearly visible that <code>f</code> becomes <code>inf</code> for equal singular values.</p>\n<p>I briefly skimmed through the paper <a href=\"https://arxiv.org/abs/1509.07838\" rel=\"nofollow\">https://arxiv.org/abs/1509.07838</a> but couldn't find an explanation for this behaviour. Can someone give an intuitive example why the gradient for similar singular values should not be defined?</p>\n<p>Similar singular values commonly appear for estimation of rotation matrices (all singular values become 1). At the moment it is impossible to use SVD for such a case.</p>\n<p>Alternative implementations of the SVD gradients based on the same paper are:</p>\n<ul>\n<li><a href=\"https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py\">https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py</a></li>\n<li><a href=\"https://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b\">https://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b</a></li>\n</ul>\n<p>which circumvent this problem by simply replacing the <code>nan</code>s or effectively setting them to 0.</p>\n<p>Could this be used alternatively to the current implementation that just divides by 0? Or alternatively just add a small epsilon to the difference of singular values.</p>\n<p>Btw, I think that no gradient computation in TensorFlow should ever return faulty gradients but raise an error message to simplify debugging. I don't see the point of using <code>nan</code> or <code>inf</code> gradients.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): ('v1.5.0-10-g5b10b34', '1.5.0')\nPython version: Python 2.7.6\nBazel version (if compiling from source): 0.11.0\nGCC/Compiler version (if compiling from source): 4.8.5\nCUDA/cuDNN version: 8.0 / 6.0\nGPU model and memory: GeForce GTX 970 4GB\nExact command to reproduce:\n\nDescribe the problem\nThe gradient of SVD becomes nan when singular values are not unique.\nFrom the code\n\n  \n    \n      tensorflow/tensorflow/python/ops/linalg_grad.py\n    \n    \n        Lines 332 to 342\n      in\n      c6a12c7\n    \n    \n    \n    \n\n        \n          \n           # NOTICE: Because of the term involving f, the gradient becomes \n        \n\n        \n          \n           # infinite (or NaN in practice) when singular values are not unique. \n        \n\n        \n          \n           # Mathematically this should not be surprising, since for (k-fold) \n        \n\n        \n          \n           # degenerate singular values, the corresponding singular vectors are \n        \n\n        \n          \n           # only defined up a (k-dimensional) subspace. In practice, this can \n        \n\n        \n          \n           # lead to numerical instability when singular values are close but not \n        \n\n        \n          \n           # exactly equal. \n        \n\n        \n          \n           f = array_ops.matrix_set_diag( \n        \n\n        \n          \n               math_ops.reciprocal( \n        \n\n        \n          \n                   array_ops.expand_dims(s2, -2) - array_ops.expand_dims(s2, -1)), \n        \n\n        \n          \n               array_ops.zeros_like(s)) \n        \n    \n  \n\n\nit is clearly visible that f becomes inf for equal singular values.\nI briefly skimmed through the paper https://arxiv.org/abs/1509.07838 but couldn't find an explanation for this behaviour. Can someone give an intuitive example why the gradient for similar singular values should not be defined?\nSimilar singular values commonly appear for estimation of rotation matrices (all singular values become 1). At the moment it is impossible to use SVD for such a case.\nAlternative implementations of the SVD gradients based on the same paper are:\n\nhttps://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py\nhttps://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b\n\nwhich circumvent this problem by simply replacing the nans or effectively setting them to 0.\nCould this be used alternatively to the current implementation that just divides by 0? Or alternatively just add a small epsilon to the difference of singular values.\nBtw, I think that no gradient computation in TensorFlow should ever return faulty gradients but raise an error message to simplify debugging. I don't see the point of using nan or inf gradients.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.5.0-10-g5b10b34', '1.5.0')\r\n- **Python version**: Python 2.7.6\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: 8.0 / 6.0\r\n- **GPU model and memory**: GeForce GTX 970 4GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThe gradient of SVD becomes `nan` when singular values are not unique.\r\n\r\nFrom the code\r\nhttps://github.com/tensorflow/tensorflow/blob/c6a12c77a50778e28de3590f4618bc2b62f3ecab/tensorflow/python/ops/linalg_grad.py#L332-L342\r\nit is clearly visible that `f` becomes `inf` for equal singular values.\r\n\r\nI briefly skimmed through the paper https://arxiv.org/abs/1509.07838 but couldn't find an explanation for this behaviour. Can someone give an intuitive example why the gradient for similar singular values should not be defined?\r\n\r\nSimilar singular values commonly appear for estimation of rotation matrices (all singular values become 1). At the moment it is impossible to use SVD for such a case.\r\n\r\nAlternative implementations of the SVD gradients based on the same paper are:\r\n- https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py\r\n- https://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b\r\n\r\nwhich circumvent this problem by simply replacing the `nan`s or effectively setting them to 0.\r\n\r\nCould this be used alternatively to the current implementation that just divides by 0? Or alternatively just add a small epsilon to the difference of singular values.\r\n\r\nBtw, I think that no gradient computation in TensorFlow should ever return faulty gradients but raise an error message to simplify debugging. I don't see the point of using `nan` or `inf` gradients."}