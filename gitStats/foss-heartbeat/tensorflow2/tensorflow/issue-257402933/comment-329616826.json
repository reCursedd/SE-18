{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329616826", "html_url": "https://github.com/tensorflow/tensorflow/issues/13017#issuecomment-329616826", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13017", "id": 329616826, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTYxNjgyNg==", "user": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-14T21:40:19Z", "updated_at": "2017-09-14T21:40:19Z", "author_association": "MEMBER", "body_html": "<p>You're right, it its still significantly slower when <code>size=21</code>.</p>\n<p>When disabling optimizations, the case where <code>size=20</code> slows down to about the speed of <code>size=21</code>, which makes me suspect certain optimizations are only applied when <code>size=20</code>. Disabling optimizations when <code>size=21</code> does not significantly affect performance.</p>\n<p>/CC <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1034716\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhangyaobit\">@zhangyaobit</a>, can you comment on whether optimizations are being applied when <code>size=20</code>? A code sample with warmup batches with optmizations disabled is below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.client <span class=\"pl-k\">import</span> timeline\n<span class=\"pl-k\">import</span> time\n\nsize <span class=\"pl-k\">=</span> <span class=\"pl-c1\">21</span>\nchannels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/CPU:0<span class=\"pl-pds\">'</span></span>):\n  x <span class=\"pl-k\">=</span> tf.random_uniform((<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">20</span>))\n  w0 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>w<span class=\"pl-pds\">'</span></span>, (<span class=\"pl-c1\">20</span>, size <span class=\"pl-k\">*</span> size <span class=\"pl-k\">*</span> channels))\n  h <span class=\"pl-k\">=</span> tf.reshape(tf.matmul(x, w0), (<span class=\"pl-c1\">100</span>, size, size, channels))\n  out <span class=\"pl-k\">=</span> tf.extract_image_patches(<span class=\"pl-v\">images</span><span class=\"pl-k\">=</span>h,\n                                 <span class=\"pl-v\">ksizes</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">1</span>),\n                                 <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>),\n                                 <span class=\"pl-v\">rates</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>),\n                                 <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>)\n\n  loss <span class=\"pl-k\">=</span> tf.reduce_mean(out)\n  op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(out)\n\n  options <span class=\"pl-k\">=</span> tf.RunOptions(<span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>)\n  run_metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n  optimizer_options <span class=\"pl-k\">=</span> tf.OptimizerOptions(<span class=\"pl-v\">opt_level</span><span class=\"pl-k\">=</span>tf.OptimizerOptions.L0)\n  config <span class=\"pl-k\">=</span> tf.ConfigProto(\n      <span class=\"pl-v\">graph_options</span><span class=\"pl-k\">=</span>tf.GraphOptions(<span class=\"pl-v\">optimizer_options</span><span class=\"pl-k\">=</span>optimizer_options))\n  <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Warmup</span>\n      sess.run(op)\n    start_time <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">50</span>):\n      sess.run(op)\n    total_time <span class=\"pl-k\">=</span> time.time() <span class=\"pl-k\">-</span> start_time\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>total time: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(total_time))\n    sess.run(op, <span class=\"pl-v\">run_metadata</span><span class=\"pl-k\">=</span>run_metadata, <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>options)\n    tl <span class=\"pl-k\">=</span> timeline.Timeline(run_metadata.step_stats)\n    ctf <span class=\"pl-k\">=</span> tl.generate_chrome_trace_format()\n    <span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>timeline.json<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>w<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n      f.write(ctf)</pre></div>", "body_text": "You're right, it its still significantly slower when size=21.\nWhen disabling optimizations, the case where size=20 slows down to about the speed of size=21, which makes me suspect certain optimizations are only applied when size=20. Disabling optimizations when size=21 does not significantly affect performance.\n/CC @zhangyaobit, can you comment on whether optimizations are being applied when size=20? A code sample with warmup batches with optmizations disabled is below:\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\nimport time\n\nsize = 21\nchannels = 64\n\nwith tf.device('/CPU:0'):\n  x = tf.random_uniform((100, 20))\n  w0 = tf.get_variable('w', (20, size * size * channels))\n  h = tf.reshape(tf.matmul(x, w0), (100, size, size, channels))\n  out = tf.extract_image_patches(images=h,\n                                 ksizes=(1, 5, 5, 1),\n                                 strides=(1, 1, 1, 1),\n                                 rates=(1, 1, 1, 1),\n                                 padding='VALID')\n\n  loss = tf.reduce_mean(out)\n  op = tf.train.AdamOptimizer().minimize(out)\n\n  options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n  run_metadata = tf.RunMetadata()\n  optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\n  config = tf.ConfigProto(\n      graph_options=tf.GraphOptions(optimizer_options=optimizer_options))\n  with tf.Session(config=config) as sess:\n    sess.run(tf.global_variables_initializer())\n    for _ in range(10):  # Warmup\n      sess.run(op)\n    start_time = time.time()\n    for _ in range(50):\n      sess.run(op)\n    total_time = time.time() - start_time\n    print('total time: {}'.format(total_time))\n    sess.run(op, run_metadata=run_metadata, options=options)\n    tl = timeline.Timeline(run_metadata.step_stats)\n    ctf = tl.generate_chrome_trace_format()\n    with open('timeline.json', 'w') as f:\n      f.write(ctf)", "body": "You're right, it its still significantly slower when `size=21`. \r\n\r\nWhen disabling optimizations, the case where `size=20` slows down to about the speed of `size=21`, which makes me suspect certain optimizations are only applied when `size=20`. Disabling optimizations when `size=21` does not significantly affect performance.\r\n\r\n/CC @zhangyaobit, can you comment on whether optimizations are being applied when `size=20`? A code sample with warmup batches with optmizations disabled is below:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\nimport time\r\n\r\nsize = 21\r\nchannels = 64\r\n\r\nwith tf.device('/CPU:0'):\r\n  x = tf.random_uniform((100, 20))\r\n  w0 = tf.get_variable('w', (20, size * size * channels))\r\n  h = tf.reshape(tf.matmul(x, w0), (100, size, size, channels))\r\n  out = tf.extract_image_patches(images=h,\r\n                                 ksizes=(1, 5, 5, 1),\r\n                                 strides=(1, 1, 1, 1),\r\n                                 rates=(1, 1, 1, 1),\r\n                                 padding='VALID')\r\n\r\n  loss = tf.reduce_mean(out)\r\n  op = tf.train.AdamOptimizer().minimize(out)\r\n\r\n  options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n  run_metadata = tf.RunMetadata()\r\n  optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\r\n  config = tf.ConfigProto(\r\n      graph_options=tf.GraphOptions(optimizer_options=optimizer_options))\r\n  with tf.Session(config=config) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for _ in range(10):  # Warmup\r\n      sess.run(op)\r\n    start_time = time.time()\r\n    for _ in range(50):\r\n      sess.run(op)\r\n    total_time = time.time() - start_time\r\n    print('total time: {}'.format(total_time))\r\n    sess.run(op, run_metadata=run_metadata, options=options)\r\n    tl = timeline.Timeline(run_metadata.step_stats)\r\n    ctf = tl.generate_chrome_trace_format()\r\n    with open('timeline.json', 'w') as f:\r\n      f.write(ctf)\r\n```"}