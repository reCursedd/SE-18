{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/413376942", "html_url": "https://github.com/tensorflow/tensorflow/issues/19283#issuecomment-413376942", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19283", "id": 413376942, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzM3Njk0Mg==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-15T23:57:52Z", "updated_at": "2018-08-15T23:57:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My 2 cents: currently all CUDA device memory are allocated through the CUDA Stream API, which does not guarantee to synchronize with user CUDA code, i.e. it only enqueues the memory allocation ops and returns immediately instead of waiting it to finish.</p>\n<p>You could either do manual synchronization or use TensorFlow\u2019s wrapped CUDA StreamExecutor for async cuMemcpy (higher performance in general).</p>", "body_text": "My 2 cents: currently all CUDA device memory are allocated through the CUDA Stream API, which does not guarantee to synchronize with user CUDA code, i.e. it only enqueues the memory allocation ops and returns immediately instead of waiting it to finish.\nYou could either do manual synchronization or use TensorFlow\u2019s wrapped CUDA StreamExecutor for async cuMemcpy (higher performance in general).", "body": "My 2 cents: currently all CUDA device memory are allocated through the CUDA Stream API, which does not guarantee to synchronize with user CUDA code, i.e. it only enqueues the memory allocation ops and returns immediately instead of waiting it to finish.\r\n\r\nYou could either do manual synchronization or use TensorFlow\u2019s wrapped CUDA StreamExecutor for async cuMemcpy (higher performance in general)."}