{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/430814852", "html_url": "https://github.com/tensorflow/tensorflow/issues/23036#issuecomment-430814852", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23036", "id": 430814852, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDgxNDg1Mg==", "user": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T22:43:10Z", "updated_at": "2018-10-17T22:43:10Z", "author_association": "NONE", "body_html": "<p>In neural networks the last layer outputs the final activation i.e final result of our model. Therefore its meaningful to interpret this result as a probability number ranging from (0-1).This squashing of final activation into desired probability value is performed by the softmax activation function of output layer. Therefore it makes sense to add a softmax layer as an output layer to your neural network model.</p>", "body_text": "In neural networks the last layer outputs the final activation i.e final result of our model. Therefore its meaningful to interpret this result as a probability number ranging from (0-1).This squashing of final activation into desired probability value is performed by the softmax activation function of output layer. Therefore it makes sense to add a softmax layer as an output layer to your neural network model.", "body": "In neural networks the last layer outputs the final activation i.e final result of our model. Therefore its meaningful to interpret this result as a probability number ranging from (0-1).This squashing of final activation into desired probability value is performed by the softmax activation function of output layer. Therefore it makes sense to add a softmax layer as an output layer to your neural network model."}