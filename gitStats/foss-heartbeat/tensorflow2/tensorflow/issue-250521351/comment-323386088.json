{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323386088", "html_url": "https://github.com/tensorflow/tensorflow/issues/12314#issuecomment-323386088", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12314", "id": 323386088, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzM4NjA4OA==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-18T15:32:58Z", "updated_at": "2017-08-18T15:32:58Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>Can you just use TF's FFT implementation for now? You can still use XLA to compile other parts of the TF graph.</p>\n</blockquote>\n<p>Unfortunately no. I need to compile a trained model for deployment. I suppose for this particular use case I could rewrite the non-supported parts of the forward pass directly in the XLA AOT C++ wrapper with Eigen though, but that's a bit messy. It might also introduce unwanted train/test skew.</p>", "body_text": "Can you just use TF's FFT implementation for now? You can still use XLA to compile other parts of the TF graph.\n\nUnfortunately no. I need to compile a trained model for deployment. I suppose for this particular use case I could rewrite the non-supported parts of the forward pass directly in the XLA AOT C++ wrapper with Eigen though, but that's a bit messy. It might also introduce unwanted train/test skew.", "body": "> Can you just use TF's FFT implementation for now? You can still use XLA to compile other parts of the TF graph.\r\n\r\nUnfortunately no. I need to compile a trained model for deployment. I suppose for this particular use case I could rewrite the non-supported parts of the forward pass directly in the XLA AOT C++ wrapper with Eigen though, but that's a bit messy. It might also introduce unwanted train/test skew."}