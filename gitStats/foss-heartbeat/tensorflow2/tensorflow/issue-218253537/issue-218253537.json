{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8846", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8846/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8846/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8846/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8846", "id": 218253537, "node_id": "MDU6SXNzdWUyMTgyNTM1Mzc=", "number": 8846, "title": "Crashing when trying distributed implementation", "user": {"login": "tommaso90", "id": 26794474, "node_id": "MDQ6VXNlcjI2Nzk0NDc0", "avatar_url": "https://avatars3.githubusercontent.com/u/26794474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tommaso90", "html_url": "https://github.com/tommaso90", "followers_url": "https://api.github.com/users/tommaso90/followers", "following_url": "https://api.github.com/users/tommaso90/following{/other_user}", "gists_url": "https://api.github.com/users/tommaso90/gists{/gist_id}", "starred_url": "https://api.github.com/users/tommaso90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tommaso90/subscriptions", "organizations_url": "https://api.github.com/users/tommaso90/orgs", "repos_url": "https://api.github.com/users/tommaso90/repos", "events_url": "https://api.github.com/users/tommaso90/events{/privacy}", "received_events_url": "https://api.github.com/users/tommaso90/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-30T16:25:58Z", "updated_at": "2017-05-30T17:27:34Z", "closed_at": "2017-05-30T17:27:34Z", "author_association": "NONE", "body_html": "<p>Hi, I start saying that I'm a new Tensorflow user :-)</p>\n<p>I was trying to test the potential speed-up due to a distributed implementation vs. a sequential one, so I came up with the following:</p>\n<ol>\n<li>A script sequentially computing matmul of two matrices with themselves and then adding them up</li>\n<li>A script that distributes the two computations to different devices and then sum them up in a third device</li>\n</ol>\n<p>The problem is the following: if I run the code below with matrices' dimensions of 100x100, it works. If I run the same with dimensions 1000x1000, the following error occurs:</p>\n<blockquote>\n<p>tensorflow.python.framework.errors_impl.InternalError: {\"created\":\"@1490890419.097000000\",\"description\":\"RST_STREAM\",\"file\":\"C:\\tf_jenkins\\home\\workspace\\release-win\\DEVICE\\cpu\\OS\\windows\\cmake_build\\grpc\\src\\grpc\\src\\core\\ext\\transport\\chttp2\\transport\\frame_rst_stream.c\",\"file_line\":107,\"http2_error\":1}</p>\n</blockquote>\n<p>I can't figure it out, so any help would be appreciated...</p>\n<p>Here is the distributed code (after 3 local Servers have been created):</p>\n<pre><code>import tensorflow as tf\nimport time\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\"]})\n\nwith tf.device(\"/job:local/task:1\"):\n    print('task 1')\n    x1 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\n    _matmul_1 = tf.matmul(x1,x1)\n\nwith tf.device(\"/job:local/task:0\"):\n    print('task 0')\n    x0 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\n    _matmul_0 = tf.matmul(x0, x0)\n\nwith tf.device(\"/job:local/task:2\"):\n    print('task 2')\n    _matmul_ = tf.add(_matmul_0,_matmul_1)\n\ntime4 = time.clock()\nsess = tf.Session(\"grpc://localhost:2222\")\nprint('session')\ninit = tf.global_variables_initializer()\nsess.run(init)\nprint(sess.run(_matmul_))\ntime5 = time.clock()\nprint(time5-time4)\n</code></pre>", "body_text": "Hi, I start saying that I'm a new Tensorflow user :-)\nI was trying to test the potential speed-up due to a distributed implementation vs. a sequential one, so I came up with the following:\n\nA script sequentially computing matmul of two matrices with themselves and then adding them up\nA script that distributes the two computations to different devices and then sum them up in a third device\n\nThe problem is the following: if I run the code below with matrices' dimensions of 100x100, it works. If I run the same with dimensions 1000x1000, the following error occurs:\n\ntensorflow.python.framework.errors_impl.InternalError: {\"created\":\"@1490890419.097000000\",\"description\":\"RST_STREAM\",\"file\":\"C:\\tf_jenkins\\home\\workspace\\release-win\\DEVICE\\cpu\\OS\\windows\\cmake_build\\grpc\\src\\grpc\\src\\core\\ext\\transport\\chttp2\\transport\\frame_rst_stream.c\",\"file_line\":107,\"http2_error\":1}\n\nI can't figure it out, so any help would be appreciated...\nHere is the distributed code (after 3 local Servers have been created):\nimport tensorflow as tf\nimport time\n\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\"]})\n\nwith tf.device(\"/job:local/task:1\"):\n    print('task 1')\n    x1 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\n    _matmul_1 = tf.matmul(x1,x1)\n\nwith tf.device(\"/job:local/task:0\"):\n    print('task 0')\n    x0 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\n    _matmul_0 = tf.matmul(x0, x0)\n\nwith tf.device(\"/job:local/task:2\"):\n    print('task 2')\n    _matmul_ = tf.add(_matmul_0,_matmul_1)\n\ntime4 = time.clock()\nsess = tf.Session(\"grpc://localhost:2222\")\nprint('session')\ninit = tf.global_variables_initializer()\nsess.run(init)\nprint(sess.run(_matmul_))\ntime5 = time.clock()\nprint(time5-time4)", "body": "Hi, I start saying that I'm a new Tensorflow user :-)\r\n\r\nI was trying to test the potential speed-up due to a distributed implementation vs. a sequential one, so I came up with the following:\r\n\r\n1. A script sequentially computing matmul of two matrices with themselves and then adding them up\r\n2. A script that distributes the two computations to different devices and then sum them up in a third device\r\n\r\nThe problem is the following: if I run the code below with matrices' dimensions of 100x100, it works. If I run the same with dimensions 1000x1000, the following error occurs:\r\n\r\n> tensorflow.python.framework.errors_impl.InternalError: {\"created\":\"@1490890419.097000000\",\"description\":\"RST_STREAM\",\"file\":\"C:\\tf_jenkins\\home\\workspace\\release-win\\DEVICE\\cpu\\OS\\windows\\cmake_build\\grpc\\src\\grpc\\src\\core\\ext\\transport\\chttp2\\transport\\frame_rst_stream.c\",\"file_line\":107,\"http2_error\":1}\r\n\r\nI can't figure it out, so any help would be appreciated...\r\n\r\nHere is the distributed code (after 3 local Servers have been created):\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\", \"localhost:2224\"]})\r\n\r\nwith tf.device(\"/job:local/task:1\"):\r\n    print('task 1')\r\n    x1 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\r\n    _matmul_1 = tf.matmul(x1,x1)\r\n\r\nwith tf.device(\"/job:local/task:0\"):\r\n    print('task 0')\r\n    x0 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)\r\n    _matmul_0 = tf.matmul(x0, x0)\r\n\r\nwith tf.device(\"/job:local/task:2\"):\r\n    print('task 2')\r\n    _matmul_ = tf.add(_matmul_0,_matmul_1)\r\n\r\ntime4 = time.clock()\r\nsess = tf.Session(\"grpc://localhost:2222\")\r\nprint('session')\r\ninit = tf.global_variables_initializer()\r\nsess.run(init)\r\nprint(sess.run(_matmul_))\r\ntime5 = time.clock()\r\nprint(time5-time4)\r\n```"}