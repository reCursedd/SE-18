{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415873759", "html_url": "https://github.com/tensorflow/tensorflow/issues/21440#issuecomment-415873759", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21440", "id": 415873759, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTg3Mzc1OQ==", "user": {"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T20:28:30Z", "updated_at": "2018-08-24T20:28:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I skimmed over the paper and I think it should handle variable input size as you said.</p>\n<p>Assuming the network architecture can really handle arbitrary input size (I skimmed over the paper and I think it does), could you try this and let us know if it works:</p>\n<ul>\n<li>When converting, use an arbitrary input size like (1, 512, 512, 3).</li>\n<li>When using the interpreter, call <code>interpreter-&gt;ResizeInputTensor</code> to resize the input tensor before calling <code>interpreter-&gt;Invoke</code>.</li>\n</ul>\n<p>Theoretically it should do the trick. Let us know if it works for your case.</p>", "body_text": "I skimmed over the paper and I think it should handle variable input size as you said.\nAssuming the network architecture can really handle arbitrary input size (I skimmed over the paper and I think it does), could you try this and let us know if it works:\n\nWhen converting, use an arbitrary input size like (1, 512, 512, 3).\nWhen using the interpreter, call interpreter->ResizeInputTensor to resize the input tensor before calling interpreter->Invoke.\n\nTheoretically it should do the trick. Let us know if it works for your case.", "body": "I skimmed over the paper and I think it should handle variable input size as you said. \r\n\r\nAssuming the network architecture can really handle arbitrary input size (I skimmed over the paper and I think it does), could you try this and let us know if it works: \r\n\r\n* When converting, use an arbitrary input size like (1, 512, 512, 3). \r\n* When using the interpreter, call `interpreter->ResizeInputTensor` to resize the input tensor before calling `interpreter->Invoke`. \r\n\r\nTheoretically it should do the trick. Let us know if it works for your case. "}