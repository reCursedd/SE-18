{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13499", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13499/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13499/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13499/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13499", "id": 262994008, "node_id": "MDU6SXNzdWUyNjI5OTQwMDg=", "number": 13499, "title": "Using third party library in custom op implementation with GPU memory manipulation", "user": {"login": "laoreja", "id": 9369143, "node_id": "MDQ6VXNlcjkzNjkxNDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/9369143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/laoreja", "html_url": "https://github.com/laoreja", "followers_url": "https://api.github.com/users/laoreja/followers", "following_url": "https://api.github.com/users/laoreja/following{/other_user}", "gists_url": "https://api.github.com/users/laoreja/gists{/gist_id}", "starred_url": "https://api.github.com/users/laoreja/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/laoreja/subscriptions", "organizations_url": "https://api.github.com/users/laoreja/orgs", "repos_url": "https://api.github.com/users/laoreja/repos", "events_url": "https://api.github.com/users/laoreja/events{/privacy}", "received_events_url": "https://api.github.com/users/laoreja/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2017-10-05T03:26:27Z", "updated_at": "2018-06-02T07:18:13Z", "closed_at": "2018-06-02T07:05:15Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Ubuntu 14.04.5</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:pip</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.2.0</li>\n<li><strong>Python version</strong>: 2.7.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:CUDA 8.0</li>\n<li><strong>GPU model and memory</strong>:GeForce GTX 1080 8G</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>To speed up the model's training and evaluating process, and to make the model more flexible, people would like to use some third party libraries for their customized ops. For example, CUDPP, <a href=\"http://cudpp.github.io/\" rel=\"nofollow\">http://cudpp.github.io/</a>, allows people to build a hash table on GPU.</p>\n<p>However, I find that TensorFlow does not allow people to manipulate GPU memory by themselves, but only to use allocate_temp in the compute function, which is very inconvenient and inflexible. And these good third party libraries involve many GPU memory manipulations. I cannot find much information about this, but I met some errors in allocating memories.</p>\n<ul>\n<li>What's the reason behind this prohibition?</li>\n<li>Is there some method to allow us manipulate GPU by ourselves? (some switches, some options)</li>\n<li>If we cannot manipulate GPU memory, then how can we use/adapt these third party GPU libraries for the customized ops? What's the good programming practice?</li>\n</ul>\n<p>More specifically, the problem I met is that I implemented a customized op on GPU, using the multivalue hash table from the CUDPP library. For very small-scale data, the customized op passed the test. But when I use larger data, and incorporate the customized op into a larger model, then I cannot allocate the memory on CUDA. <a href=\"https://stackoverflow.com/questions/40183189/trouble-compiling-with-custom-tensorflow-gpu-op\" rel=\"nofollow\">https://stackoverflow.com/questions/40183189/trouble-compiling-with-custom-tensorflow-gpu-op</a>, this expalins something. I can avoid manipulating GPU memory myself, but the CUDPP library needs to manipulate GPU memory.</p>\n<h3>Source code / logs</h3>\n<p>The cudpp git repo: <a href=\"https://github.com/cudpp/cudpp/compare?expand=1\">https://github.com/cudpp/cudpp/compare?expand=1</a>.</p>\n<p>My OpKernel:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-k\">void</span> <span class=\"pl-en\">querySquarePointLauncher</span>(<span class=\"pl-k\">int</span> b, <span class=\"pl-k\">int</span> n, <span class=\"pl-k\">int</span> m, <span class=\"pl-k\">float</span> grid_size, <span class=\"pl-k\">int</span> nsample, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *all_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *centroids_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *limits, <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> *sizes, <span class=\"pl-k\">int</span> *idx, <span class=\"pl-k\">int</span> *pts_cnt, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_keys, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_vals, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_queries, uint2 *d_vals_multivalue);\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">QuerySquarePointGpuOp</span> : <span class=\"pl-k\">public</span> <span class=\"pl-en\">OpKernel</span> {\n    <span class=\"pl-k\">public:</span>\n        <span class=\"pl-k\">explicit</span> <span class=\"pl-en\">QuerySquarePointGpuOp</span>(OpKernelConstruction* context) : OpKernel(context) {\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">GetAttr</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>grid_size<span class=\"pl-pds\">\"</span></span>, &amp;grid_size_));\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, grid_size_ &gt; <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects positive grid size<span class=\"pl-pds\">\"</span></span>));\n\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">GetAttr</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nsample<span class=\"pl-pds\">\"</span></span>, &amp;nsample_));\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, nsample_ &gt; <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects positive nsample<span class=\"pl-pds\">\"</span></span>));\n        }\n\n        <span class=\"pl-k\">void</span> <span class=\"pl-en\">Compute</span>(OpKernelContext* context) <span class=\"pl-k\">override</span> {\n            <span class=\"pl-k\">const</span> Tensor&amp; all_xyz_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>);\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, all_xyz_tensor.<span class=\"pl-c1\">dims</span>()==<span class=\"pl-c1\">3</span> &amp;&amp; all_xyz_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">2</span>)==<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects (batch_size, ndataset, 3) all_xyz_tensor shape.<span class=\"pl-pds\">\"</span></span>));\n            <span class=\"pl-k\">int</span> b = all_xyz_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">0</span>);\n            <span class=\"pl-k\">int</span> n = all_xyz_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">1</span>);\n\n            <span class=\"pl-k\">const</span> Tensor&amp; centroids_xyz_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">1</span>);\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, centroids_xyz_tensor.<span class=\"pl-c1\">dims</span>()==<span class=\"pl-c1\">3</span> &amp;&amp; centroids_xyz_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">2</span>)==<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects (batch_size, npoint, 3) centroids_xyz shape.<span class=\"pl-pds\">\"</span></span>));\n            <span class=\"pl-k\">int</span> m = centroids_xyz_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">1</span>);\n            \n            <span class=\"pl-k\">const</span> Tensor&amp; limits_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">2</span>);\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, limits_tensor.<span class=\"pl-c1\">dims</span>()==<span class=\"pl-c1\">1</span> &amp;&amp; limits_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">0</span>)==<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects (6) limits shape.<span class=\"pl-pds\">\"</span></span>))\n            \n            <span class=\"pl-k\">const</span> Tensor&amp; sizes_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">3</span>);\n            <span class=\"pl-c1\">OP_REQUIRES</span>(context, sizes_tensor.<span class=\"pl-c1\">dims</span>()==<span class=\"pl-c1\">1</span> &amp;&amp; sizes_tensor.<span class=\"pl-c1\">shape</span>().<span class=\"pl-c1\">dim_size</span>(<span class=\"pl-c1\">0</span>) == <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">errors::InvalidArgument</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint expects (3) sizes shape.<span class=\"pl-pds\">\"</span></span>))\n\n            Tensor *idx_tensor = <span class=\"pl-c1\">nullptr</span>;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">0</span>, TensorShape{b,m,nsample_}, &amp;idx_tensor));\n            Tensor *pts_cnt_tensor = <span class=\"pl-c1\">nullptr</span>;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">1</span>, TensorShape{b,m}, &amp;pts_cnt_tensor));\n            \n            Tensor keys_tensor;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_temp</span>(DT_INT32, <span class=\"pl-c1\">TensorShape</span>({b*n}), &amp;keys_tensor));\n            \n            Tensor vals_tensor;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_temp</span>(DT_INT32, <span class=\"pl-c1\">TensorShape</span>({b*n}), &amp;vals_tensor));\n            \n            Tensor vals_multivalue_tensor;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_temp</span>(DT_INT32, <span class=\"pl-c1\">TensorShape</span>({b*m*<span class=\"pl-c1\">27</span>*<span class=\"pl-c1\">2</span>}), &amp;vals_multivalue_tensor));\n            \n            Tensor queries_tensor;\n            <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_temp</span>(DT_INT32, <span class=\"pl-c1\">TensorShape</span>({b*m*<span class=\"pl-c1\">27</span>}), &amp;queries_tensor));\n            \n\n            <span class=\"pl-k\">auto</span> all_xyz_flat = all_xyz_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">float</span>&gt;();\n            <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *all_xyz = &amp;(<span class=\"pl-c1\">all_xyz_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> centroids_xyz_flat = centroids_xyz_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">float</span>&gt;();\n            <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *centroids_xyz = &amp;(<span class=\"pl-c1\">centroids_xyz_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> limits_flat = limits_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">float</span>&gt;();\n            <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *limits = &amp;(<span class=\"pl-c1\">limits_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> sizes_flat = sizes_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> *sizes = &amp;(<span class=\"pl-c1\">sizes_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> idx_flat = idx_tensor-&gt;<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">int</span> *idx = &amp;(<span class=\"pl-c1\">idx_flat</span>(<span class=\"pl-c1\">0</span>));\n            <span class=\"pl-k\">auto</span> pts_cnt_flat = pts_cnt_tensor-&gt;<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">int</span> *pts_cnt = &amp;(<span class=\"pl-c1\">pts_cnt_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> keys_flat = keys_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *keys = (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *)&amp;(<span class=\"pl-c1\">keys_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> vals_flat = vals_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *vals = (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *)&amp;(<span class=\"pl-c1\">vals_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> queries_flat = queries_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *queries = (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *)&amp;(<span class=\"pl-c1\">queries_flat</span>(<span class=\"pl-c1\">0</span>));\n            \n            <span class=\"pl-k\">auto</span> vals_multivalue_flat = vals_multivalue_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">int</span>&gt;();\n            uint2 *vals_multivalue = <span class=\"pl-k\">reinterpret_cast</span>&lt;uint2*&gt; (&amp;(<span class=\"pl-c1\">vals_multivalue_flat</span>(<span class=\"pl-c1\">0</span>)));\n            \n            <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Before launcher in cpp<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n            \n            <span class=\"pl-c1\">querySquarePointLauncher</span>(b, n, m, grid_size_, nsample_, all_xyz, centroids_xyz, limits, sizes, idx, pts_cnt, keys, vals, queries, vals_multivalue);         \n        }\n    <span class=\"pl-k\">private:</span>\n        <span class=\"pl-k\">float</span> grid_size_;\n        <span class=\"pl-k\">int</span> nsample_;\n};\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>QuerySquarePoint<span class=\"pl-pds\">\"</span></span>).Device(DEVICE_GPU), QuerySquarePointGpuOp);</pre></div>\n<p>The CUDA implementation:</p>\n<div class=\"highlight highlight-source-c++\"><pre>__global__ <span class=\"pl-k\">void</span> <span class=\"pl-en\">compose_insert_items</span>(<span class=\"pl-k\">int</span> b, <span class=\"pl-k\">int</span> n, <span class=\"pl-k\">float</span> grid_size, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *all_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *limits, <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> *sizes, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_keys, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_vals){\n    <span class=\"pl-k\">int</span> <span class=\"pl-c1\">index</span> = threadIdx.<span class=\"pl-smi\">x</span>;\n   \n    <span class=\"pl-k\">if</span>(<span class=\"pl-c1\">index</span> &lt; n){\n        <span class=\"pl-k\">int</span> batch_index = blockIdx.<span class=\"pl-smi\">x</span>;\n        all_xyz += batch_index * n * <span class=\"pl-c1\">3</span>;\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *tmp_d_keys = d_keys + batch_index * n;\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *tmp_d_vals = d_vals + batch_index * n;\n        <span class=\"pl-k\">int</span> stride = blockDim.<span class=\"pl-smi\">x</span>;\n        \n        <span class=\"pl-k\">for</span>(<span class=\"pl-k\">int</span> point_idx = <span class=\"pl-c1\">index</span>; point_idx &lt; n; point_idx += stride){\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> x_idx = <span class=\"pl-c1\">__float2uint_rd</span>((all_xyz[point_idx*<span class=\"pl-c1\">3</span>] - limits[<span class=\"pl-c1\">0</span>]) / grid_size) + <span class=\"pl-c1\">1</span>;\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> y_idx = <span class=\"pl-c1\">__float2uint_rd</span>((all_xyz[point_idx*<span class=\"pl-c1\">3</span>+<span class=\"pl-c1\">1</span>] - limits[<span class=\"pl-c1\">2</span>]) / grid_size) + <span class=\"pl-c1\">1</span>;\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> z_idx = <span class=\"pl-c1\">__float2uint_rd</span>((all_xyz[point_idx*<span class=\"pl-c1\">3</span>+<span class=\"pl-c1\">2</span>] - limits[<span class=\"pl-c1\">4</span>]) / grid_size) + <span class=\"pl-c1\">1</span>;\n            \n            tmp_d_keys[point_idx] = z_idx + sizes[<span class=\"pl-c1\">2</span>] * (y_idx + sizes[<span class=\"pl-c1\">1</span>] * (x_idx + batch_index * sizes[<span class=\"pl-c1\">0</span>]));\n            tmp_d_vals[point_idx] = point_idx;\n        }\n    }\n}\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>compose_queries&lt;&lt;&lt;b,256&gt;&gt;&gt;(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);</span>\n__global__ <span class=\"pl-k\">void</span> <span class=\"pl-en\">compose_queries</span>(<span class=\"pl-k\">int</span> b, <span class=\"pl-k\">int</span> m, <span class=\"pl-k\">float</span> grid_size, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *centroids_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *limits, <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> *sizes, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_queries){\n\n    <span class=\"pl-k\">int</span> <span class=\"pl-c1\">index</span> = threadIdx.<span class=\"pl-smi\">x</span>;\n    \n    <span class=\"pl-k\">if</span>(<span class=\"pl-c1\">index</span> &lt; m){\n        <span class=\"pl-k\">int</span> stride = blockDim.<span class=\"pl-smi\">x</span>;\n        <span class=\"pl-k\">int</span> batch_index = blockIdx.<span class=\"pl-smi\">x</span>;\n        centroids_xyz += batch_index * m * <span class=\"pl-c1\">3</span>;\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *tmp_d_queries = d_queries + batch_index * m * <span class=\"pl-c1\">27</span>;\n        \n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> x_idx = <span class=\"pl-c1\">__float2uint_rd</span>((centroids_xyz[<span class=\"pl-c1\">index</span>*<span class=\"pl-c1\">3</span>] - limits[<span class=\"pl-c1\">0</span>]) / grid_size);\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> y_idx = <span class=\"pl-c1\">__float2uint_rd</span>((centroids_xyz[<span class=\"pl-c1\">index</span>*<span class=\"pl-c1\">3</span>+<span class=\"pl-c1\">1</span>] - limits[<span class=\"pl-c1\">2</span>]) / grid_size);\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> z_idx = <span class=\"pl-c1\">__float2uint_rd</span>((centroids_xyz[<span class=\"pl-c1\">index</span>*<span class=\"pl-c1\">3</span>+<span class=\"pl-c1\">2</span>] - limits[<span class=\"pl-c1\">4</span>]) / grid_size);\n        \n        <span class=\"pl-k\">int</span> cnt = <span class=\"pl-c1\">0</span>;\n        <span class=\"pl-k\">for</span>(<span class=\"pl-k\">int</span> x_offset = <span class=\"pl-c1\">0</span>; x_offset &lt; <span class=\"pl-c1\">3</span>; x_offset++){\n            <span class=\"pl-k\">for</span>(<span class=\"pl-k\">int</span> y_offset = <span class=\"pl-c1\">0</span>; y_offset &lt; <span class=\"pl-c1\">3</span>; y_offset++){\n                <span class=\"pl-k\">for</span>(<span class=\"pl-k\">int</span> z_offset = <span class=\"pl-c1\">0</span>; z_offset &lt; <span class=\"pl-c1\">3</span>; z_offset++){\n                    tmp_d_queries[<span class=\"pl-c1\">index</span>*<span class=\"pl-c1\">27</span>+cnt] = z_idx + z_offset + sizes[<span class=\"pl-c1\">2</span>] * (y_idx + y_offset + sizes[<span class=\"pl-c1\">1</span>] * (x_idx + x_offset + batch_index * sizes[<span class=\"pl-c1\">0</span>]));  \n                    cnt++;\n                }\n            }\n        }\n\n    }\n}\n__global__ <span class=\"pl-k\">void</span> <span class=\"pl-en\">hash_square_idx_gpu</span>(<span class=\"pl-k\">int</span> b, <span class=\"pl-k\">int</span> n, <span class=\"pl-k\">int</span> m, <span class=\"pl-k\">int</span> nsample, <span class=\"pl-k\">const</span> uint2 *d_vals_multivalue, <span class=\"pl-k\">const</span> <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> * d_all_values, <span class=\"pl-k\">int</span> *idx, <span class=\"pl-k\">int</span> *pts_cnt){\n    <span class=\"pl-k\">int</span> <span class=\"pl-c1\">index</span> = threadIdx.<span class=\"pl-smi\">x</span>;\n    <span class=\"pl-k\">if</span>(<span class=\"pl-c1\">index</span> &lt; m){\n        <span class=\"pl-k\">int</span> stride = blockDim.<span class=\"pl-smi\">x</span>;\n        <span class=\"pl-k\">int</span> batch_index = blockIdx.<span class=\"pl-smi\">x</span>;\n        <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> sorted_idx[<span class=\"pl-c1\">27</span>] = {<span class=\"pl-c1\">13</span>, <span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">12</span>,<span class=\"pl-c1\">14</span>,<span class=\"pl-c1\">16</span>,<span class=\"pl-c1\">22</span>, <span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">7</span>,<span class=\"pl-c1\">9</span>,<span class=\"pl-c1\">11</span>,<span class=\"pl-c1\">15</span>,<span class=\"pl-c1\">17</span>,<span class=\"pl-c1\">19</span>,<span class=\"pl-c1\">21</span>,<span class=\"pl-c1\">23</span>,<span class=\"pl-c1\">25</span>,  <span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">6</span>,<span class=\"pl-c1\">8</span>,<span class=\"pl-c1\">18</span>,<span class=\"pl-c1\">20</span>,<span class=\"pl-c1\">24</span>,<span class=\"pl-c1\">26</span>};\n                \n        idx += batch_index * m * nsample;\n        pts_cnt += batch_index * m;\n        <span class=\"pl-k\">int</span> query_idx_base = batch_index*m*<span class=\"pl-c1\">27</span>+<span class=\"pl-c1\">index</span>*<span class=\"pl-c1\">27</span>;\n        \n        <span class=\"pl-k\">int</span> cnt = <span class=\"pl-c1\">0</span>;\n        <span class=\"pl-k\">for</span>(<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; <span class=\"pl-c1\">27</span>; i++){\n            <span class=\"pl-k\">int</span> query_idx = query_idx_base + sorted_idx[i];\n            <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> num_values = d_vals_multivalue[query_idx].<span class=\"pl-smi\">y</span>;\n            <span class=\"pl-k\">if</span>(num_values &gt; <span class=\"pl-c1\">0</span>){\n                <span class=\"pl-k\">for</span>(<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; num_values &amp;&amp; cnt &lt; nsample; j++){\n                    idx[<span class=\"pl-c1\">index</span>*nsample + cnt] = d_all_values[d_vals_multivalue[query_idx].<span class=\"pl-smi\">x</span> + j];\n                    cnt++;\n                }\n            }\n        }\n        pts_cnt[<span class=\"pl-c1\">index</span>] = cnt;\n        <span class=\"pl-k\">for</span>(;cnt &lt; nsample;cnt++){\n            idx[<span class=\"pl-c1\">index</span>*nsample + cnt] = idx[<span class=\"pl-c1\">index</span>*nsample];\n        }\n    }\n}\n\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">querySquarePointLauncher</span>(<span class=\"pl-k\">int</span> b, <span class=\"pl-k\">int</span> n, <span class=\"pl-k\">int</span> m, <span class=\"pl-k\">float</span> grid_size, <span class=\"pl-k\">int</span> nsample, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *all_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *centroids_xyz, <span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span> *limits, <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> *sizes, <span class=\"pl-k\">int</span> *idx, <span class=\"pl-k\">int</span> *pts_cnt, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_keys, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_vals, <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> *d_queries, uint2 *d_vals_multivalue) {\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Start<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);    \n    <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> <span class=\"pl-c1\">kInputSize</span> = b * n;\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>b %d, n %d, kInputSize: %u<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>, b, n, <span class=\"pl-c1\">kInputSize</span>);\n    \n    compose_insert_items&lt;&lt;&lt;b,<span class=\"pl-c1\">256</span>&gt;&gt;&gt;(b, n, grid_size, all_xyz, limits, sizes, d_keys, d_vals);\n    <span class=\"pl-c1\">cudaDeviceSynchronize</span>();\n    \n    CUDPPHandle theCudpp;\n    CUDPPResult result = <span class=\"pl-c1\">cudppCreate</span>(&amp;theCudpp);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error initializing CUDPP Library.<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n        <span class=\"pl-c1\">exit</span>(-<span class=\"pl-c1\">1</span>);\n    }\n\n    CUDPPHashTableConfig config;\n    config.<span class=\"pl-smi\">type</span> = CUDPP_MULTIVALUE_HASH_TABLE;\n    config.<span class=\"pl-smi\">kInputSize</span> = <span class=\"pl-c1\">kInputSize</span>;\n    config.<span class=\"pl-smi\">space_usage</span> = <span class=\"pl-c1\">2</span>.<span class=\"pl-c1\">0f</span>;\n    CUDPPHandle hash_table_handle;\n    result = <span class=\"pl-c1\">cudppHashTable</span>(theCudpp, &amp;hash_table_handle, &amp;config);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error in cudppHashTable call in<span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>testHashTable (make sure your device is at<span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>least compute version 2.0<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n    \n    result = <span class=\"pl-c1\">cudppHashInsert</span>(hash_table_handle, d_keys,\n                                d_vals, <span class=\"pl-c1\">kInputSize</span>);\n    <span class=\"pl-c1\">cudaThreadSynchronize</span>();\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>insert values<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error in cudppHashInsert call in<span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>testHashTable<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n    \n    <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> values_size;\n    <span class=\"pl-k\">if</span> (<span class=\"pl-c1\">cudppMultivalueHashGetValuesSize</span>(hash_table_handle,\n                                    &amp;values_size) !=\n                                    CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error: <span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cudppMultivalueHashGetValuesSize()<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n    \n    <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> * d_all_values = <span class=\"pl-c1\">NULL</span>;\n    <span class=\"pl-k\">if</span> (<span class=\"pl-c1\">cudppMultivalueHashGetAllValues</span>(hash_table_handle,\n                                        &amp;d_all_values) !=\n                                        CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error: <span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cudppMultivalueHashGetAllValues()<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n    \n    compose_queries&lt;&lt;&lt;b,<span class=\"pl-c1\">256</span>&gt;&gt;&gt;(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);\n    <span class=\"pl-c1\">cudaDeviceSynchronize</span>();\n    \n    result = <span class=\"pl-c1\">cudppHashRetrieve</span>(hash_table_handle,\n                                d_queries,\n                                d_vals_multivalue,\n                                b * m * <span class=\"pl-c1\">27</span>);\n    <span class=\"pl-c1\">cudaThreadSynchronize</span>();\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>retrieved values<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error in cudppHashRetrieve call<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n\n    hash_square_idx_gpu&lt;&lt;&lt;b,<span class=\"pl-c1\">256</span>&gt;&gt;&gt;(b, n, m, nsample, d_vals_multivalue, d_all_values, idx, pts_cnt);\n    <span class=\"pl-c1\">cudaDeviceSynchronize</span>();\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>obtain idx<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    \n    result = <span class=\"pl-c1\">cudppDestroyHashTable</span>(theCudpp, hash_table_handle);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">fprintf</span>(stderr, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error in cudppDestroyHashTable call in<span class=\"pl-pds\">\"</span></span>\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>testHashTable<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n\n    result = <span class=\"pl-c1\">cudppDestroy</span>(theCudpp);\n    <span class=\"pl-k\">if</span> (result != CUDPP_SUCCESS){\n        <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error shutting down CUDPP Library.<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n    }\n    <span class=\"pl-c1\">printf</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Ends<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>);\n}</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 14.04.5\nTensorFlow installed from (source or binary):pip\nTensorFlow version (use command below):1.2.0\nPython version: 2.7.6\nBazel version (if compiling from source):\nCUDA/cuDNN version:CUDA 8.0\nGPU model and memory:GeForce GTX 1080 8G\nExact command to reproduce:\n\nDescribe the problem\nTo speed up the model's training and evaluating process, and to make the model more flexible, people would like to use some third party libraries for their customized ops. For example, CUDPP, http://cudpp.github.io/, allows people to build a hash table on GPU.\nHowever, I find that TensorFlow does not allow people to manipulate GPU memory by themselves, but only to use allocate_temp in the compute function, which is very inconvenient and inflexible. And these good third party libraries involve many GPU memory manipulations. I cannot find much information about this, but I met some errors in allocating memories.\n\nWhat's the reason behind this prohibition?\nIs there some method to allow us manipulate GPU by ourselves? (some switches, some options)\nIf we cannot manipulate GPU memory, then how can we use/adapt these third party GPU libraries for the customized ops? What's the good programming practice?\n\nMore specifically, the problem I met is that I implemented a customized op on GPU, using the multivalue hash table from the CUDPP library. For very small-scale data, the customized op passed the test. But when I use larger data, and incorporate the customized op into a larger model, then I cannot allocate the memory on CUDA. https://stackoverflow.com/questions/40183189/trouble-compiling-with-custom-tensorflow-gpu-op, this expalins something. I can avoid manipulating GPU memory myself, but the CUDPP library needs to manipulate GPU memory.\nSource code / logs\nThe cudpp git repo: https://github.com/cudpp/cudpp/compare?expand=1.\nMy OpKernel:\nvoid querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue);\nclass QuerySquarePointGpuOp : public OpKernel {\n    public:\n        explicit QuerySquarePointGpuOp(OpKernelConstruction* context) : OpKernel(context) {\n            OP_REQUIRES_OK(context, context->GetAttr(\"grid_size\", &grid_size_));\n            OP_REQUIRES(context, grid_size_ > 0, errors::InvalidArgument(\"QuerySquarePoint expects positive grid size\"));\n\n            OP_REQUIRES_OK(context, context->GetAttr(\"nsample\", &nsample_));\n            OP_REQUIRES(context, nsample_ > 0, errors::InvalidArgument(\"QuerySquarePoint expects positive nsample\"));\n        }\n\n        void Compute(OpKernelContext* context) override {\n            const Tensor& all_xyz_tensor = context->input(0);\n            OP_REQUIRES(context, all_xyz_tensor.dims()==3 && all_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(\"QuerySquarePoint expects (batch_size, ndataset, 3) all_xyz_tensor shape.\"));\n            int b = all_xyz_tensor.shape().dim_size(0);\n            int n = all_xyz_tensor.shape().dim_size(1);\n\n            const Tensor& centroids_xyz_tensor = context->input(1);\n            OP_REQUIRES(context, centroids_xyz_tensor.dims()==3 && centroids_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(\"QuerySquarePoint expects (batch_size, npoint, 3) centroids_xyz shape.\"));\n            int m = centroids_xyz_tensor.shape().dim_size(1);\n            \n            const Tensor& limits_tensor = context->input(2);\n            OP_REQUIRES(context, limits_tensor.dims()==1 && limits_tensor.shape().dim_size(0)==6, errors::InvalidArgument(\"QuerySquarePoint expects (6) limits shape.\"))\n            \n            const Tensor& sizes_tensor = context->input(3);\n            OP_REQUIRES(context, sizes_tensor.dims()==1 && sizes_tensor.shape().dim_size(0) == 3, errors::InvalidArgument(\"QuerySquarePoint expects (3) sizes shape.\"))\n\n            Tensor *idx_tensor = nullptr;\n            OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape{b,m,nsample_}, &idx_tensor));\n            Tensor *pts_cnt_tensor = nullptr;\n            OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape{b,m}, &pts_cnt_tensor));\n            \n            Tensor keys_tensor;\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &keys_tensor));\n            \n            Tensor vals_tensor;\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &vals_tensor));\n            \n            Tensor vals_multivalue_tensor;\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27*2}), &vals_multivalue_tensor));\n            \n            Tensor queries_tensor;\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27}), &queries_tensor));\n            \n\n            auto all_xyz_flat = all_xyz_tensor.flat<float>();\n            const float *all_xyz = &(all_xyz_flat(0));\n            \n            auto centroids_xyz_flat = centroids_xyz_tensor.flat<float>();\n            const float *centroids_xyz = &(centroids_xyz_flat(0));\n            \n            auto limits_flat = limits_tensor.flat<float>();\n            const float *limits = &(limits_flat(0));\n            \n            auto sizes_flat = sizes_tensor.flat<int>();\n            const int *sizes = &(sizes_flat(0));\n            \n            auto idx_flat = idx_tensor->flat<int>();\n            int *idx = &(idx_flat(0));\n            auto pts_cnt_flat = pts_cnt_tensor->flat<int>();\n            int *pts_cnt = &(pts_cnt_flat(0));\n            \n            auto keys_flat = keys_tensor.flat<int>();\n            unsigned int *keys = (unsigned int *)&(keys_flat(0));\n            \n            auto vals_flat = vals_tensor.flat<int>();\n            unsigned int *vals = (unsigned int *)&(vals_flat(0));\n            \n            auto queries_flat = queries_tensor.flat<int>();\n            unsigned int *queries = (unsigned int *)&(queries_flat(0));\n            \n            auto vals_multivalue_flat = vals_multivalue_tensor.flat<int>();\n            uint2 *vals_multivalue = reinterpret_cast<uint2*> (&(vals_multivalue_flat(0)));\n            \n            printf(\"Before launcher in cpp\\n\");\n            \n            querySquarePointLauncher(b, n, m, grid_size_, nsample_, all_xyz, centroids_xyz, limits, sizes, idx, pts_cnt, keys, vals, queries, vals_multivalue);         \n        }\n    private:\n        float grid_size_;\n        int nsample_;\n};\nREGISTER_KERNEL_BUILDER(Name(\"QuerySquarePoint\").Device(DEVICE_GPU), QuerySquarePointGpuOp);\nThe CUDA implementation:\n__global__ void compose_insert_items(int b, int n, float grid_size, const float *all_xyz, const float *limits, const int *sizes, unsigned int *d_keys, unsigned int *d_vals){\n    int index = threadIdx.x;\n   \n    if(index < n){\n        int batch_index = blockIdx.x;\n        all_xyz += batch_index * n * 3;\n        unsigned int *tmp_d_keys = d_keys + batch_index * n;\n        unsigned int *tmp_d_vals = d_vals + batch_index * n;\n        int stride = blockDim.x;\n        \n        for(int point_idx = index; point_idx < n; point_idx += stride){\n            unsigned int x_idx = __float2uint_rd((all_xyz[point_idx*3] - limits[0]) / grid_size) + 1;\n            unsigned int y_idx = __float2uint_rd((all_xyz[point_idx*3+1] - limits[2]) / grid_size) + 1;\n            unsigned int z_idx = __float2uint_rd((all_xyz[point_idx*3+2] - limits[4]) / grid_size) + 1;\n            \n            tmp_d_keys[point_idx] = z_idx + sizes[2] * (y_idx + sizes[1] * (x_idx + batch_index * sizes[0]));\n            tmp_d_vals[point_idx] = point_idx;\n        }\n    }\n}\n//compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);\n__global__ void compose_queries(int b, int m, float grid_size, const float *centroids_xyz, const float *limits, const int *sizes, unsigned int *d_queries){\n\n    int index = threadIdx.x;\n    \n    if(index < m){\n        int stride = blockDim.x;\n        int batch_index = blockIdx.x;\n        centroids_xyz += batch_index * m * 3;\n        unsigned int *tmp_d_queries = d_queries + batch_index * m * 27;\n        \n        unsigned int x_idx = __float2uint_rd((centroids_xyz[index*3] - limits[0]) / grid_size);\n        unsigned int y_idx = __float2uint_rd((centroids_xyz[index*3+1] - limits[2]) / grid_size);\n        unsigned int z_idx = __float2uint_rd((centroids_xyz[index*3+2] - limits[4]) / grid_size);\n        \n        int cnt = 0;\n        for(int x_offset = 0; x_offset < 3; x_offset++){\n            for(int y_offset = 0; y_offset < 3; y_offset++){\n                for(int z_offset = 0; z_offset < 3; z_offset++){\n                    tmp_d_queries[index*27+cnt] = z_idx + z_offset + sizes[2] * (y_idx + y_offset + sizes[1] * (x_idx + x_offset + batch_index * sizes[0]));  \n                    cnt++;\n                }\n            }\n        }\n\n    }\n}\n__global__ void hash_square_idx_gpu(int b, int n, int m, int nsample, const uint2 *d_vals_multivalue, const unsigned int * d_all_values, int *idx, int *pts_cnt){\n    int index = threadIdx.x;\n    if(index < m){\n        int stride = blockDim.x;\n        int batch_index = blockIdx.x;\n        unsigned int sorted_idx[27] = {13, 4,10,12,14,16,22, 1,3,5,7,9,11,15,17,19,21,23,25,  0,2,6,8,18,20,24,26};\n                \n        idx += batch_index * m * nsample;\n        pts_cnt += batch_index * m;\n        int query_idx_base = batch_index*m*27+index*27;\n        \n        int cnt = 0;\n        for(int i = 0; i < 27; i++){\n            int query_idx = query_idx_base + sorted_idx[i];\n            unsigned int num_values = d_vals_multivalue[query_idx].y;\n            if(num_values > 0){\n                for(unsigned int j = 0; j < num_values && cnt < nsample; j++){\n                    idx[index*nsample + cnt] = d_all_values[d_vals_multivalue[query_idx].x + j];\n                    cnt++;\n                }\n            }\n        }\n        pts_cnt[index] = cnt;\n        for(;cnt < nsample;cnt++){\n            idx[index*nsample + cnt] = idx[index*nsample];\n        }\n    }\n}\n\nvoid querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue) {\n    printf(\"Start\\n\");    \n    unsigned int kInputSize = b * n;\n    printf(\"b %d, n %d, kInputSize: %u\\n\", b, n, kInputSize);\n    \n    compose_insert_items<<<b,256>>>(b, n, grid_size, all_xyz, limits, sizes, d_keys, d_vals);\n    cudaDeviceSynchronize();\n    \n    CUDPPHandle theCudpp;\n    CUDPPResult result = cudppCreate(&theCudpp);\n    if (result != CUDPP_SUCCESS){\n        fprintf(stderr, \"Error initializing CUDPP Library.\\n\");\n        exit(-1);\n    }\n\n    CUDPPHashTableConfig config;\n    config.type = CUDPP_MULTIVALUE_HASH_TABLE;\n    config.kInputSize = kInputSize;\n    config.space_usage = 2.0f;\n    CUDPPHandle hash_table_handle;\n    result = cudppHashTable(theCudpp, &hash_table_handle, &config);\n    if (result != CUDPP_SUCCESS){\n        fprintf(stderr, \"Error in cudppHashTable call in\"\n                \"testHashTable (make sure your device is at\"\n                \"least compute version 2.0\\n\");\n    }\n    \n    result = cudppHashInsert(hash_table_handle, d_keys,\n                                d_vals, kInputSize);\n    cudaThreadSynchronize();\n    printf(\"insert values\\n\");\n    if (result != CUDPP_SUCCESS){\n        fprintf(stderr, \"Error in cudppHashInsert call in\"\n                \"testHashTable\\n\");\n    }\n    \n    unsigned int values_size;\n    if (cudppMultivalueHashGetValuesSize(hash_table_handle,\n                                    &values_size) !=\n                                    CUDPP_SUCCESS){\n        fprintf(stderr, \"Error: \"\n                \"cudppMultivalueHashGetValuesSize()\\n\");\n    }\n    \n    unsigned int * d_all_values = NULL;\n    if (cudppMultivalueHashGetAllValues(hash_table_handle,\n                                        &d_all_values) !=\n                                        CUDPP_SUCCESS){\n        fprintf(stderr, \"Error: \"\n                \"cudppMultivalueHashGetAllValues()\\n\");\n    }\n    \n    compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);\n    cudaDeviceSynchronize();\n    \n    result = cudppHashRetrieve(hash_table_handle,\n                                d_queries,\n                                d_vals_multivalue,\n                                b * m * 27);\n    cudaThreadSynchronize();\n    printf(\"retrieved values\\n\");\n    if (result != CUDPP_SUCCESS){\n        fprintf(stderr, \"Error in cudppHashRetrieve call\\n\");\n    }\n\n    hash_square_idx_gpu<<<b,256>>>(b, n, m, nsample, d_vals_multivalue, d_all_values, idx, pts_cnt);\n    cudaDeviceSynchronize();\n    printf(\"obtain idx\\n\");\n    \n    result = cudppDestroyHashTable(theCudpp, hash_table_handle);\n    if (result != CUDPP_SUCCESS){\n        fprintf(stderr, \"Error in cudppDestroyHashTable call in\"\n                \"testHashTable\\n\");\n    }\n\n    result = cudppDestroy(theCudpp);\n    if (result != CUDPP_SUCCESS){\n        printf(\"Error shutting down CUDPP Library.\\n\");\n    }\n    printf(\"Ends\\n\");\n}", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 14.04.5\r\n- **TensorFlow installed from (source or binary)**:pip\r\n- **TensorFlow version (use command below)**:1.2.0\r\n- **Python version**: 2.7.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:CUDA 8.0\r\n- **GPU model and memory**:GeForce GTX 1080 8G\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nTo speed up the model's training and evaluating process, and to make the model more flexible, people would like to use some third party libraries for their customized ops. For example, CUDPP, http://cudpp.github.io/, allows people to build a hash table on GPU.\r\n\r\nHowever, I find that TensorFlow does not allow people to manipulate GPU memory by themselves, but only to use allocate_temp in the compute function, which is very inconvenient and inflexible. And these good third party libraries involve many GPU memory manipulations. I cannot find much information about this, but I met some errors in allocating memories.\r\n\r\n* What's the reason behind this prohibition?\r\n* Is there some method to allow us manipulate GPU by ourselves? (some switches, some options)\r\n* If we cannot manipulate GPU memory, then how can we use/adapt these third party GPU libraries for the customized ops? What's the good programming practice?\r\n\r\nMore specifically, the problem I met is that I implemented a customized op on GPU, using the multivalue hash table from the CUDPP library. For very small-scale data, the customized op passed the test. But when I use larger data, and incorporate the customized op into a larger model, then I cannot allocate the memory on CUDA. https://stackoverflow.com/questions/40183189/trouble-compiling-with-custom-tensorflow-gpu-op, this expalins something. I can avoid manipulating GPU memory myself, but the CUDPP library needs to manipulate GPU memory.\r\n\r\n\r\n\r\n### Source code / logs\r\nThe cudpp git repo: https://github.com/cudpp/cudpp/compare?expand=1.\r\n\r\nMy OpKernel:\r\n```C++\r\nvoid querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue);\r\nclass QuerySquarePointGpuOp : public OpKernel {\r\n    public:\r\n        explicit QuerySquarePointGpuOp(OpKernelConstruction* context) : OpKernel(context) {\r\n            OP_REQUIRES_OK(context, context->GetAttr(\"grid_size\", &grid_size_));\r\n            OP_REQUIRES(context, grid_size_ > 0, errors::InvalidArgument(\"QuerySquarePoint expects positive grid size\"));\r\n\r\n            OP_REQUIRES_OK(context, context->GetAttr(\"nsample\", &nsample_));\r\n            OP_REQUIRES(context, nsample_ > 0, errors::InvalidArgument(\"QuerySquarePoint expects positive nsample\"));\r\n        }\r\n\r\n        void Compute(OpKernelContext* context) override {\r\n            const Tensor& all_xyz_tensor = context->input(0);\r\n            OP_REQUIRES(context, all_xyz_tensor.dims()==3 && all_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(\"QuerySquarePoint expects (batch_size, ndataset, 3) all_xyz_tensor shape.\"));\r\n            int b = all_xyz_tensor.shape().dim_size(0);\r\n            int n = all_xyz_tensor.shape().dim_size(1);\r\n\r\n            const Tensor& centroids_xyz_tensor = context->input(1);\r\n            OP_REQUIRES(context, centroids_xyz_tensor.dims()==3 && centroids_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(\"QuerySquarePoint expects (batch_size, npoint, 3) centroids_xyz shape.\"));\r\n            int m = centroids_xyz_tensor.shape().dim_size(1);\r\n            \r\n            const Tensor& limits_tensor = context->input(2);\r\n            OP_REQUIRES(context, limits_tensor.dims()==1 && limits_tensor.shape().dim_size(0)==6, errors::InvalidArgument(\"QuerySquarePoint expects (6) limits shape.\"))\r\n            \r\n            const Tensor& sizes_tensor = context->input(3);\r\n            OP_REQUIRES(context, sizes_tensor.dims()==1 && sizes_tensor.shape().dim_size(0) == 3, errors::InvalidArgument(\"QuerySquarePoint expects (3) sizes shape.\"))\r\n\r\n            Tensor *idx_tensor = nullptr;\r\n            OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape{b,m,nsample_}, &idx_tensor));\r\n            Tensor *pts_cnt_tensor = nullptr;\r\n            OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape{b,m}, &pts_cnt_tensor));\r\n            \r\n            Tensor keys_tensor;\r\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &keys_tensor));\r\n            \r\n            Tensor vals_tensor;\r\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &vals_tensor));\r\n            \r\n            Tensor vals_multivalue_tensor;\r\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27*2}), &vals_multivalue_tensor));\r\n            \r\n            Tensor queries_tensor;\r\n            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27}), &queries_tensor));\r\n            \r\n\r\n            auto all_xyz_flat = all_xyz_tensor.flat<float>();\r\n            const float *all_xyz = &(all_xyz_flat(0));\r\n            \r\n            auto centroids_xyz_flat = centroids_xyz_tensor.flat<float>();\r\n            const float *centroids_xyz = &(centroids_xyz_flat(0));\r\n            \r\n            auto limits_flat = limits_tensor.flat<float>();\r\n            const float *limits = &(limits_flat(0));\r\n            \r\n            auto sizes_flat = sizes_tensor.flat<int>();\r\n            const int *sizes = &(sizes_flat(0));\r\n            \r\n            auto idx_flat = idx_tensor->flat<int>();\r\n            int *idx = &(idx_flat(0));\r\n            auto pts_cnt_flat = pts_cnt_tensor->flat<int>();\r\n            int *pts_cnt = &(pts_cnt_flat(0));\r\n            \r\n            auto keys_flat = keys_tensor.flat<int>();\r\n            unsigned int *keys = (unsigned int *)&(keys_flat(0));\r\n            \r\n            auto vals_flat = vals_tensor.flat<int>();\r\n            unsigned int *vals = (unsigned int *)&(vals_flat(0));\r\n            \r\n            auto queries_flat = queries_tensor.flat<int>();\r\n            unsigned int *queries = (unsigned int *)&(queries_flat(0));\r\n            \r\n            auto vals_multivalue_flat = vals_multivalue_tensor.flat<int>();\r\n            uint2 *vals_multivalue = reinterpret_cast<uint2*> (&(vals_multivalue_flat(0)));\r\n            \r\n            printf(\"Before launcher in cpp\\n\");\r\n            \r\n            querySquarePointLauncher(b, n, m, grid_size_, nsample_, all_xyz, centroids_xyz, limits, sizes, idx, pts_cnt, keys, vals, queries, vals_multivalue);         \r\n        }\r\n    private:\r\n        float grid_size_;\r\n        int nsample_;\r\n};\r\nREGISTER_KERNEL_BUILDER(Name(\"QuerySquarePoint\").Device(DEVICE_GPU), QuerySquarePointGpuOp);\r\n```\r\n\r\nThe CUDA implementation:\r\n```C++\r\n__global__ void compose_insert_items(int b, int n, float grid_size, const float *all_xyz, const float *limits, const int *sizes, unsigned int *d_keys, unsigned int *d_vals){\r\n    int index = threadIdx.x;\r\n   \r\n    if(index < n){\r\n        int batch_index = blockIdx.x;\r\n        all_xyz += batch_index * n * 3;\r\n        unsigned int *tmp_d_keys = d_keys + batch_index * n;\r\n        unsigned int *tmp_d_vals = d_vals + batch_index * n;\r\n        int stride = blockDim.x;\r\n        \r\n        for(int point_idx = index; point_idx < n; point_idx += stride){\r\n            unsigned int x_idx = __float2uint_rd((all_xyz[point_idx*3] - limits[0]) / grid_size) + 1;\r\n            unsigned int y_idx = __float2uint_rd((all_xyz[point_idx*3+1] - limits[2]) / grid_size) + 1;\r\n            unsigned int z_idx = __float2uint_rd((all_xyz[point_idx*3+2] - limits[4]) / grid_size) + 1;\r\n            \r\n            tmp_d_keys[point_idx] = z_idx + sizes[2] * (y_idx + sizes[1] * (x_idx + batch_index * sizes[0]));\r\n            tmp_d_vals[point_idx] = point_idx;\r\n        }\r\n    }\r\n}\r\n//compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);\r\n__global__ void compose_queries(int b, int m, float grid_size, const float *centroids_xyz, const float *limits, const int *sizes, unsigned int *d_queries){\r\n\r\n    int index = threadIdx.x;\r\n    \r\n    if(index < m){\r\n        int stride = blockDim.x;\r\n        int batch_index = blockIdx.x;\r\n        centroids_xyz += batch_index * m * 3;\r\n        unsigned int *tmp_d_queries = d_queries + batch_index * m * 27;\r\n        \r\n        unsigned int x_idx = __float2uint_rd((centroids_xyz[index*3] - limits[0]) / grid_size);\r\n        unsigned int y_idx = __float2uint_rd((centroids_xyz[index*3+1] - limits[2]) / grid_size);\r\n        unsigned int z_idx = __float2uint_rd((centroids_xyz[index*3+2] - limits[4]) / grid_size);\r\n        \r\n        int cnt = 0;\r\n        for(int x_offset = 0; x_offset < 3; x_offset++){\r\n            for(int y_offset = 0; y_offset < 3; y_offset++){\r\n                for(int z_offset = 0; z_offset < 3; z_offset++){\r\n                    tmp_d_queries[index*27+cnt] = z_idx + z_offset + sizes[2] * (y_idx + y_offset + sizes[1] * (x_idx + x_offset + batch_index * sizes[0]));  \r\n                    cnt++;\r\n                }\r\n            }\r\n        }\r\n\r\n    }\r\n}\r\n__global__ void hash_square_idx_gpu(int b, int n, int m, int nsample, const uint2 *d_vals_multivalue, const unsigned int * d_all_values, int *idx, int *pts_cnt){\r\n    int index = threadIdx.x;\r\n    if(index < m){\r\n        int stride = blockDim.x;\r\n        int batch_index = blockIdx.x;\r\n        unsigned int sorted_idx[27] = {13, 4,10,12,14,16,22, 1,3,5,7,9,11,15,17,19,21,23,25,  0,2,6,8,18,20,24,26};\r\n                \r\n        idx += batch_index * m * nsample;\r\n        pts_cnt += batch_index * m;\r\n        int query_idx_base = batch_index*m*27+index*27;\r\n        \r\n        int cnt = 0;\r\n        for(int i = 0; i < 27; i++){\r\n            int query_idx = query_idx_base + sorted_idx[i];\r\n            unsigned int num_values = d_vals_multivalue[query_idx].y;\r\n            if(num_values > 0){\r\n                for(unsigned int j = 0; j < num_values && cnt < nsample; j++){\r\n                    idx[index*nsample + cnt] = d_all_values[d_vals_multivalue[query_idx].x + j];\r\n                    cnt++;\r\n                }\r\n            }\r\n        }\r\n        pts_cnt[index] = cnt;\r\n        for(;cnt < nsample;cnt++){\r\n            idx[index*nsample + cnt] = idx[index*nsample];\r\n        }\r\n    }\r\n}\r\n\r\nvoid querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue) {\r\n    printf(\"Start\\n\");    \r\n    unsigned int kInputSize = b * n;\r\n    printf(\"b %d, n %d, kInputSize: %u\\n\", b, n, kInputSize);\r\n    \r\n    compose_insert_items<<<b,256>>>(b, n, grid_size, all_xyz, limits, sizes, d_keys, d_vals);\r\n    cudaDeviceSynchronize();\r\n    \r\n    CUDPPHandle theCudpp;\r\n    CUDPPResult result = cudppCreate(&theCudpp);\r\n    if (result != CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error initializing CUDPP Library.\\n\");\r\n        exit(-1);\r\n    }\r\n\r\n    CUDPPHashTableConfig config;\r\n    config.type = CUDPP_MULTIVALUE_HASH_TABLE;\r\n    config.kInputSize = kInputSize;\r\n    config.space_usage = 2.0f;\r\n    CUDPPHandle hash_table_handle;\r\n    result = cudppHashTable(theCudpp, &hash_table_handle, &config);\r\n    if (result != CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error in cudppHashTable call in\"\r\n                \"testHashTable (make sure your device is at\"\r\n                \"least compute version 2.0\\n\");\r\n    }\r\n    \r\n    result = cudppHashInsert(hash_table_handle, d_keys,\r\n                                d_vals, kInputSize);\r\n    cudaThreadSynchronize();\r\n    printf(\"insert values\\n\");\r\n    if (result != CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error in cudppHashInsert call in\"\r\n                \"testHashTable\\n\");\r\n    }\r\n    \r\n    unsigned int values_size;\r\n    if (cudppMultivalueHashGetValuesSize(hash_table_handle,\r\n                                    &values_size) !=\r\n                                    CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error: \"\r\n                \"cudppMultivalueHashGetValuesSize()\\n\");\r\n    }\r\n    \r\n    unsigned int * d_all_values = NULL;\r\n    if (cudppMultivalueHashGetAllValues(hash_table_handle,\r\n                                        &d_all_values) !=\r\n                                        CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error: \"\r\n                \"cudppMultivalueHashGetAllValues()\\n\");\r\n    }\r\n    \r\n    compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);\r\n    cudaDeviceSynchronize();\r\n    \r\n    result = cudppHashRetrieve(hash_table_handle,\r\n                                d_queries,\r\n                                d_vals_multivalue,\r\n                                b * m * 27);\r\n    cudaThreadSynchronize();\r\n    printf(\"retrieved values\\n\");\r\n    if (result != CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error in cudppHashRetrieve call\\n\");\r\n    }\r\n\r\n    hash_square_idx_gpu<<<b,256>>>(b, n, m, nsample, d_vals_multivalue, d_all_values, idx, pts_cnt);\r\n    cudaDeviceSynchronize();\r\n    printf(\"obtain idx\\n\");\r\n    \r\n    result = cudppDestroyHashTable(theCudpp, hash_table_handle);\r\n    if (result != CUDPP_SUCCESS){\r\n        fprintf(stderr, \"Error in cudppDestroyHashTable call in\"\r\n                \"testHashTable\\n\");\r\n    }\r\n\r\n    result = cudppDestroy(theCudpp);\r\n    if (result != CUDPP_SUCCESS){\r\n        printf(\"Error shutting down CUDPP Library.\\n\");\r\n    }\r\n    printf(\"Ends\\n\");\r\n}\r\n```\r\n\r\n\r\n"}