{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145853413", "pull_request_review_id": 70716276, "id": 145853413, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NTg1MzQxMw==", "diff_hunk": "@@ -45,22 +47,34 @@ def GetTestConfigs():\n \n class Conv3DTest(test.TestCase):\n \n+  def _DtypesToTest(self, use_gpu):\n+    if use_gpu:\n+      if not test_util.CudaSupportsHalfMatMulAndConv():\n+        return [dtypes.float32]\n+      else:\n+        # It is important that float32 comes before float16 here,\n+        # as we will be using its gradients as reference for fp16 gradients.\n+        return [dtypes.float32, dtypes.float16]\n+    else:\n+      return [dtypes.float64, dtypes.float32, dtypes.float16]\n+\n   def _SetupValuesForDevice(self, tensor_in_sizes, filter_in_sizes, stride,\n-                            padding, data_format, use_gpu):\n+                            padding, data_format, dtype, use_gpu):\n     total_size_1 = 1\n     total_size_2 = 1\n     for s in tensor_in_sizes:\n       total_size_1 *= s\n     for s in filter_in_sizes:\n       total_size_2 *= s\n \n-    # Initializes the input tensor with array containing incrementing\n-    # numbers from 1.\n-    x1 = [f * 1.0 for f in range(1, total_size_1 + 1)]\n-    x2 = [f * 1.0 for f in range(1, total_size_2 + 1)]\n+    # Initializes the input tensor with array containing numbers from 0 to 1.\n+    # We keep the input tensor values fairly small to avoid overflowing a float16 \n+    # tensor during the conv3d and to keep absolute errors small", "path": "tensorflow/python/kernel_tests/conv_ops_3d_test.py", "position": null, "original_position": 40, "commit_id": "7bcf8a127c5c9141535b126ac6d32b7a2dbea841", "original_commit_id": "f5466099da8bcecf91a60cafc6f607c6f56f140d", "user": {"login": "opensourcemattress", "id": 31660642, "node_id": "MDQ6VXNlcjMxNjYwNjQy", "avatar_url": "https://avatars1.githubusercontent.com/u/31660642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/opensourcemattress", "html_url": "https://github.com/opensourcemattress", "followers_url": "https://api.github.com/users/opensourcemattress/followers", "following_url": "https://api.github.com/users/opensourcemattress/following{/other_user}", "gists_url": "https://api.github.com/users/opensourcemattress/gists{/gist_id}", "starred_url": "https://api.github.com/users/opensourcemattress/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/opensourcemattress/subscriptions", "organizations_url": "https://api.github.com/users/opensourcemattress/orgs", "repos_url": "https://api.github.com/users/opensourcemattress/repos", "events_url": "https://api.github.com/users/opensourcemattress/events{/privacy}", "received_events_url": "https://api.github.com/users/opensourcemattress/received_events", "type": "User", "site_admin": false}, "body": ">Why does it matter that the absolute error is small?\r\n\r\nBecause if I understand correctly we compare results with reference using absolute difference. And absolute error depends on current significant and exponent. Large numbers (huge exponent) and small amount of bit for significant (fp16) => big absolute errors (I seen difference >10 with huge numbers in some fp16 tests).\r\n\r\nI can make 'tolerances' smaller but not sure which values are appropriate. It's hard to tell because convs are not 'pure convs' but some tricky methods from computation mathematics. Error depends on particular implementation of convolution and if we want to be really sure it's better to find out what are relative/absolute errors for particular method and particular type. But I think that from practical point of view it's better to take 'small enough' values and continue to work on other problems. ", "created_at": "2017-10-20T00:06:02Z", "updated_at": "2017-10-25T22:56:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/12832#discussion_r145853413", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12832", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/145853413"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/12832#discussion_r145853413"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12832"}}, "body_html": "<blockquote>\n<p>Why does it matter that the absolute error is small?</p>\n</blockquote>\n<p>Because if I understand correctly we compare results with reference using absolute difference. And absolute error depends on current significant and exponent. Large numbers (huge exponent) and small amount of bit for significant (fp16) =&gt; big absolute errors (I seen difference &gt;10 with huge numbers in some fp16 tests).</p>\n<p>I can make 'tolerances' smaller but not sure which values are appropriate. It's hard to tell because convs are not 'pure convs' but some tricky methods from computation mathematics. Error depends on particular implementation of convolution and if we want to be really sure it's better to find out what are relative/absolute errors for particular method and particular type. But I think that from practical point of view it's better to take 'small enough' values and continue to work on other problems.</p>", "body_text": "Why does it matter that the absolute error is small?\n\nBecause if I understand correctly we compare results with reference using absolute difference. And absolute error depends on current significant and exponent. Large numbers (huge exponent) and small amount of bit for significant (fp16) => big absolute errors (I seen difference >10 with huge numbers in some fp16 tests).\nI can make 'tolerances' smaller but not sure which values are appropriate. It's hard to tell because convs are not 'pure convs' but some tricky methods from computation mathematics. Error depends on particular implementation of convolution and if we want to be really sure it's better to find out what are relative/absolute errors for particular method and particular type. But I think that from practical point of view it's better to take 'small enough' values and continue to work on other problems.", "in_reply_to_id": 145851069}