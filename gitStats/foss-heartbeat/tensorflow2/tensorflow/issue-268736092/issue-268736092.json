{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13996", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13996/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13996/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13996/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13996", "id": 268736092, "node_id": "MDU6SXNzdWUyNjg3MzYwOTI=", "number": 13996, "title": "Proper way to handle csv input for cpu training?", "user": {"login": "littleDing", "id": 882790, "node_id": "MDQ6VXNlcjg4Mjc5MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/882790?v=4", "gravatar_id": "", "url": "https://api.github.com/users/littleDing", "html_url": "https://github.com/littleDing", "followers_url": "https://api.github.com/users/littleDing/followers", "following_url": "https://api.github.com/users/littleDing/following{/other_user}", "gists_url": "https://api.github.com/users/littleDing/gists{/gist_id}", "starred_url": "https://api.github.com/users/littleDing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/littleDing/subscriptions", "organizations_url": "https://api.github.com/users/littleDing/orgs", "repos_url": "https://api.github.com/users/littleDing/repos", "events_url": "https://api.github.com/users/littleDing/events{/privacy}", "received_events_url": "https://api.github.com/users/littleDing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-10-26T12:12:34Z", "updated_at": "2017-10-28T11:29:09Z", "closed_at": "2017-10-27T17:31:30Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nno</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nUbuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\npip</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n('v1.3.0-rc2-20-g0787eee', '1.3.0')</li>\n<li><strong>Python version</strong>:<br>\nPython 2.7.12 from Anaconda</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am training some classification model with an 32-cpu Ubuntu machine and one of the problem is to feed data fast enough to the training process.</p>\n<p>I am trying to read data from some csv file but the default tf.csv or tf.data module seems to be slow.<br>\nA speed test for reading 1000000 row * 17 column csv file shows a speed like :</p>\n<ul>\n<li>tf.decode_csv with queue and theads  :   ~192 seconds</li>\n<li>tf.data :  ~164 seconds</li>\n<li>hand write cpp reading op :  ~25 seconds</li>\n<li>pure python code with help from pandas : ~23 seconds</li>\n</ul>\n<p>It is fast enough to use pandas for one single file, but it might face the GIL problem if try to speed up with more threads.</p>\n<p>Codes can be found below. I am not sure if I use it the right way, is there any official benchmarks or guidelines for this?</p>\n<h3>Source code / logs</h3>\n<p><a href=\"https://github.com/littleDing/mini_csv_reader\">https://github.com/littleDing/mini_csv_reader</a><br>\nThe speed test is run through speed_test.py</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nno\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nUbuntu 16.04\nTensorFlow installed from (source or binary):\npip\nTensorFlow version (use command below):\n('v1.3.0-rc2-20-g0787eee', '1.3.0')\nPython version:\nPython 2.7.12 from Anaconda\n\nDescribe the problem\nI am training some classification model with an 32-cpu Ubuntu machine and one of the problem is to feed data fast enough to the training process.\nI am trying to read data from some csv file but the default tf.csv or tf.data module seems to be slow.\nA speed test for reading 1000000 row * 17 column csv file shows a speed like :\n\ntf.decode_csv with queue and theads  :   ~192 seconds\ntf.data :  ~164 seconds\nhand write cpp reading op :  ~25 seconds\npure python code with help from pandas : ~23 seconds\n\nIt is fast enough to use pandas for one single file, but it might face the GIL problem if try to speed up with more threads.\nCodes can be found below. I am not sure if I use it the right way, is there any official benchmarks or guidelines for this?\nSource code / logs\nhttps://github.com/littleDing/mini_csv_reader\nThe speed test is run through speed_test.py", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\npip\r\n- **TensorFlow version (use command below)**: \r\n('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n- **Python version**: \r\nPython 2.7.12 from Anaconda\r\n\r\n### Describe the problem\r\nI am training some classification model with an 32-cpu Ubuntu machine and one of the problem is to feed data fast enough to the training process. \r\n\r\nI am trying to read data from some csv file but the default tf.csv or tf.data module seems to be slow.\r\nA speed test for reading 1000000 row * 17 column csv file shows a speed like : \r\n* tf.decode_csv with queue and theads  :   ~192 seconds\r\n* tf.data :  ~164 seconds\r\n* hand write cpp reading op :  ~25 seconds\r\n* pure python code with help from pandas : ~23 seconds\r\n\r\nIt is fast enough to use pandas for one single file, but it might face the GIL problem if try to speed up with more threads. \r\n\r\nCodes can be found below. I am not sure if I use it the right way, is there any official benchmarks or guidelines for this? \r\n\r\n### Source code / logs\r\nhttps://github.com/littleDing/mini_csv_reader\r\nThe speed test is run through speed_test.py "}