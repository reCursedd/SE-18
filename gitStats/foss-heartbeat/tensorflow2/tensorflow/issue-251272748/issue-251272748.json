{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12394", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12394/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12394/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12394/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12394", "id": 251272748, "node_id": "MDU6SXNzdWUyNTEyNzI3NDg=", "number": 12394, "title": "[bug] CUDA messes up after improperly closing Tensorflow session ", "user": {"login": "ArturoDeza", "id": 1279233, "node_id": "MDQ6VXNlcjEyNzkyMzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1279233?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArturoDeza", "html_url": "https://github.com/ArturoDeza", "followers_url": "https://api.github.com/users/ArturoDeza/followers", "following_url": "https://api.github.com/users/ArturoDeza/following{/other_user}", "gists_url": "https://api.github.com/users/ArturoDeza/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArturoDeza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArturoDeza/subscriptions", "organizations_url": "https://api.github.com/users/ArturoDeza/orgs", "repos_url": "https://api.github.com/users/ArturoDeza/repos", "events_url": "https://api.github.com/users/ArturoDeza/events{/privacy}", "received_events_url": "https://api.github.com/users/ArturoDeza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-18T15:02:06Z", "updated_at": "2017-08-23T14:55:07Z", "closed_at": "2017-08-23T14:55:07Z", "author_association": "NONE", "body_html": "<p>Whenever I run Keras sessions on PyCharm, and I \"forget\" to properly close the session (example: I log off the computer, or close session). It seems like the CUDA driver stops working. I can still run <code>$nvcc -V</code> and <code>$nvidia-smi</code> successfully but running the <code>./deviceQuery</code> sanity check from the CUDA samples fails, which means the system has stopped detecting the graphics card.</p>\n<p>Has anyone else had this problem? I definitely recall that this is not the first time this has happened to me using tensorflow vs say using torch, pytorch that also use the graphics card and \"forgetting\" to close my session.</p>\n<p>Perhaps I am just being spoiled? Note that this has happened both using tensorflow directly and using keras with tensorflow as backend (where I do not have direct control over closing sessions directly as far as I know).</p>", "body_text": "Whenever I run Keras sessions on PyCharm, and I \"forget\" to properly close the session (example: I log off the computer, or close session). It seems like the CUDA driver stops working. I can still run $nvcc -V and $nvidia-smi successfully but running the ./deviceQuery sanity check from the CUDA samples fails, which means the system has stopped detecting the graphics card.\nHas anyone else had this problem? I definitely recall that this is not the first time this has happened to me using tensorflow vs say using torch, pytorch that also use the graphics card and \"forgetting\" to close my session.\nPerhaps I am just being spoiled? Note that this has happened both using tensorflow directly and using keras with tensorflow as backend (where I do not have direct control over closing sessions directly as far as I know).", "body": "Whenever I run Keras sessions on PyCharm, and I \"forget\" to properly close the session (example: I log off the computer, or close session). It seems like the CUDA driver stops working. I can still run `$nvcc -V` and `$nvidia-smi` successfully but running the `./deviceQuery` sanity check from the CUDA samples fails, which means the system has stopped detecting the graphics card.\r\n\r\nHas anyone else had this problem? I definitely recall that this is not the first time this has happened to me using tensorflow vs say using torch, pytorch that also use the graphics card and \"forgetting\" to close my session.\r\n\r\nPerhaps I am just being spoiled? Note that this has happened both using tensorflow directly and using keras with tensorflow as backend (where I do not have direct control over closing sessions directly as far as I know)."}