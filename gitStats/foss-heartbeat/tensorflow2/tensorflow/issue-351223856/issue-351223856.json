{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21658", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21658/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21658/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21658/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/21658", "id": 351223856, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA4ODczNzEw", "number": 21658, "title": "Add LeakyRelu C++ Op and its gradient implementation.", "user": {"login": "lowintelligence", "id": 10669111, "node_id": "MDQ6VXNlcjEwNjY5MTEx", "avatar_url": "https://avatars0.githubusercontent.com/u/10669111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lowintelligence", "html_url": "https://github.com/lowintelligence", "followers_url": "https://api.github.com/users/lowintelligence/followers", "following_url": "https://api.github.com/users/lowintelligence/following{/other_user}", "gists_url": "https://api.github.com/users/lowintelligence/gists{/gist_id}", "starred_url": "https://api.github.com/users/lowintelligence/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lowintelligence/subscriptions", "organizations_url": "https://api.github.com/users/lowintelligence/orgs", "repos_url": "https://api.github.com/users/lowintelligence/repos", "events_url": "https://api.github.com/users/lowintelligence/events{/privacy}", "received_events_url": "https://api.github.com/users/lowintelligence/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 419840263, "node_id": "MDU6TGFiZWw0MTk4NDAyNjM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20testing%20(then%20merge)", "name": "awaiting testing (then merge)", "color": "c2e0c6", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 987666414, "node_id": "MDU6TGFiZWw5ODc2NjY0MTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/ready%20to%20pull", "name": "ready to pull", "color": "2cd643", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2018-08-16T14:13:04Z", "updated_at": "2018-10-08T18:30:55Z", "closed_at": "2018-10-08T18:30:55Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21658", "html_url": "https://github.com/tensorflow/tensorflow/pull/21658", "diff_url": "https://github.com/tensorflow/tensorflow/pull/21658.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/21658.patch"}, "body_html": "<p>LeakyRelu, defined as 'y = { x (x&gt;=0) or alpha<em>x (x&lt;0) }', was computed by combined Ops 'max(x, alpha</em>x)' in current codes. Hence its gradient calculation for back propagation would contain a serial of element-wise Ops. This looks really unnecessary for such a simple op and it could be done within just one Op with less memory accesses.</p>\n<p>In fact, we meet some performance issue on CPU in an attention based model. Within the FC calculation 'Leaky ReLu' was used as the activation function, so that its back prop Ops took some CPU time. Thus we decided to implement leaky_relu and its gradient as C++ Ops.</p>", "body_text": "LeakyRelu, defined as 'y = { x (x>=0) or alphax (x<0) }', was computed by combined Ops 'max(x, alphax)' in current codes. Hence its gradient calculation for back propagation would contain a serial of element-wise Ops. This looks really unnecessary for such a simple op and it could be done within just one Op with less memory accesses.\nIn fact, we meet some performance issue on CPU in an attention based model. Within the FC calculation 'Leaky ReLu' was used as the activation function, so that its back prop Ops took some CPU time. Thus we decided to implement leaky_relu and its gradient as C++ Ops.", "body": "LeakyRelu, defined as 'y = { x (x>=0) or alpha*x (x<0) }', was computed by combined Ops 'max(x, alpha*x)' in current codes. Hence its gradient calculation for back propagation would contain a serial of element-wise Ops. This looks really unnecessary for such a simple op and it could be done within just one Op with less memory accesses.\r\n\r\nIn fact, we meet some performance issue on CPU in an attention based model. Within the FC calculation 'Leaky ReLu' was used as the activation function, so that its back prop Ops took some CPU time. Thus we decided to implement leaky_relu and its gradient as C++ Ops."}