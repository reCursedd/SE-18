{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/286235721", "html_url": "https://github.com/tensorflow/tensorflow/issues/7970#issuecomment-286235721", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7970", "id": 286235721, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjIzNTcyMQ==", "user": {"login": "volvador", "id": 15655730, "node_id": "MDQ6VXNlcjE1NjU1NzMw", "avatar_url": "https://avatars1.githubusercontent.com/u/15655730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/volvador", "html_url": "https://github.com/volvador", "followers_url": "https://api.github.com/users/volvador/followers", "following_url": "https://api.github.com/users/volvador/following{/other_user}", "gists_url": "https://api.github.com/users/volvador/gists{/gist_id}", "starred_url": "https://api.github.com/users/volvador/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/volvador/subscriptions", "organizations_url": "https://api.github.com/users/volvador/orgs", "repos_url": "https://api.github.com/users/volvador/repos", "events_url": "https://api.github.com/users/volvador/events{/privacy}", "received_events_url": "https://api.github.com/users/volvador/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-13T20:37:34Z", "updated_at": "2017-03-14T10:56:15Z", "author_association": "NONE", "body_html": "<p>Indeed training goes well, and I see the loss decreasing when I print it in the chief worker. However, the workers could not go outside the loop as you mentioned.<br>\nAnother issue is that it seems only the chief is doing the training, even if in the constructor of <code>SyncReplicasOptimizer</code> I have the parameter <code>replicas_to_aggregate=num_workers</code></p>", "body_text": "Indeed training goes well, and I see the loss decreasing when I print it in the chief worker. However, the workers could not go outside the loop as you mentioned.\nAnother issue is that it seems only the chief is doing the training, even if in the constructor of SyncReplicasOptimizer I have the parameter replicas_to_aggregate=num_workers", "body": "Indeed training goes well, and I see the loss decreasing when I print it in the chief worker. However, the workers could not go outside the loop as you mentioned.\r\nAnother issue is that it seems only the chief is doing the training, even if in the constructor of `SyncReplicasOptimizer` I have the parameter `replicas_to_aggregate=num_workers`"}