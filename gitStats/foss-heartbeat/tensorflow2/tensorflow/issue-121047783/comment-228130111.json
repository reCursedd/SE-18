{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/228130111", "html_url": "https://github.com/tensorflow/tensorflow/issues/446#issuecomment-228130111", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/446", "id": 228130111, "node_id": "MDEyOklzc3VlQ29tbWVudDIyODEzMDExMQ==", "user": {"login": "yuanbyu", "id": 2342391, "node_id": "MDQ6VXNlcjIzNDIzOTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2342391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuanbyu", "html_url": "https://github.com/yuanbyu", "followers_url": "https://api.github.com/users/yuanbyu/followers", "following_url": "https://api.github.com/users/yuanbyu/following{/other_user}", "gists_url": "https://api.github.com/users/yuanbyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuanbyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuanbyu/subscriptions", "organizations_url": "https://api.github.com/users/yuanbyu/orgs", "repos_url": "https://api.github.com/users/yuanbyu/repos", "events_url": "https://api.github.com/users/yuanbyu/events{/privacy}", "received_events_url": "https://api.github.com/users/yuanbyu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-23T17:55:55Z", "updated_at": "2016-06-23T17:55:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I guess that the Scipy optimizer makes a sequence of run calls in a TF session? Are there cases that a run call produces a tensor but the tensor is only used in a subsequent run call?  Persistent tensor would make it possible to keep such tensors \"in-place\" on the device that produced them, avoid moving them back and forth between the python client and the device.</p>\n<p>On the other hand, it would be really nice to have a real native TF implementation, possibly using a nested while loop.</p>", "body_text": "I guess that the Scipy optimizer makes a sequence of run calls in a TF session? Are there cases that a run call produces a tensor but the tensor is only used in a subsequent run call?  Persistent tensor would make it possible to keep such tensors \"in-place\" on the device that produced them, avoid moving them back and forth between the python client and the device.\nOn the other hand, it would be really nice to have a real native TF implementation, possibly using a nested while loop.", "body": "I guess that the Scipy optimizer makes a sequence of run calls in a TF session? Are there cases that a run call produces a tensor but the tensor is only used in a subsequent run call?  Persistent tensor would make it possible to keep such tensors \"in-place\" on the device that produced them, avoid moving them back and forth between the python client and the device.\n\nOn the other hand, it would be really nice to have a real native TF implementation, possibly using a nested while loop. \n"}