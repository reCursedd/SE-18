{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/216929775", "html_url": "https://github.com/tensorflow/tensorflow/issues/254#issuecomment-216929775", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/254", "id": 216929775, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNjkyOTc3NQ==", "user": {"login": "austinsteamboat", "id": 8999425, "node_id": "MDQ6VXNlcjg5OTk0MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8999425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/austinsteamboat", "html_url": "https://github.com/austinsteamboat", "followers_url": "https://api.github.com/users/austinsteamboat/followers", "following_url": "https://api.github.com/users/austinsteamboat/following{/other_user}", "gists_url": "https://api.github.com/users/austinsteamboat/gists{/gist_id}", "starred_url": "https://api.github.com/users/austinsteamboat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/austinsteamboat/subscriptions", "organizations_url": "https://api.github.com/users/austinsteamboat/orgs", "repos_url": "https://api.github.com/users/austinsteamboat/repos", "events_url": "https://api.github.com/users/austinsteamboat/events{/privacy}", "received_events_url": "https://api.github.com/users/austinsteamboat/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-04T16:52:28Z", "updated_at": "2016-05-04T16:53:07Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=170265\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/danbri\">@danbri</a> - I ran that test case on the Odroid and my laptop, there was no noticeable difference in evaluation time, definitely same order of magnitude. Looking at resource draw, it takes 4 cores at peak and ~500 MB of RAM when evaluating that imagenet model.</p>\n<p>I'm building custom classifiers one basic perceptron type model and a CNN and I can say the odroid runs 5x slower with the perceptron case (which is still plenty fast actually) and the CNN actually runs at about the same rate on both machines (really slow). When the CNN does run on the Odroid it eats between 4 and 7 of the 8 available cores and consumes ~1.9 GB of the 2 GB of RAM. I still have the swap partition turned on from the install and from what I've seen that's probably a good thing to have when running big CNNs like that. All in all pleasantly surprised by the performance so far.</p>", "body_text": "@danbri - I ran that test case on the Odroid and my laptop, there was no noticeable difference in evaluation time, definitely same order of magnitude. Looking at resource draw, it takes 4 cores at peak and ~500 MB of RAM when evaluating that imagenet model.\nI'm building custom classifiers one basic perceptron type model and a CNN and I can say the odroid runs 5x slower with the perceptron case (which is still plenty fast actually) and the CNN actually runs at about the same rate on both machines (really slow). When the CNN does run on the Odroid it eats between 4 and 7 of the 8 available cores and consumes ~1.9 GB of the 2 GB of RAM. I still have the swap partition turned on from the install and from what I've seen that's probably a good thing to have when running big CNNs like that. All in all pleasantly surprised by the performance so far.", "body": "@danbri - I ran that test case on the Odroid and my laptop, there was no noticeable difference in evaluation time, definitely same order of magnitude. Looking at resource draw, it takes 4 cores at peak and ~500 MB of RAM when evaluating that imagenet model. \n\nI'm building custom classifiers one basic perceptron type model and a CNN and I can say the odroid runs 5x slower with the perceptron case (which is still plenty fast actually) and the CNN actually runs at about the same rate on both machines (really slow). When the CNN does run on the Odroid it eats between 4 and 7 of the 8 available cores and consumes ~1.9 GB of the 2 GB of RAM. I still have the swap partition turned on from the install and from what I've seen that's probably a good thing to have when running big CNNs like that. All in all pleasantly surprised by the performance so far. \n"}