{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412738707", "html_url": "https://github.com/tensorflow/tensorflow/issues/19062#issuecomment-412738707", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19062", "id": 412738707, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjczODcwNw==", "user": {"login": "formigone", "id": 852234, "node_id": "MDQ6VXNlcjg1MjIzNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/852234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/formigone", "html_url": "https://github.com/formigone", "followers_url": "https://api.github.com/users/formigone/followers", "following_url": "https://api.github.com/users/formigone/following{/other_user}", "gists_url": "https://api.github.com/users/formigone/gists{/gist_id}", "starred_url": "https://api.github.com/users/formigone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/formigone/subscriptions", "organizations_url": "https://api.github.com/users/formigone/orgs", "repos_url": "https://api.github.com/users/formigone/repos", "events_url": "https://api.github.com/users/formigone/events{/privacy}", "received_events_url": "https://api.github.com/users/formigone/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-14T03:01:12Z", "updated_at": "2018-08-14T03:04:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Am I  understanding this right? Suppose my input_fn returns a <code>tf.data.TextLineDataset(filename).map (lamda line: tf.decode_csv(line))</code> that references a csv with, say, 1,000,000 lines, and it shuffles with <code>dataset.shuffle(buffer_size=256)</code>. If the evaluation runs after a few hundred steps of training, when training resumes, will the input_fn used in training start reading thr cvs from where it left off before doing the evaluation, or will it start over from the first line?</p>\n<p>From the explanation above, it sounds like the latest version of train_and_eval doesn't interupt the input_fn used in training (or somehow preserves it) during eval, and thus the input_fn keeps reading the long file line by line independently. Is this the case?</p>", "body_text": "Am I  understanding this right? Suppose my input_fn returns a tf.data.TextLineDataset(filename).map (lamda line: tf.decode_csv(line)) that references a csv with, say, 1,000,000 lines, and it shuffles with dataset.shuffle(buffer_size=256). If the evaluation runs after a few hundred steps of training, when training resumes, will the input_fn used in training start reading thr cvs from where it left off before doing the evaluation, or will it start over from the first line?\nFrom the explanation above, it sounds like the latest version of train_and_eval doesn't interupt the input_fn used in training (or somehow preserves it) during eval, and thus the input_fn keeps reading the long file line by line independently. Is this the case?", "body": "Am I  understanding this right? Suppose my input_fn returns a `tf.data.TextLineDataset(filename).map (lamda line: tf.decode_csv(line))` that references a csv with, say, 1,000,000 lines, and it shuffles with `dataset.shuffle(buffer_size=256)`. If the evaluation runs after a few hundred steps of training, when training resumes, will the input_fn used in training start reading thr cvs from where it left off before doing the evaluation, or will it start over from the first line?\r\n\r\nFrom the explanation above, it sounds like the latest version of train_and_eval doesn't interupt the input_fn used in training (or somehow preserves it) during eval, and thus the input_fn keeps reading the long file line by line independently. Is this the case?"}