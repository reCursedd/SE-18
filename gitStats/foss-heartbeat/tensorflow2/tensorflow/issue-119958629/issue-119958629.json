{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/394", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/394/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/394/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/394/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/394", "id": 119958629, "node_id": "MDU6SXNzdWUxMTk5NTg2Mjk=", "number": 394, "title": "failed call to cuInit: CUDA_ERROR_UNKNOWN in python programs using Ubuntu bumblebee", "user": {"login": "jpmerc", "id": 5333924, "node_id": "MDQ6VXNlcjUzMzM5MjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5333924?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpmerc", "html_url": "https://github.com/jpmerc", "followers_url": "https://api.github.com/users/jpmerc/followers", "following_url": "https://api.github.com/users/jpmerc/following{/other_user}", "gists_url": "https://api.github.com/users/jpmerc/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpmerc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpmerc/subscriptions", "organizations_url": "https://api.github.com/users/jpmerc/orgs", "repos_url": "https://api.github.com/users/jpmerc/repos", "events_url": "https://api.github.com/users/jpmerc/events{/privacy}", "received_events_url": "https://api.github.com/users/jpmerc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284463744, "node_id": "MDU6TGFiZWwyODQ0NjM3NDQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cuda", "name": "cuda", "color": "f7c6c7", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 57, "created_at": "2015-12-02T14:55:01Z", "updated_at": "2018-11-04T04:21:29Z", "closed_at": "2016-03-10T06:43:43Z", "author_association": "NONE", "body_html": "<p>I have a Quadro K1100M integrated gpu with compute capability 3.0. I had to install bumblebee to make CUDA work. I am now able to run the tutorials_example_trainer with the command <code>sudo optirun bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu</code>. I have been able to do that with <code>TF_UNOFFICIAL_SETTING=1 ./configure</code>. However, I am not able to run examples in python directly.</p>\n<p>For example, if I run the convolutional.py in tensorflow/models/image/mnist with the command <code>optirun python convolutional.py</code>, I get the following error :</p>\n<pre><code>tensorflow/tensorflow/models/image/mnist$ optirun python convolutional.py \nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8\nE tensorflow/stream_executor/cuda/cuda_driver.cc:466] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:98] retrieving CUDA diagnostic information for host: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] hostname: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:131] libcuda reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:242] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:135] kernel reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:211] kernel version seems to match DSO: 352.63\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: \nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8\n</code></pre>\n<p>It is like my gpu is not recognized in python programs because of the 3.0 compute capability.  Is there a way to avoid this problem?</p>", "body_text": "I have a Quadro K1100M integrated gpu with compute capability 3.0. I had to install bumblebee to make CUDA work. I am now able to run the tutorials_example_trainer with the command sudo optirun bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu. I have been able to do that with TF_UNOFFICIAL_SETTING=1 ./configure. However, I am not able to run examples in python directly.\nFor example, if I run the convolutional.py in tensorflow/models/image/mnist with the command optirun python convolutional.py, I get the following error :\ntensorflow/tensorflow/models/image/mnist$ optirun python convolutional.py \nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8\nE tensorflow/stream_executor/cuda/cuda_driver.cc:466] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:98] retrieving CUDA diagnostic information for host: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] hostname: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:131] libcuda reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:242] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:135] kernel reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:211] kernel version seems to match DSO: 352.63\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: \nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8\n\nIt is like my gpu is not recognized in python programs because of the 3.0 compute capability.  Is there a way to avoid this problem?", "body": "I have a Quadro K1100M integrated gpu with compute capability 3.0. I had to install bumblebee to make CUDA work. I am now able to run the tutorials_example_trainer with the command `sudo optirun bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu`. I have been able to do that with `TF_UNOFFICIAL_SETTING=1 ./configure`. However, I am not able to run examples in python directly.\n\nFor example, if I run the convolutional.py in tensorflow/models/image/mnist with the command `optirun python convolutional.py`, I get the following error : \n\n```\ntensorflow/tensorflow/models/image/mnist$ optirun python convolutional.py \nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 8\nE tensorflow/stream_executor/cuda/cuda_driver.cc:466] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:98] retrieving CUDA diagnostic information for host: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] hostname: jp-pc\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:131] libcuda reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:242] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:135] kernel reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:211] kernel version seems to match DSO: 352.63\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: \nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 8\n```\n\nIt is like my gpu is not recognized in python programs because of the 3.0 compute capability.  Is there a way to avoid this problem?\n"}