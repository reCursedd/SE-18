{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/184198727", "pull_request_review_id": 115345815, "id": 184198727, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDE5ODcyNw==", "diff_hunk": "@@ -100,112 +98,15 @@ def safe_embedding_lookup_sparse(embedding_weights,\n     logging.warn(\"The default value of combiner will change from \\\"mean\\\" \"\n                  \"to \\\"sqrtn\\\" after 2016/11/01.\")\n     combiner = \"mean\"\n-  if embedding_weights is None:\n-    raise ValueError(\"Missing embedding_weights %s.\" % embedding_weights)\n-  if isinstance(embedding_weights, variables.PartitionedVariable):\n-    embedding_weights = list(embedding_weights)  # get underlying Variables.\n-  if not isinstance(embedding_weights, list):\n-    embedding_weights = [embedding_weights]\n-  if len(embedding_weights) < 1:\n-    raise ValueError(\"Missing embedding_weights %s.\" % embedding_weights)\n-\n-  dtype = sparse_weights.dtype if sparse_weights is not None else None\n-  if isinstance(embedding_weights, variables.PartitionedVariable):\n-    embedding_weights = list(embedding_weights)\n-  embedding_weights = [\n-      ops.convert_to_tensor(w, dtype=dtype) for w in embedding_weights\n-  ]\n-\n-  contrib_tensor_util.assert_same_float_dtype(embedding_weights +\n-                                              [sparse_weights])\n-\n-  with ops.name_scope(name, \"embedding_lookup\",\n-                      embedding_weights + [sparse_ids,\n-                                           sparse_weights]) as scope:\n-    # Reshape higher-rank sparse ids and weights to linear segment ids.\n-    original_shape = sparse_ids.dense_shape\n-    original_rank_dim = sparse_ids.dense_shape.get_shape()[0]\n-    original_rank = (\n-        array_ops.size(original_shape)\n-        if original_rank_dim.value is None\n-        else original_rank_dim.value)\n-    sparse_ids = sparse_ops.sparse_reshape(sparse_ids, [\n-        math_ops.reduce_prod(\n-            array_ops.slice(original_shape, [0], [original_rank - 1])),\n-        array_ops.gather(original_shape, original_rank - 1)])\n-    if sparse_weights is not None:\n-      sparse_weights = sparse_tensor.SparseTensor(\n-          sparse_ids.indices,\n-          sparse_weights.values, sparse_ids.dense_shape)\n-\n-    # Prune invalid ids and weights.\n-    sparse_ids, sparse_weights = _prune_invalid_ids(sparse_ids, sparse_weights)\n-    if combiner != \"sum\":\n-      sparse_ids, sparse_weights = _prune_invalid_weights(\n-          sparse_ids, sparse_weights)\n-\n-    # Fill in dummy values for empty features, if necessary.\n-    sparse_ids, is_row_empty = sparse_ops.sparse_fill_empty_rows(sparse_ids,\n-                                                                 default_id or\n-                                                                 0)\n-    if sparse_weights is not None:\n-      sparse_weights, _ = sparse_ops.sparse_fill_empty_rows(sparse_weights, 1.0)\n-\n-    result = embedding_ops.embedding_lookup_sparse(\n-        embedding_weights,\n-        sparse_ids,\n-        sparse_weights,\n-        combiner=combiner,\n-        partition_strategy=partition_strategy,\n-        name=None if default_id is None else scope,\n-        max_norm=max_norm)\n-\n-    if default_id is None:\n-      # Broadcast is_row_empty to the same shape as embedding_lookup_result,\n-      # for use in Select.\n-      is_row_empty = array_ops.tile(\n-          array_ops.reshape(is_row_empty, [-1, 1]),\n-          array_ops.stack([1, array_ops.shape(result)[1]]))\n-\n-      result = array_ops.where(is_row_empty,\n-                               array_ops.zeros_like(result),\n-                               result,\n-                               name=scope)\n-\n-    # Reshape back from linear ids back into higher-dimensional dense result.\n-    final_result = array_ops.reshape(\n-        result,\n-        array_ops.concat([\n-            array_ops.slice(\n-                math_ops.cast(original_shape, dtypes.int32), [0],\n-                [original_rank - 1]),\n-            array_ops.slice(array_ops.shape(result), [1], [-1])\n-        ], 0))\n-    final_result.set_shape(tensor_shape.unknown_shape(\n-        (original_rank_dim - 1).value).concatenate(result.get_shape()[1:]))\n-    return final_result\n-\n-\n-def _prune_invalid_ids(sparse_ids, sparse_weights):\n-  \"\"\"Prune invalid IDs (< 0) from the input ids and weights.\"\"\"\n-  is_id_valid = math_ops.greater_equal(sparse_ids.values, 0)\n-  if sparse_weights is not None:\n-    is_id_valid = math_ops.logical_and(\n-        is_id_valid,\n-        array_ops.ones_like(sparse_weights.values, dtype=dtypes.bool))\n-  sparse_ids = sparse_ops.sparse_retain(sparse_ids, is_id_valid)\n-  if sparse_weights is not None:\n-    sparse_weights = sparse_ops.sparse_retain(sparse_weights, is_id_valid)\n-  return sparse_ids, sparse_weights\n-\n-\n-def _prune_invalid_weights(sparse_ids, sparse_weights):\n-  \"\"\"Prune invalid weights (< 0) from the input ids and weights.\"\"\"\n-  if sparse_weights is not None:\n-    is_weights_valid = math_ops.greater(sparse_weights.values, 0)\n-    sparse_ids = sparse_ops.sparse_retain(sparse_ids, is_weights_valid)\n-    sparse_weights = sparse_ops.sparse_retain(sparse_weights, is_weights_valid)\n-  return sparse_ids, sparse_weights\n+  return embedding_ops.safe_embedding_lookup_sparse(", "path": "tensorflow/contrib/layers/python/layers/embedding_ops.py", "position": null, "original_position": 125, "commit_id": "948577cf0cf7bbc93a8766fc19230062e9560f83", "original_commit_id": "91ad552a52242b3d382eee6a3382c79be36b7df7", "user": {"login": "ispirmustafa", "id": 19293677, "node_id": "MDQ6VXNlcjE5MjkzNjc3", "avatar_url": "https://avatars1.githubusercontent.com/u/19293677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ispirmustafa", "html_url": "https://github.com/ispirmustafa", "followers_url": "https://api.github.com/users/ispirmustafa/followers", "following_url": "https://api.github.com/users/ispirmustafa/following{/other_user}", "gists_url": "https://api.github.com/users/ispirmustafa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ispirmustafa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ispirmustafa/subscriptions", "organizations_url": "https://api.github.com/users/ispirmustafa/orgs", "repos_url": "https://api.github.com/users/ispirmustafa/repos", "events_url": "https://api.github.com/users/ispirmustafa/events{/privacy}", "received_events_url": "https://api.github.com/users/ispirmustafa/received_events", "type": "User", "site_admin": false}, "body": "let's do not change the contrib one.", "created_at": "2018-04-25T20:40:05Z", "updated_at": "2018-05-02T12:27:21Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18771#discussion_r184198727", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18771", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/184198727"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18771#discussion_r184198727"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18771"}}, "body_html": "<p>let's do not change the contrib one.</p>", "body_text": "let's do not change the contrib one."}