{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/159672345", "html_url": "https://github.com/tensorflow/tensorflow/issues/25#issuecomment-159672345", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/25", "id": 159672345, "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY3MjM0NQ==", "user": {"login": "pplonski", "id": 6959032, "node_id": "MDQ6VXNlcjY5NTkwMzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/6959032?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pplonski", "html_url": "https://github.com/pplonski", "followers_url": "https://api.github.com/users/pplonski/followers", "following_url": "https://api.github.com/users/pplonski/following{/other_user}", "gists_url": "https://api.github.com/users/pplonski/gists{/gist_id}", "starred_url": "https://api.github.com/users/pplonski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pplonski/subscriptions", "organizations_url": "https://api.github.com/users/pplonski/orgs", "repos_url": "https://api.github.com/users/pplonski/repos", "events_url": "https://api.github.com/users/pplonski/events{/privacy}", "received_events_url": "https://api.github.com/users/pplonski/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-25T17:00:51Z", "updated_at": "2015-11-25T17:00:51Z", "author_association": "NONE", "body_html": "<p>Hi! I have a problem with compilation of tensorflow with GTX 670. I run</p>\n<pre><code>TF_UNOFFICIAL_SETTING=1 ./configure\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n</code></pre>\n<p>I got error:</p>\n<pre><code>INFO: Found 1 target...\nINFO: From Compiling tensorflow/core/kernels/bias_op_gpu.cu.cc:\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=float]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias&lt;tensorflow::GPUDevice, T, Dims&gt;::operator()(const tensorflow::functor::Bias&lt;tensorflow::GPUDevice, T, Dims&gt;::Device &amp;, tensorflow::TTypes&lt;T, Dims, Eigen::DenseIndex&gt;::ConstTensor, tensorflow::TTypes&lt;T, 1, Eigen::DenseIndex&gt;::ConstVec, tensorflow::TTypes&lt;T, Dims, Eigen::DenseIndex&gt;::Tensor) [with T=float, Dims=2]\" \n(69): here\n\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=double]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias&lt;tensorflow::GPUDevice, T, Dims&gt;::operator()(const tensorflow::functor::Bias&lt;tensorflow::GPUDevice, T, Dims&gt;::Device &amp;, tensorflow::TTypes&lt;T, Dims, Eigen::DenseIndex&gt;::ConstTensor, tensorflow::TTypes&lt;T, 1, Eigen::DenseIndex&gt;::ConstVec, tensorflow::TTypes&lt;T, Dims, Eigen::DenseIndex&gt;::Tensor) [with T=double, Dims=2]\" \n(69): here\n\n2 errors detected in the compilation of \"/tmp/tmpxft_000067dd_00000000-7_bias_op_gpu.cu.cpp1.ii\".\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: output 'tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/bias_op_gpu.cu.o' was not created.\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: not all outputs were created.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n</code></pre>\n<p>Information about my card from NVIDIA samples deviceQuery:</p>\n<pre><code>Device 0: \"GeForce GTX 670\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2046 MBytes (2145235968 bytes)\n  ( 7) Multiprocessors, (192) CUDA Cores/MP:     1344 CUDA Cores\n  GPU Max Clock rate:                            980 MHz (0.98 GHz)\n  Memory Clock rate:                             3004 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 524288 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GTX 670\n</code></pre>\n<p>Any ideas why it is not working?<br>\nThanks!</p>", "body_text": "Hi! I have a problem with compilation of tensorflow with GTX 670. I run\nTF_UNOFFICIAL_SETTING=1 ./configure\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n\nI got error:\nINFO: Found 1 target...\nINFO: From Compiling tensorflow/core/kernels/bias_op_gpu.cu.cc:\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=float]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::operator()(const tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::Device &, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::ConstTensor, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::Tensor) [with T=float, Dims=2]\" \n(69): here\n\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=double]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::operator()(const tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::Device &, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::ConstTensor, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::Tensor) [with T=double, Dims=2]\" \n(69): here\n\n2 errors detected in the compilation of \"/tmp/tmpxft_000067dd_00000000-7_bias_op_gpu.cu.cpp1.ii\".\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: output 'tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/bias_op_gpu.cu.o' was not created.\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: not all outputs were created.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n\nInformation about my card from NVIDIA samples deviceQuery:\nDevice 0: \"GeForce GTX 670\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2046 MBytes (2145235968 bytes)\n  ( 7) Multiprocessors, (192) CUDA Cores/MP:     1344 CUDA Cores\n  GPU Max Clock rate:                            980 MHz (0.98 GHz)\n  Memory Clock rate:                             3004 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 524288 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GTX 670\n\nAny ideas why it is not working?\nThanks!", "body": "Hi! I have a problem with compilation of tensorflow with GTX 670. I run \n\n```\nTF_UNOFFICIAL_SETTING=1 ./configure\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n```\n\nI got error:\n\n```\nINFO: Found 1 target...\nINFO: From Compiling tensorflow/core/kernels/bias_op_gpu.cu.cc:\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=float]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::operator()(const tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::Device &, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::ConstTensor, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::Tensor) [with T=float, Dims=2]\" \n(69): here\n\ntensorflow/core/kernels/bias_op_gpu.cu.cc(40): error: identifier \"__ldg\" is undefined\n          detected during:\n            instantiation of \"void tensorflow::functor::BiasOpCustomKernel(int, const T *, const T *, int, int, T *) [with T=double]\" \n(57): here\n            instantiation of \"void tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::operator()(const tensorflow::functor::Bias<tensorflow::GPUDevice, T, Dims>::Device &, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::ConstTensor, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, Dims, Eigen::DenseIndex>::Tensor) [with T=double, Dims=2]\" \n(69): here\n\n2 errors detected in the compilation of \"/tmp/tmpxft_000067dd_00000000-7_bias_op_gpu.cu.cpp1.ii\".\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: output 'tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/bias_op_gpu.cu.o' was not created.\nERROR: /home/piotr/tensorflow/tensorflow/tensorflow/core/BUILD:248:1: not all outputs were created.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n```\n\nInformation about my card from NVIDIA samples deviceQuery:\n\n```\nDevice 0: \"GeForce GTX 670\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2046 MBytes (2145235968 bytes)\n  ( 7) Multiprocessors, (192) CUDA Cores/MP:     1344 CUDA Cores\n  GPU Max Clock rate:                            980 MHz (0.98 GHz)\n  Memory Clock rate:                             3004 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 524288 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GTX 670\n```\n\nAny ideas why it is not working?\nThanks!\n"}