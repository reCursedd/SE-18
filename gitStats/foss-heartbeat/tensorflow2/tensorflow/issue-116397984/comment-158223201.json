{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/158223201", "html_url": "https://github.com/tensorflow/tensorflow/issues/149#issuecomment-158223201", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/149", "id": 158223201, "node_id": "MDEyOklzc3VlQ29tbWVudDE1ODIyMzIwMQ==", "user": {"login": "ruffsl", "id": 2293573, "node_id": "MDQ6VXNlcjIyOTM1NzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2293573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruffsl", "html_url": "https://github.com/ruffsl", "followers_url": "https://api.github.com/users/ruffsl/followers", "following_url": "https://api.github.com/users/ruffsl/following{/other_user}", "gists_url": "https://api.github.com/users/ruffsl/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruffsl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruffsl/subscriptions", "organizations_url": "https://api.github.com/users/ruffsl/orgs", "repos_url": "https://api.github.com/users/ruffsl/repos", "events_url": "https://api.github.com/users/ruffsl/events{/privacy}", "received_events_url": "https://api.github.com/users/ruffsl/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-19T22:39:18Z", "updated_at": "2015-11-19T22:39:18Z", "author_association": "NONE", "body_html": "<p>Hmm, normally its a <a href=\"https://docs.docker.com/v1.8/articles/dockerfile_best-practices/\" rel=\"nofollow\">best practice</a> to keep a nice linear sequential hierarchy in the tag structure to leverage the storage savings and reduce duplication of binaries by reusing image layers on disk. But from what I'm seeing currently, building the project over itself (once for CPU, then for GPU) is leading to some large image sizes:</p>\n<div class=\"highlight highlight-text-shell-session\"><pre>$ <span class=\"pl-s1\">docker images</span>\n<span class=\"pl-c1\">REPOSITORY                                TAG                    IMAGE ID            CREATED             VIRTUAL SIZE</span>\n<span class=\"pl-c1\">tensorflow                                gpu                    1ca458346ab2        16 hours ago        4.847 GB</span>\n<span class=\"pl-c1\">tensorflow                                cpu                    f092a7f6f122        16 hours ago        3.967 GB</span>\n<span class=\"pl-c1\">tensorflow                                latest                 6711b8288898        16 hours ago        2.406 GB</span>\n<span class=\"pl-c1\">cudnn                                     v2-7.0                 80a8e0efea8d        21 hours ago        2.041 GB</span>\n<span class=\"pl-c1\">cuda                                      7.0                    f8abb195d52b        21 hours ago        2.012 GB</span>\n<span class=\"pl-c1\">ubuntu                                    14.04                  e9ae3c220b23        9 days ago          187.9 MB</span></pre></div>\n<p>(The above isn't really optimized yet, its just built in cascaded order with nothing flattened like in the README.md. Also, perhaps the cuda image could <a href=\"https://github.com/NVIDIA/nvidia-docker/issues/12\" data-hovercard-type=\"issue\" data-hovercard-url=\"/NVIDIA/nvidia-docker/issues/12/hovercard\">shed some weight</a>, I suspect it might be rolling in a lot of odd packages)</p>\n<p>By forking the <code>tensorflow:full</code> and <code>tensorflow:full-gpu</code> tags we could keep the disk size of each individual tag reasonable at the cost of making the sum of all tags larger. However, my expectation is that users will just deploy with one or the other so bandwidth in moving images would be the limitation. Whereas if someone has both tags locally, ether for testing or experimentation, I don't think storage would be their primary concern. The same could be done I suppose for the <code>latest</code> image, so the trade off is redundant looking dockerfiles and layers for smaller individual tags.</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>From</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>tensorflow:<code>latest</code></td>\n<td>ubuntu:<code>14.04</code></td>\n</tr>\n<tr>\n<td>tensorflow:<code>full</code></td>\n<td>tensorflow:<code>latest</code> (OR ubuntu:<code>14.04</code>)</td>\n</tr>\n<tr>\n<td>tensorflow:<code>full-gpu</code></td>\n<td>cuda:<code>7.0-cudnn</code></td>\n</tr>\n</tbody>\n</table>\n<p>We could play some tricks and keep the heads of each dockerfile similar as long as we could to <a href=\"http://thenewstack.io/understanding-the-docker-cache-for-faster-builds/\" rel=\"nofollow\">preserve the build catch</a>. I'm not sure how much the Docker Hub's build processes respects this though if an entire repo is churned with independent tags.</p>\n<p>To get to your last question: Yes, <code>latest</code> holds a special <a href=\"https://docs.docker.com/v1.8/reference/builder/#from\" rel=\"nofollow\">default</a> meaning. I haven't seen the use of <code>:latest-foo</code> anywhere, as the user would have to spell it out fully to use it anyway, so for brevity most just do <code>:foo</code> or <code>:&lt;release&gt;-foo</code>. By the way, what release is tensorflow at? Is this all still version &lt; 1.0?</p>", "body_text": "Hmm, normally its a best practice to keep a nice linear sequential hierarchy in the tag structure to leverage the storage savings and reduce duplication of binaries by reusing image layers on disk. But from what I'm seeing currently, building the project over itself (once for CPU, then for GPU) is leading to some large image sizes:\n$ docker images\nREPOSITORY                                TAG                    IMAGE ID            CREATED             VIRTUAL SIZE\ntensorflow                                gpu                    1ca458346ab2        16 hours ago        4.847 GB\ntensorflow                                cpu                    f092a7f6f122        16 hours ago        3.967 GB\ntensorflow                                latest                 6711b8288898        16 hours ago        2.406 GB\ncudnn                                     v2-7.0                 80a8e0efea8d        21 hours ago        2.041 GB\ncuda                                      7.0                    f8abb195d52b        21 hours ago        2.012 GB\nubuntu                                    14.04                  e9ae3c220b23        9 days ago          187.9 MB\n(The above isn't really optimized yet, its just built in cascaded order with nothing flattened like in the README.md. Also, perhaps the cuda image could shed some weight, I suspect it might be rolling in a lot of odd packages)\nBy forking the tensorflow:full and tensorflow:full-gpu tags we could keep the disk size of each individual tag reasonable at the cost of making the sum of all tags larger. However, my expectation is that users will just deploy with one or the other so bandwidth in moving images would be the limitation. Whereas if someone has both tags locally, ether for testing or experimentation, I don't think storage would be their primary concern. The same could be done I suppose for the latest image, so the trade off is redundant looking dockerfiles and layers for smaller individual tags.\n\n\n\nName\nFrom\n\n\n\n\ntensorflow:latest\nubuntu:14.04\n\n\ntensorflow:full\ntensorflow:latest (OR ubuntu:14.04)\n\n\ntensorflow:full-gpu\ncuda:7.0-cudnn\n\n\n\nWe could play some tricks and keep the heads of each dockerfile similar as long as we could to preserve the build catch. I'm not sure how much the Docker Hub's build processes respects this though if an entire repo is churned with independent tags.\nTo get to your last question: Yes, latest holds a special default meaning. I haven't seen the use of :latest-foo anywhere, as the user would have to spell it out fully to use it anyway, so for brevity most just do :foo or :<release>-foo. By the way, what release is tensorflow at? Is this all still version < 1.0?", "body": "Hmm, normally its a [best practice](https://docs.docker.com/v1.8/articles/dockerfile_best-practices/) to keep a nice linear sequential hierarchy in the tag structure to leverage the storage savings and reduce duplication of binaries by reusing image layers on disk. But from what I'm seeing currently, building the project over itself (once for CPU, then for GPU) is leading to some large image sizes:\n\n``` console\n$ docker images\nREPOSITORY                                TAG                    IMAGE ID            CREATED             VIRTUAL SIZE\ntensorflow                                gpu                    1ca458346ab2        16 hours ago        4.847 GB\ntensorflow                                cpu                    f092a7f6f122        16 hours ago        3.967 GB\ntensorflow                                latest                 6711b8288898        16 hours ago        2.406 GB\ncudnn                                     v2-7.0                 80a8e0efea8d        21 hours ago        2.041 GB\ncuda                                      7.0                    f8abb195d52b        21 hours ago        2.012 GB\nubuntu                                    14.04                  e9ae3c220b23        9 days ago          187.9 MB\n```\n\n(The above isn't really optimized yet, its just built in cascaded order with nothing flattened like in the README.md. Also, perhaps the cuda image could [shed some weight](https://github.com/NVIDIA/nvidia-docker/issues/12), I suspect it might be rolling in a lot of odd packages)\n\nBy forking the `tensorflow:full` and `tensorflow:full-gpu` tags we could keep the disk size of each individual tag reasonable at the cost of making the sum of all tags larger. However, my expectation is that users will just deploy with one or the other so bandwidth in moving images would be the limitation. Whereas if someone has both tags locally, ether for testing or experimentation, I don't think storage would be their primary concern. The same could be done I suppose for the `latest` image, so the trade off is redundant looking dockerfiles and layers for smaller individual tags. \n\n| Name | From |\n| --- | --- |\n| tensorflow:`latest` | ubuntu:`14.04` |\n| tensorflow:`full` | tensorflow:`latest` (OR ubuntu:`14.04`) |\n| tensorflow:`full-gpu` | cuda:`7.0-cudnn` |\n\nWe could play some tricks and keep the heads of each dockerfile similar as long as we could to [preserve the build catch](http://thenewstack.io/understanding-the-docker-cache-for-faster-builds/). I'm not sure how much the Docker Hub's build processes respects this though if an entire repo is churned with independent tags.\n\nTo get to your last question: Yes, `latest` holds a special [default](https://docs.docker.com/v1.8/reference/builder/#from) meaning. I haven't seen the use of `:latest-foo` anywhere, as the user would have to spell it out fully to use it anyway, so for brevity most just do `:foo` or `:<release>-foo`. By the way, what release is tensorflow at? Is this all still version < 1.0?\n"}