{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/200607316", "html_url": "https://github.com/tensorflow/tensorflow/pull/763#issuecomment-200607316", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/763", "id": 200607316, "node_id": "MDEyOklzc3VlQ29tbWVudDIwMDYwNzMxNg==", "user": {"login": "jeremybarnes", "id": 112556, "node_id": "MDQ6VXNlcjExMjU1Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/112556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeremybarnes", "html_url": "https://github.com/jeremybarnes", "followers_url": "https://api.github.com/users/jeremybarnes/followers", "following_url": "https://api.github.com/users/jeremybarnes/following{/other_user}", "gists_url": "https://api.github.com/users/jeremybarnes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeremybarnes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeremybarnes/subscriptions", "organizations_url": "https://api.github.com/users/jeremybarnes/orgs", "repos_url": "https://api.github.com/users/jeremybarnes/repos", "events_url": "https://api.github.com/users/jeremybarnes/events{/privacy}", "received_events_url": "https://api.github.com/users/jeremybarnes/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-24T01:32:48Z", "updated_at": "2016-03-24T01:32:48Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1710528\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bhack\">@bhack</a> This patch (or at least, where I originally branched off) works, is running in production at <a href=\"http://mldb.ai/\" rel=\"nofollow\">http://mldb.ai/</a>, and does increase the CPU-only speed of Tensorflow by a factor of 2, in both training and prediction, from C++ and Python.  It's pretty safe to use, since it's disabled by default and needs to be turned on by an environment variable.</p>\n<p>However, I don't see a viable path to getting it merged.  Several days of work went into pulling it into shape based upon the reviewer's comments (especially <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1095328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dvyukov\">@dvyukov</a> who had excellent comments and a deep review).  Unfortunately most of the comments were lost in Reviewable when the patch was rebased for merge, and there was no clarity on how many separate reviewers it would need to pass (with most review comments focusing on the more trivial aspects of style rather than a deep review of the substance).  So it ended up at a bit of a dead end.</p>\n<p>More importantly, I feel we need some input from the project leadership.  Concurrently with reviewing my patch, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1095328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dvyukov\">@dvyukov</a> proposed <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"130786204\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/967\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/967/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/967\">#967</a> which fixes slightly different problems (optimizing jobs submitted from a single thread rather than multiple threads as in this patch), but he also identified <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"129776970\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/932\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/932/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/932\">#932</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"129777677\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/933\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/933/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/933\">#933</a> which show some more fundamental issues in the thread pool model and Eigen.  We agreed that we needed a clear direction on which benchmarks or situations we were interested in optimizing for to decide, but it looks like the TF team are busy putting TF everywhere as their day-jobs whilst managing one of the most popular OSS projects on Github and we haven't heard back :)</p>\n<p>More seriously, some more structured guidance for non-Google committers would be helpful, as there is a lot of assumed knowledge of the Google development processes that external committers just don't have.  For example, it seems that Googlers look at each other's employee number to understand relative seniority when there is conflicting advice, but those aren't available on Github.  It would have also been helpful to know that reviewers will default to reviewing coding style before passing to deeper reviews, and so one should focus on getting that right before thinking about the functionality.</p>\n<p>I would also not recommend using Reviewable until it has greatly matured; my experience there was very poor.  I can see it has merits as a tool, but needs some more work and I have issues with the PR metadata and comments not being visible on Github.</p>\n<p>Since I ran out of time to work on this, I decided to put it aside until I had a clear indication that it was worth working on and had a chance of getting merged.</p>\n<p>The bright side is that MLDB's thread pool improved from the review comments, so in some ways I found a way to get Google employees to review code from another project :)</p>\n<p>The version in mldbai/tensorflow on the master branch is more up to date, if ever you want to use it, though it's based on an earlier hash.</p>", "body_text": "@bhack This patch (or at least, where I originally branched off) works, is running in production at http://mldb.ai/, and does increase the CPU-only speed of Tensorflow by a factor of 2, in both training and prediction, from C++ and Python.  It's pretty safe to use, since it's disabled by default and needs to be turned on by an environment variable.\nHowever, I don't see a viable path to getting it merged.  Several days of work went into pulling it into shape based upon the reviewer's comments (especially @dvyukov who had excellent comments and a deep review).  Unfortunately most of the comments were lost in Reviewable when the patch was rebased for merge, and there was no clarity on how many separate reviewers it would need to pass (with most review comments focusing on the more trivial aspects of style rather than a deep review of the substance).  So it ended up at a bit of a dead end.\nMore importantly, I feel we need some input from the project leadership.  Concurrently with reviewing my patch, @dvyukov proposed #967 which fixes slightly different problems (optimizing jobs submitted from a single thread rather than multiple threads as in this patch), but he also identified #932 and #933 which show some more fundamental issues in the thread pool model and Eigen.  We agreed that we needed a clear direction on which benchmarks or situations we were interested in optimizing for to decide, but it looks like the TF team are busy putting TF everywhere as their day-jobs whilst managing one of the most popular OSS projects on Github and we haven't heard back :)\nMore seriously, some more structured guidance for non-Google committers would be helpful, as there is a lot of assumed knowledge of the Google development processes that external committers just don't have.  For example, it seems that Googlers look at each other's employee number to understand relative seniority when there is conflicting advice, but those aren't available on Github.  It would have also been helpful to know that reviewers will default to reviewing coding style before passing to deeper reviews, and so one should focus on getting that right before thinking about the functionality.\nI would also not recommend using Reviewable until it has greatly matured; my experience there was very poor.  I can see it has merits as a tool, but needs some more work and I have issues with the PR metadata and comments not being visible on Github.\nSince I ran out of time to work on this, I decided to put it aside until I had a clear indication that it was worth working on and had a chance of getting merged.\nThe bright side is that MLDB's thread pool improved from the review comments, so in some ways I found a way to get Google employees to review code from another project :)\nThe version in mldbai/tensorflow on the master branch is more up to date, if ever you want to use it, though it's based on an earlier hash.", "body": "@bhack This patch (or at least, where I originally branched off) works, is running in production at http://mldb.ai/, and does increase the CPU-only speed of Tensorflow by a factor of 2, in both training and prediction, from C++ and Python.  It's pretty safe to use, since it's disabled by default and needs to be turned on by an environment variable.\n\nHowever, I don't see a viable path to getting it merged.  Several days of work went into pulling it into shape based upon the reviewer's comments (especially @dvyukov who had excellent comments and a deep review).  Unfortunately most of the comments were lost in Reviewable when the patch was rebased for merge, and there was no clarity on how many separate reviewers it would need to pass (with most review comments focusing on the more trivial aspects of style rather than a deep review of the substance).  So it ended up at a bit of a dead end.\n\nMore importantly, I feel we need some input from the project leadership.  Concurrently with reviewing my patch, @dvyukov proposed #967 which fixes slightly different problems (optimizing jobs submitted from a single thread rather than multiple threads as in this patch), but he also identified #932 and #933 which show some more fundamental issues in the thread pool model and Eigen.  We agreed that we needed a clear direction on which benchmarks or situations we were interested in optimizing for to decide, but it looks like the TF team are busy putting TF everywhere as their day-jobs whilst managing one of the most popular OSS projects on Github and we haven't heard back :)\n\nMore seriously, some more structured guidance for non-Google committers would be helpful, as there is a lot of assumed knowledge of the Google development processes that external committers just don't have.  For example, it seems that Googlers look at each other's employee number to understand relative seniority when there is conflicting advice, but those aren't available on Github.  It would have also been helpful to know that reviewers will default to reviewing coding style before passing to deeper reviews, and so one should focus on getting that right before thinking about the functionality.\n\nI would also not recommend using Reviewable until it has greatly matured; my experience there was very poor.  I can see it has merits as a tool, but needs some more work and I have issues with the PR metadata and comments not being visible on Github.\n\nSince I ran out of time to work on this, I decided to put it aside until I had a clear indication that it was worth working on and had a chance of getting merged.\n\nThe bright side is that MLDB's thread pool improved from the review comments, so in some ways I found a way to get Google employees to review code from another project :)\n\nThe version in mldbai/tensorflow on the master branch is more up to date, if ever you want to use it, though it's based on an earlier hash.\n"}