{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5050", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5050/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5050/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5050/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5050", "id": 183794065, "node_id": "MDU6SXNzdWUxODM3OTQwNjU=", "number": 5050, "title": "tf.Session.reset crashes after starting the chief queue runner", "user": {"login": "daeyun", "id": 1250682, "node_id": "MDQ6VXNlcjEyNTA2ODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1250682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daeyun", "html_url": "https://github.com/daeyun", "followers_url": "https://api.github.com/users/daeyun/followers", "following_url": "https://api.github.com/users/daeyun/following{/other_user}", "gists_url": "https://api.github.com/users/daeyun/gists{/gist_id}", "starred_url": "https://api.github.com/users/daeyun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daeyun/subscriptions", "organizations_url": "https://api.github.com/users/daeyun/orgs", "repos_url": "https://api.github.com/users/daeyun/repos", "events_url": "https://api.github.com/users/daeyun/events{/privacy}", "received_events_url": "https://api.github.com/users/daeyun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-10-18T20:27:48Z", "updated_at": "2017-09-15T12:45:30Z", "closed_at": "2017-09-15T12:45:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Code to reproduce:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tempfile\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">_</span>):\n    sync <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n    start_chief_queue_runners <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n    is_chief <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n    server <span class=\"pl-k\">=</span> tf.train.Server.create_local_server()\n    logdir <span class=\"pl-k\">=</span> tempfile.mkdtemp()\n\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n\n    device_setter <span class=\"pl-k\">=</span> tf.train.replica_device_setter(<span class=\"pl-v\">worker_device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/job:worker/task:0<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">with</span> graph.as_default(), tf.device(device_setter):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build loss op.</span>\n        x <span class=\"pl-k\">=</span> tf.random_normal([<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">128</span>])\n        y <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-v\">initial_value</span><span class=\"pl-k\">=</span>tf.random_normal([<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">128</span>]))\n        global_step <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>)\n        loss <span class=\"pl-k\">=</span> tf.reduce_sum(tf.squared_difference(x, y), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss<span class=\"pl-pds\">'</span></span>)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Set up optimizer.</span>\n        optim <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.001</span>)\n        <span class=\"pl-k\">if</span> sync:\n            optim <span class=\"pl-k\">=</span> tf.train.SyncReplicasOptimizerV2(optim, <span class=\"pl-c1\">1</span>)\n        minimize <span class=\"pl-k\">=</span> optim.minimize(loss, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>global_step, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>train_op<span class=\"pl-pds\">'</span></span>)\n\n        ready_for_local_init <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        local_step_init <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        <span class=\"pl-k\">if</span> sync:\n            init_tokens <span class=\"pl-k\">=</span> optim.get_init_tokens_op()\n            chief_qr <span class=\"pl-k\">=</span> optim.get_chief_queue_runner()\n            ready_for_local_init <span class=\"pl-k\">=</span> optim.ready_for_local_init_op\n            local_step_init <span class=\"pl-k\">=</span> optim.local_step_init_op\n        init_op <span class=\"pl-k\">=</span> tf.initialize_all_variables()\n\n    sv <span class=\"pl-k\">=</span> tf.train.Supervisor(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph,\n                             <span class=\"pl-v\">is_chief</span><span class=\"pl-k\">=</span>is_chief,\n                             <span class=\"pl-v\">ready_for_local_init_op</span><span class=\"pl-k\">=</span>ready_for_local_init,\n                             <span class=\"pl-v\">init_op</span><span class=\"pl-k\">=</span>init_op,\n                             <span class=\"pl-v\">local_init_op</span><span class=\"pl-k\">=</span>local_step_init,\n                             <span class=\"pl-v\">recovery_wait_secs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n                             <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>global_step,\n                             <span class=\"pl-v\">logdir</span><span class=\"pl-k\">=</span>logdir)\n\n    config <span class=\"pl-k\">=</span> server.server_def.default_session_config\n    sess <span class=\"pl-k\">=</span> sv.prepare_or_wait_for_session(server.target, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config,\n                                          <span class=\"pl-v\">start_standard_services</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n    <span class=\"pl-k\">with</span> sess.as_default():\n        <span class=\"pl-k\">if</span> is_chief <span class=\"pl-k\">and</span> sync <span class=\"pl-k\">and</span> start_chief_queue_runners:\n            sv.start_queue_runners(sess, [chief_qr])\n            init_tokens.run()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Wait for the queue runner to start.</span>\n    time.sleep(<span class=\"pl-c1\">2</span>)\n\n    tf.Session.reset(server.target)\n\n    time.sleep(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>restarted session<span class=\"pl-pds\">'</span></span>)\n\n    server.join()\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.app.run(main)</pre></div>\n<p>What I see:</p>\n<pre><code>I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job local -&gt; {0 -&gt; localhost:33954}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:33954\nI tensorflow/core/distributed_runtime/master_session.cc:869] Start master session 3d7c628e8fd8d707 with config: \n\n*** Error in `/home/daeyun/anaconda3/bin/python': double free or corruption (fasttop): 0x00007f2000087ca0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f20f0d35725]\n/lib/x86_64-linux-gnu/libc.so.6(+0x7ff4a)[0x7f20f0d3df4a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f20f0d41abc]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x11ae503)[0x7f20c471b503]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase16TryAttemptLockedEPSt6vectorINS0_7CleanUpESaIS2_EE+0x6c)[0x7f20c471be2c]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase13FlushUnlockedEv+0x7b)[0x7f20c471c0fb]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase6CancelEPNS_19CancellationManagerEx+0xde)[0x7f20c471c33e]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow19CancellationManager11StartCancelEv+0x28b)[0x7f20c59a5bab]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc51a16)[0x7f20c41bea16]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc5d743)[0x7f20c41ca743]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc62704)[0x7f20c41cf704]\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f20c3045c80]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x76fa)[0x7f20f179e6fa]\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f20f0dc4b5d]\n</code></pre>\n<p>This seems to happen after <code>SyncReplicasOptimizerV2</code>'s chief queue runner starts.<br>\nThis does not happen when <code>start_chief_queue_runners</code> or <code>sync</code> variable is <code>False</code>.</p>\n<p>System info: Nightly build (Python 3.4), Anaconda, Ubuntu 16.04</p>", "body_text": "Code to reproduce:\nimport tempfile\nimport time\n\nimport tensorflow as tf\n\n\ndef main(_):\n    sync = True\n    start_chief_queue_runners = True\n\n    is_chief = True\n    server = tf.train.Server.create_local_server()\n    logdir = tempfile.mkdtemp()\n\n    graph = tf.Graph()\n\n    device_setter = tf.train.replica_device_setter(worker_device='/job:worker/task:0')\n    with graph.as_default(), tf.device(device_setter):\n        # Build loss op.\n        x = tf.random_normal([100, 128])\n        y = tf.Variable(initial_value=tf.random_normal([100, 128]))\n        global_step = tf.Variable(0)\n        loss = tf.reduce_sum(tf.squared_difference(x, y), name='loss')\n\n        # Set up optimizer.\n        optim = tf.train.GradientDescentOptimizer(0.001)\n        if sync:\n            optim = tf.train.SyncReplicasOptimizerV2(optim, 1)\n        minimize = optim.minimize(loss, global_step=global_step, name='train_op')\n\n        ready_for_local_init = None\n        local_step_init = None\n        if sync:\n            init_tokens = optim.get_init_tokens_op()\n            chief_qr = optim.get_chief_queue_runner()\n            ready_for_local_init = optim.ready_for_local_init_op\n            local_step_init = optim.local_step_init_op\n        init_op = tf.initialize_all_variables()\n\n    sv = tf.train.Supervisor(graph=graph,\n                             is_chief=is_chief,\n                             ready_for_local_init_op=ready_for_local_init,\n                             init_op=init_op,\n                             local_init_op=local_step_init,\n                             recovery_wait_secs=1,\n                             global_step=global_step,\n                             logdir=logdir)\n\n    config = server.server_def.default_session_config\n    sess = sv.prepare_or_wait_for_session(server.target, config=config,\n                                          start_standard_services=False)\n\n    with sess.as_default():\n        if is_chief and sync and start_chief_queue_runners:\n            sv.start_queue_runners(sess, [chief_qr])\n            init_tokens.run()\n\n    # Wait for the queue runner to start.\n    time.sleep(2)\n\n    tf.Session.reset(server.target)\n\n    time.sleep(1)\n    print('restarted session')\n\n    server.join()\n\n\nif __name__ == '__main__':\n    tf.app.run(main)\nWhat I see:\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job local -> {0 -> localhost:33954}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:33954\nI tensorflow/core/distributed_runtime/master_session.cc:869] Start master session 3d7c628e8fd8d707 with config: \n\n*** Error in `/home/daeyun/anaconda3/bin/python': double free or corruption (fasttop): 0x00007f2000087ca0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f20f0d35725]\n/lib/x86_64-linux-gnu/libc.so.6(+0x7ff4a)[0x7f20f0d3df4a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f20f0d41abc]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x11ae503)[0x7f20c471b503]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase16TryAttemptLockedEPSt6vectorINS0_7CleanUpESaIS2_EE+0x6c)[0x7f20c471be2c]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase13FlushUnlockedEv+0x7b)[0x7f20c471c0fb]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase6CancelEPNS_19CancellationManagerEx+0xde)[0x7f20c471c33e]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow19CancellationManager11StartCancelEv+0x28b)[0x7f20c59a5bab]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc51a16)[0x7f20c41bea16]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc5d743)[0x7f20c41ca743]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc62704)[0x7f20c41cf704]\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f20c3045c80]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x76fa)[0x7f20f179e6fa]\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f20f0dc4b5d]\n\nThis seems to happen after SyncReplicasOptimizerV2's chief queue runner starts.\nThis does not happen when start_chief_queue_runners or sync variable is False.\nSystem info: Nightly build (Python 3.4), Anaconda, Ubuntu 16.04", "body": "Code to reproduce:\n\n``` python\nimport tempfile\nimport time\n\nimport tensorflow as tf\n\n\ndef main(_):\n    sync = True\n    start_chief_queue_runners = True\n\n    is_chief = True\n    server = tf.train.Server.create_local_server()\n    logdir = tempfile.mkdtemp()\n\n    graph = tf.Graph()\n\n    device_setter = tf.train.replica_device_setter(worker_device='/job:worker/task:0')\n    with graph.as_default(), tf.device(device_setter):\n        # Build loss op.\n        x = tf.random_normal([100, 128])\n        y = tf.Variable(initial_value=tf.random_normal([100, 128]))\n        global_step = tf.Variable(0)\n        loss = tf.reduce_sum(tf.squared_difference(x, y), name='loss')\n\n        # Set up optimizer.\n        optim = tf.train.GradientDescentOptimizer(0.001)\n        if sync:\n            optim = tf.train.SyncReplicasOptimizerV2(optim, 1)\n        minimize = optim.minimize(loss, global_step=global_step, name='train_op')\n\n        ready_for_local_init = None\n        local_step_init = None\n        if sync:\n            init_tokens = optim.get_init_tokens_op()\n            chief_qr = optim.get_chief_queue_runner()\n            ready_for_local_init = optim.ready_for_local_init_op\n            local_step_init = optim.local_step_init_op\n        init_op = tf.initialize_all_variables()\n\n    sv = tf.train.Supervisor(graph=graph,\n                             is_chief=is_chief,\n                             ready_for_local_init_op=ready_for_local_init,\n                             init_op=init_op,\n                             local_init_op=local_step_init,\n                             recovery_wait_secs=1,\n                             global_step=global_step,\n                             logdir=logdir)\n\n    config = server.server_def.default_session_config\n    sess = sv.prepare_or_wait_for_session(server.target, config=config,\n                                          start_standard_services=False)\n\n    with sess.as_default():\n        if is_chief and sync and start_chief_queue_runners:\n            sv.start_queue_runners(sess, [chief_qr])\n            init_tokens.run()\n\n    # Wait for the queue runner to start.\n    time.sleep(2)\n\n    tf.Session.reset(server.target)\n\n    time.sleep(1)\n    print('restarted session')\n\n    server.join()\n\n\nif __name__ == '__main__':\n    tf.app.run(main)\n```\n\nWhat I see:\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job local -> {0 -> localhost:33954}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:33954\nI tensorflow/core/distributed_runtime/master_session.cc:869] Start master session 3d7c628e8fd8d707 with config: \n\n*** Error in `/home/daeyun/anaconda3/bin/python': double free or corruption (fasttop): 0x00007f2000087ca0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f20f0d35725]\n/lib/x86_64-linux-gnu/libc.so.6(+0x7ff4a)[0x7f20f0d3df4a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f20f0d41abc]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0x11ae503)[0x7f20c471b503]\n/home/daeyun/anaconda3//lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase16TryAttemptLockedEPSt6vectorINS0_7CleanUpESaIS2_EE+0x6c)[0x7f20c471be2c]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase13FlushUnlockedEv+0x7b)[0x7f20c471c0fb]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow26ConditionalAccumulatorBase6CancelEPNS_19CancellationManagerEx+0xde)[0x7f20c471c33e]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(_ZN10tensorflow19CancellationManager11StartCancelEv+0x28b)[0x7f20c59a5bab]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc51a16)[0x7f20c41bea16]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc5d743)[0x7f20c41ca743]\n/home/daeyun/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so(+0xc62704)[0x7f20c41cf704]\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f20c3045c80]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x76fa)[0x7f20f179e6fa]\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f20f0dc4b5d]\n```\n\nThis seems to happen after `SyncReplicasOptimizerV2`'s chief queue runner starts.\nThis does not happen when `start_chief_queue_runners` or `sync` variable is `False`. \n\nSystem info: Nightly build (Python 3.4), Anaconda, Ubuntu 16.04\n"}