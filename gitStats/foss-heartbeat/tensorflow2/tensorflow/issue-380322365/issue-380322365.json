{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23720", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23720/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23720/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23720/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23720", "id": 380322365, "node_id": "MDU6SXNzdWUzODAzMjIzNjU=", "number": 23720, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2", "user": {"login": "muneeb699", "id": 3126387, "node_id": "MDQ6VXNlcjMxMjYzODc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3126387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/muneeb699", "html_url": "https://github.com/muneeb699", "followers_url": "https://api.github.com/users/muneeb699/followers", "following_url": "https://api.github.com/users/muneeb699/following{/other_user}", "gists_url": "https://api.github.com/users/muneeb699/gists{/gist_id}", "starred_url": "https://api.github.com/users/muneeb699/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/muneeb699/subscriptions", "organizations_url": "https://api.github.com/users/muneeb699/orgs", "repos_url": "https://api.github.com/users/muneeb699/repos", "events_url": "https://api.github.com/users/muneeb699/events{/privacy}", "received_events_url": "https://api.github.com/users/muneeb699/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-13T16:49:45Z", "updated_at": "2018-11-13T21:11:39Z", "closed_at": "2018-11-13T21:11:39Z", "author_association": "NONE", "body_html": "<p><strong>Error</strong></p>\n<pre><code>Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1139, in _do_call\n    return fn(*args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1121, in _run_fn\n    status, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\contextlib.py\", line 88, in __exit__\n    next(self.gen)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in &lt;module&gt;\n    train(epochs,num_steps)\n  File \"E:/VisionLearning/Segmentation/train.py\", line 47, in train\n    sess.run(optimizer, feed_dict)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 789, in run\n    run_metadata_ptr)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 997, in _run\n    feed_dict_string, options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1132, in _do_run\n    target_list, options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\nCaused by op 'Slice', defined at:\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in &lt;module&gt;\n    train(epochs,num_steps)\n  File \"E:/VisionLearning/Segmentation/train.py\", line 28, in train\n    logits = build_model(x, 0.5, 128)\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 153, in build_model\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 22, in crop_and_concat\n    x1_crop = tf.slice(x1, offsets, size)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 547, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2896, in _slice\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\n\nProcess finished with exit code 1\n</code></pre>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes</li>\n</ul>\n<pre><code>def crop_and_concat(x1,x2):\n\n    x1_shape = tf.shape(x1)\n    x2_shape = tf.shape(x2)\n\n    x2_shape1 = x2.get_shape()\n    x1_shape1 = x1.get_shape()\n\n    # offsets for the top left corner of the crop\n    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n    print(\"offsets\",offsets)\n    print(\"x1\",x1)\n\n    #offsets = [0, (int(x1_shape1[1]) - int(x2_shape1[1])) // 2, (int(x1_shape1[2]) - int(x2_shape1[2])) // 2, 0]\n    size = [-1, int(x2_shape1[1]), int(x2_shape1[2]), -1]\n    print(\"size\",size)\n    #size = [-1, x2_shape[1], x2_shape[2], -1]\n    x1_crop = tf.slice(x1, offsets, size)\n    print(\"x1 crop\",x1_crop)\n    return tf.concat([x1_crop, x2], 3)\n\ndef build_model(x, keep_prob, batch_size):\n    print(x.get_shape())\n    conv1 = tf.layers.conv2d(\n        inputs= x,\n        filters=32,\n        kernel_size=(3,3),\n        padding='same',\n        activation = tf.nn.relu\n    )#256\n    print(\"conv1\", conv1)\n    conv1_2 = tf.layers.conv2d(\n        inputs=conv1,\n        filters=32,\n        kernel_size=(3,3),\n        padding='same',\n        activation=tf.nn.relu\n    )#252\n    print(\"conv1\", conv1_2)\n    pool1 = tf.layers.max_pooling2d(\n        inputs=conv1_2,\n        pool_size=(2,2),\n        padding='same',\n        strides = 2\n    )#126\n    print(\"pool1\", pool1)\n    conv2 = tf.layers.conv2d(\n        inputs=pool1,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )#124\n    print(\"conv2\", conv2.get_shape())\n    conv2 = tf.layers.conv2d(\n        inputs=conv2,\n        filters=64,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )#122\n    print(\"conv2\", conv2.get_shape())\n    pool2 = tf.layers.max_pooling2d(\n        inputs=conv2,\n        pool_size=2,\n        strides=2\n    )#61\n    print(\"pool2\", pool2.get_shape())\n    conv3 = tf.layers.conv2d(\n        inputs=pool2,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )#59\n    print(\"conv3\", conv3.get_shape())\n    conv3 = tf.layers.conv2d(\n        inputs=conv3,\n        filters=128,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )#57\n    print(\"conv3\", conv3.get_shape())\n    pool3 = tf.layers.max_pooling2d(\n        inputs=conv3,\n        pool_size=2,\n        strides=2\n    )\n    print(\"pool3\", pool3.get_shape())\n    conv4 = tf.layers.conv2d(\n        inputs=pool3,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv4\", conv4.get_shape())\n    conv4 = tf.layers.conv2d(\n        inputs=conv4,\n        filters=256,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )\n    print(\"conv4\", conv4.get_shape())\n    pool4 = tf.layers.max_pooling2d(\n        inputs=conv4,\n        pool_size=(2,2),\n        strides=2\n    )\n    print(\"pool4\", pool4.get_shape())\n\n    conv4_1 = tf.layers.conv2d(\n        inputs=pool4,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv41\", conv4_1.get_shape())\n    conv4_1 = tf.layers.conv2d(\n        inputs=conv4_1,\n        filters=512,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )\n    print(\"conv41\", conv4_1.get_shape())\n    pool4_1 = tf.layers.max_pooling2d(\n        inputs=conv4_1,\n        pool_size=(2, 2),\n        strides=2\n    )\n    print(\"pool41\", pool4_1.get_shape())\n    conv5 = tf.layers.conv2d(\n        inputs=pool4_1,\n        filters=1024,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv5\", conv5.get_shape())\n    conv5 = tf.layers.conv2d(\n        inputs=conv5,\n        filters=1024,\n        kernel_size=(3,3),\n        activation=tf.nn.relu\n    )\n    print(\"conv5\", conv5.get_shape())\n\n    #up1_0 = layers.concatenate([layers.UpSampling2D(size=(2,2))(conv5),conv4_1])\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\n\n    print(\"up10\", up1_0.get_shape())\n    conv6 = tf.layers.conv2d(\n        inputs=up1_0,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv6\", conv6.get_shape())\n    conv6 = tf.layers.conv2d(\n        inputs=conv6,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv6\", conv6.get_shape())\n    #up1 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv6), conv4])\n    up1 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6), conv4)\n    print(\"up1\", up1.get_shape())\n    conv6_1 = tf.layers.conv2d(\n        inputs=up1,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv61\", conv6_1.get_shape())\n    conv6_1 = tf.layers.conv2d(\n        inputs=conv6_1,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv61\", conv6_1.get_shape())\n    #up2  = layers.concatenate([layers.UpSampling2D(size=2)(conv6_1),conv3])\n    up2 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6_1), conv3)\n    print(\"up2\", up2.get_shape())\n    conv7 = tf.layers.conv2d(\n        inputs=up2,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv7\", conv7.get_shape())\n    conv7 = tf.layers.conv2d(\n        inputs=conv7,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv7\", conv7.get_shape())\n    #up3 =  layers.concatenate([layers.UpSampling2D(size=2)(conv7),conv2])\n    up3 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv7), conv2)\n    print(\"up3\", up3.get_shape())\n    conv8 = tf.layers.conv2d(\n        inputs=up3,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv8\", conv8.get_shape())\n    conv8 = tf.layers.conv2d(\n        inputs=conv8,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv8\",conv8.get_shape())\n    #up4 = layers.concatenate([layers.UpSampling2D(size=2)(conv8), conv1])\n    up4 = crop_and_concat(layers.UpSampling2D(size=(4,4))(conv8), conv1)\n    print(\"up4\",up4.get_shape())\n    conv9 = tf.layers.conv2d(\n        inputs=up4,\n        filters=32,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv91\",conv9.get_shape())\n    conv9 = tf.layers.conv2d(\n        inputs=conv9,\n        filters=32,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv9\",conv9.get_shape())\n    conv10 = tf.layers.conv2d(\n        inputs=conv9,\n        filters=1,\n        kernel_size=1,\n        activation= tf.nn.sigmoid\n    )\n    print(\"conv10\",conv10.get_shape())\n    return conv10\n</code></pre>\n<pre><code>def train(epochs, num_steps):\n    dir_images = \"Dataset/JPEGImages/480p\"\n    dir_annotations = \"Dataset/Annotations/480p\"\n\n    classes, classidx = find_classes(dir_images)\n    datas = make_dataset(dir_images, dir_annotations)\n    x = tf.placeholder(tf.float32, shape=[None, 256, 256, 3], name='X') #Need to define the shape of x\n    y = tf.placeholder(tf.float32, shape=[None, 256,256, 1], name='Y')\n    logits = build_model(x, 0.5, 128)\n    model = tf.identity(logits, name='logits')\n    Cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Cost)\n\n    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    init = tf.global_variables_initializer()\n    sess = tf.InteractiveSession()\n    # Initialize all variables\n    sess.run(init)\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        # variables need to be initialized before any sess.run() calls\n        tf.global_variables_initializer().run()\n\n        for X_batch, y_batch in generator(datas,32):\n            feed_dict = {x: X_batch, y: y_batch}\n            sess.run(optimizer, feed_dict)\n</code></pre>\n<ul>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA</li>\n<li>TensorFlow installed from (source or binary):Source</li>\n<li>TensorFlow version (use command below):1.2.1</li>\n<li>Python version:3.6.4</li>\n<li>Bazel version (if compiling from source):NA</li>\n<li>GCC/Compiler version (if compiling from source):NA</li>\n<li>CUDA/cuDNN version:NA</li>\n<li>GPU model and memory:NA</li>\n</ul>\n<p><strong>Describe the current behavior</strong> Getting this error when I am tring to start the training in images.</p>\n<p><strong>Describe the expected behavior</strong><br>\nIt should start training<br>\n<strong>Code to reproduce the issue</strong><br>\nGet Davis dataset and put it in respective folders</p>", "body_text": "Error\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1139, in _do_call\n    return fn(*args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1121, in _run_fn\n    status, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\contextlib.py\", line 88, in __exit__\n    next(self.gen)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in <module>\n    train(epochs,num_steps)\n  File \"E:/VisionLearning/Segmentation/train.py\", line 47, in train\n    sess.run(optimizer, feed_dict)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 789, in run\n    run_metadata_ptr)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 997, in _run\n    feed_dict_string, options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1132, in _do_run\n    target_list, options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\nCaused by op 'Slice', defined at:\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in <module>\n    train(epochs,num_steps)\n  File \"E:/VisionLearning/Segmentation/train.py\", line 28, in train\n    logits = build_model(x, 0.5, 128)\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 153, in build_model\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 22, in crop_and_concat\n    x1_crop = tf.slice(x1, offsets, size)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 547, in slice\n    return gen_array_ops._slice(input_, begin, size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2896, in _slice\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Expected begin[1] in [0, 8], but got -2\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\n\n\nProcess finished with exit code 1\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\n\ndef crop_and_concat(x1,x2):\n\n    x1_shape = tf.shape(x1)\n    x2_shape = tf.shape(x2)\n\n    x2_shape1 = x2.get_shape()\n    x1_shape1 = x1.get_shape()\n\n    # offsets for the top left corner of the crop\n    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n    print(\"offsets\",offsets)\n    print(\"x1\",x1)\n\n    #offsets = [0, (int(x1_shape1[1]) - int(x2_shape1[1])) // 2, (int(x1_shape1[2]) - int(x2_shape1[2])) // 2, 0]\n    size = [-1, int(x2_shape1[1]), int(x2_shape1[2]), -1]\n    print(\"size\",size)\n    #size = [-1, x2_shape[1], x2_shape[2], -1]\n    x1_crop = tf.slice(x1, offsets, size)\n    print(\"x1 crop\",x1_crop)\n    return tf.concat([x1_crop, x2], 3)\n\ndef build_model(x, keep_prob, batch_size):\n    print(x.get_shape())\n    conv1 = tf.layers.conv2d(\n        inputs= x,\n        filters=32,\n        kernel_size=(3,3),\n        padding='same',\n        activation = tf.nn.relu\n    )#256\n    print(\"conv1\", conv1)\n    conv1_2 = tf.layers.conv2d(\n        inputs=conv1,\n        filters=32,\n        kernel_size=(3,3),\n        padding='same',\n        activation=tf.nn.relu\n    )#252\n    print(\"conv1\", conv1_2)\n    pool1 = tf.layers.max_pooling2d(\n        inputs=conv1_2,\n        pool_size=(2,2),\n        padding='same',\n        strides = 2\n    )#126\n    print(\"pool1\", pool1)\n    conv2 = tf.layers.conv2d(\n        inputs=pool1,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )#124\n    print(\"conv2\", conv2.get_shape())\n    conv2 = tf.layers.conv2d(\n        inputs=conv2,\n        filters=64,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )#122\n    print(\"conv2\", conv2.get_shape())\n    pool2 = tf.layers.max_pooling2d(\n        inputs=conv2,\n        pool_size=2,\n        strides=2\n    )#61\n    print(\"pool2\", pool2.get_shape())\n    conv3 = tf.layers.conv2d(\n        inputs=pool2,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )#59\n    print(\"conv3\", conv3.get_shape())\n    conv3 = tf.layers.conv2d(\n        inputs=conv3,\n        filters=128,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )#57\n    print(\"conv3\", conv3.get_shape())\n    pool3 = tf.layers.max_pooling2d(\n        inputs=conv3,\n        pool_size=2,\n        strides=2\n    )\n    print(\"pool3\", pool3.get_shape())\n    conv4 = tf.layers.conv2d(\n        inputs=pool3,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv4\", conv4.get_shape())\n    conv4 = tf.layers.conv2d(\n        inputs=conv4,\n        filters=256,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )\n    print(\"conv4\", conv4.get_shape())\n    pool4 = tf.layers.max_pooling2d(\n        inputs=conv4,\n        pool_size=(2,2),\n        strides=2\n    )\n    print(\"pool4\", pool4.get_shape())\n\n    conv4_1 = tf.layers.conv2d(\n        inputs=pool4,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv41\", conv4_1.get_shape())\n    conv4_1 = tf.layers.conv2d(\n        inputs=conv4_1,\n        filters=512,\n        kernel_size=3,\n        activation=tf.nn.relu\n    )\n    print(\"conv41\", conv4_1.get_shape())\n    pool4_1 = tf.layers.max_pooling2d(\n        inputs=conv4_1,\n        pool_size=(2, 2),\n        strides=2\n    )\n    print(\"pool41\", pool4_1.get_shape())\n    conv5 = tf.layers.conv2d(\n        inputs=pool4_1,\n        filters=1024,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv5\", conv5.get_shape())\n    conv5 = tf.layers.conv2d(\n        inputs=conv5,\n        filters=1024,\n        kernel_size=(3,3),\n        activation=tf.nn.relu\n    )\n    print(\"conv5\", conv5.get_shape())\n\n    #up1_0 = layers.concatenate([layers.UpSampling2D(size=(2,2))(conv5),conv4_1])\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\n\n    print(\"up10\", up1_0.get_shape())\n    conv6 = tf.layers.conv2d(\n        inputs=up1_0,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv6\", conv6.get_shape())\n    conv6 = tf.layers.conv2d(\n        inputs=conv6,\n        filters=512,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv6\", conv6.get_shape())\n    #up1 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv6), conv4])\n    up1 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6), conv4)\n    print(\"up1\", up1.get_shape())\n    conv6_1 = tf.layers.conv2d(\n        inputs=up1,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv61\", conv6_1.get_shape())\n    conv6_1 = tf.layers.conv2d(\n        inputs=conv6_1,\n        filters=256,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv61\", conv6_1.get_shape())\n    #up2  = layers.concatenate([layers.UpSampling2D(size=2)(conv6_1),conv3])\n    up2 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6_1), conv3)\n    print(\"up2\", up2.get_shape())\n    conv7 = tf.layers.conv2d(\n        inputs=up2,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv7\", conv7.get_shape())\n    conv7 = tf.layers.conv2d(\n        inputs=conv7,\n        filters=128,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv7\", conv7.get_shape())\n    #up3 =  layers.concatenate([layers.UpSampling2D(size=2)(conv7),conv2])\n    up3 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv7), conv2)\n    print(\"up3\", up3.get_shape())\n    conv8 = tf.layers.conv2d(\n        inputs=up3,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv8\", conv8.get_shape())\n    conv8 = tf.layers.conv2d(\n        inputs=conv8,\n        filters=64,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv8\",conv8.get_shape())\n    #up4 = layers.concatenate([layers.UpSampling2D(size=2)(conv8), conv1])\n    up4 = crop_and_concat(layers.UpSampling2D(size=(4,4))(conv8), conv1)\n    print(\"up4\",up4.get_shape())\n    conv9 = tf.layers.conv2d(\n        inputs=up4,\n        filters=32,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv91\",conv9.get_shape())\n    conv9 = tf.layers.conv2d(\n        inputs=conv9,\n        filters=32,\n        kernel_size=(3, 3),\n        padding='same',\n        activation=tf.nn.relu\n    )\n    print(\"conv9\",conv9.get_shape())\n    conv10 = tf.layers.conv2d(\n        inputs=conv9,\n        filters=1,\n        kernel_size=1,\n        activation= tf.nn.sigmoid\n    )\n    print(\"conv10\",conv10.get_shape())\n    return conv10\n\ndef train(epochs, num_steps):\n    dir_images = \"Dataset/JPEGImages/480p\"\n    dir_annotations = \"Dataset/Annotations/480p\"\n\n    classes, classidx = find_classes(dir_images)\n    datas = make_dataset(dir_images, dir_annotations)\n    x = tf.placeholder(tf.float32, shape=[None, 256, 256, 3], name='X') #Need to define the shape of x\n    y = tf.placeholder(tf.float32, shape=[None, 256,256, 1], name='Y')\n    logits = build_model(x, 0.5, 128)\n    model = tf.identity(logits, name='logits')\n    Cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Cost)\n\n    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    init = tf.global_variables_initializer()\n    sess = tf.InteractiveSession()\n    # Initialize all variables\n    sess.run(init)\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        # variables need to be initialized before any sess.run() calls\n        tf.global_variables_initializer().run()\n\n        for X_batch, y_batch in generator(datas,32):\n            feed_dict = {x: X_batch, y: y_batch}\n            sess.run(optimizer, feed_dict)\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\nTensorFlow installed from (source or binary):Source\nTensorFlow version (use command below):1.2.1\nPython version:3.6.4\nBazel version (if compiling from source):NA\nGCC/Compiler version (if compiling from source):NA\nCUDA/cuDNN version:NA\nGPU model and memory:NA\n\nDescribe the current behavior Getting this error when I am tring to start the training in images.\nDescribe the expected behavior\nIt should start training\nCode to reproduce the issue\nGet Davis dataset and put it in respective folders", "body": "**Error**\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1139, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1121, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\r\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in <module>\r\n    train(epochs,num_steps)\r\n  File \"E:/VisionLearning/Segmentation/train.py\", line 47, in train\r\n    sess.run(optimizer, feed_dict)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected begin[1] in [0, 8], but got -2\r\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\r\n\r\nCaused by op 'Slice', defined at:\r\n  File \"E:/VisionLearning/Segmentation/train.py\", line 71, in <module>\r\n    train(epochs,num_steps)\r\n  File \"E:/VisionLearning/Segmentation/train.py\", line 28, in train\r\n    logits = build_model(x, 0.5, 128)\r\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 153, in build_model\r\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\r\n  File \"E:\\VisionLearning\\Segmentation\\Model.py\", line 22, in crop_and_concat\r\n    x1_crop = tf.slice(x1, offsets, size)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 547, in slice\r\n    return gen_array_ops._slice(input_, begin, size, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2896, in _slice\r\n    name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Expected begin[1] in [0, 8], but got -2\r\n\t [[Node: Slice = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](up_sampling2d/ResizeNearestNeighbor, Slice/begin, Slice/size)]]\r\n\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n\r\n```\r\ndef crop_and_concat(x1,x2):\r\n\r\n    x1_shape = tf.shape(x1)\r\n    x2_shape = tf.shape(x2)\r\n\r\n    x2_shape1 = x2.get_shape()\r\n    x1_shape1 = x1.get_shape()\r\n\r\n    # offsets for the top left corner of the crop\r\n    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\r\n    print(\"offsets\",offsets)\r\n    print(\"x1\",x1)\r\n\r\n    #offsets = [0, (int(x1_shape1[1]) - int(x2_shape1[1])) // 2, (int(x1_shape1[2]) - int(x2_shape1[2])) // 2, 0]\r\n    size = [-1, int(x2_shape1[1]), int(x2_shape1[2]), -1]\r\n    print(\"size\",size)\r\n    #size = [-1, x2_shape[1], x2_shape[2], -1]\r\n    x1_crop = tf.slice(x1, offsets, size)\r\n    print(\"x1 crop\",x1_crop)\r\n    return tf.concat([x1_crop, x2], 3)\r\n\r\ndef build_model(x, keep_prob, batch_size):\r\n    print(x.get_shape())\r\n    conv1 = tf.layers.conv2d(\r\n        inputs= x,\r\n        filters=32,\r\n        kernel_size=(3,3),\r\n        padding='same',\r\n        activation = tf.nn.relu\r\n    )#256\r\n    print(\"conv1\", conv1)\r\n    conv1_2 = tf.layers.conv2d(\r\n        inputs=conv1,\r\n        filters=32,\r\n        kernel_size=(3,3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )#252\r\n    print(\"conv1\", conv1_2)\r\n    pool1 = tf.layers.max_pooling2d(\r\n        inputs=conv1_2,\r\n        pool_size=(2,2),\r\n        padding='same',\r\n        strides = 2\r\n    )#126\r\n    print(\"pool1\", pool1)\r\n    conv2 = tf.layers.conv2d(\r\n        inputs=pool1,\r\n        filters=64,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )#124\r\n    print(\"conv2\", conv2.get_shape())\r\n    conv2 = tf.layers.conv2d(\r\n        inputs=conv2,\r\n        filters=64,\r\n        kernel_size=3,\r\n        activation=tf.nn.relu\r\n    )#122\r\n    print(\"conv2\", conv2.get_shape())\r\n    pool2 = tf.layers.max_pooling2d(\r\n        inputs=conv2,\r\n        pool_size=2,\r\n        strides=2\r\n    )#61\r\n    print(\"pool2\", pool2.get_shape())\r\n    conv3 = tf.layers.conv2d(\r\n        inputs=pool2,\r\n        filters=128,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )#59\r\n    print(\"conv3\", conv3.get_shape())\r\n    conv3 = tf.layers.conv2d(\r\n        inputs=conv3,\r\n        filters=128,\r\n        kernel_size=3,\r\n        activation=tf.nn.relu\r\n    )#57\r\n    print(\"conv3\", conv3.get_shape())\r\n    pool3 = tf.layers.max_pooling2d(\r\n        inputs=conv3,\r\n        pool_size=2,\r\n        strides=2\r\n    )\r\n    print(\"pool3\", pool3.get_shape())\r\n    conv4 = tf.layers.conv2d(\r\n        inputs=pool3,\r\n        filters=256,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv4\", conv4.get_shape())\r\n    conv4 = tf.layers.conv2d(\r\n        inputs=conv4,\r\n        filters=256,\r\n        kernel_size=3,\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv4\", conv4.get_shape())\r\n    pool4 = tf.layers.max_pooling2d(\r\n        inputs=conv4,\r\n        pool_size=(2,2),\r\n        strides=2\r\n    )\r\n    print(\"pool4\", pool4.get_shape())\r\n\r\n    conv4_1 = tf.layers.conv2d(\r\n        inputs=pool4,\r\n        filters=512,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv41\", conv4_1.get_shape())\r\n    conv4_1 = tf.layers.conv2d(\r\n        inputs=conv4_1,\r\n        filters=512,\r\n        kernel_size=3,\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv41\", conv4_1.get_shape())\r\n    pool4_1 = tf.layers.max_pooling2d(\r\n        inputs=conv4_1,\r\n        pool_size=(2, 2),\r\n        strides=2\r\n    )\r\n    print(\"pool41\", pool4_1.get_shape())\r\n    conv5 = tf.layers.conv2d(\r\n        inputs=pool4_1,\r\n        filters=1024,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv5\", conv5.get_shape())\r\n    conv5 = tf.layers.conv2d(\r\n        inputs=conv5,\r\n        filters=1024,\r\n        kernel_size=(3,3),\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv5\", conv5.get_shape())\r\n\r\n    #up1_0 = layers.concatenate([layers.UpSampling2D(size=(2,2))(conv5),conv4_1])\r\n    up1_0 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv5), conv4_1)\r\n\r\n    print(\"up10\", up1_0.get_shape())\r\n    conv6 = tf.layers.conv2d(\r\n        inputs=up1_0,\r\n        filters=512,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv6\", conv6.get_shape())\r\n    conv6 = tf.layers.conv2d(\r\n        inputs=conv6,\r\n        filters=512,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv6\", conv6.get_shape())\r\n    #up1 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv6), conv4])\r\n    up1 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6), conv4)\r\n    print(\"up1\", up1.get_shape())\r\n    conv6_1 = tf.layers.conv2d(\r\n        inputs=up1,\r\n        filters=256,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv61\", conv6_1.get_shape())\r\n    conv6_1 = tf.layers.conv2d(\r\n        inputs=conv6_1,\r\n        filters=256,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv61\", conv6_1.get_shape())\r\n    #up2  = layers.concatenate([layers.UpSampling2D(size=2)(conv6_1),conv3])\r\n    up2 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv6_1), conv3)\r\n    print(\"up2\", up2.get_shape())\r\n    conv7 = tf.layers.conv2d(\r\n        inputs=up2,\r\n        filters=128,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv7\", conv7.get_shape())\r\n    conv7 = tf.layers.conv2d(\r\n        inputs=conv7,\r\n        filters=128,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv7\", conv7.get_shape())\r\n    #up3 =  layers.concatenate([layers.UpSampling2D(size=2)(conv7),conv2])\r\n    up3 = crop_and_concat(layers.UpSampling2D(size=(2,2))(conv7), conv2)\r\n    print(\"up3\", up3.get_shape())\r\n    conv8 = tf.layers.conv2d(\r\n        inputs=up3,\r\n        filters=64,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv8\", conv8.get_shape())\r\n    conv8 = tf.layers.conv2d(\r\n        inputs=conv8,\r\n        filters=64,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv8\",conv8.get_shape())\r\n    #up4 = layers.concatenate([layers.UpSampling2D(size=2)(conv8), conv1])\r\n    up4 = crop_and_concat(layers.UpSampling2D(size=(4,4))(conv8), conv1)\r\n    print(\"up4\",up4.get_shape())\r\n    conv9 = tf.layers.conv2d(\r\n        inputs=up4,\r\n        filters=32,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv91\",conv9.get_shape())\r\n    conv9 = tf.layers.conv2d(\r\n        inputs=conv9,\r\n        filters=32,\r\n        kernel_size=(3, 3),\r\n        padding='same',\r\n        activation=tf.nn.relu\r\n    )\r\n    print(\"conv9\",conv9.get_shape())\r\n    conv10 = tf.layers.conv2d(\r\n        inputs=conv9,\r\n        filters=1,\r\n        kernel_size=1,\r\n        activation= tf.nn.sigmoid\r\n    )\r\n    print(\"conv10\",conv10.get_shape())\r\n    return conv10\r\n```\r\n\r\n```\r\ndef train(epochs, num_steps):\r\n    dir_images = \"Dataset/JPEGImages/480p\"\r\n    dir_annotations = \"Dataset/Annotations/480p\"\r\n\r\n    classes, classidx = find_classes(dir_images)\r\n    datas = make_dataset(dir_images, dir_annotations)\r\n    x = tf.placeholder(tf.float32, shape=[None, 256, 256, 3], name='X') #Need to define the shape of x\r\n    y = tf.placeholder(tf.float32, shape=[None, 256,256, 1], name='Y')\r\n    logits = build_model(x, 0.5, 128)\r\n    model = tf.identity(logits, name='logits')\r\n    Cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Cost)\r\n\r\n    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\r\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n\r\n    init = tf.global_variables_initializer()\r\n    sess = tf.InteractiveSession()\r\n    # Initialize all variables\r\n    sess.run(init)\r\n    saver = tf.train.Saver()\r\n    with tf.Session() as sess:\r\n        # variables need to be initialized before any sess.run() calls\r\n        tf.global_variables_initializer().run()\r\n\r\n        for X_batch, y_batch in generator(datas,32):\r\n            feed_dict = {x: X_batch, y: y_batch}\r\n            sess.run(optimizer, feed_dict)\r\n```\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\r\n- TensorFlow installed from (source or binary):Source\r\n- TensorFlow version (use command below):1.2.1\r\n- Python version:3.6.4\r\n- Bazel version (if compiling from source):NA\r\n- GCC/Compiler version (if compiling from source):NA\r\n- CUDA/cuDNN version:NA\r\n- GPU model and memory:NA\r\n\r\n\r\n**Describe the current behavior** Getting this error when I am tring to start the training in images.\r\n\r\n**Describe the expected behavior**\r\nIt should start training\r\n**Code to reproduce the issue**\r\nGet Davis dataset and put it in respective folders\r\n\r\n"}