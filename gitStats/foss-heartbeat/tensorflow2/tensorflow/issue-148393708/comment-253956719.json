{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253956719", "html_url": "https://github.com/tensorflow/tensorflow/issues/1947#issuecomment-253956719", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1947", "id": 253956719, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Mzk1NjcxOQ==", "user": {"login": "dojoteef", "id": 1501173, "node_id": "MDQ6VXNlcjE1MDExNzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1501173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dojoteef", "html_url": "https://github.com/dojoteef", "followers_url": "https://api.github.com/users/dojoteef/followers", "following_url": "https://api.github.com/users/dojoteef/following{/other_user}", "gists_url": "https://api.github.com/users/dojoteef/gists{/gist_id}", "starred_url": "https://api.github.com/users/dojoteef/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dojoteef/subscriptions", "organizations_url": "https://api.github.com/users/dojoteef/orgs", "repos_url": "https://api.github.com/users/dojoteef/repos", "events_url": "https://api.github.com/users/dojoteef/events{/privacy}", "received_events_url": "https://api.github.com/users/dojoteef/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-15T02:18:14Z", "updated_at": "2016-10-15T02:18:14Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3979096\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benbarsdell\">@benbarsdell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> I am running into a similar problem.</p>\n<p>My configuration is:</p>\n<ul>\n<li>Ubuntu 16.04.1 TLS</li>\n<li>Two Nvidia Titan X (Pascal) GPUs</li>\n<li>Nvidia driver 367.57</li>\n<li>Cuda 8.0.44</li>\n<li>Cudnn 5.1.5</li>\n</ul>\n<p>I have previously tried with:</p>\n<ul>\n<li>Nvidia driver 367.44</li>\n<li>Cuda 8.0.27 (and 8.0.27.1 patch)</li>\n</ul>\n<p>I have built tensorflow from source. Here are the scripts I used to <a href=\"https://github.com/dojoteef/dotfiles/blob/a7d2321/bin/configure_tensorflow\">configure</a> and [install](<a href=\"https://github.com/dojoteef/dotfil\">https://github.com/dojoteef/dotfil</a><br>\nes/blob/a7d2321/bin/install_tensorflow) tensorflow. The output of <code>__git_version__</code> is below:</p>\n<pre><code>python -c 'import tensorflow as tf; print(tf.__git_version__)'\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\nv0.11.0rc0-787-gf6e0f64\n</code></pre>\n<p>Here are a few pastebins of bins of gdb output when the threads are stalled when running <code>cifar_multi_gpu_train.py --num_gpus=2</code>:</p>\n<ul>\n<li>Hang after 3410 steps: <a href=\"http://pastebin.com/NrTwaeH2\" rel=\"nofollow\">dump1</a>, <a href=\"http://pastebin.com/CC1EeukU\" rel=\"nofollow\">dump2</a> (after waiting a bit)</li>\n<li>Hang after 2910 steps: <a href=\"http://pastebin.com/q9SfYGUr\" rel=\"nofollow\">dump3</a></li>\n</ul>\n<p>I also received a core dump running <code>cifar_train.py</code> (I didn't attach the core dump as it's nearly 300MB, though I can if it would be helpful):</p>\n<pre><code>...\n2016-10-14 19:09:01.337748: step 1490, loss = 2.06 (1690.8 examples/sec; 0.076 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n</code></pre>\n<p>I am not sure if the issues are related or not, but it seems likely that they are.</p>\n<p>If there is anything you need me to do in order to help figure out/address the issues I am happy to. Not being able to use my GPUs is unfortunately really slowing down my ability to make progress. Thanks!</p>", "body_text": "@benbarsdell @zheng-xq I am running into a similar problem.\nMy configuration is:\n\nUbuntu 16.04.1 TLS\nTwo Nvidia Titan X (Pascal) GPUs\nNvidia driver 367.57\nCuda 8.0.44\nCudnn 5.1.5\n\nI have previously tried with:\n\nNvidia driver 367.44\nCuda 8.0.27 (and 8.0.27.1 patch)\n\nI have built tensorflow from source. Here are the scripts I used to configure and [install](https://github.com/dojoteef/dotfil\nes/blob/a7d2321/bin/install_tensorflow) tensorflow. The output of __git_version__ is below:\npython -c 'import tensorflow as tf; print(tf.__git_version__)'\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\nv0.11.0rc0-787-gf6e0f64\n\nHere are a few pastebins of bins of gdb output when the threads are stalled when running cifar_multi_gpu_train.py --num_gpus=2:\n\nHang after 3410 steps: dump1, dump2 (after waiting a bit)\nHang after 2910 steps: dump3\n\nI also received a core dump running cifar_train.py (I didn't attach the core dump as it's nearly 300MB, though I can if it would be helpful):\n...\n2016-10-14 19:09:01.337748: step 1490, loss = 2.06 (1690.8 examples/sec; 0.076 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n\nI am not sure if the issues are related or not, but it seems likely that they are.\nIf there is anything you need me to do in order to help figure out/address the issues I am happy to. Not being able to use my GPUs is unfortunately really slowing down my ability to make progress. Thanks!", "body": "@benbarsdell @zheng-xq I am running into a similar problem.\n\nMy configuration is:\n- Ubuntu 16.04.1 TLS\n- Two Nvidia Titan X (Pascal) GPUs\n- Nvidia driver 367.57\n- Cuda 8.0.44\n- Cudnn 5.1.5\n\nI have previously tried with:\n- Nvidia driver 367.44\n- Cuda 8.0.27 (and 8.0.27.1 patch)\n\nI have built tensorflow from source. Here are the scripts I used to [configure](https://github.com/dojoteef/dotfiles/blob/a7d2321/bin/configure_tensorflow) and [install](https://github.com/dojoteef/dotfil\nes/blob/a7d2321/bin/install_tensorflow) tensorflow. The output of `__git_version__` is below:\n\n```\npython -c 'import tensorflow as tf; print(tf.__git_version__)'\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\nv0.11.0rc0-787-gf6e0f64\n```\n\nHere are a few pastebins of bins of gdb output when the threads are stalled when running `cifar_multi_gpu_train.py --num_gpus=2`:\n- Hang after 3410 steps: [dump1](http://pastebin.com/NrTwaeH2), [dump2](http://pastebin.com/CC1EeukU) (after waiting a bit)\n- Hang after 2910 steps: [dump3](http://pastebin.com/q9SfYGUr)\n\nI also received a core dump running `cifar_train.py` (I didn't attach the core dump as it's nearly 300MB, though I can if it would be helpful):\n\n```\n...\n2016-10-14 19:09:01.337748: step 1490, loss = 2.06 (1690.8 examples/sec; 0.076 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n```\n\nI am not sure if the issues are related or not, but it seems likely that they are.\n\nIf there is anything you need me to do in order to help figure out/address the issues I am happy to. Not being able to use my GPUs is unfortunately really slowing down my ability to make progress. Thanks!\n"}