{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233424698", "html_url": "https://github.com/tensorflow/tensorflow/issues/1947#issuecomment-233424698", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1947", "id": 233424698, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzQyNDY5OA==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-18T18:59:18Z", "updated_at": "2016-07-18T18:59:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5978929\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ChrisHowlin\">@ChrisHowlin</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19681682\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dipanjan06\">@dipanjan06</a>, thanks for the stack traces, they are very useful. I suspect this is a bug from the Cuda driver.</p>\n<ol>\n<li>What are the Cuda driver version shown in your nvidia-smi?</li>\n<li>Could you upgrade to the latest Cuda driver and see if the problem goes away.</li>\n</ol>\n<p>Details:</p>\n<p>I found that at both stack traces, two Cuda calls are still active, while all other threads are effectively sleeping. The first one is when a new thread is starting. And the second is a thread is allocating some memory. In one case it is a Cuda device memory, and in another case it is a Cuda host memory. And it seems that those two calls are deadlocking with each other. So the problem might be with the Cuda driver. Please try with the latest driver. Also I'll add the NVIDIA team to this discussion.</p>\n<p>Thread 14 (Thread 0x7ff6ea7fc700 (LWP 6730)):<br>\n#0  0x00007ff763a89fdd in poll () at ../sysdeps/unix/syscall-template.S:81<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a>  0x00007ff749ecac1b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115898449\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4\">#4</a>  0x00007ff764477184 in start_thread (arg=0x7ff6ea7fc700) at pthread_create.c:312<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115910900\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5\">#5</a>  0x00007ff763a9737d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111</p>\n<p>Thread 1 (Thread 0x7ff764d4a740 (LWP 6687)):<br>\n#0  0x00007ff763a8e1e7 in ioctl () at ../sysdeps/unix/syscall-template.S:81<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a>  0x00007ff7497aedea in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115918299\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/13/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/13\">#13</a> 0x00007ff74978fa6d in cuMemAlloc_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115918464\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/14\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/14/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/14\">#14</a> 0x00007ff75858f711 in perftools::gputools::cuda::CUDADriver::DeviceAllocate(perftools::gputools::cuda::CudaContext*, unsigned long long) ()<br>\nfrom /home/ubuntu/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so</p>", "body_text": "@ChrisHowlin, @dipanjan06, thanks for the stack traces, they are very useful. I suspect this is a bug from the Cuda driver.\n\nWhat are the Cuda driver version shown in your nvidia-smi?\nCould you upgrade to the latest Cuda driver and see if the problem goes away.\n\nDetails:\nI found that at both stack traces, two Cuda calls are still active, while all other threads are effectively sleeping. The first one is when a new thread is starting. And the second is a thread is allocating some memory. In one case it is a Cuda device memory, and in another case it is a Cuda host memory. And it seems that those two calls are deadlocking with each other. So the problem might be with the Cuda driver. Please try with the latest driver. Also I'll add the NVIDIA team to this discussion.\nThread 14 (Thread 0x7ff6ea7fc700 (LWP 6730)):\n#0  0x00007ff763a89fdd in poll () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff749ecac1b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#4  0x00007ff764477184 in start_thread (arg=0x7ff6ea7fc700) at pthread_create.c:312\n#5  0x00007ff763a9737d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\nThread 1 (Thread 0x7ff764d4a740 (LWP 6687)):\n#0  0x00007ff763a8e1e7 in ioctl () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff7497aedea in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#13 0x00007ff74978fa6d in cuMemAlloc_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#14 0x00007ff75858f711 in perftools::gputools::cuda::CUDADriver::DeviceAllocate(perftools::gputools::cuda::CudaContext*, unsigned long long) ()\nfrom /home/ubuntu/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so", "body": "@ChrisHowlin, @dipanjan06, thanks for the stack traces, they are very useful. I suspect this is a bug from the Cuda driver. \n1. What are the Cuda driver version shown in your nvidia-smi? \n2. Could you upgrade to the latest Cuda driver and see if the problem goes away. \n\nDetails: \n\nI found that at both stack traces, two Cuda calls are still active, while all other threads are effectively sleeping. The first one is when a new thread is starting. And the second is a thread is allocating some memory. In one case it is a Cuda device memory, and in another case it is a Cuda host memory. And it seems that those two calls are deadlocking with each other. So the problem might be with the Cuda driver. Please try with the latest driver. Also I'll add the NVIDIA team to this discussion. \n\nThread 14 (Thread 0x7ff6ea7fc700 (LWP 6730)):\n#0  0x00007ff763a89fdd in poll () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff749ecac1b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#4  0x00007ff764477184 in start_thread (arg=0x7ff6ea7fc700) at pthread_create.c:312\n#5  0x00007ff763a9737d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n\nThread 1 (Thread 0x7ff764d4a740 (LWP 6687)):\n#0  0x00007ff763a8e1e7 in ioctl () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff7497aedea in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#13 0x00007ff74978fa6d in cuMemAlloc_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#14 0x00007ff75858f711 in perftools::gputools::cuda::CUDADriver::DeviceAllocate(perftools::gputools::cuda::CudaContext*, unsigned long long) ()\n   from /home/ubuntu/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so\n"}