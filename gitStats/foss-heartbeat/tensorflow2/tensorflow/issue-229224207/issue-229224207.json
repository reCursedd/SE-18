{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9952", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9952/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9952/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9952/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9952", "id": 229224207, "node_id": "MDU6SXNzdWUyMjkyMjQyMDc=", "number": 9952, "title": "Error loading saved_model.pb from C++", "user": {"login": "lirchi", "id": 4840577, "node_id": "MDQ6VXNlcjQ4NDA1Nzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/4840577?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lirchi", "html_url": "https://github.com/lirchi", "followers_url": "https://api.github.com/users/lirchi/followers", "following_url": "https://api.github.com/users/lirchi/following{/other_user}", "gists_url": "https://api.github.com/users/lirchi/gists{/gist_id}", "starred_url": "https://api.github.com/users/lirchi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lirchi/subscriptions", "organizations_url": "https://api.github.com/users/lirchi/orgs", "repos_url": "https://api.github.com/users/lirchi/repos", "events_url": "https://api.github.com/users/lirchi/events{/privacy}", "received_events_url": "https://api.github.com/users/lirchi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-05-17T02:58:13Z", "updated_at": "2018-03-23T09:04:19Z", "closed_at": "2017-05-17T16:48:34Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes (minor changes), see below.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 17.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.4.5</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I use the high level API to train an estimator (specifically, <code>tf.contrib.learn.DNNRegressor</code>) in Python. I then use <code>export_savedmodel</code> to save it to protobuf. When I try to load it from C++ I get:<br>\n<code>Data loss: Can't parse saved_model.pb as binary proto</code>.</p>\n<h3>Source code / logs</h3>\n<ul>\n<li>Python file</li>\n</ul>\n<pre><code>import numpy as np\nimport pandas as pd\nimport sys\nimport pickle\nimport tensorflow as tf\nimport random, os, shutil\nfrom tensorflow.contrib.layers import create_feature_spec_for_parsing\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n\ntf.logging.set_verbosity(tf.logging.INFO)\ntrain_filename = sys.argv[1]\ntest_filename = sys.argv[2]\nsaved_model_directory = sys.argv[3]\n\nCOLUMNS = [\"X1\", \"Y1\", \"X2\", \"Y2\", \"SP\"]\nFEATURES = [\"X1\", \"Y1\", \"X2\", \"Y2\"]\nTARGET = \"SP\"\ntraining_set = pd.read_csv(train_filename, skipinitialspace=True, names=COLUMNS)\ntest_set = pd.read_csv(test_filename, skipinitialspace=True, names=COLUMNS)\n\ndef input_fn(data_set):\n    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n    targets = tf.constant(data_set[TARGET].values)\n    return feature_cols, targets\n\nfeature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\nfeature_spec = create_feature_spec_for_parsing(feature_cols)\nserving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n    input_fn=lambda: input_fn(test_set),\n    eval_steps=1,\n    every_n_steps=100)\n\nestimator = tf.contrib.learn.DNNRegressor(\n    feature_columns=feature_cols,\n    hidden_units=[50, 25, 5],\n    model_dir=saved_model_directory,\n    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n\nestimator.fit(input_fn=lambda: input_fn(training_set), steps=100, monitors=[validation_monitor])\n\nestimator.export_savedmodel(export_dir_base=saved_model_directory,\n    serving_input_fn = serving_input_fn)\n\n</code></pre>\n<ul>\n<li>CPP file</li>\n</ul>\n<pre><code>#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/platform/env.h\"\n\nusing namespace tensorflow;\nusing std::cout;\nusing std::vector;\nusing std::pair;\n\nint main(int argc, char* argv[]) {\n  // Initialize a tensorflow session\n  Session* session;\n  Status status = NewSession(SessionOptions(), &amp;session);\n  if (!status.ok()) {\n    cout &lt;&lt; status.ToString() &lt;&lt; \"\\n\";\n    return 1;\n  }\n\n  // Read in the protobuf graph we exported\n  // (The path seems to be relative to the cwd. Keep this in mind\n  // when using `bazel run` since the cwd isn't where you call\n  // `bazel run` but from inside a temp folder.)\n  cout &lt;&lt; \"READING MODEL.\\n\";\n  GraphDef graph_def;\n  status = ReadBinaryProto(Env::Default(), \"saved_model.pb\", &amp;graph_def);\n  if (!status.ok()) {\n    cout &lt;&lt; status.ToString() &lt;&lt; \"\\n\";\n    return 1;\n  }\n  cout &lt;&lt; \"DONE reading model.\\n\";\n}\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes (minor changes), see below.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 17.04\nTensorFlow installed from (source or binary):\nbinary\nTensorFlow version (use command below):\n1.1.0\nBazel version (if compiling from source):\n0.4.5\n\nDescribe the problem\nI use the high level API to train an estimator (specifically, tf.contrib.learn.DNNRegressor) in Python. I then use export_savedmodel to save it to protobuf. When I try to load it from C++ I get:\nData loss: Can't parse saved_model.pb as binary proto.\nSource code / logs\n\nPython file\n\nimport numpy as np\nimport pandas as pd\nimport sys\nimport pickle\nimport tensorflow as tf\nimport random, os, shutil\nfrom tensorflow.contrib.layers import create_feature_spec_for_parsing\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n\ntf.logging.set_verbosity(tf.logging.INFO)\ntrain_filename = sys.argv[1]\ntest_filename = sys.argv[2]\nsaved_model_directory = sys.argv[3]\n\nCOLUMNS = [\"X1\", \"Y1\", \"X2\", \"Y2\", \"SP\"]\nFEATURES = [\"X1\", \"Y1\", \"X2\", \"Y2\"]\nTARGET = \"SP\"\ntraining_set = pd.read_csv(train_filename, skipinitialspace=True, names=COLUMNS)\ntest_set = pd.read_csv(test_filename, skipinitialspace=True, names=COLUMNS)\n\ndef input_fn(data_set):\n    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n    targets = tf.constant(data_set[TARGET].values)\n    return feature_cols, targets\n\nfeature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\nfeature_spec = create_feature_spec_for_parsing(feature_cols)\nserving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n    input_fn=lambda: input_fn(test_set),\n    eval_steps=1,\n    every_n_steps=100)\n\nestimator = tf.contrib.learn.DNNRegressor(\n    feature_columns=feature_cols,\n    hidden_units=[50, 25, 5],\n    model_dir=saved_model_directory,\n    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n\nestimator.fit(input_fn=lambda: input_fn(training_set), steps=100, monitors=[validation_monitor])\n\nestimator.export_savedmodel(export_dir_base=saved_model_directory,\n    serving_input_fn = serving_input_fn)\n\n\n\nCPP file\n\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/platform/env.h\"\n\nusing namespace tensorflow;\nusing std::cout;\nusing std::vector;\nusing std::pair;\n\nint main(int argc, char* argv[]) {\n  // Initialize a tensorflow session\n  Session* session;\n  Status status = NewSession(SessionOptions(), &session);\n  if (!status.ok()) {\n    cout << status.ToString() << \"\\n\";\n    return 1;\n  }\n\n  // Read in the protobuf graph we exported\n  // (The path seems to be relative to the cwd. Keep this in mind\n  // when using `bazel run` since the cwd isn't where you call\n  // `bazel run` but from inside a temp folder.)\n  cout << \"READING MODEL.\\n\";\n  GraphDef graph_def;\n  status = ReadBinaryProto(Env::Default(), \"saved_model.pb\", &graph_def);\n  if (!status.ok()) {\n    cout << status.ToString() << \"\\n\";\n    return 1;\n  }\n  cout << \"DONE reading model.\\n\";\n}", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes (minor changes), see below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.1.0\r\n- **Bazel version (if compiling from source)**:\r\n0.4.5\r\n\r\n### Describe the problem\r\nI use the high level API to train an estimator (specifically, `tf.contrib.learn.DNNRegressor`) in Python. I then use `export_savedmodel` to save it to protobuf. When I try to load it from C++ I get:\r\n`Data loss: Can't parse saved_model.pb as binary proto`.\r\n\r\n### Source code / logs\r\n- Python file\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport sys\r\nimport pickle\r\nimport tensorflow as tf\r\nimport random, os, shutil\r\nfrom tensorflow.contrib.layers import create_feature_spec_for_parsing\r\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\ntrain_filename = sys.argv[1]\r\ntest_filename = sys.argv[2]\r\nsaved_model_directory = sys.argv[3]\r\n\r\nCOLUMNS = [\"X1\", \"Y1\", \"X2\", \"Y2\", \"SP\"]\r\nFEATURES = [\"X1\", \"Y1\", \"X2\", \"Y2\"]\r\nTARGET = \"SP\"\r\ntraining_set = pd.read_csv(train_filename, skipinitialspace=True, names=COLUMNS)\r\ntest_set = pd.read_csv(test_filename, skipinitialspace=True, names=COLUMNS)\r\n\r\ndef input_fn(data_set):\r\n    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\r\n    targets = tf.constant(data_set[TARGET].values)\r\n    return feature_cols, targets\r\n\r\nfeature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\r\nfeature_spec = create_feature_spec_for_parsing(feature_cols)\r\nserving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\r\n\r\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\r\n    input_fn=lambda: input_fn(test_set),\r\n    eval_steps=1,\r\n    every_n_steps=100)\r\n\r\nestimator = tf.contrib.learn.DNNRegressor(\r\n    feature_columns=feature_cols,\r\n    hidden_units=[50, 25, 5],\r\n    model_dir=saved_model_directory,\r\n    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\r\n\r\nestimator.fit(input_fn=lambda: input_fn(training_set), steps=100, monitors=[validation_monitor])\r\n\r\nestimator.export_savedmodel(export_dir_base=saved_model_directory,\r\n    serving_input_fn = serving_input_fn)\r\n\r\n```\r\n\r\n- CPP file\r\n```\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n\r\nusing namespace tensorflow;\r\nusing std::cout;\r\nusing std::vector;\r\nusing std::pair;\r\n\r\nint main(int argc, char* argv[]) {\r\n  // Initialize a tensorflow session\r\n  Session* session;\r\n  Status status = NewSession(SessionOptions(), &session);\r\n  if (!status.ok()) {\r\n    cout << status.ToString() << \"\\n\";\r\n    return 1;\r\n  }\r\n\r\n  // Read in the protobuf graph we exported\r\n  // (The path seems to be relative to the cwd. Keep this in mind\r\n  // when using `bazel run` since the cwd isn't where you call\r\n  // `bazel run` but from inside a temp folder.)\r\n  cout << \"READING MODEL.\\n\";\r\n  GraphDef graph_def;\r\n  status = ReadBinaryProto(Env::Default(), \"saved_model.pb\", &graph_def);\r\n  if (!status.ok()) {\r\n    cout << status.ToString() << \"\\n\";\r\n    return 1;\r\n  }\r\n  cout << \"DONE reading model.\\n\";\r\n}\r\n```"}