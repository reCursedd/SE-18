{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/431673223", "html_url": "https://github.com/tensorflow/tensorflow/issues/23133#issuecomment-431673223", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23133", "id": 431673223, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTY3MzIyMw==", "user": {"login": "imranparuk", "id": 10554727, "node_id": "MDQ6VXNlcjEwNTU0NzI3", "avatar_url": "https://avatars3.githubusercontent.com/u/10554727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/imranparuk", "html_url": "https://github.com/imranparuk", "followers_url": "https://api.github.com/users/imranparuk/followers", "following_url": "https://api.github.com/users/imranparuk/following{/other_user}", "gists_url": "https://api.github.com/users/imranparuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/imranparuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/imranparuk/subscriptions", "organizations_url": "https://api.github.com/users/imranparuk/orgs", "repos_url": "https://api.github.com/users/imranparuk/repos", "events_url": "https://api.github.com/users/imranparuk/events{/privacy}", "received_events_url": "https://api.github.com/users/imranparuk/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-21T14:24:41Z", "updated_at": "2018-10-21T14:24:41Z", "author_association": "NONE", "body_html": "<p>It looks quite similar, however that approch uses a soft-max on layer output merge. In the Siamese paper I read they use euclidean distance, I have this function from the Keras Siamese example code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">euclidean_distance</span>(<span class=\"pl-smi\">vects</span>):\n    x, y <span class=\"pl-k\">=</span> vects\n    sum_square <span class=\"pl-k\">=</span> K.sum(K.square(x <span class=\"pl-k\">-</span> y), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keepdims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    <span class=\"pl-k\">return</span> K.sqrt(K.maximum(sum_square, K.epsilon()))</pre></div>", "body_text": "It looks quite similar, however that approch uses a soft-max on layer output merge. In the Siamese paper I read they use euclidean distance, I have this function from the Keras Siamese example code:\ndef euclidean_distance(vects):\n    x, y = vects\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))", "body": "It looks quite similar, however that approch uses a soft-max on layer output merge. In the Siamese paper I read they use euclidean distance, I have this function from the Keras Siamese example code:\r\n\r\n```python\r\ndef euclidean_distance(vects):\r\n    x, y = vects\r\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\r\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\r\n```"}