{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/273846477", "html_url": "https://github.com/tensorflow/tensorflow/issues/6954#issuecomment-273846477", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6954", "id": 273846477, "node_id": "MDEyOklzc3VlQ29tbWVudDI3Mzg0NjQ3Nw==", "user": {"login": "civilman628", "id": 8059551, "node_id": "MDQ6VXNlcjgwNTk1NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8059551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/civilman628", "html_url": "https://github.com/civilman628", "followers_url": "https://api.github.com/users/civilman628/followers", "following_url": "https://api.github.com/users/civilman628/following{/other_user}", "gists_url": "https://api.github.com/users/civilman628/gists{/gist_id}", "starred_url": "https://api.github.com/users/civilman628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/civilman628/subscriptions", "organizations_url": "https://api.github.com/users/civilman628/orgs", "repos_url": "https://api.github.com/users/civilman628/repos", "events_url": "https://api.github.com/users/civilman628/events{/privacy}", "received_events_url": "https://api.github.com/users/civilman628/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-19T17:46:37Z", "updated_at": "2017-01-19T17:47:24Z", "author_association": "NONE", "body_html": "<p>While .py is different from .pbtxt. These pre-trained models use Imagenet dataset, which has 1000 classes and 1.2 Million images and more than 100+GB in size.</p>\n<p>If I want ONLY want to get .pbtxt file for each model ( since .ckpt file is already there),  I need download that 1.2 million images and create data records to train at my local machine?</p>\n<p>To get a text graph define .pbtxt file for the model need to download 100+GB file?</p>\n<p>No one find this issue before?</p>", "body_text": "While .py is different from .pbtxt. These pre-trained models use Imagenet dataset, which has 1000 classes and 1.2 Million images and more than 100+GB in size.\nIf I want ONLY want to get .pbtxt file for each model ( since .ckpt file is already there),  I need download that 1.2 million images and create data records to train at my local machine?\nTo get a text graph define .pbtxt file for the model need to download 100+GB file?\nNo one find this issue before?", "body": "While .py is different from .pbtxt. These pre-trained models use Imagenet dataset, which has 1000 classes and 1.2 Million images and more than 100+GB in size.\r\n\r\nIf I want ONLY want to get .pbtxt file for each model ( since .ckpt file is already there),  I need download that 1.2 million images and create data records to train at my local machine? \r\n\r\nTo get a text graph define .pbtxt file for the model need to download 100+GB file?\r\n\r\nNo one find this issue before?"}