{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/117055342", "pull_request_review_id": 38726834, "id": 117055342, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNzA1NTM0Mg==", "diff_hunk": "@@ -0,0 +1,94 @@\n+## How to compile and use MPI-enabled TensorFlow\n+\n+1. Follow the regular TF compilation instructions. During configure step, if you want MPI support, answer yes to this question:\n+\n+    ```Do you wish to build TensorFlow with MPI support [y/N]```\n+\n+2. To turn on the MPI connection, add the protocol \"grpc+mpi\" in the server definition:\n+\n+    ```server = tf.train.Server(cluster, job_name=\"local\", task_index=0, protocol='grpc+mpi') # default protocol is 'grpc'```\n+\n+## Overview\n+\n+By using this protocol the TensorFlow can take advantage of the high performance networking primitives that are offered via the MPI API. This enables TensorFlow to take advantage of high performance low latency networks such as Infiniband. These changes are largely transparent to the user who only has to change the offered protocol and launch the script using the 'mpirun'  launcher. For example:\n+    ```mpirun -np 2 python my_neuralnet.py ```\n+\n+\n+\n+\n+\n+## Runtime options\n+\n+The following environment variables can be set to modify the behavior at runtime:\n+\n+**MPI_DISABLED=[0,1]**\n+\n+This environment variable allows you to disable the MPI path before launch (e.g. for performance or correctness testing). \n+\n+**MPI_OPTIMAL_PATH=[0,1]**\n+\n+When set to 0 it will use the default path where tensors are encoded to ProtoText before being copied to a remote process. When set to 1 a more optimal path will be taken where only the tensor description is encoded while the actual tensor data is transferred directly from the source buffer to the destination buffer.\n+This path is disabled by default as it requires that MPI library can directly access the pointer to the data. For CPU backed buffers this is no problem, however for GPU backed buffers this requires MPI libraries that are built with CUDA support (CUDA Aware). When using non-CUDA aware MPI libraries and GPU buffers you will get segmentation faults.", "path": "tensorflow/contrib/mpi/README.md", "position": null, "original_position": 31, "commit_id": "047546d6fee2549c5963a338cdcc2ac801097d76", "original_commit_id": "b78b5414b8ef61d41bb2bd65bd4618c3555dbf15", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "body": "s/that MPI library/that the MPI library/", "created_at": "2017-05-17T16:51:35Z", "updated_at": "2017-05-24T08:41:03Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9864#discussion_r117055342", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9864", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/117055342"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9864#discussion_r117055342"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9864"}}, "body_html": "<p>s/that MPI library/that the MPI library/</p>", "body_text": "s/that MPI library/that the MPI library/"}