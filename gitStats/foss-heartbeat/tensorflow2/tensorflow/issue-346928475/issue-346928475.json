{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21334", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21334/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21334/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21334/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21334", "id": 346928475, "node_id": "MDU6SXNzdWUzNDY5Mjg0NzU=", "number": 21334, "title": "\"could not initialize a memory descriptor\" error using tensorflow on windows using CMake", "user": {"login": "syagev", "id": 5247438, "node_id": "MDQ6VXNlcjUyNDc0Mzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5247438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syagev", "html_url": "https://github.com/syagev", "followers_url": "https://api.github.com/users/syagev/followers", "following_url": "https://api.github.com/users/syagev/following{/other_user}", "gists_url": "https://api.github.com/users/syagev/gists{/gist_id}", "starred_url": "https://api.github.com/users/syagev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syagev/subscriptions", "organizations_url": "https://api.github.com/users/syagev/orgs", "repos_url": "https://api.github.com/users/syagev/repos", "events_url": "https://api.github.com/users/syagev/events{/privacy}", "received_events_url": "https://api.github.com/users/syagev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-08-02T09:20:09Z", "updated_at": "2018-11-21T19:00:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: NO</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10 (build 17134)</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.15</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: CMake &gt; VS 2017</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: <code>Session::run()</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I've built tensorflow (r1.9, using the CMake tools) linked with MKL (v2018 U3) and mkl-dnn (v0.15). I'm running windows 10 (build 17134) on an Intel Core i7-7820HQ CPU.</p>\n<p>I've built mkl-dnn from source and it's test are passing. However, a C++ project that loads a pre-trained tensorflow graph and passes an image for inference gives the following error when calling <code>Session::run(...)</code> :</p>\n<pre><code>W d:\\dev\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at mkl_conv_ops.cc:888 : Aborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\nAborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\n         [[Node: conv1/BiasAdd = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_pad/Pad, conv1/kernel, conv1/bias, DMT/_0, DMT/_1, DMT/_2)]]\n</code></pre>\n<p>The same code (with the same pre-trained model) does work on a linux machine (Intel(R) Xeon(R) CPU E5-2673 v3, running on Microsoft Azure), also with TF built with mkl-dnn.</p>\n<h3>Source code / logs</h3>\n<p>Install MKL 2018 U3 and build MKL-DNN v0.15 from source.</p>\n<p>Build TF r1.9 with the following flags:</p>\n<pre><code>tensorflow_BUILD_ALL_KERNERS=ON\ntensorflow_BUILD_CONTRIB_KERNELS=ON\ntensorflow_BUILD_SHARED_LIB=ON\ntensorflow_ENABLE_GPU=OFF\ntensorflow_ENABLE_GRPC_SUPPORT=ON\ntensorflow_ENABLE_JEMALLOC_SUPPORT=OFF\ntensorflow_ENABLE_MKLDNN_SUPPORT=ON\ntensorflow_ENABLE_MKL_SUPPORT=ON\ntensorflow_ENABLE_POSITION_INDEPENDENT_CODE=ON\ntensorflow_ENABLE_SNAPPY_SUPPORT=ON\ntensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON\ntensorflow_WIN_CPU_SIMD_OPTIONS=ON\n</code></pre>\n<p>Build passes and generates <code>tensorflow.dll</code>. Use keras to save a pre-trained Resnet50 model and attempt inference from C++ (linked with <code>tensorflow.dll</code>) as follows:</p>\n<pre><code>Session* session;\nStatus status = NewSession(SessionOptions(), &amp;session);\n\nGraphDef graph_def;\nstatus = ReadBinaryProto(Env::Default(), \"../graph/resnet50.pb\", &amp;graph_def);\nstatus = session-&gt;Create(graph_def);\n\nMat img = imread(\"../elephant.png\"), imgFloat, imgResized;\nimg.convertTo(imgFloat, CV_32FC3);\n\nTensor tInput(DT_FLOAT, TensorShape({ 1, 224, 224, 3 }));\nauto input_tensor_mapped = tInput.tensor&lt;float, 4&gt;();\n\nMat imgTensor(224, 224, CV_32FC3);\nresize(imgFloat, imgTensor, Size(224, 224));\nimgTensor -= Scalar(103.939, 116.779, 123.68);\n\t\nauto source_data = imgTensor.ptr&lt;float&gt;(0);\nint width = imgTensor.cols, height = imgTensor.rows, depth=3;\nfor (int y = 0; y &lt; height; ++y) {\n\tfor (int x = 0; x &lt; width; ++x) {\n\t\tfor (int c = 0; c &lt; depth; ++c) {\n\t\t\tconst float* source_value = source_data + (3*width*y) + (3*x) + (2-c);\n\t\t\tinput_tensor_mapped(0, y, x, c) = *source_value;\n\t\t}\n\t}\n}\n\nstd::vector&lt;std::pair&lt;string, tensorflow::Tensor&gt;&gt; inputs = {\n\t{ \"input_1\", tInput },\n};\n\nstd::vector&lt;tensorflow::Tensor&gt; outputs;\nstatus = session-&gt;Run(inputs, { \"fc1000/Softmax\" }, {}, &amp;outputs);\nif (!status.ok()) {\n\tstd::cout &lt;&lt; status.ToString() &lt;&lt; \"\\n\";\n\treturn 1;\n}\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (build 17134)\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.9\nPython version: 3.6\nBazel version (if compiling from source): 0.15\nGCC/Compiler version (if compiling from source): CMake > VS 2017\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: Session::run()\n\nDescribe the problem\nI've built tensorflow (r1.9, using the CMake tools) linked with MKL (v2018 U3) and mkl-dnn (v0.15). I'm running windows 10 (build 17134) on an Intel Core i7-7820HQ CPU.\nI've built mkl-dnn from source and it's test are passing. However, a C++ project that loads a pre-trained tensorflow graph and passes an image for inference gives the following error when calling Session::run(...) :\nW d:\\dev\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at mkl_conv_ops.cc:888 : Aborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\nAborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\n         [[Node: conv1/BiasAdd = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_pad/Pad, conv1/kernel, conv1/bias, DMT/_0, DMT/_1, DMT/_2)]]\n\nThe same code (with the same pre-trained model) does work on a linux machine (Intel(R) Xeon(R) CPU E5-2673 v3, running on Microsoft Azure), also with TF built with mkl-dnn.\nSource code / logs\nInstall MKL 2018 U3 and build MKL-DNN v0.15 from source.\nBuild TF r1.9 with the following flags:\ntensorflow_BUILD_ALL_KERNERS=ON\ntensorflow_BUILD_CONTRIB_KERNELS=ON\ntensorflow_BUILD_SHARED_LIB=ON\ntensorflow_ENABLE_GPU=OFF\ntensorflow_ENABLE_GRPC_SUPPORT=ON\ntensorflow_ENABLE_JEMALLOC_SUPPORT=OFF\ntensorflow_ENABLE_MKLDNN_SUPPORT=ON\ntensorflow_ENABLE_MKL_SUPPORT=ON\ntensorflow_ENABLE_POSITION_INDEPENDENT_CODE=ON\ntensorflow_ENABLE_SNAPPY_SUPPORT=ON\ntensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON\ntensorflow_WIN_CPU_SIMD_OPTIONS=ON\n\nBuild passes and generates tensorflow.dll. Use keras to save a pre-trained Resnet50 model and attempt inference from C++ (linked with tensorflow.dll) as follows:\nSession* session;\nStatus status = NewSession(SessionOptions(), &session);\n\nGraphDef graph_def;\nstatus = ReadBinaryProto(Env::Default(), \"../graph/resnet50.pb\", &graph_def);\nstatus = session->Create(graph_def);\n\nMat img = imread(\"../elephant.png\"), imgFloat, imgResized;\nimg.convertTo(imgFloat, CV_32FC3);\n\nTensor tInput(DT_FLOAT, TensorShape({ 1, 224, 224, 3 }));\nauto input_tensor_mapped = tInput.tensor<float, 4>();\n\nMat imgTensor(224, 224, CV_32FC3);\nresize(imgFloat, imgTensor, Size(224, 224));\nimgTensor -= Scalar(103.939, 116.779, 123.68);\n\t\nauto source_data = imgTensor.ptr<float>(0);\nint width = imgTensor.cols, height = imgTensor.rows, depth=3;\nfor (int y = 0; y < height; ++y) {\n\tfor (int x = 0; x < width; ++x) {\n\t\tfor (int c = 0; c < depth; ++c) {\n\t\t\tconst float* source_value = source_data + (3*width*y) + (3*x) + (2-c);\n\t\t\tinput_tensor_mapped(0, y, x, c) = *source_value;\n\t\t}\n\t}\n}\n\nstd::vector<std::pair<string, tensorflow::Tensor>> inputs = {\n\t{ \"input_1\", tInput },\n};\n\nstd::vector<tensorflow::Tensor> outputs;\nstatus = session->Run(inputs, { \"fc1000/Softmax\" }, {}, &outputs);\nif (!status.ok()) {\n\tstd::cout << status.ToString() << \"\\n\";\n\treturn 1;\n}", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 (build 17134) \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.15\r\n- **GCC/Compiler version (if compiling from source)**: CMake > VS 2017\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: `Session::run()`\r\n\r\n### Describe the problem\r\n\r\nI've built tensorflow (r1.9, using the CMake tools) linked with MKL (v2018 U3) and mkl-dnn (v0.15). I'm running windows 10 (build 17134) on an Intel Core i7-7820HQ CPU. \r\n\r\nI've built mkl-dnn from source and it's test are passing. However, a C++ project that loads a pre-trained tensorflow graph and passes an image for inference gives the following error when calling `Session::run(...)` :\r\n```\r\nW d:\\dev\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at mkl_conv_ops.cc:888 : Aborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\r\nAborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file d:\\dev\\tensorflow\\tensorflow\\core\\kernels\\mkl_conv_ops.cc:886\r\n         [[Node: conv1/BiasAdd = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_pad/Pad, conv1/kernel, conv1/bias, DMT/_0, DMT/_1, DMT/_2)]]\r\n```\r\nThe same code (with the same pre-trained model) does work on a linux machine (Intel(R) Xeon(R) CPU E5-2673 v3, running on Microsoft Azure), also with TF built with mkl-dnn.\r\n\r\n### Source code / logs\r\n\r\nInstall MKL 2018 U3 and build MKL-DNN v0.15 from source.\r\n\r\nBuild TF r1.9 with the following flags:\r\n```\r\ntensorflow_BUILD_ALL_KERNERS=ON\r\ntensorflow_BUILD_CONTRIB_KERNELS=ON\r\ntensorflow_BUILD_SHARED_LIB=ON\r\ntensorflow_ENABLE_GPU=OFF\r\ntensorflow_ENABLE_GRPC_SUPPORT=ON\r\ntensorflow_ENABLE_JEMALLOC_SUPPORT=OFF\r\ntensorflow_ENABLE_MKLDNN_SUPPORT=ON\r\ntensorflow_ENABLE_MKL_SUPPORT=ON\r\ntensorflow_ENABLE_POSITION_INDEPENDENT_CODE=ON\r\ntensorflow_ENABLE_SNAPPY_SUPPORT=ON\r\ntensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON\r\ntensorflow_WIN_CPU_SIMD_OPTIONS=ON\r\n```\r\n\r\nBuild passes and generates `tensorflow.dll`. Use keras to save a pre-trained Resnet50 model and attempt inference from C++ (linked with `tensorflow.dll`) as follows:\r\n```\r\nSession* session;\r\nStatus status = NewSession(SessionOptions(), &session);\r\n\r\nGraphDef graph_def;\r\nstatus = ReadBinaryProto(Env::Default(), \"../graph/resnet50.pb\", &graph_def);\r\nstatus = session->Create(graph_def);\r\n\r\nMat img = imread(\"../elephant.png\"), imgFloat, imgResized;\r\nimg.convertTo(imgFloat, CV_32FC3);\r\n\r\nTensor tInput(DT_FLOAT, TensorShape({ 1, 224, 224, 3 }));\r\nauto input_tensor_mapped = tInput.tensor<float, 4>();\r\n\r\nMat imgTensor(224, 224, CV_32FC3);\r\nresize(imgFloat, imgTensor, Size(224, 224));\r\nimgTensor -= Scalar(103.939, 116.779, 123.68);\r\n\t\r\nauto source_data = imgTensor.ptr<float>(0);\r\nint width = imgTensor.cols, height = imgTensor.rows, depth=3;\r\nfor (int y = 0; y < height; ++y) {\r\n\tfor (int x = 0; x < width; ++x) {\r\n\t\tfor (int c = 0; c < depth; ++c) {\r\n\t\t\tconst float* source_value = source_data + (3*width*y) + (3*x) + (2-c);\r\n\t\t\tinput_tensor_mapped(0, y, x, c) = *source_value;\r\n\t\t}\r\n\t}\r\n}\r\n\r\nstd::vector<std::pair<string, tensorflow::Tensor>> inputs = {\r\n\t{ \"input_1\", tInput },\r\n};\r\n\r\nstd::vector<tensorflow::Tensor> outputs;\r\nstatus = session->Run(inputs, { \"fc1000/Softmax\" }, {}, &outputs);\r\nif (!status.ok()) {\r\n\tstd::cout << status.ToString() << \"\\n\";\r\n\treturn 1;\r\n}\r\n```"}