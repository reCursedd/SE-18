{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302470524", "html_url": "https://github.com/tensorflow/tensorflow/issues/9517#issuecomment-302470524", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517", "id": 302470524, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjQ3MDUyNA==", "user": {"login": "leo-p", "id": 17261080, "node_id": "MDQ6VXNlcjE3MjYxMDgw", "avatar_url": "https://avatars0.githubusercontent.com/u/17261080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leo-p", "html_url": "https://github.com/leo-p", "followers_url": "https://api.github.com/users/leo-p/followers", "following_url": "https://api.github.com/users/leo-p/following{/other_user}", "gists_url": "https://api.github.com/users/leo-p/gists{/gist_id}", "starred_url": "https://api.github.com/users/leo-p/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leo-p/subscriptions", "organizations_url": "https://api.github.com/users/leo-p/orgs", "repos_url": "https://api.github.com/users/leo-p/repos", "events_url": "https://api.github.com/users/leo-p/events{/privacy}", "received_events_url": "https://api.github.com/users/leo-p/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-18T16:57:23Z", "updated_at": "2017-05-18T16:57:23Z", "author_association": "NONE", "body_html": "<p>It's not exactly the same but I've found that using SLIM one can simply do:</p>\n<pre><code>with tf.device('/gpu:%d' % gpu):\n    with tf.name_scope('tower_%d' % gpu) as scope:\n        with slim.arg_scope([slim.model_variable, slim.variable], device='/cpu:0'):\n            net = slim.fully_connected(...)\n</code></pre>\n<p>Which will pin the variables on <code>/cpu:0</code> while maintaining the actual computations on <code>/gpu:x</code>.</p>\n<p>And don't forget to set <code>colocate_gradients_with_ops=True</code> when computing the gradients.</p>", "body_text": "It's not exactly the same but I've found that using SLIM one can simply do:\nwith tf.device('/gpu:%d' % gpu):\n    with tf.name_scope('tower_%d' % gpu) as scope:\n        with slim.arg_scope([slim.model_variable, slim.variable], device='/cpu:0'):\n            net = slim.fully_connected(...)\n\nWhich will pin the variables on /cpu:0 while maintaining the actual computations on /gpu:x.\nAnd don't forget to set colocate_gradients_with_ops=True when computing the gradients.", "body": "It's not exactly the same but I've found that using SLIM one can simply do:\r\n```\r\nwith tf.device('/gpu:%d' % gpu):\r\n    with tf.name_scope('tower_%d' % gpu) as scope:\r\n        with slim.arg_scope([slim.model_variable, slim.variable], device='/cpu:0'):\r\n            net = slim.fully_connected(...)\r\n```\r\n\r\nWhich will pin the variables on `/cpu:0` while maintaining the actual computations on `/gpu:x`.\r\n\r\nAnd don't forget to set `colocate_gradients_with_ops=True` when computing the gradients."}