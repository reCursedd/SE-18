{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/298166631", "html_url": "https://github.com/tensorflow/tensorflow/issues/9517#issuecomment-298166631", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517", "id": 298166631, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODE2NjYzMQ==", "user": {"login": "jhaux", "id": 9572598, "node_id": "MDQ6VXNlcjk1NzI1OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/9572598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhaux", "html_url": "https://github.com/jhaux", "followers_url": "https://api.github.com/users/jhaux/followers", "following_url": "https://api.github.com/users/jhaux/following{/other_user}", "gists_url": "https://api.github.com/users/jhaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhaux/subscriptions", "organizations_url": "https://api.github.com/users/jhaux/orgs", "repos_url": "https://api.github.com/users/jhaux/repos", "events_url": "https://api.github.com/users/jhaux/events{/privacy}", "received_events_url": "https://api.github.com/users/jhaux/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-29T12:39:50Z", "updated_at": "2017-04-29T12:44:51Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Could you elaborate on this <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=577277\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinwicke\">@martinwicke</a>? Or guide me to the documentation?<br>\nI understand how to place variables using context managers, but in this case I would like the Variable nodes to be created by the layer function.</p>\n<p>E.g. it would be desirable for me to be able do something like this:</p>\n<pre><code>with tf.device('\\gpu:0):\n    fc = fully_connected(input, ..., variable_device='\\cpu:0')\n</code></pre>\n<p>Here the variables would be created on the CPU while the matrix multiplication and bias add are done on the GPU.</p>\n<p>From what I found reading through and experimenting with the code, this functionality is basically there, one only would need to add a kwarg to the layer and pass it to the variable getter, that creates the variables. This is what I did above.</p>", "body_text": "Could you elaborate on this @martinwicke? Or guide me to the documentation?\nI understand how to place variables using context managers, but in this case I would like the Variable nodes to be created by the layer function.\nE.g. it would be desirable for me to be able do something like this:\nwith tf.device('\\gpu:0):\n    fc = fully_connected(input, ..., variable_device='\\cpu:0')\n\nHere the variables would be created on the CPU while the matrix multiplication and bias add are done on the GPU.\nFrom what I found reading through and experimenting with the code, this functionality is basically there, one only would need to add a kwarg to the layer and pass it to the variable getter, that creates the variables. This is what I did above.", "body": "Could you elaborate on this @martinwicke? Or guide me to the documentation? \r\nI understand how to place variables using context managers, but in this case I would like the Variable nodes to be created by the layer function.\r\n\r\nE.g. it would be desirable for me to be able do something like this:\r\n```\r\nwith tf.device('\\gpu:0):\r\n    fc = fully_connected(input, ..., variable_device='\\cpu:0')\r\n```\r\nHere the variables would be created on the CPU while the matrix multiplication and bias add are done on the GPU.\r\n\r\nFrom what I found reading through and experimenting with the code, this functionality is basically there, one only would need to add a kwarg to the layer and pass it to the variable getter, that creates the variables. This is what I did above."}