{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9517", "id": 225146607, "node_id": "MDU6SXNzdWUyMjUxNDY2MDc=", "number": 9517, "title": "Placing Variables on the cpu using `tf.contrib.layers` functions", "user": {"login": "jhaux", "id": 9572598, "node_id": "MDQ6VXNlcjk1NzI1OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/9572598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhaux", "html_url": "https://github.com/jhaux", "followers_url": "https://api.github.com/users/jhaux/followers", "following_url": "https://api.github.com/users/jhaux/following{/other_user}", "gists_url": "https://api.github.com/users/jhaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhaux/subscriptions", "organizations_url": "https://api.github.com/users/jhaux/orgs", "repos_url": "https://api.github.com/users/jhaux/repos", "events_url": "https://api.github.com/users/jhaux/events{/privacy}", "received_events_url": "https://api.github.com/users/jhaux/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2017-04-28T17:39:03Z", "updated_at": "2018-10-14T11:02:27Z", "closed_at": "2017-05-20T00:12:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Dear tensorflow team,</p>\n<p>After constructing my model using the functionality provided by <code>tf.contrib.layers</code> I now want to extend my model over several GPUs. I learned that it might be beneficary to place Variables on the CPU when doing that, to reduce data transfer overhead. After not seeing an easy way to do this I found a workaround I described on <a href=\"http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023\" rel=\"nofollow\">stackoverflow</a>. My solution is to generate Variable-nodes in the graph where the Variable-getter of the <code>fully_connected</code> layer for example would expect the variables to be.</p>\n<p>As this is not a very nice solution, I messed with the <code>fully_connected</code> layer and the <code>_build_variable_getter</code> function to basically allow me to specify, where I want to place the variabels. Thus after</p>\n<ul>\n<li>adding the kwarg <code>variable_device</code> to <code>tf.contrib.layer.fully_connected</code></li>\n<li>adding the kwarg <code>variable_device</code> to <code>tf.contrib.layer._build_variable_getter</code></li>\n<li>adding the kwarg <code>device</code> to <code>tf.contrib.layer._model_variable_getter</code></li>\n<li>and passing this as kwarg to <code>model_variable</code> defined in <code>tensorflow.contrib.framework.python.ops.variables</code></li>\n</ul>\n<p>I get the desired functionality when using the <code>fully_connected</code> layer.<br>\nBelow you find the modified version of <code>layers.py</code></p>\n<p>In my eyes this would be a very useful feature for all layers that contain trainable variables, which is why I would like to make a request for this feature.<br>\nIf you think the supplied modification is good enough, I can also try to make a pull request, after updating the other layers.</p>\n<p>Best, Johannes</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: As described above, I did</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version</strong>: ('v1.0.0-65-g4763edf-dirty', '1.0.1')</li>\n<li><strong>CUDA/cuDNN version</strong>: 8, 5.1</li>\n<li><strong>GPU model and memory</strong>: Titan X Pascal, 12GB</li>\n</ul>\n<h3>Source code / logs</h3>\n<p>See</p>\n<ul>\n<li><a href=\"http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023\" rel=\"nofollow\">stackoverflow</a></li>\n<li><a href=\"https://drive.google.com/file/d/0BxImZIuERGB2MHBMRDZkejM4LVU/view?usp=sharing\" rel=\"nofollow\">modified layers.py</a></li>\n</ul>", "body_text": "Dear tensorflow team,\nAfter constructing my model using the functionality provided by tf.contrib.layers I now want to extend my model over several GPUs. I learned that it might be beneficary to place Variables on the CPU when doing that, to reduce data transfer overhead. After not seeing an easy way to do this I found a workaround I described on stackoverflow. My solution is to generate Variable-nodes in the graph where the Variable-getter of the fully_connected layer for example would expect the variables to be.\nAs this is not a very nice solution, I messed with the fully_connected layer and the _build_variable_getter function to basically allow me to specify, where I want to place the variabels. Thus after\n\nadding the kwarg variable_device to tf.contrib.layer.fully_connected\nadding the kwarg variable_device to tf.contrib.layer._build_variable_getter\nadding the kwarg device to tf.contrib.layer._model_variable_getter\nand passing this as kwarg to model_variable defined in tensorflow.contrib.framework.python.ops.variables\n\nI get the desired functionality when using the fully_connected layer.\nBelow you find the modified version of layers.py\nIn my eyes this would be a very useful feature for all layers that contain trainable variables, which is why I would like to make a request for this feature.\nIf you think the supplied modification is good enough, I can also try to make a pull request, after updating the other layers.\nBest, Johannes\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): As described above, I did\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version: ('v1.0.0-65-g4763edf-dirty', '1.0.1')\nCUDA/cuDNN version: 8, 5.1\nGPU model and memory: Titan X Pascal, 12GB\n\nSource code / logs\nSee\n\nstackoverflow\nmodified layers.py", "body": "Dear tensorflow team,\r\n\r\nAfter constructing my model using the functionality provided by `tf.contrib.layers` I now want to extend my model over several GPUs. I learned that it might be beneficary to place Variables on the CPU when doing that, to reduce data transfer overhead. After not seeing an easy way to do this I found a workaround I described on [stackoverflow](http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023). My solution is to generate Variable-nodes in the graph where the Variable-getter of the `fully_connected` layer for example would expect the variables to be.\r\n\r\nAs this is not a very nice solution, I messed with the `fully_connected` layer and the `_build_variable_getter` function to basically allow me to specify, where I want to place the variabels. Thus after \r\n\r\n- adding the kwarg `variable_device` to `tf.contrib.layer.fully_connected`\r\n- adding the kwarg `variable_device` to `tf.contrib.layer._build_variable_getter`\r\n- adding the kwarg `device` to `tf.contrib.layer._model_variable_getter`\r\n- and passing this as kwarg to `model_variable` defined in `tensorflow.contrib.framework.python.ops.variables`\r\n\r\nI get the desired functionality when using the `fully_connected` layer.\r\nBelow you find the modified version of `layers.py` \r\n\r\nIn my eyes this would be a very useful feature for all layers that contain trainable variables, which is why I would like to make a request for this feature.\r\nIf you think the supplied modification is good enough, I can also try to make a pull request, after updating the other layers.\r\n\r\nBest, Johannes\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: As described above, I did\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version**: ('v1.0.0-65-g4763edf-dirty', '1.0.1')\r\n- **CUDA/cuDNN version**: 8, 5.1\r\n- **GPU model and memory**: Titan X Pascal, 12GB\r\n\r\n### Source code / logs\r\nSee \r\n- [stackoverflow](http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023)\r\n- [modified layers.py](https://drive.google.com/file/d/0BxImZIuERGB2MHBMRDZkejM4LVU/view?usp=sharing)"}