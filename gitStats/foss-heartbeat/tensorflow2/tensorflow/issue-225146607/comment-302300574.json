{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302300574", "html_url": "https://github.com/tensorflow/tensorflow/issues/9517#issuecomment-302300574", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9517", "id": 302300574, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjMwMDU3NA==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-18T04:57:57Z", "updated_at": "2017-05-18T15:25:17Z", "author_association": "MEMBER", "body_html": "<p>Here we go.  I have actually changed my mind and agree with Martin.  Although I am not an authority as you will see from my sloppy python.  Using this with the SLIM models can boost performance on systems where GPUs are not peered or Resnet which seems to often just work better with CPU:0 as the ps-server.  This is just how I do it and I am very open to criticism and a better approach.</p>\n<div class=\"highlight highlight-source-python\"><pre>tf.app.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>local_ps_device<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>CPU:0<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Local parameter server GPU:0 if gpus are peered or CPU:0 otherwise try both.<span class=\"pl-pds\">\"\"\"</span></span>)\n\n<span class=\"pl-c1\">PS_OPS</span> <span class=\"pl-k\">=</span> [\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Variable<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>VariableV2<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>AutoReloadVariable<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>MutableHashTable<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>MutableHashTableOfTensors<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>MutableDenseHashTable<span class=\"pl-pds\">'</span></span>\n]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">assign_to_device</span>(<span class=\"pl-smi\">device</span>, <span class=\"pl-smi\">ps_device</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Returns a function to place variables on the ps_device.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">        device: Device for everything but variables</span>\n<span class=\"pl-s\">        ps_device: Device to put the variables on.  Example values are GPU:0 and</span>\n<span class=\"pl-s\">        CPU:0.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    If ps_device is not set then the variables will be placed on the device.</span>\n<span class=\"pl-s\">    The best device for shared varibles depends on the platform as well as the</span>\n<span class=\"pl-s\">    model.  Start with CPU:0 and then test GPU:0 to see if there is an </span>\n<span class=\"pl-s\">    improvement.  </span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_assign</span>(<span class=\"pl-smi\">op</span>):\n        node_def <span class=\"pl-k\">=</span> op <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(op, tf.NodeDef) <span class=\"pl-k\">else</span> op.node_def\n        <span class=\"pl-k\">if</span> node_def.op <span class=\"pl-k\">in</span> <span class=\"pl-c1\">PS_OPS</span>:\n            <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> ps_device\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">return</span> device\n    <span class=\"pl-k\">return</span> _assign\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>():\n       <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Incomplete example of a train method just to show the use of assign_to_device</span>\n<span class=\"pl-s\">       </span>\n<span class=\"pl-s\">       Note: The is from a ResNet and AlexNet training CIFAR-10 example on Multi-GPU. </span>\n<span class=\"pl-s\">       I suspect there is some code \"smell\" but I was working with something that already </span>\n<span class=\"pl-s\">       existed and the purpose is to illustrate the general usage.  Feedback welcome.  </span>\n<span class=\"pl-s\">       <span class=\"pl-pds\">\"\"\"</span></span>\n        tower_grads <span class=\"pl-k\">=</span> []\n        reuse_variables <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        losses <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> six.moves.range(<span class=\"pl-c1\">FLAGS</span>.num_gpus):\n             <span class=\"pl-k\">with</span> tf.device(assign_to_device(\n                            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(i),\n                            <span class=\"pl-v\">ps_device</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.local_ps_device)):\n                <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{}</span>_<span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>TOWER<span class=\"pl-pds\">'</span></span>, i)) <span class=\"pl-k\">as</span> n_scope:\n                    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n                        images, labels <span class=\"pl-k\">=</span> cifar10_input.inputs(<span class=\"pl-c1\">False</span>, <span class=\"pl-c1\">FLAGS</span>.data_dir, <span class=\"pl-c1\">FLAGS</span>.batch_size)\n                    <span class=\"pl-k\">with</span> tf.variable_scope(tf.get_variable_scope(), <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse_variables):\n                        logits <span class=\"pl-k\">=</span> inference_small(images, <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">num_blocks</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">9</span>)\n                    tower_loss <span class=\"pl-k\">=</span> loss(logits, labels)\n                    losses.append(tower_loss)\n                    grads <span class=\"pl-k\">=</span> optimizer.compute_gradients(tower_loss)\n                    tower_grads.append(grads)\n                    reuse_variables <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n<span class=\"pl-c1\">...</span>.\n</pre></div>", "body_text": "Here we go.  I have actually changed my mind and agree with Martin.  Although I am not an authority as you will see from my sloppy python.  Using this with the SLIM models can boost performance on systems where GPUs are not peered or Resnet which seems to often just work better with CPU:0 as the ps-server.  This is just how I do it and I am very open to criticism and a better approach.\ntf.app.flags.DEFINE_string('local_ps_device', 'CPU:0', \"\"\"Local parameter server GPU:0 if gpus are peered or CPU:0 otherwise try both.\"\"\")\n\nPS_OPS = [\n      'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n      'MutableHashTableOfTensors', 'MutableDenseHashTable'\n]\n\ndef assign_to_device(device, ps_device=None):\n    \"\"\"Returns a function to place variables on the ps_device.\n\n    Args:\n        device: Device for everything but variables\n        ps_device: Device to put the variables on.  Example values are GPU:0 and\n        CPU:0.\n    \n    If ps_device is not set then the variables will be placed on the device.\n    The best device for shared varibles depends on the platform as well as the\n    model.  Start with CPU:0 and then test GPU:0 to see if there is an \n    improvement.  \n\n    \"\"\"\n    def _assign(op):\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n        if node_def.op in PS_OPS:\n            return \"/\" + ps_device\n        else:\n            return device\n    return _assign\n\ndef train():\n       \"\"\" Incomplete example of a train method just to show the use of assign_to_device\n       \n       Note: The is from a ResNet and AlexNet training CIFAR-10 example on Multi-GPU. \n       I suspect there is some code \"smell\" but I was working with something that already \n       existed and the purpose is to illustrate the general usage.  Feedback welcome.  \n       \"\"\"\n        tower_grads = []\n        reuse_variables = None\n        losses = []\n        for i in six.moves.range(FLAGS.num_gpus):\n             with tf.device(assign_to_device(\n                            '/gpu:{}'.format(i),\n                            ps_device=FLAGS.local_ps_device)):\n                with tf.name_scope('{}_{}'.format('TOWER', i)) as n_scope:\n                    with tf.device('/cpu:0'):\n                        images, labels = cifar10_input.inputs(False, FLAGS.data_dir, FLAGS.batch_size)\n                    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\n                        logits = inference_small(images, is_training=True, num_blocks=9)\n                    tower_loss = loss(logits, labels)\n                    losses.append(tower_loss)\n                    grads = optimizer.compute_gradients(tower_loss)\n                    tower_grads.append(grads)\n                    reuse_variables = True\n....", "body": "Here we go.  I have actually changed my mind and agree with Martin.  Although I am not an authority as you will see from my sloppy python.  Using this with the SLIM models can boost performance on systems where GPUs are not peered or Resnet which seems to often just work better with CPU:0 as the ps-server.  This is just how I do it and I am very open to criticism and a better approach.\r\n\r\n```python\r\ntf.app.flags.DEFINE_string('local_ps_device', 'CPU:0', \"\"\"Local parameter server GPU:0 if gpus are peered or CPU:0 otherwise try both.\"\"\")\r\n\r\nPS_OPS = [\r\n      'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\r\n      'MutableHashTableOfTensors', 'MutableDenseHashTable'\r\n]\r\n\r\ndef assign_to_device(device, ps_device=None):\r\n    \"\"\"Returns a function to place variables on the ps_device.\r\n\r\n    Args:\r\n        device: Device for everything but variables\r\n        ps_device: Device to put the variables on.  Example values are GPU:0 and\r\n        CPU:0.\r\n    \r\n    If ps_device is not set then the variables will be placed on the device.\r\n    The best device for shared varibles depends on the platform as well as the\r\n    model.  Start with CPU:0 and then test GPU:0 to see if there is an \r\n    improvement.  \r\n\r\n    \"\"\"\r\n    def _assign(op):\r\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\r\n        if node_def.op in PS_OPS:\r\n            return \"/\" + ps_device\r\n        else:\r\n            return device\r\n    return _assign\r\n\r\ndef train():\r\n       \"\"\" Incomplete example of a train method just to show the use of assign_to_device\r\n       \r\n       Note: The is from a ResNet and AlexNet training CIFAR-10 example on Multi-GPU. \r\n       I suspect there is some code \"smell\" but I was working with something that already \r\n       existed and the purpose is to illustrate the general usage.  Feedback welcome.  \r\n       \"\"\"\r\n        tower_grads = []\r\n        reuse_variables = None\r\n        losses = []\r\n        for i in six.moves.range(FLAGS.num_gpus):\r\n             with tf.device(assign_to_device(\r\n                            '/gpu:{}'.format(i),\r\n                            ps_device=FLAGS.local_ps_device)):\r\n                with tf.name_scope('{}_{}'.format('TOWER', i)) as n_scope:\r\n                    with tf.device('/cpu:0'):\r\n                        images, labels = cifar10_input.inputs(False, FLAGS.data_dir, FLAGS.batch_size)\r\n                    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\r\n                        logits = inference_small(images, is_training=True, num_blocks=9)\r\n                    tower_loss = loss(logits, labels)\r\n                    losses.append(tower_loss)\r\n                    grads = optimizer.compute_gradients(tower_loss)\r\n                    tower_grads.append(grads)\r\n                    reuse_variables = True\r\n....\r\n\r\n```\r\n\r\n"}