{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/284894833", "html_url": "https://github.com/tensorflow/tensorflow/issues/5243#issuecomment-284894833", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5243", "id": 284894833, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDg5NDgzMw==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-07T23:28:16Z", "updated_at": "2017-03-07T23:28:16Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7816846\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kushia\">@kushia</a> I don't see any reason why the cifar10 inferenfce code should require a batch of 128.<br>\nThe error message you posted is from an assign op - and there aren't any such ops in inference code. Are you sure that this isn't happening during restoring your model from checkpoint?</p>\n<p>Could you please post the full stack backtrace of the error - that way we can see what step was actually being run?</p>", "body_text": "@kushia I don't see any reason why the cifar10 inferenfce code should require a batch of 128.\nThe error message you posted is from an assign op - and there aren't any such ops in inference code. Are you sure that this isn't happening during restoring your model from checkpoint?\nCould you please post the full stack backtrace of the error - that way we can see what step was actually being run?", "body": "@kushia I don't see any reason why the cifar10 inferenfce code should require a batch of 128. \r\nThe error message you posted is from an assign op - and there aren't any such ops in inference code. Are you sure that this isn't happening during restoring your model from checkpoint?\r\n\r\nCould you please post the full stack backtrace of the error - that way we can see what step was actually being run?\r\n"}