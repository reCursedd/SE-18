{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22121", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22121/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22121/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22121/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22121", "id": 357764911, "node_id": "MDU6SXNzdWUzNTc3NjQ5MTE=", "number": 22121, "title": "Unable to profile tf.keras Model. Am I missing something or is it a known issue?", "user": {"login": "Nithanaroy", "id": 670556, "node_id": "MDQ6VXNlcjY3MDU1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/670556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nithanaroy", "html_url": "https://github.com/Nithanaroy", "followers_url": "https://api.github.com/users/Nithanaroy/followers", "following_url": "https://api.github.com/users/Nithanaroy/following{/other_user}", "gists_url": "https://api.github.com/users/Nithanaroy/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nithanaroy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nithanaroy/subscriptions", "organizations_url": "https://api.github.com/users/Nithanaroy/orgs", "repos_url": "https://api.github.com/users/Nithanaroy/repos", "events_url": "https://api.github.com/users/Nithanaroy/events{/privacy}", "received_events_url": "https://api.github.com/users/Nithanaroy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-09-06T18:02:52Z", "updated_at": "2018-11-09T18:53:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: RHEL 7</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: NA</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: No</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>: Below code</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><strong>tf.contrib.tfprof</strong> does not profile tf.keras Model. Am I missing something or is it a known issue?</p>\n<h3>Source code / logs</h3>\n<p>The goal is to find what % of total time is spent in the input pipeline (mostly IO) and what % of total time is spent on model training \u2013 ideally a chart like the one presented in the <a href=\"https://www.youtube.com/watch?v=SxOsJPaxHME&amp;feature=youtu.be&amp;t=977\" rel=\"nofollow\">Training Performance session</a> at tf dev summit 2018.</p>\n<p><strong>Model Training:</strong></p>\n<div class=\"highlight highlight-source-python\"><pre>training_set <span class=\"pl-k\">=</span> tfdata_generator_with_interleave([\u201cf1.avro\u201d, \u201cf2.avro\u201d, \u2026], <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">512</span>, <span class=\"pl-v\">preprocess_fn</span><span class=\"pl-k\">=</span>preprocess_fn_dense)\nvalidation_set <span class=\"pl-k\">=</span> tfdata_generator_with_interleave([\u201cf1_val.avro\u201d, \u201cf2_val.avro\u201d, \u2026], <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">512</span>, <span class=\"pl-v\">preprocess_fn</span><span class=\"pl-k\">=</span>preprocess_fn_dense)\nmodel <span class=\"pl-k\">=</span> my_tf_keras_dense_deep_model()\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>categorical_crossentropy<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span>\u201dadam\u201d, <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n\n<span class=\"pl-k\">with</span> tf.contrib.tfprof.ProfileContext( <span class=\"pl-s\"><span class=\"pl-pds\">'</span>./profiles/dense_model\u2019) ) as pctx:<span class=\"pl-ii\"></span></span>\n   model.fit(\n                training_set.make_one_shot_iterator(),\n                <span class=\"pl-v\">steps_per_epoch</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">TOTAL_TRAIN_RECORDS</span> <span class=\"pl-k\">//</span> <span class=\"pl-c1\">_BATCH_SIZE</span>, <span class=\"pl-c\"><span class=\"pl-c\">#</span> need this as we are feeding data using a generator</span>\n                <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">_EPOCHS</span>,\n                <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span> validation_set.make_one_shot_iterator(),\n                <span class=\"pl-v\">validation_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">TOTAL_TEST_RECORDS</span> <span class=\"pl-k\">//</span> <span class=\"pl-c1\">_BATCH_SIZE</span>,\n                <span class=\"pl-v\">callbacks</span><span class=\"pl-k\">=</span>[tensorboard])</pre></div>\n<p><strong>Input Pipeline:</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">tfdata_generator_with_interleave</span>(<span class=\"pl-smi\">data_files</span>, <span class=\"pl-smi\">is_training</span>, <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>, <span class=\"pl-smi\">preprocess_fn</span><span class=\"pl-k\">=</span>preprocess_fn_dense):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">wrap_generator</span>(<span class=\"pl-smi\">filename</span>):\n        <span class=\"pl-k\">return</span> tf.data.Dataset.from_generator(read_local_avro_data_gen, (tf.float32, tf.float64),\n                                              <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>[filename, batch_size <span class=\"pl-k\">/</span> <span class=\"pl-c1\">4</span>])\n\n    files <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(data_files)\n    dataset <span class=\"pl-k\">=</span> files.apply(tf.contrib.data.parallel_interleave(wrap_generator, <span class=\"pl-v\">cycle_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">sloppy</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n    dataset <span class=\"pl-k\">=</span> dataset.flat_map(<span class=\"pl-k\">lambda</span> <span class=\"pl-k\">*</span><span class=\"pl-smi\">x</span>: tf.data.Dataset.from_tensor_slices(x))\n\n    <span class=\"pl-k\">if</span> is_training:\n        dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.shuffle_and_repeat(<span class=\"pl-c1\">1000</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">42</span>))\n\n    dataset <span class=\"pl-k\">=</span> dataset.apply(tf.contrib.data.map_and_batch(preprocess_fn, batch_size,\n                                                          <span class=\"pl-v\">num_parallel_batches</span><span class=\"pl-k\">=</span>num_parallel_data_fetch,\n                                                          <span class=\"pl-v\">drop_remainder</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span> <span class=\"pl-k\">if</span> is_training <span class=\"pl-k\">else</span> <span class=\"pl-c1\">False</span>)\n                            )\n\n    dataset <span class=\"pl-k\">=</span> dataset.prefetch(tf.contrib.data.<span class=\"pl-c1\">AUTOTUNE</span>)\n    <span class=\"pl-k\">return</span> dataset</pre></div>\n<p>But I do not see any files to load into tensorboard or chrome in ./profiles directory. Does the profile not work with tf.keras models? Or Am I missing any setup?</p>\n<p>Also tried contacting the email address mentioned on the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/README.md\">Profiler README</a> - <a href=\"mailto:xpan@google.com\">xpan@google.com</a>, but message sending failed.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\nTensorFlow installed from (source or binary): No\nTensorFlow version (use command below): 1.9\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory: NA\nExact command to reproduce: Below code\n\nDescribe the problem\ntf.contrib.tfprof does not profile tf.keras Model. Am I missing something or is it a known issue?\nSource code / logs\nThe goal is to find what % of total time is spent in the input pipeline (mostly IO) and what % of total time is spent on model training \u2013 ideally a chart like the one presented in the Training Performance session at tf dev summit 2018.\nModel Training:\ntraining_set = tfdata_generator_with_interleave([\u201cf1.avro\u201d, \u201cf2.avro\u201d, \u2026], is_training=True, batch_size=512, preprocess_fn=preprocess_fn_dense)\nvalidation_set = tfdata_generator_with_interleave([\u201cf1_val.avro\u201d, \u201cf2_val.avro\u201d, \u2026], is_training=False, batch_size=512, preprocess_fn=preprocess_fn_dense)\nmodel = my_tf_keras_dense_deep_model()\nmodel.compile(loss='categorical_crossentropy', optimizer=\u201dadam\u201d, metrics=['accuracy'])\n\nwith tf.contrib.tfprof.ProfileContext( './profiles/dense_model\u2019) ) as pctx:\n   model.fit(\n                training_set.make_one_shot_iterator(),\n                steps_per_epoch=TOTAL_TRAIN_RECORDS // _BATCH_SIZE, # need this as we are feeding data using a generator\n                epochs=_EPOCHS,\n                validation_data= validation_set.make_one_shot_iterator(),\n                validation_steps=TOTAL_TEST_RECORDS // _BATCH_SIZE,\n                callbacks=[tensorboard])\nInput Pipeline:\ndef tfdata_generator_with_interleave(data_files, is_training, batch_size=128, preprocess_fn=preprocess_fn_dense):\n    def wrap_generator(filename):\n        return tf.data.Dataset.from_generator(read_local_avro_data_gen, (tf.float32, tf.float64),\n                                              args=[filename, batch_size / 4])\n\n    files = tf.data.Dataset.from_tensor_slices(data_files)\n    dataset = files.apply(tf.contrib.data.parallel_interleave(wrap_generator, cycle_length=4, sloppy=True))\n    dataset = dataset.flat_map(lambda *x: tf.data.Dataset.from_tensor_slices(x))\n\n    if is_training:\n        dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(1000, -1, 42))\n\n    dataset = dataset.apply(tf.contrib.data.map_and_batch(preprocess_fn, batch_size,\n                                                          num_parallel_batches=num_parallel_data_fetch,\n                                                          drop_remainder=True if is_training else False)\n                            )\n\n    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n    return dataset\nBut I do not see any files to load into tensorboard or chrome in ./profiles directory. Does the profile not work with tf.keras models? Or Am I missing any setup?\nAlso tried contacting the email address mentioned on the Profiler README - xpan@google.com, but message sending failed.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: No\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: Below code\r\n\r\n### Describe the problem\r\n**tf.contrib.tfprof** does not profile tf.keras Model. Am I missing something or is it a known issue?\r\n\r\n### Source code / logs\r\nThe goal is to find what % of total time is spent in the input pipeline (mostly IO) and what % of total time is spent on model training \u2013 ideally a chart like the one presented in the [Training Performance session](https://www.youtube.com/watch?v=SxOsJPaxHME&feature=youtu.be&t=977) at tf dev summit 2018.\r\n\r\n**Model Training:**\r\n```python\r\ntraining_set = tfdata_generator_with_interleave([\u201cf1.avro\u201d, \u201cf2.avro\u201d, \u2026], is_training=True, batch_size=512, preprocess_fn=preprocess_fn_dense)\r\nvalidation_set = tfdata_generator_with_interleave([\u201cf1_val.avro\u201d, \u201cf2_val.avro\u201d, \u2026], is_training=False, batch_size=512, preprocess_fn=preprocess_fn_dense)\r\nmodel = my_tf_keras_dense_deep_model()\r\nmodel.compile(loss='categorical_crossentropy', optimizer=\u201dadam\u201d, metrics=['accuracy'])\r\n\r\nwith tf.contrib.tfprof.ProfileContext( './profiles/dense_model\u2019) ) as pctx:\r\n   model.fit(\r\n                training_set.make_one_shot_iterator(),\r\n                steps_per_epoch=TOTAL_TRAIN_RECORDS // _BATCH_SIZE, # need this as we are feeding data using a generator\r\n                epochs=_EPOCHS,\r\n                validation_data= validation_set.make_one_shot_iterator(),\r\n                validation_steps=TOTAL_TEST_RECORDS // _BATCH_SIZE,\r\n                callbacks=[tensorboard])\r\n```\r\n\r\n**Input Pipeline:**\r\n```python\r\ndef tfdata_generator_with_interleave(data_files, is_training, batch_size=128, preprocess_fn=preprocess_fn_dense):\r\n    def wrap_generator(filename):\r\n        return tf.data.Dataset.from_generator(read_local_avro_data_gen, (tf.float32, tf.float64),\r\n                                              args=[filename, batch_size / 4])\r\n\r\n    files = tf.data.Dataset.from_tensor_slices(data_files)\r\n    dataset = files.apply(tf.contrib.data.parallel_interleave(wrap_generator, cycle_length=4, sloppy=True))\r\n    dataset = dataset.flat_map(lambda *x: tf.data.Dataset.from_tensor_slices(x))\r\n\r\n    if is_training:\r\n        dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(1000, -1, 42))\r\n\r\n    dataset = dataset.apply(tf.contrib.data.map_and_batch(preprocess_fn, batch_size,\r\n                                                          num_parallel_batches=num_parallel_data_fetch,\r\n                                                          drop_remainder=True if is_training else False)\r\n                            )\r\n\r\n    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\r\n    return dataset\r\n```\r\n\r\nBut I do not see any files to load into tensorboard or chrome in ./profiles directory. Does the profile not work with tf.keras models? Or Am I missing any setup?\r\n\r\nAlso tried contacting the email address mentioned on the [Profiler README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/README.md) - xpan@google.com, but message sending failed.\r\n"}