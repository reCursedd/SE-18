{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/267483232", "html_url": "https://github.com/tensorflow/tensorflow/issues/6322#issuecomment-267483232", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6322", "id": 267483232, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NzQ4MzIzMg==", "user": {"login": "danielgordon10", "id": 7245472, "node_id": "MDQ6VXNlcjcyNDU0NzI=", "avatar_url": "https://avatars2.githubusercontent.com/u/7245472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielgordon10", "html_url": "https://github.com/danielgordon10", "followers_url": "https://api.github.com/users/danielgordon10/followers", "following_url": "https://api.github.com/users/danielgordon10/following{/other_user}", "gists_url": "https://api.github.com/users/danielgordon10/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielgordon10/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielgordon10/subscriptions", "organizations_url": "https://api.github.com/users/danielgordon10/orgs", "repos_url": "https://api.github.com/users/danielgordon10/repos", "events_url": "https://api.github.com/users/danielgordon10/events{/privacy}", "received_events_url": "https://api.github.com/users/danielgordon10/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-16T00:16:08Z", "updated_at": "2016-12-16T00:16:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Sure. I started with the fully_connected_feed.py file and added in the necessary stuff. It seems to work for me. I tried to follow the Google style as best as I could. I even used comments! It requires Numpy and Scipy, but that isn't too much to ask.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> you may not use this file except in compliance with the License.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> You may obtain a copy of the License at</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>     http://www.apache.org/licenses/LICENSE-2.0</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Unless required by applicable law or agreed to in writing, software</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> distributed under the License is distributed on an \"AS IS\" BASIS,</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> See the License for the specific language governing permissions and</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> limitations under the License.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> @author: Daniel Gordon &lt;xkcd@cs.washington.edu&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ==============================================================================</span>\n\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Trains and Evaluates the MNIST network using a feed dictionary.<span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=missing-docstring</span>\n<span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> os.path\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">from</span> six.moves <span class=\"pl-k\">import</span> <span class=\"pl-v\">xrange</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> pylint: disable=redefined-builtin</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">from</span> tensorflow.contrib.tensorboard.plugins <span class=\"pl-k\">import</span> projector\n<span class=\"pl-k\">from</span> tensorflow.examples.tutorials.mnist <span class=\"pl-k\">import</span> input_data\n<span class=\"pl-k\">from</span> tensorflow.examples.tutorials.mnist <span class=\"pl-k\">import</span> mnist\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> scipy.misc\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Basic model parameters as external flags.</span>\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">placeholder_inputs</span>(<span class=\"pl-smi\">batch_size</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Generate placeholder variables to represent the input tensors.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  These placeholders are used as inputs by the rest of the model building</span>\n<span class=\"pl-s\">  code and will be fed from the downloaded data in the .run() loop, below.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Args:</span>\n<span class=\"pl-s\">    batch_size: The batch size will be baked into both placeholders.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    images_placeholder: Images placeholder.</span>\n<span class=\"pl-s\">    labels_placeholder: Labels placeholder.</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note that the shapes of the placeholders match the shapes of the full</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> image and label tensors, except the first dimension is now batch_size</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> rather than the full size of the train or test data sets.</span>\n  images_placeholder <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size,\n                                                         mnist.<span class=\"pl-c1\">IMAGE_PIXELS</span>))\n  labels_placeholder <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(batch_size))\n  <span class=\"pl-k\">return</span> images_placeholder, labels_placeholder\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">fill_feed_dict</span>(<span class=\"pl-smi\">data_set</span>, <span class=\"pl-smi\">images_pl</span>, <span class=\"pl-smi\">labels_pl</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Fills the feed_dict for training the given step.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  A feed_dict takes the form of:</span>\n<span class=\"pl-s\">  feed_dict = {</span>\n<span class=\"pl-s\">      &lt;placeholder&gt;: &lt;tensor of values to be passed for placeholder&gt;,</span>\n<span class=\"pl-s\">      ....</span>\n<span class=\"pl-s\">  }</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Args:</span>\n<span class=\"pl-s\">    data_set: The set of images and labels, from input_data.read_data_sets()</span>\n<span class=\"pl-s\">    images_pl: The images placeholder, from placeholder_inputs().</span>\n<span class=\"pl-s\">    labels_pl: The labels placeholder, from placeholder_inputs().</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    feed_dict: The feed dictionary mapping from placeholders to values.</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create the feed_dict for the placeholders filled with the next</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> `batch size` examples.</span>\n  images_feed, labels_feed <span class=\"pl-k\">=</span> data_set.next_batch(<span class=\"pl-c1\">FLAGS</span>.batch_size,\n                                                 <span class=\"pl-c1\">FLAGS</span>.fake_data)\n  feed_dict <span class=\"pl-k\">=</span> {\n      images_pl: images_feed,\n      labels_pl: labels_feed,\n  }\n  <span class=\"pl-k\">return</span> feed_dict\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">do_eval</span>(<span class=\"pl-smi\">sess</span>,\n            <span class=\"pl-smi\">eval_correct</span>,\n            <span class=\"pl-smi\">images_placeholder</span>,\n            <span class=\"pl-smi\">labels_placeholder</span>,\n            <span class=\"pl-smi\">data_set</span>,\n            <span class=\"pl-smi\">return_results</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Runs one evaluation against the full epoch of data.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Args:</span>\n<span class=\"pl-s\">    sess: The session in which the model has been trained.</span>\n<span class=\"pl-s\">    eval_correct: The Tensor that returns the number of correct predictions.</span>\n<span class=\"pl-s\">    images_placeholder: The images placeholder.</span>\n<span class=\"pl-s\">    labels_placeholder: The labels placeholder.</span>\n<span class=\"pl-s\">    data_set: The set of images and labels to evaluate, from</span>\n<span class=\"pl-s\">      input_data.read_data_sets().</span>\n<span class=\"pl-s\">    return_results: True if the results should be returned for the embedding.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    all_images: A list of batches of images.</span>\n<span class=\"pl-s\">    all_labels: A list of batches of labels.</span>\n<span class=\"pl-s\">    all_hidden1_outputs: A list of batches of embeddings from the first hidden</span>\n<span class=\"pl-s\">      layer.</span>\n<span class=\"pl-s\">    all_hidden2_outputs: A list of batches of embeddings from the second hidden</span>\n<span class=\"pl-s\">      layer.</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> And run one epoch of eval.</span>\n  true_count <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Counts the number of correct predictions.</span>\n  steps_per_epoch <span class=\"pl-k\">=</span> data_set.num_examples <span class=\"pl-k\">//</span> <span class=\"pl-c1\">FLAGS</span>.batch_size\n  num_examples <span class=\"pl-k\">=</span> steps_per_epoch <span class=\"pl-k\">*</span> <span class=\"pl-c1\">FLAGS</span>.batch_size\n  <span class=\"pl-k\">if</span> return_results:\n    all_images <span class=\"pl-k\">=</span> []\n    all_labels <span class=\"pl-k\">=</span> []\n    all_hidden1_outputs <span class=\"pl-k\">=</span> []\n    all_hidden2_outputs <span class=\"pl-k\">=</span> []\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get the outputs before the ReLU.</span>\n    hidden1_outputs <span class=\"pl-k\">=</span> tf.get_default_graph().get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>hidden1/add:0<span class=\"pl-pds\">'</span></span>)\n    hidden2_outputs <span class=\"pl-k\">=</span> tf.get_default_graph().get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>hidden2/add:0<span class=\"pl-pds\">'</span></span>)\n  <span class=\"pl-k\">for</span> step <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(steps_per_epoch):\n    feed_dict <span class=\"pl-k\">=</span> fill_feed_dict(data_set,\n                               images_placeholder,\n                               labels_placeholder)\n    <span class=\"pl-k\">if</span> return_results:\n      all_images.append(feed_dict[images_placeholder])\n      all_labels.append(feed_dict[labels_placeholder])\n      curr_count, hidden1_output, hidden2_output <span class=\"pl-k\">=</span> sess.run(\n              [eval_correct, hidden1_outputs, hidden2_outputs],\n              <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict)\n      true_count <span class=\"pl-k\">+=</span> curr_count\n      all_hidden1_outputs.append(hidden1_output)\n      all_hidden2_outputs.append(hidden2_output)\n    <span class=\"pl-k\">else</span>:\n      true_count <span class=\"pl-k\">+=</span> sess.run(eval_correct, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict)\n  precision <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span>(true_count) <span class=\"pl-k\">/</span> num_examples\n  <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>  Num examples: <span class=\"pl-c1\">%d</span>  Num correct: <span class=\"pl-c1\">%d</span>  Precision @ 1: <span class=\"pl-c1\">%0.04f</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span>\n        (num_examples, true_count, precision))\n  <span class=\"pl-k\">if</span> return_results:\n    <span class=\"pl-k\">return</span> (all_images, all_labels, all_hidden1_outputs, all_hidden2_outputs)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">images_to_sprite</span>(<span class=\"pl-smi\">data</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Creates the sprite image along with any necessary padding</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">      data: NxHxW[x3] tensor containing the images.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">      data: Properly shaped HxWx3 image with any necessary padding.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(data.shape) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">3</span>:\n        data <span class=\"pl-k\">=</span> np.tile(data[<span class=\"pl-c1\">...</span>,np.newaxis], (<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>))\n    data <span class=\"pl-k\">=</span> data.astype(np.float32)\n    <span class=\"pl-c1\">min</span> <span class=\"pl-k\">=</span> np.min(data.reshape((data.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    data <span class=\"pl-k\">=</span> (data.transpose(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">0</span>) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">min</span>).transpose(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>)\n    <span class=\"pl-c1\">max</span> <span class=\"pl-k\">=</span> np.max(data.reshape((data.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    data <span class=\"pl-k\">=</span> (data.transpose(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">0</span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">max</span>).transpose(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Inverting the colors seems to look better for MNIST</span>\n    data <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> data\n\n    n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(np.ceil(np.sqrt(data.shape[<span class=\"pl-c1\">0</span>])))\n    padding <span class=\"pl-k\">=</span> ((<span class=\"pl-c1\">0</span>, n <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">-</span> data.shape[<span class=\"pl-c1\">0</span>]), (<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>),\n            (<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>)) <span class=\"pl-k\">+</span> ((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>),) <span class=\"pl-k\">*</span> (data.ndim <span class=\"pl-k\">-</span> <span class=\"pl-c1\">3</span>)\n    data <span class=\"pl-k\">=</span> np.pad(data, padding, <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>constant<span class=\"pl-pds\">'</span></span>,\n            <span class=\"pl-v\">constant_values</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Tile the individual thumbnails into an image.</span>\n    data <span class=\"pl-k\">=</span> data.reshape((n, n) <span class=\"pl-k\">+</span> data.shape[<span class=\"pl-c1\">1</span>:]).transpose((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>)\n            <span class=\"pl-k\">+</span> <span class=\"pl-c1\">tuple</span>(<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>, data.ndim <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)))\n    data <span class=\"pl-k\">=</span> data.reshape((n <span class=\"pl-k\">*</span> data.shape[<span class=\"pl-c1\">1</span>], n <span class=\"pl-k\">*</span> data.shape[<span class=\"pl-c1\">3</span>]) <span class=\"pl-k\">+</span> data.shape[<span class=\"pl-c1\">4</span>:])\n    data <span class=\"pl-k\">=</span> (data <span class=\"pl-k\">*</span> <span class=\"pl-c1\">255</span>).astype(np.uint8)\n    <span class=\"pl-k\">return</span> data\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run_training</span>():\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Train MNIST for a number of steps.<span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get the sets of images and labels for training, validation, and</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> test on MNIST.</span>\n  data_sets <span class=\"pl-k\">=</span> input_data.read_data_sets(<span class=\"pl-c1\">FLAGS</span>.input_data_dir, <span class=\"pl-c1\">FLAGS</span>.fake_data)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Tell TensorFlow that the model will be built into the default Graph.</span>\n  <span class=\"pl-k\">with</span> tf.Graph().as_default():\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Generate placeholders for the images and labels.</span>\n    images_placeholder, labels_placeholder <span class=\"pl-k\">=</span> placeholder_inputs(\n        <span class=\"pl-c1\">FLAGS</span>.batch_size)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build a Graph that computes predictions from the inference model.</span>\n    logits <span class=\"pl-k\">=</span> mnist.inference(images_placeholder,\n                             <span class=\"pl-c1\">FLAGS</span>.hidden1,\n                             <span class=\"pl-c1\">FLAGS</span>.hidden2)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add to the Graph the Ops for loss calculation.</span>\n    loss <span class=\"pl-k\">=</span> mnist.loss(logits, labels_placeholder)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add to the Graph the Ops that calculate and apply gradients.</span>\n    train_op <span class=\"pl-k\">=</span> mnist.training(loss, <span class=\"pl-c1\">FLAGS</span>.learning_rate)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the Op to compare the logits to the labels during evaluation.</span>\n    eval_correct <span class=\"pl-k\">=</span> mnist.evaluation(logits, labels_placeholder)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build the summary Tensor based on the TF collection of Summaries.</span>\n    summary <span class=\"pl-k\">=</span> tf.summary.merge_all()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Add the variable initializer Op.</span>\n    init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a saver for writing training checkpoints.</span>\n    saver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a session for running Ops on the Graph.</span>\n    sess <span class=\"pl-k\">=</span> tf.Session()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Instantiate a SummaryWriter to output summaries and the Graph.</span>\n    summary_writer <span class=\"pl-k\">=</span> tf.summary.FileWriter(<span class=\"pl-c1\">FLAGS</span>.log_dir, sess.graph)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> And then after everything is built:</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Run the Op to initialize the variables.</span>\n    sess.run(init)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Start the training loop.</span>\n    <span class=\"pl-k\">for</span> step <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">FLAGS</span>.max_steps):\n      start_time <span class=\"pl-k\">=</span> time.time()\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Fill a feed dictionary with the actual set of images and labels</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> for this particular training step.</span>\n      feed_dict <span class=\"pl-k\">=</span> fill_feed_dict(data_sets.train,\n                                 images_placeholder,\n                                 labels_placeholder)\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Run one step of the model.  The return values are the activations</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> from the `train_op` (which is discarded) and the `loss` Op.  To</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> inspect the values of your Ops or variables, you may include them</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> in the list passed to sess.run() and the value tensors will be</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> returned in the tuple from the call.</span>\n      _, loss_value <span class=\"pl-k\">=</span> sess.run([train_op, loss],\n                               <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict)\n\n      duration <span class=\"pl-k\">=</span> time.time() <span class=\"pl-k\">-</span> start_time\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Write the summaries and print an overview fairly often.</span>\n      <span class=\"pl-k\">if</span> step <span class=\"pl-k\">%</span> <span class=\"pl-c1\">100</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Print status to stdout.</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Step <span class=\"pl-c1\">%d</span>: loss = <span class=\"pl-c1\">%.2f</span> (<span class=\"pl-c1\">%.3f</span> sec)<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (step, loss_value, duration))\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Update the events file.</span>\n        summary_str <span class=\"pl-k\">=</span> sess.run(summary, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict)\n        summary_writer.add_summary(summary_str, step)\n        summary_writer.flush()\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save a checkpoint and evaluate the model periodically.</span>\n      <span class=\"pl-k\">if</span> (step <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">%</span> <span class=\"pl-c1\">1000</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">or</span> (step <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">FLAGS</span>.max_steps:\n        checkpoint_file <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.log_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.ckpt<span class=\"pl-pds\">'</span></span>)\n        saver.save(sess, checkpoint_file, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>step)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Evaluate against the training set.</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Training Data Eval:<span class=\"pl-pds\">'</span></span>)\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.train)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Evaluate against the validation set.</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Validation Data Eval:<span class=\"pl-pds\">'</span></span>)\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.validation)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Evaluate against the test set.</span>\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Test Data Eval:<span class=\"pl-pds\">'</span></span>)\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.test)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Compute embeddings and save them.</span>\n    thumbnail_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(np.sqrt(mnist.<span class=\"pl-c1\">IMAGE_PIXELS</span>))\n    <span class=\"pl-k\">for</span> data_set, name <span class=\"pl-k\">in</span> [\n            (data_sets.train, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>train<span class=\"pl-pds\">'</span></span>),\n            (data_sets.validation, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>validation<span class=\"pl-pds\">'</span></span>),\n            (data_sets.test, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>test<span class=\"pl-pds\">'</span></span>)]:\n      output_path <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.log_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>embed<span class=\"pl-pds\">'</span></span>, name)\n      <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Computing <span class=\"pl-c1\">%s</span> Embedding<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> name)\n      (all_images, all_labels, hidden1_vectors, hidden2_vectors) <span class=\"pl-k\">=</span> do_eval(\n              sess,\n              eval_correct,\n              images_placeholder,\n              labels_placeholder,\n              data_set,\n              <span class=\"pl-c1\">True</span>)\n      embed_tensors <span class=\"pl-k\">=</span> []\n      summary_writer <span class=\"pl-k\">=</span> tf.summary.FileWriter(output_path, sess.graph)\n      config <span class=\"pl-k\">=</span> projector.ProjectorConfig()\n      <span class=\"pl-k\">for</span> layer, embed_vectors <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>([hidden1_vectors, hidden2_vectors]):\n        embed_tensor <span class=\"pl-k\">=</span> tf.Variable(\n                np.array(embed_vectors).reshape(\n                    <span class=\"pl-c1\">len</span>(embed_vectors) <span class=\"pl-k\">*</span> embed_vectors[<span class=\"pl-c1\">0</span>].shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>),\n                <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>_layer_<span class=\"pl-c1\">%s</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (name, layer)))\n        embed_tensors.append(embed_tensor)\n        sess.run(embed_tensor.initializer)\n        embedding <span class=\"pl-k\">=</span> config.embeddings.add()\n        embedding.tensor_name <span class=\"pl-k\">=</span> embed_tensor.name\n        embedding.metadata_path <span class=\"pl-k\">=</span> os.path.join(output_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels.tsv<span class=\"pl-pds\">'</span></span>)\n        embedding.sprite.image_path <span class=\"pl-k\">=</span> os.path.join(output_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>sprite.png<span class=\"pl-pds\">'</span></span>)\n        embedding.sprite.single_image_dim.extend(\n                [thumbnail_size, thumbnail_size])\n        projector.visualize_embeddings(summary_writer, config)\n      result <span class=\"pl-k\">=</span> sess.run(embed_tensors)\n      saver <span class=\"pl-k\">=</span> tf.train.Saver(embed_tensors)\n      saver.save(sess, os.path.join(output_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.ckpt<span class=\"pl-pds\">'</span></span>), layer)\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Make sprite and labels.</span>\n      images <span class=\"pl-k\">=</span> np.array(all_images).reshape(\n              <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, thumbnail_size, thumbnail_size).astype(np.float32)\n      sprite <span class=\"pl-k\">=</span> images_to_sprite(images)\n      scipy.misc.imsave(os.path.join(output_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>sprite.png<span class=\"pl-pds\">'</span></span>), sprite)\n      all_labels <span class=\"pl-k\">=</span> np.array(all_labels).flatten()\n      metadata_file <span class=\"pl-k\">=</span> <span class=\"pl-c1\">open</span>(os.path.join(output_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels.tsv<span class=\"pl-pds\">'</span></span>), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>w<span class=\"pl-pds\">'</span></span>)\n      metadata_file.write(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Name<span class=\"pl-cce\">\\t</span>Class<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>)\n      <span class=\"pl-k\">for</span> ll <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">len</span>(all_labels)):\n        metadata_file.write(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%06d</span><span class=\"pl-cce\">\\t</span><span class=\"pl-c1\">%d</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (ll, all_labels[ll]))\n      metadata_file.close()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">_</span>):\n  <span class=\"pl-k\">if</span> tf.gfile.Exists(<span class=\"pl-c1\">FLAGS</span>.log_dir):\n    tf.gfile.DeleteRecursively(<span class=\"pl-c1\">FLAGS</span>.log_dir)\n  tf.gfile.MakeDirs(<span class=\"pl-c1\">FLAGS</span>.log_dir)\n  run_training()\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n  parser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--learning_rate<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">float</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.01</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Initial learning rate.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--max_steps<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2000</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Number of steps to run trainer.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--hidden1<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Number of units in hidden layer 1.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--hidden2<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Number of units in hidden layer 2.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--batch_size<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Batch size.  Must divide evenly into the dataset sizes.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--input_data_dir<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/tensorflow/mnist/input_data<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Directory to put the input data.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--log_dir<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/tensorflow/mnist/logs/fully_connected_feed<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Directory to put the log data.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--fake_data<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>If true, uses fake data for unit testing.<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">action</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>store_true<span class=\"pl-pds\">'</span></span>\n  )\n\n  <span class=\"pl-c1\">FLAGS</span>, unparsed <span class=\"pl-k\">=</span> parser.parse_known_args()\n  tf.app.run(<span class=\"pl-v\">main</span><span class=\"pl-k\">=</span>main, <span class=\"pl-v\">argv</span><span class=\"pl-k\">=</span>[sys.argv[<span class=\"pl-c1\">0</span>]] <span class=\"pl-k\">+</span> unparsed)</pre></div>", "body_text": "Sure. I started with the fully_connected_feed.py file and added in the necessary stuff. It seems to work for me. I tried to follow the Google style as best as I could. I even used comments! It requires Numpy and Scipy, but that isn't too much to ask.\n# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# @author: Daniel Gordon <xkcd@cs.washington.edu>\n#\n# ==============================================================================\n\n\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=missing-docstring\nimport argparse\nimport os.path\nimport sys\nimport time\n\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\nfrom tensorflow.contrib.tensorboard.plugins import projector\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.examples.tutorials.mnist import mnist\n\nimport numpy as np\nimport scipy.misc\n\n\n# Basic model parameters as external flags.\nFLAGS = None\n\n\ndef placeholder_inputs(batch_size):\n  \"\"\"Generate placeholder variables to represent the input tensors.\n\n  These placeholders are used as inputs by the rest of the model building\n  code and will be fed from the downloaded data in the .run() loop, below.\n\n  Args:\n    batch_size: The batch size will be baked into both placeholders.\n\n  Returns:\n    images_placeholder: Images placeholder.\n    labels_placeholder: Labels placeholder.\n  \"\"\"\n  # Note that the shapes of the placeholders match the shapes of the full\n  # image and label tensors, except the first dimension is now batch_size\n  # rather than the full size of the train or test data sets.\n  images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n                                                         mnist.IMAGE_PIXELS))\n  labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n  return images_placeholder, labels_placeholder\n\n\ndef fill_feed_dict(data_set, images_pl, labels_pl):\n  \"\"\"Fills the feed_dict for training the given step.\n\n  A feed_dict takes the form of:\n  feed_dict = {\n      <placeholder>: <tensor of values to be passed for placeholder>,\n      ....\n  }\n\n  Args:\n    data_set: The set of images and labels, from input_data.read_data_sets()\n    images_pl: The images placeholder, from placeholder_inputs().\n    labels_pl: The labels placeholder, from placeholder_inputs().\n\n  Returns:\n    feed_dict: The feed dictionary mapping from placeholders to values.\n  \"\"\"\n  # Create the feed_dict for the placeholders filled with the next\n  # `batch size` examples.\n  images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,\n                                                 FLAGS.fake_data)\n  feed_dict = {\n      images_pl: images_feed,\n      labels_pl: labels_feed,\n  }\n  return feed_dict\n\n\ndef do_eval(sess,\n            eval_correct,\n            images_placeholder,\n            labels_placeholder,\n            data_set,\n            return_results=False):\n  \"\"\"Runs one evaluation against the full epoch of data.\n\n  Args:\n    sess: The session in which the model has been trained.\n    eval_correct: The Tensor that returns the number of correct predictions.\n    images_placeholder: The images placeholder.\n    labels_placeholder: The labels placeholder.\n    data_set: The set of images and labels to evaluate, from\n      input_data.read_data_sets().\n    return_results: True if the results should be returned for the embedding.\n\n  Returns:\n    all_images: A list of batches of images.\n    all_labels: A list of batches of labels.\n    all_hidden1_outputs: A list of batches of embeddings from the first hidden\n      layer.\n    all_hidden2_outputs: A list of batches of embeddings from the second hidden\n      layer.\n  \"\"\"\n  # And run one epoch of eval.\n  true_count = 0  # Counts the number of correct predictions.\n  steps_per_epoch = data_set.num_examples // FLAGS.batch_size\n  num_examples = steps_per_epoch * FLAGS.batch_size\n  if return_results:\n    all_images = []\n    all_labels = []\n    all_hidden1_outputs = []\n    all_hidden2_outputs = []\n    # Get the outputs before the ReLU.\n    hidden1_outputs = tf.get_default_graph().get_tensor_by_name('hidden1/add:0')\n    hidden2_outputs = tf.get_default_graph().get_tensor_by_name('hidden2/add:0')\n  for step in xrange(steps_per_epoch):\n    feed_dict = fill_feed_dict(data_set,\n                               images_placeholder,\n                               labels_placeholder)\n    if return_results:\n      all_images.append(feed_dict[images_placeholder])\n      all_labels.append(feed_dict[labels_placeholder])\n      curr_count, hidden1_output, hidden2_output = sess.run(\n              [eval_correct, hidden1_outputs, hidden2_outputs],\n              feed_dict=feed_dict)\n      true_count += curr_count\n      all_hidden1_outputs.append(hidden1_output)\n      all_hidden2_outputs.append(hidden2_output)\n    else:\n      true_count += sess.run(eval_correct, feed_dict=feed_dict)\n  precision = float(true_count) / num_examples\n  print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n        (num_examples, true_count, precision))\n  if return_results:\n    return (all_images, all_labels, all_hidden1_outputs, all_hidden2_outputs)\n\n\ndef images_to_sprite(data):\n    \"\"\"Creates the sprite image along with any necessary padding\n\n    Args:\n      data: NxHxW[x3] tensor containing the images.\n\n    Returns:\n      data: Properly shaped HxWx3 image with any necessary padding.\n    \"\"\"\n    if len(data.shape) == 3:\n        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n    data = data.astype(np.float32)\n    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n    # Inverting the colors seems to look better for MNIST\n    data = 1 - data\n\n    n = int(np.ceil(np.sqrt(data.shape[0])))\n    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n    data = np.pad(data, padding, mode='constant',\n            constant_values=0)\n    # Tile the individual thumbnails into an image.\n    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n            + tuple(range(4, data.ndim + 1)))\n    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef run_training():\n  \"\"\"Train MNIST for a number of steps.\"\"\"\n  # Get the sets of images and labels for training, validation, and\n  # test on MNIST.\n  data_sets = input_data.read_data_sets(FLAGS.input_data_dir, FLAGS.fake_data)\n\n  # Tell TensorFlow that the model will be built into the default Graph.\n  with tf.Graph().as_default():\n    # Generate placeholders for the images and labels.\n    images_placeholder, labels_placeholder = placeholder_inputs(\n        FLAGS.batch_size)\n\n    # Build a Graph that computes predictions from the inference model.\n    logits = mnist.inference(images_placeholder,\n                             FLAGS.hidden1,\n                             FLAGS.hidden2)\n\n    # Add to the Graph the Ops for loss calculation.\n    loss = mnist.loss(logits, labels_placeholder)\n\n    # Add to the Graph the Ops that calculate and apply gradients.\n    train_op = mnist.training(loss, FLAGS.learning_rate)\n\n    # Add the Op to compare the logits to the labels during evaluation.\n    eval_correct = mnist.evaluation(logits, labels_placeholder)\n\n    # Build the summary Tensor based on the TF collection of Summaries.\n    summary = tf.summary.merge_all()\n\n    # Add the variable initializer Op.\n    init = tf.global_variables_initializer()\n\n    # Create a saver for writing training checkpoints.\n    saver = tf.train.Saver()\n\n    # Create a session for running Ops on the Graph.\n    sess = tf.Session()\n\n    # Instantiate a SummaryWriter to output summaries and the Graph.\n    summary_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n\n    # And then after everything is built:\n\n    # Run the Op to initialize the variables.\n    sess.run(init)\n\n    # Start the training loop.\n    for step in xrange(FLAGS.max_steps):\n      start_time = time.time()\n\n      # Fill a feed dictionary with the actual set of images and labels\n      # for this particular training step.\n      feed_dict = fill_feed_dict(data_sets.train,\n                                 images_placeholder,\n                                 labels_placeholder)\n\n      # Run one step of the model.  The return values are the activations\n      # from the `train_op` (which is discarded) and the `loss` Op.  To\n      # inspect the values of your Ops or variables, you may include them\n      # in the list passed to sess.run() and the value tensors will be\n      # returned in the tuple from the call.\n      _, loss_value = sess.run([train_op, loss],\n                               feed_dict=feed_dict)\n\n      duration = time.time() - start_time\n\n      # Write the summaries and print an overview fairly often.\n      if step % 100 == 0:\n        # Print status to stdout.\n        print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n        # Update the events file.\n        summary_str = sess.run(summary, feed_dict=feed_dict)\n        summary_writer.add_summary(summary_str, step)\n        summary_writer.flush()\n\n      # Save a checkpoint and evaluate the model periodically.\n      if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n        checkpoint_file = os.path.join(FLAGS.log_dir, 'model.ckpt')\n        saver.save(sess, checkpoint_file, global_step=step)\n        # Evaluate against the training set.\n        print('Training Data Eval:')\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.train)\n        # Evaluate against the validation set.\n        print('Validation Data Eval:')\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.validation)\n        # Evaluate against the test set.\n        print('Test Data Eval:')\n        do_eval(sess,\n                eval_correct,\n                images_placeholder,\n                labels_placeholder,\n                data_sets.test)\n\n    # Compute embeddings and save them.\n    thumbnail_size = int(np.sqrt(mnist.IMAGE_PIXELS))\n    for data_set, name in [\n            (data_sets.train, 'train'),\n            (data_sets.validation, 'validation'),\n            (data_sets.test, 'test')]:\n      output_path = os.path.join(FLAGS.log_dir, 'embed', name)\n      print('Computing %s Embedding' % name)\n      (all_images, all_labels, hidden1_vectors, hidden2_vectors) = do_eval(\n              sess,\n              eval_correct,\n              images_placeholder,\n              labels_placeholder,\n              data_set,\n              True)\n      embed_tensors = []\n      summary_writer = tf.summary.FileWriter(output_path, sess.graph)\n      config = projector.ProjectorConfig()\n      for layer, embed_vectors in enumerate([hidden1_vectors, hidden2_vectors]):\n        embed_tensor = tf.Variable(\n                np.array(embed_vectors).reshape(\n                    len(embed_vectors) * embed_vectors[0].shape[0], -1),\n                name=('%s_layer_%s' % (name, layer)))\n        embed_tensors.append(embed_tensor)\n        sess.run(embed_tensor.initializer)\n        embedding = config.embeddings.add()\n        embedding.tensor_name = embed_tensor.name\n        embedding.metadata_path = os.path.join(output_path, 'labels.tsv')\n        embedding.sprite.image_path = os.path.join(output_path, 'sprite.png')\n        embedding.sprite.single_image_dim.extend(\n                [thumbnail_size, thumbnail_size])\n        projector.visualize_embeddings(summary_writer, config)\n      result = sess.run(embed_tensors)\n      saver = tf.train.Saver(embed_tensors)\n      saver.save(sess, os.path.join(output_path, 'model.ckpt'), layer)\n\n      # Make sprite and labels.\n      images = np.array(all_images).reshape(\n              -1, thumbnail_size, thumbnail_size).astype(np.float32)\n      sprite = images_to_sprite(images)\n      scipy.misc.imsave(os.path.join(output_path, 'sprite.png'), sprite)\n      all_labels = np.array(all_labels).flatten()\n      metadata_file = open(os.path.join(output_path, 'labels.tsv'), 'w')\n      metadata_file.write('Name\\tClass\\n')\n      for ll in xrange(len(all_labels)):\n        metadata_file.write('%06d\\t%d\\n' % (ll, all_labels[ll]))\n      metadata_file.close()\n\ndef main(_):\n  if tf.gfile.Exists(FLAGS.log_dir):\n    tf.gfile.DeleteRecursively(FLAGS.log_dir)\n  tf.gfile.MakeDirs(FLAGS.log_dir)\n  run_training()\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--learning_rate',\n      type=float,\n      default=0.01,\n      help='Initial learning rate.'\n  )\n  parser.add_argument(\n      '--max_steps',\n      type=int,\n      default=2000,\n      help='Number of steps to run trainer.'\n  )\n  parser.add_argument(\n      '--hidden1',\n      type=int,\n      default=128,\n      help='Number of units in hidden layer 1.'\n  )\n  parser.add_argument(\n      '--hidden2',\n      type=int,\n      default=32,\n      help='Number of units in hidden layer 2.'\n  )\n  parser.add_argument(\n      '--batch_size',\n      type=int,\n      default=100,\n      help='Batch size.  Must divide evenly into the dataset sizes.'\n  )\n  parser.add_argument(\n      '--input_data_dir',\n      type=str,\n      default='/tmp/tensorflow/mnist/input_data',\n      help='Directory to put the input data.'\n  )\n  parser.add_argument(\n      '--log_dir',\n      type=str,\n      default='/tmp/tensorflow/mnist/logs/fully_connected_feed',\n      help='Directory to put the log data.'\n  )\n  parser.add_argument(\n      '--fake_data',\n      default=False,\n      help='If true, uses fake data for unit testing.',\n      action='store_true'\n  )\n\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)", "body": "Sure. I started with the fully_connected_feed.py file and added in the necessary stuff. It seems to work for me. I tried to follow the Google style as best as I could. I even used comments! It requires Numpy and Scipy, but that isn't too much to ask.\r\n\r\n```python\r\n# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n#\r\n# @author: Daniel Gordon <xkcd@cs.washington.edu>\r\n#\r\n# ==============================================================================\r\n\r\n\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\n# pylint: disable=missing-docstring\r\nimport argparse\r\nimport os.path\r\nimport sys\r\nimport time\r\n\r\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.contrib.tensorboard.plugins import projector\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nfrom tensorflow.examples.tutorials.mnist import mnist\r\n\r\nimport numpy as np\r\nimport scipy.misc\r\n\r\n\r\n# Basic model parameters as external flags.\r\nFLAGS = None\r\n\r\n\r\ndef placeholder_inputs(batch_size):\r\n  \"\"\"Generate placeholder variables to represent the input tensors.\r\n\r\n  These placeholders are used as inputs by the rest of the model building\r\n  code and will be fed from the downloaded data in the .run() loop, below.\r\n\r\n  Args:\r\n    batch_size: The batch size will be baked into both placeholders.\r\n\r\n  Returns:\r\n    images_placeholder: Images placeholder.\r\n    labels_placeholder: Labels placeholder.\r\n  \"\"\"\r\n  # Note that the shapes of the placeholders match the shapes of the full\r\n  # image and label tensors, except the first dimension is now batch_size\r\n  # rather than the full size of the train or test data sets.\r\n  images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\r\n                                                         mnist.IMAGE_PIXELS))\r\n  labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\r\n  return images_placeholder, labels_placeholder\r\n\r\n\r\ndef fill_feed_dict(data_set, images_pl, labels_pl):\r\n  \"\"\"Fills the feed_dict for training the given step.\r\n\r\n  A feed_dict takes the form of:\r\n  feed_dict = {\r\n      <placeholder>: <tensor of values to be passed for placeholder>,\r\n      ....\r\n  }\r\n\r\n  Args:\r\n    data_set: The set of images and labels, from input_data.read_data_sets()\r\n    images_pl: The images placeholder, from placeholder_inputs().\r\n    labels_pl: The labels placeholder, from placeholder_inputs().\r\n\r\n  Returns:\r\n    feed_dict: The feed dictionary mapping from placeholders to values.\r\n  \"\"\"\r\n  # Create the feed_dict for the placeholders filled with the next\r\n  # `batch size` examples.\r\n  images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,\r\n                                                 FLAGS.fake_data)\r\n  feed_dict = {\r\n      images_pl: images_feed,\r\n      labels_pl: labels_feed,\r\n  }\r\n  return feed_dict\r\n\r\n\r\ndef do_eval(sess,\r\n            eval_correct,\r\n            images_placeholder,\r\n            labels_placeholder,\r\n            data_set,\r\n            return_results=False):\r\n  \"\"\"Runs one evaluation against the full epoch of data.\r\n\r\n  Args:\r\n    sess: The session in which the model has been trained.\r\n    eval_correct: The Tensor that returns the number of correct predictions.\r\n    images_placeholder: The images placeholder.\r\n    labels_placeholder: The labels placeholder.\r\n    data_set: The set of images and labels to evaluate, from\r\n      input_data.read_data_sets().\r\n    return_results: True if the results should be returned for the embedding.\r\n\r\n  Returns:\r\n    all_images: A list of batches of images.\r\n    all_labels: A list of batches of labels.\r\n    all_hidden1_outputs: A list of batches of embeddings from the first hidden\r\n      layer.\r\n    all_hidden2_outputs: A list of batches of embeddings from the second hidden\r\n      layer.\r\n  \"\"\"\r\n  # And run one epoch of eval.\r\n  true_count = 0  # Counts the number of correct predictions.\r\n  steps_per_epoch = data_set.num_examples // FLAGS.batch_size\r\n  num_examples = steps_per_epoch * FLAGS.batch_size\r\n  if return_results:\r\n    all_images = []\r\n    all_labels = []\r\n    all_hidden1_outputs = []\r\n    all_hidden2_outputs = []\r\n    # Get the outputs before the ReLU.\r\n    hidden1_outputs = tf.get_default_graph().get_tensor_by_name('hidden1/add:0')\r\n    hidden2_outputs = tf.get_default_graph().get_tensor_by_name('hidden2/add:0')\r\n  for step in xrange(steps_per_epoch):\r\n    feed_dict = fill_feed_dict(data_set,\r\n                               images_placeholder,\r\n                               labels_placeholder)\r\n    if return_results:\r\n      all_images.append(feed_dict[images_placeholder])\r\n      all_labels.append(feed_dict[labels_placeholder])\r\n      curr_count, hidden1_output, hidden2_output = sess.run(\r\n              [eval_correct, hidden1_outputs, hidden2_outputs],\r\n              feed_dict=feed_dict)\r\n      true_count += curr_count\r\n      all_hidden1_outputs.append(hidden1_output)\r\n      all_hidden2_outputs.append(hidden2_output)\r\n    else:\r\n      true_count += sess.run(eval_correct, feed_dict=feed_dict)\r\n  precision = float(true_count) / num_examples\r\n  print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\r\n        (num_examples, true_count, precision))\r\n  if return_results:\r\n    return (all_images, all_labels, all_hidden1_outputs, all_hidden2_outputs)\r\n\r\n\r\ndef images_to_sprite(data):\r\n    \"\"\"Creates the sprite image along with any necessary padding\r\n\r\n    Args:\r\n      data: NxHxW[x3] tensor containing the images.\r\n\r\n    Returns:\r\n      data: Properly shaped HxWx3 image with any necessary padding.\r\n    \"\"\"\r\n    if len(data.shape) == 3:\r\n        data = np.tile(data[...,np.newaxis], (1,1,1,3))\r\n    data = data.astype(np.float32)\r\n    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\r\n    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\r\n    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\r\n    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\r\n    # Inverting the colors seems to look better for MNIST\r\n    data = 1 - data\r\n\r\n    n = int(np.ceil(np.sqrt(data.shape[0])))\r\n    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\r\n            (0, 0)) + ((0, 0),) * (data.ndim - 3)\r\n    data = np.pad(data, padding, mode='constant',\r\n            constant_values=0)\r\n    # Tile the individual thumbnails into an image.\r\n    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\r\n            + tuple(range(4, data.ndim + 1)))\r\n    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\r\n    data = (data * 255).astype(np.uint8)\r\n    return data\r\n\r\ndef run_training():\r\n  \"\"\"Train MNIST for a number of steps.\"\"\"\r\n  # Get the sets of images and labels for training, validation, and\r\n  # test on MNIST.\r\n  data_sets = input_data.read_data_sets(FLAGS.input_data_dir, FLAGS.fake_data)\r\n\r\n  # Tell TensorFlow that the model will be built into the default Graph.\r\n  with tf.Graph().as_default():\r\n    # Generate placeholders for the images and labels.\r\n    images_placeholder, labels_placeholder = placeholder_inputs(\r\n        FLAGS.batch_size)\r\n\r\n    # Build a Graph that computes predictions from the inference model.\r\n    logits = mnist.inference(images_placeholder,\r\n                             FLAGS.hidden1,\r\n                             FLAGS.hidden2)\r\n\r\n    # Add to the Graph the Ops for loss calculation.\r\n    loss = mnist.loss(logits, labels_placeholder)\r\n\r\n    # Add to the Graph the Ops that calculate and apply gradients.\r\n    train_op = mnist.training(loss, FLAGS.learning_rate)\r\n\r\n    # Add the Op to compare the logits to the labels during evaluation.\r\n    eval_correct = mnist.evaluation(logits, labels_placeholder)\r\n\r\n    # Build the summary Tensor based on the TF collection of Summaries.\r\n    summary = tf.summary.merge_all()\r\n\r\n    # Add the variable initializer Op.\r\n    init = tf.global_variables_initializer()\r\n\r\n    # Create a saver for writing training checkpoints.\r\n    saver = tf.train.Saver()\r\n\r\n    # Create a session for running Ops on the Graph.\r\n    sess = tf.Session()\r\n\r\n    # Instantiate a SummaryWriter to output summaries and the Graph.\r\n    summary_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\r\n\r\n    # And then after everything is built:\r\n\r\n    # Run the Op to initialize the variables.\r\n    sess.run(init)\r\n\r\n    # Start the training loop.\r\n    for step in xrange(FLAGS.max_steps):\r\n      start_time = time.time()\r\n\r\n      # Fill a feed dictionary with the actual set of images and labels\r\n      # for this particular training step.\r\n      feed_dict = fill_feed_dict(data_sets.train,\r\n                                 images_placeholder,\r\n                                 labels_placeholder)\r\n\r\n      # Run one step of the model.  The return values are the activations\r\n      # from the `train_op` (which is discarded) and the `loss` Op.  To\r\n      # inspect the values of your Ops or variables, you may include them\r\n      # in the list passed to sess.run() and the value tensors will be\r\n      # returned in the tuple from the call.\r\n      _, loss_value = sess.run([train_op, loss],\r\n                               feed_dict=feed_dict)\r\n\r\n      duration = time.time() - start_time\r\n\r\n      # Write the summaries and print an overview fairly often.\r\n      if step % 100 == 0:\r\n        # Print status to stdout.\r\n        print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\r\n        # Update the events file.\r\n        summary_str = sess.run(summary, feed_dict=feed_dict)\r\n        summary_writer.add_summary(summary_str, step)\r\n        summary_writer.flush()\r\n\r\n      # Save a checkpoint and evaluate the model periodically.\r\n      if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:\r\n        checkpoint_file = os.path.join(FLAGS.log_dir, 'model.ckpt')\r\n        saver.save(sess, checkpoint_file, global_step=step)\r\n        # Evaluate against the training set.\r\n        print('Training Data Eval:')\r\n        do_eval(sess,\r\n                eval_correct,\r\n                images_placeholder,\r\n                labels_placeholder,\r\n                data_sets.train)\r\n        # Evaluate against the validation set.\r\n        print('Validation Data Eval:')\r\n        do_eval(sess,\r\n                eval_correct,\r\n                images_placeholder,\r\n                labels_placeholder,\r\n                data_sets.validation)\r\n        # Evaluate against the test set.\r\n        print('Test Data Eval:')\r\n        do_eval(sess,\r\n                eval_correct,\r\n                images_placeholder,\r\n                labels_placeholder,\r\n                data_sets.test)\r\n\r\n    # Compute embeddings and save them.\r\n    thumbnail_size = int(np.sqrt(mnist.IMAGE_PIXELS))\r\n    for data_set, name in [\r\n            (data_sets.train, 'train'),\r\n            (data_sets.validation, 'validation'),\r\n            (data_sets.test, 'test')]:\r\n      output_path = os.path.join(FLAGS.log_dir, 'embed', name)\r\n      print('Computing %s Embedding' % name)\r\n      (all_images, all_labels, hidden1_vectors, hidden2_vectors) = do_eval(\r\n              sess,\r\n              eval_correct,\r\n              images_placeholder,\r\n              labels_placeholder,\r\n              data_set,\r\n              True)\r\n      embed_tensors = []\r\n      summary_writer = tf.summary.FileWriter(output_path, sess.graph)\r\n      config = projector.ProjectorConfig()\r\n      for layer, embed_vectors in enumerate([hidden1_vectors, hidden2_vectors]):\r\n        embed_tensor = tf.Variable(\r\n                np.array(embed_vectors).reshape(\r\n                    len(embed_vectors) * embed_vectors[0].shape[0], -1),\r\n                name=('%s_layer_%s' % (name, layer)))\r\n        embed_tensors.append(embed_tensor)\r\n        sess.run(embed_tensor.initializer)\r\n        embedding = config.embeddings.add()\r\n        embedding.tensor_name = embed_tensor.name\r\n        embedding.metadata_path = os.path.join(output_path, 'labels.tsv')\r\n        embedding.sprite.image_path = os.path.join(output_path, 'sprite.png')\r\n        embedding.sprite.single_image_dim.extend(\r\n                [thumbnail_size, thumbnail_size])\r\n        projector.visualize_embeddings(summary_writer, config)\r\n      result = sess.run(embed_tensors)\r\n      saver = tf.train.Saver(embed_tensors)\r\n      saver.save(sess, os.path.join(output_path, 'model.ckpt'), layer)\r\n\r\n      # Make sprite and labels.\r\n      images = np.array(all_images).reshape(\r\n              -1, thumbnail_size, thumbnail_size).astype(np.float32)\r\n      sprite = images_to_sprite(images)\r\n      scipy.misc.imsave(os.path.join(output_path, 'sprite.png'), sprite)\r\n      all_labels = np.array(all_labels).flatten()\r\n      metadata_file = open(os.path.join(output_path, 'labels.tsv'), 'w')\r\n      metadata_file.write('Name\\tClass\\n')\r\n      for ll in xrange(len(all_labels)):\r\n        metadata_file.write('%06d\\t%d\\n' % (ll, all_labels[ll]))\r\n      metadata_file.close()\r\n\r\ndef main(_):\r\n  if tf.gfile.Exists(FLAGS.log_dir):\r\n    tf.gfile.DeleteRecursively(FLAGS.log_dir)\r\n  tf.gfile.MakeDirs(FLAGS.log_dir)\r\n  run_training()\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--learning_rate',\r\n      type=float,\r\n      default=0.01,\r\n      help='Initial learning rate.'\r\n  )\r\n  parser.add_argument(\r\n      '--max_steps',\r\n      type=int,\r\n      default=2000,\r\n      help='Number of steps to run trainer.'\r\n  )\r\n  parser.add_argument(\r\n      '--hidden1',\r\n      type=int,\r\n      default=128,\r\n      help='Number of units in hidden layer 1.'\r\n  )\r\n  parser.add_argument(\r\n      '--hidden2',\r\n      type=int,\r\n      default=32,\r\n      help='Number of units in hidden layer 2.'\r\n  )\r\n  parser.add_argument(\r\n      '--batch_size',\r\n      type=int,\r\n      default=100,\r\n      help='Batch size.  Must divide evenly into the dataset sizes.'\r\n  )\r\n  parser.add_argument(\r\n      '--input_data_dir',\r\n      type=str,\r\n      default='/tmp/tensorflow/mnist/input_data',\r\n      help='Directory to put the input data.'\r\n  )\r\n  parser.add_argument(\r\n      '--log_dir',\r\n      type=str,\r\n      default='/tmp/tensorflow/mnist/logs/fully_connected_feed',\r\n      help='Directory to put the log data.'\r\n  )\r\n  parser.add_argument(\r\n      '--fake_data',\r\n      default=False,\r\n      help='If true, uses fake data for unit testing.',\r\n      action='store_true'\r\n  )\r\n\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```"}