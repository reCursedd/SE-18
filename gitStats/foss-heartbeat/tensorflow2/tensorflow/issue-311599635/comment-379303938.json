{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/379303938", "html_url": "https://github.com/tensorflow/tensorflow/issues/18260#issuecomment-379303938", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18260", "id": 379303938, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTMwMzkzOA==", "user": {"login": "Pyrestone", "id": 20396757, "node_id": "MDQ6VXNlcjIwMzk2NzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/20396757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pyrestone", "html_url": "https://github.com/Pyrestone", "followers_url": "https://api.github.com/users/Pyrestone/followers", "following_url": "https://api.github.com/users/Pyrestone/following{/other_user}", "gists_url": "https://api.github.com/users/Pyrestone/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pyrestone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pyrestone/subscriptions", "organizations_url": "https://api.github.com/users/Pyrestone/orgs", "repos_url": "https://api.github.com/users/Pyrestone/repos", "events_url": "https://api.github.com/users/Pyrestone/events{/privacy}", "received_events_url": "https://api.github.com/users/Pyrestone/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-06T16:20:18Z", "updated_at": "2018-04-06T16:22:29Z", "author_association": "NONE", "body_html": "<p>Here's how to check if anyone's interested:</p>\n<details><p>\n  </p><summary>Click to expand</summary>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\ncontrib_data<span class=\"pl-k\">=</span>tf.contrib.data\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\ncp<span class=\"pl-k\">=</span>tf.ConfigProto()\ncp.allow_soft_placement<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\ncp.gpu_options.allow_growth<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\ncp.log_device_placement<span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>\ntf.enable_eager_execution(cp)\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>#GPU Version</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>generate some large dummy values</span>\nds<span class=\"pl-k\">=</span>tf.data.Dataset.range(<span class=\"pl-c1\">100000</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">64</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">20</span>)\nds<span class=\"pl-k\">=</span>ds.batch(<span class=\"pl-c1\">100000</span>)\nds<span class=\"pl-k\">=</span>ds.map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: tf.reshape(x,(<span class=\"pl-c1\">100000</span>,)))\nds<span class=\"pl-k\">=</span>ds.batch(<span class=\"pl-c1\">64</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>cache them to not be input-bound</span>\nds<span class=\"pl-k\">=</span>ds.cache(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>)\nds<span class=\"pl-k\">=</span>ds.repeat(<span class=\"pl-c1\">1000</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>prefetch on CPU</span>\nds<span class=\"pl-k\">=</span>ds.prefetch(<span class=\"pl-c1\">5</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>create Iterator on GPU</span>\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:1<span class=\"pl-pds\">\"</span></span>):\n    it<span class=\"pl-k\">=</span>tfe.Iterator(ds)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>make sure all batches are cached </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>so it's not bound anywhere else    </span>\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">20</span>):\n    <span class=\"pl-c1\">next</span>(it)\n\nmt<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\nnt<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\nt<span class=\"pl-k\">=</span>time.time()\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:1<span class=\"pl-pds\">\"</span></span>):\n    <span class=\"pl-k\">for</span> c <span class=\"pl-k\">in</span> it:\n        o<span class=\"pl-k\">=</span>c<span class=\"pl-k\">*</span>c\n        nt<span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\nmt<span class=\"pl-k\">=</span>time.time()<span class=\"pl-k\">-</span>t\n<span class=\"pl-c1\">print</span>(mt<span class=\"pl-k\">/</span>nt)<span class=\"pl-c\"><span class=\"pl-c\">#</span>&gt;&gt;&gt;0.01107s/batch</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>#CPU Version</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>generate some large dummy values</span>\nds<span class=\"pl-k\">=</span>tf.data.Dataset.range(<span class=\"pl-c1\">100000</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">64</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">20</span>)\nds<span class=\"pl-k\">=</span>ds.batch(<span class=\"pl-c1\">100000</span>)\nds<span class=\"pl-k\">=</span>ds.map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: tf.reshape(x,(<span class=\"pl-c1\">100000</span>,)))\nds<span class=\"pl-k\">=</span>ds.batch(<span class=\"pl-c1\">64</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>cache them to not be input-bound</span>\nds<span class=\"pl-k\">=</span>ds.cache(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>)\nds<span class=\"pl-k\">=</span>ds.repeat(<span class=\"pl-c1\">1000</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>prefetch on CPU</span>\nds<span class=\"pl-k\">=</span>ds.prefetch(<span class=\"pl-c1\">5</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>create Iterator on CPU</span>\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/cpu:0<span class=\"pl-pds\">\"</span></span>):\n    it<span class=\"pl-k\">=</span>tfe.Iterator(ds)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>make sure all batches are cached </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>so it's not bound anywhere else    </span>\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">20</span>):\n    <span class=\"pl-c1\">next</span>(it)\n\nmt<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\nnt<span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>\nt<span class=\"pl-k\">=</span>time.time()\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:1<span class=\"pl-pds\">\"</span></span>):\n    <span class=\"pl-k\">for</span> c <span class=\"pl-k\">in</span> it:\n        o<span class=\"pl-k\">=</span>c<span class=\"pl-k\">*</span>c\n        nt<span class=\"pl-k\">+=</span><span class=\"pl-c1\">1</span>\nmt<span class=\"pl-k\">=</span>time.time()<span class=\"pl-k\">-</span>t\n<span class=\"pl-c1\">print</span>(mt<span class=\"pl-k\">/</span>nt)<span class=\"pl-c\"><span class=\"pl-c\">#</span>&gt;&gt;0.02176s/batch</span></pre></div>\n<p></p>\n</details>", "body_text": "Here's how to check if anyone's interested:\n\n  Click to expand\nimport tensorflow as tf\ncontrib_data=tf.contrib.data\nimport tensorflow.contrib.eager as tfe\ncp=tf.ConfigProto()\ncp.allow_soft_placement=True\ncp.gpu_options.allow_growth=True\ncp.log_device_placement=False\ntf.enable_eager_execution(cp)\nimport time\n\n##GPU Version\n\n#generate some large dummy values\nds=tf.data.Dataset.range(100000*64*20)\nds=ds.batch(100000)\nds=ds.map(lambda x: tf.reshape(x,(100000,)))\nds=ds.batch(64)\n#cache them to not be input-bound\nds=ds.cache('')\nds=ds.repeat(1000)\n#prefetch on CPU\nds=ds.prefetch(5)\n\n#create Iterator on GPU\nwith tf.device(\"/gpu:1\"):\n    it=tfe.Iterator(ds)\n\n#make sure all batches are cached \n#so it's not bound anywhere else    \nfor i in range(20):\n    next(it)\n\nmt=0\nnt=0\nt=time.time()\nwith tf.device(\"/gpu:1\"):\n    for c in it:\n        o=c*c\n        nt+=1\nmt=time.time()-t\nprint(mt/nt)#>>>0.01107s/batch\n\n##CPU Version\n\n#generate some large dummy values\nds=tf.data.Dataset.range(100000*64*20)\nds=ds.batch(100000)\nds=ds.map(lambda x: tf.reshape(x,(100000,)))\nds=ds.batch(64)\n#cache them to not be input-bound\nds=ds.cache('')\nds=ds.repeat(1000)\n#prefetch on CPU\nds=ds.prefetch(5)\n\n#create Iterator on CPU\nwith tf.device(\"/cpu:0\"):\n    it=tfe.Iterator(ds)\n\n#make sure all batches are cached \n#so it's not bound anywhere else    \nfor i in range(20):\n    next(it)\n\nmt=0\nnt=0\nt=time.time()\nwith tf.device(\"/gpu:1\"):\n    for c in it:\n        o=c*c\n        nt+=1\nmt=time.time()-t\nprint(mt/nt)#>>0.02176s/batch", "body": "Here's how to check if anyone's interested:\r\n<details><p>\r\n  <summary>Click to expand</summary>\r\n\r\n```python\r\nimport tensorflow as tf\r\ncontrib_data=tf.contrib.data\r\nimport tensorflow.contrib.eager as tfe\r\ncp=tf.ConfigProto()\r\ncp.allow_soft_placement=True\r\ncp.gpu_options.allow_growth=True\r\ncp.log_device_placement=False\r\ntf.enable_eager_execution(cp)\r\nimport time\r\n\r\n##GPU Version\r\n\r\n#generate some large dummy values\r\nds=tf.data.Dataset.range(100000*64*20)\r\nds=ds.batch(100000)\r\nds=ds.map(lambda x: tf.reshape(x,(100000,)))\r\nds=ds.batch(64)\r\n#cache them to not be input-bound\r\nds=ds.cache('')\r\nds=ds.repeat(1000)\r\n#prefetch on CPU\r\nds=ds.prefetch(5)\r\n\r\n#create Iterator on GPU\r\nwith tf.device(\"/gpu:1\"):\r\n    it=tfe.Iterator(ds)\r\n\r\n#make sure all batches are cached \r\n#so it's not bound anywhere else    \r\nfor i in range(20):\r\n    next(it)\r\n\r\nmt=0\r\nnt=0\r\nt=time.time()\r\nwith tf.device(\"/gpu:1\"):\r\n    for c in it:\r\n        o=c*c\r\n        nt+=1\r\nmt=time.time()-t\r\nprint(mt/nt)#>>>0.01107s/batch\r\n\r\n##CPU Version\r\n\r\n#generate some large dummy values\r\nds=tf.data.Dataset.range(100000*64*20)\r\nds=ds.batch(100000)\r\nds=ds.map(lambda x: tf.reshape(x,(100000,)))\r\nds=ds.batch(64)\r\n#cache them to not be input-bound\r\nds=ds.cache('')\r\nds=ds.repeat(1000)\r\n#prefetch on CPU\r\nds=ds.prefetch(5)\r\n\r\n#create Iterator on CPU\r\nwith tf.device(\"/cpu:0\"):\r\n    it=tfe.Iterator(ds)\r\n\r\n#make sure all batches are cached \r\n#so it's not bound anywhere else    \r\nfor i in range(20):\r\n    next(it)\r\n\r\nmt=0\r\nnt=0\r\nt=time.time()\r\nwith tf.device(\"/gpu:1\"):\r\n    for c in it:\r\n        o=c*c\r\n        nt+=1\r\nmt=time.time()-t\r\nprint(mt/nt)#>>0.02176s/batch\r\n```\r\n</p>\r\n</details>"}