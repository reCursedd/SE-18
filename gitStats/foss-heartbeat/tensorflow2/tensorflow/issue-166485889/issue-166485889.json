{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3402", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3402/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3402/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3402/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3402", "id": 166485889, "node_id": "MDU6SXNzdWUxNjY0ODU4ODk=", "number": 3402, "title": "Given one input tensor, why tf.nn.max_pool generate two tensors?", "user": {"login": "leihe001", "id": 20062851, "node_id": "MDQ6VXNlcjIwMDYyODUx", "avatar_url": "https://avatars0.githubusercontent.com/u/20062851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leihe001", "html_url": "https://github.com/leihe001", "followers_url": "https://api.github.com/users/leihe001/followers", "following_url": "https://api.github.com/users/leihe001/following{/other_user}", "gists_url": "https://api.github.com/users/leihe001/gists{/gist_id}", "starred_url": "https://api.github.com/users/leihe001/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leihe001/subscriptions", "organizations_url": "https://api.github.com/users/leihe001/orgs", "repos_url": "https://api.github.com/users/leihe001/repos", "events_url": "https://api.github.com/users/leihe001/events{/privacy}", "received_events_url": "https://api.github.com/users/leihe001/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-07-20T03:19:02Z", "updated_at": "2016-07-22T21:36:47Z", "closed_at": "2016-07-22T21:36:47Z", "author_association": "NONE", "body_html": "<p>with tf.name_scope('layer3'):<br>\nconv3_weights = tf.Variable(tf.truncated_normal(<br>\n[3, 3, 128, 256], stddev=0.1))<br>\nvariable_summaries(conv3_weights, 'layer3' + '/weights')<br>\nconv3_biases = tf.Variable(tf.constant(0.1, shape=[256]))<br>\nvariable_summaries(conv3_biases, 'layer3' + '/biases')<br>\nconv3 = tf.nn.conv2d(pool2,<br>\nconv3_weights,<br>\nstrides=[1, 1, 1, 1],<br>\npadding='SAME')<br>\ntf.histogram_summary('layer3'+'/pre_activations', conv3)<br>\nrelu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))<br>\ntf.histogram_summary('layer3'+'/activations', relu3)<br>\nprint relu3.get_shape()<br>\npool3 = tf.nn.max_pool(relu3,<br>\nksize=[1, 2, 2, 1],<br>\nstrides=[1, 2, 2, 1],<br>\npadding='SAME')<br>\ntf.histogram_summary('layer3'+'/pool', pool3)<br>\nprint pool3.get_shape()</p>\n<p>When using TensorBoard to visualize the graph, I find the output of the layer3 are two tensors. I am puzzled why does it happen? Thank you very much!<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/20062851/16974093/b96aee78-4e6b-11e6-97c5-c266b4dc28d8.jpg\"><img src=\"https://cloud.githubusercontent.com/assets/20062851/16974093/b96aee78-4e6b-11e6-97c5-c266b4dc28d8.jpg\" alt=\"1\" style=\"max-width:100%;\"></a></p>", "body_text": "with tf.name_scope('layer3'):\nconv3_weights = tf.Variable(tf.truncated_normal(\n[3, 3, 128, 256], stddev=0.1))\nvariable_summaries(conv3_weights, 'layer3' + '/weights')\nconv3_biases = tf.Variable(tf.constant(0.1, shape=[256]))\nvariable_summaries(conv3_biases, 'layer3' + '/biases')\nconv3 = tf.nn.conv2d(pool2,\nconv3_weights,\nstrides=[1, 1, 1, 1],\npadding='SAME')\ntf.histogram_summary('layer3'+'/pre_activations', conv3)\nrelu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))\ntf.histogram_summary('layer3'+'/activations', relu3)\nprint relu3.get_shape()\npool3 = tf.nn.max_pool(relu3,\nksize=[1, 2, 2, 1],\nstrides=[1, 2, 2, 1],\npadding='SAME')\ntf.histogram_summary('layer3'+'/pool', pool3)\nprint pool3.get_shape()\nWhen using TensorBoard to visualize the graph, I find the output of the layer3 are two tensors. I am puzzled why does it happen? Thank you very much!", "body": "  with tf.name_scope('layer3'):\n    conv3_weights = tf.Variable(tf.truncated_normal(\n      [3, 3, 128, 256], stddev=0.1))\n    variable_summaries(conv3_weights, 'layer3' + '/weights')\n    conv3_biases = tf.Variable(tf.constant(0.1, shape=[256]))\n    variable_summaries(conv3_biases, 'layer3' + '/biases')\n    conv3 = tf.nn.conv2d(pool2,\n      conv3_weights,\n      strides=[1, 1, 1, 1],\n      padding='SAME')\n    tf.histogram_summary('layer3'+'/pre_activations', conv3)\n    relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))\n    tf.histogram_summary('layer3'+'/activations', relu3)\n    print relu3.get_shape()\n    pool3 = tf.nn.max_pool(relu3,\n      ksize=[1, 2, 2, 1],\n      strides=[1, 2, 2, 1],\n      padding='SAME')\n    tf.histogram_summary('layer3'+'/pool', pool3)\n    print pool3.get_shape()\n\nWhen using TensorBoard to visualize the graph, I find the output of the layer3 are two tensors. I am puzzled why does it happen? Thank you very much! \n![1](https://cloud.githubusercontent.com/assets/20062851/16974093/b96aee78-4e6b-11e6-97c5-c266b4dc28d8.jpg)\n"}