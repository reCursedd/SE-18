{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17400", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17400/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17400/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17400/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17400", "id": 302008545, "node_id": "MDU6SXNzdWUzMDIwMDg1NDU=", "number": 17400, "title": "Eager: Allowing GPU memory growth", "user": {"login": "nostringattached", "id": 30821244, "node_id": "MDQ6VXNlcjMwODIxMjQ0", "avatar_url": "https://avatars3.githubusercontent.com/u/30821244?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nostringattached", "html_url": "https://github.com/nostringattached", "followers_url": "https://api.github.com/users/nostringattached/followers", "following_url": "https://api.github.com/users/nostringattached/following{/other_user}", "gists_url": "https://api.github.com/users/nostringattached/gists{/gist_id}", "starred_url": "https://api.github.com/users/nostringattached/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nostringattached/subscriptions", "organizations_url": "https://api.github.com/users/nostringattached/orgs", "repos_url": "https://api.github.com/users/nostringattached/repos", "events_url": "https://api.github.com/users/nostringattached/events{/privacy}", "received_events_url": "https://api.github.com/users/nostringattached/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-03T15:52:35Z", "updated_at": "2018-03-04T06:42:14Z", "closed_at": "2018-03-04T06:42:14Z", "author_association": "NONE", "body_html": "<p>Since we don't have session in eager mode, how can we allocate only as much GPU memory as needed in our program?</p>\n<p>Or can we set the fraction of the overall amount of memory that each visible GPU should be allocated?</p>\n<p>When will this feature be supported?</p>", "body_text": "Since we don't have session in eager mode, how can we allocate only as much GPU memory as needed in our program?\nOr can we set the fraction of the overall amount of memory that each visible GPU should be allocated?\nWhen will this feature be supported?", "body": "Since we don't have session in eager mode, how can we allocate only as much GPU memory as needed in our program?\r\n\r\nOr can we set the fraction of the overall amount of memory that each visible GPU should be allocated?\r\n\r\nWhen will this feature be supported?"}