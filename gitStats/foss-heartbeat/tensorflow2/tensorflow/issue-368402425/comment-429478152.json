{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429478152", "html_url": "https://github.com/tensorflow/tensorflow/issues/22853#issuecomment-429478152", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22853", "id": 429478152, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTQ3ODE1Mg==", "user": {"login": "jpatts", "id": 14956156, "node_id": "MDQ6VXNlcjE0OTU2MTU2", "avatar_url": "https://avatars0.githubusercontent.com/u/14956156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpatts", "html_url": "https://github.com/jpatts", "followers_url": "https://api.github.com/users/jpatts/followers", "following_url": "https://api.github.com/users/jpatts/following{/other_user}", "gists_url": "https://api.github.com/users/jpatts/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpatts/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpatts/subscriptions", "organizations_url": "https://api.github.com/users/jpatts/orgs", "repos_url": "https://api.github.com/users/jpatts/repos", "events_url": "https://api.github.com/users/jpatts/events{/privacy}", "received_events_url": "https://api.github.com/users/jpatts/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T22:18:04Z", "updated_at": "2018-10-12T22:18:04Z", "author_association": "NONE", "body_html": "<p>With more investigation, <code>tf.enable_eager_execution</code> appears to be involved as well. I believe this to be a compatibility issue with <code>tf.keras.Model</code> and <code>tf.enable_eager_execution</code>. I am unable to pass data contained within a ListWrapper() into my model, as well as in other functions, while both of those are present.<br>\nThe following code runs without issue:</p>\n<pre><code>import tensorflow as tf\n\nclass my_class(object):\n\n    def __init__(self):\n        super(my_class, self).__init__()\n\n        self.model = tf.keras.layers.Dense(3)\n        # Specify input size\n        self.model.build((32, 32, 1))\n    \n    def forward(self):\n        image = tf.zeros((32, 32, 1))\n        self.images = []\n        self.images.append(image)\n        self.model(self.images)\n\nmodel = my_class()\nmodel.forward()\n</code></pre>\n<p>Adding tf.enable_eager_execution() OR tf.keras.Model does not break this program.<br>\nHowever, adding tf.enable_eager_execution() AND tf.keras.Model causes an ugly error:</p>\n<pre><code>import tensorflow as tf\n\ntf.enable_eager_execution()\n\nclass my_class(tf.keras.Model):\n\n    def __init__(self):\n        super(my_class, self).__init__()\n\n        self.model = tf.keras.layers.Dense(3)\n        # Specify input size\n        self.model.build((32, 32, 1))\n    \n    def forward(self):\n        image = tf.zeros((32, 32, 1))\n        self.images = []\n        self.images.append(image)\n        self.model(self.images)\n\nmodel = my_class()\nmodel.forward()\n</code></pre>\n<pre><code>2018-10-12 18:17:23.199858: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-10-12 18:17:23.394365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:01:00.0\ntotalMemory: 7.93GiB freeMemory: 5.87GiB\n2018-10-12 18:17:23.394407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-10-12 18:17:23.630373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-12 18:17:23.630403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\n2018-10-12 18:17:23.630410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\n2018-10-12 18:17:23.630591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5641 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"test.py\", line 21, in &lt;module&gt;\n    model.forward()\n  File \"test.py\", line 18, in forward\n    self.model(self.images)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 769, in __call__\n    outputs = self.call(inputs, *args, **kwargs)  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 936, in call\n    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1048, in convert_to_tensor\n    as_ref=False)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1144, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 971, in _autopacking_conversion_function\n    return _autopacking_helper(v, dtype, name or \"packed\")\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 893, in _autopacking_helper\n    return gen_array_ops.pack(list_or_tuple, name=name)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4713, in pack\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\n  File \"&lt;string&gt;\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.InvalidArgumentError: OpKernel 'Pack' has constraint on attr 'T' not in NodeDef '{{node Pack}} = Pack[N=0, axis=0]()', KernelDef: 'op: \"Pack\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"values\" host_memory_arg: \"output\"' [Op:Pack] name: packed\n</code></pre>", "body_text": "With more investigation, tf.enable_eager_execution appears to be involved as well. I believe this to be a compatibility issue with tf.keras.Model and tf.enable_eager_execution. I am unable to pass data contained within a ListWrapper() into my model, as well as in other functions, while both of those are present.\nThe following code runs without issue:\nimport tensorflow as tf\n\nclass my_class(object):\n\n    def __init__(self):\n        super(my_class, self).__init__()\n\n        self.model = tf.keras.layers.Dense(3)\n        # Specify input size\n        self.model.build((32, 32, 1))\n    \n    def forward(self):\n        image = tf.zeros((32, 32, 1))\n        self.images = []\n        self.images.append(image)\n        self.model(self.images)\n\nmodel = my_class()\nmodel.forward()\n\nAdding tf.enable_eager_execution() OR tf.keras.Model does not break this program.\nHowever, adding tf.enable_eager_execution() AND tf.keras.Model causes an ugly error:\nimport tensorflow as tf\n\ntf.enable_eager_execution()\n\nclass my_class(tf.keras.Model):\n\n    def __init__(self):\n        super(my_class, self).__init__()\n\n        self.model = tf.keras.layers.Dense(3)\n        # Specify input size\n        self.model.build((32, 32, 1))\n    \n    def forward(self):\n        image = tf.zeros((32, 32, 1))\n        self.images = []\n        self.images.append(image)\n        self.model(self.images)\n\nmodel = my_class()\nmodel.forward()\n\n2018-10-12 18:17:23.199858: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-10-12 18:17:23.394365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:01:00.0\ntotalMemory: 7.93GiB freeMemory: 5.87GiB\n2018-10-12 18:17:23.394407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-10-12 18:17:23.630373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-12 18:17:23.630403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\n2018-10-12 18:17:23.630410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\n2018-10-12 18:17:23.630591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5641 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\nTraceback (most recent call last):\n  File \"test.py\", line 21, in <module>\n    model.forward()\n  File \"test.py\", line 18, in forward\n    self.model(self.images)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 769, in __call__\n    outputs = self.call(inputs, *args, **kwargs)  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 936, in call\n    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1048, in convert_to_tensor\n    as_ref=False)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1144, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 971, in _autopacking_conversion_function\n    return _autopacking_helper(v, dtype, name or \"packed\")\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 893, in _autopacking_helper\n    return gen_array_ops.pack(list_or_tuple, name=name)\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4713, in pack\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\n  File \"<string>\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.InvalidArgumentError: OpKernel 'Pack' has constraint on attr 'T' not in NodeDef '{{node Pack}} = Pack[N=0, axis=0]()', KernelDef: 'op: \"Pack\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"values\" host_memory_arg: \"output\"' [Op:Pack] name: packed", "body": "With more investigation, `tf.enable_eager_execution` appears to be involved as well. I believe this to be a compatibility issue with `tf.keras.Model` and `tf.enable_eager_execution`. I am unable to pass data contained within a ListWrapper() into my model, as well as in other functions, while both of those are present.\r\nThe following code runs without issue:\r\n```\r\nimport tensorflow as tf\r\n\r\nclass my_class(object):\r\n\r\n    def __init__(self):\r\n        super(my_class, self).__init__()\r\n\r\n        self.model = tf.keras.layers.Dense(3)\r\n        # Specify input size\r\n        self.model.build((32, 32, 1))\r\n    \r\n    def forward(self):\r\n        image = tf.zeros((32, 32, 1))\r\n        self.images = []\r\n        self.images.append(image)\r\n        self.model(self.images)\r\n\r\nmodel = my_class()\r\nmodel.forward()\r\n```\r\nAdding tf.enable_eager_execution() OR tf.keras.Model does not break this program.\r\nHowever, adding tf.enable_eager_execution() AND tf.keras.Model causes an ugly error:\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\nclass my_class(tf.keras.Model):\r\n\r\n    def __init__(self):\r\n        super(my_class, self).__init__()\r\n\r\n        self.model = tf.keras.layers.Dense(3)\r\n        # Specify input size\r\n        self.model.build((32, 32, 1))\r\n    \r\n    def forward(self):\r\n        image = tf.zeros((32, 32, 1))\r\n        self.images = []\r\n        self.images.append(image)\r\n        self.model(self.images)\r\n\r\nmodel = my_class()\r\nmodel.forward()\r\n```\r\n```\r\n2018-10-12 18:17:23.199858: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-10-12 18:17:23.394365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.93GiB freeMemory: 5.87GiB\r\n2018-10-12 18:17:23.394407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-10-12 18:17:23.630373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-12 18:17:23.630403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\r\n2018-10-12 18:17:23.630410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\r\n2018-10-12 18:17:23.630591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5641 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 21, in <module>\r\n    model.forward()\r\n  File \"test.py\", line 18, in forward\r\n    self.model(self.images)\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 936, in call\r\n    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1048, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1144, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 971, in _autopacking_conversion_function\r\n    return _autopacking_helper(v, dtype, name or \"packed\")\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 893, in _autopacking_helper\r\n    return gen_array_ops.pack(list_or_tuple, name=name)\r\n  File \"/home/jpatts/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4713, in pack\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: OpKernel 'Pack' has constraint on attr 'T' not in NodeDef '{{node Pack}} = Pack[N=0, axis=0]()', KernelDef: 'op: \"Pack\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"values\" host_memory_arg: \"output\"' [Op:Pack] name: packed\r\n```"}