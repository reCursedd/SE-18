{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14894", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14894/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14894/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14894/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14894", "id": 276874753, "node_id": "MDU6SXNzdWUyNzY4NzQ3NTM=", "number": 14894, "title": "'No gradients provided for any variable, check your graph for ops that do not support gradients'", "user": {"login": "uptodiff", "id": 17905794, "node_id": "MDQ6VXNlcjE3OTA1Nzk0", "avatar_url": "https://avatars0.githubusercontent.com/u/17905794?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uptodiff", "html_url": "https://github.com/uptodiff", "followers_url": "https://api.github.com/users/uptodiff/followers", "following_url": "https://api.github.com/users/uptodiff/following{/other_user}", "gists_url": "https://api.github.com/users/uptodiff/gists{/gist_id}", "starred_url": "https://api.github.com/users/uptodiff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uptodiff/subscriptions", "organizations_url": "https://api.github.com/users/uptodiff/orgs", "repos_url": "https://api.github.com/users/uptodiff/repos", "events_url": "https://api.github.com/users/uptodiff/events{/privacy}", "received_events_url": "https://api.github.com/users/uptodiff/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-11-27T01:06:56Z", "updated_at": "2018-03-28T23:36:03Z", "closed_at": "2017-11-29T18:49:20Z", "author_association": "NONE", "body_html": "<p>I write the code like following</p>\n<pre><code>import tensorflow as tf\ninput1=tf.Variable([1.0,2.0,3.0,4.0,5.0,6.0],name='input1')\ninput2=tf.Variable([2.0,3.0,4.0,6.0,8.0,9.0],name='input2')\nvalues_range = tf.constant([0., 10.], dtype = tf.float32)\nsource_hist = tf.histogram_fixed_width(tf.to_float(input1), values_range, 11)\ntemplate_hist = tf.histogram_fixed_width(tf.to_float(input2), values_range, 11)\nsource_hist=tf.cast(source_hist,tf.float32)\ntemplate_hist=tf.cast(template_hist,tf.float32)\nloss=2*tf.nn.l2_loss(source_hist-template_hist)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    writer=tf.summary.FileWriter('./',sess.graph)\n    train_step=tf.train.AdamOptimizer(0.001).minimize(loss)\n    for i in range(0,10000,1):\n        sess.run(train_step)\n        print('input1_value',input1.eval())\n        print('input2_value',input2.eval())\n    writer.close()\n</code></pre>\n<p>Tensorflow throws an error and shows<br>\n''ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"&lt;tf.Variable 'input1:0' shape=(6,) dtype=float32_ref&gt;\", \"&lt;tf.Variable 'input2:0' shape=(6,) dtype=float32_ref&gt;\"] and loss Tensor(\"mul:0\", shape=(), dtype=float32).''</p>\n<p>I know the op  tf.histogram_fixed_width doesn't support backpropagation and is not differentiable. While<br>\nthe op tf.floor has the same attribute as  tf.histogram_fixed_width. And the code below can run  without any error which surprises me a lot.</p>\n<pre><code>import tensorflow as tf\ncst=tf.constant([1.2,1.4,2.8,4.6,6.8], dtype=tf.float32)\ninput=tf.Variable(cst)\nnew=tf.floor(input)\nloss=2*tf.nn.l2_loss(input-new)\ntrain_step=tf.train.AdamOptimizer(0.001).minimize(loss)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(0,10000,1):\n        sess.run(train_step)\n        print('input_value',input.eval())\n        print('new_value',new.eval())\n</code></pre>\n<p>I could not figure it out for days, please help</p>", "body_text": "I write the code like following\nimport tensorflow as tf\ninput1=tf.Variable([1.0,2.0,3.0,4.0,5.0,6.0],name='input1')\ninput2=tf.Variable([2.0,3.0,4.0,6.0,8.0,9.0],name='input2')\nvalues_range = tf.constant([0., 10.], dtype = tf.float32)\nsource_hist = tf.histogram_fixed_width(tf.to_float(input1), values_range, 11)\ntemplate_hist = tf.histogram_fixed_width(tf.to_float(input2), values_range, 11)\nsource_hist=tf.cast(source_hist,tf.float32)\ntemplate_hist=tf.cast(template_hist,tf.float32)\nloss=2*tf.nn.l2_loss(source_hist-template_hist)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    writer=tf.summary.FileWriter('./',sess.graph)\n    train_step=tf.train.AdamOptimizer(0.001).minimize(loss)\n    for i in range(0,10000,1):\n        sess.run(train_step)\n        print('input1_value',input1.eval())\n        print('input2_value',input2.eval())\n    writer.close()\n\nTensorflow throws an error and shows\n''ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'input1:0' shape=(6,) dtype=float32_ref>\", \"<tf.Variable 'input2:0' shape=(6,) dtype=float32_ref>\"] and loss Tensor(\"mul:0\", shape=(), dtype=float32).''\nI know the op  tf.histogram_fixed_width doesn't support backpropagation and is not differentiable. While\nthe op tf.floor has the same attribute as  tf.histogram_fixed_width. And the code below can run  without any error which surprises me a lot.\nimport tensorflow as tf\ncst=tf.constant([1.2,1.4,2.8,4.6,6.8], dtype=tf.float32)\ninput=tf.Variable(cst)\nnew=tf.floor(input)\nloss=2*tf.nn.l2_loss(input-new)\ntrain_step=tf.train.AdamOptimizer(0.001).minimize(loss)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(0,10000,1):\n        sess.run(train_step)\n        print('input_value',input.eval())\n        print('new_value',new.eval())\n\nI could not figure it out for days, please help", "body": "I write the code like following\r\n```\r\nimport tensorflow as tf\r\ninput1=tf.Variable([1.0,2.0,3.0,4.0,5.0,6.0],name='input1')\r\ninput2=tf.Variable([2.0,3.0,4.0,6.0,8.0,9.0],name='input2')\r\nvalues_range = tf.constant([0., 10.], dtype = tf.float32)\r\nsource_hist = tf.histogram_fixed_width(tf.to_float(input1), values_range, 11)\r\ntemplate_hist = tf.histogram_fixed_width(tf.to_float(input2), values_range, 11)\r\nsource_hist=tf.cast(source_hist,tf.float32)\r\ntemplate_hist=tf.cast(template_hist,tf.float32)\r\nloss=2*tf.nn.l2_loss(source_hist-template_hist)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    writer=tf.summary.FileWriter('./',sess.graph)\r\n    train_step=tf.train.AdamOptimizer(0.001).minimize(loss)\r\n    for i in range(0,10000,1):\r\n        sess.run(train_step)\r\n        print('input1_value',input1.eval())\r\n        print('input2_value',input2.eval())\r\n    writer.close()\r\n```\r\nTensorflow throws an error and shows \r\n''ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'input1:0' shape=(6,) dtype=float32_ref>\", \"<tf.Variable 'input2:0' shape=(6,) dtype=float32_ref>\"] and loss Tensor(\"mul:0\", shape=(), dtype=float32).''\r\n\r\n  I know the op  tf.histogram_fixed_width doesn't support backpropagation and is not differentiable. While \r\nthe op tf.floor has the same attribute as  tf.histogram_fixed_width. And the code below can run  without any error which surprises me a lot.\r\n\r\n```\r\nimport tensorflow as tf\r\ncst=tf.constant([1.2,1.4,2.8,4.6,6.8], dtype=tf.float32)\r\ninput=tf.Variable(cst)\r\nnew=tf.floor(input)\r\nloss=2*tf.nn.l2_loss(input-new)\r\ntrain_step=tf.train.AdamOptimizer(0.001).minimize(loss)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for i in range(0,10000,1):\r\n        sess.run(train_step)\r\n        print('input_value',input.eval())\r\n        print('new_value',new.eval())\r\n```\r\nI could not figure it out for days, please help"}