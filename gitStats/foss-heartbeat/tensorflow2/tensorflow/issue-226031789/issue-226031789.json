{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9633", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9633/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9633/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9633/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9633", "id": 226031789, "node_id": "MDU6SXNzdWUyMjYwMzE3ODk=", "number": 9633, "title": "SIGSEGV with sparse_add and broadcasting", "user": {"login": "tpet", "id": 3949136, "node_id": "MDQ6VXNlcjM5NDkxMzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3949136?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tpet", "html_url": "https://github.com/tpet", "followers_url": "https://api.github.com/users/tpet/followers", "following_url": "https://api.github.com/users/tpet/following{/other_user}", "gists_url": "https://api.github.com/users/tpet/gists{/gist_id}", "starred_url": "https://api.github.com/users/tpet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tpet/subscriptions", "organizations_url": "https://api.github.com/users/tpet/orgs", "repos_url": "https://api.github.com/users/tpet/repos", "events_url": "https://api.github.com/users/tpet/events{/privacy}", "received_events_url": "https://api.github.com/users/tpet/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-05-03T15:49:22Z", "updated_at": "2017-05-05T18:20:38Z", "closed_at": "2017-05-05T18:20:38Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nyes, enclosed below</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nUbuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary via pip</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n('v1.0.0-65-g4763edf-dirty', '1.0.1')</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nN/A, using pip installation</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nN/A, CPU-only</li>\n<li><strong>GPU model and memory</strong>:<br>\nnone</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>from __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\n\ndense_sz = [1, 1000, 1000]\ndense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)\n\nsparse_sz = [10, 1000, 1000]\nnnz = 100\nnz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)\nnz_ind = np.unravel_index(nz_ind, dims=sparse_sz)\nnz_ind = np.array(nz_ind).T\nassert np.all(nz_ind &lt; np.array(sparse_sz)[None, :])\n# Ensure canonical ordering.\nind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])\nnz_ind = nz_ind[ind, :]\nprint('nz_ind\\n', nz_ind)\n\nsparse_plc = tf.sparse_placeholder(tf.float32)\nsparse_sum = tf.sparse_add(dense, sparse_plc)\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    print('after init')\n    res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})\n    print('sum\\n', res)\n</code></pre>\n<h3>Describe the problem</h3>\n<p>Running the code above results in</p>\n<pre><code>[...]\nafter init\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n</code></pre>\n<p>For lower values of nnz, (nnz = 1) it finishes fine quite often.</p>\n<pre><code>[...]\nafter init\nsum\n [[[ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  ..., \n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]]]\n\nProcess finished with exit code 0\n</code></pre>\n<h3>Source code / logs</h3>\n<p>See above.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nyes, enclosed below\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nUbuntu 16.04\nTensorFlow installed from (source or binary):\nbinary via pip\nTensorFlow version (use command below):\n('v1.0.0-65-g4763edf-dirty', '1.0.1')\nBazel version (if compiling from source):\nN/A, using pip installation\nCUDA/cuDNN version:\nN/A, CPU-only\nGPU model and memory:\nnone\nExact command to reproduce:\n\nfrom __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\n\ndense_sz = [1, 1000, 1000]\ndense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)\n\nsparse_sz = [10, 1000, 1000]\nnnz = 100\nnz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)\nnz_ind = np.unravel_index(nz_ind, dims=sparse_sz)\nnz_ind = np.array(nz_ind).T\nassert np.all(nz_ind < np.array(sparse_sz)[None, :])\n# Ensure canonical ordering.\nind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])\nnz_ind = nz_ind[ind, :]\nprint('nz_ind\\n', nz_ind)\n\nsparse_plc = tf.sparse_placeholder(tf.float32)\nsparse_sum = tf.sparse_add(dense, sparse_plc)\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    print('after init')\n    res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})\n    print('sum\\n', res)\n\nDescribe the problem\nRunning the code above results in\n[...]\nafter init\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n\nFor lower values of nnz, (nnz = 1) it finishes fine quite often.\n[...]\nafter init\nsum\n [[[ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  ..., \n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]\n  [ 1.  1.  1. ...,  1.  1.  1.]]]\n\nProcess finished with exit code 0\n\nSource code / logs\nSee above.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes, enclosed below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary via pip\r\n- **TensorFlow version (use command below)**:\r\n('v1.0.0-65-g4763edf-dirty', '1.0.1')\r\n- **Bazel version (if compiling from source)**:\r\nN/A, using pip installation\r\n- **CUDA/cuDNN version**:\r\nN/A, CPU-only\r\n- **GPU model and memory**:\r\nnone\r\n- **Exact command to reproduce**:\r\n```\r\nfrom __future__ import print_function\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndense_sz = [1, 1000, 1000]\r\ndense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)\r\n\r\nsparse_sz = [10, 1000, 1000]\r\nnnz = 100\r\nnz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)\r\nnz_ind = np.unravel_index(nz_ind, dims=sparse_sz)\r\nnz_ind = np.array(nz_ind).T\r\nassert np.all(nz_ind < np.array(sparse_sz)[None, :])\r\n# Ensure canonical ordering.\r\nind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])\r\nnz_ind = nz_ind[ind, :]\r\nprint('nz_ind\\n', nz_ind)\r\n\r\nsparse_plc = tf.sparse_placeholder(tf.float32)\r\nsparse_sum = tf.sparse_add(dense, sparse_plc)\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    print('after init')\r\n    res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})\r\n    print('sum\\n', res)\r\n```\r\n\r\n### Describe the problem\r\nRunning the code above results in\r\n```\r\n[...]\r\nafter init\r\n\r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n```\r\nFor lower values of nnz, (nnz = 1) it finishes fine quite often.\r\n```\r\n[...]\r\nafter init\r\nsum\r\n [[[ 1.  1.  1. ...,  1.  1.  1.]\r\n  [ 1.  1.  1. ...,  1.  1.  1.]\r\n  [ 1.  1.  1. ...,  1.  1.  1.]\r\n  ..., \r\n  [ 1.  1.  1. ...,  1.  1.  1.]\r\n  [ 1.  1.  1. ...,  1.  1.  1.]\r\n  [ 1.  1.  1. ...,  1.  1.  1.]]]\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\n### Source code / logs\r\nSee above."}