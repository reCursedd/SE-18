{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/406123820", "html_url": "https://github.com/tensorflow/tensorflow/issues/20769#issuecomment-406123820", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20769", "id": 406123820, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjEyMzgyMA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-19T01:19:42Z", "updated_at": "2018-07-19T01:19:42Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=30656390\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DutAlex\">@DutAlex</a> : There seem to be two things in your comment</p>\n<ol>\n<li>Even after setting <code>per_process_gpu_memory_fraction</code>, all GPU memory is being allocated.</li>\n<li>Setting that option doesn't change the time it takes to run predictions.</li>\n</ol>\n<p>I don't quite see why setting the memory fraction option should change the latency of predictions. The 65% utilization of GPU cores is not something this option would address. Most likely there is some other limitation (in the model) that precludes better GPU utilization.</p>\n<p>So, of 1. and 2., I think only 1. is concerning here :)<br>\nCould you create a <a href=\"https://stackoverflow.com/help/mcve\" rel=\"nofollow\">minimal, verifiable, complete</a> example to help reproduce the problem?</p>\n<p>For example, I tried the following  - <a href=\"https://gist.github.com/asimshankar/2d65be7ef53f1888cf7dc93758a565c9\">https://gist.github.com/asimshankar/2d65be7ef53f1888cf7dc93758a565c9</a> - which suggests to me that the change is working (in that it is respecting options provided to the <code>ConfigProto</code> message).</p>\n<p>In particular, note that without the <code>setPerProcessGpuMemoryFraction()</code> line, <code>nvidia-smi</code> shows that the JVM process has allocated all ~12GB of GPU memory:</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    241863      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java 11615MiB |\n\n</code></pre>\n<p>but with that line, it allocates ~370MB:</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    241613      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java   371MiB |\n\n</code></pre>\n<p>A way to reproduce the problem will be helpful, otherwise it may be hard to figure out what's going on in your particular setup. Thanks!</p>", "body_text": "@DutAlex : There seem to be two things in your comment\n\nEven after setting per_process_gpu_memory_fraction, all GPU memory is being allocated.\nSetting that option doesn't change the time it takes to run predictions.\n\nI don't quite see why setting the memory fraction option should change the latency of predictions. The 65% utilization of GPU cores is not something this option would address. Most likely there is some other limitation (in the model) that precludes better GPU utilization.\nSo, of 1. and 2., I think only 1. is concerning here :)\nCould you create a minimal, verifiable, complete example to help reproduce the problem?\nFor example, I tried the following  - https://gist.github.com/asimshankar/2d65be7ef53f1888cf7dc93758a565c9 - which suggests to me that the change is working (in that it is respecting options provided to the ConfigProto message).\nIn particular, note that without the setPerProcessGpuMemoryFraction() line, nvidia-smi shows that the JVM process has allocated all ~12GB of GPU memory:\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    241863      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java 11615MiB |\n\n\nbut with that line, it allocates ~370MB:\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    241613      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java   371MiB |\n\n\nA way to reproduce the problem will be helpful, otherwise it may be hard to figure out what's going on in your particular setup. Thanks!", "body": "@DutAlex : There seem to be two things in your comment\r\n\r\n1. Even after setting `per_process_gpu_memory_fraction`, all GPU memory is being allocated.\r\n2. Setting that option doesn't change the time it takes to run predictions.\r\n\r\nI don't quite see why setting the memory fraction option should change the latency of predictions. The 65% utilization of GPU cores is not something this option would address. Most likely there is some other limitation (in the model) that precludes better GPU utilization.\r\n\r\nSo, of 1. and 2., I think only 1. is concerning here :)\r\nCould you create a [minimal, verifiable, complete](https://stackoverflow.com/help/mcve) example to help reproduce the problem?\r\n\r\nFor example, I tried the following  - https://gist.github.com/asimshankar/2d65be7ef53f1888cf7dc93758a565c9 - which suggests to me that the change is working (in that it is respecting options provided to the `ConfigProto` message).\r\n\r\nIn particular, note that without the `setPerProcessGpuMemoryFraction()` line, `nvidia-smi` shows that the JVM process has allocated all ~12GB of GPU memory:\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0    241863      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java 11615MiB |\r\n\r\n```\r\n\r\nbut with that line, it allocates ~370MB:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0    241613      C   /usr/lib/jvm/java-8-openjdk-amd64/bin/java   371MiB |\r\n\r\n```\r\n\r\nA way to reproduce the problem will be helpful, otherwise it may be hard to figure out what's going on in your particular setup. Thanks!"}