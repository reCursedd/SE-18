{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396749222", "html_url": "https://github.com/tensorflow/tensorflow/issues/19931#issuecomment-396749222", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19931", "id": 396749222, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Njc0OTIyMg==", "user": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T22:03:12Z", "updated_at": "2018-06-12T22:03:12Z", "author_association": "MEMBER", "body_html": "<p>You are trying to convert a quantized model so you need to change the input flags used as the error message says:</p>\n<pre><code>If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\n</code></pre>\n<p>You should pass</p>\n<pre><code> --inference_type=QUANTIZED_UINT8\n--std_values=128\n--mean_values=128\n</code></pre>\n<p>To toco if running quantized.</p>", "body_text": "You are trying to convert a quantized model so you need to change the input flags used as the error message says:\nIf running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\n\nYou should pass\n --inference_type=QUANTIZED_UINT8\n--std_values=128\n--mean_values=128\n\nTo toco if running quantized.", "body": "You are trying to convert a quantized model so you need to change the input flags used as the error message says:\r\n```\r\nIf running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n```\r\n\r\nYou should pass\r\n```\r\n --inference_type=QUANTIZED_UINT8\r\n--std_values=128\r\n--mean_values=128\r\n```\r\n\r\nTo toco if running quantized."}