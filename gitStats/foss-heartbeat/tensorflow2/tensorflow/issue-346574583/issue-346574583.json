{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21306", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21306/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21306/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21306/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21306", "id": 346574583, "node_id": "MDU6SXNzdWUzNDY1NzQ1ODM=", "number": 21306, "title": "Support for NCE-loss/sampled softmax with dynamic_decode()", "user": {"login": "iamgroot42", "id": 10141323, "node_id": "MDQ6VXNlcjEwMTQxMzIz", "avatar_url": "https://avatars1.githubusercontent.com/u/10141323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamgroot42", "html_url": "https://github.com/iamgroot42", "followers_url": "https://api.github.com/users/iamgroot42/followers", "following_url": "https://api.github.com/users/iamgroot42/following{/other_user}", "gists_url": "https://api.github.com/users/iamgroot42/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamgroot42/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamgroot42/subscriptions", "organizations_url": "https://api.github.com/users/iamgroot42/orgs", "repos_url": "https://api.github.com/users/iamgroot42/repos", "events_url": "https://api.github.com/users/iamgroot42/events{/privacy}", "received_events_url": "https://api.github.com/users/iamgroot42/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-08-01T12:16:57Z", "updated_at": "2018-08-27T12:30:08Z", "closed_at": "2018-08-27T12:30:08Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: NA</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8.0</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.1</li>\n<li><strong>GPU model and memory</strong>: TITAN Xp 12196MB * 8</li>\n<li><strong>Exact command to reproduce</strong>: NA</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>NCE loss/Sampled Softmax loss both require inputs along with the softmax-weight (used for multiplication to obtain logits). However, the current <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss\" rel=\"nofollow\">sequence_loss()</a> function in <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode\" rel=\"nofollow\">dynamic_decode()</a> function expects a loss function that works with logits, not these inputs. To provide these inputs to this custom loss function, the only method right now is to override the <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L137\">cell </a> being used, <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/seq2seq/python/ops/decoder.py#L265\">return</a> their outputs (before passing through output layer) all the way up via its BasicDecoder. Then, this output can be used in the custom loss function.</p>\n<p>There should be some support for an optional flag which lets one return the output state (before being passed through that matrix) as well, so that it may be passed to the custom loss function. TO compliment this, the custom loss function should also accept a loss in the format (inputs, outputs) instead if just (logits, outputs).</p>\n<p>I spent nearly a week into looking for a workaround for this and could not find anywhere, hence this issue/feature request.</p>\n<p>P.S.: If anyone has used NCE loss/sampled softmax loss with dynamic_decode() without going through all of this hassle, please let me know. There is nothing on Stack Overflow/Github/Tensorflow's examples about this (there is one example, but they used the logits as inputs to the sequence_loss's custom loss, which is wrong)</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.8.0\nPython version: 3.5\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: CUDA 9.1\nGPU model and memory: TITAN Xp 12196MB * 8\nExact command to reproduce: NA\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nNCE loss/Sampled Softmax loss both require inputs along with the softmax-weight (used for multiplication to obtain logits). However, the current sequence_loss() function in dynamic_decode() function expects a loss function that works with logits, not these inputs. To provide these inputs to this custom loss function, the only method right now is to override the cell  being used, return their outputs (before passing through output layer) all the way up via its BasicDecoder. Then, this output can be used in the custom loss function.\nThere should be some support for an optional flag which lets one return the output state (before being passed through that matrix) as well, so that it may be passed to the custom loss function. TO compliment this, the custom loss function should also accept a loss in the format (inputs, outputs) instead if just (logits, outputs).\nI spent nearly a week into looking for a workaround for this and could not find anywhere, hence this issue/feature request.\nP.S.: If anyone has used NCE loss/sampled softmax loss with dynamic_decode() without going through all of this hassle, please let me know. There is nothing on Stack Overflow/Github/Tensorflow's examples about this (there is one example, but they used the logits as inputs to the sequence_loss's custom loss, which is wrong)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: CUDA 9.1\r\n- **GPU model and memory**: TITAN Xp 12196MB * 8\r\n- **Exact command to reproduce**: NA\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nNCE loss/Sampled Softmax loss both require inputs along with the softmax-weight (used for multiplication to obtain logits). However, the current [sequence_loss()](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss) function in [dynamic_decode()](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode) function expects a loss function that works with logits, not these inputs. To provide these inputs to this custom loss function, the only method right now is to override the [cell ](https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L137) being used, [return](https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/seq2seq/python/ops/decoder.py#L265) their outputs (before passing through output layer) all the way up via its BasicDecoder. Then, this output can be used in the custom loss function.\r\n\r\nThere should be some support for an optional flag which lets one return the output state (before being passed through that matrix) as well, so that it may be passed to the custom loss function. TO compliment this, the custom loss function should also accept a loss in the format (inputs, outputs) instead if just (logits, outputs).\r\n\r\nI spent nearly a week into looking for a workaround for this and could not find anywhere, hence this issue/feature request.\r\n\r\nP.S.: If anyone has used NCE loss/sampled softmax loss with dynamic_decode() without going through all of this hassle, please let me know. There is nothing on Stack Overflow/Github/Tensorflow's examples about this (there is one example, but they used the logits as inputs to the sequence_loss's custom loss, which is wrong)"}