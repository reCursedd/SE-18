{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9414", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9414/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9414/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9414/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9414", "id": 223818121, "node_id": "MDU6SXNzdWUyMjM4MTgxMjE=", "number": 9414, "title": "CNN pip installed error E tensorflow/stream_executor/cuda/cuda_dnn.cc:352]", "user": {"login": "nazandr", "id": 18089618, "node_id": "MDQ6VXNlcjE4MDg5NjE4", "avatar_url": "https://avatars3.githubusercontent.com/u/18089618?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nazandr", "html_url": "https://github.com/nazandr", "followers_url": "https://api.github.com/users/nazandr/followers", "following_url": "https://api.github.com/users/nazandr/following{/other_user}", "gists_url": "https://api.github.com/users/nazandr/gists{/gist_id}", "starred_url": "https://api.github.com/users/nazandr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nazandr/subscriptions", "organizations_url": "https://api.github.com/users/nazandr/orgs", "repos_url": "https://api.github.com/users/nazandr/repos", "events_url": "https://api.github.com/users/nazandr/events{/privacy}", "received_events_url": "https://api.github.com/users/nazandr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-24T13:21:51Z", "updated_at": "2017-06-16T21:07:56Z", "closed_at": "2017-06-16T21:07:56Z", "author_association": "NONE", "body_html": "<p>MacOS pip installed tensorflow<br>\nOnly cnn triggered this error</p>\n<pre><code>2017-04-24 04:14:57.699073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-04-24 04:14:57.699094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-04-24 04:14:57.701039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GT 650M, pci bus id: 0000:01:00.0)\n2017-04-24 04:15:04.233947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\n2017-04-24 04:15:04.234420: F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms) \nAbort trap: 6\n</code></pre>\n<pre><code>Name: tensorflow-gpu\nVersion: 1.1.0\nSummary: TensorFlow helps the tensors flow\nHome-page: http://tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: opensource@google.com\nLicense: Apache 2.0\nLocation: /Users/andrey/tf/lib/python3.6/site-packages\nRequires: wheel, protobuf, six, numpy, werkzeug\n</code></pre>\n<p>CUDA Driver Version: 8.0.81<br>\nGPU Driver Version: 10.16.34 355.10.05.35f05</p>\n<pre><code>Device 0: \"GeForce GT 650M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 1024 MBytes (1073414144 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            900 MHz (0.90 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 650M\n</code></pre>", "body_text": "MacOS pip installed tensorflow\nOnly cnn triggered this error\n2017-04-24 04:14:57.699073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-04-24 04:14:57.699094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-04-24 04:14:57.701039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 650M, pci bus id: 0000:01:00.0)\n2017-04-24 04:15:04.233947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\n2017-04-24 04:15:04.234420: F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \nAbort trap: 6\n\nName: tensorflow-gpu\nVersion: 1.1.0\nSummary: TensorFlow helps the tensors flow\nHome-page: http://tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: opensource@google.com\nLicense: Apache 2.0\nLocation: /Users/andrey/tf/lib/python3.6/site-packages\nRequires: wheel, protobuf, six, numpy, werkzeug\n\nCUDA Driver Version: 8.0.81\nGPU Driver Version: 10.16.34 355.10.05.35f05\nDevice 0: \"GeForce GT 650M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 1024 MBytes (1073414144 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            900 MHz (0.90 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 650M", "body": "MacOS pip installed tensorflow \r\nOnly cnn triggered this error \r\n```\r\n2017-04-24 04:14:57.699073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-04-24 04:14:57.699094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-04-24 04:14:57.701039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 650M, pci bus id: 0000:01:00.0)\r\n2017-04-24 04:15:04.233947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\r\n2017-04-24 04:15:04.234420: F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \r\nAbort trap: 6\r\n```\r\n```\r\nName: tensorflow-gpu\r\nVersion: 1.1.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: http://tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /Users/andrey/tf/lib/python3.6/site-packages\r\nRequires: wheel, protobuf, six, numpy, werkzeug\r\n```\r\nCUDA Driver Version: 8.0.81\r\nGPU Driver Version: 10.16.34 355.10.05.35f05\r\n\r\n```\r\nDevice 0: \"GeForce GT 650M\"\r\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\r\n  CUDA Capability Major/Minor version number:    3.0\r\n  Total amount of global memory:                 1024 MBytes (1073414144 bytes)\r\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\r\n  GPU Max Clock rate:                            900 MHz (0.90 GHz)\r\n  Memory Clock rate:                             2508 Mhz\r\n  Memory Bus Width:                              128-bit\r\n  L2 Cache Size:                                 262144 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 650M\r\n```\r\n"}