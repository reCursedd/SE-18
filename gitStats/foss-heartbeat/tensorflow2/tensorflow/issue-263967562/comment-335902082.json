{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335902082", "html_url": "https://github.com/tensorflow/tensorflow/issues/13591#issuecomment-335902082", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13591", "id": 335902082, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTkwMjA4Mg==", "user": {"login": "ybsave", "id": 26417094, "node_id": "MDQ6VXNlcjI2NDE3MDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26417094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybsave", "html_url": "https://github.com/ybsave", "followers_url": "https://api.github.com/users/ybsave/followers", "following_url": "https://api.github.com/users/ybsave/following{/other_user}", "gists_url": "https://api.github.com/users/ybsave/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybsave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybsave/subscriptions", "organizations_url": "https://api.github.com/users/ybsave/orgs", "repos_url": "https://api.github.com/users/ybsave/repos", "events_url": "https://api.github.com/users/ybsave/events{/privacy}", "received_events_url": "https://api.github.com/users/ybsave/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-11T18:20:40Z", "updated_at": "2017-10-11T18:23:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a> My previous test codes are exactly the same as yours, and it did not crash when NUM_ELEMS= int((7 * GPU_MEMORY_BYTES / 8) / 4). The codes' outputs are:</p>\n<pre><code>2017-10-11 10:58:27.944911: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 10:58:27.945590: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 10:58:28.179010: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 10:58:28.179994: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\n2017-10-11 10:58:28.180991: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\n2017-10-11 10:58:28.181884: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 10:58:45.303652: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 17179869184 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:45.304306: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 17179869184\n2017-10-11 10:58:52.164328: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 15461881856 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:52.164914: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 15461881856\n2017-10-11 10:58:57.874112: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 13915693056 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:57.874684: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 13915693056\n2017-10-11 10:59:03.462710: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 12524123136 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:03.463291: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 12524123136\n2017-10-11 10:59:08.392877: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 11271710720 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:08.393505: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 11271710720\n2017-10-11 10:59:12.736219: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 10144539648 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:12.736467: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 10144539648\n-536870912\n</code></pre>\n<p>Thanks to your explanation, I think the int32 type question is clear now. Now the problem comes from only float32 issue.</p>\n<p>When I change the type to float32 (all other codes are fixed, I also copy them below), the single GPU version can only support NUM_ELEMS = int((1.8 * GPU_MEMORY_BYTES / 8) / 4) but will crash when NUM_ELEMS = int((2 * GPU_MEMORY_BYTES / 8) / 4). However, I check many times to make sure that my GPU usage before calling is very low as shown:<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 376.51                 Driver Version: 376.51                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Quadro M4000       WDDM  | 0000:03:00.0      On |                  N/A |<br>\n| 48%   45C    P8    21W / 120W |    772MiB /  8192MiB |      1%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Quadro M4000        TCC  | 0000:04:00.0     Off |                  N/A |<br>\n| 49%   46C    P8    21W / 120W |      0MiB /  8121MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>When using two GPUs, the codes run successfully when NUM_ELEMS = int((3 * GPU_MEMORY_BYTES / 8) / 4), but will crash when NUM_ELEMS = int((4 * GPU_MEMORY_BYTES / 8) / 4).</p>\n<p>This phenomenon seems indicating that Tensorflow always need double size of the actual data in the memory. Is this a bug in Tensorflow? Is there any way to fix this issue? Thank you.</p>\n<p>My test codes are:</p>\n<pre><code>def Test4():\n  with tf.device(\"/gpu:0\"):\n\tt = tf.ones([2, NUM_ELEMS], tf.float32)\n  s = tf.reduce_sum(t)\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0'),\n\t\t\t\t\t\t  allow_soft_placement=False)\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\n  with tf.Session(config=config) as sess:\n\tprint(sess.run(s))\n\ndef Test5():\n  with tf.device(\"/gpu:0\"):\n\tt0 = tf.ones([NUM_ELEMS], tf.float32)\n\ts0 = tf.reduce_sum(t0)\n  with tf.device(\"/gpu:1\"):\n\tt1 = tf.ones([NUM_ELEMS], tf.float32)\n\ts1 = tf.reduce_sum(t1)\n  s = tf.add(s0, s1)\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0,1'),\n\t\t\t\t\t\t  allow_soft_placement=False)\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\n  with tf.Session(config=config) as sess:\n\tprint(sess.run([s0, s1, s]))\n</code></pre>\n<p>The error messages when crashing for single gpu (test4) are:</p>\n<pre><code>2017-10-11 11:17:28.183277: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:17:28.183968: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:17:28.477173: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 11:17:28.478131: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\n2017-10-11 11:17:28.478488: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\n2017-10-11 11:17:28.478857: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 11:17:39.968193: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\n2017-10-11 11:17:39.968928: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.969705: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.970396: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.971082: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.971800: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.972469: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.973140: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.973810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.974515: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.975196: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.975882: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.976544: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.977217: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.978161: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.978837: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.979513: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.980190: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.980896: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.985346: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.986052: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.986728: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.987393: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\n2017-10-11 11:17:39.987850: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40000 of size 1280\n2017-10-11 11:17:39.988368: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40500 of size 8029879040\n2017-10-11 11:17:39.988810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\n2017-10-11 11:17:39.989287: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\n2017-10-11 11:17:39.989747: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 8029879040 totalling 7.48GiB\n2017-10-11 11:17:39.990202: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 7.48GiB\n2017-10-11 11:17:39.990649: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\nLimit:                  8029880320\nInUse:                  8029880320\nMaxInUse:               8029880320\nNumAllocs:                       2\nMaxAllocSize:           8029879040\n\n2017-10-11 11:17:39.991605: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n2017-10-11 11:17:39.992210: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n\treturn fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n\tstatus, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\n\tnext(self.gen)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n\tpywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"Test_two_GPUs.py\", line 100, in &lt;module&gt;\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest4()\n  File \"Test_two_GPUs.py\", line 77, in Test4\n\tprint(sess.run(s))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n\trun_metadata_ptr)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n\tfeed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n\toptions, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n\traise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n\nCaused by op 'Sum', defined at:\n  File \"Test_two_GPUs.py\", line 100, in &lt;module&gt;\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest4()\n  File \"Test_two_GPUs.py\", line 72, in Test4\n\ts = tf.reduce_sum(t)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n\tname=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n\tkeep_dims=keep_dims, name=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n\top_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n\toriginal_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n</code></pre>\n<p>The error message for two GPUs (test5) are:</p>\n<pre><code>2017-10-11 11:19:20.563267: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:19:20.563990: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:19:20.843673: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 11:19:21.098788: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:523] A non-primary context 0000000EF7D9B640 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2017-10-11 11:19:21.099703: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 1 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:03:00.0\nTotal memory: 8.00GiB\nFree memory: 6.71GiB\n2017-10-11 11:19:21.100621: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1\n2017-10-11 11:19:21.101004: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0\n2017-10-11 11:19:21.101448: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 1\n2017-10-11 11:19:21.101779: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y N\n2017-10-11 11:19:21.102121: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 1:   N Y\n2017-10-11 11:19:21.102487: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 11:19:21.102945: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Quadro M4000, pci bus id: 0000:03:00.0)\n2017-10-11 11:19:34.108912: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_1_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\n2017-10-11 11:19:34.109688: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.110365: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.111035: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.111702: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.112383: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.113054: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.113725: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.114401: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.115132: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.115808: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.116466: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.117129: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.117864: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.118552: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.119231: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.119925: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.120600: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.121283: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.121969: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.122698: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.123359: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.124031: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\n2017-10-11 11:19:34.124492: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80000 of size 1280\n2017-10-11 11:19:34.125033: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80500 of size 6843439616\n2017-10-11 11:19:34.125652: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\n2017-10-11 11:19:34.126135: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\n2017-10-11 11:19:34.126603: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 6843439616 totalling 6.37GiB\n2017-10-11 11:19:34.127074: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 6.37GiB\n2017-10-11 11:19:34.127530: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\nLimit:                  6843440988\nInUse:                  6843440896\nMaxInUse:               6843440896\nNumAllocs:                       2\nMaxAllocSize:           6843439616\n\n2017-10-11 11:19:34.128516: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] *******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n2017-10-11 11:19:34.129120: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n\treturn fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n\tstatus, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\n\tnext(self.gen)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n\tpywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"Test_two_GPUs.py\", line 100, in &lt;module&gt;\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest5()\n  File \"Test_two_GPUs.py\", line 91, in Test5\n\tprint(sess.run([s0, s1, s]))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n\trun_metadata_ptr)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n\tfeed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n\toptions, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n\traise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\n\nCaused by op 'Sum_1', defined at:\n  File \"Test_two_GPUs.py\", line 100, in &lt;module&gt;\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest5()\n  File \"Test_two_GPUs.py\", line 85, in Test5\n\ts1 = tf.reduce_sum(t1)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n\tname=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n\tkeep_dims=keep_dims, name=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n\top_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n\toriginal_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\n</code></pre>", "body_text": "@reedwm My previous test codes are exactly the same as yours, and it did not crash when NUM_ELEMS= int((7 * GPU_MEMORY_BYTES / 8) / 4). The codes' outputs are:\n2017-10-11 10:58:27.944911: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 10:58:27.945590: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 10:58:28.179010: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 10:58:28.179994: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\n2017-10-11 10:58:28.180991: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\n2017-10-11 10:58:28.181884: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 10:58:45.303652: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 17179869184 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:45.304306: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 17179869184\n2017-10-11 10:58:52.164328: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 15461881856 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:52.164914: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 15461881856\n2017-10-11 10:58:57.874112: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 13915693056 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:58:57.874684: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 13915693056\n2017-10-11 10:59:03.462710: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 12524123136 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:03.463291: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 12524123136\n2017-10-11 10:59:08.392877: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 11271710720 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:08.393505: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 11271710720\n2017-10-11 10:59:12.736219: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 10144539648 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\n2017-10-11 10:59:12.736467: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 10144539648\n-536870912\n\nThanks to your explanation, I think the int32 type question is clear now. Now the problem comes from only float32 issue.\nWhen I change the type to float32 (all other codes are fixed, I also copy them below), the single GPU version can only support NUM_ELEMS = int((1.8 * GPU_MEMORY_BYTES / 8) / 4) but will crash when NUM_ELEMS = int((2 * GPU_MEMORY_BYTES / 8) / 4). However, I check many times to make sure that my GPU usage before calling is very low as shown:\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 376.51                 Driver Version: 376.51                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Quadro M4000       WDDM  | 0000:03:00.0      On |                  N/A |\n| 48%   45C    P8    21W / 120W |    772MiB /  8192MiB |      1%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Quadro M4000        TCC  | 0000:04:00.0     Off |                  N/A |\n| 49%   46C    P8    21W / 120W |      0MiB /  8121MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\nWhen using two GPUs, the codes run successfully when NUM_ELEMS = int((3 * GPU_MEMORY_BYTES / 8) / 4), but will crash when NUM_ELEMS = int((4 * GPU_MEMORY_BYTES / 8) / 4).\nThis phenomenon seems indicating that Tensorflow always need double size of the actual data in the memory. Is this a bug in Tensorflow? Is there any way to fix this issue? Thank you.\nMy test codes are:\ndef Test4():\n  with tf.device(\"/gpu:0\"):\n\tt = tf.ones([2, NUM_ELEMS], tf.float32)\n  s = tf.reduce_sum(t)\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0'),\n\t\t\t\t\t\t  allow_soft_placement=False)\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\n  with tf.Session(config=config) as sess:\n\tprint(sess.run(s))\n\ndef Test5():\n  with tf.device(\"/gpu:0\"):\n\tt0 = tf.ones([NUM_ELEMS], tf.float32)\n\ts0 = tf.reduce_sum(t0)\n  with tf.device(\"/gpu:1\"):\n\tt1 = tf.ones([NUM_ELEMS], tf.float32)\n\ts1 = tf.reduce_sum(t1)\n  s = tf.add(s0, s1)\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0,1'),\n\t\t\t\t\t\t  allow_soft_placement=False)\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\n  with tf.Session(config=config) as sess:\n\tprint(sess.run([s0, s1, s]))\n\nThe error messages when crashing for single gpu (test4) are:\n2017-10-11 11:17:28.183277: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:17:28.183968: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:17:28.477173: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 11:17:28.478131: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\n2017-10-11 11:17:28.478488: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\n2017-10-11 11:17:28.478857: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 11:17:39.968193: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\n2017-10-11 11:17:39.968928: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.969705: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.970396: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.971082: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.971800: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.972469: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.973140: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.973810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.974515: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.975196: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.975882: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.976544: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.977217: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.978161: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.978837: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.979513: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.980190: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.980896: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.985346: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.986052: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.986728: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:17:39.987393: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\n2017-10-11 11:17:39.987850: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40000 of size 1280\n2017-10-11 11:17:39.988368: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40500 of size 8029879040\n2017-10-11 11:17:39.988810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\n2017-10-11 11:17:39.989287: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\n2017-10-11 11:17:39.989747: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 8029879040 totalling 7.48GiB\n2017-10-11 11:17:39.990202: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 7.48GiB\n2017-10-11 11:17:39.990649: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\nLimit:                  8029880320\nInUse:                  8029880320\nMaxInUse:               8029880320\nNumAllocs:                       2\nMaxAllocSize:           8029879040\n\n2017-10-11 11:17:39.991605: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n2017-10-11 11:17:39.992210: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n\treturn fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n\tstatus, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\n\tnext(self.gen)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n\tpywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"Test_two_GPUs.py\", line 100, in <module>\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest4()\n  File \"Test_two_GPUs.py\", line 77, in Test4\n\tprint(sess.run(s))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n\trun_metadata_ptr)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n\tfeed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n\toptions, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n\traise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n\nCaused by op 'Sum', defined at:\n  File \"Test_two_GPUs.py\", line 100, in <module>\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest4()\n  File \"Test_two_GPUs.py\", line 72, in Test4\n\ts = tf.reduce_sum(t)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n\tname=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n\tkeep_dims=keep_dims, name=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n\top_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n\toriginal_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\n\nThe error message for two GPUs (test5) are:\n2017-10-11 11:19:20.563267: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:19:20.563990: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-11 11:19:20.843673: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:04:00.0\nTotal memory: 7.93GiB\nFree memory: 7.87GiB\n2017-10-11 11:19:21.098788: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:523] A non-primary context 0000000EF7D9B640 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2017-10-11 11:19:21.099703: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 1 with properties:\nname: Quadro M4000\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\npciBusID 0000:03:00.0\nTotal memory: 8.00GiB\nFree memory: 6.71GiB\n2017-10-11 11:19:21.100621: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1\n2017-10-11 11:19:21.101004: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0\n2017-10-11 11:19:21.101448: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 1\n2017-10-11 11:19:21.101779: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y N\n2017-10-11 11:19:21.102121: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 1:   N Y\n2017-10-11 11:19:21.102487: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\n2017-10-11 11:19:21.102945: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Quadro M4000, pci bus id: 0000:03:00.0)\n2017-10-11 11:19:34.108912: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_1_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\n2017-10-11 11:19:34.109688: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.110365: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.111035: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.111702: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.112383: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.113054: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.113725: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.114401: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.115132: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.115808: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.116466: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.117129: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.117864: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.118552: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.119231: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.119925: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.120600: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.121283: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.121969: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.122698: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.123359: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2017-10-11 11:19:34.124031: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\n2017-10-11 11:19:34.124492: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80000 of size 1280\n2017-10-11 11:19:34.125033: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80500 of size 6843439616\n2017-10-11 11:19:34.125652: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\n2017-10-11 11:19:34.126135: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\n2017-10-11 11:19:34.126603: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 6843439616 totalling 6.37GiB\n2017-10-11 11:19:34.127074: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 6.37GiB\n2017-10-11 11:19:34.127530: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\nLimit:                  6843440988\nInUse:                  6843440896\nMaxInUse:               6843440896\nNumAllocs:                       2\nMaxAllocSize:           6843439616\n\n2017-10-11 11:19:34.128516: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] *******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n2017-10-11 11:19:34.129120: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\n\treturn fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\n\tstatus, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\n\tnext(self.gen)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n\tpywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"Test_two_GPUs.py\", line 100, in <module>\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest5()\n  File \"Test_two_GPUs.py\", line 91, in Test5\n\tprint(sess.run([s0, s1, s]))\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n\trun_metadata_ptr)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\n\tfeed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\n\toptions, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\n\traise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\n\nCaused by op 'Sum_1', defined at:\n  File \"Test_two_GPUs.py\", line 100, in <module>\n\ttf.app.run()\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"Test_two_GPUs.py\", line 96, in main\n\tTest5()\n  File \"Test_two_GPUs.py\", line 85, in Test5\n\ts1 = tf.reduce_sum(t1)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n\tname=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n\tkeep_dims=keep_dims, name=name)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n\top_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n\toriginal_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]", "body": "@reedwm My previous test codes are exactly the same as yours, and it did not crash when NUM_ELEMS= int((7 * GPU_MEMORY_BYTES / 8) / 4). The codes' outputs are:\r\n\r\n\t2017-10-11 10:58:27.944911: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 10:58:27.945590: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 10:58:28.179010: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\r\n\tname: Quadro M4000\r\n\tmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\r\n\tpciBusID 0000:04:00.0\r\n\tTotal memory: 7.93GiB\r\n\tFree memory: 7.87GiB\r\n\t2017-10-11 10:58:28.179994: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\r\n\t2017-10-11 10:58:28.180991: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\r\n\t2017-10-11 10:58:28.181884: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\r\n\t2017-10-11 10:58:45.303652: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 17179869184 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:58:45.304306: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 17179869184\r\n\t2017-10-11 10:58:52.164328: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 15461881856 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:58:52.164914: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 15461881856\r\n\t2017-10-11 10:58:57.874112: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 13915693056 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:58:57.874684: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 13915693056\r\n\t2017-10-11 10:59:03.462710: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 12524123136 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:59:03.463291: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 12524123136\r\n\t2017-10-11 10:59:08.392877: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 11271710720 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:59:08.393505: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 11271710720\r\n\t2017-10-11 10:59:12.736219: E C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:955] failed to alloc 10144539648 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n\t2017-10-11 10:59:12.736467: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 10144539648\r\n\t-536870912\r\n\r\nThanks to your explanation, I think the int32 type question is clear now. Now the problem comes from only float32 issue.\r\n\r\nWhen I change the type to float32 (all other codes are fixed, I also copy them below), the single GPU version can only support NUM_ELEMS = int((1.8 * GPU_MEMORY_BYTES / 8) / 4) but will crash when NUM_ELEMS = int((2 * GPU_MEMORY_BYTES / 8) / 4). However, I check many times to make sure that my GPU usage before calling is very low as shown:\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 376.51                 Driver Version: 376.51                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro M4000       WDDM  | 0000:03:00.0      On |                  N/A |\r\n| 48%   45C    P8    21W / 120W |    772MiB /  8192MiB |      1%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Quadro M4000        TCC  | 0000:04:00.0     Off |                  N/A |\r\n| 49%   46C    P8    21W / 120W |      0MiB /  8121MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\nWhen using two GPUs, the codes run successfully when NUM_ELEMS = int((3 * GPU_MEMORY_BYTES / 8) / 4), but will crash when NUM_ELEMS = int((4 * GPU_MEMORY_BYTES / 8) / 4). \r\n\r\nThis phenomenon seems indicating that Tensorflow always need double size of the actual data in the memory. Is this a bug in Tensorflow? Is there any way to fix this issue? Thank you.\r\n\r\nMy test codes are:\r\n\r\n\tdef Test4():\r\n\t  with tf.device(\"/gpu:0\"):\r\n\t\tt = tf.ones([2, NUM_ELEMS], tf.float32)\r\n\t  s = tf.reduce_sum(t)\r\n\t  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0'),\r\n\t\t\t\t\t\t\t  allow_soft_placement=False)\r\n\t  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\r\n\t  with tf.Session(config=config) as sess:\r\n\t\tprint(sess.run(s))\r\n\r\n\tdef Test5():\r\n\t  with tf.device(\"/gpu:0\"):\r\n\t\tt0 = tf.ones([NUM_ELEMS], tf.float32)\r\n\t\ts0 = tf.reduce_sum(t0)\r\n\t  with tf.device(\"/gpu:1\"):\r\n\t\tt1 = tf.ones([NUM_ELEMS], tf.float32)\r\n\t\ts1 = tf.reduce_sum(t1)\r\n\t  s = tf.add(s0, s1)\r\n\t  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0,1'),\r\n\t\t\t\t\t\t\t  allow_soft_placement=False)\r\n\t  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\r\n\t  with tf.Session(config=config) as sess:\r\n\t\tprint(sess.run([s0, s1, s]))\r\n\r\nThe error messages when crashing for single gpu (test4) are:\r\n\r\n\t2017-10-11 11:17:28.183277: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 11:17:28.183968: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 11:17:28.477173: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\r\n\tname: Quadro M4000\r\n\tmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\r\n\tpciBusID 0000:04:00.0\r\n\tTotal memory: 7.93GiB\r\n\tFree memory: 7.87GiB\r\n\t2017-10-11 11:17:28.478131: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\r\n\t2017-10-11 11:17:28.478488: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\r\n\t2017-10-11 11:17:28.478857: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\r\n\t2017-10-11 11:17:39.968193: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\r\n\t2017-10-11 11:17:39.968928: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.969705: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.970396: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.971082: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.971800: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.972469: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.973140: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.973810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.974515: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.975196: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.975882: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.976544: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.977217: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.978161: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.978837: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.979513: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.980190: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.980896: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.985346: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.986052: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.986728: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:17:39.987393: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\r\n\t2017-10-11 11:17:39.987850: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40000 of size 1280\r\n\t2017-10-11 11:17:39.988368: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 0000001403A40500 of size 8029879040\r\n\t2017-10-11 11:17:39.988810: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\r\n\t2017-10-11 11:17:39.989287: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\r\n\t2017-10-11 11:17:39.989747: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 8029879040 totalling 7.48GiB\r\n\t2017-10-11 11:17:39.990202: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 7.48GiB\r\n\t2017-10-11 11:17:39.990649: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\r\n\tLimit:                  8029880320\r\n\tInUse:                  8029880320\r\n\tMaxInUse:               8029880320\r\n\tNumAllocs:                       2\r\n\tMaxAllocSize:           8029879040\r\n\r\n\t2017-10-11 11:17:39.991605: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n\t2017-10-11 11:17:39.992210: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\r\n\tTraceback (most recent call last):\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\r\n\t\treturn fn(*args)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\r\n\t\tstatus, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\r\n\t\tnext(self.gen)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n\t\tpywrap_tensorflow.TF_GetCode(status))\r\n\ttensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\r\n\r\n\tDuring handling of the above exception, another exception occurred:\r\n\r\n\tTraceback (most recent call last):\r\n\t  File \"Test_two_GPUs.py\", line 100, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"Test_two_GPUs.py\", line 96, in main\r\n\t\tTest4()\r\n\t  File \"Test_two_GPUs.py\", line 77, in Test4\r\n\t\tprint(sess.run(s))\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\n\t\trun_metadata_ptr)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\r\n\t\tfeed_dict_tensor, options, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\r\n\t\toptions, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\r\n\t\traise type(e)(node_def, op, message)\r\n\ttensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\r\n\r\n\tCaused by op 'Sum', defined at:\r\n\t  File \"Test_two_GPUs.py\", line 100, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"Test_two_GPUs.py\", line 96, in main\r\n\t\tTest4()\r\n\t  File \"Test_two_GPUs.py\", line 72, in Test4\r\n\t\ts = tf.reduce_sum(t)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\r\n\t\tname=name)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\r\n\t\tkeep_dims=keep_dims, name=name)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n\t\top_def=op_def)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\r\n\t\toriginal_op=self._default_original_op, op_def=op_def)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\r\n\t\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\tResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](ones, Const)]]\r\n\r\nThe error message for two GPUs (test5) are:\r\n\r\n\t2017-10-11 11:19:20.563267: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 11:19:20.563990: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n\t2017-10-11 11:19:20.843673: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\r\n\tname: Quadro M4000\r\n\tmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\r\n\tpciBusID 0000:04:00.0\r\n\tTotal memory: 7.93GiB\r\n\tFree memory: 7.87GiB\r\n\t2017-10-11 11:19:21.098788: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:523] A non-primary context 0000000EF7D9B640 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n\t2017-10-11 11:19:21.099703: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 1 with properties:\r\n\tname: Quadro M4000\r\n\tmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\r\n\tpciBusID 0000:03:00.0\r\n\tTotal memory: 8.00GiB\r\n\tFree memory: 6.71GiB\r\n\t2017-10-11 11:19:21.100621: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1\r\n\t2017-10-11 11:19:21.101004: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0\r\n\t2017-10-11 11:19:21.101448: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0 1\r\n\t2017-10-11 11:19:21.101779: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y N\r\n\t2017-10-11 11:19:21.102121: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 1:   N Y\r\n\t2017-10-11 11:19:21.102487: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:04:00.0)\r\n\t2017-10-11 11:19:21.102945: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Quadro M4000, pci bus id: 0000:03:00.0)\r\n\t2017-10-11 11:19:34.108912: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_1_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.\r\n\t2017-10-11 11:19:34.109688: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (256):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.110365: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (512):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.111035: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1024):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.111702: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2048):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.112383: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4096):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.113054: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8192):         Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.113725: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16384):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.114401: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (32768):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.115132: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (65536):        Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.115808: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (131072):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.116466: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (262144):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.117129: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (524288):       Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.117864: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (1048576):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.118552: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (2097152):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.119231: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (4194304):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.119925: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (8388608):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.120600: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.121283: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.121969: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.122698: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (134217728):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.123359: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:643] Bin (268435456):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n\t2017-10-11 11:19:34.124031: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State:\r\n\t2017-10-11 11:19:34.124492: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80000 of size 1280\r\n\t2017-10-11 11:19:34.125033: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Chunk at 00000004E5E80500 of size 6843439616\r\n\t2017-10-11 11:19:34.125652: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:693]      Summary of in-use Chunks by size:\r\n\t2017-10-11 11:19:34.126135: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.3KiB\r\n\t2017-10-11 11:19:34.126603: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:696] 1 Chunks of size 6843439616 totalling 6.37GiB\r\n\t2017-10-11 11:19:34.127074: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:700] Sum Total of in-use chunks: 6.37GiB\r\n\t2017-10-11 11:19:34.127530: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:702] Stats:\r\n\tLimit:                  6843440988\r\n\tInUse:                  6843440896\r\n\tMaxInUse:               6843440896\r\n\tNumAllocs:                       2\r\n\tMaxAllocSize:           6843439616\r\n\r\n\t2017-10-11 11:19:34.128516: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] *******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\r\n\t2017-10-11 11:19:34.129120: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]\r\n\tTraceback (most recent call last):\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1327, in _do_call\r\n\t\treturn fn(*args)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1306, in _run_fn\r\n\t\tstatus, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\contextlib.py\", line 88, in __exit__\r\n\t\tnext(self.gen)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n\t\tpywrap_tensorflow.TF_GetCode(status))\r\n\ttensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\r\n\r\n\tDuring handling of the above exception, another exception occurred:\r\n\r\n\tTraceback (most recent call last):\r\n\t  File \"Test_two_GPUs.py\", line 100, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"Test_two_GPUs.py\", line 96, in main\r\n\t\tTest5()\r\n\t  File \"Test_two_GPUs.py\", line 91, in Test5\r\n\t\tprint(sess.run([s0, s1, s]))\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\n\t\trun_metadata_ptr)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1124, in _run\r\n\t\tfeed_dict_tensor, options, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1321, in _do_run\r\n\t\toptions, run_metadata)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _do_call\r\n\t\traise type(e)(node_def, op, message)\r\n\ttensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]\r\n\r\n\tCaused by op 'Sum_1', defined at:\r\n\t  File \"Test_two_GPUs.py\", line 100, in <module>\r\n\t\ttf.app.run()\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n\t\t_sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n\t  File \"Test_two_GPUs.py\", line 96, in main\r\n\t\tTest5()\r\n\t  File \"Test_two_GPUs.py\", line 85, in Test5\r\n\t\ts1 = tf.reduce_sum(t1)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\r\n\t\tname=name)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\r\n\t\tkeep_dims=keep_dims, name=name)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n\t\top_def=op_def)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\r\n\t\toriginal_op=self._default_original_op, op_def=op_def)\r\n\t  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\r\n\t\tself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\tResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\r\n\t\t\t [[Node: Sum_1 = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:1\"](ones_1, Const_1)]]"}