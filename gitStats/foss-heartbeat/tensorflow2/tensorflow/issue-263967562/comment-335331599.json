{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335331599", "html_url": "https://github.com/tensorflow/tensorflow/issues/13591#issuecomment-335331599", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13591", "id": 335331599, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMzMTU5OQ==", "user": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-10T01:18:11Z", "updated_at": "2017-10-10T01:18:11Z", "author_association": "MEMBER", "body_html": "<p>To answer your first question, the GPU allocation did not crash, because the optimizer did constant folding, which is run on the CPU. Constant folding evaluated the <code>tf.reduce_sum</code> call. The following code should crash on TensorFlow 1.3:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.core.protobuf <span class=\"pl-k\">import</span> rewriter_config_pb2\n\n<span class=\"pl-c1\">GPU_MEMORY_BYTES</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span><span class=\"pl-k\">**</span><span class=\"pl-c1\">30</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> Assuming your GPU has 8GB of memory, adjust accordingly</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Number of float32 elements (4 bytes) that consume 7/8 of GPU memory</span>\n<span class=\"pl-c1\">NUM_ELEMS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>((<span class=\"pl-c1\">7</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">GPU_MEMORY_BYTES</span> <span class=\"pl-k\">/</span> <span class=\"pl-c1\">8</span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">4</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">Test1</span>():\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/gpu:0<span class=\"pl-pds\">\"</span></span>):\n    t <span class=\"pl-k\">=</span> tf.ones([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">NUM_ELEMS</span>])\n  s <span class=\"pl-k\">=</span> tf.reduce_sum(t)\n  config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">gpu_options</span><span class=\"pl-k\">=</span>tf.GPUOptions(<span class=\"pl-v\">visible_device_list</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>0<span class=\"pl-pds\">'</span></span>),\n                          <span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n  config.graph_options.optimizer_options.opt_level <span class=\"pl-k\">=</span> tf.OptimizerOptions.L0\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> config.graph_options.rewrite_options.constant_folding = rewriter_config_pb2.RewriterConfig.OFF</span>\n  <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span>(sess.run(s)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> This should fail since it consumes more memory than exists in the GPU</span>\n\nTest1()</pre></div>\n<p>On master, the <code>config.graph_options.rewrite_options.constant_folding</code> line must also be uncommented to cause a crash.</p>\n<p>As for your second question, when I run <code>Test1</code> without disabling optimizations, I get 3.7581e+09, which is the correct answer. Perhaps you're getting a different result due to thread scheduling. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2533174\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ekelsen\">@ekelsen</a> do you know if reductions on the CPU consistency compute the reduce_sum of 3,758,096,384 float32 ones in a numerically stable way?</p>", "body_text": "To answer your first question, the GPU allocation did not crash, because the optimizer did constant folding, which is run on the CPU. Constant folding evaluated the tf.reduce_sum call. The following code should crash on TensorFlow 1.3:\nimport tensorflow as tf\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\nGPU_MEMORY_BYTES = 8 * 2**30 # Assuming your GPU has 8GB of memory, adjust accordingly\n\n# Number of float32 elements (4 bytes) that consume 7/8 of GPU memory\nNUM_ELEMS = int((7 * GPU_MEMORY_BYTES / 8) / 4)\n\ndef Test1():\n  with tf.device(\"/gpu:0\"):\n    t = tf.ones([2, NUM_ELEMS])\n  s = tf.reduce_sum(t)\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0'),\n                          allow_soft_placement=False)\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\n  # config.graph_options.rewrite_options.constant_folding = rewriter_config_pb2.RewriterConfig.OFF\n  with tf.Session(config=config) as sess:\n    print(sess.run(s)) # This should fail since it consumes more memory than exists in the GPU\n\nTest1()\nOn master, the config.graph_options.rewrite_options.constant_folding line must also be uncommented to cause a crash.\nAs for your second question, when I run Test1 without disabling optimizations, I get 3.7581e+09, which is the correct answer. Perhaps you're getting a different result due to thread scheduling. @ekelsen do you know if reductions on the CPU consistency compute the reduce_sum of 3,758,096,384 float32 ones in a numerically stable way?", "body": "To answer your first question, the GPU allocation did not crash, because the optimizer did constant folding, which is run on the CPU. Constant folding evaluated the `tf.reduce_sum` call. The following code should crash on TensorFlow 1.3:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2\r\n\r\nGPU_MEMORY_BYTES = 8 * 2**30 # Assuming your GPU has 8GB of memory, adjust accordingly\r\n\r\n# Number of float32 elements (4 bytes) that consume 7/8 of GPU memory\r\nNUM_ELEMS = int((7 * GPU_MEMORY_BYTES / 8) / 4)\r\n\r\ndef Test1():\r\n  with tf.device(\"/gpu:0\"):\r\n    t = tf.ones([2, NUM_ELEMS])\r\n  s = tf.reduce_sum(t)\r\n  config = tf.ConfigProto(gpu_options=tf.GPUOptions(visible_device_list='0'),\r\n                          allow_soft_placement=False)\r\n  config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\r\n  # config.graph_options.rewrite_options.constant_folding = rewriter_config_pb2.RewriterConfig.OFF\r\n  with tf.Session(config=config) as sess:\r\n    print(sess.run(s)) # This should fail since it consumes more memory than exists in the GPU\r\n\r\nTest1()\r\n```\r\n\r\nOn master, the `config.graph_options.rewrite_options.constant_folding` line must also be uncommented to cause a crash.\r\n\r\nAs for your second question, when I run `Test1` without disabling optimizations, I get 3.7581e+09, which is the correct answer. Perhaps you're getting a different result due to thread scheduling. @ekelsen do you know if reductions on the CPU consistency compute the reduce_sum of 3,758,096,384 float32 ones in a numerically stable way?"}