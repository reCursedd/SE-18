{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2995", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2995/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2995/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2995/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2995", "id": 161695751, "node_id": "MDU6SXNzdWUxNjE2OTU3NTE=", "number": 2995, "title": "Multiple (Bidirectional)LSTM layers leads to nan in loss when time step is large", "user": {"login": "yluo42", "id": 6149558, "node_id": "MDQ6VXNlcjYxNDk1NTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6149558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yluo42", "html_url": "https://github.com/yluo42", "followers_url": "https://api.github.com/users/yluo42/followers", "following_url": "https://api.github.com/users/yluo42/following{/other_user}", "gists_url": "https://api.github.com/users/yluo42/gists{/gist_id}", "starred_url": "https://api.github.com/users/yluo42/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yluo42/subscriptions", "organizations_url": "https://api.github.com/users/yluo42/orgs", "repos_url": "https://api.github.com/users/yluo42/repos", "events_url": "https://api.github.com/users/yluo42/events{/privacy}", "received_events_url": "https://api.github.com/users/yluo42/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2016-06-22T14:18:42Z", "updated_at": "2018-02-14T16:02:41Z", "closed_at": "2016-06-23T17:55:17Z", "author_association": "NONE", "body_html": "<p>I've tried to implement a deep LSTM network and tested it on an autoencoder task in recovering audio magnitude spectrogram. At first I set the number of frames in spectrogram (i.e. time step in LSTM) to be small, and both LSTM and BLSTM worked well. However, when the time step is large, both LSTM and BLSTM began to generate nan loss. To be more specific, when I used a time step of 20 frames, BLSTM worked well with 4 layers and can successfully recover the input; but when I increased it to 100, a 3 layer BLSTM network began to generate nan in two training steps.</p>\n<p>I think there might be some problem within the code for <code>rnn</code> and <code>bidirectional_rnn</code> function (maybe due to unrolling?), but I'm not sure if I did anything wrong.</p>\n<p>The codes for (B)LSTM I use are:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">LSTM</span>(<span class=\"pl-smi\">lstm_hidden</span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">X</span>, <span class=\"pl-smi\">chunk_size</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>LSTM<span class=\"pl-pds\">'</span></span>, <span class=\"pl-smi\">seq_len</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    initializer <span class=\"pl-k\">=</span> tf.random_uniform_initializer(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>)\n\n    cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.LSTMCell(lstm_hidden, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>initializer, \n                                   <span class=\"pl-v\">use_peepholes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">state_is_tuple</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    initial_state <span class=\"pl-k\">=</span> cell.zero_state(batch_size, tf.float32)\n\n    <span class=\"pl-k\">if</span> seq_len <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:     \n        output, _ <span class=\"pl-k\">=</span> tf.nn.rnn(cell, X, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>initial_state,\n                                             <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>seq_len, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>name)\n    <span class=\"pl-k\">else</span>:\n        output, _ <span class=\"pl-k\">=</span> tf.nn.rnn(cell, X, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>initial_state, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>name)\n\n    <span class=\"pl-k\">return</span> output</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">BLSTM</span>(<span class=\"pl-smi\">lstm_hidden</span>, <span class=\"pl-smi\">batch_size</span>, <span class=\"pl-smi\">X</span>, <span class=\"pl-smi\">chunk_size</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>BLSTM<span class=\"pl-pds\">'</span></span>, <span class=\"pl-smi\">seq_len</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    initializer <span class=\"pl-k\">=</span> tf.random_uniform_initializer(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>)\n\n    cell_fw <span class=\"pl-k\">=</span> tf.nn.rnn_cell.LSTMCell(lstm_hidden, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>initializer, \n                                      <span class=\"pl-v\">use_peepholes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">state_is_tuple</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    cell_bw <span class=\"pl-k\">=</span> tf.nn.rnn_cell.LSTMCell(lstm_hidden, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>initializer, \n                                      <span class=\"pl-v\">use_peepholes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">state_is_tuple</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> initial states</span>\n    initial_state_fw <span class=\"pl-k\">=</span> cell_fw.zero_state(batch_size, tf.float32)\n    initial_state_bw <span class=\"pl-k\">=</span> cell_bw.zero_state(batch_size, tf.float32)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> BLSTM</span>\n    <span class=\"pl-k\">if</span> seq_len <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:     \n        output, _, _ <span class=\"pl-k\">=</span> tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               <span class=\"pl-v\">initial_state_fw</span><span class=\"pl-k\">=</span>initial_state_fw,\n                                               <span class=\"pl-v\">initial_state_bw</span><span class=\"pl-k\">=</span>initial_state_bw, \n                                               <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>seq_len, \n                                               <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>name)\n\n    <span class=\"pl-k\">else</span>:\n        output, _, _ <span class=\"pl-k\">=</span> tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               <span class=\"pl-v\">initial_state_fw</span><span class=\"pl-k\">=</span>initial_state_fw,\n                                               <span class=\"pl-v\">initial_state_bw</span><span class=\"pl-k\">=</span>initial_state_bw, \n                                               <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>name)\n    <span class=\"pl-k\">return</span> output</pre></div>\n<p>and the loss function is the L2-loss between the recovered magnitude spectrogram and the input, so there might not be a divide-by-zero problem (anyway it works well when time step is small, so I think it's not due to the loss function).</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04.3<br>\nPython version: 2.7.6<br>\nTensorflow version: r0.9<br>\nCUDA version: 7.5</p>", "body_text": "I've tried to implement a deep LSTM network and tested it on an autoencoder task in recovering audio magnitude spectrogram. At first I set the number of frames in spectrogram (i.e. time step in LSTM) to be small, and both LSTM and BLSTM worked well. However, when the time step is large, both LSTM and BLSTM began to generate nan loss. To be more specific, when I used a time step of 20 frames, BLSTM worked well with 4 layers and can successfully recover the input; but when I increased it to 100, a 3 layer BLSTM network began to generate nan in two training steps.\nI think there might be some problem within the code for rnn and bidirectional_rnn function (maybe due to unrolling?), but I'm not sure if I did anything wrong.\nThe codes for (B)LSTM I use are:\ndef LSTM(lstm_hidden, batch_size, X, chunk_size, name='LSTM', seq_len=None):\n    initializer = tf.random_uniform_initializer(-1, 1)\n\n    cell = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                   use_peepholes=True, state_is_tuple=True)\n\n    initial_state = cell.zero_state(batch_size, tf.float32)\n\n    if seq_len is not None:     \n        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state,\n                                             sequence_length=seq_len, scope=name)\n    else:\n        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state, scope=name)\n\n    return output\ndef BLSTM(lstm_hidden, batch_size, X, chunk_size, name='BLSTM', seq_len=None):\n    initializer = tf.random_uniform_initializer(-1, 1)\n\n    cell_fw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                      use_peepholes=True, state_is_tuple=True)\n    cell_bw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                      use_peepholes=True, state_is_tuple=True)\n\n    # initial states\n    initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)\n    initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)\n\n    # BLSTM\n    if seq_len is not None:     \n        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               initial_state_fw=initial_state_fw,\n                                               initial_state_bw=initial_state_bw, \n                                               sequence_length=seq_len, \n                                               scope=name)\n\n    else:\n        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               initial_state_fw=initial_state_fw,\n                                               initial_state_bw=initial_state_bw, \n                                               scope=name)\n    return output\nand the loss function is the L2-loss between the recovered magnitude spectrogram and the input, so there might not be a divide-by-zero problem (anyway it works well when time step is small, so I think it's not due to the loss function).\nEnvironment info\nOperating System: Ubuntu 14.04.3\nPython version: 2.7.6\nTensorflow version: r0.9\nCUDA version: 7.5", "body": "I've tried to implement a deep LSTM network and tested it on an autoencoder task in recovering audio magnitude spectrogram. At first I set the number of frames in spectrogram (i.e. time step in LSTM) to be small, and both LSTM and BLSTM worked well. However, when the time step is large, both LSTM and BLSTM began to generate nan loss. To be more specific, when I used a time step of 20 frames, BLSTM worked well with 4 layers and can successfully recover the input; but when I increased it to 100, a 3 layer BLSTM network began to generate nan in two training steps.\n\nI think there might be some problem within the code for `rnn` and `bidirectional_rnn` function (maybe due to unrolling?), but I'm not sure if I did anything wrong.\n\nThe codes for (B)LSTM I use are:\n\n``` python\ndef LSTM(lstm_hidden, batch_size, X, chunk_size, name='LSTM', seq_len=None):\n    initializer = tf.random_uniform_initializer(-1, 1)\n\n    cell = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                   use_peepholes=True, state_is_tuple=True)\n\n    initial_state = cell.zero_state(batch_size, tf.float32)\n\n    if seq_len is not None:     \n        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state,\n                                             sequence_length=seq_len, scope=name)\n    else:\n        output, _ = tf.nn.rnn(cell, X, initial_state=initial_state, scope=name)\n\n    return output\n```\n\n``` python\ndef BLSTM(lstm_hidden, batch_size, X, chunk_size, name='BLSTM', seq_len=None):\n    initializer = tf.random_uniform_initializer(-1, 1)\n\n    cell_fw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                      use_peepholes=True, state_is_tuple=True)\n    cell_bw = tf.nn.rnn_cell.LSTMCell(lstm_hidden, initializer=initializer, \n                                      use_peepholes=True, state_is_tuple=True)\n\n    # initial states\n    initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)\n    initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)\n\n    # BLSTM\n    if seq_len is not None:     \n        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               initial_state_fw=initial_state_fw,\n                                               initial_state_bw=initial_state_bw, \n                                               sequence_length=seq_len, \n                                               scope=name)\n\n    else:\n        output, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, X, \n                                               initial_state_fw=initial_state_fw,\n                                               initial_state_bw=initial_state_bw, \n                                               scope=name)\n    return output\n```\n\nand the loss function is the L2-loss between the recovered magnitude spectrogram and the input, so there might not be a divide-by-zero problem (anyway it works well when time step is small, so I think it's not due to the loss function).\n### Environment info\n\nOperating System: Ubuntu 14.04.3\nPython version: 2.7.6\nTensorflow version: r0.9\nCUDA version: 7.5\n"}