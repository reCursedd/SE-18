{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232955908", "html_url": "https://github.com/tensorflow/tensorflow/issues/2995#issuecomment-232955908", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2995", "id": 232955908, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjk1NTkwOA==", "user": {"login": "rajkumarcm", "id": 9053016, "node_id": "MDQ6VXNlcjkwNTMwMTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9053016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajkumarcm", "html_url": "https://github.com/rajkumarcm", "followers_url": "https://api.github.com/users/rajkumarcm/followers", "following_url": "https://api.github.com/users/rajkumarcm/following{/other_user}", "gists_url": "https://api.github.com/users/rajkumarcm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajkumarcm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajkumarcm/subscriptions", "organizations_url": "https://api.github.com/users/rajkumarcm/orgs", "repos_url": "https://api.github.com/users/rajkumarcm/repos", "events_url": "https://api.github.com/users/rajkumarcm/events{/privacy}", "received_events_url": "https://api.github.com/users/rajkumarcm/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-15T13:50:57Z", "updated_at": "2016-07-15T13:50:57Z", "author_association": "NONE", "body_html": "<p>@ScartleRoy Could you please explain why you are concatenating the outputs from forward, and backward cells though ?<br>\nI thought it should be (as per <a href=\"http://www.cs.toronto.edu/~graves/asru_2013.pdf\" rel=\"nofollow\">Alex Graves, 2013):</a></p>\n<pre><code>\nfw_out = output[0]\nbw_out = output[1]\nfw_out = tf.reshape(fw_out,[-1,hidden_size])\nbw_out = tf.reshape(bw_out,[-1,hidden_size])\nW_fw   = tf.Variable(tf.truncated_normal(shape=[hidden_size,n_chars],\n                                         mean=0,stddev=0.1,dtype=tf.float32))\nW_bw = tf.Variable(tf.truncated_normal(shape=[hidden_size, n_chars],\n                                       mean=0, stddev=0.1, dtype=tf.float32))\nb_out = tf.constant(0.1,shape=[n_chars])\nlogits = tf.add(tf.add(tf.matmul(fw_out,W_fw), tf.matmul(bw_out,W_bw)),b_out)\n</code></pre>", "body_text": "@ScartleRoy Could you please explain why you are concatenating the outputs from forward, and backward cells though ?\nI thought it should be (as per Alex Graves, 2013):\n\nfw_out = output[0]\nbw_out = output[1]\nfw_out = tf.reshape(fw_out,[-1,hidden_size])\nbw_out = tf.reshape(bw_out,[-1,hidden_size])\nW_fw   = tf.Variable(tf.truncated_normal(shape=[hidden_size,n_chars],\n                                         mean=0,stddev=0.1,dtype=tf.float32))\nW_bw = tf.Variable(tf.truncated_normal(shape=[hidden_size, n_chars],\n                                       mean=0, stddev=0.1, dtype=tf.float32))\nb_out = tf.constant(0.1,shape=[n_chars])\nlogits = tf.add(tf.add(tf.matmul(fw_out,W_fw), tf.matmul(bw_out,W_bw)),b_out)", "body": "@ScartleRoy Could you please explain why you are concatenating the outputs from forward, and backward cells though ?\nI thought it should be (as per [Alex Graves, 2013):](http://www.cs.toronto.edu/~graves/asru_2013.pdf)\n\n<pre><code>\nfw_out = output[0]\nbw_out = output[1]\nfw_out = tf.reshape(fw_out,[-1,hidden_size])\nbw_out = tf.reshape(bw_out,[-1,hidden_size])\nW_fw   = tf.Variable(tf.truncated_normal(shape=[hidden_size,n_chars],\n                                         mean=0,stddev=0.1,dtype=tf.float32))\nW_bw = tf.Variable(tf.truncated_normal(shape=[hidden_size, n_chars],\n                                       mean=0, stddev=0.1, dtype=tf.float32))\nb_out = tf.constant(0.1,shape=[n_chars])\nlogits = tf.add(tf.add(tf.matmul(fw_out,W_fw), tf.matmul(bw_out,W_bw)),b_out)\n</code></pre>\n"}