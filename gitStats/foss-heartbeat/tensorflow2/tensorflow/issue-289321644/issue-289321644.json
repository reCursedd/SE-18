{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16194", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16194/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16194/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16194/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16194", "id": 289321644, "node_id": "MDU6SXNzdWUyODkzMjE2NDQ=", "number": 16194, "title": "Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.", "user": {"login": "xav12358", "id": 12400238, "node_id": "MDQ6VXNlcjEyNDAwMjM4", "avatar_url": "https://avatars2.githubusercontent.com/u/12400238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xav12358", "html_url": "https://github.com/xav12358", "followers_url": "https://api.github.com/users/xav12358/followers", "following_url": "https://api.github.com/users/xav12358/following{/other_user}", "gists_url": "https://api.github.com/users/xav12358/gists{/gist_id}", "starred_url": "https://api.github.com/users/xav12358/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xav12358/subscriptions", "organizations_url": "https://api.github.com/users/xav12358/orgs", "repos_url": "https://api.github.com/users/xav12358/repos", "events_url": "https://api.github.com/users/xav12358/events{/privacy}", "received_events_url": "https://api.github.com/users/xav12358/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-01-17T16:09:30Z", "updated_at": "2018-09-30T06:12:37Z", "closed_at": "2018-02-15T00:07:39Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>I try to get the output of each layer of my CNN. Here is the full example:</p>\n<pre><code>`from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport tempfile\nimport os\nimport DatasetReader as dr\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nimport utils\nFLAGS = None\nPLOT_DIR = './output/plots'\n\n\ndef deepnn(x):\n\n  with tf.name_scope('reshape'):\n\n    x_image = tf.reshape(x, [-1, 100, 100, 1])#(x, [-1, 28, 28, 1])\n\n  # First convolutional layer - maps one grayscale image to 32 feature maps.\n  with tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 32])#([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    # conv1dis = conv2d(x_image, W_conv1) + b_conv1\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n    tf.add_to_collection('conv_weights', conv2d(x_image, W_conv1))\n\n  # Pooling layer - downsamples by 2X.\n  with tf.name_scope('pool1'):\n    h_pool1 = max_pool_2x2(h_conv1)\n\n  # Second convolutional layer -- maps 32 feature maps to 64.\n  with tf.name_scope('conv2'):\n    W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv2 = bias_variable([64])\n    # conv2dis = conv2d(h_pool1, W_conv2) + b_conv2\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    # tf.add_to_collection('conv_weights', h_conv2)\n\n  # Second pooling layer.\n  with tf.name_scope('pool2'):\n    h_pool2 = max_pool_2x2(h_conv2)\n\n  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n  with tf.name_scope('fc1'):\n    W_fc1 = weight_variable([25 * 25 * 64, 1024])\n    b_fc1 = bias_variable([1024])\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 25*25*64])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n    # tf.add_to_collection('conv_weights', W_fc1)\n\n  # Dropout - controls the complexity of the model, prevents co-adaptation of\n  # features.\n  with tf.name_scope('dropout'):\n    keep_prob = tf.placeholder(tf.float32)\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n  # Map the 1024 features to 10 classes, one for each digit\n  with tf.name_scope('fc2'):\n    W_fc2 = weight_variable([1024, 2])\n    b_fc2 = bias_variable([2])\n\n  y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n  return y_conv, keep_prob\n\n\ndef conv2d(x, W):\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\n\n\ndef weight_variable(shape):\n  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\n\ndef main(_):\n  # Import data\n  V0Dataset = dr.read_data_sets(FLAGS.data_dir, one_hot=True)\n\n  datasize = 10000\n  # Create the model\n  x = tf.placeholder(tf.float32, [None, datasize])#224*172])\n\n  # Define loss and optimizer\n  y_ = tf.placeholder(tf.float32, [None, 2])\n  print(\"logits shape {}\".format(y_))\n\n\n  # # Build the graph for the deep net\n  y_conv, keep_prob = deepnn(x)\n\n  with tf.name_scope('loss'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n                                                            logits=y_conv)\n  cross_entropy = tf.reduce_mean(cross_entropy)\n\n  with tf.name_scope('adam_optimizer'):\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n  with tf.name_scope('accuracy'):\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\n\n  accuracy = tf.reduce_mean(correct_prediction)\n\n  print('cross_entropy {}'.format(cross_entropy))\n  print('accuracy {}'.format(accuracy))\n\n\n\n  with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(2):#500):\n      batch = V0Dataset.train.next_batch(10)\n      a = batch[1];\n      a = a.reshape(10,2)\n      train_step.run(feed_dict={x: batch[0], y_: a, keep_prob: 0.5})\n\n\n\n    graph_location = tempfile.mkdtemp()\n    print('Saving graph to: %s' % graph_location)\n    train_writer = tf.summary.FileWriter(\"/tmp/tensorflow/\")\n    train_writer.add_graph(tf.get_default_graph())\n\n    conv0 = sess.graph.get_tensor_by_name('conv1/Conv2D:0')\n    print(\"conv0 {}\".format(conv0))\n\n    predictions0 = sess.run(conv0,\n                           {'DecodeJpeg/contents:0': batch[0]}) # Error!!!!\n    print(\"predictions0 {}\".format(predictions0))\n    print(\"predictions0 {}\".format(predictions0.size))\n\n</code></pre>\n<p>Here are the errors I get:</p>\n<pre><code>`Traceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1064, in _run\n    allow_operation=False)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3035, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3077, in _as_graph_element_locked\n    \"graph.\" % (repr(name), repr(op_name)))\nKeyError: \"The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\"\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./deep_charging_station_train.py\", line 309, in &lt;module&gt;\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"./deep_charging_station_train.py\", line 297, in main\n    {'DecodeJpeg/contents:0': batch[0]})\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1067, in _run\n    + e.args[0])\nTypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\n`\n\n\n\n</code></pre>\n<p>I don't understand why this appends. I looked with Tensorboard I don't know where should I get the DecodeJpeg informations of the layer</p>\n<p>Edit:<br>\nHave I written custom code : I use deep mnist tutorial example and I modify the size of the input image<br>\nOS Platform and Distribution : Ubuntu 16.04<br>\nTensorFlow installed from<br>\nTensorFlow version 1.4.0<br>\nBazel version N/A<br>\nCUDA/cuDNN version N/A<br>\nGPU model and memory N/A<br>\nExact command to reproduce</p>", "body_text": "Hello,\nI try to get the output of each layer of my CNN. Here is the full example:\n`from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport tempfile\nimport os\nimport DatasetReader as dr\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nimport utils\nFLAGS = None\nPLOT_DIR = './output/plots'\n\n\ndef deepnn(x):\n\n  with tf.name_scope('reshape'):\n\n    x_image = tf.reshape(x, [-1, 100, 100, 1])#(x, [-1, 28, 28, 1])\n\n  # First convolutional layer - maps one grayscale image to 32 feature maps.\n  with tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 32])#([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    # conv1dis = conv2d(x_image, W_conv1) + b_conv1\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n    tf.add_to_collection('conv_weights', conv2d(x_image, W_conv1))\n\n  # Pooling layer - downsamples by 2X.\n  with tf.name_scope('pool1'):\n    h_pool1 = max_pool_2x2(h_conv1)\n\n  # Second convolutional layer -- maps 32 feature maps to 64.\n  with tf.name_scope('conv2'):\n    W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv2 = bias_variable([64])\n    # conv2dis = conv2d(h_pool1, W_conv2) + b_conv2\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    # tf.add_to_collection('conv_weights', h_conv2)\n\n  # Second pooling layer.\n  with tf.name_scope('pool2'):\n    h_pool2 = max_pool_2x2(h_conv2)\n\n  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n  with tf.name_scope('fc1'):\n    W_fc1 = weight_variable([25 * 25 * 64, 1024])\n    b_fc1 = bias_variable([1024])\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 25*25*64])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n    # tf.add_to_collection('conv_weights', W_fc1)\n\n  # Dropout - controls the complexity of the model, prevents co-adaptation of\n  # features.\n  with tf.name_scope('dropout'):\n    keep_prob = tf.placeholder(tf.float32)\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n  # Map the 1024 features to 10 classes, one for each digit\n  with tf.name_scope('fc2'):\n    W_fc2 = weight_variable([1024, 2])\n    b_fc2 = bias_variable([2])\n\n  y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n  return y_conv, keep_prob\n\n\ndef conv2d(x, W):\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\n\n\ndef weight_variable(shape):\n  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\n\ndef main(_):\n  # Import data\n  V0Dataset = dr.read_data_sets(FLAGS.data_dir, one_hot=True)\n\n  datasize = 10000\n  # Create the model\n  x = tf.placeholder(tf.float32, [None, datasize])#224*172])\n\n  # Define loss and optimizer\n  y_ = tf.placeholder(tf.float32, [None, 2])\n  print(\"logits shape {}\".format(y_))\n\n\n  # # Build the graph for the deep net\n  y_conv, keep_prob = deepnn(x)\n\n  with tf.name_scope('loss'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n                                                            logits=y_conv)\n  cross_entropy = tf.reduce_mean(cross_entropy)\n\n  with tf.name_scope('adam_optimizer'):\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n  with tf.name_scope('accuracy'):\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\n\n  accuracy = tf.reduce_mean(correct_prediction)\n\n  print('cross_entropy {}'.format(cross_entropy))\n  print('accuracy {}'.format(accuracy))\n\n\n\n  with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(2):#500):\n      batch = V0Dataset.train.next_batch(10)\n      a = batch[1];\n      a = a.reshape(10,2)\n      train_step.run(feed_dict={x: batch[0], y_: a, keep_prob: 0.5})\n\n\n\n    graph_location = tempfile.mkdtemp()\n    print('Saving graph to: %s' % graph_location)\n    train_writer = tf.summary.FileWriter(\"/tmp/tensorflow/\")\n    train_writer.add_graph(tf.get_default_graph())\n\n    conv0 = sess.graph.get_tensor_by_name('conv1/Conv2D:0')\n    print(\"conv0 {}\".format(conv0))\n\n    predictions0 = sess.run(conv0,\n                           {'DecodeJpeg/contents:0': batch[0]}) # Error!!!!\n    print(\"predictions0 {}\".format(predictions0))\n    print(\"predictions0 {}\".format(predictions0.size))\n\n\nHere are the errors I get:\n`Traceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1064, in _run\n    allow_operation=False)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3035, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3077, in _as_graph_element_locked\n    \"graph.\" % (repr(name), repr(op_name)))\nKeyError: \"The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\"\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./deep_charging_station_train.py\", line 309, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"./deep_charging_station_train.py\", line 297, in main\n    {'DecodeJpeg/contents:0': batch[0]})\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1067, in _run\n    + e.args[0])\nTypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\n`\n\n\n\n\nI don't understand why this appends. I looked with Tensorboard I don't know where should I get the DecodeJpeg informations of the layer\nEdit:\nHave I written custom code : I use deep mnist tutorial example and I modify the size of the input image\nOS Platform and Distribution : Ubuntu 16.04\nTensorFlow installed from\nTensorFlow version 1.4.0\nBazel version N/A\nCUDA/cuDNN version N/A\nGPU model and memory N/A\nExact command to reproduce", "body": "Hello,\r\n\r\nI try to get the output of each layer of my CNN. Here is the full example:\r\n```\r\n`from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport sys\r\nimport tempfile\r\nimport os\r\nimport DatasetReader as dr\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nimport tensorflow as tf\r\nimport utils\r\nFLAGS = None\r\nPLOT_DIR = './output/plots'\r\n\r\n\r\ndef deepnn(x):\r\n\r\n  with tf.name_scope('reshape'):\r\n\r\n    x_image = tf.reshape(x, [-1, 100, 100, 1])#(x, [-1, 28, 28, 1])\r\n\r\n  # First convolutional layer - maps one grayscale image to 32 feature maps.\r\n  with tf.name_scope('conv1'):\r\n    W_conv1 = weight_variable([5, 5, 1, 32])#([5, 5, 1, 32])\r\n    b_conv1 = bias_variable([32])\r\n    # conv1dis = conv2d(x_image, W_conv1) + b_conv1\r\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n    tf.add_to_collection('conv_weights', conv2d(x_image, W_conv1))\r\n\r\n  # Pooling layer - downsamples by 2X.\r\n  with tf.name_scope('pool1'):\r\n    h_pool1 = max_pool_2x2(h_conv1)\r\n\r\n  # Second convolutional layer -- maps 32 feature maps to 64.\r\n  with tf.name_scope('conv2'):\r\n    W_conv2 = weight_variable([5, 5, 32, 64])\r\n    b_conv2 = bias_variable([64])\r\n    # conv2dis = conv2d(h_pool1, W_conv2) + b_conv2\r\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n    # tf.add_to_collection('conv_weights', h_conv2)\r\n\r\n  # Second pooling layer.\r\n  with tf.name_scope('pool2'):\r\n    h_pool2 = max_pool_2x2(h_conv2)\r\n\r\n  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\r\n  # is down to 7x7x64 feature maps -- maps this to 1024 features.\r\n  with tf.name_scope('fc1'):\r\n    W_fc1 = weight_variable([25 * 25 * 64, 1024])\r\n    b_fc1 = bias_variable([1024])\r\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 25*25*64])\r\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\r\n    # tf.add_to_collection('conv_weights', W_fc1)\r\n\r\n  # Dropout - controls the complexity of the model, prevents co-adaptation of\r\n  # features.\r\n  with tf.name_scope('dropout'):\r\n    keep_prob = tf.placeholder(tf.float32)\r\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n\r\n  # Map the 1024 features to 10 classes, one for each digit\r\n  with tf.name_scope('fc2'):\r\n    W_fc2 = weight_variable([1024, 2])\r\n    b_fc2 = bias_variable([2])\r\n\r\n  y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\r\n\r\n  return y_conv, keep_prob\r\n\r\n\r\ndef conv2d(x, W):\r\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\r\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\n\r\ndef max_pool_2x2(x):\r\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\r\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\r\n                        strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\ndef weight_variable(shape):\r\n  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\r\n  initial = tf.truncated_normal(shape, stddev=0.1)\r\n  return tf.Variable(initial)\r\n\r\n\r\ndef bias_variable(shape):\r\n  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\r\n  initial = tf.constant(0.1, shape=shape)\r\n  return tf.Variable(initial)\r\n\r\n\r\ndef main(_):\r\n  # Import data\r\n  V0Dataset = dr.read_data_sets(FLAGS.data_dir, one_hot=True)\r\n\r\n  datasize = 10000\r\n  # Create the model\r\n  x = tf.placeholder(tf.float32, [None, datasize])#224*172])\r\n\r\n  # Define loss and optimizer\r\n  y_ = tf.placeholder(tf.float32, [None, 2])\r\n  print(\"logits shape {}\".format(y_))\r\n\r\n\r\n  # # Build the graph for the deep net\r\n  y_conv, keep_prob = deepnn(x)\r\n\r\n  with tf.name_scope('loss'):\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\r\n                                                            logits=y_conv)\r\n  cross_entropy = tf.reduce_mean(cross_entropy)\r\n\r\n  with tf.name_scope('adam_optimizer'):\r\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n\r\n  with tf.name_scope('accuracy'):\r\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\r\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\r\n\r\n  accuracy = tf.reduce_mean(correct_prediction)\r\n\r\n  print('cross_entropy {}'.format(cross_entropy))\r\n  print('accuracy {}'.format(accuracy))\r\n\r\n\r\n\r\n  with tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for i in range(2):#500):\r\n      batch = V0Dataset.train.next_batch(10)\r\n      a = batch[1];\r\n      a = a.reshape(10,2)\r\n      train_step.run(feed_dict={x: batch[0], y_: a, keep_prob: 0.5})\r\n\r\n\r\n\r\n    graph_location = tempfile.mkdtemp()\r\n    print('Saving graph to: %s' % graph_location)\r\n    train_writer = tf.summary.FileWriter(\"/tmp/tensorflow/\")\r\n    train_writer.add_graph(tf.get_default_graph())\r\n\r\n    conv0 = sess.graph.get_tensor_by_name('conv1/Conv2D:0')\r\n    print(\"conv0 {}\".format(conv0))\r\n\r\n    predictions0 = sess.run(conv0,\r\n                           {'DecodeJpeg/contents:0': batch[0]}) # Error!!!!\r\n    print(\"predictions0 {}\".format(predictions0))\r\n    print(\"predictions0 {}\".format(predictions0.size))\r\n\r\n```\r\n\r\nHere are the errors I get:\r\n```\r\n`Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1064, in _run\r\n    allow_operation=False)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3035, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3077, in _as_graph_element_locked\r\n    \"graph.\" % (repr(name), repr(op_name)))\r\nKeyError: \"The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./deep_charging_station_train.py\", line 309, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"./deep_charging_station_train.py\", line 297, in main\r\n    {'DecodeJpeg/contents:0': batch[0]})\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1067, in _run\r\n    + e.args[0])\r\nTypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\r\n`\r\n\r\n\r\n\r\n```\r\n\r\nI don't understand why this appends. I looked with Tensorboard I don't know where should I get the DecodeJpeg informations of the layer\r\n\r\nEdit:\r\nHave I written custom code : I use deep mnist tutorial example and I modify the size of the input image\r\nOS Platform and Distribution : Ubuntu 16.04\r\nTensorFlow installed from\r\nTensorFlow version 1.4.0\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce\r\n"}