{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257000911", "html_url": "https://github.com/tensorflow/tensorflow/issues/5253#issuecomment-257000911", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5253", "id": 257000911, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzAwMDkxMQ==", "user": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T18:57:16Z", "updated_at": "2016-10-28T18:57:16Z", "author_association": "MEMBER", "body_html": "<p>It's possible that the related issues are <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"139073853\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/bazelbuild/bazel/issues/1022\" data-hovercard-type=\"issue\" data-hovercard-url=\"/bazelbuild/bazel/issues/1022/hovercard\" href=\"https://github.com/bazelbuild/bazel/issues/1022\">bazelbuild/bazel#1022</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"168825770\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/bazelbuild/bazel/issues/1595\" data-hovercard-type=\"issue\" data-hovercard-url=\"/bazelbuild/bazel/issues/1595/hovercard\" href=\"https://github.com/bazelbuild/bazel/issues/1595\">bazelbuild/bazel#1595</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"136202727\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/bazelbuild/bazel/issues/974\" data-hovercard-type=\"issue\" data-hovercard-url=\"/bazelbuild/bazel/issues/974/hovercard\" href=\"https://github.com/bazelbuild/bazel/issues/974\">bazelbuild/bazel#974</a>. There was another one, but I'm having trouble digging it up.</p>\n<p>Also here is an explanation that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5283042\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/davidzchen\">@davidzchen</a> gave me a week ago regarding the necessity of fetch.</p>\n<blockquote>\n<p>The reason why we fetch in the configure script is because the way the script<br>\npasses values to the cuda_configure workspace rule is via environment variables<br>\n(see comment at the top of <a href=\"https://github.com/tensorflow/tensorflow/blob/d95a5b7cc6dca2d3603d73da1078274b29639ec7/third_party/gpus/cuda_configure.bzl\">cuda_configure.bzl</a>).</p>\n<p>The configure script exports these environment variables before calling bazel<br>\nfetch, which will set up external repositories, such as @local_config_cuda,<br>\naccording to the values provided by the user. However, if we do not do this,<br>\nwhen the user runs bazel fetch/build after running ./configure, then<br>\ncuda_configure will use the environment variables in the user's shell, which<br>\nwould not contain any of the values set by ./configure.</p>\n<p>That is, with this change, even if the user runs ./configure to enabling<br>\nbuilding with CUDA, when the user subsequently runs bazel build, the build will<br>\nfail because @local_config_cuda would have been configured without GPU support.</p>\n<p>It might be more ideal to be able to pass values to Skylark repository rules<br>\nvia command line flags. For example, something like the following would build<br>\nwith CUDA support enabled, and cuda_configure would look for the cuda<br>\ninstallation in a set of standard install locations:</p>\n<pre><code>bazel build --enable_cuda //tensorflow/...\n</code></pre>\n<p>If the user would like to specify a custom cuda install location, then she<br>\nwould be able to do so with another flag:</p>\n<pre><code>bazel build --enable_cuda --cuda_toolkit_path=/opt/local //tensorflow/...\n</code></pre>\n<p>If adding arbitrary flags is not feasible, then perhaps we can use an approach<br>\nsimilar to the kubernetes vars:</p>\n<pre><code>bazel build --vars=enable_cuda=true,cuda_toolkit_path=/opt/local //tensorflow/...\n</code></pre>\n<p>These are hypothetical examples, and I haven't scoped out the work that would<br>\nbe required to implement this feature. However, with the way things are set up<br>\ncurrently, removing the fetch from the configure script would cause the build<br>\nto fail.</p>\n</blockquote>\n<p>We're also working hard to pay off the technical debt in TensorFlow that is contributing to this broader problem. For example, we recently committed <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/1dba78b997dc49df9df663a838e0bacd6602f5b8/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/1dba78b997dc49df9df663a838e0bacd6602f5b8\"><tt>1dba78b</tt></a> which removes SWIG from the configure script. So we're one step closer to having a hermetically sealed build.</p>\n<p>Once the Bazel bugs are fixed, and once TensorFlow is fully hermetically sealed, <code>bazel clean</code> will become a command that no one will ever need to run again.</p>", "body_text": "It's possible that the related issues are bazelbuild/bazel#1022 and bazelbuild/bazel#1595 and bazelbuild/bazel#974. There was another one, but I'm having trouble digging it up.\nAlso here is an explanation that @davidzchen gave me a week ago regarding the necessity of fetch.\n\nThe reason why we fetch in the configure script is because the way the script\npasses values to the cuda_configure workspace rule is via environment variables\n(see comment at the top of cuda_configure.bzl).\nThe configure script exports these environment variables before calling bazel\nfetch, which will set up external repositories, such as @local_config_cuda,\naccording to the values provided by the user. However, if we do not do this,\nwhen the user runs bazel fetch/build after running ./configure, then\ncuda_configure will use the environment variables in the user's shell, which\nwould not contain any of the values set by ./configure.\nThat is, with this change, even if the user runs ./configure to enabling\nbuilding with CUDA, when the user subsequently runs bazel build, the build will\nfail because @local_config_cuda would have been configured without GPU support.\nIt might be more ideal to be able to pass values to Skylark repository rules\nvia command line flags. For example, something like the following would build\nwith CUDA support enabled, and cuda_configure would look for the cuda\ninstallation in a set of standard install locations:\nbazel build --enable_cuda //tensorflow/...\n\nIf the user would like to specify a custom cuda install location, then she\nwould be able to do so with another flag:\nbazel build --enable_cuda --cuda_toolkit_path=/opt/local //tensorflow/...\n\nIf adding arbitrary flags is not feasible, then perhaps we can use an approach\nsimilar to the kubernetes vars:\nbazel build --vars=enable_cuda=true,cuda_toolkit_path=/opt/local //tensorflow/...\n\nThese are hypothetical examples, and I haven't scoped out the work that would\nbe required to implement this feature. However, with the way things are set up\ncurrently, removing the fetch from the configure script would cause the build\nto fail.\n\nWe're also working hard to pay off the technical debt in TensorFlow that is contributing to this broader problem. For example, we recently committed 1dba78b which removes SWIG from the configure script. So we're one step closer to having a hermetically sealed build.\nOnce the Bazel bugs are fixed, and once TensorFlow is fully hermetically sealed, bazel clean will become a command that no one will ever need to run again.", "body": "It's possible that the related issues are https://github.com/bazelbuild/bazel/issues/1022 and https://github.com/bazelbuild/bazel/issues/1595 and https://github.com/bazelbuild/bazel/issues/974. There was another one, but I'm having trouble digging it up.\n\nAlso here is an explanation that @davidzchen gave me a week ago regarding the necessity of fetch.\n\n> The reason why we fetch in the configure script is because the way the script\n> passes values to the cuda_configure workspace rule is via environment variables\n> (see comment at the top of [cuda_configure.bzl](https://github.com/tensorflow/tensorflow/blob/d95a5b7cc6dca2d3603d73da1078274b29639ec7/third_party/gpus/cuda_configure.bzl)).\n> \n> The configure script exports these environment variables before calling bazel\n> fetch, which will set up external repositories, such as @local_config_cuda,\n> according to the values provided by the user. However, if we do not do this,\n> when the user runs bazel fetch/build after running ./configure, then\n> cuda_configure will use the environment variables in the user's shell, which\n> would not contain any of the values set by ./configure.\n> \n> That is, with this change, even if the user runs ./configure to enabling\n> building with CUDA, when the user subsequently runs bazel build, the build will\n> fail because @local_config_cuda would have been configured without GPU support.\n> \n> It might be more ideal to be able to pass values to Skylark repository rules\n> via command line flags. For example, something like the following would build\n> with CUDA support enabled, and cuda_configure would look for the cuda\n> installation in a set of standard install locations:\n> \n> ```\n> bazel build --enable_cuda //tensorflow/...\n> ```\n> \n> If the user would like to specify a custom cuda install location, then she\n> would be able to do so with another flag:\n> \n> ```\n> bazel build --enable_cuda --cuda_toolkit_path=/opt/local //tensorflow/...\n> ```\n> \n> If adding arbitrary flags is not feasible, then perhaps we can use an approach\n> similar to the kubernetes vars:\n> \n> ```\n> bazel build --vars=enable_cuda=true,cuda_toolkit_path=/opt/local //tensorflow/...\n> ```\n> \n> These are hypothetical examples, and I haven't scoped out the work that would\n> be required to implement this feature. However, with the way things are set up\n> currently, removing the fetch from the configure script would cause the build\n> to fail.\n\nWe're also working hard to pay off the technical debt in TensorFlow that is contributing to this broader problem. For example, we recently committed https://github.com/tensorflow/tensorflow/commit/1dba78b997dc49df9df663a838e0bacd6602f5b8 which removes SWIG from the configure script. So we're one step closer to having a hermetically sealed build.\n\nOnce the Bazel bugs are fixed, and once TensorFlow is fully hermetically sealed, `bazel clean` will become a command that no one will ever need to run again.\n"}