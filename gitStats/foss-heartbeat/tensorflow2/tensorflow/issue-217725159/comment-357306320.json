{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357306320", "html_url": "https://github.com/tensorflow/tensorflow/issues/8787#issuecomment-357306320", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8787", "id": 357306320, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzMwNjMyMA==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-12T17:43:40Z", "updated_at": "2018-01-12T17:43:40Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">What would happen here is that you process the inputs in the TensorFlow\ngraph, evaluate them individually (note that every Session.run call has\nsome non-trivial overhead, especially if you transfer data, such as res),\nand then do a bunch of work to get them back into the graph (which is what\nfit_generator does).\n\nIt would work, but it would be very inefficient.\n\nTry using model_to_estimator, or, especially if you're writing a model from\nscratch, put your model directly into a model_fn.\n\nMartin</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Jan 12, 2018 at 9:23 AM, \u041c\u0438\u0445\u0430\u0438\u043b \u041e\u0441\u044c\u043a\u0438\u043d ***@***.***&gt; wrote:\n Are there any disadvantages in converting input_tensor from tfrecords into\n a generator this way:\n\n def` tensors2gen(*input_tensors):\n     while True:\n         res = sess.run(input_tensors)\n         if len(input_tensors) == 1:\n             res = res[0]\n         yield res\n\n and then train a model using fit_generator that also supports validation\n data parameter?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"217725159\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8787\" href=\"https://github.com/tensorflow/tensorflow/issues/8787#issuecomment-357289279\">#8787 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAjO_QBThSQuVoklfCI-5GaomoDEHhvTks5tJ5UGgaJpZM4MsVNC\">https://github.com/notifications/unsubscribe-auth/AAjO_QBThSQuVoklfCI-5GaomoDEHhvTks5tJ5UGgaJpZM4MsVNC</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "What would happen here is that you process the inputs in the TensorFlow\ngraph, evaluate them individually (note that every Session.run call has\nsome non-trivial overhead, especially if you transfer data, such as res),\nand then do a bunch of work to get them back into the graph (which is what\nfit_generator does).\n\nIt would work, but it would be very inefficient.\n\nTry using model_to_estimator, or, especially if you're writing a model from\nscratch, put your model directly into a model_fn.\n\nMartin\n\u2026\nOn Fri, Jan 12, 2018 at 9:23 AM, \u041c\u0438\u0445\u0430\u0438\u043b \u041e\u0441\u044c\u043a\u0438\u043d ***@***.***> wrote:\n Are there any disadvantages in converting input_tensor from tfrecords into\n a generator this way:\n\n def` tensors2gen(*input_tensors):\n     while True:\n         res = sess.run(input_tensors)\n         if len(input_tensors) == 1:\n             res = res[0]\n         yield res\n\n and then train a model using fit_generator that also supports validation\n data parameter?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#8787 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAjO_QBThSQuVoklfCI-5GaomoDEHhvTks5tJ5UGgaJpZM4MsVNC>\n .", "body": "What would happen here is that you process the inputs in the TensorFlow\ngraph, evaluate them individually (note that every Session.run call has\nsome non-trivial overhead, especially if you transfer data, such as res),\nand then do a bunch of work to get them back into the graph (which is what\nfit_generator does).\n\nIt would work, but it would be very inefficient.\n\nTry using model_to_estimator, or, especially if you're writing a model from\nscratch, put your model directly into a model_fn.\n\nMartin\n\nOn Fri, Jan 12, 2018 at 9:23 AM, \u041c\u0438\u0445\u0430\u0438\u043b \u041e\u0441\u044c\u043a\u0438\u043d <notifications@github.com>\nwrote:\n\n> Are there any disadvantages in converting input_tensor from tfrecords into\n> a generator this way:\n>\n> def` tensors2gen(*input_tensors):\n>     while True:\n>         res = sess.run(input_tensors)\n>         if len(input_tensors) == 1:\n>             res = res[0]\n>         yield res\n>\n> and then train a model using fit_generator that also supports validation\n> data parameter?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8787#issuecomment-357289279>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAjO_QBThSQuVoklfCI-5GaomoDEHhvTks5tJ5UGgaJpZM4MsVNC>\n> .\n>\n"}