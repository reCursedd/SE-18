{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13157", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13157/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13157/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13157/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13157", "id": 258873063, "node_id": "MDU6SXNzdWUyNTg4NzMwNjM=", "number": 13157, "title": "Error for slim dataset using fixed length reader", "user": {"login": "ybsave", "id": 26417094, "node_id": "MDQ6VXNlcjI2NDE3MDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26417094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybsave", "html_url": "https://github.com/ybsave", "followers_url": "https://api.github.com/users/ybsave/followers", "following_url": "https://api.github.com/users/ybsave/following{/other_user}", "gists_url": "https://api.github.com/users/ybsave/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybsave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybsave/subscriptions", "organizations_url": "https://api.github.com/users/ybsave/orgs", "repos_url": "https://api.github.com/users/ybsave/repos", "events_url": "https://api.github.com/users/ybsave/events{/privacy}", "received_events_url": "https://api.github.com/users/ybsave/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-19T15:54:14Z", "updated_at": "2017-09-19T22:42:48Z", "closed_at": "2017-09-19T17:17:21Z", "author_association": "NONE", "body_html": "<p>I want to use tensorflow slim data provider. All examples I can find only are only reading tfrecord files. However, I want to read binary files directly by my own reader. I use fixed length reader to extract Cifar10 binary data.</p>\n<p>However, \"dataBytes = tf.decode_raw(data, tf.unit8)\" always produce error that \"AttributeError: module 'tensorflow' has no attribute 'unit8'\" when using in slim DatasetDataProvider.</p>\n<p>But no such error occurs when I use the reader directly without using DatasetDataProvider. Did I not use it correctly or does DatasetDataProvider only support tfrecord readers? Thank you.</p>\n<p>My codes are as below:</p>\n<pre><code>CIFAR_LABEL_BYTE = 1\nCIFAR_HEIGHT = 32\nCIFAR_WIDTH = 32\nCIFAR_DEPTH = 3\nCIFAR_RECORD_BYTE = CIFAR_HEIGHT * CIFAR_WIDTH * CIFAR_DEPTH + CIFAR_LABEL_BYTE\n\nCIFAR_CLASS_NUM = 10\nCIFAR_TRAINING_NUM = 50000\nCIFAR_TEST_NUM = 10000\n\n_ITEMS_TO_DESCRIPTIONS = {\n\t'image': 'A [32 x 32 x 3] color image.',\n\t'label': 'A single integer between 0 and 9',\n}\n\nclass CifarBinaryDecoder(DataDecoder):\n  def decode(self, data, items):\n\toutputs = []\n            print(data.shape)\n\tdataBytes = tf.decode_raw(data, tf.uint8)\n\tfor item in items:\n\t  if item == 'label':\n\t\tcurrLabel = tf.cast(tf.strided_slice(dataBytes, [0], CIFAR_LABEL_BYTE), tf.int32)\n\t\toutputs.append(currLabel)\n\t  if item == 'image':\n\t\timageData = tf.reshpae(tf.strided_slice(dataBytes, [CIFAR_LABEL_BYTE],[CIFAR_RECORD_BYTE]), [CIFAR_DEPTH, CIFAR_HEIGHT, CIFAR_WIDTH])\n\t\timageData = tf.transpose(imageData, [1, 2, 0])\n\t\toutputs.append(imageData)\n\n\treturn outputs\n\n def list_items(self):\n\treturn ['label', 'image']\n\ndef get_cifar10_training_filenames(binary_data_dir):\n  file_pattern = ['test_batch.bin']\n  return file_pattern\n\ndef get_cifar_training_dataset(binary_data_dir):\n  file_pattern = get_cifar10_training_filenames(binary_data_dir)\n  decoder = CifarBinaryDecoder()\n  return slim.dataset.Dataset(data_sources = file_pattern,\n\t\t\t\t\t\t\t  reader = tf.FixedLengthRecordReader,\n\t\t\t\t\t\t\t  decoder = decoder,\n\t\t\t\t\t\t\t  num_samples = CIFAR_TRAINING_NUM,\n\t\t\t\t\t\t\t  items_to_descriptions = _ITEMS_TO_DESCRIPTIONS,\n\t\t\t\t\t\t\t  num_classes = CIFAR_CLASS_NUM)\n\ndef main(_):  \n  dataset = get_cifar_training_dataset(FLAGS.cifar_data_dir)\n  provider = slim.dataset_data_provider.DatasetDataProvider(\n\t  dataset,\n\t  num_readers = 1,\n\t  common_queue_capacity = 1000,\n\t  common_queue_min = 500,\n\t  reader_kwargs={'record_bytes' : CIFAR_RECORD_BYTE})\n\n with tf.Session() as sess:\n\tinit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n\tsess.run(init_op)\n\ttf.train.start_queue_runners()\n\n\tfor i in range(2):\n\t  [img, lab] = provider.get(['image', 'label'])\n              image, label = sess.run([img, lab])\n</code></pre>", "body_text": "I want to use tensorflow slim data provider. All examples I can find only are only reading tfrecord files. However, I want to read binary files directly by my own reader. I use fixed length reader to extract Cifar10 binary data.\nHowever, \"dataBytes = tf.decode_raw(data, tf.unit8)\" always produce error that \"AttributeError: module 'tensorflow' has no attribute 'unit8'\" when using in slim DatasetDataProvider.\nBut no such error occurs when I use the reader directly without using DatasetDataProvider. Did I not use it correctly or does DatasetDataProvider only support tfrecord readers? Thank you.\nMy codes are as below:\nCIFAR_LABEL_BYTE = 1\nCIFAR_HEIGHT = 32\nCIFAR_WIDTH = 32\nCIFAR_DEPTH = 3\nCIFAR_RECORD_BYTE = CIFAR_HEIGHT * CIFAR_WIDTH * CIFAR_DEPTH + CIFAR_LABEL_BYTE\n\nCIFAR_CLASS_NUM = 10\nCIFAR_TRAINING_NUM = 50000\nCIFAR_TEST_NUM = 10000\n\n_ITEMS_TO_DESCRIPTIONS = {\n\t'image': 'A [32 x 32 x 3] color image.',\n\t'label': 'A single integer between 0 and 9',\n}\n\nclass CifarBinaryDecoder(DataDecoder):\n  def decode(self, data, items):\n\toutputs = []\n            print(data.shape)\n\tdataBytes = tf.decode_raw(data, tf.uint8)\n\tfor item in items:\n\t  if item == 'label':\n\t\tcurrLabel = tf.cast(tf.strided_slice(dataBytes, [0], CIFAR_LABEL_BYTE), tf.int32)\n\t\toutputs.append(currLabel)\n\t  if item == 'image':\n\t\timageData = tf.reshpae(tf.strided_slice(dataBytes, [CIFAR_LABEL_BYTE],[CIFAR_RECORD_BYTE]), [CIFAR_DEPTH, CIFAR_HEIGHT, CIFAR_WIDTH])\n\t\timageData = tf.transpose(imageData, [1, 2, 0])\n\t\toutputs.append(imageData)\n\n\treturn outputs\n\n def list_items(self):\n\treturn ['label', 'image']\n\ndef get_cifar10_training_filenames(binary_data_dir):\n  file_pattern = ['test_batch.bin']\n  return file_pattern\n\ndef get_cifar_training_dataset(binary_data_dir):\n  file_pattern = get_cifar10_training_filenames(binary_data_dir)\n  decoder = CifarBinaryDecoder()\n  return slim.dataset.Dataset(data_sources = file_pattern,\n\t\t\t\t\t\t\t  reader = tf.FixedLengthRecordReader,\n\t\t\t\t\t\t\t  decoder = decoder,\n\t\t\t\t\t\t\t  num_samples = CIFAR_TRAINING_NUM,\n\t\t\t\t\t\t\t  items_to_descriptions = _ITEMS_TO_DESCRIPTIONS,\n\t\t\t\t\t\t\t  num_classes = CIFAR_CLASS_NUM)\n\ndef main(_):  \n  dataset = get_cifar_training_dataset(FLAGS.cifar_data_dir)\n  provider = slim.dataset_data_provider.DatasetDataProvider(\n\t  dataset,\n\t  num_readers = 1,\n\t  common_queue_capacity = 1000,\n\t  common_queue_min = 500,\n\t  reader_kwargs={'record_bytes' : CIFAR_RECORD_BYTE})\n\n with tf.Session() as sess:\n\tinit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n\tsess.run(init_op)\n\ttf.train.start_queue_runners()\n\n\tfor i in range(2):\n\t  [img, lab] = provider.get(['image', 'label'])\n              image, label = sess.run([img, lab])", "body": "I want to use tensorflow slim data provider. All examples I can find only are only reading tfrecord files. However, I want to read binary files directly by my own reader. I use fixed length reader to extract Cifar10 binary data. \r\n\r\nHowever, \"dataBytes = tf.decode_raw(data, tf.unit8)\" always produce error that \"AttributeError: module 'tensorflow' has no attribute 'unit8'\" when using in slim DatasetDataProvider. \r\n\r\nBut no such error occurs when I use the reader directly without using DatasetDataProvider. Did I not use it correctly or does DatasetDataProvider only support tfrecord readers? Thank you.\r\n\r\nMy codes are as below:  \t\r\n\r\n\tCIFAR_LABEL_BYTE = 1\r\n\tCIFAR_HEIGHT = 32\r\n\tCIFAR_WIDTH = 32\r\n\tCIFAR_DEPTH = 3\r\n\tCIFAR_RECORD_BYTE = CIFAR_HEIGHT * CIFAR_WIDTH * CIFAR_DEPTH + CIFAR_LABEL_BYTE\r\n\r\n\tCIFAR_CLASS_NUM = 10\r\n\tCIFAR_TRAINING_NUM = 50000\r\n\tCIFAR_TEST_NUM = 10000\r\n\r\n\t_ITEMS_TO_DESCRIPTIONS = {\r\n\t\t'image': 'A [32 x 32 x 3] color image.',\r\n\t\t'label': 'A single integer between 0 and 9',\r\n\t}\r\n\r\n    class CifarBinaryDecoder(DataDecoder):\r\n\t  def decode(self, data, items):\r\n\t\toutputs = []\r\n                print(data.shape)\r\n\t\tdataBytes = tf.decode_raw(data, tf.uint8)\r\n\t\tfor item in items:\r\n\t\t  if item == 'label':\r\n\t\t\tcurrLabel = tf.cast(tf.strided_slice(dataBytes, [0], CIFAR_LABEL_BYTE), tf.int32)\r\n\t\t\toutputs.append(currLabel)\r\n\t\t  if item == 'image':\r\n\t\t\timageData = tf.reshpae(tf.strided_slice(dataBytes, [CIFAR_LABEL_BYTE],[CIFAR_RECORD_BYTE]), [CIFAR_DEPTH, CIFAR_HEIGHT, CIFAR_WIDTH])\r\n\t\t\timageData = tf.transpose(imageData, [1, 2, 0])\r\n\t\t\toutputs.append(imageData)\r\n\r\n\t\treturn outputs\r\n\r\n\t def list_items(self):\r\n\t\treturn ['label', 'image']\r\n\r\n\tdef get_cifar10_training_filenames(binary_data_dir):\r\n\t  file_pattern = ['test_batch.bin']\r\n\t  return file_pattern\r\n\r\n\tdef get_cifar_training_dataset(binary_data_dir):\r\n\t  file_pattern = get_cifar10_training_filenames(binary_data_dir)\r\n\t  decoder = CifarBinaryDecoder()\r\n\t  return slim.dataset.Dataset(data_sources = file_pattern,\r\n\t\t\t\t\t\t\t\t  reader = tf.FixedLengthRecordReader,\r\n\t\t\t\t\t\t\t\t  decoder = decoder,\r\n\t\t\t\t\t\t\t\t  num_samples = CIFAR_TRAINING_NUM,\r\n\t\t\t\t\t\t\t\t  items_to_descriptions = _ITEMS_TO_DESCRIPTIONS,\r\n\t\t\t\t\t\t\t\t  num_classes = CIFAR_CLASS_NUM)\r\n\r\n\tdef main(_):  \r\n\t  dataset = get_cifar_training_dataset(FLAGS.cifar_data_dir)\r\n\t  provider = slim.dataset_data_provider.DatasetDataProvider(\r\n\t\t  dataset,\r\n\t\t  num_readers = 1,\r\n\t\t  common_queue_capacity = 1000,\r\n\t\t  common_queue_min = 500,\r\n\t\t  reader_kwargs={'record_bytes' : CIFAR_RECORD_BYTE})\r\n\r\n\t with tf.Session() as sess:\r\n\t\tinit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n\t\tsess.run(init_op)\r\n\t\ttf.train.start_queue_runners()\r\n\r\n\t\tfor i in range(2):\r\n\t\t  [img, lab] = provider.get(['image', 'label'])\r\n                  image, label = sess.run([img, lab])"}