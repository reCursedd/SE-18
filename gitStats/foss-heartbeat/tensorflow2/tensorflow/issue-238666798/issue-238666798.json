{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11067", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11067/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11067/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11067/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11067", "id": 238666798, "node_id": "MDU6SXNzdWUyMzg2NjY3OTg=", "number": 11067, "title": "Feature Request: How to Access Attention Weights of Attention Wrapper", "user": {"login": "RylanSchaeffer", "id": 8942987, "node_id": "MDQ6VXNlcjg5NDI5ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8942987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RylanSchaeffer", "html_url": "https://github.com/RylanSchaeffer", "followers_url": "https://api.github.com/users/RylanSchaeffer/followers", "following_url": "https://api.github.com/users/RylanSchaeffer/following{/other_user}", "gists_url": "https://api.github.com/users/RylanSchaeffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/RylanSchaeffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RylanSchaeffer/subscriptions", "organizations_url": "https://api.github.com/users/RylanSchaeffer/orgs", "repos_url": "https://api.github.com/users/RylanSchaeffer/repos", "events_url": "https://api.github.com/users/RylanSchaeffer/events{/privacy}", "received_events_url": "https://api.github.com/users/RylanSchaeffer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-06-26T20:55:10Z", "updated_at": "2017-07-29T19:21:07Z", "closed_at": "2017-06-26T21:16:02Z", "author_association": "NONE", "body_html": "<p>OS: macOS Sierra version 10.12.5<br>\nTensorFlow Version: v1.2.0-rc2-21-g12f033d 1.2.0</p>\n<p>This is a two-part request related to <code>tensorflow.contrib.seq2seq</code>. I would like the ability to visualize the attention weights of the <code>AttentionWrapper</code>, but I'm hampered by the lack of examples and I'm struggling to infer the input for <code>BahdanauAttention</code>'s <code>__call__</code> method's argument <code>previous_alignments</code>.</p>\n<p>First, could someone clarify how to access the attention weights?</p>\n<p>Second, would it be possible to add some tool that visualizes the attention weights (possibly to TensorBoard)?</p>", "body_text": "OS: macOS Sierra version 10.12.5\nTensorFlow Version: v1.2.0-rc2-21-g12f033d 1.2.0\nThis is a two-part request related to tensorflow.contrib.seq2seq. I would like the ability to visualize the attention weights of the AttentionWrapper, but I'm hampered by the lack of examples and I'm struggling to infer the input for BahdanauAttention's __call__ method's argument previous_alignments.\nFirst, could someone clarify how to access the attention weights?\nSecond, would it be possible to add some tool that visualizes the attention weights (possibly to TensorBoard)?", "body": "OS: macOS Sierra version 10.12.5\r\nTensorFlow Version: v1.2.0-rc2-21-g12f033d 1.2.0\r\n\r\nThis is a two-part request related to `tensorflow.contrib.seq2seq`. I would like the ability to visualize the attention weights of the `AttentionWrapper`, but I'm hampered by the lack of examples and I'm struggling to infer the input for `BahdanauAttention`'s `__call__` method's argument `previous_alignments`.\r\n\r\nFirst, could someone clarify how to access the attention weights?\r\n\r\nSecond, would it be possible to add some tool that visualizes the attention weights (possibly to TensorBoard)?"}