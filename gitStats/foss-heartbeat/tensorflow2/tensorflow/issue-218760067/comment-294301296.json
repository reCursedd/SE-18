{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294301296", "html_url": "https://github.com/tensorflow/tensorflow/pull/8906#issuecomment-294301296", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8906", "id": 294301296, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDMwMTI5Ng==", "user": {"login": "Namnamseo", "id": 12743061, "node_id": "MDQ6VXNlcjEyNzQzMDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/12743061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Namnamseo", "html_url": "https://github.com/Namnamseo", "followers_url": "https://api.github.com/users/Namnamseo/followers", "following_url": "https://api.github.com/users/Namnamseo/following{/other_user}", "gists_url": "https://api.github.com/users/Namnamseo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Namnamseo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Namnamseo/subscriptions", "organizations_url": "https://api.github.com/users/Namnamseo/orgs", "repos_url": "https://api.github.com/users/Namnamseo/repos", "events_url": "https://api.github.com/users/Namnamseo/events{/privacy}", "received_events_url": "https://api.github.com/users/Namnamseo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-15T15:48:14Z", "updated_at": "2017-04-15T15:59:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>To compare, this is the result without the commits:</p>\n<pre><code>Forward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.029457 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.027027 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.049702 secs\n=== op vs py: -8.3% ===\n=== py vs slow: 83.9% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009391 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004322 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007878 secs\n=== op vs py: -54.0% ===\n=== py vs slow: 82.3% ===\nForward/backward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250639 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.256498 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.341756 secs\n=== op vs py: 2.3% ===\n=== py vs slow: 33.2% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.059267 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.046172 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.061998 secs\n=== op vs py: 4.6% ===\n=== py vs slow: -44.9% ===\nForward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.024732 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.015260 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029841 secs\n=== op vs py: -38.3% ===\n=== py vs slow: 95.6% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005794 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002716 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004691 secs\n=== op vs py: -53.1% ===\n=== py vs slow: 72.7% ===\nForward/backward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.164564 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.174291 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.240674 secs\n=== op vs py: 5.9% ===\n=== py vs slow: 38.1% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.038100 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.027701 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.036765 secs\n=== op vs py: -27.3% ===\n=== py vs slow: 32.7% ===\nForward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001692 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002541 secs\n=== py vs slow: 50.2% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000689 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000595 secs\n=== py vs slow: -13.6% ===\nForward/backward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005530 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007350 secs\n=== py vs slow: 32.9% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005176 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.005340 secs\n=== py vs slow: 3.2% ===\n</code></pre>\n<p>While running the benchmark, the workstation was not perfectly idle -- some tasks were running on it. Thus there is a limited reliability on the exact times. But, as the workstation has a lot of(40 logical) cores, and the very GPU used here (among the ones equipped with the workstation) was idle, and the job was not I/O intensive, I think it would be okay.</p>\n<p>In fact, I noticed a typo on <code>batch_norm_benchmark.py</code> in line 201; <code>t2</code> is used twice, affecting the result for the fourth test. Look at the GPU benchmark of Forward/backward convolution (lower layers), the \"py vs slow\" percentage (which should be (slow - py) / py * 100) is certainly wrong. I suppose someone(maybe I?) should fix this ;)</p>", "body_text": "To compare, this is the result without the commits:\nForward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.029457 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.027027 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.049702 secs\n=== op vs py: -8.3% ===\n=== py vs slow: 83.9% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009391 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004322 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007878 secs\n=== op vs py: -54.0% ===\n=== py vs slow: 82.3% ===\nForward/backward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250639 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.256498 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.341756 secs\n=== op vs py: 2.3% ===\n=== py vs slow: 33.2% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.059267 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.046172 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.061998 secs\n=== op vs py: 4.6% ===\n=== py vs slow: -44.9% ===\nForward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.024732 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.015260 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029841 secs\n=== op vs py: -38.3% ===\n=== py vs slow: 95.6% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005794 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002716 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004691 secs\n=== op vs py: -53.1% ===\n=== py vs slow: 72.7% ===\nForward/backward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.164564 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.174291 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.240674 secs\n=== op vs py: 5.9% ===\n=== py vs slow: 38.1% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.038100 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.027701 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.036765 secs\n=== op vs py: -27.3% ===\n=== py vs slow: 32.7% ===\nForward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001692 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002541 secs\n=== py vs slow: 50.2% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000689 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000595 secs\n=== py vs slow: -13.6% ===\nForward/backward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005530 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007350 secs\n=== py vs slow: 32.9% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005176 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.005340 secs\n=== py vs slow: 3.2% ===\n\nWhile running the benchmark, the workstation was not perfectly idle -- some tasks were running on it. Thus there is a limited reliability on the exact times. But, as the workstation has a lot of(40 logical) cores, and the very GPU used here (among the ones equipped with the workstation) was idle, and the job was not I/O intensive, I think it would be okay.\nIn fact, I noticed a typo on batch_norm_benchmark.py in line 201; t2 is used twice, affecting the result for the fourth test. Look at the GPU benchmark of Forward/backward convolution (lower layers), the \"py vs slow\" percentage (which should be (slow - py) / py * 100) is certainly wrong. I suppose someone(maybe I?) should fix this ;)", "body": "To compare, this is the result without the commits:\r\n```\r\nForward convolution (lower layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.029457 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.027027 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.049702 secs\r\n=== op vs py: -8.3% ===\r\n=== py vs slow: 83.9% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009391 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004322 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007878 secs\r\n=== op vs py: -54.0% ===\r\n=== py vs slow: 82.3% ===\r\nForward/backward convolution (lower layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250639 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.256498 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.341756 secs\r\n=== op vs py: 2.3% ===\r\n=== py vs slow: 33.2% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.059267 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.046172 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.061998 secs\r\n=== op vs py: 4.6% ===\r\n=== py vs slow: -44.9% ===\r\nForward convolution (higher layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.024732 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.015260 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029841 secs\r\n=== op vs py: -38.3% ===\r\n=== py vs slow: 95.6% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005794 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002716 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004691 secs\r\n=== op vs py: -53.1% ===\r\n=== py vs slow: 72.7% ===\r\nForward/backward convolution (higher layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.164564 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.174291 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.240674 secs\r\n=== op vs py: 5.9% ===\r\n=== py vs slow: 38.1% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.038100 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.027701 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.036765 secs\r\n=== op vs py: -27.3% ===\r\n=== py vs slow: 32.7% ===\r\nForward fully-connected.\r\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001692 secs\r\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002541 secs\r\n=== py vs slow: 50.2% ===\r\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000689 secs\r\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000595 secs\r\n=== py vs slow: -13.6% ===\r\nForward/backward fully-connected.\r\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005530 secs\r\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007350 secs\r\n=== py vs slow: 32.9% ===\r\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005176 secs\r\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.005340 secs\r\n=== py vs slow: 3.2% ===\r\n```\r\n\r\nWhile running the benchmark, the workstation was not perfectly idle -- some tasks were running on it. Thus there is a limited reliability on the exact times. But, as the workstation has a lot of(40 logical) cores, and the very GPU used here (among the ones equipped with the workstation) was idle, and the job was not I/O intensive, I think it would be okay.\r\n\r\nIn fact, I noticed a typo on `batch_norm_benchmark.py` in line 201; `t2` is used twice, affecting the result for the fourth test. Look at the GPU benchmark of Forward/backward convolution (lower layers), the \"py vs slow\" percentage (which should be (slow - py) / py * 100) is certainly wrong. I suppose someone(maybe I?) should fix this ;)"}