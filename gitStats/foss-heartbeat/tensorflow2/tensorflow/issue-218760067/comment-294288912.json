{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294288912", "html_url": "https://github.com/tensorflow/tensorflow/pull/8906#issuecomment-294288912", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8906", "id": 294288912, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDI4ODkxMg==", "user": {"login": "Namnamseo", "id": 12743061, "node_id": "MDQ6VXNlcjEyNzQzMDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/12743061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Namnamseo", "html_url": "https://github.com/Namnamseo", "followers_url": "https://api.github.com/users/Namnamseo/followers", "following_url": "https://api.github.com/users/Namnamseo/following{/other_user}", "gists_url": "https://api.github.com/users/Namnamseo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Namnamseo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Namnamseo/subscriptions", "organizations_url": "https://api.github.com/users/Namnamseo/orgs", "repos_url": "https://api.github.com/users/Namnamseo/repos", "events_url": "https://api.github.com/users/Namnamseo/events{/privacy}", "received_events_url": "https://api.github.com/users/Namnamseo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-15T12:01:09Z", "updated_at": "2017-04-15T14:57:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is the result of <code>batch_norm_benchmark.py</code>.<br>\nXeon E5-2680v2 and Tesla K40c are used.<br>\nIs the result consistent with what is expected?</p>\n<pre><code>Forward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.028565 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.026461 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.047894 secs\n=== op vs py: -7.4% ===\n=== py vs slow: 81.0% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009358 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004293 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007882 secs\n=== op vs py: -54.1% ===\n=== py vs slow: 83.6% ===\nForward/backward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250261 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.255890 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.338562 secs\n=== op vs py: 2.2% ===\n=== py vs slow: 32.3% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.064522 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.050912 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.066883 secs\n=== op vs py: 3.7% ===\n=== py vs slow: -49.4% ===\nForward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.025934 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.014913 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029672 secs\n=== op vs py: -42.5% ===\n=== py vs slow: 99.0% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005782 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002708 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004732 secs\n=== op vs py: -53.2% ===\n=== py vs slow: 74.8% ===\nForward/backward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.163545 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.177408 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.233097 secs\n=== op vs py: 8.5% ===\n=== py vs slow: 31.4% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.041899 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.030979 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.039969 secs\n=== op vs py: -26.1% ===\n=== py vs slow: 29.0% ===\nForward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001318 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002452 secs\n=== py vs slow: 86.0% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000731 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000627 secs\n=== py vs slow: -14.2% ===\nForward/backward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005600 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007404 secs\n=== py vs slow: 32.2% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.007516 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007703 secs\n=== py vs slow: 2.5% ===\n</code></pre>", "body_text": "This is the result of batch_norm_benchmark.py.\nXeon E5-2680v2 and Tesla K40c are used.\nIs the result consistent with what is expected?\nForward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.028565 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.026461 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.047894 secs\n=== op vs py: -7.4% ===\n=== py vs slow: 81.0% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009358 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004293 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007882 secs\n=== op vs py: -54.1% ===\n=== py vs slow: 83.6% ===\nForward/backward convolution (lower layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250261 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.255890 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.338562 secs\n=== op vs py: 2.2% ===\n=== py vs slow: 32.3% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.064522 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.050912 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.066883 secs\n=== op vs py: 3.7% ===\n=== py vs slow: -49.4% ===\nForward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.025934 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.014913 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029672 secs\n=== op vs py: -42.5% ===\n=== py vs slow: 99.0% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005782 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002708 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004732 secs\n=== op vs py: -53.2% ===\n=== py vs slow: 74.8% ===\nForward/backward convolution (higher layers).\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.163545 secs\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.177408 secs\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.233097 secs\n=== op vs py: 8.5% ===\n=== py vs slow: 31.4% ===\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.041899 secs\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.030979 secs\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.039969 secs\n=== op vs py: -26.1% ===\n=== py vs slow: 29.0% ===\nForward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001318 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002452 secs\n=== py vs slow: 86.0% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000731 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000627 secs\n=== py vs slow: -14.2% ===\nForward/backward fully-connected.\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005600 secs\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007404 secs\n=== py vs slow: 32.2% ===\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.007516 secs\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007703 secs\n=== py vs slow: 2.5% ===", "body": "This is the result of `batch_norm_benchmark.py`.\r\nXeon E5-2680v2 and Tesla K40c are used.\r\nIs the result consistent with what is expected?\r\n\r\n```\r\nForward convolution (lower layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.028565 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.026461 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.047894 secs\r\n=== op vs py: -7.4% ===\r\n=== py vs slow: 81.0% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.009358 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.004293 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.007882 secs\r\n=== op vs py: -54.1% ===\r\n=== py vs slow: 83.6% ===\r\nForward/backward convolution (lower layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.250261 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.255890 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.338562 secs\r\n=== op vs py: 2.2% ===\r\n=== py vs slow: 32.3% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.064522 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.050912 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.066883 secs\r\n=== op vs py: 3.7% ===\r\n=== py vs slow: -49.4% ===\r\nForward convolution (higher layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.025934 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.014913 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.029672 secs\r\n=== op vs py: -42.5% ===\r\n=== py vs slow: 99.0% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.005782 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.002708 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.004732 secs\r\n=== op vs py: -53.2% ===\r\n=== py vs slow: 74.8% ===\r\nForward/backward convolution (higher layers).\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.163545 secs\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.177408 secs\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.233097 secs\r\n=== op vs py: 8.5% ===\r\n=== py vs slow: 31.4% ===\r\ngpu shape:4/3 #layers:10 mode:op scale:True train:True - 0.041899 secs\r\ngpu shape:4/3 #layers:10 mode:py scale:True train:True - 0.030979 secs\r\ngpu shape:4/3 #layers:10 mode:slow scale:True train:True - 0.039969 secs\r\n=== op vs py: -26.1% ===\r\n=== py vs slow: 29.0% ===\r\nForward fully-connected.\r\ncpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.001318 secs\r\ncpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.002452 secs\r\n=== py vs slow: 86.0% ===\r\ngpu shape:2/1 #layers:10 mode:py scale:True train:False - 0.000731 secs\r\ngpu shape:2/1 #layers:10 mode:slow scale:True train:False - 0.000627 secs\r\n=== py vs slow: -14.2% ===\r\nForward/backward fully-connected.\r\ncpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.005600 secs\r\ncpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007404 secs\r\n=== py vs slow: 32.2% ===\r\ngpu shape:2/1 #layers:10 mode:py scale:True train:True - 0.007516 secs\r\ngpu shape:2/1 #layers:10 mode:slow scale:True train:True - 0.007703 secs\r\n=== py vs slow: 2.5% ===\r\n```"}