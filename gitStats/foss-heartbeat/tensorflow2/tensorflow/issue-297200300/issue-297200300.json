{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17016", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17016/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17016/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17016/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17016", "id": 297200300, "node_id": "MDU6SXNzdWUyOTcyMDAzMDA=", "number": 17016, "title": "Error in `tfe.implicit_gradients(loss)` in eager mode", "user": {"login": "AakashKumarNain", "id": 11736571, "node_id": "MDQ6VXNlcjExNzM2NTcx", "avatar_url": "https://avatars3.githubusercontent.com/u/11736571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AakashKumarNain", "html_url": "https://github.com/AakashKumarNain", "followers_url": "https://api.github.com/users/AakashKumarNain/followers", "following_url": "https://api.github.com/users/AakashKumarNain/following{/other_user}", "gists_url": "https://api.github.com/users/AakashKumarNain/gists{/gist_id}", "starred_url": "https://api.github.com/users/AakashKumarNain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AakashKumarNain/subscriptions", "organizations_url": "https://api.github.com/users/AakashKumarNain/orgs", "repos_url": "https://api.github.com/users/AakashKumarNain/repos", "events_url": "https://api.github.com/users/AakashKumarNain/events{/privacy}", "received_events_url": "https://api.github.com/users/AakashKumarNain/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-02-14T18:33:28Z", "updated_at": "2018-02-21T16:55:08Z", "closed_at": "2018-02-21T16:55:08Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 7.2.0</li>\n<li><strong>CUDA/cuDNN version</strong>: -</li>\n<li><strong>GPU model and memory</strong>: -</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<hr>\n<p>I was trying to run MNIST model in <code>Eager</code> mode on Kaggle Kernels but as I am passing data to my model, the optimizer is throwing this particular error :<br>\n<code>ValueError: No trainable variables were accessed while the function was being computed.</code> I can confirm that the data being passed to the model are non-zero and are in the correct shape. I don't understand why is the model is throwing the error then. Here is my code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n\ntfe.enable_eager_execution()\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">MNIST</span>(<span class=\"pl-c1\">object</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">data_format</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Set the input shape according to the availability of GPU </span>\n        <span class=\"pl-k\">if</span> data_format <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span>:\n            <span class=\"pl-c1\">self</span>._input_shape <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>]\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-c1\">self</span>._input_shape <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>]\n        \n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> tf.layers.Conv2D(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">3</span>, \n                                      <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, \n                                      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, \n                                      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n        \n        <span class=\"pl-c1\">self</span>.maxpool <span class=\"pl-k\">=</span> tf.layers.MaxPooling2D((<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>), (<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>), \n                                            <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, \n                                            <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n        \n        <span class=\"pl-c1\">self</span>.conv2 <span class=\"pl-k\">=</span> tf.layers.Conv2D(<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">3</span>, \n                                      <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu, \n                                      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, \n                                      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span>data_format)\n        \n        <span class=\"pl-c1\">self</span>.dense1 <span class=\"pl-k\">=</span> tf.layers.Dense(<span class=\"pl-c1\">1024</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu)\n        <span class=\"pl-c1\">self</span>.dropout <span class=\"pl-k\">=</span> tf.layers.Dropout(<span class=\"pl-c1\">0.5</span>)\n        <span class=\"pl-c1\">self</span>.dense2 <span class=\"pl-k\">=</span> tf.layers.Dense(<span class=\"pl-c1\">10</span>)\n        \n        \n \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">predict</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>):\n        x <span class=\"pl-k\">=</span> tf.reshape(inputs, <span class=\"pl-c1\">self</span>._input_shape)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv1(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.maxpool(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv2(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.maxpool(x)\n        x <span class=\"pl-k\">=</span> tf.layers.flatten(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.dense1(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.dropout(x) <span class=\"pl-c\"><span class=\"pl-c\">#</span>enable at training and disable at testing</span>\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.dense2(x)\n        <span class=\"pl-k\">return</span> x\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Define loss functions</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">loss</span>(<span class=\"pl-smi\">model</span>, <span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">targets</span>):\n    <span class=\"pl-k\">return</span> tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n                          <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>model.predict(inputs), <span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>targets))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Calculate accuracy</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">compute_accuracy</span>(<span class=\"pl-smi\">predictions</span>, <span class=\"pl-smi\">labels</span>):\n    model_pred <span class=\"pl-k\">=</span> tf.argmax(predictions, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,<span class=\"pl-v\">output_type</span><span class=\"pl-k\">=</span>tf.int64)\n    actual_labels <span class=\"pl-k\">=</span> tf.argmax(labels, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">output_type</span><span class=\"pl-k\">=</span>tf.int64)\n    <span class=\"pl-k\">return</span> tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels)),<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">float</span>(predictions.shape[<span class=\"pl-c1\">0</span>].value)\n\ndevice <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu:0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> tfe.num_gpus() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu:0<span class=\"pl-pds\">\"</span></span>\nmodel <span class=\"pl-k\">=</span> MNIST(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_first<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">if</span> tfe.num_gpus() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>channels_last<span class=\"pl-pds\">'</span></span>)\noptimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>)\ngrad <span class=\"pl-k\">=</span> tfe.implicit_gradients(loss)\n\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span>\ntrain_batches <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(X_train) <span class=\"pl-k\">//</span> batch_size\nvalid_batches <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(X_valid) <span class=\"pl-k\">//</span> batch_size\nnb_epochs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(nb_epochs):\n    <span class=\"pl-k\">with</span> tf.device(device):\n        <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(train_batches):\n            inputs, targets <span class=\"pl-k\">=</span> <span class=\"pl-c1\">next</span>(train_data_gen)\n            optimizer.apply_gradients(grad(model, inputs, targets))\n            <span class=\"pl-k\">if</span> j <span class=\"pl-k\">%</span> <span class=\"pl-c1\">10</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Step <span class=\"pl-c1\">%d</span>: Loss on training set : <span class=\"pl-c1\">%f</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span>(i, loss(model, inputs, targets).numpy()))\n        </pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below): 1.5.0\nPython version: 3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source): 7.2.0\nCUDA/cuDNN version: -\nGPU model and memory: -\nExact command to reproduce:\n\n\nI was trying to run MNIST model in Eager mode on Kaggle Kernels but as I am passing data to my model, the optimizer is throwing this particular error :\nValueError: No trainable variables were accessed while the function was being computed. I can confirm that the data being passed to the model are non-zero and are in the correct shape. I don't understand why is the model is throwing the error then. Here is my code:\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nclass MNIST(object):\n    def __init__(self, data_format):\n        # Set the input shape according to the availability of GPU \n        if data_format == 'channels_first':\n            self._input_shape = [-1, 1, 28, 28]\n        else:\n            self._input_shape = [-1, 28, 28, 1]\n        \n        self.conv1 = tf.layers.Conv2D(32, 3, \n                                      activation=tf.nn.relu, \n                                      padding='same', \n                                      data_format=data_format)\n        \n        self.maxpool = tf.layers.MaxPooling2D((2,2), (2,2), \n                                            padding='same', \n                                            data_format=data_format)\n        \n        self.conv2 = tf.layers.Conv2D(64, 3, \n                                      activation=tf.nn.relu, \n                                      padding='same', \n                                      data_format=data_format)\n        \n        self.dense1 = tf.layers.Dense(1024, activation=tf.nn.relu)\n        self.dropout = tf.layers.Dropout(0.5)\n        self.dense2 = tf.layers.Dense(10)\n        \n        \n \n    def predict(self, inputs):\n        x = tf.reshape(inputs, self._input_shape)\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.maxpool(x)\n        x = tf.layers.flatten(x)\n        x = self.dense1(x)\n        x = self.dropout(x) #enable at training and disable at testing\n        x = self.dense2(x)\n        return x\n\n# Define loss functions\ndef loss(model, inputs, targets):\n    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n                          logits=model.predict(inputs), labels=targets))\n\n# Calculate accuracy\ndef compute_accuracy(predictions, labels):\n    model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\n    actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\n    return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels)),dtype=tf.float32) / float(predictions.shape[0].value)\n\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\nmodel = MNIST('channels_first' if tfe.num_gpus() else 'channels_last')\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\ngrad = tfe.implicit_gradients(loss)\n\nbatch_size = 8\ntrain_batches = len(X_train) // batch_size\nvalid_batches = len(X_valid) // batch_size\nnb_epochs = 5\n\nfor i in range(nb_epochs):\n    with tf.device(device):\n        for j in range(train_batches):\n            inputs, targets = next(train_data_gen)\n            optimizer.apply_gradients(grad(model, inputs, targets))\n            if j % 10 == 0:\n                print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets).numpy()))", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**:\r\n---\r\n\r\nI was trying to run MNIST model in `Eager` mode on Kaggle Kernels but as I am passing data to my model, the optimizer is throwing this particular error :\r\n`ValueError: No trainable variables were accessed while the function was being computed.` I can confirm that the data being passed to the model are non-zero and are in the correct shape. I don't understand why is the model is throwing the error then. Here is my code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\nclass MNIST(object):\r\n    def __init__(self, data_format):\r\n        # Set the input shape according to the availability of GPU \r\n        if data_format == 'channels_first':\r\n            self._input_shape = [-1, 1, 28, 28]\r\n        else:\r\n            self._input_shape = [-1, 28, 28, 1]\r\n        \r\n        self.conv1 = tf.layers.Conv2D(32, 3, \r\n                                      activation=tf.nn.relu, \r\n                                      padding='same', \r\n                                      data_format=data_format)\r\n        \r\n        self.maxpool = tf.layers.MaxPooling2D((2,2), (2,2), \r\n                                            padding='same', \r\n                                            data_format=data_format)\r\n        \r\n        self.conv2 = tf.layers.Conv2D(64, 3, \r\n                                      activation=tf.nn.relu, \r\n                                      padding='same', \r\n                                      data_format=data_format)\r\n        \r\n        self.dense1 = tf.layers.Dense(1024, activation=tf.nn.relu)\r\n        self.dropout = tf.layers.Dropout(0.5)\r\n        self.dense2 = tf.layers.Dense(10)\r\n        \r\n        \r\n \r\n    def predict(self, inputs):\r\n        x = tf.reshape(inputs, self._input_shape)\r\n        x = self.conv1(x)\r\n        x = self.maxpool(x)\r\n        x = self.conv2(x)\r\n        x = self.maxpool(x)\r\n        x = tf.layers.flatten(x)\r\n        x = self.dense1(x)\r\n        x = self.dropout(x) #enable at training and disable at testing\r\n        x = self.dense2(x)\r\n        return x\r\n\r\n# Define loss functions\r\ndef loss(model, inputs, targets):\r\n    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\r\n                          logits=model.predict(inputs), labels=targets))\r\n\r\n# Calculate accuracy\r\ndef compute_accuracy(predictions, labels):\r\n    model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\r\n    actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\r\n    return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels)),dtype=tf.float32) / float(predictions.shape[0].value)\r\n\r\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\r\nmodel = MNIST('channels_first' if tfe.num_gpus() else 'channels_last')\r\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\r\ngrad = tfe.implicit_gradients(loss)\r\n\r\nbatch_size = 8\r\ntrain_batches = len(X_train) // batch_size\r\nvalid_batches = len(X_valid) // batch_size\r\nnb_epochs = 5\r\n\r\nfor i in range(nb_epochs):\r\n    with tf.device(device):\r\n        for j in range(train_batches):\r\n            inputs, targets = next(train_data_gen)\r\n            optimizer.apply_gradients(grad(model, inputs, targets))\r\n            if j % 10 == 0:\r\n                print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets).numpy()))\r\n        \r\n"}