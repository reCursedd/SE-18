{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/233218443", "html_url": "https://github.com/tensorflow/tensorflow/issues/3320#issuecomment-233218443", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3320", "id": 233218443, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzIxODQ0Mw==", "user": {"login": "Mazecreator", "id": 18412448, "node_id": "MDQ6VXNlcjE4NDEyNDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/18412448?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mazecreator", "html_url": "https://github.com/Mazecreator", "followers_url": "https://api.github.com/users/Mazecreator/followers", "following_url": "https://api.github.com/users/Mazecreator/following{/other_user}", "gists_url": "https://api.github.com/users/Mazecreator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mazecreator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mazecreator/subscriptions", "organizations_url": "https://api.github.com/users/Mazecreator/orgs", "repos_url": "https://api.github.com/users/Mazecreator/repos", "events_url": "https://api.github.com/users/Mazecreator/events{/privacy}", "received_events_url": "https://api.github.com/users/Mazecreator/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-18T02:15:25Z", "updated_at": "2016-07-18T02:15:25Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a>, sorry for the delay getting back to you but as I was putting the test case together I bumped into some unexpected results.</p>\n<p>What I did was to take my <strong>Original Solution</strong> and stripped out the \"Game Environment\".  I replaced it with a random data generation.  In this Game Environment, there is no creation/modification of the TensorFlow Graph.  The structure closely follows/leverages <a href=\"https://github.com/nivwusquorum/tensorflow-deepq/tree/master\">nivwusquorum's Github Reinforcement Learning Example</a>.</p>\n<p>On 7/15/2016 I did a \"git pull\" to head for Tensorflow.  I executed the Graph with and without the GPU enabled and recorded the times (see attached chart).  The unexpected result is the GPU outperformed the CPU (which is the initial expectation that wasn't met).  So this code \"cpuvsgpu.py\" with the supporting libraries performs better with the GPU.  So I turned my attention to what may be different between my <strong>Original Solution</strong> and the published code.  I also update the head to 7/17/2016.  Something did improve as the overall difference between the CPU &amp; GPU on the <strong>Original Solution</strong> is much closer than a week again where I was seeing 47s CPU vs 71s GPU .  A quick look at the new Traces vs my initial trace, seems like \"summary's\" may have been changed but there may have been other improvements as well.</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/18412448/16904662/0cc86c72-4c68-11e6-9a79-c06bb1565215.png\"><img src=\"https://cloud.githubusercontent.com/assets/18412448/16904662/0cc86c72-4c68-11e6-9a79-c06bb1565215.png\" alt=\"gtx 950 timing\" style=\"max-width:100%;\"></a></p>\n<p>I tried 2 other combinations to better reflect how the <strong>Original Solution</strong> functioned.  Those were under heavy CPU load (~60% - 70%) and simulated that with concurrent execution of that script.  The other variation was to increase the \"Data IO\", the <strong>Original Solution</strong> uses lists of observations to randomly select observations for training.  This list has a fixed upper limit and then starts deleting the first item in the list while appending the new.  I figured maybe one of these was slowing down streaming of data to the GPU.  Unfortunately, neither of these version caused the CPU to outperform the GPU.  I also ran a quick GPUTESTER app which does large matrix multiplication to get a feel for timing differences with size of task and are as expected.</p>\n<p>I have enclosed the test scripts as well as some of the raw data, Trace Files &amp; TensorBoard log files to speed up any review.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/368246/CPUvsGPU.testing.zip\">CPUvsGPU testing.zip</a></p>\n<p>I am going to keep looking at the <strong>Original Solution</strong> to see if I can figure out what is indirectly causing the GPU to perform poorly (any thoughts you have would be great).  I am going to start at the only real interface between the Game Environment and the graph and that is the \"current_controller.store(observation, action, reward, new_observation)\" line.  The only thing I can figure is maybe \"observation\"'s are not the same as what I think is generated by the Game Environment.  Again, not sure why GPU would perform poorly compared to CPU but would like to understand where this indirect affect on the graph is taking place.  Reinforcement Learning is slow as it is so any performance improvement would be appreciated.</p>\n<p>I would like to follow-up with you on your comments from above as I really don't know how to improve this graph or where the small OPS may be hiding.  Also, batch size may affect convergence negatively but I can experiment with that future.  It seems like this is where most of the performance may be going.  Also, if you have any tricks to combine smaller ops into bigger ones without impacting the logic (function) of the graph.</p>", "body_text": "@zheng-xq, sorry for the delay getting back to you but as I was putting the test case together I bumped into some unexpected results.\nWhat I did was to take my Original Solution and stripped out the \"Game Environment\".  I replaced it with a random data generation.  In this Game Environment, there is no creation/modification of the TensorFlow Graph.  The structure closely follows/leverages nivwusquorum's Github Reinforcement Learning Example.\nOn 7/15/2016 I did a \"git pull\" to head for Tensorflow.  I executed the Graph with and without the GPU enabled and recorded the times (see attached chart).  The unexpected result is the GPU outperformed the CPU (which is the initial expectation that wasn't met).  So this code \"cpuvsgpu.py\" with the supporting libraries performs better with the GPU.  So I turned my attention to what may be different between my Original Solution and the published code.  I also update the head to 7/17/2016.  Something did improve as the overall difference between the CPU & GPU on the Original Solution is much closer than a week again where I was seeing 47s CPU vs 71s GPU .  A quick look at the new Traces vs my initial trace, seems like \"summary's\" may have been changed but there may have been other improvements as well.\n\nI tried 2 other combinations to better reflect how the Original Solution functioned.  Those were under heavy CPU load (~60% - 70%) and simulated that with concurrent execution of that script.  The other variation was to increase the \"Data IO\", the Original Solution uses lists of observations to randomly select observations for training.  This list has a fixed upper limit and then starts deleting the first item in the list while appending the new.  I figured maybe one of these was slowing down streaming of data to the GPU.  Unfortunately, neither of these version caused the CPU to outperform the GPU.  I also ran a quick GPUTESTER app which does large matrix multiplication to get a feel for timing differences with size of task and are as expected.\nI have enclosed the test scripts as well as some of the raw data, Trace Files & TensorBoard log files to speed up any review.\nCPUvsGPU testing.zip\nI am going to keep looking at the Original Solution to see if I can figure out what is indirectly causing the GPU to perform poorly (any thoughts you have would be great).  I am going to start at the only real interface between the Game Environment and the graph and that is the \"current_controller.store(observation, action, reward, new_observation)\" line.  The only thing I can figure is maybe \"observation\"'s are not the same as what I think is generated by the Game Environment.  Again, not sure why GPU would perform poorly compared to CPU but would like to understand where this indirect affect on the graph is taking place.  Reinforcement Learning is slow as it is so any performance improvement would be appreciated.\nI would like to follow-up with you on your comments from above as I really don't know how to improve this graph or where the small OPS may be hiding.  Also, batch size may affect convergence negatively but I can experiment with that future.  It seems like this is where most of the performance may be going.  Also, if you have any tricks to combine smaller ops into bigger ones without impacting the logic (function) of the graph.", "body": "@zheng-xq, sorry for the delay getting back to you but as I was putting the test case together I bumped into some unexpected results.\n\nWhat I did was to take my **Original Solution** and stripped out the \"Game Environment\".  I replaced it with a random data generation.  In this Game Environment, there is no creation/modification of the TensorFlow Graph.  The structure closely follows/leverages [nivwusquorum's Github Reinforcement Learning Example](https://github.com/nivwusquorum/tensorflow-deepq/tree/master).\n\nOn 7/15/2016 I did a \"git pull\" to head for Tensorflow.  I executed the Graph with and without the GPU enabled and recorded the times (see attached chart).  The unexpected result is the GPU outperformed the CPU (which is the initial expectation that wasn't met).  So this code \"cpuvsgpu.py\" with the supporting libraries performs better with the GPU.  So I turned my attention to what may be different between my **Original Solution** and the published code.  I also update the head to 7/17/2016.  Something did improve as the overall difference between the CPU & GPU on the **Original Solution** is much closer than a week again where I was seeing 47s CPU vs 71s GPU .  A quick look at the new Traces vs my initial trace, seems like \"summary's\" may have been changed but there may have been other improvements as well. \n\n![gtx 950 timing](https://cloud.githubusercontent.com/assets/18412448/16904662/0cc86c72-4c68-11e6-9a79-c06bb1565215.png)\n\nI tried 2 other combinations to better reflect how the **Original Solution** functioned.  Those were under heavy CPU load (~60% - 70%) and simulated that with concurrent execution of that script.  The other variation was to increase the \"Data IO\", the **Original Solution** uses lists of observations to randomly select observations for training.  This list has a fixed upper limit and then starts deleting the first item in the list while appending the new.  I figured maybe one of these was slowing down streaming of data to the GPU.  Unfortunately, neither of these version caused the CPU to outperform the GPU.  I also ran a quick GPUTESTER app which does large matrix multiplication to get a feel for timing differences with size of task and are as expected.\n\nI have enclosed the test scripts as well as some of the raw data, Trace Files & TensorBoard log files to speed up any review.\n[CPUvsGPU testing.zip](https://github.com/tensorflow/tensorflow/files/368246/CPUvsGPU.testing.zip)\n\nI am going to keep looking at the **Original Solution** to see if I can figure out what is indirectly causing the GPU to perform poorly (any thoughts you have would be great).  I am going to start at the only real interface between the Game Environment and the graph and that is the \"current_controller.store(observation, action, reward, new_observation)\" line.  The only thing I can figure is maybe \"observation\"'s are not the same as what I think is generated by the Game Environment.  Again, not sure why GPU would perform poorly compared to CPU but would like to understand where this indirect affect on the graph is taking place.  Reinforcement Learning is slow as it is so any performance improvement would be appreciated.\n\nI would like to follow-up with you on your comments from above as I really don't know how to improve this graph or where the small OPS may be hiding.  Also, batch size may affect convergence negatively but I can experiment with that future.  It seems like this is where most of the performance may be going.  Also, if you have any tricks to combine smaller ops into bigger ones without impacting the logic (function) of the graph. \n"}