{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363006555", "html_url": "https://github.com/tensorflow/tensorflow/issues/16768#issuecomment-363006555", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16768", "id": 363006555, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzAwNjU1NQ==", "user": {"login": "unwritten", "id": 1272812, "node_id": "MDQ6VXNlcjEyNzI4MTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1272812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/unwritten", "html_url": "https://github.com/unwritten", "followers_url": "https://api.github.com/users/unwritten/followers", "following_url": "https://api.github.com/users/unwritten/following{/other_user}", "gists_url": "https://api.github.com/users/unwritten/gists{/gist_id}", "starred_url": "https://api.github.com/users/unwritten/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/unwritten/subscriptions", "organizations_url": "https://api.github.com/users/unwritten/orgs", "repos_url": "https://api.github.com/users/unwritten/repos", "events_url": "https://api.github.com/users/unwritten/events{/privacy}", "received_events_url": "https://api.github.com/users/unwritten/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-05T07:54:16Z", "updated_at": "2018-02-05T07:54:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a>  thx for attention;</p>\n<p>I tried batch size 64 or 32, both failed, I also tried:<br>\ncustom_config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)<br>\ncustom_config.gpu_options.allocator_type = 'BFC'<br>\ncustom_config.gpu_options.per_process_gpu_memory_fraction = 0.90</p>\n<p>failed too;</p>\n<p>the error happened when computing the gradient,</p>\n<p>here're my GPUs:</p>\n<p>| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla K80           Off  | 259C:00:00.0     Off |                    0 |<br>\n| N/A   30C    P8    26W / 149W |      0MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla K80           Off  | 3A8D:00:00.0     Off |                    0 |<br>\n| N/A   26C    P8    32W / 149W |      0MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>", "body_text": "@drpngx  thx for attention;\nI tried batch size 64 or 32, both failed, I also tried:\ncustom_config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\ncustom_config.gpu_options.allocator_type = 'BFC'\ncustom_config.gpu_options.per_process_gpu_memory_fraction = 0.90\nfailed too;\nthe error happened when computing the gradient,\nhere're my GPUs:\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 259C:00:00.0     Off |                    0 |\n| N/A   30C    P8    26W / 149W |      0MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 3A8D:00:00.0     Off |                    0 |\n| N/A   26C    P8    32W / 149W |      0MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+", "body": "@drpngx  thx for attention;\r\n\r\nI tried batch size 64 or 32, both failed, I also tried:\r\n        custom_config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\r\n        custom_config.gpu_options.allocator_type = 'BFC'\r\n        custom_config.gpu_options.per_process_gpu_memory_fraction = 0.90\r\n\r\nfailed too;\r\n\r\nthe error happened when computing the gradient, \r\n\r\nhere're my GPUs:\r\n\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 259C:00:00.0     Off |                    0 |\r\n| N/A   30C    P8    26W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 3A8D:00:00.0     Off |                    0 |\r\n| N/A   26C    P8    32W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n"}