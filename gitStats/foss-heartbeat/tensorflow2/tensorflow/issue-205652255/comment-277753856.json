{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277753856", "html_url": "https://github.com/tensorflow/tensorflow/issues/7297#issuecomment-277753856", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7297", "id": 277753856, "node_id": "MDEyOklzc3VlQ29tbWVudDI3Nzc1Mzg1Ng==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-06T17:33:22Z", "updated_at": "2017-02-06T17:41:39Z", "author_association": "CONTRIBUTOR", "body_html": "<ol>\n<li>You can't match fp32 performance of a good gaming card with current cloud compute offering. M60 is rated for peak 3.8 TFlops per core, whereas 1080 is is 8.4 TFlops. Also, M60 is an older Pascal architecture, so it's peak flops are harder to achieve.</li>\n<li>They may be physically attached, but from software standpoint, each GPU chip is a separate device. Do any other tools see both GPUs? Can you rule out driver issues? Our system people had some difficulty getting multi-GPU setups to work on Azure although I don't have details handy.</li>\n<li>TensorFlow networks usually only utilize 1 GPU, you need a special architecture that will use more than one. Cifar multi-GPU example is one such -- <a href=\"https://www.tensorflow.org/tutorials/deep_cnn/#training_a_model_using_multiple_gpu_cards\" rel=\"nofollow\">https://www.tensorflow.org/tutorials/deep_cnn/#training_a_model_using_multiple_gpu_cards</a></li>\n</ol>", "body_text": "You can't match fp32 performance of a good gaming card with current cloud compute offering. M60 is rated for peak 3.8 TFlops per core, whereas 1080 is is 8.4 TFlops. Also, M60 is an older Pascal architecture, so it's peak flops are harder to achieve.\nThey may be physically attached, but from software standpoint, each GPU chip is a separate device. Do any other tools see both GPUs? Can you rule out driver issues? Our system people had some difficulty getting multi-GPU setups to work on Azure although I don't have details handy.\nTensorFlow networks usually only utilize 1 GPU, you need a special architecture that will use more than one. Cifar multi-GPU example is one such -- https://www.tensorflow.org/tutorials/deep_cnn/#training_a_model_using_multiple_gpu_cards", "body": "1. You can't match fp32 performance of a good gaming card with current cloud compute offering. M60 is rated for peak 3.8 TFlops per core, whereas 1080 is is 8.4 TFlops. Also, M60 is an older Pascal architecture, so it's peak flops are harder to achieve.\r\n2. They may be physically attached, but from software standpoint, each GPU chip is a separate device. Do any other tools see both GPUs? Can you rule out driver issues? Our system people had some difficulty getting multi-GPU setups to work on Azure although I don't have details handy.\r\n3. TensorFlow networks usually only utilize 1 GPU, you need a special architecture that will use more than one. Cifar multi-GPU example is one such -- https://www.tensorflow.org/tutorials/deep_cnn/#training_a_model_using_multiple_gpu_cards"}