{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/60494134", "pull_request_review_id": null, "id": 60494134, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwNDk0MTM0", "diff_hunk": "@@ -0,0 +1,329 @@\n+/* Copyright 2015 Google Inc. All Rights Reserved.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#define USE_EIGEN_TENSOR\n+#define EIGEN_USE_THREADS\n+\n+#include <vector>\n+#include \"tensorflow/core/framework/numeric_op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_slice.h\"\n+#include \"tensorflow/core/kernels/bounds_check.h\"\n+#include \"tensorflow/core/kernels/ops_util.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/gtl/array_slice.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/platform/macros.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+#include \"tensorflow/core/util/use_cudnn.h\"\n+\n+#if GOOGLE_CUDA\n+#include \"tensorflow/core/platform/stream_executor.h\"\n+#endif  // GOOGLE_CUDA\n+\n+namespace tensorflow {\n+\n+#if GOOGLE_CUDA\n+namespace {\n+template <typename T>\n+perftools::gputools::DeviceMemory<T> AsDeviceMemory(const T* cuda_memory,\n+                                                    uint64 size) {\n+  perftools::gputools::DeviceMemoryBase wrapped(const_cast<T*>(cuda_memory),\n+                                                size * sizeof(T));\n+  perftools::gputools::DeviceMemory<T> typed(wrapped);\n+  return typed;\n+}\n+}  // namespace\n+#endif  // GOOGLE_CUDA\n+\n+typedef Eigen::ThreadPoolDevice CPUDevice;\n+typedef Eigen::GpuDevice GPUDevice;\n+\n+template <typename Device, typename T>\n+struct LaunchBatchNormalizeTraining;\n+\n+template <typename T>\n+struct LaunchBatchNormalizeTraining<GPUDevice, T> {\n+  static void launch(OpKernelContext* ctx,\n+                     const float epsilon,\n+                     const float exponential_average_factor,\n+                     const Tensor& input,\n+                     const Tensor& scale_param, const Tensor& bias_param,\n+                     Tensor* output,\n+                     Tensor* running_mean,\n+                     Tensor* running_inv_var,\n+                     Tensor* save_mean,\n+                     Tensor* save_inv_var) {\n+    auto* stream = ctx->op_device_context()->stream();\n+    OP_REQUIRES(ctx, stream, errors::Internal(\"No GPU stream avalible\"));\n+\n+    TensorFormat data_format = FORMAT_NCHW;\n+    const int64 in_batch = GetTensorDim(input, data_format, 'N');\n+    const int64 in_depths = GetTensorDim(input, data_format, 'C');\n+    const int64 in_cols = GetTensorDim(input, data_format, 'H');\n+    const int64 in_rows = GetTensorDim(input, data_format, 'W');\n+\n+    perftools::gputools::dnn::BatchDescriptor input_desc;\n+    input_desc.set_count(in_batch)\n+      .set_feature_map_count(in_depths)\n+      .set_height(in_rows)\n+      .set_width(in_cols)\n+      .set_layout(perftools::gputools::dnn::DataLayout::kBatchDepthYX);\n+\n+    perftools::gputools::dnn::BatchDescriptor scale_bias_mean_var_desc;\n+    scale_bias_mean_var_desc.set_count(1)\n+      .set_feature_map_count(in_depths)\n+      .set_height(1)\n+      .set_width(1)\n+      .set_layout(perftools::gputools::dnn::DataLayout::kBatchDepthYX);\n+\n+    auto input_ptr = AsDeviceMemory(input.template flat<T>().data(),\n+                                    input.template flat<T>().size());\n+    auto output_ptr = AsDeviceMemory(output->template flat<T>().data(),\n+                                     output->template flat<T>().size());\n+    auto scale_ptr = AsDeviceMemory(scale_param.template flat<T>().data(),\n+                                    scale_param.template flat<T>().size());\n+    auto bias_ptr = AsDeviceMemory(bias_param.template flat<T>().data(),\n+                                    bias_param.template flat<T>().size());\n+\n+    auto running_mean_ptr = AsDeviceMemory(running_mean->template flat<T>().data(),\n+                                    running_mean->template flat<T>().size());\n+\n+    auto running_inv_var_ptr = AsDeviceMemory(running_inv_var->template flat<T>().data(),\n+                                    running_inv_var->template flat<T>().size());\n+\n+    auto save_mean_ptr = AsDeviceMemory(save_mean->template flat<T>().data(),\n+                                        save_mean->template flat<T>().size());\n+    auto save_inv_var_ptr = AsDeviceMemory(save_inv_var->template flat<T>().data(),\n+                                        save_inv_var->template flat<T>().size());\n+\n+    bool cudnn_launch_status =\n+      stream\n+        ->ThenBatchNormalizeTrainingForward(epsilon,\n+                                    exponential_average_factor,\n+                                    input_desc,\n+                                    input_ptr,\n+                                    scale_bias_mean_var_desc,\n+                                    scale_ptr,\n+                                    bias_ptr,\n+                                    input_desc,\n+                                    &output_ptr,\n+                                    &running_mean_ptr,\n+                                    &running_inv_var_ptr,\n+                                    &save_mean_ptr,\n+                                    &save_inv_var_ptr)\n+        .ok();\n+\n+      if (!cudnn_launch_status) {\n+        ctx->SetStatus(errors::Internal(\n+            \"cuDNN launch failure : input shape(\", input.shape().DebugString(),\n+            \")\"));\n+      }\n+  }\n+};\n+\n+template <typename Device, typename T>\n+class BatchNormalizeTrainingOp : public OpKernel {\n+  public:\n+    explicit BatchNormalizeTrainingOp(OpKernelConstruction* context) : OpKernel(context) {\n+      const DataType dt = DataTypeToEnum<T>::v();\n+      const DataType dt_ref = DataTypeToEnum<T>::ref();\n+      OP_REQUIRES_OK(context, context->MatchSignature({dt, dt, dt, dt_ref, dt_ref}, {dt, dt, dt}));\n+\n+      //Do some type checking here\n+      OP_REQUIRES_OK(context, context->GetAttr(\"epsilon\", &epsilon_));\n+      OP_REQUIRES_OK(context, context->GetAttr(\"exponential_average_factor\",\n+                                               &exponential_average_factor_));\n+    }\n+\n+    void Compute(OpKernelContext* context) override {\n+      //TODO a whole bunch of error checking", "path": "tensorflow/core/kernels/cudnn_batchnorm_op.cc", "position": null, "original_position": 153, "commit_id": "458ad677e40b083992f338f2cdd2836e06b99896", "original_commit_id": "dd8c1650a8e8e59d5493cdfed7c756b26ef04b9f", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "Agree. We should check all the dimension compatibilities here. \n", "created_at": "2016-04-20T21:50:00Z", "updated_at": "2016-05-30T21:43:27Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1759#discussion_r60494134", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1759", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/60494134"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1759#discussion_r60494134"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1759"}}, "body_html": "<p>Agree. We should check all the dimension compatibilities here.</p>", "body_text": "Agree. We should check all the dimension compatibilities here."}