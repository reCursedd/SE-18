{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/221124706", "html_url": "https://github.com/tensorflow/tensorflow/issues/1968#issuecomment-221124706", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1968", "id": 221124706, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMTEyNDcwNg==", "user": {"login": "concretevitamin", "id": 592670, "node_id": "MDQ6VXNlcjU5MjY3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/592670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/concretevitamin", "html_url": "https://github.com/concretevitamin", "followers_url": "https://api.github.com/users/concretevitamin/followers", "following_url": "https://api.github.com/users/concretevitamin/following{/other_user}", "gists_url": "https://api.github.com/users/concretevitamin/gists{/gist_id}", "starred_url": "https://api.github.com/users/concretevitamin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/concretevitamin/subscriptions", "organizations_url": "https://api.github.com/users/concretevitamin/orgs", "repos_url": "https://api.github.com/users/concretevitamin/repos", "events_url": "https://api.github.com/users/concretevitamin/events{/privacy}", "received_events_url": "https://api.github.com/users/concretevitamin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-23T23:23:19Z", "updated_at": "2016-05-23T23:23:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2789456\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/siddharth-agrawal\">@siddharth-agrawal</a> Essentially, SparseTensor in Python can be thought of as a 3-tuple of dense tensors, <code>(indices, values, shape)</code>.  You're right that most underlying Ops take these three dense Tensors separately, but there's no \"conversion\" going on.</p>\n<p>As for <code>sparse_matmul()</code>: due to historical reasons it's actually a misnomer.  It does not operate on <code>SparseTensor</code>s, but instead uses an optimized algorithm to operate on two dense Tensors depending on the two flags.  So that op is irrelevant.</p>", "body_text": "@siddharth-agrawal Essentially, SparseTensor in Python can be thought of as a 3-tuple of dense tensors, (indices, values, shape).  You're right that most underlying Ops take these three dense Tensors separately, but there's no \"conversion\" going on.\nAs for sparse_matmul(): due to historical reasons it's actually a misnomer.  It does not operate on SparseTensors, but instead uses an optimized algorithm to operate on two dense Tensors depending on the two flags.  So that op is irrelevant.", "body": "@siddharth-agrawal Essentially, SparseTensor in Python can be thought of as a 3-tuple of dense tensors, `(indices, values, shape)`.  You're right that most underlying Ops take these three dense Tensors separately, but there's no \"conversion\" going on. \n\nAs for `sparse_matmul()`: due to historical reasons it's actually a misnomer.  It does not operate on `SparseTensor`s, but instead uses an optimized algorithm to operate on two dense Tensors depending on the two flags.  So that op is irrelevant. \n"}