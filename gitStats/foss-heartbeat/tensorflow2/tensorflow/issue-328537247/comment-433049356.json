{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/433049356", "html_url": "https://github.com/tensorflow/tensorflow/issues/19691#issuecomment-433049356", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19691", "id": 433049356, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzA0OTM1Ng==", "user": {"login": "Luonic", "id": 13236173, "node_id": "MDQ6VXNlcjEzMjM2MTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/13236173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Luonic", "html_url": "https://github.com/Luonic", "followers_url": "https://api.github.com/users/Luonic/followers", "following_url": "https://api.github.com/users/Luonic/following{/other_user}", "gists_url": "https://api.github.com/users/Luonic/gists{/gist_id}", "starred_url": "https://api.github.com/users/Luonic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Luonic/subscriptions", "organizations_url": "https://api.github.com/users/Luonic/orgs", "repos_url": "https://api.github.com/users/Luonic/repos", "events_url": "https://api.github.com/users/Luonic/events{/privacy}", "received_events_url": "https://api.github.com/users/Luonic/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-25T13:24:42Z", "updated_at": "2018-10-25T13:24:42Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a>! I have presented example in first post.<br>\nI will try to explain:<br>\nAs we read in docs:</p>\n<blockquote>\n<p>Images that are represented using floating point values are expected to have values in the range [0,1).</p>\n</blockquote>\n<p>So when we do</p>\n<pre><code>image_gt = tf.image.decode_image(image_parsed[\"image\"], channels=3)\nimage_gt = tf.image.convert_image_dtype(image_gt, tf.float32, saturate=False)\n</code></pre>\n<p>we expect result to be in 0..1 range because <code>tf.image.decode_image</code> result is tf.uint8 tensor and <code>tf.image.convert_image_dtype</code> has a <code>tf.float32</code> as target dtype param</p>\n<p>and when we do <code>image_gt = tf.Print(image_gt, [tf.reduce_max(image_gt)], \"image_gt_cast\")</code><br>\nwe expect maximum value of converted tensor to be 1.0<br>\nBut instead we get unscaled values</p>\n<pre><code>image_gt_cast[250.892319]\nimage_gt_cast[244.243454]\nimage_gt_cast[245.468872]\nimage_gt_cast[258.527466]\nimage_gt_cast[270.992615]\nimage_gt_cast[227.410767]\n</code></pre>\n<p>in example above maximum values differ because i were feeding different images<br>\nI hope this clarified this problem for you</p>", "body_text": "Hi @drpngx! I have presented example in first post.\nI will try to explain:\nAs we read in docs:\n\nImages that are represented using floating point values are expected to have values in the range [0,1).\n\nSo when we do\nimage_gt = tf.image.decode_image(image_parsed[\"image\"], channels=3)\nimage_gt = tf.image.convert_image_dtype(image_gt, tf.float32, saturate=False)\n\nwe expect result to be in 0..1 range because tf.image.decode_image result is tf.uint8 tensor and tf.image.convert_image_dtype has a tf.float32 as target dtype param\nand when we do image_gt = tf.Print(image_gt, [tf.reduce_max(image_gt)], \"image_gt_cast\")\nwe expect maximum value of converted tensor to be 1.0\nBut instead we get unscaled values\nimage_gt_cast[250.892319]\nimage_gt_cast[244.243454]\nimage_gt_cast[245.468872]\nimage_gt_cast[258.527466]\nimage_gt_cast[270.992615]\nimage_gt_cast[227.410767]\n\nin example above maximum values differ because i were feeding different images\nI hope this clarified this problem for you", "body": "Hi @drpngx! I have presented example in first post. \r\nI will try to explain:\r\n As we read in docs: \r\n> Images that are represented using floating point values are expected to have values in the range [0,1).\r\n\r\nSo when we do \r\n```\r\nimage_gt = tf.image.decode_image(image_parsed[\"image\"], channels=3)\r\nimage_gt = tf.image.convert_image_dtype(image_gt, tf.float32, saturate=False)\r\n```\r\nwe expect result to be in 0..1 range because `tf.image.decode_image` result is tf.uint8 tensor and `tf.image.convert_image_dtype` has a `tf.float32` as target dtype param\r\n\r\nand when we do `image_gt = tf.Print(image_gt, [tf.reduce_max(image_gt)], \"image_gt_cast\")`\r\nwe expect maximum value of converted tensor to be 1.0\r\nBut instead we get unscaled values\r\n```\r\nimage_gt_cast[250.892319]\r\nimage_gt_cast[244.243454]\r\nimage_gt_cast[245.468872]\r\nimage_gt_cast[258.527466]\r\nimage_gt_cast[270.992615]\r\nimage_gt_cast[227.410767]\r\n```\r\nin example above maximum values differ because i were feeding different images\r\nI hope this clarified this problem for you"}