{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288513107", "html_url": "https://github.com/tensorflow/tensorflow/issues/8617#issuecomment-288513107", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8617", "id": 288513107, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUxMzEwNw==", "user": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T19:31:18Z", "updated_at": "2017-03-22T19:31:18Z", "author_association": "MEMBER", "body_html": "<p>For the time being, any op that is not a Keras layer should be wrapped inside a Keras <code>Lambda</code> layer:</p>\n<div class=\"highlight highlight-source-python\"><pre>inputs <span class=\"pl-k\">=</span> keras.layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>string<span class=\"pl-pds\">'</span></span>)\nlut <span class=\"pl-k\">=</span> tensorflow.contrib.lookup.HashTable(tensorflow.contrib.lookup.KeyValueTensorInitializer([<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>c<span class=\"pl-pds\">'</span></span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>]), <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\nlut_output <span class=\"pl-k\">=</span> keras.layers.Lambda(lut.lookup)(inputs)</pre></div>\n<p>If the wrapping is broken at any point, then it prevents you from being able to build a Keras model with your inputs/outputs later on.</p>\n<p>We will automate this wrapping in a later version.</p>", "body_text": "For the time being, any op that is not a Keras layer should be wrapped inside a Keras Lambda layer:\ninputs = keras.layers.Input(shape=(1,), name='input', dtype='string')\nlut = tensorflow.contrib.lookup.HashTable(tensorflow.contrib.lookup.KeyValueTensorInitializer(['a', 'b', 'c'], [1, 2, 3]), default_value=-1)\nlut_output = keras.layers.Lambda(lut.lookup)(inputs)\nIf the wrapping is broken at any point, then it prevents you from being able to build a Keras model with your inputs/outputs later on.\nWe will automate this wrapping in a later version.", "body": "For the time being, any op that is not a Keras layer should be wrapped inside a Keras `Lambda` layer:\r\n\r\n```python\r\ninputs = keras.layers.Input(shape=(1,), name='input', dtype='string')\r\nlut = tensorflow.contrib.lookup.HashTable(tensorflow.contrib.lookup.KeyValueTensorInitializer(['a', 'b', 'c'], [1, 2, 3]), default_value=-1)\r\nlut_output = keras.layers.Lambda(lut.lookup)(inputs)\r\n```\r\n\r\nIf the wrapping is broken at any point, then it prevents you from being able to build a Keras model with your inputs/outputs later on.\r\n\r\nWe will automate this wrapping in a later version.\r\n"}