{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23668", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23668/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23668/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23668/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23668", "id": 379596611, "node_id": "MDU6SXNzdWUzNzk1OTY2MTE=", "number": 23668, "title": "A method to improve accuracy of LazyAdam", "user": {"login": "mpjlu", "id": 13826327, "node_id": "MDQ6VXNlcjEzODI2MzI3", "avatar_url": "https://avatars1.githubusercontent.com/u/13826327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mpjlu", "html_url": "https://github.com/mpjlu", "followers_url": "https://api.github.com/users/mpjlu/followers", "following_url": "https://api.github.com/users/mpjlu/following{/other_user}", "gists_url": "https://api.github.com/users/mpjlu/gists{/gist_id}", "starred_url": "https://api.github.com/users/mpjlu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mpjlu/subscriptions", "organizations_url": "https://api.github.com/users/mpjlu/orgs", "repos_url": "https://api.github.com/users/mpjlu/repos", "events_url": "https://api.github.com/users/mpjlu/events{/privacy}", "received_events_url": "https://api.github.com/users/mpjlu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-11-12T02:24:35Z", "updated_at": "2018-11-22T11:55:54Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>LazyAdam is not convergent on NCF (MLPerf requires NCF to reach 0.635 HR in 10 epchos, but with LazyAdam HR can\u2019t reach the goal).</p>\n<p>The main problem of LazyAdam is it doesn't update m and v when the gradient is 0. Actually, m and v should be updated when other weight changed.  So the convergence accuracy of LazyAdam is lower than Adam.</p>\n<p>I have designed a method to optimize Adam on Sparse data (named SparseAdam) :\u3000SparseAdam provides similar semantics as the original Adam algorithm, so the convergence is also close to Adam, and the TPT is about the same as LazyAdam.</p>\n<p><strong>The only change of our method to LazyAdam is we compute the learning rate based the the steps skipped.</strong></p>\n<p>The convergence comparing of Adam and LazyAdam on NCF (Hit Rate score):<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/13826327/48746725-9b11d500-ecab-11e8-8b39-947a60103890.png\"><img src=\"https://user-images.githubusercontent.com/13826327/48746725-9b11d500-ecab-11e8-8b39-947a60103890.png\" alt=\"adam and lazyadam comparing\" style=\"max-width:100%;\"></a></p>\n<p>Convergence comparing of Adam, LazyAdam and SparseAdam (the proposed method) on NCF (Hit Rate score)<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/13826327/48746832-08256a80-ecac-11e8-9752-3a78b79ab0e9.png\"><img src=\"https://user-images.githubusercontent.com/13826327/48746832-08256a80-ecac-11e8-9752-3a78b79ab0e9.png\" alt=\"adam lazyadam and sparseadam comparing\" style=\"max-width:100%;\"></a></p>", "body_text": "LazyAdam is not convergent on NCF (MLPerf requires NCF to reach 0.635 HR in 10 epchos, but with LazyAdam HR can\u2019t reach the goal).\nThe main problem of LazyAdam is it doesn't update m and v when the gradient is 0. Actually, m and v should be updated when other weight changed.  So the convergence accuracy of LazyAdam is lower than Adam.\nI have designed a method to optimize Adam on Sparse data (named SparseAdam) :\u3000SparseAdam provides similar semantics as the original Adam algorithm, so the convergence is also close to Adam, and the TPT is about the same as LazyAdam.\nThe only change of our method to LazyAdam is we compute the learning rate based the the steps skipped.\nThe convergence comparing of Adam and LazyAdam on NCF (Hit Rate score):\n\nConvergence comparing of Adam, LazyAdam and SparseAdam (the proposed method) on NCF (Hit Rate score)", "body": "LazyAdam is not convergent on NCF (MLPerf requires NCF to reach 0.635 HR in 10 epchos, but with LazyAdam HR can\u2019t reach the goal). \r\n\r\nThe main problem of LazyAdam is it doesn't update m and v when the gradient is 0. Actually, m and v should be updated when other weight changed.  So the convergence accuracy of LazyAdam is lower than Adam.\r\n\r\nI have designed a method to optimize Adam on Sparse data (named SparseAdam) :\u3000SparseAdam provides similar semantics as the original Adam algorithm, so the convergence is also close to Adam, and the TPT is about the same as LazyAdam.\r\n\r\n**The only change of our method to LazyAdam is we compute the learning rate based the the steps skipped.**\r\n\r\nThe convergence comparing of Adam and LazyAdam on NCF (Hit Rate score):\r\n![adam and lazyadam comparing](https://user-images.githubusercontent.com/13826327/48746725-9b11d500-ecab-11e8-8b39-947a60103890.png)\r\n\r\nConvergence comparing of Adam, LazyAdam and SparseAdam (the proposed method) on NCF (Hit Rate score)\r\n![adam lazyadam and sparseadam comparing](https://user-images.githubusercontent.com/13826327/48746832-08256a80-ecac-11e8-9752-3a78b79ab0e9.png)\r\n\r\n\r\n\r\n"}