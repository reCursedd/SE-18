{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285414896", "html_url": "https://github.com/tensorflow/tensorflow/issues/8239#issuecomment-285414896", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8239", "id": 285414896, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTQxNDg5Ng==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-09T17:08:28Z", "updated_at": "2017-03-09T17:08:28Z", "author_association": "MEMBER", "body_html": "<p>The tensorflow runtime by default enumerates all GPUs and initializes them.  (including pre-allocating a bunch of GPU memory to reduce runtime overheads).</p>\n<p>All that <code>with tf.device(\"/gpu:1\")</code> does is request to place a <em>particular</em> op on a specific GPU.  Other ops without device constraints may be automatically assigned to any device.</p>\n<p>You can restrict the set of device used by TensorFlow by setting the <code>CUDA_VISIBLE_DEVICES</code> environment variable.</p>\n<p>You can also remap the numbering of GPUs via by passing <code>ConfigProto.gpu_options.visible_devices_list</code> argument to <code>tf.Session()</code>.</p>\n<p>Closing since this is not a bug/issue, but rather a general usage question (which should really be directed to StackOverflow)</p>", "body_text": "The tensorflow runtime by default enumerates all GPUs and initializes them.  (including pre-allocating a bunch of GPU memory to reduce runtime overheads).\nAll that with tf.device(\"/gpu:1\") does is request to place a particular op on a specific GPU.  Other ops without device constraints may be automatically assigned to any device.\nYou can restrict the set of device used by TensorFlow by setting the CUDA_VISIBLE_DEVICES environment variable.\nYou can also remap the numbering of GPUs via by passing ConfigProto.gpu_options.visible_devices_list argument to tf.Session().\nClosing since this is not a bug/issue, but rather a general usage question (which should really be directed to StackOverflow)", "body": "The tensorflow runtime by default enumerates all GPUs and initializes them.  (including pre-allocating a bunch of GPU memory to reduce runtime overheads).\r\n\r\nAll that `with tf.device(\"/gpu:1\")` does is request to place a _particular_ op on a specific GPU.  Other ops without device constraints may be automatically assigned to any device.\r\n\r\nYou can restrict the set of device used by TensorFlow by setting the `CUDA_VISIBLE_DEVICES` environment variable. \r\n\r\nYou can also remap the numbering of GPUs via by passing `ConfigProto.gpu_options.visible_devices_list` argument to `tf.Session()`.\r\n\r\nClosing since this is not a bug/issue, but rather a general usage question (which should really be directed to StackOverflow)"}