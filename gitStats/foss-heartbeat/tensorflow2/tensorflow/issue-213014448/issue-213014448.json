{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8239", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8239/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8239/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8239/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8239", "id": 213014448, "node_id": "MDU6SXNzdWUyMTMwMTQ0NDg=", "number": 8239, "title": "Why still using two gpus even if I have set gpu_device to the second gpu?", "user": {"login": "brisker", "id": 13804492, "node_id": "MDQ6VXNlcjEzODA0NDky", "avatar_url": "https://avatars3.githubusercontent.com/u/13804492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brisker", "html_url": "https://github.com/brisker", "followers_url": "https://api.github.com/users/brisker/followers", "following_url": "https://api.github.com/users/brisker/following{/other_user}", "gists_url": "https://api.github.com/users/brisker/gists{/gist_id}", "starred_url": "https://api.github.com/users/brisker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brisker/subscriptions", "organizations_url": "https://api.github.com/users/brisker/orgs", "repos_url": "https://api.github.com/users/brisker/repos", "events_url": "https://api.github.com/users/brisker/events{/privacy}", "received_events_url": "https://api.github.com/users/brisker/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-09T11:50:38Z", "updated_at": "2017-03-09T17:08:28Z", "closed_at": "2017-03-09T17:08:28Z", "author_association": "NONE", "body_html": "<p>NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.</p>\n<p>I want to use the second gpu, and I use the following code to do this:<br>\nwith tf.Session() as sess:<br>\nwith tf.device(\"/gpu:1\"):</p>\n<p>but why the nvidis-smi results still shows that tensorflow is using both of the two gpus?<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu14.04 ,Tensorflow 1.0.0rc2</p>\n<p>Installed version of CUDA and cuDNN:  cuda7.5, cudnn5<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<h3>What other attempted solutions have you tried?</h3>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\nI want to use the second gpu, and I use the following code to do this:\nwith tf.Session() as sess:\nwith tf.device(\"/gpu:1\"):\nbut why the nvidis-smi results still shows that tensorflow is using both of the two gpus?\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nEnvironment info\nOperating System: Ubuntu14.04 ,Tensorflow 1.0.0rc2\nInstalled version of CUDA and cuDNN:  cuda7.5, cudnn5\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\nThe output of bazel version\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nWhat other attempted solutions have you tried?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nI want to use the second gpu, and I use the following code to do this:\r\n        with tf.Session() as sess:\r\n            with tf.device(\"/gpu:1\"):\r\n\r\nbut why the nvidis-smi results still shows that tensorflow is using both of the two gpus?\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Ubuntu14.04 ,Tensorflow 1.0.0rc2\r\n\r\nInstalled version of CUDA and cuDNN:  cuda7.5, cudnn5\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}