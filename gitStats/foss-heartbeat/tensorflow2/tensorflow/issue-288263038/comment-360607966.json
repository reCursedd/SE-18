{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360607966", "html_url": "https://github.com/tensorflow/tensorflow/pull/16085#issuecomment-360607966", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16085", "id": 360607966, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDYwNzk2Ng==", "user": {"login": "yongtang", "id": 6932348, "node_id": "MDQ6VXNlcjY5MzIzNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6932348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongtang", "html_url": "https://github.com/yongtang", "followers_url": "https://api.github.com/users/yongtang/followers", "following_url": "https://api.github.com/users/yongtang/following{/other_user}", "gists_url": "https://api.github.com/users/yongtang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongtang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongtang/subscriptions", "organizations_url": "https://api.github.com/users/yongtang/orgs", "repos_url": "https://api.github.com/users/yongtang/repos", "events_url": "https://api.github.com/users/yongtang/events{/privacy}", "received_events_url": "https://api.github.com/users/yongtang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-25T21:34:45Z", "updated_at": "2018-01-25T21:34:45Z", "author_association": "MEMBER", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a>. The broadcasting compatibility for dropout is the reverse of normal broadcasting compatibility. In other words, with</p>\n<pre><code>&gt;&gt;&gt; a = tf.TensorShape([None, 1])\n&gt;&gt;&gt; b = tf.TensorShape([1200, 3])\n</code></pre>\n<p>the expected result is <code>[1200, 1]</code>.</p>\n<p>I think this specific shape processing might be used in other places in the future as well.<br>\nMaybe I could add a method in common_shapes.py, e.g.,</p>\n<pre><code>def as_shape_with_default(shape_x, shape_y): \n...\n</code></pre>\n<p>and calling the defined method from <code>nn_ops.py</code>?</p>", "body_text": "Thanks @vrv. The broadcasting compatibility for dropout is the reverse of normal broadcasting compatibility. In other words, with\n>>> a = tf.TensorShape([None, 1])\n>>> b = tf.TensorShape([1200, 3])\n\nthe expected result is [1200, 1].\nI think this specific shape processing might be used in other places in the future as well.\nMaybe I could add a method in common_shapes.py, e.g.,\ndef as_shape_with_default(shape_x, shape_y): \n...\n\nand calling the defined method from nn_ops.py?", "body": "Thanks @vrv. The broadcasting compatibility for dropout is the reverse of normal broadcasting compatibility. In other words, with\r\n```\r\n>>> a = tf.TensorShape([None, 1])\r\n>>> b = tf.TensorShape([1200, 3])\r\n```\r\nthe expected result is `[1200, 1]`.\r\n\r\nI think this specific shape processing might be used in other places in the future as well.\r\nMaybe I could add a method in common_shapes.py, e.g.,\r\n```\r\ndef as_shape_with_default(shape_x, shape_y): \r\n...\r\n```\r\nand calling the defined method from `nn_ops.py`?"}