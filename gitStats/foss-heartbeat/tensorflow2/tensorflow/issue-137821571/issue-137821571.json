{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1355", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1355/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1355/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1355/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1355", "id": 137821571, "node_id": "MDU6SXNzdWUxMzc4MjE1NzE=", "number": 1355, "title": "Resource exhausted", "user": {"login": "omarcr", "id": 6231285, "node_id": "MDQ6VXNlcjYyMzEyODU=", "avatar_url": "https://avatars2.githubusercontent.com/u/6231285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/omarcr", "html_url": "https://github.com/omarcr", "followers_url": "https://api.github.com/users/omarcr/followers", "following_url": "https://api.github.com/users/omarcr/following{/other_user}", "gists_url": "https://api.github.com/users/omarcr/gists{/gist_id}", "starred_url": "https://api.github.com/users/omarcr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/omarcr/subscriptions", "organizations_url": "https://api.github.com/users/omarcr/orgs", "repos_url": "https://api.github.com/users/omarcr/repos", "events_url": "https://api.github.com/users/omarcr/events{/privacy}", "received_events_url": "https://api.github.com/users/omarcr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2016-03-02T09:33:41Z", "updated_at": "2018-07-24T18:53:12Z", "closed_at": "2016-03-03T18:02:33Z", "author_association": "NONE", "body_html": "<p>This error happens when training several models in a for loop:</p>\n<p><code>W tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 W tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 Compute status: Resource exhausted: OOM when allocating tensor with shape [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]] Traceback (most recent call last): File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in &lt;module&gt; fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit shuffle=shuffle, metrics=metrics) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit outs = f(ins_batch) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__ updated = session.run(self.outputs + self.updates, feed_dict=feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run e.code) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 } [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]] [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]] Caused by op u'mul_4305', defined at: File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in &lt;module&gt; model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary') File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile train_loss) File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates m_t = (self.beta_1 * m) + (1 - self.beta_1) * g File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in &lt;lambda&gt; setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b)) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp return getattr(ops.Tensor, operator)(a._AsTensor(), b) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper return func(x, y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op original_op=self._default_original_op, op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__ self._traceback = _extract_stack() : OOM when allocating tensor with shape [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]] Traceback (most recent call last): File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in &lt;module&gt; fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit shuffle=shuffle, metrics=metrics) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit outs = f(ins_batch) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__ updated = session.run(self.outputs + self.updates, feed_dict=feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run e.code) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 } [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]] [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]] Caused by op u'mul_4305', defined at: File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in &lt;module&gt; model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary') File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile train_loss) File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates m_t = (self.beta_1 * m) + (1 - self.beta_1) * g File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in &lt;lambda&gt; setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b)) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp return getattr(ops.Tensor, operator)(a._AsTensor(), b) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper return func(x, y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op original_op=self._default_original_op, op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__ self._traceback = _extract_stack() </code></p>\n<p>Any advice on how to solve this?</p>\n<p>Thank you</p>", "body_text": "This error happens when training several models in a for loop:\nW tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 W tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 Compute status: Resource exhausted: OOM when allocating tensor with shape [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]] Traceback (most recent call last): File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in <module> fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit shuffle=shuffle, metrics=metrics) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit outs = f(ins_batch) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__ updated = session.run(self.outputs + self.updates, feed_dict=feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run e.code) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 } [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]] [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]] Caused by op u'mul_4305', defined at: File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in <module> model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary') File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile train_loss) File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates m_t = (self.beta_1 * m) + (1 - self.beta_1) * g File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in <lambda> setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b)) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp return getattr(ops.Tensor, operator)(a._AsTensor(), b) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper return func(x, y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op original_op=self._default_original_op, op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__ self._traceback = _extract_stack() : OOM when allocating tensor with shape [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]] Traceback (most recent call last): File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in <module> fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit shuffle=shuffle, metrics=metrics) File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit outs = f(ins_batch) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__ updated = session.run(self.outputs + self.updates, feed_dict=feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run e.code) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 } [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]] [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]] Caused by op u'mul_4305', defined at: File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in <module> model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary') File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile train_loss) File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates m_t = (self.beta_1 * m) + (1 - self.beta_1) * g File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in <lambda> setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b)) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp return getattr(ops.Tensor, operator)(a._AsTensor(), b) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper return func(x, y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op original_op=self._default_original_op, op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__ self._traceback = _extract_stack() \nAny advice on how to solve this?\nThank you", "body": "This error happens when training several models in a for loop:\n\n`W tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 W tensorflow/core/common_runtime/executor.cc:1076] 0x18ef02bb0 Compute status: Resource exhausted: OOM when allocating tensor with shape\n     [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]]\nTraceback (most recent call last):\n  File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in <module>\n    fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit\n    shuffle=shuffle, metrics=metrics)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit\n    outs = f(ins_batch)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__\n    updated = session.run(self.outputs + self.updates, feed_dict=feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 }\n     [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]]\n     [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'mul_4305', defined at:\n  File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in <module>\n    model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile\n    train_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates\n    m_t = (self.beta_1 * m) + (1 - self.beta_1) * g\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in <lambda>\n    setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp\n    return getattr(ops.Tensor, operator)(a._AsTensor(), b)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n: OOM when allocating tensor with shape\n     [[Node: sub_2518 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](sub_2518/x, Variable_1955/read)]]\nTraceback (most recent call last):\n  File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 398, in <module>\n    fited = model.fit(Xtrain, ytrain, nb_epoch=n_epochs, batch_size=batch_size, show_accuracy=True, shuffle=True, validation_split=0.35)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 581, in fit\n    shuffle=shuffle, metrics=metrics)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 239, in _fit\n    outs = f(ins_batch)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 336, in __call__\n    updated = session.run(self.outputs + self.updates, feed_dict=feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 3200 } dim { size: 2000 }\n     [[Node: mul_4305 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_1954/read, Variable_1956/read)]]\n     [[Node: add_3103/_9711 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_423_add_3103\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'mul_4305', defined at:\n  File \"/media/konet/01D15611945D72C0/Pycharm_ubuntu/deep_neural_network_binary/dnn_127_models_binary.py\", line 387, in <module>\n    model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary')\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 440, in compile\n    train_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 262, in get_updates\n    m_t = (self.beta_1 * m) + (1 - self.beta_1) * g\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 452, in <lambda>\n    setattr(Variable, operator, lambda a, b: Variable._RunOp(operator, a, b))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 467, in _RunOp\n    return getattr(ops.Tensor, operator)(a._AsTensor(), b)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n`\n\nAny advice on how to solve this?\n\nThank you\n"}