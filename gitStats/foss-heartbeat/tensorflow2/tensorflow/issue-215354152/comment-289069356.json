{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/289069356", "html_url": "https://github.com/tensorflow/tensorflow/issues/8550#issuecomment-289069356", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8550", "id": 289069356, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTA2OTM1Ng==", "user": {"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-24T16:16:53Z", "updated_at": "2017-03-24T16:20:59Z", "author_association": "MEMBER", "body_html": "<p>Ok, so 1920x1080 produces the inference error, while 1440x1080 complains about invalid size? That makes more sense.</p>\n<p>Three possible options here when legacy mode is detected:</p>\n<ol>\n<li>Only use the luminance plane to create the image. It would be something like:</li>\n</ol>\n<pre><code>byte[] inputBuffer = // from preview frame plane 0\nint[] bitmapBuffer = new int[frameHeight * frameWidth];\nfor (int y = 0; y &lt; frameHeight; ++y) {\n  for (int x = 0; x &lt; frameWidth; ++x) {\n    int pixelValue = inputBuffer[y * frameWidth + x];\n    bitmapBuffer[y * frameWidth + x] = Color.ARGB(255, value, value, value);\n  }\n}\n</code></pre>\n<p>Then bitmapBuffer would be used to initialize the RGB bitmap before it gets resized.</p>\n<ol start=\"2\">\n<li>\n<p>Use the android.hardware.Camera API rather than Camera2 and see if you have better luck. You could try updating the implementation <a href=\"https://github.com/hamidb/tensorflow/blob/api20/tensorflow/examples/android/src/org/tensorflow/demo/CameraConnectionFragment.java\">here</a> to work with the current demo code.</p>\n</li>\n<li>\n<p>Figure out the correct conversion for whatever random color format your phone tries to use, but that would mean finding out programmatically what that is.</p>\n</li>\n</ol>\n<p>I'd suggest 1 or 2, which we would gladly welcome contributions for. 3 seems a bit too special-cased for this demo code, but if you just want to get it working for yourself is an option.</p>", "body_text": "Ok, so 1920x1080 produces the inference error, while 1440x1080 complains about invalid size? That makes more sense.\nThree possible options here when legacy mode is detected:\n\nOnly use the luminance plane to create the image. It would be something like:\n\nbyte[] inputBuffer = // from preview frame plane 0\nint[] bitmapBuffer = new int[frameHeight * frameWidth];\nfor (int y = 0; y < frameHeight; ++y) {\n  for (int x = 0; x < frameWidth; ++x) {\n    int pixelValue = inputBuffer[y * frameWidth + x];\n    bitmapBuffer[y * frameWidth + x] = Color.ARGB(255, value, value, value);\n  }\n}\n\nThen bitmapBuffer would be used to initialize the RGB bitmap before it gets resized.\n\n\nUse the android.hardware.Camera API rather than Camera2 and see if you have better luck. You could try updating the implementation here to work with the current demo code.\n\n\nFigure out the correct conversion for whatever random color format your phone tries to use, but that would mean finding out programmatically what that is.\n\n\nI'd suggest 1 or 2, which we would gladly welcome contributions for. 3 seems a bit too special-cased for this demo code, but if you just want to get it working for yourself is an option.", "body": "Ok, so 1920x1080 produces the inference error, while 1440x1080 complains about invalid size? That makes more sense.\r\n\r\nThree possible options here when legacy mode is detected:\r\n\r\n1. Only use the luminance plane to create the image. It would be something like:\r\n```\r\nbyte[] inputBuffer = // from preview frame plane 0\r\nint[] bitmapBuffer = new int[frameHeight * frameWidth];\r\nfor (int y = 0; y < frameHeight; ++y) {\r\n  for (int x = 0; x < frameWidth; ++x) {\r\n    int pixelValue = inputBuffer[y * frameWidth + x];\r\n    bitmapBuffer[y * frameWidth + x] = Color.ARGB(255, value, value, value);\r\n  }\r\n}\r\n```\r\n\r\nThen bitmapBuffer would be used to initialize the RGB bitmap before it gets resized.\r\n\r\n\r\n2. Use the android.hardware.Camera API rather than Camera2 and see if you have better luck. You could try updating the implementation [here](https://github.com/hamidb/tensorflow/blob/api20/tensorflow/examples/android/src/org/tensorflow/demo/CameraConnectionFragment.java) to work with the current demo code.\r\n\r\n\r\n3. Figure out the correct conversion for whatever random color format your phone tries to use, but that would mean finding out programmatically what that is.\r\n\r\n\r\nI'd suggest 1 or 2, which we would gladly welcome contributions for. 3 seems a bit too special-cased for this demo code, but if you just want to get it working for yourself is an option.\r\n\r\n\r\n\r\n"}