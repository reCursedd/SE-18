{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291983877", "html_url": "https://github.com/tensorflow/tensorflow/issues/6132#issuecomment-291983877", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6132", "id": 291983877, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTk4Mzg3Nw==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T20:16:45Z", "updated_at": "2017-04-05T20:16:45Z", "author_association": "MEMBER", "body_html": "<p>I don't think creating sparse string Tensors on the GPU will work since the GPU does not support strings.</p>\n<p>It's best to structure your model so the string to int conversion happens on the CPU, and the GPU just processes the dense part of your model.</p>\n<p>That said, the linear regression canned estimator will probably see no benefit from running on the GPU (not enough matrix multiplications to offset the data transfer cost).</p>", "body_text": "I don't think creating sparse string Tensors on the GPU will work since the GPU does not support strings.\nIt's best to structure your model so the string to int conversion happens on the CPU, and the GPU just processes the dense part of your model.\nThat said, the linear regression canned estimator will probably see no benefit from running on the GPU (not enough matrix multiplications to offset the data transfer cost).", "body": "I don't think creating sparse string Tensors on the GPU will work since the GPU does not support strings.\r\n\r\nIt's best to structure your model so the string to int conversion happens on the CPU, and the GPU just processes the dense part of your model.\r\n\r\nThat said, the linear regression canned estimator will probably see no benefit from running on the GPU (not enough matrix multiplications to offset the data transfer cost)."}