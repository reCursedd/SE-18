{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/249623937", "html_url": "https://github.com/tensorflow/tensorflow/issues/2540#issuecomment-249623937", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2540", "id": 249623937, "node_id": "MDEyOklzc3VlQ29tbWVudDI0OTYyMzkzNw==", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-26T16:35:54Z", "updated_at": "2016-09-26T16:35:54Z", "author_association": "NONE", "body_html": "<p>After reading some code and docs, I think I see the difficulty with <code>select</code> gradient.</p>\n<p>The <code>select</code> gradient is here: <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/math_grad.py#L688\">tensorflow/tensorflow/python/ops/math_grad.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 688\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/4addf4b5806cd731949c6582a83f5824599cd1ef\">4addf4b</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L688\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"688\"></td>\n          <td id=\"LC688\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-en\">@ops.RegisterGradient</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Select<span class=\"pl-pds\">\"</span></span>) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>Gradients are only taken on the output of an op with respect to the input (and then multiplied by the accumulated gradient from objective to output of op), so in my example above the <code>select</code> gradient computes <code>dw/dt=1</code> and <code>dw/de=0</code>. This gives <code>dL/dt=dL/dw</code> and <code>dL/de=0</code> for objective <code>L</code>.</p>\n<p>However, the graph traversal algorithm to compute gradient continues, and computes <code>dt/dx = 1, de/dx = -Infinity</code>, which finally gives <code>dL/dx = dL/dt * dt/dx + dL/de * de/dx = dL/dt * 1 + 0 * Inf = dL/dt + NaN = NaN</code>.</p>\n<p>The issue is the <code>0 * Inf = NaN</code> term, and the fact that this computation doesn't happen in the select node (happens in the divide node in this case).</p>\n<p>I spent a few minutes thinking of possible solutions to this, and none of them are pretty or seem worth implementing.<br>\nOne option is to pass a mask of hard zero gradients around during gradient computation. In this case, after each node computes it's gradients, the hard zero gradients can be reset to 0. This isn't a very appealing option.<br>\nThe other option is to significantly change the gradient propagation algorithm. Rather than computing gradient of objective with respect to op input, compute gradient of op output with respect to op input for all ops first. Then do a multiplicative accumulate pass. This has the downside of significant framework rewrite, and is unworkable because gradient of op output wrt op input can be high order tensors (gradient of matrix multiply wrt inputs is very large).<br>\nIn summary, there doesn't seem to be a good way to make Tensorflow compute the select gradient correctly. I wrote this largely for my own understanding of why \"[NaN gradient] is inevitable\", hopefully this can be useful to someone else who happens across the issue.</p>", "body_text": "After reading some code and docs, I think I see the difficulty with select gradient.\nThe select gradient is here: \n  \n    \n      tensorflow/tensorflow/python/ops/math_grad.py\n    \n    \n         Line 688\n      in\n      4addf4b\n    \n    \n    \n    \n\n        \n          \n           @ops.RegisterGradient(\"Select\") \n        \n    \n  \n\n\nGradients are only taken on the output of an op with respect to the input (and then multiplied by the accumulated gradient from objective to output of op), so in my example above the select gradient computes dw/dt=1 and dw/de=0. This gives dL/dt=dL/dw and dL/de=0 for objective L.\nHowever, the graph traversal algorithm to compute gradient continues, and computes dt/dx = 1, de/dx = -Infinity, which finally gives dL/dx = dL/dt * dt/dx + dL/de * de/dx = dL/dt * 1 + 0 * Inf = dL/dt + NaN = NaN.\nThe issue is the 0 * Inf = NaN term, and the fact that this computation doesn't happen in the select node (happens in the divide node in this case).\nI spent a few minutes thinking of possible solutions to this, and none of them are pretty or seem worth implementing.\nOne option is to pass a mask of hard zero gradients around during gradient computation. In this case, after each node computes it's gradients, the hard zero gradients can be reset to 0. This isn't a very appealing option.\nThe other option is to significantly change the gradient propagation algorithm. Rather than computing gradient of objective with respect to op input, compute gradient of op output with respect to op input for all ops first. Then do a multiplicative accumulate pass. This has the downside of significant framework rewrite, and is unworkable because gradient of op output wrt op input can be high order tensors (gradient of matrix multiply wrt inputs is very large).\nIn summary, there doesn't seem to be a good way to make Tensorflow compute the select gradient correctly. I wrote this largely for my own understanding of why \"[NaN gradient] is inevitable\", hopefully this can be useful to someone else who happens across the issue.", "body": "After reading some code and docs, I think I see the difficulty with `select` gradient.\n\nThe `select` gradient is here: https://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/math_grad.py#L688\n\nGradients are only taken on the output of an op with respect to the input (and then multiplied by the accumulated gradient from objective to output of op), so in my example above the `select` gradient computes `dw/dt=1` and `dw/de=0`. This gives `dL/dt=dL/dw` and `dL/de=0` for objective `L`.\n\nHowever, the graph traversal algorithm to compute gradient continues, and computes `dt/dx = 1, de/dx = -Infinity`, which finally gives `dL/dx = dL/dt * dt/dx + dL/de * de/dx = dL/dt * 1 + 0 * Inf = dL/dt + NaN = NaN`.\n\nThe issue is the `0 * Inf = NaN` term, and the fact that this computation doesn't happen in the select node (happens in the divide node in this case).\n\nI spent a few minutes thinking of possible solutions to this, and none of them are pretty or seem worth implementing. \nOne option is to pass a mask of hard zero gradients around during gradient computation. In this case, after each node computes it's gradients, the hard zero gradients can be reset to 0. This isn't a very appealing option.\nThe other option is to significantly change the gradient propagation algorithm. Rather than computing gradient of objective with respect to op input, compute gradient of op output with respect to op input for all ops first. Then do a multiplicative accumulate pass. This has the downside of significant framework rewrite, and is unworkable because gradient of op output wrt op input can be high order tensors (gradient of matrix multiply wrt inputs is very large).\nIn summary, there doesn't seem to be a good way to make Tensorflow compute the select gradient correctly. I wrote this largely for my own understanding of why \"[NaN gradient] is inevitable\", hopefully this can be useful to someone else who happens across the issue.\n"}