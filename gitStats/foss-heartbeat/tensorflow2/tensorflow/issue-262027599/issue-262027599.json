{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13441", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13441/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13441/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13441/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13441", "id": 262027599, "node_id": "MDU6SXNzdWUyNjIwMjc1OTk=", "number": 13441, "title": "tf.biderectional_dynamic_rnn get stuck when running the graph", "user": {"login": "LiuZichuan", "id": 22128160, "node_id": "MDQ6VXNlcjIyMTI4MTYw", "avatar_url": "https://avatars2.githubusercontent.com/u/22128160?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LiuZichuan", "html_url": "https://github.com/LiuZichuan", "followers_url": "https://api.github.com/users/LiuZichuan/followers", "following_url": "https://api.github.com/users/LiuZichuan/following{/other_user}", "gists_url": "https://api.github.com/users/LiuZichuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/LiuZichuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LiuZichuan/subscriptions", "organizations_url": "https://api.github.com/users/LiuZichuan/orgs", "repos_url": "https://api.github.com/users/LiuZichuan/repos", "events_url": "https://api.github.com/users/LiuZichuan/events{/privacy}", "received_events_url": "https://api.github.com/users/LiuZichuan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2017-10-02T09:27:09Z", "updated_at": "2018-10-08T16:35:50Z", "closed_at": "2018-01-03T19:14:31Z", "author_association": "NONE", "body_html": "<p>I built a 1-layer bidirectional RNN with 128 hidden nodes using the <code>output = tf.nn.bidirectional_dynamic_rnn(forward_cell, backward_cell, inputs, seqlens, tf.float32, is_tuple=True, time_major=True)</code> interface. I run the network with input data size of 57x285x4608 ([time_step x batch_size x num_feature]) but get stuck in the <code>_outputs = sess.run(outputs, feeds)</code>. The system does not indicate any resource exhausted. When I reduce the time_step to 31, the network runs successfully. When I only reduce the number of 3rd dimension to 512, it still fails to work. It seems there is some constraints on the input sequence length.</p>\n<p>Any idea on this problem?</p>\n<p>I run this program on Nvidia DGX Server with 4 Tesla P100 GPUs. The OS is ubuntu 14.04.</p>", "body_text": "I built a 1-layer bidirectional RNN with 128 hidden nodes using the output = tf.nn.bidirectional_dynamic_rnn(forward_cell, backward_cell, inputs, seqlens, tf.float32, is_tuple=True, time_major=True) interface. I run the network with input data size of 57x285x4608 ([time_step x batch_size x num_feature]) but get stuck in the _outputs = sess.run(outputs, feeds). The system does not indicate any resource exhausted. When I reduce the time_step to 31, the network runs successfully. When I only reduce the number of 3rd dimension to 512, it still fails to work. It seems there is some constraints on the input sequence length.\nAny idea on this problem?\nI run this program on Nvidia DGX Server with 4 Tesla P100 GPUs. The OS is ubuntu 14.04.", "body": "I built a 1-layer bidirectional RNN with 128 hidden nodes using the `output = tf.nn.bidirectional_dynamic_rnn(forward_cell, backward_cell, inputs, seqlens, tf.float32, is_tuple=True, time_major=True)` interface. I run the network with input data size of 57x285x4608 ([time_step x batch_size x num_feature]) but get stuck in the `_outputs = sess.run(outputs, feeds)`. The system does not indicate any resource exhausted. When I reduce the time_step to 31, the network runs successfully. When I only reduce the number of 3rd dimension to 512, it still fails to work. It seems there is some constraints on the input sequence length.\r\n\r\nAny idea on this problem?\r\n\r\nI run this program on Nvidia DGX Server with 4 Tesla P100 GPUs. The OS is ubuntu 14.04."}