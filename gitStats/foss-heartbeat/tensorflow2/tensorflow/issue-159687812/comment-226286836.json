{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226286836", "html_url": "https://github.com/tensorflow/tensorflow/issues/2788#issuecomment-226286836", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2788", "id": 226286836, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjI4NjgzNg==", "user": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-15T19:00:50Z", "updated_at": "2016-06-15T19:00:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The cifar model uses local response normalization operation. Since this op doesn't have a GPU implementation it is being run on the CPU and therefore a fairly high average CPU utilization is expected.<br>\nHowever since most of the graph is being processed on the GPU I expect that the threads will often be waiting for actual work to do,  and therefore the stack trace will often show them stuck in sched_yield() or std::condition_variable::wait().</p>\n<p>The thing that I can't explain in your stack trace is that we have 10 calls to CopyTensor::ViaDMA running at the same time. Are you creating multiple towers ?</p>", "body_text": "The cifar model uses local response normalization operation. Since this op doesn't have a GPU implementation it is being run on the CPU and therefore a fairly high average CPU utilization is expected.\nHowever since most of the graph is being processed on the GPU I expect that the threads will often be waiting for actual work to do,  and therefore the stack trace will often show them stuck in sched_yield() or std::condition_variable::wait().\nThe thing that I can't explain in your stack trace is that we have 10 calls to CopyTensor::ViaDMA running at the same time. Are you creating multiple towers ?", "body": "The cifar model uses local response normalization operation. Since this op doesn't have a GPU implementation it is being run on the CPU and therefore a fairly high average CPU utilization is expected.\nHowever since most of the graph is being processed on the GPU I expect that the threads will often be waiting for actual work to do,  and therefore the stack trace will often show them stuck in sched_yield() or std::condition_variable::wait().\n\nThe thing that I can't explain in your stack trace is that we have 10 calls to CopyTensor::ViaDMA running at the same time. Are you creating multiple towers ?\n"}