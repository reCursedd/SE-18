{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18988", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18988/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18988/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18988/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18988", "id": 319007821, "node_id": "MDU6SXNzdWUzMTkwMDc4MjE=", "number": 18988, "title": "Tensorflow input pipeline & performance - images - memory", "user": {"login": "verbeemen", "id": 3610840, "node_id": "MDQ6VXNlcjM2MTA4NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/3610840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/verbeemen", "html_url": "https://github.com/verbeemen", "followers_url": "https://api.github.com/users/verbeemen/followers", "following_url": "https://api.github.com/users/verbeemen/following{/other_user}", "gists_url": "https://api.github.com/users/verbeemen/gists{/gist_id}", "starred_url": "https://api.github.com/users/verbeemen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/verbeemen/subscriptions", "organizations_url": "https://api.github.com/users/verbeemen/orgs", "repos_url": "https://api.github.com/users/verbeemen/repos", "events_url": "https://api.github.com/users/verbeemen/events{/privacy}", "received_events_url": "https://api.github.com/users/verbeemen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-30T19:32:39Z", "updated_at": "2018-05-18T00:43:50Z", "closed_at": "2018-05-18T00:43:49Z", "author_association": "NONE", "body_html": "<p>Best,</p>\n<h1>system properties:</h1>\n<ul>\n<li>\n<p>windows 10</p>\n</li>\n<li>\n<p>intel core i7-6820HQ CPU | 2.70GHZ 8CPUs</p>\n</li>\n<li>\n<p>16GB ram</p>\n</li>\n<li>\n<p>64bit</p>\n</li>\n<li>\n<p>NVIDIA Quadro M1000M</p>\n<ul>\n<li>approx. total memory: 10093 MB</li>\n<li>Display memory (VRAM): 2019 MB</li>\n<li>Shared Memory: 8073 MB</li>\n</ul>\n</li>\n<li>\n<p>Tensorflow 1.8</p>\n</li>\n<li>\n<p>Python 3.5.2</p>\n</li>\n<li>\n<p>images (i've 36k images):</p>\n<ul>\n<li>train: 3000 x (720x1280x3)</li>\n<li>valid: 500 x (720x1280x3)</li>\n<li>test : 500 x (720x1280x3)</li>\n</ul>\n</li>\n</ul>\n<h3>My story &amp; strugles</h3>\n<p>First of all, I would like to say that I really like machine learning, specially neural networks. But most of the time, when I'm working with Tensorflow, I've the feeling that it is backstabbing me the entirely time. (like for example, the speed of those releases... (1.8 :O )) &amp; Sometimes I even don't know any more if I'm doing it right or wrong? (Or can I do it better?)</p>\n<p>Therefore, my main question is: <strong>How do you create a proper input pipeline!</strong><br>\npreferable with tensorflow gpu</p>\n<p>Because come one, it should be easy as $*%\u20ack no? Especially, <strong>can't you cover 90% of all the input pipelines into 1, 2 or 3 template pipelines?</strong> (I think it is +/- possible, (a giant image with a cat is still an image | matrix))<br>\nand if it is possible, why can't we have an optimized template/base for it?</p>\n<p>as you would have noticed, I've provided my system properties and info about the data which I'm using. My goals are:</p>\n<ul>\n<li>Create a GAN-network (GPU)(doesn't have to be a gan for this question)</li>\n<li>Use the TF-estimator api (with custom features)</li>\n<li>Use TF-records !</li>\n<li>Use TF-dataset !</li>\n</ul>\n<p>But Unfortunately, most of the time, I'll receive errors like for example that I'm out of memory :'(<br>\nAnd the more I look things up, the more I start to hesitate...</p>\n<h2>Step 1: create TF-records</h2>\n<p>In my first step, I create a tf-record (train). And as you can see, I loop over the images (from a certain folder) and write all the data into 1 tf-record.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Helper-function for wrapping an integer so it can be saved to the TFRecords file</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">wrap_int64</span>(<span class=\"pl-smi\">value</span>):\n    <span class=\"pl-k\">return</span> tf.train.Feature(<span class=\"pl-v\">int64_list</span><span class=\"pl-k\">=</span>tf.train.Int64List(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>[value]))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Helper-function for wrapping raw bytes so they can be saved to the TFRecords file.</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">wrap_bytes</span>(<span class=\"pl-smi\">value</span>):\n    <span class=\"pl-k\">return</span> tf.train.Feature(<span class=\"pl-v\">bytes_list</span><span class=\"pl-k\">=</span>tf.train.BytesList(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>[value]))\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>from skimage.transform import rescale, resize, downscale_local_mean</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">convert</span>(<span class=\"pl-smi\">image_paths</span>, <span class=\"pl-smi\">out_path</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Args:</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> image_paths   List of file-paths for the images.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> labels        Class-labels for the images.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> out_path      File-path for the TFRecords output file.</span>\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Converting: <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> out_path)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Number of images. Used when printing the progress.</span>\n    num_images <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(image_paths)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Open a TFRecordWriter for the output-file.</span>\n    <span class=\"pl-k\">with</span> tf.python_io.TFRecordWriter(out_path) <span class=\"pl-k\">as</span> writer:\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Iterate over all the image-paths and class-labels.</span>\n        <span class=\"pl-k\">for</span> i, path <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(image_paths):\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Print the percentage-progress.</span>\n            print_progress(<span class=\"pl-v\">count</span><span class=\"pl-k\">=</span>i<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">total</span><span class=\"pl-k\">=</span>num_images)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Load the image-file using matplotlib's imread function.</span>\n            img_bytes_sharp <span class=\"pl-k\">=</span> load_images(path)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Convert the image to raw bytes.</span>\n            img_bytes_sharp <span class=\"pl-k\">=</span> tf.compat.as_bytes(img_bytes_sharp.tostring())\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a dict with the data we want to save in the</span>\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> TFRecords file. You can add more relevant data here.</span>\n            data <span class=\"pl-k\">=</span> \\\n                {\n                    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: wrap_bytes(img_bytes_sharp)\n                }\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Wrap the data as TensorFlow Features.</span>\n            feature <span class=\"pl-k\">=</span> tf.train.Features(<span class=\"pl-v\">feature</span><span class=\"pl-k\">=</span>data)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Wrap again as a TensorFlow Example.</span>\n            example <span class=\"pl-k\">=</span> tf.train.Example(<span class=\"pl-v\">features</span><span class=\"pl-k\">=</span>feature)\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Serialize the data.</span>\n            serialized <span class=\"pl-k\">=</span> example.SerializeToString()\n\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Write the serialized data to the TFRecords file.</span>\n            writer.write(serialized)</pre></div>\n<p>about the tf-record:</p>\n<ul>\n<li>size: 6 GB</li>\n<li>3000 images</li>\n<li>preprocessed:\n<ul>\n<li>RGB values between: 0 and 1</li>\n<li>type: float32</li>\n</ul>\n</li>\n</ul>\n<h2>Step 2: Load TF-records (parser)</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">parse</span>(<span class=\"pl-smi\">serialized</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Define a dict with the data-names and types we expect to</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> find in the TFRecords file.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> It is a bit awkward that this needs to be specified again,</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> because it could have been written in the header of the</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> TFRecords file instead.</span>\n    features <span class=\"pl-k\">=</span> \\\n        {\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.string)\n        }\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Parse the serialized data so we get a dict with our data.</span>\n    parsed_example <span class=\"pl-k\">=</span> tf.parse_single_example(<span class=\"pl-v\">serialized</span><span class=\"pl-k\">=</span>serialized,\n                                             <span class=\"pl-v\">features</span><span class=\"pl-k\">=</span>features)\n\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decode the raw bytes so it becomes a tensor with type.</span>\n    image_x <span class=\"pl-k\">=</span> tf.decode_raw(parsed_example[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>], tf.float32)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> The type is now uint8 but we need it to be float.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>image_x = tf.cast(image_x, tf.float32)</span>\n\n    <span class=\"pl-k\">return</span> image_x</pre></div>\n<h2>Step 2+1: Load TF-records (for real)</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>(<span class=\"pl-smi\">filenames</span>, <span class=\"pl-smi\">train</span>, <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, <span class=\"pl-smi\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2048</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Args:</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> filenames:   Filenames for the TFRecords files.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> train:       Boolean whether training (True) or testing (False).</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> batch_size:  Return batches of this size.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> buffer_size: Read buffers of this size. The random shuffling</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>              is done on the buffer, so it must be big enough.</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a TensorFlow Dataset-object which has functionality</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> for reading and shuffling data from TFRecords files.</span>\n    dataset <span class=\"pl-k\">=</span> tf.data.TFRecordDataset(<span class=\"pl-v\">filenames</span><span class=\"pl-k\">=</span>filenames)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Parse the serialized data in the TFRecords files.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This returns TensorFlow tensors for the image and labels.</span>\n    dataset <span class=\"pl-k\">=</span> dataset.map(parse)\n\n    <span class=\"pl-k\">if</span> train:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> If training then read a buffer of the given size and</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> randomly shuffle it.</span>\n        dataset <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span>buffer_size)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Allow infinite reading of the data.</span>\n        num_repeat <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> If testing then don't shuffle the data.</span>\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Only go through the data once.</span>\n        num_repeat <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Repeat the dataset the given number of times.</span>\n    dataset <span class=\"pl-k\">=</span> dataset.repeat(num_repeat)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get a batch of data with the given size.</span>\n    dataset <span class=\"pl-k\">=</span> dataset.batch(batch_size)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create an iterator for the dataset and the above modifications.</span>\n    iterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get the next batch of images and labels.</span>\n    images_batch <span class=\"pl-k\">=</span> iterator.get_next()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> The input-function must return a dict wrapping the images.</span>\n    x <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image<span class=\"pl-pds\">'</span></span>: images_batch}\n\n    <span class=\"pl-k\">return</span> x</pre></div>\n<h1>But but but but</h1>\n<p>although, I think that the above set-up is quite clear, as soon as I get rid of the mnist dataset (32x32 images), I receive memory issues. (can't even perform a batch-size of 2)</p>\n<ul>\n<li>Also when I'm trying to solve this and watch/read the tensorflow summit videos (2018), I even wonder if I'm doing it correctly at the first place :s</li>\n</ul>\n<p>For example:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/0d57e9b0b5bafcd6bff0682345c121424fca3548/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f4f644849302e706e67\"><img src=\"https://camo.githubusercontent.com/0d57e9b0b5bafcd6bff0682345c121424fca3548/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f4f644849302e706e67\" alt=\"alt image from ppt summet\" title=\"code\" data-canonical-src=\"https://i.stack.imgur.com/OdHI0.png\" style=\"max-width:100%;\"></a></p>\n<ol>\n<li>\n<p>First of all, how to deal with memory issues? I really can understand that I've a memory issue, when TF tries to store, the whole tf-record 6-7gig in its memory (video-card memory)? but I also would think that it is smarter then that ... (doesn't it work like a generator? add only x values in memory + their location)<br>\n1.1 I really would like to keep the tf-records because they promises us that it is faster then e.g. the placeholders (actually it is also easier to use)</p>\n</li>\n<li>\n<p>In the image, you see at the beginning: <code>Dataset.list_files</code> the question which I've with this is. Is this just 1 file, or does this mean that each image which I've is a <strong>new</strong> tf.record? (do I've) to create 3000 tf records?)(and is this the reason why I might have memory issues?)</p>\n</li>\n<li>\n<p>The image returns a dataset and not a iterator (like in my piece of code), any clue where they might do it (this is necessary right?), when they are using the tf-estimator api?</p>\n</li>\n</ol>\n<p>And that is basically it.<br>\n<strong>underlying question i</strong>s: How can I work &amp; play with Tensorflow|tf-records|tf-estimator <strong>on</strong> <em>BIG</em> images. (even bigger than 720p)</p>\n<p><em>extra info:</em><br>\n(<a href=\"https://www.youtube.com/watch?v=SxOsJPaxHME\" rel=\"nofollow\">https://www.youtube.com/watch?v=SxOsJPaxHME</a> <a href=\"https://www.tensorflow.org/versions/master/performance/datasets_performance\" rel=\"nofollow\">https://www.tensorflow.org/versions/master/performance/datasets_performance</a>)</p>", "body_text": "Best,\nsystem properties:\n\n\nwindows 10\n\n\nintel core i7-6820HQ CPU | 2.70GHZ 8CPUs\n\n\n16GB ram\n\n\n64bit\n\n\nNVIDIA Quadro M1000M\n\napprox. total memory: 10093 MB\nDisplay memory (VRAM): 2019 MB\nShared Memory: 8073 MB\n\n\n\nTensorflow 1.8\n\n\nPython 3.5.2\n\n\nimages (i've 36k images):\n\ntrain: 3000 x (720x1280x3)\nvalid: 500 x (720x1280x3)\ntest : 500 x (720x1280x3)\n\n\n\nMy story & strugles\nFirst of all, I would like to say that I really like machine learning, specially neural networks. But most of the time, when I'm working with Tensorflow, I've the feeling that it is backstabbing me the entirely time. (like for example, the speed of those releases... (1.8 :O )) & Sometimes I even don't know any more if I'm doing it right or wrong? (Or can I do it better?)\nTherefore, my main question is: How do you create a proper input pipeline!\npreferable with tensorflow gpu\nBecause come one, it should be easy as $*%\u20ack no? Especially, can't you cover 90% of all the input pipelines into 1, 2 or 3 template pipelines? (I think it is +/- possible, (a giant image with a cat is still an image | matrix))\nand if it is possible, why can't we have an optimized template/base for it?\nas you would have noticed, I've provided my system properties and info about the data which I'm using. My goals are:\n\nCreate a GAN-network (GPU)(doesn't have to be a gan for this question)\nUse the TF-estimator api (with custom features)\nUse TF-records !\nUse TF-dataset !\n\nBut Unfortunately, most of the time, I'll receive errors like for example that I'm out of memory :'(\nAnd the more I look things up, the more I start to hesitate...\nStep 1: create TF-records\nIn my first step, I create a tf-record (train). And as you can see, I loop over the images (from a certain folder) and write all the data into 1 tf-record.\n# Helper-function for wrapping an integer so it can be saved to the TFRecords file\ndef wrap_int64(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n# Helper-function for wrapping raw bytes so they can be saved to the TFRecords file.\n\ndef wrap_bytes(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\n#from skimage.transform import rescale, resize, downscale_local_mean\n\ndef convert(image_paths, out_path):\n    # Args:\n    # image_paths   List of file-paths for the images.\n    # labels        Class-labels for the images.\n    # out_path      File-path for the TFRecords output file.\n\n    print(\"Converting: \" + out_path)\n\n    # Number of images. Used when printing the progress.\n    num_images = len(image_paths)\n\n    # Open a TFRecordWriter for the output-file.\n    with tf.python_io.TFRecordWriter(out_path) as writer:\n\n        # Iterate over all the image-paths and class-labels.\n        for i, path in enumerate(image_paths):\n\n            # Print the percentage-progress.\n            print_progress(count=i+1, total=num_images)\n\n            # Load the image-file using matplotlib's imread function.\n            img_bytes_sharp = load_images(path)\n\n            # Convert the image to raw bytes.\n            img_bytes_sharp = tf.compat.as_bytes(img_bytes_sharp.tostring())\n\n            # Create a dict with the data we want to save in the\n            # TFRecords file. You can add more relevant data here.\n            data = \\\n                {\n                    'x': wrap_bytes(img_bytes_sharp)\n                }\n\n            # Wrap the data as TensorFlow Features.\n            feature = tf.train.Features(feature=data)\n\n            # Wrap again as a TensorFlow Example.\n            example = tf.train.Example(features=feature)\n\n            # Serialize the data.\n            serialized = example.SerializeToString()\n\n            # Write the serialized data to the TFRecords file.\n            writer.write(serialized)\nabout the tf-record:\n\nsize: 6 GB\n3000 images\npreprocessed:\n\nRGB values between: 0 and 1\ntype: float32\n\n\n\nStep 2: Load TF-records (parser)\ndef parse(serialized):\n    # Define a dict with the data-names and types we expect to\n    # find in the TFRecords file.\n    # It is a bit awkward that this needs to be specified again,\n    # because it could have been written in the header of the\n    # TFRecords file instead.\n    features = \\\n        {\n            'x': tf.FixedLenFeature([], tf.string)\n        }\n\n    # Parse the serialized data so we get a dict with our data.\n    parsed_example = tf.parse_single_example(serialized=serialized,\n                                             features=features)\n\n\n    # Decode the raw bytes so it becomes a tensor with type.\n    image_x = tf.decode_raw(parsed_example['x'], tf.float32)\n\n    # The type is now uint8 but we need it to be float.\n    #image_x = tf.cast(image_x, tf.float32)\n\n    return image_x\nStep 2+1: Load TF-records (for real)\ndef input_fn(filenames, train, batch_size=32, buffer_size=2048):\n    # Args:\n    # filenames:   Filenames for the TFRecords files.\n    # train:       Boolean whether training (True) or testing (False).\n    # batch_size:  Return batches of this size.\n    # buffer_size: Read buffers of this size. The random shuffling\n    #              is done on the buffer, so it must be big enough.\n\n    # Create a TensorFlow Dataset-object which has functionality\n    # for reading and shuffling data from TFRecords files.\n    dataset = tf.data.TFRecordDataset(filenames=filenames)\n\n    # Parse the serialized data in the TFRecords files.\n    # This returns TensorFlow tensors for the image and labels.\n    dataset = dataset.map(parse)\n\n    if train:\n        # If training then read a buffer of the given size and\n        # randomly shuffle it.\n        dataset = dataset.shuffle(buffer_size=buffer_size)\n\n        # Allow infinite reading of the data.\n        num_repeat = None\n    else:\n        # If testing then don't shuffle the data.\n\n        # Only go through the data once.\n        num_repeat = 1\n\n    # Repeat the dataset the given number of times.\n    dataset = dataset.repeat(num_repeat)\n\n    # Get a batch of data with the given size.\n    dataset = dataset.batch(batch_size)\n\n    # Create an iterator for the dataset and the above modifications.\n    iterator = dataset.make_one_shot_iterator()\n\n    # Get the next batch of images and labels.\n    images_batch = iterator.get_next()\n\n    # The input-function must return a dict wrapping the images.\n    x = {'image': images_batch}\n\n    return x\nBut but but but\nalthough, I think that the above set-up is quite clear, as soon as I get rid of the mnist dataset (32x32 images), I receive memory issues. (can't even perform a batch-size of 2)\n\nAlso when I'm trying to solve this and watch/read the tensorflow summit videos (2018), I even wonder if I'm doing it correctly at the first place :s\n\nFor example:\n\n\n\nFirst of all, how to deal with memory issues? I really can understand that I've a memory issue, when TF tries to store, the whole tf-record 6-7gig in its memory (video-card memory)? but I also would think that it is smarter then that ... (doesn't it work like a generator? add only x values in memory + their location)\n1.1 I really would like to keep the tf-records because they promises us that it is faster then e.g. the placeholders (actually it is also easier to use)\n\n\nIn the image, you see at the beginning: Dataset.list_files the question which I've with this is. Is this just 1 file, or does this mean that each image which I've is a new tf.record? (do I've) to create 3000 tf records?)(and is this the reason why I might have memory issues?)\n\n\nThe image returns a dataset and not a iterator (like in my piece of code), any clue where they might do it (this is necessary right?), when they are using the tf-estimator api?\n\n\nAnd that is basically it.\nunderlying question is: How can I work & play with Tensorflow|tf-records|tf-estimator on BIG images. (even bigger than 720p)\nextra info:\n(https://www.youtube.com/watch?v=SxOsJPaxHME https://www.tensorflow.org/versions/master/performance/datasets_performance)", "body": "Best,\r\n\r\n# system properties:\r\n\r\n- windows 10\r\n- intel core i7-6820HQ CPU | 2.70GHZ 8CPUs\r\n- 16GB ram\r\n- 64bit \r\n- NVIDIA Quadro M1000M\r\n   - approx. total memory: 10093 MB\r\n   - Display memory (VRAM): 2019 MB\r\n   - Shared Memory: 8073 MB\r\n \r\n- Tensorflow 1.8\r\n- Python 3.5.2\r\n \r\n- images (i've 36k images):\r\n   - train: 3000 x (720x1280x3)\r\n   - valid: 500 x (720x1280x3)\r\n   - test : 500 x (720x1280x3)\r\n\r\n \r\n### My story & strugles\r\nFirst of all, I would like to say that I really like machine learning, specially neural networks. But most of the time, when I'm working with Tensorflow, I've the feeling that it is backstabbing me the entirely time. (like for example, the speed of those releases... (1.8 :O )) & Sometimes I even don't know any more if I'm doing it right or wrong? (Or can I do it better?)\r\n\r\nTherefore, my main question is: **How do you create a proper input pipeline!**\r\npreferable with tensorflow gpu\r\n\r\nBecause come one, it should be easy as $*%\u20ack no? Especially, **can't you cover 90% of all the input pipelines into 1, 2 or 3 template pipelines?** (I think it is +/- possible, (a giant image with a cat is still an image | matrix))\r\nand if it is possible, why can't we have an optimized template/base for it?\r\n\r\n\r\nas you would have noticed, I've provided my system properties and info about the data which I'm using. My goals are:\r\n\r\n - Create a GAN-network (GPU)(doesn't have to be a gan for this question)\r\n - Use the TF-estimator api (with custom features)\r\n - Use TF-records !\r\n - Use TF-dataset !\r\n\r\nBut Unfortunately, most of the time, I'll receive errors like for example that I'm out of memory :'(\r\nAnd the more I look things up, the more I start to hesitate...\r\n\r\n\r\n## Step 1: create TF-records\r\nIn my first step, I create a tf-record (train). And as you can see, I loop over the images (from a certain folder) and write all the data into 1 tf-record.\r\n```python \r\n# Helper-function for wrapping an integer so it can be saved to the TFRecords file\r\ndef wrap_int64(value):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n\r\n# Helper-function for wrapping raw bytes so they can be saved to the TFRecords file.\r\n\r\ndef wrap_bytes(value):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\n\r\n#from skimage.transform import rescale, resize, downscale_local_mean\r\n\r\ndef convert(image_paths, out_path):\r\n    # Args:\r\n    # image_paths   List of file-paths for the images.\r\n    # labels        Class-labels for the images.\r\n    # out_path      File-path for the TFRecords output file.\r\n\r\n    print(\"Converting: \" + out_path)\r\n\r\n    # Number of images. Used when printing the progress.\r\n    num_images = len(image_paths)\r\n\r\n    # Open a TFRecordWriter for the output-file.\r\n    with tf.python_io.TFRecordWriter(out_path) as writer:\r\n\r\n        # Iterate over all the image-paths and class-labels.\r\n        for i, path in enumerate(image_paths):\r\n\r\n            # Print the percentage-progress.\r\n            print_progress(count=i+1, total=num_images)\r\n\r\n            # Load the image-file using matplotlib's imread function.\r\n            img_bytes_sharp = load_images(path)\r\n\r\n            # Convert the image to raw bytes.\r\n            img_bytes_sharp = tf.compat.as_bytes(img_bytes_sharp.tostring())\r\n\r\n            # Create a dict with the data we want to save in the\r\n            # TFRecords file. You can add more relevant data here.\r\n            data = \\\r\n                {\r\n                    'x': wrap_bytes(img_bytes_sharp)\r\n                }\r\n\r\n            # Wrap the data as TensorFlow Features.\r\n            feature = tf.train.Features(feature=data)\r\n\r\n            # Wrap again as a TensorFlow Example.\r\n            example = tf.train.Example(features=feature)\r\n\r\n            # Serialize the data.\r\n            serialized = example.SerializeToString()\r\n\r\n            # Write the serialized data to the TFRecords file.\r\n            writer.write(serialized)\r\n```\r\n\r\nabout the tf-record:\r\n- size: 6 GB\r\n- 3000 images\r\n- preprocessed:\r\n   - RGB values between: 0 and 1\r\n    - type: float32\r\n\r\n\r\n\r\n## Step 2: Load TF-records (parser)\r\n\r\n```python\r\ndef parse(serialized):\r\n    # Define a dict with the data-names and types we expect to\r\n    # find in the TFRecords file.\r\n    # It is a bit awkward that this needs to be specified again,\r\n    # because it could have been written in the header of the\r\n    # TFRecords file instead.\r\n    features = \\\r\n        {\r\n            'x': tf.FixedLenFeature([], tf.string)\r\n        }\r\n\r\n    # Parse the serialized data so we get a dict with our data.\r\n    parsed_example = tf.parse_single_example(serialized=serialized,\r\n                                             features=features)\r\n\r\n\r\n    # Decode the raw bytes so it becomes a tensor with type.\r\n    image_x = tf.decode_raw(parsed_example['x'], tf.float32)\r\n\r\n    # The type is now uint8 but we need it to be float.\r\n    #image_x = tf.cast(image_x, tf.float32)\r\n\r\n    return image_x\r\n```\r\n\r\n\r\n\r\n## Step 2+1: Load TF-records (for real)\r\n```python\r\ndef input_fn(filenames, train, batch_size=32, buffer_size=2048):\r\n    # Args:\r\n    # filenames:   Filenames for the TFRecords files.\r\n    # train:       Boolean whether training (True) or testing (False).\r\n    # batch_size:  Return batches of this size.\r\n    # buffer_size: Read buffers of this size. The random shuffling\r\n    #              is done on the buffer, so it must be big enough.\r\n\r\n    # Create a TensorFlow Dataset-object which has functionality\r\n    # for reading and shuffling data from TFRecords files.\r\n    dataset = tf.data.TFRecordDataset(filenames=filenames)\r\n\r\n    # Parse the serialized data in the TFRecords files.\r\n    # This returns TensorFlow tensors for the image and labels.\r\n    dataset = dataset.map(parse)\r\n\r\n    if train:\r\n        # If training then read a buffer of the given size and\r\n        # randomly shuffle it.\r\n        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n\r\n        # Allow infinite reading of the data.\r\n        num_repeat = None\r\n    else:\r\n        # If testing then don't shuffle the data.\r\n\r\n        # Only go through the data once.\r\n        num_repeat = 1\r\n\r\n    # Repeat the dataset the given number of times.\r\n    dataset = dataset.repeat(num_repeat)\r\n\r\n    # Get a batch of data with the given size.\r\n    dataset = dataset.batch(batch_size)\r\n\r\n    # Create an iterator for the dataset and the above modifications.\r\n    iterator = dataset.make_one_shot_iterator()\r\n\r\n    # Get the next batch of images and labels.\r\n    images_batch = iterator.get_next()\r\n\r\n    # The input-function must return a dict wrapping the images.\r\n    x = {'image': images_batch}\r\n\r\n    return x\r\n```\r\n\r\n\r\n\r\n# But but but but\r\nalthough, I think that the above set-up is quite clear, as soon as I get rid of the mnist dataset (32x32 images), I receive memory issues. (can't even perform a batch-size of 2)\r\n+ Also when I'm trying to solve this and watch/read the tensorflow summit videos (2018), I even wonder if I'm doing it correctly at the first place :s\r\n\r\nFor example:  \r\n![alt image from ppt summet](https://i.stack.imgur.com/OdHI0.png \"code\")\r\n\r\n\r\n1. First of all, how to deal with memory issues? I really can understand that I've a memory issue, when TF tries to store, the whole tf-record 6-7gig in its memory (video-card memory)? but I also would think that it is smarter then that ... (doesn't it work like a generator? add only x values in memory + their location)\r\n    1.1 I really would like to keep the tf-records because they promises us that it is faster then e.g. the placeholders (actually it is also easier to use)\r\n\r\n2. In the image, you see at the beginning: `Dataset.list_files` the question which I've with this is. Is this just 1 file, or does this mean that each image which I've is a **new** tf.record? (do I've) to create 3000 tf records?)(and is this the reason why I might have memory issues?)\r\n\r\n3. The image returns a dataset and not a iterator (like in my piece of code), any clue where they might do it (this is necessary right?), when they are using the tf-estimator api?\r\n\r\n\r\n\r\n\r\nAnd that is basically it.\r\n**underlying question i**s: How can I work & play with Tensorflow|tf-records|tf-estimator **on** _BIG_ images. (even bigger than 720p)\r\n\r\n\r\n_extra info:_\r\n(https://www.youtube.com/watch?v=SxOsJPaxHME https://www.tensorflow.org/versions/master/performance/datasets_performance)\r\n"}