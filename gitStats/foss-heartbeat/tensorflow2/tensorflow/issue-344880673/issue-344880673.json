{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21166", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21166/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21166/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21166/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21166", "id": 344880673, "node_id": "MDU6SXNzdWUzNDQ4ODA2NzM=", "number": 21166, "title": "Numpy with Tensorflow Eager as backend?", "user": {"login": "Hoeze", "id": 1200058, "node_id": "MDQ6VXNlcjEyMDAwNTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1200058?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hoeze", "html_url": "https://github.com/Hoeze", "followers_url": "https://api.github.com/users/Hoeze/followers", "following_url": "https://api.github.com/users/Hoeze/following{/other_user}", "gists_url": "https://api.github.com/users/Hoeze/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hoeze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hoeze/subscriptions", "organizations_url": "https://api.github.com/users/Hoeze/orgs", "repos_url": "https://api.github.com/users/Hoeze/repos", "events_url": "https://api.github.com/users/Hoeze/events{/privacy}", "received_events_url": "https://api.github.com/users/Hoeze/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-26T14:57:13Z", "updated_at": "2018-09-15T18:50:21Z", "closed_at": "2018-09-15T18:30:29Z", "author_association": "NONE", "body_html": "<p>It would be really cool if the eager execution would not be exclusive in one session.</p>\n<p>If we could use default and eager execution in parallel, it would be possible to use Tensorflow Eager Execution as backend to numpy.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: None</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: None</li>\n<li><strong>TensorFlow version (use command below)</strong>: None</li>\n<li><strong>Python version</strong>: 3.6.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: None</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: None</li>\n<li><strong>CUDA/cuDNN version</strong>: None</li>\n<li><strong>GPU model and memory</strong>: None</li>\n<li><strong>Exact command to reproduce</strong>: None</li>\n</ul>", "body_text": "It would be really cool if the eager execution would not be exclusive in one session.\nIf we could use default and eager execution in parallel, it would be possible to use Tensorflow Eager Execution as backend to numpy.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): None\nTensorFlow installed from (source or binary): None\nTensorFlow version (use command below): None\nPython version: 3.6.6\nBazel version (if compiling from source): None\nGCC/Compiler version (if compiling from source): None\nCUDA/cuDNN version: None\nGPU model and memory: None\nExact command to reproduce: None", "body": "It would be really cool if the eager execution would not be exclusive in one session.\r\n\r\nIf we could use default and eager execution in parallel, it would be possible to use Tensorflow Eager Execution as backend to numpy.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: None\r\n- **TensorFlow installed from (source or binary)**: None\r\n- **TensorFlow version (use command below)**: None\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: None\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: None\r\n"}