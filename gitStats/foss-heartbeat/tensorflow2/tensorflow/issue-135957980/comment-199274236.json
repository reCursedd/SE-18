{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/199274236", "html_url": "https://github.com/tensorflow/tensorflow/issues/1269#issuecomment-199274236", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1269", "id": 199274236, "node_id": "MDEyOklzc3VlQ29tbWVudDE5OTI3NDIzNg==", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-21T13:22:54Z", "updated_at": "2016-03-21T13:22:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4500138\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/islamoc\">@islamoc</a> Hi, I did the following (you'll find some steps you already did, so ignore them :) )</p>\n<ul>\n<li>Get the latest tensorflow from git hub and build it using bazel.</li>\n<li>Find the coded_stream.h in the google/protobuf section of your tensorflow build and modify the 64 to 256 in the following line:</li>\n</ul>\n<p><code>static const int kDefaultTotalBytesLimit = 64 &lt;&lt; 20;  // Change the 64 to 256 MB</code></p>\n<ul>\n<li>Rebuild the tensorflow</li>\n<li>Download the newer inception model from <a href=\"https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\" rel=\"nofollow\">https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip</a></li>\n</ul>\n<p>Note: The .pb file in the zip is the same as the classify_image_graph_def used in some other example. Only the name is different. It is the same name as in the original android demo but you will notice the filesize is bigger, reflecting that it is the newer model. Also you'll find in the zip file that the label file is different than the imagenet_synset_to_human_label_map.txt. It is because of the way the android demo is reading the labels vs how the the label_image example is reading them. So don't use the imagenet_synset_to_human_label_map in the android demo.</p>\n<ul>\n<li>Modify only the input_size to 299 and the image_mean to 128 in the TensorflowImageListener.java</li>\n<li>Go to tensorflow_jni.cc in the android demo and modify as follows:</li>\n</ul>\n<pre><code>\n      input_tensor_mapped(0, i, j, 0) =\n          (static_cast&lt;float&gt;(src-&gt;red) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 1) =\n          (static_cast&lt;float&gt;(src-&gt;green) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 2) =\n          (static_cast&lt;float&gt;(src-&gt;blue) - g_image_mean)/g_image_mean;\n      ++src;\n\nstd::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; input_tensors(\n      {{\"Mul\", input_tensor}});\n\nstd::vector&lt;std::string&gt; output_names({\"softmax\"});\n</code></pre>\n<ul>\n<li>Build the android demo</li>\n</ul>\n<p>This should let you use the android demo with the newest inception model. If you want to use a retrained model. Just change the model name and label in the android demo and change the output_names({\"softmax\"}) to output_names({\"final_result\"})</p>", "body_text": "@islamoc Hi, I did the following (you'll find some steps you already did, so ignore them :) )\n\nGet the latest tensorflow from git hub and build it using bazel.\nFind the coded_stream.h in the google/protobuf section of your tensorflow build and modify the 64 to 256 in the following line:\n\nstatic const int kDefaultTotalBytesLimit = 64 << 20;  // Change the 64 to 256 MB\n\nRebuild the tensorflow\nDownload the newer inception model from https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\n\nNote: The .pb file in the zip is the same as the classify_image_graph_def used in some other example. Only the name is different. It is the same name as in the original android demo but you will notice the filesize is bigger, reflecting that it is the newer model. Also you'll find in the zip file that the label file is different than the imagenet_synset_to_human_label_map.txt. It is because of the way the android demo is reading the labels vs how the the label_image example is reading them. So don't use the imagenet_synset_to_human_label_map in the android demo.\n\nModify only the input_size to 299 and the image_mean to 128 in the TensorflowImageListener.java\nGo to tensorflow_jni.cc in the android demo and modify as follows:\n\n\n      input_tensor_mapped(0, i, j, 0) =\n          (static_cast<float>(src->red) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 1) =\n          (static_cast<float>(src->green) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 2) =\n          (static_cast<float>(src->blue) - g_image_mean)/g_image_mean;\n      ++src;\n\nstd::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors(\n      {{\"Mul\", input_tensor}});\n\nstd::vector<std::string> output_names({\"softmax\"});\n\n\nBuild the android demo\n\nThis should let you use the android demo with the newest inception model. If you want to use a retrained model. Just change the model name and label in the android demo and change the output_names({\"softmax\"}) to output_names({\"final_result\"})", "body": "@islamoc Hi, I did the following (you'll find some steps you already did, so ignore them :) )\n- Get the latest tensorflow from git hub and build it using bazel.\n- Find the coded_stream.h in the google/protobuf section of your tensorflow build and modify the 64 to 256 in the following line:\n\n`static const int kDefaultTotalBytesLimit = 64 << 20;  // Change the 64 to 256 MB`\n- Rebuild the tensorflow\n- Download the newer inception model from https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\n\nNote: The .pb file in the zip is the same as the classify_image_graph_def used in some other example. Only the name is different. It is the same name as in the original android demo but you will notice the filesize is bigger, reflecting that it is the newer model. Also you'll find in the zip file that the label file is different than the imagenet_synset_to_human_label_map.txt. It is because of the way the android demo is reading the labels vs how the the label_image example is reading them. So don't use the imagenet_synset_to_human_label_map in the android demo.\n- Modify only the input_size to 299 and the image_mean to 128 in the TensorflowImageListener.java\n- Go to tensorflow_jni.cc in the android demo and modify as follows:\n\n```\n\n      input_tensor_mapped(0, i, j, 0) =\n          (static_cast<float>(src->red) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 1) =\n          (static_cast<float>(src->green) - g_image_mean)/g_image_mean;\n      input_tensor_mapped(0, i, j, 2) =\n          (static_cast<float>(src->blue) - g_image_mean)/g_image_mean;\n      ++src;\n\nstd::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors(\n      {{\"Mul\", input_tensor}});\n\nstd::vector<std::string> output_names({\"softmax\"});\n```\n- Build the android demo\n\nThis should let you use the android demo with the newest inception model. If you want to use a retrained model. Just change the model name and label in the android demo and change the output_names({\"softmax\"}) to output_names({\"final_result\"})\n"}