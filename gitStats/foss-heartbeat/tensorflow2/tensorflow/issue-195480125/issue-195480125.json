{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6305", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6305/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6305/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6305/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6305", "id": 195480125, "node_id": "MDU6SXNzdWUxOTU0ODAxMjU=", "number": 6305, "title": "RNN Variables mistakenly (?) placed on GPU when doing multi tower training. ", "user": {"login": "talolard", "id": 5352830, "node_id": "MDQ6VXNlcjUzNTI4MzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5352830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/talolard", "html_url": "https://github.com/talolard", "followers_url": "https://api.github.com/users/talolard/followers", "following_url": "https://api.github.com/users/talolard/following{/other_user}", "gists_url": "https://api.github.com/users/talolard/gists{/gist_id}", "starred_url": "https://api.github.com/users/talolard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/talolard/subscriptions", "organizations_url": "https://api.github.com/users/talolard/orgs", "repos_url": "https://api.github.com/users/talolard/repos", "events_url": "https://api.github.com/users/talolard/events{/privacy}", "received_events_url": "https://api.github.com/users/talolard/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-12-14T09:27:12Z", "updated_at": "2016-12-29T20:00:30Z", "closed_at": "2016-12-29T20:00:30Z", "author_association": "NONE", "body_html": "<p>I'm trying to do \"data parallelism\" following the cifar-10 multi gpu example. Main difference is that I am using tensorflow's rnn abstractions. When I run the code ( <a href=\"https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz\">mgf.tar.gz</a> ) on a CPU machine it works but when I run it on a machine with 1-4 gpus it crashes, reporting that some of the GRU/LSTm variables have not been initialized (on the gpu).</p>\n<pre><code>Traceback (most recent call last):\n  File \"trainMultiGPU.py\", line 211, in &lt;module&gt;\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"trainMultiGPU.py\", line 207, in main\n    train(args)\n  File \"trainMultiGPU.py\", line 171, in train\n    sess.run(init)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\n\n\n\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value RNN/GRUCell/Gates/Linear/Matrix\n         [[Node: RNN/GRUCell/Gates/Linear/Matrix/_52 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_149_RNN/GRUCell/Gates/Linear/Matrix\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/GRUCell/Gates/Linear/Matrix)]]\n         [[Node: init/NoOp_1/_62 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_164_init/NoOp_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]`**\n\n</code></pre>\n<p>I've tried this both with the vanilla and dynamic variations of the rnn functions and with LSTM as well as GRU.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138655648\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1390\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1390/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1390\">#1390</a></p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nRHEL 7.2</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<blockquote>\n<p>[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ ls -l /usr/local/cuda/lib64/libcud*<br>\n-rw-r--r--. 1 root root   558720 Dec  6 10:55 /usr/local/cuda/lib64/libcudadevrt.a<br>\nlrwxrwxrwx. 1 root root       16 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0<br>\nlrwxrwxrwx. 1 root root       19 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44<br>\n-rwxr-xr-x. 1 root root   415432 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0.44<br>\n-rw-r--r--. 1 root root   775162 Dec  6 10:55 /usr/local/cuda/lib64/libcudart_static.a<br>\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so<br>\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5<br>\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5.1.5<br>\n-rw-r--r--. 1 root root 69756172 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn_static.a</p>\n</blockquote>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:<br>\nexport TF_BINARY_URL=<a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc1-cp27-none-linux_x86_64.whl</a></li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ python -c \"import tensorflow;</li>\n</ol>\n<blockquote>\n<p>print(tensorflow.<strong>version</strong>)\"<br>\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally<br>\n0.12.0-rc1</p>\n</blockquote>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>I've attached a tar with a minimal reproducing example. Unfortunately I am behind a corporate proxy and can't push to github.<br>\n[<a href=\"https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz\">mgf.tar.gz - reproducible example </a><br>\nTo recreate the example simply run</p>\n<blockquote>\n<p>python trainMultiGPU.py<br>\nIt should work fine on a CPU only machine. On a machine with gpus you should see the above traceback.</p>\n</blockquote>\n<h3>What other attempted solutions have you tried?</h3>\n<ul>\n<li>I've tried variants of rnn (dynamic, regular, bidirectional)</li>\n<li>I've tried LSTMCell and GRUCell</li>\n<li>I've tried passing the scope explicitly to the call to rnn</li>\n<li>I've tried wrapping the call to rnn with a device placement on the cpu. This prevents the traceback but I think it places the OP on the cpu as well as processing becomes incredibly slow.</li>\n</ul>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/651206/device_placements.txt\">device_placements.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/651207/nvidia-smi.out.txt\">nvidia-smi.out.txt</a><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/651208/TRACEBACK.txt\">TRACEBACK.txt</a></p>", "body_text": "I'm trying to do \"data parallelism\" following the cifar-10 multi gpu example. Main difference is that I am using tensorflow's rnn abstractions. When I run the code ( mgf.tar.gz ) on a CPU machine it works but when I run it on a machine with 1-4 gpus it crashes, reporting that some of the GRU/LSTm variables have not been initialized (on the gpu).\nTraceback (most recent call last):\n  File \"trainMultiGPU.py\", line 211, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"trainMultiGPU.py\", line 207, in main\n    train(args)\n  File \"trainMultiGPU.py\", line 171, in train\n    sess.run(init)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\n\n\n\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value RNN/GRUCell/Gates/Linear/Matrix\n         [[Node: RNN/GRUCell/Gates/Linear/Matrix/_52 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_149_RNN/GRUCell/Gates/Linear/Matrix\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/GRUCell/Gates/Linear/Matrix)]]\n         [[Node: init/NoOp_1/_62 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_164_init/NoOp_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]`**\n\n\nI've tried this both with the vanilla and dynamic variations of the rnn functions and with LSTM as well as GRU.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nIssue #1390\nEnvironment info\nOperating System:\nRHEL 7.2\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n\n[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r--. 1 root root   558720 Dec  6 10:55 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx. 1 root root       16 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx. 1 root root       19 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x. 1 root root   415432 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r--. 1 root root   775162 Dec  6 10:55 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r--. 1 root root 69756172 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc1-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ python -c \"import tensorflow;\n\n\nprint(tensorflow.version)\"\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\n0.12.0-rc1\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nI've attached a tar with a minimal reproducing example. Unfortunately I am behind a corporate proxy and can't push to github.\n[mgf.tar.gz - reproducible example \nTo recreate the example simply run\n\npython trainMultiGPU.py\nIt should work fine on a CPU only machine. On a machine with gpus you should see the above traceback.\n\nWhat other attempted solutions have you tried?\n\nI've tried variants of rnn (dynamic, regular, bidirectional)\nI've tried LSTMCell and GRUCell\nI've tried passing the scope explicitly to the call to rnn\nI've tried wrapping the call to rnn with a device placement on the cpu. This prevents the traceback but I think it places the OP on the cpu as well as processing becomes incredibly slow.\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\ndevice_placements.txt\nnvidia-smi.out.txt\nTRACEBACK.txt", "body": "I'm trying to do \"data parallelism\" following the cifar-10 multi gpu example. Main difference is that I am using tensorflow's rnn abstractions. When I run the code ( [mgf.tar.gz](https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz) ) on a CPU machine it works but when I run it on a machine with 1-4 gpus it crashes, reporting that some of the GRU/LSTm variables have not been initialized (on the gpu). \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"trainMultiGPU.py\", line 211, in <module>\r\n    tf.app.run()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"trainMultiGPU.py\", line 207, in main\r\n    train(args)\r\n  File \"trainMultiGPU.py\", line 171, in train\r\n    sess.run(init)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\n\r\n\r\n\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value RNN/GRUCell/Gates/Linear/Matrix\r\n         [[Node: RNN/GRUCell/Gates/Linear/Matrix/_52 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_149_RNN/GRUCell/Gates/Linear/Matrix\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/GRUCell/Gates/Linear/Matrix)]]\r\n         [[Node: init/NoOp_1/_62 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_164_init/NoOp_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]`**\r\n\r\n```\r\nI've tried this both with the vanilla and dynamic variations of the rnn functions and with LSTM as well as GRU. \r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nIssue #1390  \r\n\r\n\r\n### Environment info\r\nOperating System:\r\nRHEL 7.2\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n> [tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ ls -l /usr/local/cuda/lib64/libcud*\r\n> -rw-r--r--. 1 root root   558720 Dec  6 10:55 /usr/local/cuda/lib64/libcudadevrt.a\r\n> lrwxrwxrwx. 1 root root       16 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\n> lrwxrwxrwx. 1 root root       19 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n> -rwxr-xr-x. 1 root root   415432 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n> -rw-r--r--. 1 root root   775162 Dec  6 10:55 /usr/local/cuda/lib64/libcudart_static.a\r\n> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so\r\n> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5\r\n> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n> -rw-r--r--. 1 root root 69756172 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn_static.a\r\n> \r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc1-cp27-none-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ python -c \"import tensorflow; \r\n\r\n> print(tensorflow.__version__)\"\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n> 0.12.0-rc1\r\n> \r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI've attached a tar with a minimal reproducing example. Unfortunately I am behind a corporate proxy and can't push to github. \r\n[[mgf.tar.gz - reproducible example ](https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz)\r\nTo recreate the example simply run \r\n\r\n> python trainMultiGPU.py\r\nIt should work fine on a CPU only machine. On a machine with gpus you should see the above traceback. \r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n- I've tried variants of rnn (dynamic, regular, bidirectional)\r\n- I've tried LSTMCell and GRUCell\r\n- I've tried passing the scope explicitly to the call to rnn\r\n- I've tried wrapping the call to rnn with a device placement on the cpu. This prevents the traceback but I think it places the OP on the cpu as well as processing becomes incredibly slow. \r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n[device_placements.txt](https://github.com/tensorflow/tensorflow/files/651206/device_placements.txt)\r\n[nvidia-smi.out.txt](https://github.com/tensorflow/tensorflow/files/651207/nvidia-smi.out.txt)\r\n[TRACEBACK.txt](https://github.com/tensorflow/tensorflow/files/651208/TRACEBACK.txt)\r\n\r\n\r\n\r\n\r\n"}