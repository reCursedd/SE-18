{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402343099", "html_url": "https://github.com/tensorflow/tensorflow/pull/16476#issuecomment-402343099", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16476", "id": 402343099, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjM0MzA5OQ==", "user": {"login": "WenguoLi", "id": 31765154, "node_id": "MDQ6VXNlcjMxNzY1MTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/31765154?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WenguoLi", "html_url": "https://github.com/WenguoLi", "followers_url": "https://api.github.com/users/WenguoLi/followers", "following_url": "https://api.github.com/users/WenguoLi/following{/other_user}", "gists_url": "https://api.github.com/users/WenguoLi/gists{/gist_id}", "starred_url": "https://api.github.com/users/WenguoLi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WenguoLi/subscriptions", "organizations_url": "https://api.github.com/users/WenguoLi/orgs", "repos_url": "https://api.github.com/users/WenguoLi/repos", "events_url": "https://api.github.com/users/WenguoLi/events{/privacy}", "received_events_url": "https://api.github.com/users/WenguoLi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-04T02:16:36Z", "updated_at": "2018-07-04T02:24:47Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3480703\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mohamedadaly\">@mohamedadaly</a> , After adding SSD Postprocessing ops,  how to convert mobilenet-ssd .pb model to tflite model ?</p>\n<p>like this ?<br>\nbazel run --config=opt <br>\n//tensorflow/contrib/lite/toco:toco -- <br>\n--input_file=${MODEL_PATH}/frozen_inference_graph_stripped.pb <br>\n--output_file=${MODEL_PATH}/ssd_mobilenet_v1_float.tflite <br>\n--input_format=TENSORFLOW_GRAPHDEF <br>\n--output_format=TFLITE <br>\n--inference_type=FLOAT <br>\n--input_shapes=1,300,300,3 <br>\n--input_arrays=Preprocessor/sub <br>\n--output_arrays=<strong>detection_boxes,detection_scores,detection_classes,num_detections</strong> <br>\n--dump_graphviz=${MODEL_PATH}<br>\nbut convert failed,  I don't know how you converted the model to use these SSD Postprocessing ops.</p>\n<p>Thanks</p>", "body_text": "@mohamedadaly , After adding SSD Postprocessing ops,  how to convert mobilenet-ssd .pb model to tflite model ?\nlike this ?\nbazel run --config=opt \n//tensorflow/contrib/lite/toco:toco -- \n--input_file=${MODEL_PATH}/frozen_inference_graph_stripped.pb \n--output_file=${MODEL_PATH}/ssd_mobilenet_v1_float.tflite \n--input_format=TENSORFLOW_GRAPHDEF \n--output_format=TFLITE \n--inference_type=FLOAT \n--input_shapes=1,300,300,3 \n--input_arrays=Preprocessor/sub \n--output_arrays=detection_boxes,detection_scores,detection_classes,num_detections \n--dump_graphviz=${MODEL_PATH}\nbut convert failed,  I don't know how you converted the model to use these SSD Postprocessing ops.\nThanks", "body": "@mohamedadaly , After adding SSD Postprocessing ops,  how to convert mobilenet-ssd .pb model to tflite model ?\r\n\r\nlike this ?\r\nbazel run --config=opt \\\r\n  //tensorflow/contrib/lite/toco:toco -- \\\r\n  --input_file=${MODEL_PATH}/frozen_inference_graph_stripped.pb \\\r\n  --output_file=${MODEL_PATH}/ssd_mobilenet_v1_float.tflite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=FLOAT \\\r\n  --input_shapes=1,300,300,3 \\\r\n  --input_arrays=Preprocessor/sub \\\r\n  --output_arrays=**detection_boxes,detection_scores,detection_classes,num_detections** \\\r\n  --dump_graphviz=${MODEL_PATH}\r\nbut convert failed,  I don't know how you converted the model to use these SSD Postprocessing ops.\r\n\r\nThanks\r\n"}