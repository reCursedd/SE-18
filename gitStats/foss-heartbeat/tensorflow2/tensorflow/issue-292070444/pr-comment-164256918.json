{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/164256918", "pull_request_review_id": 92009995, "id": 164256918, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NDI1NjkxOA==", "diff_hunk": "@@ -0,0 +1,1184 @@\n+#include \"tensorflow/contrib/lite/kernels/ssd_ops.h\"\n+\n+#include <chrono>\n+#include <iostream>\n+#include <tuple>\n+#include <vector>\n+\n+#include \"tensorflow/contrib/lite/context.h\"\n+#include \"tensorflow/contrib/lite/kernels/internal/tensor.h\"\n+#include \"tensorflow/contrib/lite/kernels/internal/types.h\"\n+#include \"tensorflow/contrib/lite/kernels/kernel_util.h\"\n+#include \"tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h\"\n+#include \"tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h\"\n+\n+namespace tflite {\n+namespace ops {\n+namespace custom {\n+\n+\n+inline void Exp(const float* input_data, const Dims<4>& input_dims,\n+                float* output_data, const Dims<4>& output_dims) {\n+  // Get sizes\n+  const int batches = MatchingArraySize(input_dims, 3, output_dims, 3);\n+  const int height = MatchingArraySize(input_dims, 2, output_dims, 2);\n+  const int width = MatchingArraySize(input_dims, 1, output_dims, 1);\n+  const int depth = MatchingArraySize(input_dims, 0, output_dims, 0);\n+\n+  // Loop\n+  for (int b = 0; b < batches; ++b) {\n+    for (int y = 0; y < height; ++y) {\n+      for (int x = 0; x < width; ++x) {\n+        for (int c = 0; c < depth; ++c) {\n+          // Get offsets\n+          int input_offset = Offset(input_dims, c, x, y, b);\n+          int output_offset = Offset(output_dims, c, x, y, b);\n+\n+          // Compute exp\n+          output_data[output_offset] = std::exp(input_data[input_offset]);", "path": "tensorflow/contrib/lite/kernels/ssd_ops.cc", "position": 117, "original_position": 38, "commit_id": "4d41db9a1a2a90fca40c4229b57252db9a5124a8", "original_commit_id": "e1e202e3ade733b4f22df82395dbc95dde00c5e3", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "Perhaps a naive question, but why do you write inefficient code like this when we have SIMD vectorized kernels for the same ops in TensorFlow (based on Eigen)?", "created_at": "2018-01-27T01:16:36Z", "updated_at": "2018-01-31T23:12:06Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/16476#discussion_r164256918", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16476", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/164256918"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/16476#discussion_r164256918"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/16476"}}, "body_html": "<p>Perhaps a naive question, but why do you write inefficient code like this when we have SIMD vectorized kernels for the same ops in TensorFlow (based on Eigen)?</p>", "body_text": "Perhaps a naive question, but why do you write inefficient code like this when we have SIMD vectorized kernels for the same ops in TensorFlow (based on Eigen)?"}