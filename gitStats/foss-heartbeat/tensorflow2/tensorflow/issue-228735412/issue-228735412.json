{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9914", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9914/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9914/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9914/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9914", "id": 228735412, "node_id": "MDU6SXNzdWUyMjg3MzU0MTI=", "number": 9914, "title": "Optimizing valid TensorFlow graph yields \"graph_def is invalid\" ValueError", "user": {"login": "qtdaniel", "id": 21170884, "node_id": "MDQ6VXNlcjIxMTcwODg0", "avatar_url": "https://avatars2.githubusercontent.com/u/21170884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qtdaniel", "html_url": "https://github.com/qtdaniel", "followers_url": "https://api.github.com/users/qtdaniel/followers", "following_url": "https://api.github.com/users/qtdaniel/following{/other_user}", "gists_url": "https://api.github.com/users/qtdaniel/gists{/gist_id}", "starred_url": "https://api.github.com/users/qtdaniel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qtdaniel/subscriptions", "organizations_url": "https://api.github.com/users/qtdaniel/orgs", "repos_url": "https://api.github.com/users/qtdaniel/repos", "events_url": "https://api.github.com/users/qtdaniel/events{/privacy}", "received_events_url": "https://api.github.com/users/qtdaniel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2017-05-15T14:34:22Z", "updated_at": "2017-06-16T20:53:39Z", "closed_at": "2017-06-16T20:53:39Z", "author_association": "NONE", "body_html": "<p><code>tensorflow.python.tools.optimize_for_inference_lib.optimize_for_inference</code> is producing an invalid graph definition. So far as I can tell this is not user error; optimizing a valid graph definition should produce a valid graph definition, so this appears to be a bug.</p>\n<p>The following code demonstrates the problem. You will need the input graph definition <a href=\"https://github.com/tensorflow/tensorflow/files/1001369/model.txt.gz\">model.txt.gz</a>. Running the code loads the graph definition, verifies it is valid (by importing it and printing the number of nodes) then calls <code>optimize_for_inference</code>. We then attempt to verify the resulting graph definition but get the error</p>\n<pre><code>ValueError: graph_def is invalid at node u'valid/valid_fed/model/rnn/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis': More inputs specified ('valid/valid_fed/model/rnn/rnn/while/Switch:1') than the op expects..\n</code></pre>\n<p>The error originates from</p>\n<pre><code>tensorflow/python/framework/importer.py, line 362, in import_graph_def\n</code></pre>\n<p>The attached model definition has been manually altered to reduce the size of the (frozen) parameters but the same error occurs with the unmodified original. Attempts to reproduce this problem with a simpler graph failed. Simpler graphs can be optimized successfully. I don't know what it is about this graph that causes the failure.</p>\n<pre><code>import gzip\n\nimport tensorflow as tf\nfrom google.protobuf import text_format\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\n\ndef verify(graph_def):\n    with tf.Graph().as_default():\n        tf.import_graph_def(graph_def, name=\"\")\n        print(len(tf.get_default_graph().as_graph_def().node))\n\n\ndef read_graph_def(path):\n    graph_def = tf.GraphDef()\n\n    with gzip.open(path, \"rb\") as input_file:\n        text_format.Merge(input_file.read(), graph_def)\n\n    return graph_def\n\n\ndef optimize(input_graph_def):\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n        input_graph_def, [\"valid/valid_fed/model/input/x\"],\n        [\"valid/valid_fed/model/output/y\"], tf.int32.as_datatype_enum)\n    return output_graph_def\n\n\ndef main():\n    input_graph_def = read_graph_def(\"model.txt.gz\")\n    verify(input_graph_def)\n    output_graph_def = optimize(input_graph_def)\n    verify(output_graph_def)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n<p>Environment details:</p>\n<ul>\n<li>Linux Ubuntu 14.04</li>\n<li>TensorFlow installed from source</li>\n<li>TensorFlow version: ('v1.1.0-0-g1ec6ed5', '1.1.0')</li>\n<li>Bazel version: 0.4.5</li>\n<li>No GPU</li>\n</ul>", "body_text": "tensorflow.python.tools.optimize_for_inference_lib.optimize_for_inference is producing an invalid graph definition. So far as I can tell this is not user error; optimizing a valid graph definition should produce a valid graph definition, so this appears to be a bug.\nThe following code demonstrates the problem. You will need the input graph definition model.txt.gz. Running the code loads the graph definition, verifies it is valid (by importing it and printing the number of nodes) then calls optimize_for_inference. We then attempt to verify the resulting graph definition but get the error\nValueError: graph_def is invalid at node u'valid/valid_fed/model/rnn/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis': More inputs specified ('valid/valid_fed/model/rnn/rnn/while/Switch:1') than the op expects..\n\nThe error originates from\ntensorflow/python/framework/importer.py, line 362, in import_graph_def\n\nThe attached model definition has been manually altered to reduce the size of the (frozen) parameters but the same error occurs with the unmodified original. Attempts to reproduce this problem with a simpler graph failed. Simpler graphs can be optimized successfully. I don't know what it is about this graph that causes the failure.\nimport gzip\n\nimport tensorflow as tf\nfrom google.protobuf import text_format\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\n\ndef verify(graph_def):\n    with tf.Graph().as_default():\n        tf.import_graph_def(graph_def, name=\"\")\n        print(len(tf.get_default_graph().as_graph_def().node))\n\n\ndef read_graph_def(path):\n    graph_def = tf.GraphDef()\n\n    with gzip.open(path, \"rb\") as input_file:\n        text_format.Merge(input_file.read(), graph_def)\n\n    return graph_def\n\n\ndef optimize(input_graph_def):\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n        input_graph_def, [\"valid/valid_fed/model/input/x\"],\n        [\"valid/valid_fed/model/output/y\"], tf.int32.as_datatype_enum)\n    return output_graph_def\n\n\ndef main():\n    input_graph_def = read_graph_def(\"model.txt.gz\")\n    verify(input_graph_def)\n    output_graph_def = optimize(input_graph_def)\n    verify(output_graph_def)\n\n\nif __name__ == \"__main__\":\n    main()\n\nEnvironment details:\n\nLinux Ubuntu 14.04\nTensorFlow installed from source\nTensorFlow version: ('v1.1.0-0-g1ec6ed5', '1.1.0')\nBazel version: 0.4.5\nNo GPU", "body": "`tensorflow.python.tools.optimize_for_inference_lib.optimize_for_inference` is producing an invalid graph definition. So far as I can tell this is not user error; optimizing a valid graph definition should produce a valid graph definition, so this appears to be a bug.\r\n\r\nThe following code demonstrates the problem. You will need the input graph definition [model.txt.gz](https://github.com/tensorflow/tensorflow/files/1001369/model.txt.gz). Running the code loads the graph definition, verifies it is valid (by importing it and printing the number of nodes) then calls `optimize_for_inference`. We then attempt to verify the resulting graph definition but get the error\r\n\r\n    ValueError: graph_def is invalid at node u'valid/valid_fed/model/rnn/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis': More inputs specified ('valid/valid_fed/model/rnn/rnn/while/Switch:1') than the op expects..\r\n\r\nThe error originates from\r\n\r\n    tensorflow/python/framework/importer.py, line 362, in import_graph_def\r\n\r\nThe attached model definition has been manually altered to reduce the size of the (frozen) parameters but the same error occurs with the unmodified original. Attempts to reproduce this problem with a simpler graph failed. Simpler graphs can be optimized successfully. I don't know what it is about this graph that causes the failure.\r\n\r\n    import gzip\r\n    \r\n    import tensorflow as tf\r\n    from google.protobuf import text_format\r\n    from tensorflow.python.tools import optimize_for_inference_lib\r\n    \r\n    \r\n    def verify(graph_def):\r\n        with tf.Graph().as_default():\r\n            tf.import_graph_def(graph_def, name=\"\")\r\n            print(len(tf.get_default_graph().as_graph_def().node))\r\n    \r\n    \r\n    def read_graph_def(path):\r\n        graph_def = tf.GraphDef()\r\n    \r\n        with gzip.open(path, \"rb\") as input_file:\r\n            text_format.Merge(input_file.read(), graph_def)\r\n    \r\n        return graph_def\r\n    \r\n    \r\n    def optimize(input_graph_def):\r\n        output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n            input_graph_def, [\"valid/valid_fed/model/input/x\"],\r\n            [\"valid/valid_fed/model/output/y\"], tf.int32.as_datatype_enum)\r\n        return output_graph_def\r\n    \r\n    \r\n    def main():\r\n        input_graph_def = read_graph_def(\"model.txt.gz\")\r\n        verify(input_graph_def)\r\n        output_graph_def = optimize(input_graph_def)\r\n        verify(output_graph_def)\r\n    \r\n    \r\n    if __name__ == \"__main__\":\r\n        main()\r\n\r\nEnvironment details:\r\n\r\n- Linux Ubuntu 14.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: ('v1.1.0-0-g1ec6ed5', '1.1.0')\r\n- Bazel version: 0.4.5\r\n- No GPU\r\n"}