{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8845", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8845/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8845/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8845/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8845", "id": 218246837, "node_id": "MDU6SXNzdWUyMTgyNDY4Mzc=", "number": 8845, "title": "Tensorboard not showing data on Windows", "user": {"login": "IgorX2", "id": 5511726, "node_id": "MDQ6VXNlcjU1MTE3MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/5511726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IgorX2", "html_url": "https://github.com/IgorX2", "followers_url": "https://api.github.com/users/IgorX2/followers", "following_url": "https://api.github.com/users/IgorX2/following{/other_user}", "gists_url": "https://api.github.com/users/IgorX2/gists{/gist_id}", "starred_url": "https://api.github.com/users/IgorX2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IgorX2/subscriptions", "organizations_url": "https://api.github.com/users/IgorX2/orgs", "repos_url": "https://api.github.com/users/IgorX2/repos", "events_url": "https://api.github.com/users/IgorX2/events{/privacy}", "received_events_url": "https://api.github.com/users/IgorX2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-03-30T16:02:24Z", "updated_at": "2017-04-04T15:39:40Z", "closed_at": "2017-04-04T15:39:39Z", "author_association": "NONE", "body_html": "<p>I have a simple example of a MNIST classifier that works well for the dataset. However, Tensorboard is unable to read the data from the saved logs. I have inspected the data using <code>tensorboard --inspect --logdir...</code> and the files seem to be in order.</p>\n<p>I have tested this and a much simpler model on a different machine, and got the same results. Tensorboard runs and the interface is accessible, but no data is shown (I tested with Google Chrome and Edge).</p>\n<p>The code is as follows:</p>\n<pre><code>from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\nwith tf.name_scope('input'):\n    x = tf.placeholder(tf.float32, shape=[None, 784])\n    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n\ndef variable_summaries(var):\n  with tf.name_scope('summaries'):\n    mean = tf.reduce_mean(var)\n    tf.summary.scalar('mean', mean)\n    with tf.name_scope('stddev'):\n      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n    tf.summary.scalar('stddev', stddev)\n    tf.summary.scalar('max', tf.reduce_max(var))\n    tf.summary.scalar('min', tf.reduce_min(var))\n    tf.summary.histogram('histogram', var)\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1, name='weights')\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape, name='bias')\n  return tf.Variable(initial)\n\ndef conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='conv')\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool')\n\nwith tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    variable_summaries(W_conv1)\n    variable_summaries(b_conv1)\n\n    x_image = tf.reshape(x, [-1, 28, 28, 1], name='reshape')\n    tf.summary.image('image', x_image, 3)\n\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='relu')\n    h_pool1 = max_pool_2x2(h_conv1)\n    variable_summaries(h_conv1)\n    variable_summaries(h_pool1)\n\nwith tf.name_scope('conv2x'):\n    W_conv2x = weight_variable([5, 5, 32, 64])\n    b_conv2x = bias_variable([64])\n    variable_summaries(W_conv2x)\n    variable_summaries(b_conv2x)\n\n    h_conv2x = tf.nn.relu(conv2d(h_pool1, W_conv2x) + b_conv2x, name='relu')\n    h_pool2x = max_pool_2x2(h_conv2x)\n    variable_summaries(h_conv2x)\n    variable_summaries(h_pool2x)\n\nwith tf.name_scope('conv2y'):\n    W_conv2y = weight_variable([3, 3, 32, 64])\n    b_conv2y = bias_variable([64])\n    variable_summaries(W_conv2y)\n    variable_summaries(b_conv2y)\n\n    h_conv2y = tf.nn.relu(conv2d(h_pool1, W_conv2y) + b_conv2y, name='relu')\n    h_pool2y = max_pool_2x2(h_conv2x)\n    variable_summaries(h_conv2y)\n    variable_summaries(h_pool2y)\n\nwith tf.name_scope('concat'):\n    h_pool2 = tf.concat([h_pool2x, h_pool2y], 3)\n    variable_summaries(h_pool2)\n\nwith tf.name_scope('fc1'):\n    W_fc1 = weight_variable([7 * 7 * (64*2), 1024])\n    b_fc1 = bias_variable([1024])\n    variable_summaries(W_fc1)\n    variable_summaries(b_fc1)\n\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * (64*2)])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name='relu')\n    variable_summaries(h_pool2_flat)\n    variable_summaries(h_fc1)\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='dropout')\nvariable_summaries(h_fc1_drop)\n\nwith tf.name_scope('fc2'):\n    W_fc2 = weight_variable([1024, 10])\n    b_fc2 = bias_variable([10])\n    variable_summaries(W_fc2)\n    variable_summaries(b_fc2)\n\n    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n    variable_summaries(y_conv)\n\nlearning_rate = tf.placeholder(tf.float32, shape=[])\ntf.summary.scalar('learning_rate', learning_rate)\n\nwith tf.name_scope('loss'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)\n    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n    variable_summaries(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\ntf.summary.scalar('accuracy', accuracy)\n\nmerged = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter('summaries/train', sess.graph)\ntest_writer = tf.summary.FileWriter('summaries/test', sess.graph)\n\ntf.global_variables_initializer().run()\n\nfor i in range(101):\n  batch = mnist.train.next_batch(100)\n  summary, _, acc = sess.run([merged, train_step, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0.02, keep_prob: 0.5})\n  train_writer.add_summary(summary, i)\n  #train_writer.add_graph(sess.graph, i)\n  print(\"step %d, training accuracy %g\" % (i, acc))\n  if i % 100 == 0:\n    #This is just a test model, the accuracy is not important\n    batch = mnist.test.next_batch(100)\n    summary, acc = sess.run([merged, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0, keep_prob: 1.0})\n    test_writer.add_summary(summary, i)\n    print(\"step %d, test accuracy %g\" % (i, acc))\n\ntrain_writer.close()\ntest_writer.close()\n</code></pre>\n<p>The logs are provided below.<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/883033/summaries.zip\">summaries.zip</a></p>\n<p>System information:<br>\nWindows 10<br>\nCUDA 8.0, cuDNN 5.0<br>\nTensorflow 1.0.1<br>\nPython 3.5 64-bit</p>", "body_text": "I have a simple example of a MNIST classifier that works well for the dataset. However, Tensorboard is unable to read the data from the saved logs. I have inspected the data using tensorboard --inspect --logdir... and the files seem to be in order.\nI have tested this and a much simpler model on a different machine, and got the same results. Tensorboard runs and the interface is accessible, but no data is shown (I tested with Google Chrome and Edge).\nThe code is as follows:\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\nwith tf.name_scope('input'):\n    x = tf.placeholder(tf.float32, shape=[None, 784])\n    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n\ndef variable_summaries(var):\n  with tf.name_scope('summaries'):\n    mean = tf.reduce_mean(var)\n    tf.summary.scalar('mean', mean)\n    with tf.name_scope('stddev'):\n      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n    tf.summary.scalar('stddev', stddev)\n    tf.summary.scalar('max', tf.reduce_max(var))\n    tf.summary.scalar('min', tf.reduce_min(var))\n    tf.summary.histogram('histogram', var)\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1, name='weights')\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape, name='bias')\n  return tf.Variable(initial)\n\ndef conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='conv')\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool')\n\nwith tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    variable_summaries(W_conv1)\n    variable_summaries(b_conv1)\n\n    x_image = tf.reshape(x, [-1, 28, 28, 1], name='reshape')\n    tf.summary.image('image', x_image, 3)\n\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='relu')\n    h_pool1 = max_pool_2x2(h_conv1)\n    variable_summaries(h_conv1)\n    variable_summaries(h_pool1)\n\nwith tf.name_scope('conv2x'):\n    W_conv2x = weight_variable([5, 5, 32, 64])\n    b_conv2x = bias_variable([64])\n    variable_summaries(W_conv2x)\n    variable_summaries(b_conv2x)\n\n    h_conv2x = tf.nn.relu(conv2d(h_pool1, W_conv2x) + b_conv2x, name='relu')\n    h_pool2x = max_pool_2x2(h_conv2x)\n    variable_summaries(h_conv2x)\n    variable_summaries(h_pool2x)\n\nwith tf.name_scope('conv2y'):\n    W_conv2y = weight_variable([3, 3, 32, 64])\n    b_conv2y = bias_variable([64])\n    variable_summaries(W_conv2y)\n    variable_summaries(b_conv2y)\n\n    h_conv2y = tf.nn.relu(conv2d(h_pool1, W_conv2y) + b_conv2y, name='relu')\n    h_pool2y = max_pool_2x2(h_conv2x)\n    variable_summaries(h_conv2y)\n    variable_summaries(h_pool2y)\n\nwith tf.name_scope('concat'):\n    h_pool2 = tf.concat([h_pool2x, h_pool2y], 3)\n    variable_summaries(h_pool2)\n\nwith tf.name_scope('fc1'):\n    W_fc1 = weight_variable([7 * 7 * (64*2), 1024])\n    b_fc1 = bias_variable([1024])\n    variable_summaries(W_fc1)\n    variable_summaries(b_fc1)\n\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * (64*2)])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name='relu')\n    variable_summaries(h_pool2_flat)\n    variable_summaries(h_fc1)\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='dropout')\nvariable_summaries(h_fc1_drop)\n\nwith tf.name_scope('fc2'):\n    W_fc2 = weight_variable([1024, 10])\n    b_fc2 = bias_variable([10])\n    variable_summaries(W_fc2)\n    variable_summaries(b_fc2)\n\n    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n    variable_summaries(y_conv)\n\nlearning_rate = tf.placeholder(tf.float32, shape=[])\ntf.summary.scalar('learning_rate', learning_rate)\n\nwith tf.name_scope('loss'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)\n    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n    variable_summaries(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\ntf.summary.scalar('accuracy', accuracy)\n\nmerged = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter('summaries/train', sess.graph)\ntest_writer = tf.summary.FileWriter('summaries/test', sess.graph)\n\ntf.global_variables_initializer().run()\n\nfor i in range(101):\n  batch = mnist.train.next_batch(100)\n  summary, _, acc = sess.run([merged, train_step, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0.02, keep_prob: 0.5})\n  train_writer.add_summary(summary, i)\n  #train_writer.add_graph(sess.graph, i)\n  print(\"step %d, training accuracy %g\" % (i, acc))\n  if i % 100 == 0:\n    #This is just a test model, the accuracy is not important\n    batch = mnist.test.next_batch(100)\n    summary, acc = sess.run([merged, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0, keep_prob: 1.0})\n    test_writer.add_summary(summary, i)\n    print(\"step %d, test accuracy %g\" % (i, acc))\n\ntrain_writer.close()\ntest_writer.close()\n\nThe logs are provided below.\nsummaries.zip\nSystem information:\nWindows 10\nCUDA 8.0, cuDNN 5.0\nTensorflow 1.0.1\nPython 3.5 64-bit", "body": "I have a simple example of a MNIST classifier that works well for the dataset. However, Tensorboard is unable to read the data from the saved logs. I have inspected the data using `tensorboard --inspect --logdir...` and the files seem to be in order.\r\n\r\nI have tested this and a much simpler model on a different machine, and got the same results. Tensorboard runs and the interface is accessible, but no data is shown (I tested with Google Chrome and Edge).\r\n\r\nThe code is as follows:\r\n```\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\r\n\r\nimport tensorflow as tf\r\nsess = tf.InteractiveSession()\r\n\r\nwith tf.name_scope('input'):\r\n    x = tf.placeholder(tf.float32, shape=[None, 784])\r\n    y_ = tf.placeholder(tf.float32, shape=[None, 10])\r\n\r\ndef variable_summaries(var):\r\n  with tf.name_scope('summaries'):\r\n    mean = tf.reduce_mean(var)\r\n    tf.summary.scalar('mean', mean)\r\n    with tf.name_scope('stddev'):\r\n      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\r\n    tf.summary.scalar('stddev', stddev)\r\n    tf.summary.scalar('max', tf.reduce_max(var))\r\n    tf.summary.scalar('min', tf.reduce_min(var))\r\n    tf.summary.histogram('histogram', var)\r\n\r\ndef weight_variable(shape):\r\n  initial = tf.truncated_normal(shape, stddev=0.1, name='weights')\r\n  return tf.Variable(initial)\r\n\r\ndef bias_variable(shape):\r\n  initial = tf.constant(0.1, shape=shape, name='bias')\r\n  return tf.Variable(initial)\r\n\r\ndef conv2d(x, W):\r\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='conv')\r\n\r\ndef max_pool_2x2(x):\r\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool')\r\n\r\nwith tf.name_scope('conv1'):\r\n    W_conv1 = weight_variable([5, 5, 1, 32])\r\n    b_conv1 = bias_variable([32])\r\n    variable_summaries(W_conv1)\r\n    variable_summaries(b_conv1)\r\n\r\n    x_image = tf.reshape(x, [-1, 28, 28, 1], name='reshape')\r\n    tf.summary.image('image', x_image, 3)\r\n\r\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='relu')\r\n    h_pool1 = max_pool_2x2(h_conv1)\r\n    variable_summaries(h_conv1)\r\n    variable_summaries(h_pool1)\r\n\r\nwith tf.name_scope('conv2x'):\r\n    W_conv2x = weight_variable([5, 5, 32, 64])\r\n    b_conv2x = bias_variable([64])\r\n    variable_summaries(W_conv2x)\r\n    variable_summaries(b_conv2x)\r\n\r\n    h_conv2x = tf.nn.relu(conv2d(h_pool1, W_conv2x) + b_conv2x, name='relu')\r\n    h_pool2x = max_pool_2x2(h_conv2x)\r\n    variable_summaries(h_conv2x)\r\n    variable_summaries(h_pool2x)\r\n\r\nwith tf.name_scope('conv2y'):\r\n    W_conv2y = weight_variable([3, 3, 32, 64])\r\n    b_conv2y = bias_variable([64])\r\n    variable_summaries(W_conv2y)\r\n    variable_summaries(b_conv2y)\r\n\r\n    h_conv2y = tf.nn.relu(conv2d(h_pool1, W_conv2y) + b_conv2y, name='relu')\r\n    h_pool2y = max_pool_2x2(h_conv2x)\r\n    variable_summaries(h_conv2y)\r\n    variable_summaries(h_pool2y)\r\n\r\nwith tf.name_scope('concat'):\r\n    h_pool2 = tf.concat([h_pool2x, h_pool2y], 3)\r\n    variable_summaries(h_pool2)\r\n\r\nwith tf.name_scope('fc1'):\r\n    W_fc1 = weight_variable([7 * 7 * (64*2), 1024])\r\n    b_fc1 = bias_variable([1024])\r\n    variable_summaries(W_fc1)\r\n    variable_summaries(b_fc1)\r\n\r\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * (64*2)])\r\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name='relu')\r\n    variable_summaries(h_pool2_flat)\r\n    variable_summaries(h_fc1)\r\n\r\nkeep_prob = tf.placeholder(tf.float32)\r\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='dropout')\r\nvariable_summaries(h_fc1_drop)\r\n\r\nwith tf.name_scope('fc2'):\r\n    W_fc2 = weight_variable([1024, 10])\r\n    b_fc2 = bias_variable([10])\r\n    variable_summaries(W_fc2)\r\n    variable_summaries(b_fc2)\r\n\r\n    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\r\n    variable_summaries(y_conv)\r\n\r\nlearning_rate = tf.placeholder(tf.float32, shape=[])\r\ntf.summary.scalar('learning_rate', learning_rate)\r\n\r\nwith tf.name_scope('loss'):\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)\r\n    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\r\n    variable_summaries(cross_entropy)\r\n\r\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\r\ntf.summary.scalar('accuracy', accuracy)\r\n\r\nmerged = tf.summary.merge_all()\r\ntrain_writer = tf.summary.FileWriter('summaries/train', sess.graph)\r\ntest_writer = tf.summary.FileWriter('summaries/test', sess.graph)\r\n\r\ntf.global_variables_initializer().run()\r\n\r\nfor i in range(101):\r\n  batch = mnist.train.next_batch(100)\r\n  summary, _, acc = sess.run([merged, train_step, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0.02, keep_prob: 0.5})\r\n  train_writer.add_summary(summary, i)\r\n  #train_writer.add_graph(sess.graph, i)\r\n  print(\"step %d, training accuracy %g\" % (i, acc))\r\n  if i % 100 == 0:\r\n    #This is just a test model, the accuracy is not important\r\n    batch = mnist.test.next_batch(100)\r\n    summary, acc = sess.run([merged, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0, keep_prob: 1.0})\r\n    test_writer.add_summary(summary, i)\r\n    print(\"step %d, test accuracy %g\" % (i, acc))\r\n\r\ntrain_writer.close()\r\ntest_writer.close()\r\n```\r\n\r\nThe logs are provided below.\r\n[summaries.zip](https://github.com/tensorflow/tensorflow/files/883033/summaries.zip)\r\n\r\nSystem information:\r\nWindows 10\r\nCUDA 8.0, cuDNN 5.0\r\nTensorflow 1.0.1\r\nPython 3.5 64-bit\r\n\r\n"}