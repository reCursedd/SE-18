{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11665", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11665/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11665/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11665/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11665", "id": 244643883, "node_id": "MDU6SXNzdWUyNDQ2NDM4ODM=", "number": 11665, "title": "Feature request: add a `local_init_feed_dict` to `tf.train.Scaffold`", "user": {"login": "lsorber", "id": 4543654, "node_id": "MDQ6VXNlcjQ1NDM2NTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4543654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lsorber", "html_url": "https://github.com/lsorber", "followers_url": "https://api.github.com/users/lsorber/followers", "following_url": "https://api.github.com/users/lsorber/following{/other_user}", "gists_url": "https://api.github.com/users/lsorber/gists{/gist_id}", "starred_url": "https://api.github.com/users/lsorber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lsorber/subscriptions", "organizations_url": "https://api.github.com/users/lsorber/orgs", "repos_url": "https://api.github.com/users/lsorber/repos", "events_url": "https://api.github.com/users/lsorber/events{/privacy}", "received_events_url": "https://api.github.com/users/lsorber/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-07-21T11:37:38Z", "updated_at": "2018-02-26T15:22:33Z", "closed_at": "2018-01-23T23:40:32Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.2.0</li>\n<li><strong>Python version</strong>: 3.6.1</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: See below.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Feature request: add a <code>local_init_feed_dict</code> to <code>tf.train.Scaffold</code>. It would be useful to be able to create local variables (which are not saved or restored) and have them initialized by a <code>tf.train.MonitoredTrainingSession</code> with a <code>feed_dict</code>. In the example below, the variable <code>X_var</code> is forced to be part of the <code>GLOBAL_VARIABLES</code> collection in order to be able to initialize the variable with a <code>feed_dict</code>. This has the undesirable consequence that the variable will be saved to disk.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Data that we wish to sample, but not save to disk.</span>\nX <span class=\"pl-k\">=</span> np.eye(<span class=\"pl-c1\">15</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a graph that samples rows from X randomly.</span>\ngraph <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> graph.as_default():\n    X_init <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>X.shape)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Here, we want to use tf.GraphKeys.LOCAL_VARIABLES,</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> but can't because there is no feed_dict for that collection in tf.train.Scaffold.</span>\n    X_var <span class=\"pl-k\">=</span> tf.Variable(X_init, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">collections</span><span class=\"pl-k\">=</span>[tf.GraphKeys.<span class=\"pl-c1\">GLOBAL_VARIABLES</span>])\n    queue <span class=\"pl-k\">=</span> tf.RandomShuffleQueue(\n        <span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span>X.shape[<span class=\"pl-c1\">0</span>],\n        <span class=\"pl-v\">min_after_dequeue</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n        <span class=\"pl-v\">dtypes</span><span class=\"pl-k\">=</span>[tf.float32],\n        <span class=\"pl-v\">shapes</span><span class=\"pl-k\">=</span>[X.shape[<span class=\"pl-c1\">1</span>]])\n    enqueue_op <span class=\"pl-k\">=</span> queue.enqueue_many([X_var])\n    row <span class=\"pl-k\">=</span> queue.dequeue()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Sample a few rows from X.</span>\n<span class=\"pl-k\">with</span> graph.as_default():\n    sess_params <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scaffold<span class=\"pl-pds\">'</span></span>: tf.train.Scaffold(\n            <span class=\"pl-v\">init_feed_dict</span><span class=\"pl-k\">=</span>{X_init: X},\n            <span class=\"pl-v\">init_fn</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">scaffold</span>, <span class=\"pl-smi\">sess</span>: sess.run(enqueue_op))\n    }\n    <span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-k\">**</span>sess_params) <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-c1\">print</span>(sess.run(row))\n        <span class=\"pl-c1\">print</span>(sess.run(row))</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.2.0\nPython version: 3.6.1\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: See below.\n\nDescribe the problem\nFeature request: add a local_init_feed_dict to tf.train.Scaffold. It would be useful to be able to create local variables (which are not saved or restored) and have them initialized by a tf.train.MonitoredTrainingSession with a feed_dict. In the example below, the variable X_var is forced to be part of the GLOBAL_VARIABLES collection in order to be able to initialize the variable with a feed_dict. This has the undesirable consequence that the variable will be saved to disk.\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\n\n# Data that we wish to sample, but not save to disk.\nX = np.eye(15, dtype=np.float32)\n\n# Create a graph that samples rows from X randomly.\ngraph = tf.Graph()\nwith graph.as_default():\n    X_init = tf.placeholder(tf.float32, shape=X.shape)\n    # Here, we want to use tf.GraphKeys.LOCAL_VARIABLES,\n    # but can't because there is no feed_dict for that collection in tf.train.Scaffold.\n    X_var = tf.Variable(X_init, trainable=False, collections=[tf.GraphKeys.GLOBAL_VARIABLES])\n    queue = tf.RandomShuffleQueue(\n        capacity=X.shape[0],\n        min_after_dequeue=1,\n        dtypes=[tf.float32],\n        shapes=[X.shape[1]])\n    enqueue_op = queue.enqueue_many([X_var])\n    row = queue.dequeue()\n\n# Sample a few rows from X.\nwith graph.as_default():\n    sess_params = {\n        'scaffold': tf.train.Scaffold(\n            init_feed_dict={X_init: X},\n            init_fn=lambda scaffold, sess: sess.run(enqueue_op))\n    }\n    with tf.train.MonitoredTrainingSession(**sess_params) as sess:\n        print(sess.run(row))\n        print(sess.run(row))", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2.0\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below.\r\n\r\n### Describe the problem\r\nFeature request: add a `local_init_feed_dict` to `tf.train.Scaffold`. It would be useful to be able to create local variables (which are not saved or restored) and have them initialized by a `tf.train.MonitoredTrainingSession` with a `feed_dict`. In the example below, the variable `X_var` is forced to be part of the `GLOBAL_VARIABLES` collection in order to be able to initialize the variable with a `feed_dict`. This has the undesirable consequence that the variable will be saved to disk.\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# Data that we wish to sample, but not save to disk.\r\nX = np.eye(15, dtype=np.float32)\r\n\r\n# Create a graph that samples rows from X randomly.\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    X_init = tf.placeholder(tf.float32, shape=X.shape)\r\n    # Here, we want to use tf.GraphKeys.LOCAL_VARIABLES,\r\n    # but can't because there is no feed_dict for that collection in tf.train.Scaffold.\r\n    X_var = tf.Variable(X_init, trainable=False, collections=[tf.GraphKeys.GLOBAL_VARIABLES])\r\n    queue = tf.RandomShuffleQueue(\r\n        capacity=X.shape[0],\r\n        min_after_dequeue=1,\r\n        dtypes=[tf.float32],\r\n        shapes=[X.shape[1]])\r\n    enqueue_op = queue.enqueue_many([X_var])\r\n    row = queue.dequeue()\r\n\r\n# Sample a few rows from X.\r\nwith graph.as_default():\r\n    sess_params = {\r\n        'scaffold': tf.train.Scaffold(\r\n            init_feed_dict={X_init: X},\r\n            init_fn=lambda scaffold, sess: sess.run(enqueue_op))\r\n    }\r\n    with tf.train.MonitoredTrainingSession(**sess_params) as sess:\r\n        print(sess.run(row))\r\n        print(sess.run(row))\r\n```\r\n"}