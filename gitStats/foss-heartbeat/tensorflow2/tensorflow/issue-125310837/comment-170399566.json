{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/170399566", "html_url": "https://github.com/tensorflow/tensorflow/issues/713#issuecomment-170399566", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/713", "id": 170399566, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MDM5OTU2Ng==", "user": {"login": "jeremybarnes", "id": 112556, "node_id": "MDQ6VXNlcjExMjU1Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/112556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeremybarnes", "html_url": "https://github.com/jeremybarnes", "followers_url": "https://api.github.com/users/jeremybarnes/followers", "following_url": "https://api.github.com/users/jeremybarnes/following{/other_user}", "gists_url": "https://api.github.com/users/jeremybarnes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeremybarnes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeremybarnes/subscriptions", "organizations_url": "https://api.github.com/users/jeremybarnes/orgs", "repos_url": "https://api.github.com/users/jeremybarnes/repos", "events_url": "https://api.github.com/users/jeremybarnes/events{/privacy}", "received_events_url": "https://api.github.com/users/jeremybarnes/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-10T22:24:40Z", "updated_at": "2016-01-11T12:06:01Z", "author_association": "NONE", "body_html": "<p>FWIW, I spent some time independently debugging this issue as well.   What I found was that the preprocessor magic in Eigen was removing nvcc's ability to know what templated kernels to instantiate for the device code.  The fix for the non-convolutional kernels was to modify the <code>eigen/unsupported/CXX11/src/tensor/TensorDeviceCuda.h</code> file and modify the LAUNCH_CUDA_KERNEL macro for the device code to force instantiation of the kernel.</p>\n<p>The full patch and details are in the Bitbucket pull request:</p>\n<p><a href=\"https://bitbucket.org/eigen/eigen/pull-requests/152/alternative-way-of-forcing-instantiation/diff\" rel=\"nofollow\">https://bitbucket.org/eigen/eigen/pull-requests/152/alternative-way-of-forcing-instantiation/diff</a></p>\n<pre><code>#ifndef __CUDA_ARCH__\n#define LAUNCH_CUDA_KERNEL(kernel, gridsize, blocksize, sharedmem, device, ...)            \\\n    (kernel) &lt;&lt;&lt; (gridsize), (blocksize), (sharedmem), (device).stream() &gt;&gt;&gt; (__VA_ARGS__); \\\n    assert(cudaGetLastError() == cudaSuccess);\n#else\n#define LAUNCH_CUDA_KERNEL(kernel, ...)  \\\n    { static const auto __attribute__((__unused__)) __makeTheKernelInstantiate = &amp;(kernel); } \\\n   eigen_assert(false &amp;&amp; \"Cannot launch a kernel from another kernel\");\n#endif\n</code></pre>", "body_text": "FWIW, I spent some time independently debugging this issue as well.   What I found was that the preprocessor magic in Eigen was removing nvcc's ability to know what templated kernels to instantiate for the device code.  The fix for the non-convolutional kernels was to modify the eigen/unsupported/CXX11/src/tensor/TensorDeviceCuda.h file and modify the LAUNCH_CUDA_KERNEL macro for the device code to force instantiation of the kernel.\nThe full patch and details are in the Bitbucket pull request:\nhttps://bitbucket.org/eigen/eigen/pull-requests/152/alternative-way-of-forcing-instantiation/diff\n#ifndef __CUDA_ARCH__\n#define LAUNCH_CUDA_KERNEL(kernel, gridsize, blocksize, sharedmem, device, ...)            \\\n    (kernel) <<< (gridsize), (blocksize), (sharedmem), (device).stream() >>> (__VA_ARGS__); \\\n    assert(cudaGetLastError() == cudaSuccess);\n#else\n#define LAUNCH_CUDA_KERNEL(kernel, ...)  \\\n    { static const auto __attribute__((__unused__)) __makeTheKernelInstantiate = &(kernel); } \\\n   eigen_assert(false && \"Cannot launch a kernel from another kernel\");\n#endif", "body": "FWIW, I spent some time independently debugging this issue as well.   What I found was that the preprocessor magic in Eigen was removing nvcc's ability to know what templated kernels to instantiate for the device code.  The fix for the non-convolutional kernels was to modify the `eigen/unsupported/CXX11/src/tensor/TensorDeviceCuda.h` file and modify the LAUNCH_CUDA_KERNEL macro for the device code to force instantiation of the kernel.\n\nThe full patch and details are in the Bitbucket pull request:\n\nhttps://bitbucket.org/eigen/eigen/pull-requests/152/alternative-way-of-forcing-instantiation/diff\n\n```\n#ifndef __CUDA_ARCH__\n#define LAUNCH_CUDA_KERNEL(kernel, gridsize, blocksize, sharedmem, device, ...)            \\\n    (kernel) <<< (gridsize), (blocksize), (sharedmem), (device).stream() >>> (__VA_ARGS__); \\\n    assert(cudaGetLastError() == cudaSuccess);\n#else\n#define LAUNCH_CUDA_KERNEL(kernel, ...)  \\\n    { static const auto __attribute__((__unused__)) __makeTheKernelInstantiate = &(kernel); } \\\n   eigen_assert(false && \"Cannot launch a kernel from another kernel\");\n#endif\n```\n"}