{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/160354041", "html_url": "https://github.com/tensorflow/tensorflow/issues/342#issuecomment-160354041", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342", "id": 160354041, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MDM1NDA0MQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-29T01:35:05Z", "updated_at": "2015-11-29T01:36:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Suppose you have a minibatch of 2 entries.  The first entry has sparse ids [53, 87, 101], values [0.1, 0.2, 0.3] and the second has sparse ids [34, 98], weights [-1.0, 3.5].  Suppose your total vocab size is 500.  Suppose also that the hidden layer has depth 25 (25 units).</p>\n<p>then:</p>\n<div class=\"highlight highlight-source-python\"><pre>X <span class=\"pl-k\">=</span> tf.Variable(tf.truncated_normal([<span class=\"pl-c1\">500</span>, <span class=\"pl-c1\">25</span>], <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">500.0</span>))\nsp_indices <span class=\"pl-k\">=</span> tf.placeholder(tf.int64)\nsp_shape <span class=\"pl-k\">=</span> tf.placeholder(tf.int64)\nsp_ids_val <span class=\"pl-k\">=</span> tf.placeholder(tf.int64)\nsp_weights_val <span class=\"pl-k\">=</span> tf.placeholder(tf.float32)\nsp_ids <span class=\"pl-k\">=</span> tf.SparseTensor(sp_indices, sp_ids_val, sp_shape)\nsp_weights <span class=\"pl-k\">=</span> tf.SparseTensor(sp_indices, sp_weights_val, sp_shape)\ny <span class=\"pl-k\">=</span> tf.nn.embedding_lookup_sparse(X, sp_ids, sp_weights, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>sum<span class=\"pl-pds\">\"</span></span>)\ntf.initialize_all_variables().run()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> initialize values in X</span>\n\ny_values <span class=\"pl-k\">=</span> tf.run(y, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{\n  sp_indices: [[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>], [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>], [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]],  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 3 entries in minibatch entry 0, 2 entries in entry 1.</span>\n  sp_shape: [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>],  <span class=\"pl-c\"><span class=\"pl-c\">#</span> batch size: 2, max index: 2 (so index count == 3)</span>\n  sp_ids_val: [<span class=\"pl-c1\">53</span>, <span class=\"pl-c1\">87</span>, <span class=\"pl-c1\">101</span>, <span class=\"pl-c1\">34</span>, <span class=\"pl-c1\">98</span>],\n  sp_weights_val: [<span class=\"pl-c1\">0.1</span>, <span class=\"pl-c1\">0.2</span>, <span class=\"pl-c1\">0.3</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">3.5</span>]})</pre></div>\n<p>y_values should be the output of X*[w1, w2], where w1 and w2 are the two minibatch entries.</p>", "body_text": "Suppose you have a minibatch of 2 entries.  The first entry has sparse ids [53, 87, 101], values [0.1, 0.2, 0.3] and the second has sparse ids [34, 98], weights [-1.0, 3.5].  Suppose your total vocab size is 500.  Suppose also that the hidden layer has depth 25 (25 units).\nthen:\nX = tf.Variable(tf.truncated_normal([500, 25], stddev=1/500.0))\nsp_indices = tf.placeholder(tf.int64)\nsp_shape = tf.placeholder(tf.int64)\nsp_ids_val = tf.placeholder(tf.int64)\nsp_weights_val = tf.placeholder(tf.float32)\nsp_ids = tf.SparseTensor(sp_indices, sp_ids_val, sp_shape)\nsp_weights = tf.SparseTensor(sp_indices, sp_weights_val, sp_shape)\ny = tf.nn.embedding_lookup_sparse(X, sp_ids, sp_weights, \"sum\")\ntf.initialize_all_variables().run()  # initialize values in X\n\ny_values = tf.run(y, feed_dict={\n  sp_indices: [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],  # 3 entries in minibatch entry 0, 2 entries in entry 1.\n  sp_shape: [2, 3],  # batch size: 2, max index: 2 (so index count == 3)\n  sp_ids_val: [53, 87, 101, 34, 98],\n  sp_weights_val: [0.1, 0.2, 0.3, -1.0, 3.5]})\ny_values should be the output of X*[w1, w2], where w1 and w2 are the two minibatch entries.", "body": "Suppose you have a minibatch of 2 entries.  The first entry has sparse ids [53, 87, 101], values [0.1, 0.2, 0.3] and the second has sparse ids [34, 98], weights [-1.0, 3.5].  Suppose your total vocab size is 500.  Suppose also that the hidden layer has depth 25 (25 units).\n\nthen:\n\n``` python\nX = tf.Variable(tf.truncated_normal([500, 25], stddev=1/500.0))\nsp_indices = tf.placeholder(tf.int64)\nsp_shape = tf.placeholder(tf.int64)\nsp_ids_val = tf.placeholder(tf.int64)\nsp_weights_val = tf.placeholder(tf.float32)\nsp_ids = tf.SparseTensor(sp_indices, sp_ids_val, sp_shape)\nsp_weights = tf.SparseTensor(sp_indices, sp_weights_val, sp_shape)\ny = tf.nn.embedding_lookup_sparse(X, sp_ids, sp_weights, \"sum\")\ntf.initialize_all_variables().run()  # initialize values in X\n\ny_values = tf.run(y, feed_dict={\n  sp_indices: [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],  # 3 entries in minibatch entry 0, 2 entries in entry 1.\n  sp_shape: [2, 3],  # batch size: 2, max index: 2 (so index count == 3)\n  sp_ids_val: [53, 87, 101, 34, 98],\n  sp_weights_val: [0.1, 0.2, 0.3, -1.0, 3.5]})\n```\n\ny_values should be the output of X*[w1, w2], where w1 and w2 are the two minibatch entries.\n"}