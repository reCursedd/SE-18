{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/160034584", "html_url": "https://github.com/tensorflow/tensorflow/issues/342#issuecomment-160034584", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342", "id": 160034584, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MDAzNDU4NA==", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-27T03:32:10Z", "updated_at": "2015-11-27T03:32:10Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a>  I want to use tensorflow doing text classification experiment.<br>\nSay I may use the mini batch sgd implementation logistic regression for text classification.<br>\nThen each mini batch is sparse matrix, like for each instance , will contain 400k features(where only 100 will be non zero), so for matmul(X,w) operation, X(mini batch input matrix) is sparse, w(weight vector) is dense.</p>\n<p>I find the code comment , seems only accept tensor nor sparse tensor, it has parameter a_is_sparse,<br>\nbut I'm not sure how to use ? convert sparse mini batch to dense matrix(tensor), then set (a_is_sparse=True)\uff1f<br>\ndef matmul(a, b,<br>\ntranspose_a=False, transpose_b=False,<br>\na_is_sparse=False, b_is_sparse=False,<br>\nname=None):<br>\n\"\"\"Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>\n<p>The inputs must be two-dimensional matrices, with matching inner dimensions,<br>\npossibly after transposition.</p>\n<p>Both matrices must be of the same type. The supported types are:<br>\n<code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>.</p>\n<p>Either matrix can be transposed on the fly by setting the corresponding flag<br>\nto <code>True</code>. This is <code>False</code> by default.</p>\n<p>If one or both of the matrices contain a lot of zeros, a more efficient<br>\nmultiplication algorithm can be used by setting the corresponding<br>\n<code>a_is_sparse</code> or <code>b_is_sparse</code> flag to <code>True</code>. These are <code>False</code> by default.</p>\n<p>For example:</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 2-D tensor `a`</span>\n  a <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">6</span>], <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>]) <span class=\"pl-k\">=</span><span class=\"pl-k\">&gt;</span> [[<span class=\"pl-c1\">1</span>. 2. 3.]\n                                                        [<span class=\"pl-c1\">4</span>. 5. 6.]]\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 2-D tensor `b`</span>\n  b <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">11</span>, <span class=\"pl-c1\">12</span>], <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>]) <span class=\"pl-k\">=</span><span class=\"pl-k\">&gt;</span> [[<span class=\"pl-c1\">7</span>. 8.]\n                                                           [<span class=\"pl-c1\">9</span>. 10.]\n                                                           [<span class=\"pl-c1\">11</span>. 12.]]\n  c <span class=\"pl-k\">=</span> tf.matmul(a, b) <span class=\"pl-k\">=</span><span class=\"pl-k\">&gt;</span> [[<span class=\"pl-c1\">58</span> <span class=\"pl-c1\">64</span>]\n                          [<span class=\"pl-c1\">139</span> <span class=\"pl-c1\">154</span>]]</pre></div>\n<p>Args:<br>\na: <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code> or <code>complex64</code>.<br>\nb: <code>Tensor</code> with same type as <code>a</code>.<br>\ntranspose_a: If <code>True</code>, <code>a</code> is transposed before multiplication.<br>\ntranspose_b: If <code>True</code>, <code>b</code> is transposed before multiplication.<br>\na_is_sparse: If <code>True</code>, <code>a</code> is treated as a sparse matrix.<br>\nb_is_sparse: If <code>True</code>, <code>b</code> is treated as a sparse matrix.<br>\nname: Name for the operation (optional).</p>\n<p>Returns:<br>\nA <code>Tensor</code> of the same type as <code>a</code>.<br>\n\"\"\"</p>", "body_text": "@ebrevdo  I want to use tensorflow doing text classification experiment.\nSay I may use the mini batch sgd implementation logistic regression for text classification.\nThen each mini batch is sparse matrix, like for each instance , will contain 400k features(where only 100 will be non zero), so for matmul(X,w) operation, X(mini batch input matrix) is sparse, w(weight vector) is dense.\nI find the code comment , seems only accept tensor nor sparse tensor, it has parameter a_is_sparse,\nbut I'm not sure how to use ? convert sparse mini batch to dense matrix(tensor), then set (a_is_sparse=True)\uff1f\ndef matmul(a, b,\ntranspose_a=False, transpose_b=False,\na_is_sparse=False, b_is_sparse=False,\nname=None):\n\"\"\"Multiplies matrix a by matrix b, producing a * b.\nThe inputs must be two-dimensional matrices, with matching inner dimensions,\npossibly after transposition.\nBoth matrices must be of the same type. The supported types are:\nfloat, double, int32, complex64.\nEither matrix can be transposed on the fly by setting the corresponding flag\nto True. This is False by default.\nIf one or both of the matrices contain a lot of zeros, a more efficient\nmultiplication algorithm can be used by setting the corresponding\na_is_sparse or b_is_sparse flag to True. These are False by default.\nFor example:\n  # 2-D tensor `a`\n  a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) => [[1. 2. 3.]\n                                                        [4. 5. 6.]]\n  # 2-D tensor `b`\n  b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) => [[7. 8.]\n                                                           [9. 10.]\n                                                           [11. 12.]]\n  c = tf.matmul(a, b) => [[58 64]\n                          [139 154]]\nArgs:\na: Tensor of type float, double, int32 or complex64.\nb: Tensor with same type as a.\ntranspose_a: If True, a is transposed before multiplication.\ntranspose_b: If True, b is transposed before multiplication.\na_is_sparse: If True, a is treated as a sparse matrix.\nb_is_sparse: If True, b is treated as a sparse matrix.\nname: Name for the operation (optional).\nReturns:\nA Tensor of the same type as a.\n\"\"\"", "body": "@ebrevdo  I want to use tensorflow doing text classification experiment. \nSay I may use the mini batch sgd implementation logistic regression for text classification.\nThen each mini batch is sparse matrix, like for each instance , will contain 400k features(where only 100 will be non zero), so for matmul(X,w) operation, X(mini batch input matrix) is sparse, w(weight vector) is dense. \n\nI find the code comment , seems only accept tensor nor sparse tensor, it has parameter a_is_sparse,\nbut I'm not sure how to use ? convert sparse mini batch to dense matrix(tensor), then set (a_is_sparse=True)\uff1f\ndef matmul(a, b,\n           transpose_a=False, transpose_b=False,\n           a_is_sparse=False, b_is_sparse=False,\n           name=None):\n  \"\"\"Multiplies matrix `a` by matrix `b`, producing `a` \\* `b`.\n\n  The inputs must be two-dimensional matrices, with matching inner dimensions,\n  possibly after transposition.\n\n  Both matrices must be of the same type. The supported types are:\n  `float`, `double`, `int32`, `complex64`.\n\n  Either matrix can be transposed on the fly by setting the corresponding flag\n  to `True`. This is `False` by default.\n\n  If one or both of the matrices contain a lot of zeros, a more efficient\n  multiplication algorithm can be used by setting the corresponding\n  `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n\n  For example:\n\n``` python\n  # 2-D tensor `a`\n  a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) => [[1. 2. 3.]\n                                                        [4. 5. 6.]]\n  # 2-D tensor `b`\n  b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) => [[7. 8.]\n                                                           [9. 10.]\n                                                           [11. 12.]]\n  c = tf.matmul(a, b) => [[58 64]\n                          [139 154]]\n```\n\n  Args:\n    a: `Tensor` of type `float`, `double`, `int32` or `complex64`.\n    b: `Tensor` with same type as `a`.\n    transpose_a: If `True`, `a` is transposed before multiplication.\n    transpose_b: If `True`, `b` is transposed before multiplication.\n    a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n    b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n    name: Name for the operation (optional).\n\n  Returns:\n    A `Tensor` of the same type as `a`.\n  \"\"\"\n"}