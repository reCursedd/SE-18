{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/342/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/342", "id": 118586549, "node_id": "MDU6SXNzdWUxMTg1ODY1NDk=", "number": 342, "title": "Feed sparse array for placeholder ?", "user": {"login": "chenghuige", "id": 6323467, "node_id": "MDQ6VXNlcjYzMjM0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6323467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenghuige", "html_url": "https://github.com/chenghuige", "followers_url": "https://api.github.com/users/chenghuige/followers", "following_url": "https://api.github.com/users/chenghuige/following{/other_user}", "gists_url": "https://api.github.com/users/chenghuige/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenghuige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenghuige/subscriptions", "organizations_url": "https://api.github.com/users/chenghuige/orgs", "repos_url": "https://api.github.com/users/chenghuige/repos", "events_url": "https://api.github.com/users/chenghuige/events{/privacy}", "received_events_url": "https://api.github.com/users/chenghuige/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 25, "created_at": "2015-11-24T11:24:19Z", "updated_at": "2017-02-28T09:46:33Z", "closed_at": "2015-11-30T05:38:35Z", "author_association": "NONE", "body_html": "<p>X = tf.placeholder(\"float\", [None, num_features]) # create symbolic variables<br>\nY = tf.placeholder(\"float\", [None, 1])</p>\n<p>predicts = sess.run(predict_op, feed_dict={X: teX, Y: teY})</p>\n<p>What if I'am facing text classification problem, where every instance is extremely sparse,<br>\nlike using scipy.sparse.csr_matrix or somethint else, what's the best to do this ?</p>", "body_text": "X = tf.placeholder(\"float\", [None, num_features]) # create symbolic variables\nY = tf.placeholder(\"float\", [None, 1])\npredicts = sess.run(predict_op, feed_dict={X: teX, Y: teY})\nWhat if I'am facing text classification problem, where every instance is extremely sparse,\nlike using scipy.sparse.csr_matrix or somethint else, what's the best to do this ?", "body": "X = tf.placeholder(\"float\", [None, num_features]) # create symbolic variables\nY = tf.placeholder(\"float\", [None, 1])\n\npredicts = sess.run(predict_op, feed_dict={X: teX, Y: teY})\n\nWhat if I'am facing text classification problem, where every instance is extremely sparse, \nlike using scipy.sparse.csr_matrix or somethint else, what's the best to do this ?\n"}