{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12097", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12097/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12097/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12097/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12097", "id": 248593359, "node_id": "MDU6SXNzdWUyNDg1OTMzNTk=", "number": 12097, "title": "I got a type error without rhyme or reason\uff0cwhen i rewrite a _linear function in the rnn_cell_impl.py", "user": {"login": "lsdustc", "id": 28560351, "node_id": "MDQ6VXNlcjI4NTYwMzUx", "avatar_url": "https://avatars2.githubusercontent.com/u/28560351?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lsdustc", "html_url": "https://github.com/lsdustc", "followers_url": "https://api.github.com/users/lsdustc/followers", "following_url": "https://api.github.com/users/lsdustc/following{/other_user}", "gists_url": "https://api.github.com/users/lsdustc/gists{/gist_id}", "starred_url": "https://api.github.com/users/lsdustc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lsdustc/subscriptions", "organizations_url": "https://api.github.com/users/lsdustc/orgs", "repos_url": "https://api.github.com/users/lsdustc/repos", "events_url": "https://api.github.com/users/lsdustc/events{/privacy}", "received_events_url": "https://api.github.com/users/lsdustc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-08-08T03:51:08Z", "updated_at": "2017-08-08T05:24:04Z", "closed_at": "2017-08-08T05:24:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:win64</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.2</li>\n<li><strong>Python version</strong>:  3.6</li>\n<li><strong>CUDA/cuDNN version</strong>:ONLY CPU</li>\n<li><strong>GPU model and memory</strong>:ONLY CPU</li>\n<li><strong>Exact command to reproduce</strong>: No</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I want to write a lstm with batch normalization . After , i read the code of BasicLSTMCell , i find i only need to wirte a _linear function acording to this paper <a href=\"https://arxiv.org/pdf/1603.09025.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1603.09025.pdf</a> section 3<br>\nand the new _batchlinear function is  below here , the only difference between _batchlinear function  and<br>\n_linear function is  the arg mul it's weights separately and do  it's batch normalization .when i build a  multi layer rnn like this</p>\n<pre><code>cells       = [BatchLSTMCell(rnn_numhidden,forget_bias=0.,activation=tf.tanh) for _ in range(num_rnn)]\nstack       = tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\nnet, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)\n</code></pre>\n<p>TypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'</p>\n<h3>Source code / logs</h3>\n<p>source code are here</p>\n<pre><code>def _batchlinear(   args,\n                    output_size,\n                    bias,\n                    xh_epsilon = 1e-3,\n                    hh_epsilon = 1e-3,\n                    bias_initializer=None,\n                    kernel_initializer= None):           \n  if args is None or (nest.is_sequence(args) and not args):\n    raise ValueError(\"`args` must be specified\")\n  if not nest.is_sequence(args):\n    args = [args]\n\n  # Calculate the total size of arguments on dimension 1.\n  total_arg_size = 0\n  shapes = [a.get_shape() for a in args]\n  for shape in shapes:\n    if shape.ndims != 2:\n      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n    if shape[1].value is None:\n      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n                       \"but saw %s\" % (shape, shape[1]))\n    else:\n      total_arg_size += shape[1].value\n\n  dtype = [a.dtype for a in args][0]\n\n  # Now the computation.\n  scope = vs.get_variable_scope()\n  with vs.variable_scope(scope) as outer_scope:\n    if len(args) == 1:\n        weights_xh = vs.get_variable('W_xh',\n            [shapes[0], output_size],\n            dtype = dtype,\n            initializer=kernel_initializer)\n        res = math_ops.matmul(args[0], weights_xh)\n    else:\n        weights_xh = vs.get_variable('W_xh',\n            [shapes[0], output_size],\n            dtype = dtype,\n            initializer=kernel_initializer)\n        xh = math_ops.matmul(args[0], weights_xh)\n        xh_scale = vs.get_variable('xh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\n        xh_offset = vs.get_variable('xh_offset', [output_size])\n        xh_batch_mean, xh_batch_var = nn_impl.moments(xh, [0])\n        xh = (xh - xh_batch_mean) / math_ops.sqrt(xh_batch_var + xh_epsilon)\n        xh = xh_scale*xh + xh_offset\n        if kernel_initializer is None:\n            weights_hh = vs.get_variable('W_hh',\n                [shapes[0], output_size],\n                dtype = dtype)\n        hh = math_ops.matmul(args[0],weights_hh)\n        hh_scale = vs.get_variable('hh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\n        hh_offset = vs.get_variable('hh_offset', [output_size])\n        hh_batch_mean, hh_batch_var = nn_impl.moments(hh, [0])\n        hh = (hh - hh_batch_mean) / math_ops.sqrt(hh_batch_var + hh_epsilon)\n        xh = hh_scale*hh + hh_offset\n        res = xh+hh\n    if not bias:\n      return res\n    with vs.variable_scope(outer_scope) as inner_scope:\n      inner_scope.set_partitioner(None)\n      if bias_initializer is None:\n        bias_initializer = init_ops.constant_initializer(0.0, dtype=dtype)\n      biases = vs.get_variable(\n          'bias', [output_size],\n          dtype=dtype,\n          initializer=bias_initializer)\n    return nn_ops.bias_add(res, biases)\n</code></pre>\n<pre><code>class BatchLSTMCell(RNNCell):\n  \"\"\"Basic LSTM recurrent network cell.\n\n  The implementation is based on: http://arxiv.org/abs/1409.2329.\n\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\n  reduce the scale of forgetting in the beginning of the training.\n\n  It does not allow cell clipping, a projection layer, and does not\n  use peep-hole connections: it is the basic baseline.\n\n  For advanced models, please use the full @{tf.nn.rnn_cell.LSTMCell}\n  that follows.\n  \"\"\"\n\n  def __init__(self, num_units, forget_bias=1.0,\n               state_is_tuple=True, activation=None, reuse=None):\n    \"\"\"Initialize the basic LSTM cell.\n\n    Args:\n      num_units: int, The number of units in the LSTM cell.\n      forget_bias: float, The bias added to forget gates (see above).\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\n        the `c_state` and `m_state`.  If False, they are concatenated\n        along the column axis.  The latter behavior will soon be deprecated.\n      activation: Activation function of the inner states.  Default: `tanh`.\n      reuse: (optional) Python boolean describing whether to reuse variables\n        in an existing scope.  If not `True`, and the existing scope already has\n        the given variables, an error is raised.\n    \"\"\"\n    super(BatchLSTMCell, self).__init__(_reuse=reuse)\n    if not state_is_tuple:\n      logging.warn(\"%s: Using a concatenated state is slower and will soon be \"\n                   \"deprecated.  Use state_is_tuple=True.\", self)\n    self._num_units = num_units\n    self._forget_bias = forget_bias\n    self._state_is_tuple = state_is_tuple\n    self._activation = activation or math_ops.tanh\n\n  @property\n  def state_size(self):\n    return (LSTMStateTuple(self._num_units, self._num_units)\n            if self._state_is_tuple else 2 * self._num_units)\n\n  @property\n  def output_size(self):\n    return self._num_units\n\n  def call(self, inputs, state):\n    \"\"\"Long short-term memory cell (LSTM).\"\"\"\n    sigmoid = math_ops.sigmoid\n    # Parameters of gates are concatenated into one multiply for efficiency.\n    if self._state_is_tuple:\n      c, h = state\n    else:\n      c, h = array_ops.split(value=state, num_or_size_splits=2, axis=1)\n\n      concat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)\n\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = array_ops.split(value=concat, num_or_size_splits=4, axis=1)\n\n    new_c = (\n        c * sigmoid(f + self._forget_bias) + sigmoid(i) * self._activation(j))\n    new_h = self._activation(new_c) * sigmoid(o)\n\n    if self._state_is_tuple:\n      new_state = LSTMStateTuple(new_c, new_h)\n    else:\n      new_state = array_ops.concat([new_c, new_h], 1)\n    return new_h, new_state\n</code></pre>\n<p>logs are here<br>\nTraceback (most recent call last):</p>\n<p>File \"\", line 1, in <br>\nrunfile('C:/Users/Administrator/Test/char_rnn.py', wdir='C:/Users/Administrator/Test')</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 688, in runfile<br>\nexecfile(filename, namespace)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 101, in execfile<br>\nexec(compile(f.read(), filename, 'exec'), namespace)</p>\n<p>File \"C:/Users/Administrator/Test/char_rnn.py\", line 25, in <br>\nfinal_logits = charRnn(char_seq_batch,seqlen_batch,charsize=charsize,num_rnn=num_layers,rnn_numhidden = rnn_numhidden)</p>\n<p>File \"C:\\Users\\Administrator\\Test\\networks.py\", line 221, in charRnn<br>\nnet, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 574, in dynamic_rnn<br>\ndtype=dtype)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 737, in _dynamic_rnn_loop<br>\nswap_memory=swap_memory)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop<br>\nresult = context.BuildLoop(cond, body, loop_vars, shape_invariants)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop<br>\npred, body, original_loop_vars, loop_vars, shape_invariants)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop<br>\nbody_result = body(*packed_vars_for_body)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 720, in _time_step<br>\nskip_conditionals=True)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 206, in _rnn_step<br>\nnew_output, new_state = call_cell()</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 708, in <br>\ncall_cell = lambda: cell(input_t, state)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in <strong>call</strong><br>\nreturn super(RNNCell, self).<strong>call</strong>(inputs, state)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 917, in call<br>\ncur_inp, new_state = cell(cur_inp, cur_state)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in <strong>call</strong><br>\nreturn super(RNNCell, self).<strong>call</strong>(inputs, state)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in <strong>call</strong><br>\noutputs = self.call(inputs, *args, **kwargs)</p>\n<p>File \"C:\\Users\\Administrator\\Test\\networks.py\", line 167, in call<br>\nconcat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)</p>\n<p>File \"C:\\Users\\Administrator\\Test\\networks.py\", line 80, in _batchlinear<br>\ninitializer=kernel_initializer)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1065, in get_variable<br>\nuse_resource=use_resource, custom_getter=custom_getter)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 962, in get_variable<br>\nuse_resource=use_resource, custom_getter=custom_getter)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 360, in get_variable<br>\nvalidate_shape=validate_shape, use_resource=use_resource)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1405, in wrapped_custom_getter<br>\n*args, **kwargs)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable<br>\nvariable = getter(*args, **kwargs)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable<br>\nvariable = getter(*args, **kwargs)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 352, in _true_getter<br>\nuse_resource=use_resource)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 653, in _get_single_variable<br>\nshape = tensor_shape.as_shape(shape)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 798, in as_shape<br>\nreturn TensorShape(shape)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in <strong>init</strong><br>\nself._dims = [as_dimension(d) for d in dims_iter]</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in <br>\nself._dims = [as_dimension(d) for d in dims_iter]</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 376, in as_dimension<br>\nreturn Dimension(value)</p>\n<p>File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 32, in <strong>init</strong><br>\nself._value = int(value)</p>\n<p>TypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):win64\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below):1.2\nPython version:  3.6\nCUDA/cuDNN version:ONLY CPU\nGPU model and memory:ONLY CPU\nExact command to reproduce: No\n\nDescribe the problem\nI want to write a lstm with batch normalization . After , i read the code of BasicLSTMCell , i find i only need to wirte a _linear function acording to this paper https://arxiv.org/pdf/1603.09025.pdf section 3\nand the new _batchlinear function is  below here , the only difference between _batchlinear function  and\n_linear function is  the arg mul it's weights separately and do  it's batch normalization .when i build a  multi layer rnn like this\ncells       = [BatchLSTMCell(rnn_numhidden,forget_bias=0.,activation=tf.tanh) for _ in range(num_rnn)]\nstack       = tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\nnet, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)\n\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'\nSource code / logs\nsource code are here\ndef _batchlinear(   args,\n                    output_size,\n                    bias,\n                    xh_epsilon = 1e-3,\n                    hh_epsilon = 1e-3,\n                    bias_initializer=None,\n                    kernel_initializer= None):           \n  if args is None or (nest.is_sequence(args) and not args):\n    raise ValueError(\"`args` must be specified\")\n  if not nest.is_sequence(args):\n    args = [args]\n\n  # Calculate the total size of arguments on dimension 1.\n  total_arg_size = 0\n  shapes = [a.get_shape() for a in args]\n  for shape in shapes:\n    if shape.ndims != 2:\n      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n    if shape[1].value is None:\n      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n                       \"but saw %s\" % (shape, shape[1]))\n    else:\n      total_arg_size += shape[1].value\n\n  dtype = [a.dtype for a in args][0]\n\n  # Now the computation.\n  scope = vs.get_variable_scope()\n  with vs.variable_scope(scope) as outer_scope:\n    if len(args) == 1:\n        weights_xh = vs.get_variable('W_xh',\n            [shapes[0], output_size],\n            dtype = dtype,\n            initializer=kernel_initializer)\n        res = math_ops.matmul(args[0], weights_xh)\n    else:\n        weights_xh = vs.get_variable('W_xh',\n            [shapes[0], output_size],\n            dtype = dtype,\n            initializer=kernel_initializer)\n        xh = math_ops.matmul(args[0], weights_xh)\n        xh_scale = vs.get_variable('xh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\n        xh_offset = vs.get_variable('xh_offset', [output_size])\n        xh_batch_mean, xh_batch_var = nn_impl.moments(xh, [0])\n        xh = (xh - xh_batch_mean) / math_ops.sqrt(xh_batch_var + xh_epsilon)\n        xh = xh_scale*xh + xh_offset\n        if kernel_initializer is None:\n            weights_hh = vs.get_variable('W_hh',\n                [shapes[0], output_size],\n                dtype = dtype)\n        hh = math_ops.matmul(args[0],weights_hh)\n        hh_scale = vs.get_variable('hh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\n        hh_offset = vs.get_variable('hh_offset', [output_size])\n        hh_batch_mean, hh_batch_var = nn_impl.moments(hh, [0])\n        hh = (hh - hh_batch_mean) / math_ops.sqrt(hh_batch_var + hh_epsilon)\n        xh = hh_scale*hh + hh_offset\n        res = xh+hh\n    if not bias:\n      return res\n    with vs.variable_scope(outer_scope) as inner_scope:\n      inner_scope.set_partitioner(None)\n      if bias_initializer is None:\n        bias_initializer = init_ops.constant_initializer(0.0, dtype=dtype)\n      biases = vs.get_variable(\n          'bias', [output_size],\n          dtype=dtype,\n          initializer=bias_initializer)\n    return nn_ops.bias_add(res, biases)\n\nclass BatchLSTMCell(RNNCell):\n  \"\"\"Basic LSTM recurrent network cell.\n\n  The implementation is based on: http://arxiv.org/abs/1409.2329.\n\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\n  reduce the scale of forgetting in the beginning of the training.\n\n  It does not allow cell clipping, a projection layer, and does not\n  use peep-hole connections: it is the basic baseline.\n\n  For advanced models, please use the full @{tf.nn.rnn_cell.LSTMCell}\n  that follows.\n  \"\"\"\n\n  def __init__(self, num_units, forget_bias=1.0,\n               state_is_tuple=True, activation=None, reuse=None):\n    \"\"\"Initialize the basic LSTM cell.\n\n    Args:\n      num_units: int, The number of units in the LSTM cell.\n      forget_bias: float, The bias added to forget gates (see above).\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\n        the `c_state` and `m_state`.  If False, they are concatenated\n        along the column axis.  The latter behavior will soon be deprecated.\n      activation: Activation function of the inner states.  Default: `tanh`.\n      reuse: (optional) Python boolean describing whether to reuse variables\n        in an existing scope.  If not `True`, and the existing scope already has\n        the given variables, an error is raised.\n    \"\"\"\n    super(BatchLSTMCell, self).__init__(_reuse=reuse)\n    if not state_is_tuple:\n      logging.warn(\"%s: Using a concatenated state is slower and will soon be \"\n                   \"deprecated.  Use state_is_tuple=True.\", self)\n    self._num_units = num_units\n    self._forget_bias = forget_bias\n    self._state_is_tuple = state_is_tuple\n    self._activation = activation or math_ops.tanh\n\n  @property\n  def state_size(self):\n    return (LSTMStateTuple(self._num_units, self._num_units)\n            if self._state_is_tuple else 2 * self._num_units)\n\n  @property\n  def output_size(self):\n    return self._num_units\n\n  def call(self, inputs, state):\n    \"\"\"Long short-term memory cell (LSTM).\"\"\"\n    sigmoid = math_ops.sigmoid\n    # Parameters of gates are concatenated into one multiply for efficiency.\n    if self._state_is_tuple:\n      c, h = state\n    else:\n      c, h = array_ops.split(value=state, num_or_size_splits=2, axis=1)\n\n      concat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)\n\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = array_ops.split(value=concat, num_or_size_splits=4, axis=1)\n\n    new_c = (\n        c * sigmoid(f + self._forget_bias) + sigmoid(i) * self._activation(j))\n    new_h = self._activation(new_c) * sigmoid(o)\n\n    if self._state_is_tuple:\n      new_state = LSTMStateTuple(new_c, new_h)\n    else:\n      new_state = array_ops.concat([new_c, new_h], 1)\n    return new_h, new_state\n\nlogs are here\nTraceback (most recent call last):\nFile \"\", line 1, in \nrunfile('C:/Users/Administrator/Test/char_rnn.py', wdir='C:/Users/Administrator/Test')\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 688, in runfile\nexecfile(filename, namespace)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 101, in execfile\nexec(compile(f.read(), filename, 'exec'), namespace)\nFile \"C:/Users/Administrator/Test/char_rnn.py\", line 25, in \nfinal_logits = charRnn(char_seq_batch,seqlen_batch,charsize=charsize,num_rnn=num_layers,rnn_numhidden = rnn_numhidden)\nFile \"C:\\Users\\Administrator\\Test\\networks.py\", line 221, in charRnn\nnet, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 574, in dynamic_rnn\ndtype=dtype)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 737, in _dynamic_rnn_loop\nswap_memory=swap_memory)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\nresult = context.BuildLoop(cond, body, loop_vars, shape_invariants)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\npred, body, original_loop_vars, loop_vars, shape_invariants)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\nbody_result = body(*packed_vars_for_body)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 720, in _time_step\nskip_conditionals=True)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 206, in _rnn_step\nnew_output, new_state = call_cell()\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 708, in \ncall_cell = lambda: cell(input_t, state)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in call\nreturn super(RNNCell, self).call(inputs, state)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 917, in call\ncur_inp, new_state = cell(cur_inp, cur_state)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in call\nreturn super(RNNCell, self).call(inputs, state)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in call\noutputs = self.call(inputs, *args, **kwargs)\nFile \"C:\\Users\\Administrator\\Test\\networks.py\", line 167, in call\nconcat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)\nFile \"C:\\Users\\Administrator\\Test\\networks.py\", line 80, in _batchlinear\ninitializer=kernel_initializer)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1065, in get_variable\nuse_resource=use_resource, custom_getter=custom_getter)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 962, in get_variable\nuse_resource=use_resource, custom_getter=custom_getter)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 360, in get_variable\nvalidate_shape=validate_shape, use_resource=use_resource)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1405, in wrapped_custom_getter\n*args, **kwargs)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable\nvariable = getter(*args, **kwargs)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable\nvariable = getter(*args, **kwargs)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 352, in _true_getter\nuse_resource=use_resource)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 653, in _get_single_variable\nshape = tensor_shape.as_shape(shape)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 798, in as_shape\nreturn TensorShape(shape)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in init\nself._dims = [as_dimension(d) for d in dims_iter]\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in \nself._dims = [as_dimension(d) for d in dims_iter]\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 376, in as_dimension\nreturn Dimension(value)\nFile \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 32, in init\nself._value = int(value)\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win64\r\n- **TensorFlow installed from (source or binary)**: pip \r\n- **TensorFlow version (use command below)**:1.2\r\n- **Python version**:  3.6\r\n- **CUDA/cuDNN version**:ONLY CPU\r\n- **GPU model and memory**:ONLY CPU\r\n- **Exact command to reproduce**: No\r\n\r\n### Describe the problem\r\nI want to write a lstm with batch normalization . After , i read the code of BasicLSTMCell , i find i only need to wirte a _linear function acording to this paper https://arxiv.org/pdf/1603.09025.pdf section 3\r\nand the new _batchlinear function is  below here , the only difference between _batchlinear function  and \r\n_linear function is  the arg mul it's weights separately and do  it's batch normalization .when i build a  multi layer rnn like this \r\n```\r\ncells       = [BatchLSTMCell(rnn_numhidden,forget_bias=0.,activation=tf.tanh) for _ in range(num_rnn)]\r\nstack       = tf.contrib.rnn.MultiRNNCell(cells,state_is_tuple=True)\r\nnet, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)\r\n```\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'\r\n### Source code / logs\r\nsource code are here\r\n```\r\ndef _batchlinear(   args,\r\n                    output_size,\r\n                    bias,\r\n                    xh_epsilon = 1e-3,\r\n                    hh_epsilon = 1e-3,\r\n                    bias_initializer=None,\r\n                    kernel_initializer= None):           \r\n  if args is None or (nest.is_sequence(args) and not args):\r\n    raise ValueError(\"`args` must be specified\")\r\n  if not nest.is_sequence(args):\r\n    args = [args]\r\n\r\n  # Calculate the total size of arguments on dimension 1.\r\n  total_arg_size = 0\r\n  shapes = [a.get_shape() for a in args]\r\n  for shape in shapes:\r\n    if shape.ndims != 2:\r\n      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\r\n    if shape[1].value is None:\r\n      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\r\n                       \"but saw %s\" % (shape, shape[1]))\r\n    else:\r\n      total_arg_size += shape[1].value\r\n\r\n  dtype = [a.dtype for a in args][0]\r\n\r\n  # Now the computation.\r\n  scope = vs.get_variable_scope()\r\n  with vs.variable_scope(scope) as outer_scope:\r\n    if len(args) == 1:\r\n        weights_xh = vs.get_variable('W_xh',\r\n            [shapes[0], output_size],\r\n            dtype = dtype,\r\n            initializer=kernel_initializer)\r\n        res = math_ops.matmul(args[0], weights_xh)\r\n    else:\r\n        weights_xh = vs.get_variable('W_xh',\r\n            [shapes[0], output_size],\r\n            dtype = dtype,\r\n            initializer=kernel_initializer)\r\n        xh = math_ops.matmul(args[0], weights_xh)\r\n        xh_scale = vs.get_variable('xh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\r\n        xh_offset = vs.get_variable('xh_offset', [output_size])\r\n        xh_batch_mean, xh_batch_var = nn_impl.moments(xh, [0])\r\n        xh = (xh - xh_batch_mean) / math_ops.sqrt(xh_batch_var + xh_epsilon)\r\n        xh = xh_scale*xh + xh_offset\r\n        if kernel_initializer is None:\r\n            weights_hh = vs.get_variable('W_hh',\r\n                [shapes[0], output_size],\r\n                dtype = dtype)\r\n        hh = math_ops.matmul(args[0],weights_hh)\r\n        hh_scale = vs.get_variable('hh_scale', [output_size], initializer=init_ops.constant_initializer(0.1, dtype=dtype))\r\n        hh_offset = vs.get_variable('hh_offset', [output_size])\r\n        hh_batch_mean, hh_batch_var = nn_impl.moments(hh, [0])\r\n        hh = (hh - hh_batch_mean) / math_ops.sqrt(hh_batch_var + hh_epsilon)\r\n        xh = hh_scale*hh + hh_offset\r\n        res = xh+hh\r\n    if not bias:\r\n      return res\r\n    with vs.variable_scope(outer_scope) as inner_scope:\r\n      inner_scope.set_partitioner(None)\r\n      if bias_initializer is None:\r\n        bias_initializer = init_ops.constant_initializer(0.0, dtype=dtype)\r\n      biases = vs.get_variable(\r\n          'bias', [output_size],\r\n          dtype=dtype,\r\n          initializer=bias_initializer)\r\n    return nn_ops.bias_add(res, biases)\r\n```\r\n```\r\nclass BatchLSTMCell(RNNCell):\r\n  \"\"\"Basic LSTM recurrent network cell.\r\n\r\n  The implementation is based on: http://arxiv.org/abs/1409.2329.\r\n\r\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\r\n  reduce the scale of forgetting in the beginning of the training.\r\n\r\n  It does not allow cell clipping, a projection layer, and does not\r\n  use peep-hole connections: it is the basic baseline.\r\n\r\n  For advanced models, please use the full @{tf.nn.rnn_cell.LSTMCell}\r\n  that follows.\r\n  \"\"\"\r\n\r\n  def __init__(self, num_units, forget_bias=1.0,\r\n               state_is_tuple=True, activation=None, reuse=None):\r\n    \"\"\"Initialize the basic LSTM cell.\r\n\r\n    Args:\r\n      num_units: int, The number of units in the LSTM cell.\r\n      forget_bias: float, The bias added to forget gates (see above).\r\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\r\n        the `c_state` and `m_state`.  If False, they are concatenated\r\n        along the column axis.  The latter behavior will soon be deprecated.\r\n      activation: Activation function of the inner states.  Default: `tanh`.\r\n      reuse: (optional) Python boolean describing whether to reuse variables\r\n        in an existing scope.  If not `True`, and the existing scope already has\r\n        the given variables, an error is raised.\r\n    \"\"\"\r\n    super(BatchLSTMCell, self).__init__(_reuse=reuse)\r\n    if not state_is_tuple:\r\n      logging.warn(\"%s: Using a concatenated state is slower and will soon be \"\r\n                   \"deprecated.  Use state_is_tuple=True.\", self)\r\n    self._num_units = num_units\r\n    self._forget_bias = forget_bias\r\n    self._state_is_tuple = state_is_tuple\r\n    self._activation = activation or math_ops.tanh\r\n\r\n  @property\r\n  def state_size(self):\r\n    return (LSTMStateTuple(self._num_units, self._num_units)\r\n            if self._state_is_tuple else 2 * self._num_units)\r\n\r\n  @property\r\n  def output_size(self):\r\n    return self._num_units\r\n\r\n  def call(self, inputs, state):\r\n    \"\"\"Long short-term memory cell (LSTM).\"\"\"\r\n    sigmoid = math_ops.sigmoid\r\n    # Parameters of gates are concatenated into one multiply for efficiency.\r\n    if self._state_is_tuple:\r\n      c, h = state\r\n    else:\r\n      c, h = array_ops.split(value=state, num_or_size_splits=2, axis=1)\r\n\r\n      concat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)\r\n\r\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\r\n    i, j, f, o = array_ops.split(value=concat, num_or_size_splits=4, axis=1)\r\n\r\n    new_c = (\r\n        c * sigmoid(f + self._forget_bias) + sigmoid(i) * self._activation(j))\r\n    new_h = self._activation(new_c) * sigmoid(o)\r\n\r\n    if self._state_is_tuple:\r\n      new_state = LSTMStateTuple(new_c, new_h)\r\n    else:\r\n      new_state = array_ops.concat([new_c, new_h], 1)\r\n    return new_h, new_state\r\n```\r\n\r\nlogs are here \r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-21f874a460ec>\", line 1, in <module>\r\n    runfile('C:/Users/Administrator/Test/char_rnn.py', wdir='C:/Users/Administrator/Test')\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 688, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 101, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"C:/Users/Administrator/Test/char_rnn.py\", line 25, in <module>\r\n    final_logits = charRnn(char_seq_batch,seqlen_batch,charsize=charsize,num_rnn=num_layers,rnn_numhidden = rnn_numhidden)\r\n\r\n  File \"C:\\Users\\Administrator\\Test\\networks.py\", line 221, in charRnn\r\n    net, _      = tf.nn.dynamic_rnn(stack, net, seqlen_batch, dtype=tf.float32)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 206, in _rnn_step\r\n    new_output, new_state = call_cell()\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 708, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 917, in call\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 181, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n\r\n  File \"C:\\Users\\Administrator\\Test\\networks.py\", line 167, in call\r\n    concat = _batchlinear(args=[inputs, h], output_size=4 * self._num_units, bias=True)\r\n\r\n  File \"C:\\Users\\Administrator\\Test\\networks.py\", line 80, in _batchlinear\r\n    initializer=kernel_initializer)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1065, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 962, in get_variable\r\n    use_resource=use_resource, custom_getter=custom_getter)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 360, in get_variable\r\n    validate_shape=validate_shape, use_resource=use_resource)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1405, in wrapped_custom_getter\r\n    *args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable\r\n    variable = getter(*args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 184, in _rnn_get_variable\r\n    variable = getter(*args, **kwargs)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 352, in _true_getter\r\n    use_resource=use_resource)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 653, in _get_single_variable\r\n    shape = tensor_shape.as_shape(shape)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 798, in as_shape\r\n    return TensorShape(shape)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in __init__\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 434, in <listcomp>\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 376, in as_dimension\r\n    return Dimension(value)\r\n\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 32, in __init__\r\n    self._value = int(value)\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'"}