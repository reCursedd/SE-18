{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/899", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/899/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/899/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/899/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/899", "id": 129014935, "node_id": "MDU6SXNzdWUxMjkwMTQ5MzU=", "number": 899, "title": "MatMul \"flops\" statistic looks incorrect", "user": {"login": "rdadolf", "id": 6673605, "node_id": "MDQ6VXNlcjY2NzM2MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6673605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdadolf", "html_url": "https://github.com/rdadolf", "followers_url": "https://api.github.com/users/rdadolf/followers", "following_url": "https://api.github.com/users/rdadolf/following{/other_user}", "gists_url": "https://api.github.com/users/rdadolf/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdadolf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdadolf/subscriptions", "organizations_url": "https://api.github.com/users/rdadolf/orgs", "repos_url": "https://api.github.com/users/rdadolf/repos", "events_url": "https://api.github.com/users/rdadolf/events{/privacy}", "received_events_url": "https://api.github.com/users/rdadolf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-01-27T03:12:06Z", "updated_at": "2018-03-28T00:02:23Z", "closed_at": "2016-02-02T00:10:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think the flops estimate for MatMul is incorrect. In a vanilla matrix multiply AB=C with dimensions <code>shape_A=(i,j)</code>, <code>shape_B=(j,k)</code>, and <code>shape_C=(i,k)</code>, we should get ~ <code>2*i*j*k</code>. It appears <code>_calc_mat_mul_flops</code> is giving <code>shape_A[0] * prod(shape_C)</code>, or <code>2*i*i*k</code> for an un-transposed multiply, ignoring the internal dimensions. I believe you meant <code>shape_A[0] * prod(shape_B)</code>. Or if it helps,</p>\n<pre><code>weights_shape = graph_util.tensor_shape_from_node_def_name(graph,node.input[1])\nweights_shape.assert_is_fully_defined()\nweight_count = np.prod(weight_shape.as_list())\nreturn ops.OpStats(\"flops\", (k * weight_count * 2))\n</code></pre>\n<p>Also, here's a minimum working example that demonstrates the problem.</p>\n<pre><code>import tensorflow as tf\nimport tensorflow.python.framework.ops as ops \ng = tf.Graph()\nwith g.as_default():\n  A = tf.Variable(tf.random_normal( [25,16] ))\n  B = tf.Variable(tf.random_normal( [16,9] ))\n  C = tf.matmul(A,B) # shape=[25,9]\nfor op in g.get_operations():\n  flops = ops.get_stats_for_node_def(g, op.node_def, 'flops').value\n  if flops is not None:\n    print 'Flops should be ~',2*25*16*9\n    print '25 x 25 x 9 would be',2*25*25*9 # ignores internal dim, repeats first\n    print 'TF stats gives',flops\n</code></pre>\n<p>And it's output:</p>\n<pre><code>Flops should be ~ 7200\n25 x 25 x 9 would be 11250\nTF stats gives 11250\n</code></pre>", "body_text": "I think the flops estimate for MatMul is incorrect. In a vanilla matrix multiply AB=C with dimensions shape_A=(i,j), shape_B=(j,k), and shape_C=(i,k), we should get ~ 2*i*j*k. It appears _calc_mat_mul_flops is giving shape_A[0] * prod(shape_C), or 2*i*i*k for an un-transposed multiply, ignoring the internal dimensions. I believe you meant shape_A[0] * prod(shape_B). Or if it helps,\nweights_shape = graph_util.tensor_shape_from_node_def_name(graph,node.input[1])\nweights_shape.assert_is_fully_defined()\nweight_count = np.prod(weight_shape.as_list())\nreturn ops.OpStats(\"flops\", (k * weight_count * 2))\n\nAlso, here's a minimum working example that demonstrates the problem.\nimport tensorflow as tf\nimport tensorflow.python.framework.ops as ops \ng = tf.Graph()\nwith g.as_default():\n  A = tf.Variable(tf.random_normal( [25,16] ))\n  B = tf.Variable(tf.random_normal( [16,9] ))\n  C = tf.matmul(A,B) # shape=[25,9]\nfor op in g.get_operations():\n  flops = ops.get_stats_for_node_def(g, op.node_def, 'flops').value\n  if flops is not None:\n    print 'Flops should be ~',2*25*16*9\n    print '25 x 25 x 9 would be',2*25*25*9 # ignores internal dim, repeats first\n    print 'TF stats gives',flops\n\nAnd it's output:\nFlops should be ~ 7200\n25 x 25 x 9 would be 11250\nTF stats gives 11250", "body": "I think the flops estimate for MatMul is incorrect. In a vanilla matrix multiply AB=C with dimensions `shape_A=(i,j)`, `shape_B=(j,k)`, and `shape_C=(i,k)`, we should get ~ `2*i*j*k`. It appears `_calc_mat_mul_flops` is giving `shape_A[0] * prod(shape_C)`, or `2*i*i*k` for an un-transposed multiply, ignoring the internal dimensions. I believe you meant `shape_A[0] * prod(shape_B)`. Or if it helps,\n\n```\nweights_shape = graph_util.tensor_shape_from_node_def_name(graph,node.input[1])\nweights_shape.assert_is_fully_defined()\nweight_count = np.prod(weight_shape.as_list())\nreturn ops.OpStats(\"flops\", (k * weight_count * 2))\n```\n\nAlso, here's a minimum working example that demonstrates the problem.\n\n```\nimport tensorflow as tf\nimport tensorflow.python.framework.ops as ops \ng = tf.Graph()\nwith g.as_default():\n  A = tf.Variable(tf.random_normal( [25,16] ))\n  B = tf.Variable(tf.random_normal( [16,9] ))\n  C = tf.matmul(A,B) # shape=[25,9]\nfor op in g.get_operations():\n  flops = ops.get_stats_for_node_def(g, op.node_def, 'flops').value\n  if flops is not None:\n    print 'Flops should be ~',2*25*16*9\n    print '25 x 25 x 9 would be',2*25*25*9 # ignores internal dim, repeats first\n    print 'TF stats gives',flops\n```\n\nAnd it's output:\n\n```\nFlops should be ~ 7200\n25 x 25 x 9 would be 11250\nTF stats gives 11250\n```\n"}