{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/330684765", "html_url": "https://github.com/tensorflow/tensorflow/pull/13055#issuecomment-330684765", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13055", "id": 330684765, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDY4NDc2NQ==", "user": {"login": "yongtang", "id": 6932348, "node_id": "MDQ6VXNlcjY5MzIzNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6932348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongtang", "html_url": "https://github.com/yongtang", "followers_url": "https://api.github.com/users/yongtang/followers", "following_url": "https://api.github.com/users/yongtang/following{/other_user}", "gists_url": "https://api.github.com/users/yongtang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongtang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongtang/subscriptions", "organizations_url": "https://api.github.com/users/yongtang/orgs", "repos_url": "https://api.github.com/users/yongtang/repos", "events_url": "https://api.github.com/users/yongtang/events{/privacy}", "received_events_url": "https://api.github.com/users/yongtang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-19T21:53:29Z", "updated_at": "2017-09-19T21:53:29Z", "author_association": "MEMBER", "body_html": "<p>Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> for the review. I addressed some of the comments. For using <code>tf.where</code> with <code>reduce_sum</code>, I am still playing with it.</p>\n<p>However, I noticed that at the moment, the behavior of CPU and GPU is actually different. On CPU, negative indices will through out an error while on GPU negative indices will be ignored silently.</p>\n<p>In other words, on GPU the behavior of <code>tf.unsorted_segment_sum</code> is already <code>drop_negatives=True</code> even before this PR.</p>\n<p>I am wondering if it make sense to just adjust the behavior on CPU so that negatives will be dropped?</p>\n<p>This will bring the behavior of GPU and CPU to the same without introducing another flag of <code>drop_negatives=True</code>.</p>\n<p>Below is the output for GPU and CPU without this PR:</p>\n<div class=\"highlight highlight-source-python\"><pre>Python <span class=\"pl-c1\">2.7</span>.12 (default, Nov <span class=\"pl-c1\">19</span> <span class=\"pl-c1\">2016</span>, <span class=\"pl-c1\">0<span class=\"pl-ii\">6</span></span>:<span class=\"pl-c1\">48</span>:<span class=\"pl-c1\">10</span>) \n[<span class=\"pl-c1\">GCC</span> <span class=\"pl-c1\">5.4</span>.0 <span class=\"pl-c1\">20160609</span>] on linux2\nType <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>help<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>copyright<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>credits<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">or</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>license<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">for</span> more information.\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span> tf.<span class=\"pl-c1\">__version__</span>\n<span class=\"pl-c1\">1.3</span>.0\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n<span class=\"pl-c1\">...</span>   v <span class=\"pl-k\">=</span> tf.unsorted_segment_sum([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">KeyboardInterrupt</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> \n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n<span class=\"pl-c1\">...</span> v <span class=\"pl-k\">=</span> tf.unsorted_segment_sum(np.asarray([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np., [<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">KeyboardInterrupt</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> \n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> \n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n<span class=\"pl-c1\">...</span>   <span class=\"pl-v\">v</span> <span class=\"pl-k\">=</span> tf.unsorted_segment_sum([<span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">2.0</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">...</span>   tf.Session().run(v)\n<span class=\"pl-c1\">...</span> \n<span class=\"pl-c1\">...</span>.\narray([ <span class=\"pl-c1\">0</span>.,  <span class=\"pl-c1\">1</span>.,  <span class=\"pl-c1\">0</span>.,  <span class=\"pl-c1\">0</span>.,  <span class=\"pl-c1\">0</span>.], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n<span class=\"pl-c1\">...</span>   <span class=\"pl-v\">v</span> <span class=\"pl-k\">=</span> tf.unsorted_segment_sum([<span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">2.0</span>], [<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">...</span>   tf.Session().run(v)\n<span class=\"pl-c1\">...</span> \n<span class=\"pl-c1\">2017</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">9</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">19</span> <span class=\"pl-c1\">21</span>:<span class=\"pl-c1\">26</span>:<span class=\"pl-c1\">50.961788</span>: I tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device.cc:<span class=\"pl-c1\">1055</span>] Creating TensorFlow device (<span class=\"pl-k\">/</span>device:<span class=\"pl-c1\">GPU</span>:<span class=\"pl-c1\">0</span>) <span class=\"pl-ii\">-&gt;</span> (device: <span class=\"pl-c1\">0</span>, name: Tesla K80, pci bus <span class=\"pl-c1\">id</span>: <span class=\"pl-c1\">0000</span>:<span class=\"pl-c1\">00</span>:<span class=\"pl-ii\">1e</span>.0, compute capability: <span class=\"pl-c1\">3.7</span>)\nTraceback (most recent call last):\n<span class=\"pl-c1\">...</span>\n<span class=\"pl-c1\">...</span>\nInvalidArgumentError (see above <span class=\"pl-k\">for</span> traceback): segment_ids[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span> <span class=\"pl-k\">is</span> out of <span class=\"pl-c1\">range</span> [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">5</span>)\n\t [[Node: UnsortedSegmentSum_1 = UnsortedSegmentSum[T=<span class=\"pl-c1\">DT_FLOAT</span>, Tindices=<span class=\"pl-c1\">DT_INT32</span>, _device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/cpu:0<span class=\"pl-pds\">\"</span></span>](UnsortedSegmentSum_1<span class=\"pl-k\">/</span>data, UnsortedSegmentSum_1<span class=\"pl-k\">/</span>segment_ids, UnsortedSegmentSum_1<span class=\"pl-k\">/</span>num_segments)]]\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> </pre></div>", "body_text": "Thanks @drpngx for the review. I addressed some of the comments. For using tf.where with reduce_sum, I am still playing with it.\nHowever, I noticed that at the moment, the behavior of CPU and GPU is actually different. On CPU, negative indices will through out an error while on GPU negative indices will be ignored silently.\nIn other words, on GPU the behavior of tf.unsorted_segment_sum is already drop_negatives=True even before this PR.\nI am wondering if it make sense to just adjust the behavior on CPU so that negatives will be dropped?\nThis will bring the behavior of GPU and CPU to the same without introducing another flag of drop_negatives=True.\nBelow is the output for GPU and CPU without this PR:\nPython 2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow as tf\n>>> print tf.__version__\n1.3.0\n>>> with tf.device('/gpu:0'):\n...   v = tf.unsorted_segment_sum([1,2], [1, -1], 5)\nKeyboardInterrupt\n>>> \n>>> import numpy as np\n>>> with tf.device('/gpu:0'):\n... v = tf.unsorted_segment_sum(np.asarray([1,2], dtype=np., [1, -1], 5)\nKeyboardInterrupt\n>>> \n>>> \n>>> with tf.device('/gpu:0'):\n...   v = tf.unsorted_segment_sum([1.0, 2.0], [1, -1], 5)\n...   tf.Session().run(v)\n... \n....\narray([ 0.,  1.,  0.,  0.,  0.], dtype=float32)\n>>> with tf.device('/cpu:0'):\n...   v = tf.unsorted_segment_sum([1.0, 2.0], [1, -1], 5)\n...   tf.Session().run(v)\n... \n2017-09-19 21:26:50.961788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\nTraceback (most recent call last):\n...\n...\nInvalidArgumentError (see above for traceback): segment_ids[1] = -1 is out of range [0, 5)\n\t [[Node: UnsortedSegmentSum_1 = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](UnsortedSegmentSum_1/data, UnsortedSegmentSum_1/segment_ids, UnsortedSegmentSum_1/num_segments)]]\n\n>>>", "body": "Thanks @drpngx for the review. I addressed some of the comments. For using `tf.where` with `reduce_sum`, I am still playing with it.\r\n\r\nHowever, I noticed that at the moment, the behavior of CPU and GPU is actually different. On CPU, negative indices will through out an error while on GPU negative indices will be ignored silently.\r\n\r\nIn other words, on GPU the behavior of `tf.unsorted_segment_sum` is already `drop_negatives=True` even before this PR.\r\n\r\nI am wondering if it make sense to just adjust the behavior on CPU so that negatives will be dropped? \r\n\r\nThis will bring the behavior of GPU and CPU to the same without introducing another flag of `drop_negatives=True`.\r\n\r\nBelow is the output for GPU and CPU without this PR:\r\n```python\r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print tf.__version__\r\n1.3.0\r\n>>> with tf.device('/gpu:0'):\r\n...   v = tf.unsorted_segment_sum([1,2], [1, -1], 5)\r\nKeyboardInterrupt\r\n>>> \r\n>>> import numpy as np\r\n>>> with tf.device('/gpu:0'):\r\n... v = tf.unsorted_segment_sum(np.asarray([1,2], dtype=np., [1, -1], 5)\r\nKeyboardInterrupt\r\n>>> \r\n>>> \r\n>>> with tf.device('/gpu:0'):\r\n...   v = tf.unsorted_segment_sum([1.0, 2.0], [1, -1], 5)\r\n...   tf.Session().run(v)\r\n... \r\n....\r\narray([ 0.,  1.,  0.,  0.,  0.], dtype=float32)\r\n>>> with tf.device('/cpu:0'):\r\n...   v = tf.unsorted_segment_sum([1.0, 2.0], [1, -1], 5)\r\n...   tf.Session().run(v)\r\n... \r\n2017-09-19 21:26:50.961788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\nTraceback (most recent call last):\r\n...\r\n...\r\nInvalidArgumentError (see above for traceback): segment_ids[1] = -1 is out of range [0, 5)\r\n\t [[Node: UnsortedSegmentSum_1 = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](UnsortedSegmentSum_1/data, UnsortedSegmentSum_1/segment_ids, UnsortedSegmentSum_1/num_segments)]]\r\n\r\n>>> \r\n```"}