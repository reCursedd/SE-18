{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23196", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23196/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23196/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23196/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23196", "id": 373189776, "node_id": "MDU6SXNzdWUzNzMxODk3NzY=", "number": 23196, "title": "sess.run() returns inconsistent results", "user": {"login": "shyoshyo", "id": 5780122, "node_id": "MDQ6VXNlcjU3ODAxMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/5780122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shyoshyo", "html_url": "https://github.com/shyoshyo", "followers_url": "https://api.github.com/users/shyoshyo/followers", "following_url": "https://api.github.com/users/shyoshyo/following{/other_user}", "gists_url": "https://api.github.com/users/shyoshyo/gists{/gist_id}", "starred_url": "https://api.github.com/users/shyoshyo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shyoshyo/subscriptions", "organizations_url": "https://api.github.com/users/shyoshyo/orgs", "repos_url": "https://api.github.com/users/shyoshyo/repos", "events_url": "https://api.github.com/users/shyoshyo/events{/privacy}", "received_events_url": "https://api.github.com/users/shyoshyo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-10-23T20:35:15Z", "updated_at": "2018-11-23T11:26:23Z", "closed_at": "2018-11-23T11:26:23Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version (use command below): b'v1.10.1-0-g4dcfddc' 1.10.1</li>\n<li>Python version: Python 3.6.6 :: Anaconda, Inc.</li>\n<li>Bazel version (if compiling from source): Build label: 0.16.1</li>\n<li>GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609</li>\n<li>CUDA/cuDNN version: CUDA 8.0, CuDNN 7</li>\n<li>GPU model and memory: GeForce GTX 1080 Ti x 4</li>\n</ul>\n<pre><code>\n== cat /etc/issue ===============================================\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy            1.14.5   \nprotobuf         3.6.1    \ntensorflow       1.10.1   \n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.10.1\ntf.GIT_VERSION = b'v1.10.1-0-g4dcfddc'\ntf.COMPILER_VERSION = b'v1.10.1-0-g4dcfddc'\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Oct 24 04:18:19 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |\n| 47%   67C    P0    80W / 250W |    144MiB / 11175MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n| 76%   87C    P2   152W / 250W |   8428MiB / 11178MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n| 43%   64C    P2    81W / 250W |   4774MiB / 11178MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n| 26%   43C    P0    73W / 250W |     12MiB / 11178MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1426      G   /usr/lib/xorg/Xorg                            51MiB |\n|    0      3507      G   /usr/lib/xorg/Xorg                            14MiB |\n|    1      9564      C   python                                      5133MiB |\n|    1     14381      C   /home/***/torch/install/bin/luajit         3283MiB |\n|    2      7595      C   python                                      4611MiB |\n|    2     12553      C   python                                       151MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-5d6d23a3.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n\n</code></pre>\n<p><strong>Describe the current behavior</strong><br>\nConsider following two source codes</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nimg <span class=\"pl-k\">=</span> tf.random_normal((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>)\nmask <span class=\"pl-k\">=</span> tf.random_normal((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>)\n\nnormalization_factor <span class=\"pl-k\">=</span> tf.reduce_sum(mask) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">3</span>\nmasked_img <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> mask\nmasked_img_sqr <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> masked_img <span class=\"pl-c\"><span class=\"pl-c\">#</span> = img ^ 2 * mask</span>\n\nmean <span class=\"pl-k\">=</span> tf.reduce_sum(masked_img) <span class=\"pl-k\">/</span> normalization_factor\nvariance <span class=\"pl-k\">=</span> tf.reduce_sum(masked_img_sqr) <span class=\"pl-k\">/</span> normalization_factor\nvariance <span class=\"pl-k\">=</span> variance <span class=\"pl-k\">-</span> tf.square(mean)\nadjusted_variance <span class=\"pl-k\">=</span> tf.maximum(variance, <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> normalization_factor)\nstddev <span class=\"pl-k\">=</span> tf.sqrt(variance)\n\nimg <span class=\"pl-k\">=</span> (img <span class=\"pl-k\">-</span> mean) <span class=\"pl-k\">/</span> stddev\nwhiten_img <span class=\"pl-k\">=</span> img\n\nrand <span class=\"pl-k\">=</span> tf.random_normal(\n    <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>),\n    <span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>., <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>., <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n    <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>random_back<span class=\"pl-pds\">'</span></span>)\nimg <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> mask <span class=\"pl-k\">+</span> rand <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> mask)\n\nimg <span class=\"pl-k\">=</span> tf.concat([img, mask], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n\n\ndebug_info <span class=\"pl-k\">=</span> {\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>mean<span class=\"pl-pds\">'</span></span>: mean,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>variance<span class=\"pl-pds\">'</span></span>: variance,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>stddev<span class=\"pl-pds\">'</span></span>: stddev,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>adjusted_variance<span class=\"pl-pds\">'</span></span>: adjusted_variance,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>threshold<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> normalization_factor,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>normalization_factor<span class=\"pl-pds\">'</span></span>: normalization_factor,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>whiten_img_minmax<span class=\"pl-pds\">'</span></span>: [tf.reduce_min(whiten_img[<span class=\"pl-c1\">...</span>, :<span class=\"pl-c1\">3</span>]), tf.reduce_max(whiten_img[<span class=\"pl-c1\">...</span>, :<span class=\"pl-c1\">3</span>])],\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>minmax_mask<span class=\"pl-pds\">'</span></span>: [tf.reduce_min(img[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>]), tf.reduce_max(img[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>])],\n}\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  <span class=\"pl-c1\">print</span>(sess.run(debug_info))</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nimg <span class=\"pl-k\">=</span> tf.random_normal((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>)\nmask <span class=\"pl-k\">=</span> tf.random_normal((<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>)\n\nnormalization_factor <span class=\"pl-k\">=</span> tf.reduce_sum(mask) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">3</span>\nmasked_img <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> mask\nmasked_img_sqr <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> masked_img <span class=\"pl-c\"><span class=\"pl-c\">#</span> = img ^ 2 * mask</span>\n\nmean <span class=\"pl-k\">=</span> tf.reduce_sum(masked_img) <span class=\"pl-k\">/</span> normalization_factor\nvariance <span class=\"pl-k\">=</span> tf.reduce_sum(masked_img_sqr) <span class=\"pl-k\">/</span> normalization_factor\nvariance <span class=\"pl-k\">=</span> variance <span class=\"pl-k\">-</span> tf.square(mean)\nadjusted_variance <span class=\"pl-k\">=</span> tf.maximum(variance, <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> normalization_factor)\nstddev <span class=\"pl-k\">=</span> tf.sqrt(variance)\n\nimg <span class=\"pl-k\">=</span> (img <span class=\"pl-k\">-</span> mean) <span class=\"pl-k\">/</span> stddev\nwhiten_img <span class=\"pl-k\">=</span> img\n\nrand <span class=\"pl-k\">=</span> tf.random_normal(\n    <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>),\n    <span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>., <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>., <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n    <span class=\"pl-v\">seed</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12345</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>random_back<span class=\"pl-pds\">'</span></span>)\nimg <span class=\"pl-k\">=</span> img <span class=\"pl-k\">*</span> mask <span class=\"pl-k\">+</span> rand <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> mask)\n\nimg <span class=\"pl-k\">=</span> tf.concat([img, mask], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n\n\ndebug_info <span class=\"pl-k\">=</span> {\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>mean<span class=\"pl-pds\">'</span></span>: mean,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>variance<span class=\"pl-pds\">'</span></span>: variance,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>stddev<span class=\"pl-pds\">'</span></span>: stddev <span class=\"pl-k\">+</span> <span class=\"pl-c1\">0</span>,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>adjusted_variance<span class=\"pl-pds\">'</span></span>: adjusted_variance,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>threshold<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> normalization_factor,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>normalization_factor<span class=\"pl-pds\">'</span></span>: normalization_factor,\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>whiten_img_minmax<span class=\"pl-pds\">'</span></span>: [tf.reduce_min(whiten_img[<span class=\"pl-c1\">...</span>, :<span class=\"pl-c1\">3</span>]), tf.reduce_max(whiten_img[<span class=\"pl-c1\">...</span>, :<span class=\"pl-c1\">3</span>])],\n  <span class=\"pl-s\"><span class=\"pl-pds\">'</span>minmax_mask<span class=\"pl-pds\">'</span></span>: [tf.reduce_min(img[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>]), tf.reduce_max(img[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>])],\n}\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  <span class=\"pl-c1\">print</span>(sess.run(debug_info))</pre></div>\n<p>The only difference between them is <code>'stddev': stddev,</code> and <code>'stddev': stddev + 0,</code></p>\n<p>But the first code (with <code>'stddev': stddev,</code>) outputs</p>\n<pre><code>{..., 'stddev': 1.1902559, ...}\n</code></pre>\n<p>and the second (with <code>'stddev': stddev + 0,</code>) outputs</p>\n<pre><code>{..., 'stddev': 0.8401555, ...}\n</code></pre>\n<p>It seems like that the correct output is <code>'stddev': 0.8401555,</code><br>\nBut in the first code, <code>1./stddev = 1./0.8401555 = 1.1902559</code> was calculated</p>\n<p>Here is the screenshot<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5780122/47388961-15e7de80-d746-11e8-8959-f37c46e66c8b.png\"><img src=\"https://user-images.githubusercontent.com/5780122/47388961-15e7de80-d746-11e8-8959-f37c46e66c8b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>The outputs of two codes should be correct (consistent at least)</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<p><strong>Other info / logs</strong></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): b'v1.10.1-0-g4dcfddc' 1.10.1\nPython version: Python 3.6.6 :: Anaconda, Inc.\nBazel version (if compiling from source): Build label: 0.16.1\nGCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCUDA/cuDNN version: CUDA 8.0, CuDNN 7\nGPU model and memory: GeForce GTX 1080 Ti x 4\n\n\n== cat /etc/issue ===============================================\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy            1.14.5   \nprotobuf         3.6.1    \ntensorflow       1.10.1   \n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.10.1\ntf.GIT_VERSION = b'v1.10.1-0-g4dcfddc'\ntf.COMPILER_VERSION = b'v1.10.1-0-g4dcfddc'\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nWed Oct 24 04:18:19 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |\n| 47%   67C    P0    80W / 250W |    144MiB / 11175MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n| 76%   87C    P2   152W / 250W |   8428MiB / 11178MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n| 43%   64C    P2    81W / 250W |   4774MiB / 11178MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n| 26%   43C    P0    73W / 250W |     12MiB / 11178MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1426      G   /usr/lib/xorg/Xorg                            51MiB |\n|    0      3507      G   /usr/lib/xorg/Xorg                            14MiB |\n|    1      9564      C   python                                      5133MiB |\n|    1     14381      C   /home/***/torch/install/bin/luajit         3283MiB |\n|    2      7595      C   python                                      4611MiB |\n|    2     12553      C   python                                       151MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-5d6d23a3.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n\n\nDescribe the current behavior\nConsider following two source codes\nimport tensorflow as tf\n\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\n\nnormalization_factor = tf.reduce_sum(mask) * 3\nmasked_img = img * mask\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\n\nmean = tf.reduce_sum(masked_img) / normalization_factor\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\nvariance = variance - tf.square(mean)\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\nstddev = tf.sqrt(variance)\n\nimg = (img - mean) / stddev\nwhiten_img = img\n\nrand = tf.random_normal(\n    shape=(10, 10, 3),\n    mean=0., stddev=1., dtype=tf.float32,\n    seed=12345, name='random_back')\nimg = img * mask + rand * (1 - mask)\n\nimg = tf.concat([img, mask], axis=-1)\n\n\ndebug_info = {\n  'mean': mean,\n  'variance': variance,\n  'stddev': stddev,\n  'adjusted_variance': adjusted_variance,\n  'threshold': 1. / normalization_factor,\n  'normalization_factor': normalization_factor,\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\n}\n\nwith tf.Session() as sess:\n  print(sess.run(debug_info))\nimport tensorflow as tf\n\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\n\nnormalization_factor = tf.reduce_sum(mask) * 3\nmasked_img = img * mask\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\n\nmean = tf.reduce_sum(masked_img) / normalization_factor\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\nvariance = variance - tf.square(mean)\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\nstddev = tf.sqrt(variance)\n\nimg = (img - mean) / stddev\nwhiten_img = img\n\nrand = tf.random_normal(\n    shape=(10, 10, 3),\n    mean=0., stddev=1., dtype=tf.float32,\n    seed=12345, name='random_back')\nimg = img * mask + rand * (1 - mask)\n\nimg = tf.concat([img, mask], axis=-1)\n\n\ndebug_info = {\n  'mean': mean,\n  'variance': variance,\n  'stddev': stddev + 0,\n  'adjusted_variance': adjusted_variance,\n  'threshold': 1. / normalization_factor,\n  'normalization_factor': normalization_factor,\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\n}\n\nwith tf.Session() as sess:\n  print(sess.run(debug_info))\nThe only difference between them is 'stddev': stddev, and 'stddev': stddev + 0,\nBut the first code (with 'stddev': stddev,) outputs\n{..., 'stddev': 1.1902559, ...}\n\nand the second (with 'stddev': stddev + 0,) outputs\n{..., 'stddev': 0.8401555, ...}\n\nIt seems like that the correct output is 'stddev': 0.8401555,\nBut in the first code, 1./stddev = 1./0.8401555 = 1.1902559 was calculated\nHere is the screenshot\n\nDescribe the expected behavior\nThe outputs of two codes should be correct (consistent at least)\nCode to reproduce the issue\nOther info / logs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): b'v1.10.1-0-g4dcfddc' 1.10.1\r\n- Python version: Python 3.6.6 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source): Build label: 0.16.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- CUDA/cuDNN version: CUDA 8.0, CuDNN 7\r\n- GPU model and memory: GeForce GTX 1080 Ti x 4\r\n\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy            1.14.5   \r\nprotobuf         3.6.1    \r\ntensorflow       1.10.1   \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.1\r\ntf.GIT_VERSION = b'v1.10.1-0-g4dcfddc'\r\ntf.COMPILER_VERSION = b'v1.10.1-0-g4dcfddc'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Oct 24 04:18:19 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |\r\n| 47%   67C    P0    80W / 250W |    144MiB / 11175MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\r\n| 76%   87C    P2   152W / 250W |   8428MiB / 11178MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n| 43%   64C    P2    81W / 250W |   4774MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\r\n| 26%   43C    P0    73W / 250W |     12MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1426      G   /usr/lib/xorg/Xorg                            51MiB |\r\n|    0      3507      G   /usr/lib/xorg/Xorg                            14MiB |\r\n|    1      9564      C   python                                      5133MiB |\r\n|    1     14381      C   /home/***/torch/install/bin/luajit         3283MiB |\r\n|    2      7595      C   python                                      4611MiB |\r\n|    2     12553      C   python                                       151MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-5d6d23a3.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n\r\n```\r\n\r\n**Describe the current behavior**\r\nConsider following two source codes\r\n```Python\r\nimport tensorflow as tf\r\n\r\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\r\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\n\r\nnormalization_factor = tf.reduce_sum(mask) * 3\r\nmasked_img = img * mask\r\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\r\n\r\nmean = tf.reduce_sum(masked_img) / normalization_factor\r\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\r\nvariance = variance - tf.square(mean)\r\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\r\nstddev = tf.sqrt(variance)\r\n\r\nimg = (img - mean) / stddev\r\nwhiten_img = img\r\n\r\nrand = tf.random_normal(\r\n    shape=(10, 10, 3),\r\n    mean=0., stddev=1., dtype=tf.float32,\r\n    seed=12345, name='random_back')\r\nimg = img * mask + rand * (1 - mask)\r\n\r\nimg = tf.concat([img, mask], axis=-1)\r\n\r\n\r\ndebug_info = {\r\n  'mean': mean,\r\n  'variance': variance,\r\n  'stddev': stddev,\r\n  'adjusted_variance': adjusted_variance,\r\n  'threshold': 1. / normalization_factor,\r\n  'normalization_factor': normalization_factor,\r\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\r\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\r\n}\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(debug_info))\r\n```\r\n\r\n```Python\r\nimport tensorflow as tf\r\n\r\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\r\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\n\r\nnormalization_factor = tf.reduce_sum(mask) * 3\r\nmasked_img = img * mask\r\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\r\n\r\nmean = tf.reduce_sum(masked_img) / normalization_factor\r\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\r\nvariance = variance - tf.square(mean)\r\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\r\nstddev = tf.sqrt(variance)\r\n\r\nimg = (img - mean) / stddev\r\nwhiten_img = img\r\n\r\nrand = tf.random_normal(\r\n    shape=(10, 10, 3),\r\n    mean=0., stddev=1., dtype=tf.float32,\r\n    seed=12345, name='random_back')\r\nimg = img * mask + rand * (1 - mask)\r\n\r\nimg = tf.concat([img, mask], axis=-1)\r\n\r\n\r\ndebug_info = {\r\n  'mean': mean,\r\n  'variance': variance,\r\n  'stddev': stddev + 0,\r\n  'adjusted_variance': adjusted_variance,\r\n  'threshold': 1. / normalization_factor,\r\n  'normalization_factor': normalization_factor,\r\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\r\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\r\n}\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(debug_info))\r\n```\r\n\r\nThe only difference between them is `'stddev': stddev,` and `'stddev': stddev + 0,`\r\n\r\nBut the first code (with `'stddev': stddev,`) outputs\r\n```\r\n{..., 'stddev': 1.1902559, ...}\r\n```\r\nand the second (with `'stddev': stddev + 0,`) outputs\r\n```\r\n{..., 'stddev': 0.8401555, ...}\r\n```\r\n\r\nIt seems like that the correct output is `'stddev': 0.8401555,`\r\nBut in the first code, `1./stddev = 1./0.8401555 = 1.1902559` was calculated\r\n\r\nHere is the screenshot\r\n![image](https://user-images.githubusercontent.com/5780122/47388961-15e7de80-d746-11e8-8959-f37c46e66c8b.png)\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe outputs of two codes should be correct (consistent at least) \r\n\r\n**Code to reproduce the issue**\r\n\r\n**Other info / logs**\r\n"}