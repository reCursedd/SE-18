{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/78411582", "pull_request_review_id": null, "id": 78411582, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc4NDExNTgy", "diff_hunk": "@@ -810,5 +810,27 @@ def testInitFromCheckpointWithScopes(self):\n       self.assertAllEqual(init_value0, var0.eval())\n       self.assertAllEqual(init_value1, var1.eval())\n \n+class ZeroInitializerOpTest(tf.test.TestCase):\n+\n+  def _testZeroInitializer(self, shape, dtype):\n+    var0 = tf.Variable(tf.zeros(shape, dtype=dtype))\n+    var1 = tf.Variable(tf.ones(shape, dtype=dtype))\n+    var0_zero = tf.contrib.framework.zero_initializer(var0)\n+    var1_zero = tf.contrib.framework.zero_initializer(var1)", "path": "tensorflow/contrib/framework/python/ops/variables_test.py", "position": null, "original_position": 10, "commit_id": "32f95e65a29c60629b8ae0b9db2891d50c8f1c1b", "original_commit_id": "3b33a6518b3550e60f325b8f1390f70f264680b9", "user": {"login": "suiyuan2009", "id": 5105569, "node_id": "MDQ6VXNlcjUxMDU1Njk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5105569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suiyuan2009", "html_url": "https://github.com/suiyuan2009", "followers_url": "https://api.github.com/users/suiyuan2009/followers", "following_url": "https://api.github.com/users/suiyuan2009/following{/other_user}", "gists_url": "https://api.github.com/users/suiyuan2009/gists{/gist_id}", "starred_url": "https://api.github.com/users/suiyuan2009/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suiyuan2009/subscriptions", "organizations_url": "https://api.github.com/users/suiyuan2009/orgs", "repos_url": "https://api.github.com/users/suiyuan2009/repos", "events_url": "https://api.github.com/users/suiyuan2009/events{/privacy}", "received_events_url": "https://api.github.com/users/suiyuan2009/received_events", "type": "User", "site_admin": false}, "body": "you can read mrry's comment, because tf.Variable will assign init_var to var, and the two tensors will stay in memory.\n\n\u53d1\u81ea\u6211\u7684 iPhone\n\n> \u5728 2016\u5e749\u670813\u65e5\uff0c\u4e0a\u534812:32\uff0cAlexandre Passos notifications@github.com \u5199\u9053\uff1a\n> \n> In tensorflow/contrib/framework/python/ops/variables_test.py:\n> \n> > @@ -810,5 +810,27 @@ def testInitFromCheckpointWithScopes(self):\n> >        self.assertAllEqual(init_value0, var0.eval())\n> >        self.assertAllEqual(init_value1, var1.eval())\n> > \n> > +class ZeroInitializerOpTest(tf.test.TestCase):\n> > +\n> > -  def _testZeroInitializer(self, shape, dtype):\n> > -    var0 = tf.Variable(tf.zeros(shape, dtype=dtype))\n> > -    var1 = tf.Variable(tf.ones(shape, dtype=dtype))\n> > -    var0_zero = tf.contrib.framework.zero_initializer(var0)\n> > -    var1_zero = tf.contrib.framework.zero_initializer(var1)\n> >   It doesn't have to if zero_initializer is the op you wrote; the op passed to tf.Variable is just added to the initializers graph collection so it is run by tf.initialize_all_variables(). If it doesn't create any additional storage (and the op you wrote doesn't) then you should be fine.\n> \n> I also think we should test the memory usage by turning tracing on in the RunOptions and examining the step_stats.dev_stats.node_stats.allocator_used_memory.peak_bytes. That way the unit test will protect the code from changes which break this important property.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "created_at": "2016-09-12T17:01:38Z", "updated_at": "2016-09-27T10:47:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4077#discussion_r78411582", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4077", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/78411582"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4077#discussion_r78411582"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4077"}}, "body_html": "<p>you can read mrry's comment, because tf.Variable will assign init_var to var, and the two tensors will stay in memory.</p>\n<p>\u53d1\u81ea\u6211\u7684 iPhone</p>\n<blockquote>\n<p>\u5728 2016\u5e749\u670813\u65e5\uff0c\u4e0a\u534812:32\uff0cAlexandre Passos <a href=\"mailto:notifications@github.com\">notifications@github.com</a> \u5199\u9053\uff1a</p>\n<p>In tensorflow/contrib/framework/python/ops/variables_test.py:</p>\n<blockquote>\n<p>@@ -810,5 +810,27 @@ def testInitFromCheckpointWithScopes(self):<br>\nself.assertAllEqual(init_value0, var0.eval())<br>\nself.assertAllEqual(init_value1, var1.eval())</p>\n<p>+class ZeroInitializerOpTest(tf.test.TestCase):<br>\n+</p>\n<ul>\n<li>def _testZeroInitializer(self, shape, dtype):</li>\n<li>var0 = tf.Variable(tf.zeros(shape, dtype=dtype))</li>\n<li>var1 = tf.Variable(tf.ones(shape, dtype=dtype))</li>\n<li>var0_zero = tf.contrib.framework.zero_initializer(var0)</li>\n<li>var1_zero = tf.contrib.framework.zero_initializer(var1)<br>\nIt doesn't have to if zero_initializer is the op you wrote; the op passed to tf.Variable is just added to the initializers graph collection so it is run by tf.initialize_all_variables(). If it doesn't create any additional storage (and the op you wrote doesn't) then you should be fine.</li>\n</ul>\n</blockquote>\n<p>I also think we should test the memory usage by turning tracing on in the RunOptions and examining the step_stats.dev_stats.node_stats.allocator_used_memory.peak_bytes. That way the unit test will protect the code from changes which break this important property.</p>\n<p>\u2014<br>\nYou are receiving this because you were mentioned.<br>\nReply to this email directly, view it on GitHub, or mute the thread.</p>\n</blockquote>", "body_text": "you can read mrry's comment, because tf.Variable will assign init_var to var, and the two tensors will stay in memory.\n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e749\u670813\u65e5\uff0c\u4e0a\u534812:32\uff0cAlexandre Passos notifications@github.com \u5199\u9053\uff1a\nIn tensorflow/contrib/framework/python/ops/variables_test.py:\n\n@@ -810,5 +810,27 @@ def testInitFromCheckpointWithScopes(self):\nself.assertAllEqual(init_value0, var0.eval())\nself.assertAllEqual(init_value1, var1.eval())\n+class ZeroInitializerOpTest(tf.test.TestCase):\n+\n\ndef _testZeroInitializer(self, shape, dtype):\nvar0 = tf.Variable(tf.zeros(shape, dtype=dtype))\nvar1 = tf.Variable(tf.ones(shape, dtype=dtype))\nvar0_zero = tf.contrib.framework.zero_initializer(var0)\nvar1_zero = tf.contrib.framework.zero_initializer(var1)\nIt doesn't have to if zero_initializer is the op you wrote; the op passed to tf.Variable is just added to the initializers graph collection so it is run by tf.initialize_all_variables(). If it doesn't create any additional storage (and the op you wrote doesn't) then you should be fine.\n\n\nI also think we should test the memory usage by turning tracing on in the RunOptions and examining the step_stats.dev_stats.node_stats.allocator_used_memory.peak_bytes. That way the unit test will protect the code from changes which break this important property.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.", "in_reply_to_id": 78406229}