{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3600", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3600/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3600/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3600/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3600", "id": 168686262, "node_id": "MDU6SXNzdWUxNjg2ODYyNjI=", "number": 3600, "title": "failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED", "user": {"login": "mccajm", "id": 3830784, "node_id": "MDQ6VXNlcjM4MzA3ODQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/3830784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mccajm", "html_url": "https://github.com/mccajm", "followers_url": "https://api.github.com/users/mccajm/followers", "following_url": "https://api.github.com/users/mccajm/following{/other_user}", "gists_url": "https://api.github.com/users/mccajm/gists{/gist_id}", "starred_url": "https://api.github.com/users/mccajm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mccajm/subscriptions", "organizations_url": "https://api.github.com/users/mccajm/orgs", "repos_url": "https://api.github.com/users/mccajm/repos", "events_url": "https://api.github.com/users/mccajm/events{/privacy}", "received_events_url": "https://api.github.com/users/mccajm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-08-01T16:23:43Z", "updated_at": "2017-12-27T19:22:46Z", "closed_at": "2016-08-12T16:46:28Z", "author_association": "NONE", "body_html": "<p>With the current master branch I receive the following error 20% of the time when training an RNN.</p>\n<blockquote>\n<p>I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:<br>\nname: GeForce GTX TITAN X<br>\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076<br>\npciBusID 0000:83:00.0<br>\nTotal memory: 12.00GiB<br>\nFree memory: 11.86GiB<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0<br>\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)<br>\nE tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED<br>\nW tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support<br>\nI tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60<br>\nI tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nI tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12<br>\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]<br>\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU-&gt;GPU Memcpy failed</p>\n</blockquote>\n<h3>Environment info</h3>\n<p>Scientific Linux 7<br>\ncuda 7.5.18<br>\ncudnn 5.0.5</p>\n<p>$ bazel version<br>\n....<br>\nBuild label: 0.3.0<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)<br>\nBuild timestamp: 1465558703<br>\nBuild timestamp as int: 1465558703<br>\n$ git rev-parse HEAD<br>\n<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/88d9bc16d6a16e5b660cda548b74944f27ddcd1b/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/88d9bc16d6a16e5b660cda548b74944f27ddcd1b\"><tt>88d9bc1</tt></a></p>\n<p>$ nvidia-smi -L<br>\nGPU 0: GeForce GTX TITAN X</p>", "body_text": "With the current master branch I receive the following error 20% of the time when training an RNN.\n\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:83:00.0\nTotal memory: 12.00GiB\nFree memory: 11.86GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)\nE tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\nW tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support\nI tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60\nI tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nI tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nW tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU->GPU Memcpy failed\n\nEnvironment info\nScientific Linux 7\ncuda 7.5.18\ncudnn 5.0.5\n$ bazel version\n....\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n$ git rev-parse HEAD\n88d9bc1\n$ nvidia-smi -L\nGPU 0: GeForce GTX TITAN X", "body": "With the current master branch I receive the following error 20% of the time when training an RNN.\n\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: GeForce GTX TITAN X\n> major: 5 minor: 2 memoryClockRate (GHz) 1.076\n> pciBusID 0000:83:00.0\n> Total memory: 12.00GiB\n> Free memory: 11.86GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)\n> E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n> W tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support\n> I tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60\n> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> F tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU->GPU Memcpy failed\n### Environment info\n\nScientific Linux 7\ncuda 7.5.18\ncudnn 5.0.5\n\n$ bazel version\n....\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n$ git rev-parse HEAD\n88d9bc16d6a16e5b660cda548b74944f27ddcd1b\n\n$ nvidia-smi -L\nGPU 0: GeForce GTX TITAN X\n"}