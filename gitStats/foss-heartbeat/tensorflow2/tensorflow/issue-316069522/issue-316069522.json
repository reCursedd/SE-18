{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18708", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18708/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18708/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18708/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18708", "id": 316069522, "node_id": "MDU6SXNzdWUzMTYwNjk1MjI=", "number": 18708, "title": "Placeholder shape checking inside tf.cond not properly enforced", "user": {"login": "Novak3", "id": 2293807, "node_id": "MDQ6VXNlcjIyOTM4MDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2293807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Novak3", "html_url": "https://github.com/Novak3", "followers_url": "https://api.github.com/users/Novak3/followers", "following_url": "https://api.github.com/users/Novak3/following{/other_user}", "gists_url": "https://api.github.com/users/Novak3/gists{/gist_id}", "starred_url": "https://api.github.com/users/Novak3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Novak3/subscriptions", "organizations_url": "https://api.github.com/users/Novak3/orgs", "repos_url": "https://api.github.com/users/Novak3/repos", "events_url": "https://api.github.com/users/Novak3/events{/privacy}", "received_events_url": "https://api.github.com/users/Novak3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-19T23:00:05Z", "updated_at": "2018-05-17T21:59:49Z", "closed_at": "2018-05-17T21:59:49Z", "author_association": "NONE", "body_html": "<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Tensorflow 1.7 Docker under CentOS 7.3</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Tensorflow 1.7 Docker</li>\n<li><strong>TensorFlow version (use command below)</strong>:  1.7</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:  N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0</li>\n<li><strong>GPU model and memory</strong>: Quadro M4000</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When a placeholder is defined in a tf.cond statement, shape checking is not enforced until the merge, and ends up being only rank checking.</p>\n<h3>Source code / logs</h3>\n<p>Consider the following toy graph/session, developed in the pursuit of a larger issue.  I suspect this entire approach of trying to have differently shaped placeholders is doomed to failure.  But, the graph produced clearly shows placeholders of appropriate shape inside the conditional; shows appropriately sized tensors flowing into the merge, but shows the merge itself as shape (?,?) and that is where the shape checking happens.  As a result, you can put just about any rank two tensor in and set the boolean to anything you like and tensorflow doesn't care.</p>\n<p>Heck, you can make another op completely outside the conditional to compute matmul (a, matrix_inverse(a)) and it'll chug merrily along.</p>\n<p>Is this the desired behavior?</p>\n<pre><code>with graph.as_default():\n    pred   = tf.placeholder(tf.bool, shape=[])\n\n    def fnTrue():\n        a      = tf.placeholder(tf.float32, shape=[5, 1], name=\"column\")\n        return a\n\n    def fnFalse():\n        a      = tf.placeholder(tf.float32, shape=[1, 5], name=\"row\")\n        return a\n\n    a = tf.cond(pred, fnTrue, fnFalse, name=\"my_conditional\")\ngraphWriter = tf.summary.FileWriter(logdir='logdir', graph=graph)\ngraphWriter.flush()\n\nwith tf.Session(graph=graph) as session:\n    writer_graph         = tf.summary.FileWriter(LogPath , session.graph)\n    writer_graph.flush()\n    writer_graph.close()\n    plTrue       = np.ones((15, 2)) * 2     # column\n    plFalse      = np.ones((12, 15)) * 3     # row\n    feed_dict = {\n        a            : plTrue,\n        pred         : False\n    }\n\n    d = session.run( a , feed_dict = feed_dict)\n    print(d)\n    print(d.shape)\n</code></pre>", "body_text": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tensorflow 1.7 Docker under CentOS 7.3\nTensorFlow installed from (source or binary): Tensorflow 1.7 Docker\nTensorFlow version (use command below):  1.7\nPython version: 3.6\nBazel version (if compiling from source):  N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0\nGPU model and memory: Quadro M4000\nExact command to reproduce:\n\nDescribe the problem\nWhen a placeholder is defined in a tf.cond statement, shape checking is not enforced until the merge, and ends up being only rank checking.\nSource code / logs\nConsider the following toy graph/session, developed in the pursuit of a larger issue.  I suspect this entire approach of trying to have differently shaped placeholders is doomed to failure.  But, the graph produced clearly shows placeholders of appropriate shape inside the conditional; shows appropriately sized tensors flowing into the merge, but shows the merge itself as shape (?,?) and that is where the shape checking happens.  As a result, you can put just about any rank two tensor in and set the boolean to anything you like and tensorflow doesn't care.\nHeck, you can make another op completely outside the conditional to compute matmul (a, matrix_inverse(a)) and it'll chug merrily along.\nIs this the desired behavior?\nwith graph.as_default():\n    pred   = tf.placeholder(tf.bool, shape=[])\n\n    def fnTrue():\n        a      = tf.placeholder(tf.float32, shape=[5, 1], name=\"column\")\n        return a\n\n    def fnFalse():\n        a      = tf.placeholder(tf.float32, shape=[1, 5], name=\"row\")\n        return a\n\n    a = tf.cond(pred, fnTrue, fnFalse, name=\"my_conditional\")\ngraphWriter = tf.summary.FileWriter(logdir='logdir', graph=graph)\ngraphWriter.flush()\n\nwith tf.Session(graph=graph) as session:\n    writer_graph         = tf.summary.FileWriter(LogPath , session.graph)\n    writer_graph.flush()\n    writer_graph.close()\n    plTrue       = np.ones((15, 2)) * 2     # column\n    plFalse      = np.ones((12, 15)) * 3     # row\n    feed_dict = {\n        a            : plTrue,\n        pred         : False\n    }\n\n    d = session.run( a , feed_dict = feed_dict)\n    print(d)\n    print(d.shape)", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Tensorflow 1.7 Docker under CentOS 7.3\r\n- **TensorFlow installed from (source or binary)**: Tensorflow 1.7 Docker\r\n- **TensorFlow version (use command below)**:  1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:  N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: Quadro M4000\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen a placeholder is defined in a tf.cond statement, shape checking is not enforced until the merge, and ends up being only rank checking.\r\n\r\n### Source code / logs\r\n Consider the following toy graph/session, developed in the pursuit of a larger issue.  I suspect this entire approach of trying to have differently shaped placeholders is doomed to failure.  But, the graph produced clearly shows placeholders of appropriate shape inside the conditional; shows appropriately sized tensors flowing into the merge, but shows the merge itself as shape (?,?) and that is where the shape checking happens.  As a result, you can put just about any rank two tensor in and set the boolean to anything you like and tensorflow doesn't care. \r\n\r\nHeck, you can make another op completely outside the conditional to compute matmul (a, matrix_inverse(a)) and it'll chug merrily along. \r\n\r\nIs this the desired behavior?  \r\n\r\n\r\n```\r\nwith graph.as_default():\r\n    pred   = tf.placeholder(tf.bool, shape=[])\r\n\r\n    def fnTrue():\r\n        a      = tf.placeholder(tf.float32, shape=[5, 1], name=\"column\")\r\n        return a\r\n\r\n    def fnFalse():\r\n        a      = tf.placeholder(tf.float32, shape=[1, 5], name=\"row\")\r\n        return a\r\n\r\n    a = tf.cond(pred, fnTrue, fnFalse, name=\"my_conditional\")\r\ngraphWriter = tf.summary.FileWriter(logdir='logdir', graph=graph)\r\ngraphWriter.flush()\r\n\r\nwith tf.Session(graph=graph) as session:\r\n    writer_graph         = tf.summary.FileWriter(LogPath , session.graph)\r\n    writer_graph.flush()\r\n    writer_graph.close()\r\n    plTrue       = np.ones((15, 2)) * 2     # column\r\n    plFalse      = np.ones((12, 15)) * 3     # row\r\n    feed_dict = {\r\n        a            : plTrue,\r\n        pred         : False\r\n    }\r\n\r\n    d = session.run( a , feed_dict = feed_dict)\r\n    print(d)\r\n    print(d.shape)\r\n```"}