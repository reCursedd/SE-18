{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/593", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/593/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/593/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/593/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/593", "id": 123597444, "node_id": "MDU6SXNzdWUxMjM1OTc0NDQ=", "number": 593, "title": "TensorArray failure with automatic gradient computation for nested scan/map_fn/fold", "user": {"login": "trubin", "id": 890936, "node_id": "MDQ6VXNlcjg5MDkzNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/890936?v=4", "gravatar_id": "", "url": "https://api.github.com/users/trubin", "html_url": "https://github.com/trubin", "followers_url": "https://api.github.com/users/trubin/followers", "following_url": "https://api.github.com/users/trubin/following{/other_user}", "gists_url": "https://api.github.com/users/trubin/gists{/gist_id}", "starred_url": "https://api.github.com/users/trubin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/trubin/subscriptions", "organizations_url": "https://api.github.com/users/trubin/orgs", "repos_url": "https://api.github.com/users/trubin/repos", "events_url": "https://api.github.com/users/trubin/events{/privacy}", "received_events_url": "https://api.github.com/users/trubin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 30, "created_at": "2015-12-23T03:41:18Z", "updated_at": "2018-03-08T14:47:27Z", "closed_at": "2016-06-17T03:36:29Z", "author_association": "NONE", "body_html": "<p>I drew up this simple example to show that nested While gradient computation fails in the python interface (as the gradContext for the forwardContext of the second input of the Add op is None). Toggling the comment demonstrates the issue is not with all control flow graphs.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.ops <span class=\"pl-k\">import</span> control_flow_ops\n\n<span class=\"pl-c1\">OUTER_LOOP_MAX</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n<span class=\"pl-c1\">INNER_LOOP_MAX</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\n\ninner <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>float32<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">INNER_LOOP_MAX</span>])\nouter <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>float32<span class=\"pl-pds\">\"</span></span>, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">OUTER_LOOP_MAX</span>])\n\nX <span class=\"pl-k\">=</span> tf.Variable(tf.zeros([<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>float32<span class=\"pl-pds\">\"</span></span>))\n\n<span class=\"pl-c1\">max</span> <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">outer_cond_func</span>(<span class=\"pl-smi\">c1</span>, <span class=\"pl-smi\">outer_acc</span>, <span class=\"pl-smi\">outer_array</span>):\n    <span class=\"pl-k\">return</span> tf.less(c1, <span class=\"pl-c1\">OUTER_LOOP_MAX</span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">outer_body_func</span>(<span class=\"pl-smi\">c1</span>, <span class=\"pl-smi\">outer_acc</span>, <span class=\"pl-smi\">outer_array</span>):\n    concat <span class=\"pl-k\">=</span> tf.concat(<span class=\"pl-c1\">0</span>, [[<span class=\"pl-c1\">0</span>], tf.expand_dims(c1, <span class=\"pl-c1\">0</span>)])\n    <span class=\"pl-c1\">slice</span> <span class=\"pl-k\">=</span> tf.slice(outer_array, concat, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])\n    outer_num <span class=\"pl-k\">=</span> tf.reduce_sum(<span class=\"pl-c1\">slice</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">inner_cond_func</span>(<span class=\"pl-smi\">c2</span>, <span class=\"pl-smi\">inner_acc</span>, <span class=\"pl-smi\">inner_array</span>):\n        <span class=\"pl-k\">return</span> tf.less(c2, <span class=\"pl-c1\">INNER_LOOP_MAX</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">inner_body_func</span>(<span class=\"pl-smi\">c2</span>, <span class=\"pl-smi\">inner_acc</span>, <span class=\"pl-smi\">inner_array</span>):\n        concat2 <span class=\"pl-k\">=</span> tf.concat(<span class=\"pl-c1\">0</span>, [[<span class=\"pl-c1\">0</span>], tf.expand_dims(c2, <span class=\"pl-c1\">0</span>)])\n        inner_num <span class=\"pl-k\">=</span> tf.reduce_sum(tf.slice(inner_array, concat2, [<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>]))\n        inner_acc <span class=\"pl-k\">+=</span> inner_num <span class=\"pl-k\">*</span> outer_num <span class=\"pl-k\">*</span> X\n\n        c2 <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-k\">return</span> c2, inner_acc, inner_array\n\n    _, inside_summed_products, _ <span class=\"pl-k\">=</span> control_flow_ops.While(inner_cond_func, inner_body_func, [tf.constant(<span class=\"pl-c1\">0</span>), tf.constant(<span class=\"pl-c1\">0.0</span>), inner])\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">true_func</span>():\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span>outer_num\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">false_func</span>():\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">3</span><span class=\"pl-k\">*</span>outer_num\n\n    cond_num <span class=\"pl-k\">=</span> control_flow_ops.cond(tf.less(c1,<span class=\"pl-c1\">max</span>),true_func, false_func)\n    outer_acc <span class=\"pl-k\">=</span> tf.add(outer_acc, inside_summed_products)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> outer_acc = tf.add(outer_acc, cond_num)</span>\n    c1 <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-k\">return</span> c1, outer_acc, outer_array\n\n_, value, _ <span class=\"pl-k\">=</span> control_flow_ops.While(outer_cond_func, outer_body_func, [tf.constant(<span class=\"pl-c1\">0</span>), tf.constant(<span class=\"pl-c1\">0.0</span>), outer])\ncontrol_flow_ops.switch()\n\nloss <span class=\"pl-k\">=</span> value <span class=\"pl-k\">*</span> X\ntrain_op <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>).minimize(loss)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\ninit <span class=\"pl-k\">=</span> tf.initialize_all_variables()\nsess.run(init)\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">10</span>):\n    feed_dict <span class=\"pl-k\">=</span> {inner: [[<span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">2.0</span>, <span class=\"pl-c1\">3.0</span>]], outer: [[<span class=\"pl-c1\">4.0</span>, <span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">6.0</span>, <span class=\"pl-c1\">7.0</span>, <span class=\"pl-c1\">8.0</span>]]}\n    <span class=\"pl-c1\">print</span> sess.run([train_op, loss], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict)</pre></div>", "body_text": "I drew up this simple example to show that nested While gradient computation fails in the python interface (as the gradContext for the forwardContext of the second input of the Add op is None). Toggling the comment demonstrates the issue is not with all control flow graphs.\nimport tensorflow as tf\nfrom tensorflow.python.ops import control_flow_ops\n\nOUTER_LOOP_MAX = 5\nINNER_LOOP_MAX = 3\n\ninner = tf.placeholder(\"float32\", [1, INNER_LOOP_MAX])\nouter = tf.placeholder(\"float32\", [1, OUTER_LOOP_MAX])\n\nX = tf.Variable(tf.zeros([1], dtype=\"float32\"))\n\nmax = tf.constant(1)\n\ndef outer_cond_func(c1, outer_acc, outer_array):\n    return tf.less(c1, OUTER_LOOP_MAX)\n\n\ndef outer_body_func(c1, outer_acc, outer_array):\n    concat = tf.concat(0, [[0], tf.expand_dims(c1, 0)])\n    slice = tf.slice(outer_array, concat, [1, 1])\n    outer_num = tf.reduce_sum(slice)\n\n    def inner_cond_func(c2, inner_acc, inner_array):\n        return tf.less(c2, INNER_LOOP_MAX)\n\n    def inner_body_func(c2, inner_acc, inner_array):\n        concat2 = tf.concat(0, [[0], tf.expand_dims(c2, 0)])\n        inner_num = tf.reduce_sum(tf.slice(inner_array, concat2, [1,1]))\n        inner_acc += inner_num * outer_num * X\n\n        c2 += 1\n        return c2, inner_acc, inner_array\n\n    _, inside_summed_products, _ = control_flow_ops.While(inner_cond_func, inner_body_func, [tf.constant(0), tf.constant(0.0), inner])\n\n    def true_func():\n        return 2*outer_num\n\n    def false_func():\n        return 3*outer_num\n\n    cond_num = control_flow_ops.cond(tf.less(c1,max),true_func, false_func)\n    outer_acc = tf.add(outer_acc, inside_summed_products)\n    # outer_acc = tf.add(outer_acc, cond_num)\n    c1 += 1\n    return c1, outer_acc, outer_array\n\n_, value, _ = control_flow_ops.While(outer_cond_func, outer_body_func, [tf.constant(0), tf.constant(0.0), outer])\ncontrol_flow_ops.switch()\n\nloss = value * X\ntrain_op = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\nfor i in xrange(1, 10):\n    feed_dict = {inner: [[1.0, 2.0, 3.0]], outer: [[4.0, 5.0, 6.0, 7.0, 8.0]]}\n    print sess.run([train_op, loss], feed_dict=feed_dict)", "body": "I drew up this simple example to show that nested While gradient computation fails in the python interface (as the gradContext for the forwardContext of the second input of the Add op is None). Toggling the comment demonstrates the issue is not with all control flow graphs.\n\n``` python\nimport tensorflow as tf\nfrom tensorflow.python.ops import control_flow_ops\n\nOUTER_LOOP_MAX = 5\nINNER_LOOP_MAX = 3\n\ninner = tf.placeholder(\"float32\", [1, INNER_LOOP_MAX])\nouter = tf.placeholder(\"float32\", [1, OUTER_LOOP_MAX])\n\nX = tf.Variable(tf.zeros([1], dtype=\"float32\"))\n\nmax = tf.constant(1)\n\ndef outer_cond_func(c1, outer_acc, outer_array):\n    return tf.less(c1, OUTER_LOOP_MAX)\n\n\ndef outer_body_func(c1, outer_acc, outer_array):\n    concat = tf.concat(0, [[0], tf.expand_dims(c1, 0)])\n    slice = tf.slice(outer_array, concat, [1, 1])\n    outer_num = tf.reduce_sum(slice)\n\n    def inner_cond_func(c2, inner_acc, inner_array):\n        return tf.less(c2, INNER_LOOP_MAX)\n\n    def inner_body_func(c2, inner_acc, inner_array):\n        concat2 = tf.concat(0, [[0], tf.expand_dims(c2, 0)])\n        inner_num = tf.reduce_sum(tf.slice(inner_array, concat2, [1,1]))\n        inner_acc += inner_num * outer_num * X\n\n        c2 += 1\n        return c2, inner_acc, inner_array\n\n    _, inside_summed_products, _ = control_flow_ops.While(inner_cond_func, inner_body_func, [tf.constant(0), tf.constant(0.0), inner])\n\n    def true_func():\n        return 2*outer_num\n\n    def false_func():\n        return 3*outer_num\n\n    cond_num = control_flow_ops.cond(tf.less(c1,max),true_func, false_func)\n    outer_acc = tf.add(outer_acc, inside_summed_products)\n    # outer_acc = tf.add(outer_acc, cond_num)\n    c1 += 1\n    return c1, outer_acc, outer_array\n\n_, value, _ = control_flow_ops.While(outer_cond_func, outer_body_func, [tf.constant(0), tf.constant(0.0), outer])\ncontrol_flow_ops.switch()\n\nloss = value * X\ntrain_op = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\nfor i in xrange(1, 10):\n    feed_dict = {inner: [[1.0, 2.0, 3.0]], outer: [[4.0, 5.0, 6.0, 7.0, 8.0]]}\n    print sess.run([train_op, loss], feed_dict=feed_dict)\n```\n"}