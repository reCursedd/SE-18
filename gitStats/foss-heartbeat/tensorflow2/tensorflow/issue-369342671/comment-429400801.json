{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429400801", "html_url": "https://github.com/tensorflow/tensorflow/pull/22912#issuecomment-429400801", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22912", "id": 429400801, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTQwMDgwMQ==", "user": {"login": "guoshimin", "id": 11787293, "node_id": "MDQ6VXNlcjExNzg3Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/11787293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guoshimin", "html_url": "https://github.com/guoshimin", "followers_url": "https://api.github.com/users/guoshimin/followers", "following_url": "https://api.github.com/users/guoshimin/following{/other_user}", "gists_url": "https://api.github.com/users/guoshimin/gists{/gist_id}", "starred_url": "https://api.github.com/users/guoshimin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guoshimin/subscriptions", "organizations_url": "https://api.github.com/users/guoshimin/orgs", "repos_url": "https://api.github.com/users/guoshimin/repos", "events_url": "https://api.github.com/users/guoshimin/events{/privacy}", "received_events_url": "https://api.github.com/users/guoshimin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T17:28:29Z", "updated_at": "2018-10-12T17:28:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>To give some background, we initially noticed issues with misplaced ops in multi-gpu training when we upgraded from 1.4 to 1.9. Some ops belonging to tower N, which used to run on GPU N, are now running on GPU 0, causing GPU 0 to run out of memory and a big slowdown.</p>\n<p>We examined our code and verified that we called tf.device correctly when creating the ops. Further investigation revealed that ops created from <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L630\">graph_editor.copy_with_input_replacements</a> didn't have devices assigned when the graph was constructed. <code>graph_editor.copy_with_input_replacements</code> replicates existing ops and then makes modifications. To replicate an op, it</p>\n<ul>\n<li><a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L156\">makes a copy of the original node's node_def</a>, and</li>\n<li><a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L176\">calls tf.Operation() with it</a>.</li>\n</ul>\n<p>The resulting op had the original op's device (<code>op.device</code>) up until v1.7. What changed between 1.7 and 1.8 was that the default for <code>_USE_C_API</code> changed from False to True. It being True means <code>g._scoped_c_graph</code> is now <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L2908-L2913\">always set</a>, and that activates <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L1748-L1756\">this branch</a>, which sets <code>self._c_op</code> for the op using <code>_create_c_op</code>, which doesn't copy over the device assignment in <code>node_def</code>. Then, when we call <code>op.device</code>, we hit <a href=\"https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L1894-L1895\">this branch</a>, which has no knowledge of the device in the original node_def that was used to create this op.</p>\n<p>With this fix, we are no longer seeing misplaced ops, and training speed is back to what it was before.</p>", "body_text": "To give some background, we initially noticed issues with misplaced ops in multi-gpu training when we upgraded from 1.4 to 1.9. Some ops belonging to tower N, which used to run on GPU N, are now running on GPU 0, causing GPU 0 to run out of memory and a big slowdown.\nWe examined our code and verified that we called tf.device correctly when creating the ops. Further investigation revealed that ops created from graph_editor.copy_with_input_replacements didn't have devices assigned when the graph was constructed. graph_editor.copy_with_input_replacements replicates existing ops and then makes modifications. To replicate an op, it\n\nmakes a copy of the original node's node_def, and\ncalls tf.Operation() with it.\n\nThe resulting op had the original op's device (op.device) up until v1.7. What changed between 1.7 and 1.8 was that the default for _USE_C_API changed from False to True. It being True means g._scoped_c_graph is now always set, and that activates this branch, which sets self._c_op for the op using _create_c_op, which doesn't copy over the device assignment in node_def. Then, when we call op.device, we hit this branch, which has no knowledge of the device in the original node_def that was used to create this op.\nWith this fix, we are no longer seeing misplaced ops, and training speed is back to what it was before.", "body": "To give some background, we initially noticed issues with misplaced ops in multi-gpu training when we upgraded from 1.4 to 1.9. Some ops belonging to tower N, which used to run on GPU N, are now running on GPU 0, causing GPU 0 to run out of memory and a big slowdown.\r\n\r\nWe examined our code and verified that we called tf.device correctly when creating the ops. Further investigation revealed that ops created from [graph_editor.copy_with_input_replacements](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L630) didn't have devices assigned when the graph was constructed. `graph_editor.copy_with_input_replacements` replicates existing ops and then makes modifications. To replicate an op, it\r\n\r\n- [makes a copy of the original node's node_def](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L156), and\r\n- [calls tf.Operation() with it](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/contrib/graph_editor/transform.py#L176). \r\n\r\nThe resulting op had the original op's device (`op.device`) up until v1.7. What changed between 1.7 and 1.8 was that the default for `_USE_C_API` changed from False to True. It being True means `g._scoped_c_graph` is now [always set](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L2908-L2913), and that activates [this branch](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L1748-L1756), which sets `self._c_op` for the op using `_create_c_op`, which doesn't copy over the device assignment in `node_def`. Then, when we call `op.device`, we hit [this branch](https://github.com/tensorflow/tensorflow/blob/v1.9.0/tensorflow/python/framework/ops.py#L1894-L1895), which has no knowledge of the device in the original node_def that was used to create this op.\r\n\r\nWith this fix, we are no longer seeing misplaced ops, and training speed is back to what it was before."}