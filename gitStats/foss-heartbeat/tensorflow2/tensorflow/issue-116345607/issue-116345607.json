{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/140", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/140/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/140/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/140/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/140", "id": 116345607, "node_id": "MDU6SXNzdWUxMTYzNDU2MDc=", "number": 140, "title": "Questions about using LSTM ", "user": {"login": "jazzsaxmafia", "id": 8408608, "node_id": "MDQ6VXNlcjg0MDg2MDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/8408608?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jazzsaxmafia", "html_url": "https://github.com/jazzsaxmafia", "followers_url": "https://api.github.com/users/jazzsaxmafia/followers", "following_url": "https://api.github.com/users/jazzsaxmafia/following{/other_user}", "gists_url": "https://api.github.com/users/jazzsaxmafia/gists{/gist_id}", "starred_url": "https://api.github.com/users/jazzsaxmafia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jazzsaxmafia/subscriptions", "organizations_url": "https://api.github.com/users/jazzsaxmafia/orgs", "repos_url": "https://api.github.com/users/jazzsaxmafia/repos", "events_url": "https://api.github.com/users/jazzsaxmafia/events{/privacy}", "received_events_url": "https://api.github.com/users/jazzsaxmafia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-11-11T14:32:15Z", "updated_at": "2015-11-11T18:47:18Z", "closed_at": "2015-11-11T18:47:18Z", "author_association": "NONE", "body_html": "<p>Hi. I am a newbie on TensorFlow, just like most of the others here.<br>\nI was trying to use the LSTM modules, and some questions arose.</p>\n<ol>\n<li>How can I cope with non-fixed length of sequences? For example, the length of longest sentence in each batch is different, but in RNN tutorial, it does like</li>\n</ol>\n<p>for i in range(len(num_steps)):<br>\n# The value of state is updated after processing each batch of words.<br>\noutput, state = lstm(words[:, i], state)</p>\n<p>....</p>\n<p>when this \"num_steps\" is not set, what kind of value or variable can I use?</p>\n<ol>\n<li>How can I use mask in LSTM? within a batch, all the sentences have different length, so it is essential to mask the lstm results according to the length of each sentence. I don't think there is masking function inside TensorFlor LSTM module. What options do I have?</li>\n</ol>\n<p>Sorry for bothering you, and thank you for making public this great project.</p>\n<p>-Taeksoo</p>", "body_text": "Hi. I am a newbie on TensorFlow, just like most of the others here.\nI was trying to use the LSTM modules, and some questions arose.\n\nHow can I cope with non-fixed length of sequences? For example, the length of longest sentence in each batch is different, but in RNN tutorial, it does like\n\nfor i in range(len(num_steps)):\n# The value of state is updated after processing each batch of words.\noutput, state = lstm(words[:, i], state)\n....\nwhen this \"num_steps\" is not set, what kind of value or variable can I use?\n\nHow can I use mask in LSTM? within a batch, all the sentences have different length, so it is essential to mask the lstm results according to the length of each sentence. I don't think there is masking function inside TensorFlor LSTM module. What options do I have?\n\nSorry for bothering you, and thank you for making public this great project.\n-Taeksoo", "body": "Hi. I am a newbie on TensorFlow, just like most of the others here.\nI was trying to use the LSTM modules, and some questions arose.\n1. How can I cope with non-fixed length of sequences? For example, the length of longest sentence in each batch is different, but in RNN tutorial, it does like \n\nfor i in range(len(num_steps)):\n    # The value of state is updated after processing each batch of words.\n    output, state = lstm(words[:, i], state)\n\n....\n\nwhen this \"num_steps\" is not set, what kind of value or variable can I use?\n1. How can I use mask in LSTM? within a batch, all the sentences have different length, so it is essential to mask the lstm results according to the length of each sentence. I don't think there is masking function inside TensorFlor LSTM module. What options do I have?\n\nSorry for bothering you, and thank you for making public this great project.\n\n-Taeksoo\n"}