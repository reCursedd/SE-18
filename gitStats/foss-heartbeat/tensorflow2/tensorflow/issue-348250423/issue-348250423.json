{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21439", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21439/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21439/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21439/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21439", "id": 348250423, "node_id": "MDU6SXNzdWUzNDgyNTA0MjM=", "number": 21439, "title": "Reduce_sum error", "user": {"login": "Lillypucien", "id": 25703961, "node_id": "MDQ6VXNlcjI1NzAzOTYx", "avatar_url": "https://avatars1.githubusercontent.com/u/25703961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lillypucien", "html_url": "https://github.com/Lillypucien", "followers_url": "https://api.github.com/users/Lillypucien/followers", "following_url": "https://api.github.com/users/Lillypucien/following{/other_user}", "gists_url": "https://api.github.com/users/Lillypucien/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lillypucien/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lillypucien/subscriptions", "organizations_url": "https://api.github.com/users/Lillypucien/orgs", "repos_url": "https://api.github.com/users/Lillypucien/repos", "events_url": "https://api.github.com/users/Lillypucien/events{/privacy}", "received_events_url": "https://api.github.com/users/Lillypucien/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-08-07T09:57:10Z", "updated_at": "2018-11-10T18:49:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: YES</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10 64 bits</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / v7</li>\n<li><strong>GPU model and memory</strong>: Nvidia GTX TITANX 12GB, driver up to date (398.82)</li>\n<li><strong>Bazel version</strong>: N/A</li>\n<li><strong>Mobile device</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Hi,</p>\n<p>See test case below. On this specific setting it happens that tf.reduce_sum returns wrong values, as attested by the loss which should always return 0, but does not in this case (see logs at the end).</p>\n<p>The bug does not happen when running on CPU, or when batchSize is strictly lesser than 33, or when \"models\" tensor has only 3 dimensions (even if we increase its size), or when \"models\" is smaller, or when the reduce_sum is applied on all axes instead of the last axis.</p>\n<p>The reduce_sum is also correct for the first 32 elements of its first dimension, and only goes wrong for the 33rd (and next) element(s).</p>\n<p>If we replace the \"diff = inputTensor - inputTensor\" tensor by a tf.zeros tensor, the bug does not appear.</p>\n<p>The bug also happens with other reducing tensorflow methods (such as tf.reduce_min, tf.reduce_max and tf.reduce_mean).</p>\n<p>Thanks in advance</p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom random import random\n\nbatchSize = 33\n\nnp.random.seed(0)\nmodels = np.random.rand(batchSize, 2050, 2050, 2)\nmodels = np.asarray(models, dtype = \"float32\")\n\ndataPlaceholder = tf.placeholder(\"float32\", models.shape)\ninputTensor = dataPlaceholder\n\ndiff = inputTensor - inputTensor\n# diff = tf.zeros(inputTensor.shape)\n\nsum = tf.reduce_sum(diff, axis = 3)\n\nloss = tf.reduce_max(sum)\nloss = tf.Print(loss, [diff[batchSize-1,0,0], sum[batchSize-1,0,0]], message=\"diff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : \")\n\nif __name__ == '__main__':\n\twith tf.Session() as sess:\n\t\tbatchLoss = sess.run(loss, feed_dict = {dataPlaceholder: models[:batchSize]})\n\t\tprint(\"batch loss : {}\".format(batchLoss))\n\n---------------------------------------------------\nbatch loss : 0.999999463558197\ndiff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : [0 0][0.154408231]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bits\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.9.0\nPython version: 3.5\nCUDA/cuDNN version: 9.0 / v7\nGPU model and memory: Nvidia GTX TITANX 12GB, driver up to date (398.82)\nBazel version: N/A\nMobile device: N/A\nExact command to reproduce:\n\nDescribe the problem\nHi,\nSee test case below. On this specific setting it happens that tf.reduce_sum returns wrong values, as attested by the loss which should always return 0, but does not in this case (see logs at the end).\nThe bug does not happen when running on CPU, or when batchSize is strictly lesser than 33, or when \"models\" tensor has only 3 dimensions (even if we increase its size), or when \"models\" is smaller, or when the reduce_sum is applied on all axes instead of the last axis.\nThe reduce_sum is also correct for the first 32 elements of its first dimension, and only goes wrong for the 33rd (and next) element(s).\nIf we replace the \"diff = inputTensor - inputTensor\" tensor by a tf.zeros tensor, the bug does not appear.\nThe bug also happens with other reducing tensorflow methods (such as tf.reduce_min, tf.reduce_max and tf.reduce_mean).\nThanks in advance\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\nfrom random import random\n\nbatchSize = 33\n\nnp.random.seed(0)\nmodels = np.random.rand(batchSize, 2050, 2050, 2)\nmodels = np.asarray(models, dtype = \"float32\")\n\ndataPlaceholder = tf.placeholder(\"float32\", models.shape)\ninputTensor = dataPlaceholder\n\ndiff = inputTensor - inputTensor\n# diff = tf.zeros(inputTensor.shape)\n\nsum = tf.reduce_sum(diff, axis = 3)\n\nloss = tf.reduce_max(sum)\nloss = tf.Print(loss, [diff[batchSize-1,0,0], sum[batchSize-1,0,0]], message=\"diff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : \")\n\nif __name__ == '__main__':\n\twith tf.Session() as sess:\n\t\tbatchLoss = sess.run(loss, feed_dict = {dataPlaceholder: models[:batchSize]})\n\t\tprint(\"batch loss : {}\".format(batchLoss))\n\n---------------------------------------------------\nbatch loss : 0.999999463558197\ndiff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : [0 0][0.154408231]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 bits\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.5\r\n- **CUDA/cuDNN version**: 9.0 / v7\r\n- **GPU model and memory**: Nvidia GTX TITANX 12GB, driver up to date (398.82)\r\n- **Bazel version**: N/A\r\n- **Mobile device**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nHi,\r\n\r\nSee test case below. On this specific setting it happens that tf.reduce_sum returns wrong values, as attested by the loss which should always return 0, but does not in this case (see logs at the end).\r\n\r\nThe bug does not happen when running on CPU, or when batchSize is strictly lesser than 33, or when \"models\" tensor has only 3 dimensions (even if we increase its size), or when \"models\" is smaller, or when the reduce_sum is applied on all axes instead of the last axis.\r\n\r\nThe reduce_sum is also correct for the first 32 elements of its first dimension, and only goes wrong for the 33rd (and next) element(s). \r\n\r\nIf we replace the \"diff = inputTensor - inputTensor\" tensor by a tf.zeros tensor, the bug does not appear.\r\n\r\nThe bug also happens with other reducing tensorflow methods (such as tf.reduce_min, tf.reduce_max and tf.reduce_mean).\r\n\r\nThanks in advance\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom random import random\r\n\r\nbatchSize = 33\r\n\r\nnp.random.seed(0)\r\nmodels = np.random.rand(batchSize, 2050, 2050, 2)\r\nmodels = np.asarray(models, dtype = \"float32\")\r\n\r\ndataPlaceholder = tf.placeholder(\"float32\", models.shape)\r\ninputTensor = dataPlaceholder\r\n\r\ndiff = inputTensor - inputTensor\r\n# diff = tf.zeros(inputTensor.shape)\r\n\r\nsum = tf.reduce_sum(diff, axis = 3)\r\n\r\nloss = tf.reduce_max(sum)\r\nloss = tf.Print(loss, [diff[batchSize-1,0,0], sum[batchSize-1,0,0]], message=\"diff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : \")\r\n\r\nif __name__ == '__main__':\r\n\twith tf.Session() as sess:\r\n\t\tbatchLoss = sess.run(loss, feed_dict = {dataPlaceholder: models[:batchSize]})\r\n\t\tprint(\"batch loss : {}\".format(batchLoss))\r\n\r\n---------------------------------------------------\r\nbatch loss : 0.999999463558197\r\ndiff[batchSize-1,0,0], reduce_sum[batchSize-1,0,0] : [0 0][0.154408231]\r\n```"}