{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/233990672", "pull_request_review_id": 175024525, "id": 233990672, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMzk5MDY3Mg==", "diff_hunk": "@@ -1278,6 +1292,85 @@ class CudnnRnnSequenceTensorDescriptor\n   SE_DISALLOW_COPY_AND_ASSIGN(CudnnRnnSequenceTensorDescriptor);\n };\n \n+class CudnnRnnVariableSequenceTensorDescriptor\n+    : public dnn::RnnVariableSequenceTensorDescriptor {\n+  CudnnRnnVariableSequenceTensorDescriptor(CUDAExecutor* parent, int seq_length,\n+                                           int batch_size, int data_size,\n+                                           int* seq_lens,\n+                                           cudnnDataType_t data_type,\n+                                           bool is_ready,\n+                                           RNNDataDescriptor handle)\n+      : parent_(parent),\n+        seq_length_(seq_length),\n+        batch_size_(batch_size),\n+        data_size_(data_size),\n+        seq_lens_(seq_lens),\n+        is_ready_(is_ready),\n+        data_type_(data_type),\n+        handle_(std::move(handle)) {}\n+\n+  CudnnRnnVariableSequenceTensorDescriptor(CUDAExecutor* parent)\n+      : parent_(parent), is_ready_(false) {}\n+\n+ public:\n+  CudnnRnnVariableSequenceTensorDescriptor(\n+      CudnnRnnVariableSequenceTensorDescriptor&&) = default;\n+\n+  static port::StatusOr<CudnnRnnVariableSequenceTensorDescriptor> Create(\n+      CUDAExecutor* parent, int seq_length, int batch_size, int data_size,\n+      int* seq_lens,  // This is the device memory\n+      cudnnDataType_t data_type) {\n+    CHECK_GT(seq_length, 0);\n+    RNNDataDescriptor tensor_desc = CreateRNNDataDescriptor();\n+    float paddingFill = 0.0f;\n+    std::vector<int> seq_lens_h(batch_size);\n+    cudaStream_t stream;", "path": "tensorflow/stream_executor/cuda/cuda_dnn.cc", "position": null, "original_position": 78, "commit_id": "2301b4fabf41b7799919e1e29a1a3651367495aa", "original_commit_id": "514b05b38845eab0936f73b42e6e225702460e45", "user": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "body": "Let's mark the following input to the new op as `HostMemory` in all registrations, s.t it's already in host memory when it reaches kernel's `Compute()` method.  There'll be no need to do the manual `cudaMemcpy`.\r\n```\r\n.Input(\"sequence_lengths: int32\")\r\n```\r\nExample: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cudnn_rnn_ops.cc#L956\r\n", "created_at": "2018-11-15T20:08:20Z", "updated_at": "2018-11-21T22:30:12Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/23588#discussion_r233990672", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23588", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/233990672"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23588#discussion_r233990672"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23588"}}, "body_html": "<p>Let's mark the following input to the new op as <code>HostMemory</code> in all registrations, s.t it's already in host memory when it reaches kernel's <code>Compute()</code> method.  There'll be no need to do the manual <code>cudaMemcpy</code>.</p>\n<pre><code>.Input(\"sequence_lengths: int32\")\n</code></pre>\n<p>Example: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cudnn_rnn_ops.cc#L956\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cudnn_rnn_ops.cc#L956</a></p>", "body_text": "Let's mark the following input to the new op as HostMemory in all registrations, s.t it's already in host memory when it reaches kernel's Compute() method.  There'll be no need to do the manual cudaMemcpy.\n.Input(\"sequence_lengths: int32\")\n\nExample: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cudnn_rnn_ops.cc#L956"}