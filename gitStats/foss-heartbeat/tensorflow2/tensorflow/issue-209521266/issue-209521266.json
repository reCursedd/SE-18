{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7786", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7786/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7786/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7786/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7786", "id": 209521266, "node_id": "MDU6SXNzdWUyMDk1MjEyNjY=", "number": 7786, "title": "Feature Request: Embedding Lookup Gradient", "user": {"login": "shawnjhenry", "id": 9464836, "node_id": "MDQ6VXNlcjk0NjQ4MzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9464836?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shawnjhenry", "html_url": "https://github.com/shawnjhenry", "followers_url": "https://api.github.com/users/shawnjhenry/followers", "following_url": "https://api.github.com/users/shawnjhenry/following{/other_user}", "gists_url": "https://api.github.com/users/shawnjhenry/gists{/gist_id}", "starred_url": "https://api.github.com/users/shawnjhenry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shawnjhenry/subscriptions", "organizations_url": "https://api.github.com/users/shawnjhenry/orgs", "repos_url": "https://api.github.com/users/shawnjhenry/repos", "events_url": "https://api.github.com/users/shawnjhenry/events{/privacy}", "received_events_url": "https://api.github.com/users/shawnjhenry/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-02-22T17:16:43Z", "updated_at": "2017-03-09T18:29:29Z", "closed_at": "2017-03-09T18:29:29Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>Since <code>embedding_lookup</code> is just a fast way of doing a matrix multiplication between the embedding weights and a tensor of one-hot vectors, it would be nice to have an option to get the gradient of the <code>embedding_lookup</code> as if it were such a matrix multiplication.  There are situations where this is actually useful - for example, the one-hots could be sampled from a high-dimensional multinomial distribution computed by a first neural network and passed as input to a second neural network, where using <code>embedding_lookup</code> would be much faster because of the high dimensionality.  There are some recent papers with various methods for back-propagating through the sampling procedure that I would like to implement, but I don't see any way to do it efficiently for high-dimensional distributions without a feature like this.</p>\n<p>Thanks,<br>\nShawn</p>", "body_text": "Hi,\nSince embedding_lookup is just a fast way of doing a matrix multiplication between the embedding weights and a tensor of one-hot vectors, it would be nice to have an option to get the gradient of the embedding_lookup as if it were such a matrix multiplication.  There are situations where this is actually useful - for example, the one-hots could be sampled from a high-dimensional multinomial distribution computed by a first neural network and passed as input to a second neural network, where using embedding_lookup would be much faster because of the high dimensionality.  There are some recent papers with various methods for back-propagating through the sampling procedure that I would like to implement, but I don't see any way to do it efficiently for high-dimensional distributions without a feature like this.\nThanks,\nShawn", "body": "Hi,\r\n\r\nSince `embedding_lookup` is just a fast way of doing a matrix multiplication between the embedding weights and a tensor of one-hot vectors, it would be nice to have an option to get the gradient of the `embedding_lookup` as if it were such a matrix multiplication.  There are situations where this is actually useful - for example, the one-hots could be sampled from a high-dimensional multinomial distribution computed by a first neural network and passed as input to a second neural network, where using `embedding_lookup` would be much faster because of the high dimensionality.  There are some recent papers with various methods for back-propagating through the sampling procedure that I would like to implement, but I don't see any way to do it efficiently for high-dimensional distributions without a feature like this. \r\n\r\nThanks,\r\nShawn\r\n"}