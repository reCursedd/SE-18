{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/355189154", "html_url": "https://github.com/tensorflow/tensorflow/issues/6035#issuecomment-355189154", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6035", "id": 355189154, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTE4OTE1NA==", "user": {"login": "alecGraves", "id": 15484056, "node_id": "MDQ6VXNlcjE1NDg0MDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/15484056?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alecGraves", "html_url": "https://github.com/alecGraves", "followers_url": "https://api.github.com/users/alecGraves/followers", "following_url": "https://api.github.com/users/alecGraves/following{/other_user}", "gists_url": "https://api.github.com/users/alecGraves/gists{/gist_id}", "starred_url": "https://api.github.com/users/alecGraves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alecGraves/subscriptions", "organizations_url": "https://api.github.com/users/alecGraves/orgs", "repos_url": "https://api.github.com/users/alecGraves/repos", "events_url": "https://api.github.com/users/alecGraves/events{/privacy}", "received_events_url": "https://api.github.com/users/alecGraves/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T03:15:09Z", "updated_at": "2018-01-04T03:15:09Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1001128\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mmpinso\">@mmpinso</a><br>\nI think all of the ops for my workaround ended up using multiple gigs of memory simply with ENet. There is a pretty good chance it would not fit in a gpu (or even system ram) during training. Definitely would not fit in most mobile devices, and it is pretty slow.</p>\n<p>In the mean time, I might try to make a lightweight segmentation architecture which uses features from the downsampling layers to guide the upsampling layers. Maybe an architecture like this already exists...</p>\n<p>Anyway, anyone want to learn <a href=\"https://www.tensorflow.org/extend/adding_an_op\" rel=\"nofollow\">how to make ops</a>?</p>", "body_text": "@mmpinso\nI think all of the ops for my workaround ended up using multiple gigs of memory simply with ENet. There is a pretty good chance it would not fit in a gpu (or even system ram) during training. Definitely would not fit in most mobile devices, and it is pretty slow.\nIn the mean time, I might try to make a lightweight segmentation architecture which uses features from the downsampling layers to guide the upsampling layers. Maybe an architecture like this already exists...\nAnyway, anyone want to learn how to make ops?", "body": "@mmpinso \r\nI think all of the ops for my workaround ended up using multiple gigs of memory simply with ENet. There is a pretty good chance it would not fit in a gpu (or even system ram) during training. Definitely would not fit in most mobile devices, and it is pretty slow.\r\n\r\nIn the mean time, I might try to make a lightweight segmentation architecture which uses features from the downsampling layers to guide the upsampling layers. Maybe an architecture like this already exists...\r\n\r\nAnyway, anyone want to learn [how to make ops](https://www.tensorflow.org/extend/adding_an_op)?"}