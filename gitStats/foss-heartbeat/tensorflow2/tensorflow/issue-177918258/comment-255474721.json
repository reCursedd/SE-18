{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/255474721", "html_url": "https://github.com/tensorflow/tensorflow/issues/4478#issuecomment-255474721", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4478", "id": 255474721, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NTQ3NDcyMQ==", "user": {"login": "osdf", "id": 193341, "node_id": "MDQ6VXNlcjE5MzM0MQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/193341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/osdf", "html_url": "https://github.com/osdf", "followers_url": "https://api.github.com/users/osdf/followers", "following_url": "https://api.github.com/users/osdf/following{/other_user}", "gists_url": "https://api.github.com/users/osdf/gists{/gist_id}", "starred_url": "https://api.github.com/users/osdf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/osdf/subscriptions", "organizations_url": "https://api.github.com/users/osdf/orgs", "repos_url": "https://api.github.com/users/osdf/repos", "events_url": "https://api.github.com/users/osdf/events{/privacy}", "received_events_url": "https://api.github.com/users/osdf/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-21T21:54:30Z", "updated_at": "2016-10-21T22:04:03Z", "author_association": "NONE", "body_html": "<p>I'm having the same error message that is reported in the issue(s). I have a RNN like structure that has some building blocks (component neural networks) that are passed in by the user. Here is a minimal example:</p>\n<pre><code>import tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    \"\"\"\n    A simple rnn that makes the standard update, then\n    feeds the new hidden state through some external\n    function.\n    \"\"\"\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\n# the external function, relying on the templating mechanism.\ndef ext_fct(hiddens):\n    \"\"\"\n    \"\"\"\n    def tmp(input):\n        shape = (hiddens, hiddens)\n        _init = initialize(shape)\n        W = tf.get_variable(\"ext_w\", initializer=_init)\n        b = 0\n        return tf.add(tf.matmul(input, W), b, name=\"external\")\n    return tf.make_template(name_=\"external_fct\", func_=tmp)\n\n# run from here on\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\n\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\next = ext_fct(hiddens)\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n</code></pre>\n<p>with the error ending in:</p>\n<pre><code>InvalidArgumentError: All inputs to node external_fct/ext_w/Assign must be from the same frame.\n</code></pre>\n<p>With <code>Frame</code>, I would associate an area on the stack. So I thought that maybe <code>tf.make_template</code> does something very wired, and thus it is not useable here. The external function can be rewritten a bit and then called more directly, like so:</p>\n<pre><code>import tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        \"\"\"\n        \"\"\"\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t, hiddens)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\ndef ext_fct_new(input, hiddens):\n    \"\"\"\n    \"\"\"\n    shape = (hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"ext_w_new\", initializer=_init)\n    b = 0\n    return tf.add(tf.matmul(input, W), b, name=\"external_new\")\n\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext_fct_new)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n</code></pre>\n<p>However, still the same error <code>InvalidArgumentError: All inputs to node ext_w_new/Assign must be from the same frame.</code></p>\n<p>Of course, moving contents of the external function into the <code>_step</code> part (and <code>tf.get_variable</code>ing before) works. But then the flexibility (necessary in the original code) is gone.</p>\n<p>What am I doing wrong?</p>", "body_text": "I'm having the same error message that is reported in the issue(s). I have a RNN like structure that has some building blocks (component neural networks) that are passed in by the user. Here is a minimal example:\nimport tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    \"\"\"\n    A simple rnn that makes the standard update, then\n    feeds the new hidden state through some external\n    function.\n    \"\"\"\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\n# the external function, relying on the templating mechanism.\ndef ext_fct(hiddens):\n    \"\"\"\n    \"\"\"\n    def tmp(input):\n        shape = (hiddens, hiddens)\n        _init = initialize(shape)\n        W = tf.get_variable(\"ext_w\", initializer=_init)\n        b = 0\n        return tf.add(tf.matmul(input, W), b, name=\"external\")\n    return tf.make_template(name_=\"external_fct\", func_=tmp)\n\n# run from here on\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\n\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\next = ext_fct(hiddens)\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n\nwith the error ending in:\nInvalidArgumentError: All inputs to node external_fct/ext_w/Assign must be from the same frame.\n\nWith Frame, I would associate an area on the stack. So I thought that maybe tf.make_template does something very wired, and thus it is not useable here. The external function can be rewritten a bit and then called more directly, like so:\nimport tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        \"\"\"\n        \"\"\"\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t, hiddens)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\ndef ext_fct_new(input, hiddens):\n    \"\"\"\n    \"\"\"\n    shape = (hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"ext_w_new\", initializer=_init)\n    b = 0\n    return tf.add(tf.matmul(input, W), b, name=\"external_new\")\n\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext_fct_new)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n\nHowever, still the same error InvalidArgumentError: All inputs to node ext_w_new/Assign must be from the same frame.\nOf course, moving contents of the external function into the _step part (and tf.get_variableing before) works. But then the flexibility (necessary in the original code) is gone.\nWhat am I doing wrong?", "body": "I'm having the same error message that is reported in the issue(s). I have a RNN like structure that has some building blocks (component neural networks) that are passed in by the user. Here is a minimal example:\n\n```\nimport tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    \"\"\"\n    A simple rnn that makes the standard update, then\n    feeds the new hidden state through some external\n    function.\n    \"\"\"\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\n# the external function, relying on the templating mechanism.\ndef ext_fct(hiddens):\n    \"\"\"\n    \"\"\"\n    def tmp(input):\n        shape = (hiddens, hiddens)\n        _init = initialize(shape)\n        W = tf.get_variable(\"ext_w\", initializer=_init)\n        b = 0\n        return tf.add(tf.matmul(input, W), b, name=\"external\")\n    return tf.make_template(name_=\"external_fct\", func_=tmp)\n\n# run from here on\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\n\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\next = ext_fct(hiddens)\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n```\n\nwith the error ending in:\n\n```\nInvalidArgumentError: All inputs to node external_fct/ext_w/Assign must be from the same frame.\n```\n\nWith `Frame`, I would associate an area on the stack. So I thought that maybe `tf.make_template` does something very wired, and thus it is not useable here. The external function can be rewritten a bit and then called more directly, like so:\n\n```\nimport tensorflow as tf\ntf.reset_default_graph()\n\ndef initialize(shape):\n    init = tf.random_normal(shape, mean=0, stddev=0.1, dtype=tf.float32)\n    return init\n\ndef test_rnn_with_external(input, hiddens, external_fct):\n    dim_in = input.get_shape().as_list()[-1]\n    btsz = input.get_shape().as_list()[1]\n    shape = (dim_in + hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"rnn_w\", initializer=_init)\n    _init = tf.zeros([hiddens])\n    b = tf.get_variable(\"rnn_b\", initializer=_init)\n\n    def _step(previous, input):\n        \"\"\"\n        \"\"\"\n        concat = tf.concat(1, [input, previous])     \n        h_t = tf.tanh(tf.add(tf.matmul(concat, W), b))\n\n        h_t = external_fct(h_t, hiddens)\n\n        return h_t\n\n    h_0 = tf.zeros([btsz, hiddens])\n    states = tf.scan(_step,\n                     input,\n                     initializer=h_0,\n                     name=\"states\")\n    return states\n\ndef ext_fct_new(input, hiddens):\n    \"\"\"\n    \"\"\"\n    shape = (hiddens, hiddens)\n    _init = initialize(shape)\n    W = tf.get_variable(\"ext_w_new\", initializer=_init)\n    b = 0\n    return tf.add(tf.matmul(input, W), b, name=\"external_new\")\n\nt = 5\nbtsz = 4\ndim = 2\nhiddens = 3\nx = tf.placeholder(tf.float32, shape=(t, btsz, dim))\n\nstates = test_rnn_with_external(x, hiddens, external_fct=ext_fct_new)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n```\n\nHowever, still the same error `InvalidArgumentError: All inputs to node ext_w_new/Assign must be from the same frame.`\n\nOf course, moving contents of the external function into the `_step` part (and `tf.get_variable`ing before) works. But then the flexibility (necessary in the original code) is gone.\n\nWhat am I doing wrong?\n"}