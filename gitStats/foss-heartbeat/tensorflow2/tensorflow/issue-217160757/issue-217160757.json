{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8744", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8744/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8744/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8744/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8744", "id": 217160757, "node_id": "MDU6SXNzdWUyMTcxNjA3NTc=", "number": 8744, "title": "DC-ASGD(Delay Compensated Asynchronous Stochastic Gradient Descent)?", "user": {"login": "liufei1656", "id": 18588802, "node_id": "MDQ6VXNlcjE4NTg4ODAy", "avatar_url": "https://avatars0.githubusercontent.com/u/18588802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liufei1656", "html_url": "https://github.com/liufei1656", "followers_url": "https://api.github.com/users/liufei1656/followers", "following_url": "https://api.github.com/users/liufei1656/following{/other_user}", "gists_url": "https://api.github.com/users/liufei1656/gists{/gist_id}", "starred_url": "https://api.github.com/users/liufei1656/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liufei1656/subscriptions", "organizations_url": "https://api.github.com/users/liufei1656/orgs", "repos_url": "https://api.github.com/users/liufei1656/repos", "events_url": "https://api.github.com/users/liufei1656/events{/privacy}", "received_events_url": "https://api.github.com/users/liufei1656/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-03-27T07:41:09Z", "updated_at": "2017-10-25T23:54:12Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>DC-ASGD is Microsoft's very useful algorithm for distributed asynchronous training. Compared with the ordinary ASGD algorithm, DC-ASGD has no significant loss in speed, but can get almost the same effect as Sequential SGD. As far as I know, other mainstream deep learning open source tools have implemented this algorithm, such as: CNTK, Mxnet, Paddle and so on. But in Tensorflow I have not found similar modules.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"200856669\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/Microsoft/CNTK/issues/1295\" data-hovercard-type=\"issue\" data-hovercard-url=\"/Microsoft/CNTK/issues/1295/hovercard\" href=\"https://github.com/Microsoft/CNTK/issues/1295\">Microsoft/CNTK#1295</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"182161055\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/PaddlePaddle/Paddle/issues/185\" data-hovercard-type=\"issue\" data-hovercard-url=\"/PaddlePaddle/Paddle/issues/185/hovercard\" href=\"https://github.com/PaddlePaddle/Paddle/issues/185\">PaddlePaddle/Paddle#185</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"185041541\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/apache/incubator-mxnet/issues/3614\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/apache/incubator-mxnet/pull/3614/hovercard\" href=\"https://github.com/apache/incubator-mxnet/pull/3614\">apache/incubator-mxnet#3614</a></p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>I tried to implement this algorithm in Tensorflow by myself.  I do not have enough ability to do this now.</p>\n<h3>The link address of the paper</h3>\n<p><a href=\"https://arxiv.org/abs/1609.08326\" rel=\"nofollow\">Asynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning</a></p>", "body_text": "DC-ASGD is Microsoft's very useful algorithm for distributed asynchronous training. Compared with the ordinary ASGD algorithm, DC-ASGD has no significant loss in speed, but can get almost the same effect as Sequential SGD. As far as I know, other mainstream deep learning open source tools have implemented this algorithm, such as: CNTK, Mxnet, Paddle and so on. But in Tensorflow I have not found similar modules.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nMicrosoft/CNTK#1295\nPaddlePaddle/Paddle#185\napache/incubator-mxnet#3614\nWhat other attempted solutions have you tried?\nI tried to implement this algorithm in Tensorflow by myself.  I do not have enough ability to do this now.\nThe link address of the paper\nAsynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning", "body": "DC-ASGD is Microsoft's very useful algorithm for distributed asynchronous training. Compared with the ordinary ASGD algorithm, DC-ASGD has no significant loss in speed, but can get almost the same effect as Sequential SGD. As far as I know, other mainstream deep learning open source tools have implemented this algorithm, such as: CNTK, Mxnet, Paddle and so on. But in Tensorflow I have not found similar modules.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n[https://github.com/Microsoft/CNTK/issues/1295](https://github.com/Microsoft/CNTK/issues/1295)\r\n[https://github.com/PaddlePaddle/Paddle/issues/185](https://github.com/PaddlePaddle/Paddle/issues/185)\r\n[https://github.com/dmlc/mxnet/pull/3614](https://github.com/dmlc/mxnet/pull/3614)\r\n\r\n### What other attempted solutions have you tried?\r\nI tried to implement this algorithm in Tensorflow by myself.  I do not have enough ability to do this now.\r\n\r\n### The link address of the paper\r\n[Asynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning](https://arxiv.org/abs/1609.08326)"}