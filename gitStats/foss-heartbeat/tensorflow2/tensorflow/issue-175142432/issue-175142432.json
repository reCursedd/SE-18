{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4218", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4218/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4218/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4218/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4218", "id": 175142432, "node_id": "MDU6SXNzdWUxNzUxNDI0MzI=", "number": 4218, "title": "seq2seq: Cannot parse tensor from proto: dtype: DT_FLOAT", "user": {"login": "zhaopku", "id": 20232241, "node_id": "MDQ6VXNlcjIwMjMyMjQx", "avatar_url": "https://avatars1.githubusercontent.com/u/20232241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhaopku", "html_url": "https://github.com/zhaopku", "followers_url": "https://api.github.com/users/zhaopku/followers", "following_url": "https://api.github.com/users/zhaopku/following{/other_user}", "gists_url": "https://api.github.com/users/zhaopku/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhaopku/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhaopku/subscriptions", "organizations_url": "https://api.github.com/users/zhaopku/orgs", "repos_url": "https://api.github.com/users/zhaopku/repos", "events_url": "https://api.github.com/users/zhaopku/events{/privacy}", "received_events_url": "https://api.github.com/users/zhaopku/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2016-09-06T01:15:41Z", "updated_at": "2017-01-20T02:45:14Z", "closed_at": "2016-09-09T06:03:48Z", "author_association": "NONE", "body_html": "<p>My platform is ubuntu 14.04 with tensorflow version of 0.10, CPU version.</p>\n<p>I am using functions in <code>seq2seq.py</code> to build a model. The code works fine when I use the <code>embedding_rnn_seq2seq</code> function, but when I use <code>embedding_attention_seq2seq</code>, it has error like this:</p>\n<p><code>AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'</code></p>\n<p>To fix this, I turned the <code>state_is_tuple</code> to <code>false</code>, but now it has another problem:</p>\n<pre><code>W tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_29 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 730, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 712, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"main.py\", line 29, in &lt;module&gt;\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 208, in main\n    self.sess.run(tf.initialize_all_variables())\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=&lt;Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0&gt;, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'zeros_28', defined at:\n  File \"main.py\", line 29, in &lt;module&gt;\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 169, in main\n    self.model = Model(self.args, self.textData)\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 58, in __init__\n    self.buildNetwork()\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 118, in buildNetwork\n    self.optOp = opt.minimize(self.lossFct)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 198, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 300, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/adam.py\", line 118, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 494, in _zeros_slot\n    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/slot_creator.py\", line 106, in create_zeros_slot\n    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py\", line 1131, in zeros\n    output = constant(0, shape=shape, dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 167, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n</code></pre>\n<p>Code is as follows:</p>\n<pre><code># Creation of the rnn cell\nencoDecoCell = tf.nn.rnn_cell.BasicLSTMCell(self.args.hiddenSize, state_is_tuple=False)  # Or GRUCell, LSTMCell(args.hiddenSize)\n#encoDecoCell = tf.nn.rnn_cell.DropoutWrapper(encoDecoCell, input_keep_prob=1.0, output_keep_prob=1.0)  # TODO: Custom values (WARNING: No dropout when testing !!!)\nencoDecoCell = tf.nn.rnn_cell.MultiRNNCell([encoDecoCell] * self.args.numLayers, state_is_tuple=False)\n\n# Network input (placeholders)\n\nself.encoderInputs  = [tf.placeholder(tf.int32,   [None, ]) for _ in range(self.args.maxLengthEnco)]  # Batch size * sequence length * input dim\n\nself.decoderInputs  = [tf.placeholder(tf.int32,   [None, ], name='inputs') for _ in range(self.args.maxLengthDeco)]  # Same sentence length for input and output (Right ?)\nself.decoderTargets = [tf.placeholder(tf.int32,   [None, ], name='targets') for _ in range(self.args.maxLengthDeco)]\nself.decoderWeights = [tf.placeholder(tf.float32, [None, ], name='weights') for _ in range(self.args.maxLengthDeco)]\n\n# Define the network\n# Here we use an embedding model, it takes integer as input and convert them into word vector for\n# better word representation\ndecoderOutputs, states = tf.nn.seq2seq.embedding_attention_seq2seq(\n    self.encoderInputs,  # List&lt;[batch=?, inputDim=1]&gt;, list of size args.maxLength\n    self.decoderInputs,  # For training, we force the correct output (feed_previous=False)\n    encoDecoCell,\n    self.textData.getVocabularySize(),\n    self.textData.getVocabularySize(),  # Both encoder and decoder have the same number of class\n    embedding_size=self.args.embeddingSize,  # Dimension of each word\n    output_projection=None,  # Eventually\n    feed_previous=bool(self.args.test)  # When we test (self.args.test), we use previous output as next input (feed_previous)\n)\n</code></pre>", "body_text": "My platform is ubuntu 14.04 with tensorflow version of 0.10, CPU version.\nI am using functions in seq2seq.py to build a model. The code works fine when I use the embedding_rnn_seq2seq function, but when I use embedding_attention_seq2seq, it has error like this:\nAttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\nTo fix this, I turned the state_is_tuple to false, but now it has another problem:\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_29 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 730, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 712, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"main.py\", line 29, in <module>\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 208, in main\n    self.sess.run(tf.initialize_all_variables())\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'zeros_28', defined at:\n  File \"main.py\", line 29, in <module>\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 169, in main\n    self.model = Model(self.args, self.textData)\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 58, in __init__\n    self.buildNetwork()\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 118, in buildNetwork\n    self.optOp = opt.minimize(self.lossFct)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 198, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 300, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/adam.py\", line 118, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 494, in _zeros_slot\n    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/slot_creator.py\", line 106, in create_zeros_slot\n    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py\", line 1131, in zeros\n    output = constant(0, shape=shape, dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 167, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n\nCode is as follows:\n# Creation of the rnn cell\nencoDecoCell = tf.nn.rnn_cell.BasicLSTMCell(self.args.hiddenSize, state_is_tuple=False)  # Or GRUCell, LSTMCell(args.hiddenSize)\n#encoDecoCell = tf.nn.rnn_cell.DropoutWrapper(encoDecoCell, input_keep_prob=1.0, output_keep_prob=1.0)  # TODO: Custom values (WARNING: No dropout when testing !!!)\nencoDecoCell = tf.nn.rnn_cell.MultiRNNCell([encoDecoCell] * self.args.numLayers, state_is_tuple=False)\n\n# Network input (placeholders)\n\nself.encoderInputs  = [tf.placeholder(tf.int32,   [None, ]) for _ in range(self.args.maxLengthEnco)]  # Batch size * sequence length * input dim\n\nself.decoderInputs  = [tf.placeholder(tf.int32,   [None, ], name='inputs') for _ in range(self.args.maxLengthDeco)]  # Same sentence length for input and output (Right ?)\nself.decoderTargets = [tf.placeholder(tf.int32,   [None, ], name='targets') for _ in range(self.args.maxLengthDeco)]\nself.decoderWeights = [tf.placeholder(tf.float32, [None, ], name='weights') for _ in range(self.args.maxLengthDeco)]\n\n# Define the network\n# Here we use an embedding model, it takes integer as input and convert them into word vector for\n# better word representation\ndecoderOutputs, states = tf.nn.seq2seq.embedding_attention_seq2seq(\n    self.encoderInputs,  # List<[batch=?, inputDim=1]>, list of size args.maxLength\n    self.decoderInputs,  # For training, we force the correct output (feed_previous=False)\n    encoDecoCell,\n    self.textData.getVocabularySize(),\n    self.textData.getVocabularySize(),  # Both encoder and decoder have the same number of class\n    embedding_size=self.args.embeddingSize,  # Dimension of each word\n    output_projection=None,  # Eventually\n    feed_previous=bool(self.args.test)  # When we test (self.args.test), we use previous output as next input (feed_previous)\n)", "body": "My platform is ubuntu 14.04 with tensorflow version of 0.10, CPU version.\n\nI am using functions in `seq2seq.py` to build a model. The code works fine when I use the `embedding_rnn_seq2seq` function, but when I use `embedding_attention_seq2seq`, it has error like this:\n\n`AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'`\n\nTo fix this, I turned the `state_is_tuple` to `false`, but now it has another problem:\n\n```\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_29 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/framework/op_kernel.cc:926] Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\nE tensorflow/core/common_runtime/executor.cc:334] Executor failed to create kernel. Invalid argument: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 730, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 712, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"main.py\", line 29, in <module>\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 208, in main\n    self.sess.run(tf.initialize_all_variables())\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 52772\n  }\n  dim {\n    size: 52767\n  }\n}\nfloat_val: 0\n\n         [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=<Invalid TensorProto: dtype: DT_FLOAT tensor_shape { dim { size: 52772 } dim { size: 52767 } } float_val: 0>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'zeros_28', defined at:\n  File \"main.py\", line 29, in <module>\n    chatbot.main()\n  File \"/mnt/d/DeepQA/chatbot/chatbot.py\", line 169, in main\n    self.model = Model(self.args, self.textData)\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 58, in __init__\n    self.buildNetwork()\n  File \"/mnt/d/DeepQA/chatbot/model.py\", line 118, in buildNetwork\n    self.optOp = opt.minimize(self.lossFct)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 198, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 300, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/adam.py\", line 118, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 494, in _zeros_slot\n    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/slot_creator.py\", line 106, in create_zeros_slot\n    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py\", line 1131, in zeros\n    output = constant(0, shape=shape, dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 167, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n\nCode is as follows:\n\n```\n# Creation of the rnn cell\nencoDecoCell = tf.nn.rnn_cell.BasicLSTMCell(self.args.hiddenSize, state_is_tuple=False)  # Or GRUCell, LSTMCell(args.hiddenSize)\n#encoDecoCell = tf.nn.rnn_cell.DropoutWrapper(encoDecoCell, input_keep_prob=1.0, output_keep_prob=1.0)  # TODO: Custom values (WARNING: No dropout when testing !!!)\nencoDecoCell = tf.nn.rnn_cell.MultiRNNCell([encoDecoCell] * self.args.numLayers, state_is_tuple=False)\n\n# Network input (placeholders)\n\nself.encoderInputs  = [tf.placeholder(tf.int32,   [None, ]) for _ in range(self.args.maxLengthEnco)]  # Batch size * sequence length * input dim\n\nself.decoderInputs  = [tf.placeholder(tf.int32,   [None, ], name='inputs') for _ in range(self.args.maxLengthDeco)]  # Same sentence length for input and output (Right ?)\nself.decoderTargets = [tf.placeholder(tf.int32,   [None, ], name='targets') for _ in range(self.args.maxLengthDeco)]\nself.decoderWeights = [tf.placeholder(tf.float32, [None, ], name='weights') for _ in range(self.args.maxLengthDeco)]\n\n# Define the network\n# Here we use an embedding model, it takes integer as input and convert them into word vector for\n# better word representation\ndecoderOutputs, states = tf.nn.seq2seq.embedding_attention_seq2seq(\n    self.encoderInputs,  # List<[batch=?, inputDim=1]>, list of size args.maxLength\n    self.decoderInputs,  # For training, we force the correct output (feed_previous=False)\n    encoDecoCell,\n    self.textData.getVocabularySize(),\n    self.textData.getVocabularySize(),  # Both encoder and decoder have the same number of class\n    embedding_size=self.args.embeddingSize,  # Dimension of each word\n    output_projection=None,  # Eventually\n    feed_previous=bool(self.args.test)  # When we test (self.args.test), we use previous output as next input (feed_previous)\n)\n```\n"}