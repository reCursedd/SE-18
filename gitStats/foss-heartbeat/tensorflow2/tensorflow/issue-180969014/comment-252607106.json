{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/252607106", "html_url": "https://github.com/tensorflow/tensorflow/pull/4761#issuecomment-252607106", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4761", "id": 252607106, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjYwNzEwNg==", "user": {"login": "ethancaballero", "id": 5994634, "node_id": "MDQ6VXNlcjU5OTQ2MzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5994634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethancaballero", "html_url": "https://github.com/ethancaballero", "followers_url": "https://api.github.com/users/ethancaballero/followers", "following_url": "https://api.github.com/users/ethancaballero/following{/other_user}", "gists_url": "https://api.github.com/users/ethancaballero/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethancaballero/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethancaballero/subscriptions", "organizations_url": "https://api.github.com/users/ethancaballero/orgs", "repos_url": "https://api.github.com/users/ethancaballero/repos", "events_url": "https://api.github.com/users/ethancaballero/events{/privacy}", "received_events_url": "https://api.github.com/users/ethancaballero/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-10T12:39:27Z", "updated_at": "2016-10-10T12:39:27Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12167999\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alrojo\">@alrojo</a> Does your <code>dynamic_rnn_decoder_attention</code> do beam-search in the graph?<br>\nAlso, I can help out with adding a multi-hop attention option (similar to Memory Networks) to <code>seq2seq</code> for use cases that require transitive reasoning about inputs.</p>", "body_text": "@alrojo Does your dynamic_rnn_decoder_attention do beam-search in the graph?\nAlso, I can help out with adding a multi-hop attention option (similar to Memory Networks) to seq2seq for use cases that require transitive reasoning about inputs.", "body": "@alrojo Does your `dynamic_rnn_decoder_attention` do beam-search in the graph?\nAlso, I can help out with adding a multi-hop attention option (similar to Memory Networks) to `seq2seq` for use cases that require transitive reasoning about inputs.\n"}