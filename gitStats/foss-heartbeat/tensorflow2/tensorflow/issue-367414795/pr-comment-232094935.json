{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/232094935", "pull_request_review_id": 173215578, "id": 232094935, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMjA5NDkzNQ==", "diff_hunk": "@@ -95,6 +95,9 @@ inline tensorflow::Status ConvertDType(tensorflow::DataType tf_dtype,\n     case tensorflow::DataType::DT_INT8:\n       *trt_dtype = nvinfer1::DataType::kINT8;\n       break;\n+    case tensorflow::DataType::DT_QINT8:", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 4, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "No they're not the same:\r\n\r\n- DT_INT8 is not quantize type, it doesn't require min/max range information for computation (similar to DT_INT32, DT_FLOAT32, etc)\r\n- DT_QINT8 is quantize type and we do need range information for any computation. I think this is equivalent to TRT's INT8, since TRT's INT8 needs either calibration to populate the ranges or use setDynamicRange(). This is why I think converting DT_INT8 to TRT's INT8 may be wrong.", "created_at": "2018-11-08T23:13:36Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r232094935", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/232094935"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r232094935"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>No they're not the same:</p>\n<ul>\n<li>DT_INT8 is not quantize type, it doesn't require min/max range information for computation (similar to DT_INT32, DT_FLOAT32, etc)</li>\n<li>DT_QINT8 is quantize type and we do need range information for any computation. I think this is equivalent to TRT's INT8, since TRT's INT8 needs either calibration to populate the ranges or use setDynamicRange(). This is why I think converting DT_INT8 to TRT's INT8 may be wrong.</li>\n</ul>", "body_text": "No they're not the same:\n\nDT_INT8 is not quantize type, it doesn't require min/max range information for computation (similar to DT_INT32, DT_FLOAT32, etc)\nDT_QINT8 is quantize type and we do need range information for any computation. I think this is equivalent to TRT's INT8, since TRT's INT8 needs either calibration to populate the ranges or use setDynamicRange(). This is why I think converting DT_INT8 to TRT's INT8 may be wrong.", "in_reply_to_id": 231582820}