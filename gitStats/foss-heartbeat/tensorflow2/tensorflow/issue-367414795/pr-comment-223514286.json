{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/223514286", "pull_request_review_id": 162660585, "id": 223514286, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMzUxNDI4Ng==", "diff_hunk": "@@ -69,7 +69,8 @@ def tensorrt_rewriter_config(max_batch_size=1,\n                              minimum_segment_size=3,\n                              is_dynamic_op=False,\n                              maximum_cached_engines=1,\n-                             cached_engine_batch_sizes=None):\n+                             cached_engine_batch_sizes=None,\n+                             use_calibration=True):", "path": "tensorflow/contrib/tensorrt/python/trt_convert.py", "position": null, "original_position": 6, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "09c215a9c134dcc52882b153973617e125ad300b", "user": {"login": "wujingyue", "id": 2772612, "node_id": "MDQ6VXNlcjI3NzI2MTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2772612?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wujingyue", "html_url": "https://github.com/wujingyue", "followers_url": "https://api.github.com/users/wujingyue/followers", "following_url": "https://api.github.com/users/wujingyue/following{/other_user}", "gists_url": "https://api.github.com/users/wujingyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/wujingyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wujingyue/subscriptions", "organizations_url": "https://api.github.com/users/wujingyue/orgs", "repos_url": "https://api.github.com/users/wujingyue/repos", "events_url": "https://api.github.com/users/wujingyue/events{/privacy}", "received_events_url": "https://api.github.com/users/wujingyue/received_events", "type": "User", "site_admin": false}, "body": "I feel not_use_calibration and precision_mode are mutually exclusive. When using calibration, you definitely need precision_mode otherwise you wouldn't figure that out from the graph. When not using calibration, you don't need precision_mode because your graph specifies what precision it needs using QuantizeAndDequantize ops (QuantizeAndDequantize has a num_bits flag). In fact, a user could even do mixed-precision execution in *one* graph by adding some QuantizeAndDequantizes with num_bits=8 and some other QuantizeAndDequantizes with num_bits=4. ", "created_at": "2018-10-08T22:27:42Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r223514286", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/223514286"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r223514286"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>I feel not_use_calibration and precision_mode are mutually exclusive. When using calibration, you definitely need precision_mode otherwise you wouldn't figure that out from the graph. When not using calibration, you don't need precision_mode because your graph specifies what precision it needs using QuantizeAndDequantize ops (QuantizeAndDequantize has a num_bits flag). In fact, a user could even do mixed-precision execution in <em>one</em> graph by adding some QuantizeAndDequantizes with num_bits=8 and some other QuantizeAndDequantizes with num_bits=4.</p>", "body_text": "I feel not_use_calibration and precision_mode are mutually exclusive. When using calibration, you definitely need precision_mode otherwise you wouldn't figure that out from the graph. When not using calibration, you don't need precision_mode because your graph specifies what precision it needs using QuantizeAndDequantize ops (QuantizeAndDequantize has a num_bits flag). In fact, a user could even do mixed-precision execution in one graph by adding some QuantizeAndDequantizes with num_bits=8 and some other QuantizeAndDequantizes with num_bits=4.", "in_reply_to_id": 223252646}