{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231588855", "pull_request_review_id": 172562485, "id": 231588855, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTU4ODg1NQ==", "diff_hunk": "@@ -1823,6 +1983,129 @@ tensorflow::Status ConvertActivation(OpConverterParams* params) {\n   return tensorflow::Status::OK();\n }\n \n+tensorflow::Status ConvertQuantize(OpConverterParams* params) {\n+  const auto& inputs = params->inputs;\n+  const auto& node_def = params->node_def;\n+  if (inputs.size() > 0 && inputs.at(0).is_weights()) {\n+    // TensorRT will automatically quantize weights, so we will ignore ranges\n+    // for weights.\n+    params->outputs->push_back(inputs.at(0));\n+    return tensorflow::Status::OK();\n+  }\n+  float min_range = 0.0f;\n+  float max_range = 0.0f;\n+  if (inputs.size() == 1) {\n+    // Get ranges from attributes\n+    TFAttrs attrs(node_def);\n+    if (attrs.count(\"min\") == 0 || attrs.count(\"max\") == 0) {\n+      return tensorflow::errors::InvalidArgument(\n+          \"Min or max attribute not found for quantize, at \", node_def.name());\n+    }\n+    min_range = attrs.get<float>(\"min\");\n+    max_range = attrs.get<float>(\"max\");\n+  } else if (inputs.size() == 3) {\n+    // Get ranges from inputs\n+    if (!inputs.at(1).is_weights() || !inputs.at(2).is_weights()) {\n+      return tensorflow::errors::InvalidArgument(\n+          \"Min and max for quantize must be weights not tensors, at \",\n+          node_def.name());\n+    }\n+    // Min\n+    TRT_ShapedWeights weights_min = inputs.at(1).weights();\n+    auto weights_min_ptr = static_cast<float*>(const_cast<void*>(\n+        weights_min.GetValues()));\n+    min_range = weights_min_ptr[0];\n+    // Max\n+    TRT_ShapedWeights weights_max = inputs.at(2).weights();\n+    auto weights_max_ptr = static_cast<float*>(const_cast<void*>(\n+        weights_max.GetValues()));\n+    max_range = weights_max_ptr[0];\n+  } else {\n+    return tensorflow::errors::InvalidArgument(\n+        \"Expected 1 or 3 inputs for quantize node, at \", node_def.name());\n+  }\n+  // Store ranges for tensor\n+  params->converter->ProvideQuantizationRange(\n+      const_cast<nvinfer1::ITensor*>(inputs.at(0).tensor()),\n+      min_range,\n+      max_range);\n+  // Sometimes, TRT may not quantize a tensor, either because it chooses to\n+  // execute a higher precision kernel or because of op fusion. In these cases,\n+  // accuracy will suffer if the model was trained to expect quantization at\n+  // that tensor. We should consider adding a clip(tensor, min_range, max_range)\n+  // operation here to ensure that any arbitrarily placed quantize node will\n+  // execute as expected. However, this will negatively affect performance. If\n+  // users train their models in a way which models inference as close as\n+  // possible (i.e. not quantizing in place where fusion will occur), then there\n+  // is no problem with the current implementation.\n+  params->outputs->push_back(inputs.at(0));\n+  return tensorflow::Status::OK();\n+}\n+\n+// TODO(pdavoodi): we should update relu6 implementation once TensorRT supports\n+// Relu6 natively.\n+tensorflow::Status ConvertRelu6(OpConverterParams* params) {", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 311, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Please add a test for this method using OpConverterTest.", "created_at": "2018-11-07T16:53:55Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231588855", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231588855"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231588855"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>Please add a test for this method using OpConverterTest.</p>", "body_text": "Please add a test for this method using OpConverterTest."}