{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231577674", "pull_request_review_id": 172562485, "id": 231577674, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTU3NzY3NA==", "diff_hunk": "@@ -128,11 +128,25 @@ Status TrtCandidateSelector::IsTensorRTCandidate(const tensorflow::Node* node) {\n     \"Prod\",\n     \"Max\",\n     \"Min\",\n+    \"Relu6\",\n   };\n+  bool is_supported_op_type = (candidate_ops.count(node->type_string()) ||\n+      PluginFactoryTensorRT::GetInstance()->IsPlugin(node->type_string()));\n+#if NV_TENSORRT_MAJOR >= 5\n+  static const std::set<string> quantize_ops = {\n+    \"QuantizeV2\",\n+    \"Dequantize\",\n+    \"QuantizeAndDequantizeV2\",\n+    \"QuantizeAndDequantizeV3\",\n+    \"FakeQuantWithMinMaxVars\",\n+    \"FakeQuantWithMinMaxArgs\",\n+  };\n+  if (precision_mode == INT8MODE &&", "path": "tensorflow/contrib/tensorrt/convert/convert_graph.cc", "position": null, "original_position": 26, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Please add a comment, saying that in int8 mode we always apply the min/max ranges provided by these ops, regardless of the value of `use_calibration`.", "created_at": "2018-11-07T16:29:43Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231577674", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231577674"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231577674"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>Please add a comment, saying that in int8 mode we always apply the min/max ranges provided by these ops, regardless of the value of <code>use_calibration</code>.</p>", "body_text": "Please add a comment, saying that in int8 mode we always apply the min/max ranges provided by these ops, regardless of the value of use_calibration."}