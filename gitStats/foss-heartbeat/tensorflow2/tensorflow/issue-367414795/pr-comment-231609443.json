{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231609443", "pull_request_review_id": 172562485, "id": 231609443, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTYwOTQ0Mw==", "diff_hunk": "@@ -0,0 +1,197 @@\n+import tensorflow as tf\n+import tensorflow.contrib.tensorrt as trt\n+import numpy as np\n+import argparse\n+from tensorflow.python.framework import test_util\n+from tensorflow.python.platform import test\n+\n+INPUT_NODE_NAME = 'input'\n+OUTPUT_NODE_NAME = 'output'\n+\n+def build_graph(x):\n+  def quantize(x, r):\n+    x = tf.fake_quant_with_min_max_args(x, -r, r)\n+    return x\n+\n+  def dense_layer(x, num_inputs, num_outputs, quantization_range, name='dense'):\n+    \"\"\"Equivalent to tf.layers.dense but with a quantization range between\n+    the MatMul and BiasAdd.\"\"\"\n+    with tf.variable_scope(name) as scope:\n+      kernel = tf.get_variable('kernel', shape=[num_inputs, num_outputs],\n+          dtype=tf.float32, initializer=tf.keras.initializers.glorot_uniform())\n+      bias = tf.get_variable('bias', shape=[num_outputs,],\n+          dtype=tf.float32, initializer=tf.keras.initializers.zeros())\n+      x = tf.matmul(x, kernel)\n+      x = quantize(x, quantization_range)\n+      x = tf.nn.bias_add(x, bias)\n+    return x\n+\n+  x = quantize(x, 1)\n+  # Conv + Bias + Relu6\n+  x = tf.layers.conv2d(x, filters=32, kernel_size=3, use_bias=True)\n+  x = tf.nn.relu6(x)\n+  # Conv + Bias + Relu6\n+  x = tf.layers.conv2d(x, filters=64, kernel_size=3, use_bias=True)\n+  x = tf.nn.relu6(x)\n+  x = tf.reduce_mean(x, [1, 2])\n+  x = quantize(x, 6)\n+  # FC1\n+  x = dense_layer(x, 64, 512, 6, name='dense')\n+  x = quantize(x, 6)\n+  x = tf.nn.relu6(x)\n+  # FC2\n+  x = dense_layer(x, 512, 10, 25, name='dense_1')\n+  x = quantize(x, 25)\n+  x = tf.identity(x, name=OUTPUT_NODE_NAME)\n+  return x\n+\n+def preprocess_fn(x, y):\n+  x = tf.cast(x, tf.float32)\n+  x = tf.expand_dims(x, axis=2)\n+  x = 2.0 * (x / 255.0) - 1.0\n+  y = tf.cast(y, tf.int32)\n+  return x, y\n+\n+def run(is_training, use_trt, batch_size, num_epochs, model_dir):\n+  \"\"\"Train or evaluate the model.\n+\n+  Args:\n+    is_training: Whether to train or evaluate the model. In training mode,\n+      quantization will be simulated where the fake_quant_with_min_max_args\n+      are placed.\n+    use_trt: If true, use TRT INT8 mode for evaluation, which will perform real\n+      quantization. Otherwise use native TensorFlow which will perform\n+      simulated quantization. Ignored if is_training is True.\n+    batch_size: Batch size.\n+    num_epochs: How many epochs to train. Ignored if is_training is False.\n+    model_dir: Where to save or load checkpoint.\n+  \"\"\"\n+  # Get dataset\n+  train, test = tf.keras.datasets.mnist.load_data()\n+  \n+  def eval_input_fn():\n+    mnist_x, mnist_y = test\n+    dataset = tf.data.Dataset.from_tensor_slices((mnist_x, mnist_y))\n+    dataset = dataset.apply(tf.data.experimental.map_and_batch(\n+        map_func=preprocess_fn,\n+        batch_size=batch_size,\n+        num_parallel_calls=8))\n+    dataset = dataset.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)\n+    dataset = dataset.repeat(count=1)\n+    iterator = dataset.make_one_shot_iterator()\n+    features, labels = iterator.get_next()\n+    return features, labels\n+\n+  def train_input_fn():\n+    mnist_x, mnist_y = train\n+    dataset = tf.data.Dataset.from_tensor_slices((mnist_x, mnist_y))\n+    dataset = dataset.shuffle(2*len(mnist_x))\n+    dataset = dataset.apply(tf.data.experimental.map_and_batch(\n+        map_func=preprocess_fn,\n+        batch_size=batch_size,\n+        num_parallel_calls=8))\n+    dataset = dataset.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)\n+    dataset = dataset.repeat(count=num_epochs)\n+    iterator = dataset.make_one_shot_iterator()\n+    features, labels = iterator.get_next()\n+    return features, labels\n+\n+  def model_fn(features, labels, mode):\n+    if is_training:\n+      logits_out = build_graph(features)\n+    else:\n+      graph_def = get_graph_def(use_trt, batch_size, model_dir)\n+      logits_out = tf.import_graph_def(graph_def,\n+          input_map={INPUT_NODE_NAME: features},\n+          return_elements=[OUTPUT_NODE_NAME+':0'],\n+          name='')[0]\n+    loss = tf.losses.sparse_softmax_cross_entropy(\n+        labels=labels,\n+        logits=logits_out)\n+    tf.summary.scalar('loss', loss)\n+    classes_out = tf.argmax(logits_out, axis=1, name='classes_out')\n+    accuracy = tf.metrics.accuracy(\n+        labels=labels,\n+        predictions=classes_out,\n+        name='acc_op')\n+    tf.summary.scalar('accuracy', accuracy[1])\n+    if mode == tf.estimator.ModeKeys.EVAL:\n+      return tf.estimator.EstimatorSpec(\n+          mode,\n+          loss=loss,\n+          eval_metric_ops={'accuracy': accuracy})\n+    elif mode == tf.estimator.ModeKeys.TRAIN:\n+      optimizer = tf.train.AdamOptimizer(learning_rate=1e-2)\n+      train_op = optimizer.minimize(\n+          loss,\n+          global_step=tf.train.get_global_step())\n+      return tf.estimator.EstimatorSpec(\n+          mode,\n+          loss=loss,\n+          train_op=train_op)\n+\n+  tf_config = tf.ConfigProto()\n+  tf_config.gpu_options.allow_growth = True\n+  estimator = tf.estimator.Estimator(\n+      model_fn=model_fn,\n+      model_dir=model_dir,\n+      config=tf.estimator.RunConfig(session_config=tf_config))\n+  if is_training:\n+    estimator.train(train_input_fn)\n+  results = estimator.evaluate(eval_input_fn)\n+  print('accuracy:', results['accuracy'])\n+  return results\n+\n+def get_graph_def(use_trt, batch_size, model_dir):\n+  # Load graph and freeze\n+  with tf.Graph().as_default() as graph:\n+    with tf.Session() as sess:\n+      x = tf.placeholder(shape=(None, 28, 28, 1),\n+                         dtype=tf.float32,\n+                         name=INPUT_NODE_NAME)\n+      logits_out = build_graph(x)\n+      # Load weights\n+      saver = tf.train.Saver()\n+      checkpoint_file = tf.train.latest_checkpoint(model_dir)\n+      saver.restore(sess, checkpoint_file)\n+      # Freeze\n+      graph_def = tf.graph_util.convert_variables_to_constants(\n+          sess,\n+          sess.graph_def,\n+          output_node_names=[OUTPUT_NODE_NAME]\n+      )\n+  # Convert with TF-TRT\n+  if use_trt:\n+    print('nodes before:', len(graph_def.node))\n+    graph_def = trt.create_inference_graph(graph_def,\n+        outputs=[OUTPUT_NODE_NAME],\n+        max_batch_size=batch_size,\n+        precision_mode='int8',\n+        max_workspace_size_bytes=4096 << 19,\n+        minimum_segment_size=2,\n+        use_calibration=False,\n+    )\n+    print('tftrt total nodes:', len(graph_def.node))\n+    print('trt only nodes',\n+        len([1 for n in graph_def.node if str(n.op)=='TRTEngineOp']))\n+  return graph_def\n+\n+\n+class QuantizationAwareTrainingMNISTTest(test_util.TensorFlowTestCase):\n+\n+  def testEval(self):\n+    acc_tf = run(is_training=False,\n+        use_trt=False,\n+        batch_size=128,\n+        num_epochs=None,\n+        model_dir='./quantization_mnist_test_data')['accuracy']", "path": "tensorflow/contrib/tensorrt/test/quantization_mnist_test.py", "position": null, "original_position": 187, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Please add a build rule for the test data and access it maybe using `test.test_src_dir_path()`. There is an example [BUILD](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/BUILD#L3021) and [py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.py#L78) file you can follow.", "created_at": "2018-11-07T17:48:17Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231609443", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231609443"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231609443"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>Please add a build rule for the test data and access it maybe using <code>test.test_src_dir_path()</code>. There is an example <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/BUILD#L3021\">BUILD</a> and <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.py#L78\">py</a> file you can follow.</p>", "body_text": "Please add a build rule for the test data and access it maybe using test.test_src_dir_path(). There is an example BUILD and py file you can follow."}