{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231591061", "pull_request_review_id": 172562485, "id": 231591061, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTU5MTA2MQ==", "diff_hunk": "@@ -1823,6 +1983,129 @@ tensorflow::Status ConvertActivation(OpConverterParams* params) {\n   return tensorflow::Status::OK();\n }\n \n+tensorflow::Status ConvertQuantize(OpConverterParams* params) {\n+  const auto& inputs = params->inputs;\n+  const auto& node_def = params->node_def;\n+  if (inputs.size() > 0 && inputs.at(0).is_weights()) {\n+    // TensorRT will automatically quantize weights, so we will ignore ranges\n+    // for weights.\n+    params->outputs->push_back(inputs.at(0));\n+    return tensorflow::Status::OK();\n+  }\n+  float min_range = 0.0f;\n+  float max_range = 0.0f;\n+  if (inputs.size() == 1) {\n+    // Get ranges from attributes\n+    TFAttrs attrs(node_def);\n+    if (attrs.count(\"min\") == 0 || attrs.count(\"max\") == 0) {\n+      return tensorflow::errors::InvalidArgument(\n+          \"Min or max attribute not found for quantize, at \", node_def.name());\n+    }\n+    min_range = attrs.get<float>(\"min\");\n+    max_range = attrs.get<float>(\"max\");\n+  } else if (inputs.size() == 3) {\n+    // Get ranges from inputs\n+    if (!inputs.at(1).is_weights() || !inputs.at(2).is_weights()) {\n+      return tensorflow::errors::InvalidArgument(\n+          \"Min and max for quantize must be weights not tensors, at \",\n+          node_def.name());\n+    }\n+    // Min\n+    TRT_ShapedWeights weights_min = inputs.at(1).weights();\n+    auto weights_min_ptr = static_cast<float*>(const_cast<void*>(\n+        weights_min.GetValues()));\n+    min_range = weights_min_ptr[0];\n+    // Max\n+    TRT_ShapedWeights weights_max = inputs.at(2).weights();\n+    auto weights_max_ptr = static_cast<float*>(const_cast<void*>(\n+        weights_max.GetValues()));\n+    max_range = weights_max_ptr[0];\n+  } else {\n+    return tensorflow::errors::InvalidArgument(\n+        \"Expected 1 or 3 inputs for quantize node, at \", node_def.name());\n+  }\n+  // Store ranges for tensor\n+  params->converter->ProvideQuantizationRange(\n+      const_cast<nvinfer1::ITensor*>(inputs.at(0).tensor()),\n+      min_range,\n+      max_range);\n+  // Sometimes, TRT may not quantize a tensor, either because it chooses to\n+  // execute a higher precision kernel or because of op fusion. In these cases,\n+  // accuracy will suffer if the model was trained to expect quantization at\n+  // that tensor. We should consider adding a clip(tensor, min_range, max_range)\n+  // operation here to ensure that any arbitrarily placed quantize node will\n+  // execute as expected. However, this will negatively affect performance. If\n+  // users train their models in a way which models inference as close as\n+  // possible (i.e. not quantizing in place where fusion will occur), then there\n+  // is no problem with the current implementation.\n+  params->outputs->push_back(inputs.at(0));\n+  return tensorflow::Status::OK();\n+}\n+\n+// TODO(pdavoodi): we should update relu6 implementation once TensorRT supports\n+// Relu6 natively.\n+tensorflow::Status ConvertRelu6(OpConverterParams* params) {\n+  const auto& inputs = params->inputs;\n+  const auto& node_def = params->node_def;\n+  // ***************************************************************************\n+  // TensorRT does not implement Relu6 natively. This function converts Relu6 op\n+  // to available TensorRT ops: Relu6(x) = min(Relu(x), 6)\n+  // ***************************************************************************\n+\n+  // Input Tensor \n+  const nvinfer1::ITensor* tensor = inputs.at(0).tensor();\n+  \n+  // Relu operation i.e. Relu(x) = max(0, x)\n+  nvinfer1::IActivationLayer* relu_layer = \n+      params->converter->network()->addActivation(\n+          *const_cast<nvinfer1::ITensor*>(tensor),\n+          nvinfer1::ActivationType::kRELU);\n+  TFTRT_RETURN_ERROR_IF_NULLPTR(relu_layer, node_def.name());\n+  \n+  // Large range of relu is problematic during quantization in INT8 precision mode.\n+  // Setting dynamic range of relu = [0.f, 6.0f] helps with quantization.\n+  // TRT only uses dynamic ranges in INT8 precision mode,\n+  // and this does not affect the FP32 path.\n+  params->converter->ProvideQuantizationRange(\n+      relu_layer->getOutput(0), 0.0f, 6.0f);\n+  \n+  // Create a constant layer to store the floating point weight i.e. 6.0f This\n+  // tensor will be broadcasted uniformly during elementwise `min` operation.\n+  // The constant has to have the same rank as the input in order for TRT to\n+  // broadcast\n+  nvinfer1::Dims dims;\n+  dims.nbDims = relu_layer->getOutput(0)->getDimensions().nbDims;\n+  for (int i = 0; i < dims.nbDims; i++)", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 342, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "nit: please add `{}`.", "created_at": "2018-11-07T16:59:03Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231591061", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231591061"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231591061"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>nit: please add <code>{}</code>.</p>", "body_text": "nit: please add {}."}