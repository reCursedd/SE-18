{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231718849", "pull_request_review_id": 172750230, "id": 231718849, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTcxODg0OQ==", "diff_hunk": "@@ -1004,6 +1030,21 @@ Status Converter::PrepareTensorForShape(const TRT_TensorOrWeights& input,\n         this->network()->addConstant(dims, input.weights().GetTrtWeights());\n     TFTRT_RETURN_ERROR_IF_NULLPTR(layer, \"TF-TRT Internal Reshape\");\n     *tensor = layer->getOutput(0);\n+    // We need to set a quantization range for the output tensor of the\n+    // IConstantLayer. Here we set the range to [min(weights), max(weights)].\n+    float min_range = 0.0f;", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 39, "commit_id": "c9774910f1e24b964f0a31fdbf98df472d92501b", "original_commit_id": "de0ed5a2bf01342d4c23357d3abf39eb68bb0b2a", "user": {"login": "trevor-m", "id": 12981474, "node_id": "MDQ6VXNlcjEyOTgxNDc0", "avatar_url": "https://avatars1.githubusercontent.com/u/12981474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/trevor-m", "html_url": "https://github.com/trevor-m", "followers_url": "https://api.github.com/users/trevor-m/followers", "following_url": "https://api.github.com/users/trevor-m/following{/other_user}", "gists_url": "https://api.github.com/users/trevor-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/trevor-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/trevor-m/subscriptions", "organizations_url": "https://api.github.com/users/trevor-m/orgs", "repos_url": "https://api.github.com/users/trevor-m/repos", "events_url": "https://api.github.com/users/trevor-m/events{/privacy}", "received_events_url": "https://api.github.com/users/trevor-m/received_events", "type": "User", "site_admin": false}, "body": "I agree that with use_calibration=True we should not set a range here. \r\nWhen precision_mode is not int8, the quantization ranges will be ignored by TRT. Are you concerned about wasting CPU cycles computing the min/max in this case?", "created_at": "2018-11-07T23:35:25Z", "updated_at": "2018-11-21T23:48:52Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231718849", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231718849"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22788#discussion_r231718849"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22788"}}, "body_html": "<p>I agree that with use_calibration=True we should not set a range here.<br>\nWhen precision_mode is not int8, the quantization ranges will be ignored by TRT. Are you concerned about wasting CPU cycles computing the min/max in this case?</p>", "body_text": "I agree that with use_calibration=True we should not set a range here.\nWhen precision_mode is not int8, the quantization ranges will be ignored by TRT. Are you concerned about wasting CPU cycles computing the min/max in this case?", "in_reply_to_id": 231574607}