{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412552812", "html_url": "https://github.com/tensorflow/tensorflow/issues/21487#issuecomment-412552812", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21487", "id": 412552812, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjU1MjgxMg==", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-13T15:11:02Z", "updated_at": "2018-08-13T15:11:02Z", "author_association": "MEMBER", "body_html": "<blockquote>\n<p>I have try to add <code>with graph.device('gpu:0')</code> when building model, then error came up as:</p>\n<p><code>Non-OK-status: GpuIdManager::TfToCudaGpuId(tf_gpu_id, &amp;cuda_gpu_id) status: Not found: TensorFlow device GPU:0 was not registered</code></p>\n</blockquote>\n<p>I think this is because the device is not initialized when you call <code>trt.create_inference_graph()</code>. Are you running with TF r1.10? Could you retry by initializing a session before calling <code>trt.create_inference_graph()</code>?</p>\n<p>Actually I think this should be fixed in master by <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"335966786\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20318\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/20318/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/20318\">#20318</a>. Could you also help to tried with master?</p>\n<p>Thanks.</p>", "body_text": "I have try to add with graph.device('gpu:0') when building model, then error came up as:\nNon-OK-status: GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id) status: Not found: TensorFlow device GPU:0 was not registered\n\nI think this is because the device is not initialized when you call trt.create_inference_graph(). Are you running with TF r1.10? Could you retry by initializing a session before calling trt.create_inference_graph()?\nActually I think this should be fixed in master by #20318. Could you also help to tried with master?\nThanks.", "body": "> I have try to add `with graph.device('gpu:0')` when building model, then error came up as:\r\n> \r\n> `Non-OK-status: GpuIdManager::TfToCudaGpuId(tf_gpu_id, &cuda_gpu_id) status: Not found: TensorFlow device GPU:0 was not registered`\r\n\r\nI think this is because the device is not initialized when you call `trt.create_inference_graph()`. Are you running with TF r1.10? Could you retry by initializing a session before calling `trt.create_inference_graph()`?\r\n\r\nActually I think this should be fixed in master by #20318. Could you also help to tried with master?\r\n\r\nThanks."}