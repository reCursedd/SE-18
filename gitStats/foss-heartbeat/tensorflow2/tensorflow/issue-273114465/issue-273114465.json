{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14475", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14475/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14475/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14475/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14475", "id": 273114465, "node_id": "MDU6SXNzdWUyNzMxMTQ0NjU=", "number": 14475, "title": "Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain", "user": {"login": "hookover", "id": 9047209, "node_id": "MDQ6VXNlcjkwNDcyMDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/9047209?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hookover", "html_url": "https://github.com/hookover", "followers_url": "https://api.github.com/users/hookover/followers", "following_url": "https://api.github.com/users/hookover/following{/other_user}", "gists_url": "https://api.github.com/users/hookover/gists{/gist_id}", "starred_url": "https://api.github.com/users/hookover/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hookover/subscriptions", "organizations_url": "https://api.github.com/users/hookover/orgs", "repos_url": "https://api.github.com/users/hookover/repos", "events_url": "https://api.github.com/users/hookover/events{/privacy}", "received_events_url": "https://api.github.com/users/hookover/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-11T03:21:54Z", "updated_at": "2018-04-19T20:59:44Z", "closed_at": "2018-01-03T19:36:30Z", "author_association": "NONE", "body_html": "<h3>SYSTEM Infomation</h3>\n<p>ubuntu16.04<br>\ncuda7.5<br>\ncudnn5<br>\ngtx1060<br>\ntensorflow1.0.1<br>\npython3.5<br>\nmemory 15.6G ,used 5.3GB</p>\n<p>$ nvidia-smi</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n| 33%   38C    P2    27W / 120W |   6012MiB /  6071MiB |      3%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1536      G   /usr/lib/xorg/Xorg                           273MiB |\n|    0      3210      G   compiz                                       115MiB |\n|    0      3811      G   ...-token=C6D7A354DD6B35830E1B2860115A47BF    82MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<h3>run train script get this error:</h3>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nCalled with args:\nNamespace(cfg_file='./lstm/lstm.yml', gpu_id=0, max_iters=700000, network_name='LSTM_train', pre_train=None, randomize=False, restore=0, set_cfgs=None)\nUsing config:\n{'CHARSET': '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n 'EXP_DIR': 'lstm_ctc',\n 'FONT': 'fonts/Ubuntu-M.ttf',\n 'GPU_ID': 0,\n 'IMG_SHAPE': [180, 60],\n 'LOG_DIR': 'lstm_ctc',\n 'MAX_CHAR_LEN': 6,\n 'MAX_LEN': 6,\n 'MIN_LEN': 4,\n 'NCHANNELS': 1,\n 'NCLASSES': 64,\n 'NET_NAME': 'LSTM',\n 'NUM_FEATURES': 60,\n 'POOL_SCALE': 2,\n 'RNG_SEED': 3,\n 'ROOT_DIR': '/srv/python/lstm_ctc_ocr_with_tf_1.0.1',\n 'SPACE_INDEX': 0,\n 'SPACE_TOKEN': '',\n 'TEST': {},\n 'TIME_STEP': 90,\n 'TRAIN': {'BATCH_SIZE': 32,\n           'DISPLAY': 100,\n           'GAMMA': 1.0,\n           'LEARNING_RATE': 0.001,\n           'LOG_IMAGE_ITERS': 100,\n           'MOMENTUM': 0.9,\n           'NUM_EPOCHS': 2000,\n           'NUM_HID': 128,\n           'NUM_LAYERS': 2,\n           'SNAPSHOT_INFIX': '',\n           'SNAPSHOT_ITERS': 2000,\n           'SNAPSHOT_PREFIX': 'lstm',\n           'SOLVER': 'RMS',\n           'STEPSIZE': 2000,\n           'WEIGHT_DECAY': 1e-05},\n 'VAL': {'BATCH_SIZE': 128,\n         'NUM_EPOCHS': 1000,\n         'PRINT_NUM': 5,\n         'VAL_STEP': 500}}\nOutput will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/output/lstm_ctc`\nLogs will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/logs/lstm_ctc/lstm_train/2017-11-11-11-13-49`\n/gpu:0\nTensor(\"data:0\", shape=(?, ?, 60), dtype=float32)\nTensor(\"conv4/BiasAdd:0\", shape=(?, ?, 30, 1), dtype=float32)\nTensor(\"time_step_len:0\", shape=(?,), dtype=int32)\nUse network `LSTM_train` in training\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nE tensorflow/core/common_runtime/direct_session.cc:137] \nInternal: failed initializing StreamExecutor \nfor CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: \nCUDA_ERROR_OUT_OF_MEMORY; total memory reported: 18446744073709551615\nTraceback (most recent call last):\n  File \"./lstm/train_net.py\", line 89, in &lt;module&gt;\n    restore=bool(int(args.restore)))\n  File \"./lstm/../lib/lstm/train.py\", line 187, in train_net\n    with tf.Session(config=config) as sess:\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1176, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 552, in __init__\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\n\n</code></pre>\n<p>I will be grateful to anyone for helping me<br>\nThanks everyone</p>", "body_text": "SYSTEM Infomation\nubuntu16.04\ncuda7.5\ncudnn5\ngtx1060\ntensorflow1.0.1\npython3.5\nmemory 15.6G ,used 5.3GB\n$ nvidia-smi\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n| 33%   38C    P2    27W / 120W |   6012MiB /  6071MiB |      3%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1536      G   /usr/lib/xorg/Xorg                           273MiB |\n|    0      3210      G   compiz                                       115MiB |\n|    0      3811      G   ...-token=C6D7A354DD6B35830E1B2860115A47BF    82MiB |\n+-----------------------------------------------------------------------------+\n\nrun train script get this error:\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nCalled with args:\nNamespace(cfg_file='./lstm/lstm.yml', gpu_id=0, max_iters=700000, network_name='LSTM_train', pre_train=None, randomize=False, restore=0, set_cfgs=None)\nUsing config:\n{'CHARSET': '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n 'EXP_DIR': 'lstm_ctc',\n 'FONT': 'fonts/Ubuntu-M.ttf',\n 'GPU_ID': 0,\n 'IMG_SHAPE': [180, 60],\n 'LOG_DIR': 'lstm_ctc',\n 'MAX_CHAR_LEN': 6,\n 'MAX_LEN': 6,\n 'MIN_LEN': 4,\n 'NCHANNELS': 1,\n 'NCLASSES': 64,\n 'NET_NAME': 'LSTM',\n 'NUM_FEATURES': 60,\n 'POOL_SCALE': 2,\n 'RNG_SEED': 3,\n 'ROOT_DIR': '/srv/python/lstm_ctc_ocr_with_tf_1.0.1',\n 'SPACE_INDEX': 0,\n 'SPACE_TOKEN': '',\n 'TEST': {},\n 'TIME_STEP': 90,\n 'TRAIN': {'BATCH_SIZE': 32,\n           'DISPLAY': 100,\n           'GAMMA': 1.0,\n           'LEARNING_RATE': 0.001,\n           'LOG_IMAGE_ITERS': 100,\n           'MOMENTUM': 0.9,\n           'NUM_EPOCHS': 2000,\n           'NUM_HID': 128,\n           'NUM_LAYERS': 2,\n           'SNAPSHOT_INFIX': '',\n           'SNAPSHOT_ITERS': 2000,\n           'SNAPSHOT_PREFIX': 'lstm',\n           'SOLVER': 'RMS',\n           'STEPSIZE': 2000,\n           'WEIGHT_DECAY': 1e-05},\n 'VAL': {'BATCH_SIZE': 128,\n         'NUM_EPOCHS': 1000,\n         'PRINT_NUM': 5,\n         'VAL_STEP': 500}}\nOutput will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/output/lstm_ctc`\nLogs will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/logs/lstm_ctc/lstm_train/2017-11-11-11-13-49`\n/gpu:0\nTensor(\"data:0\", shape=(?, ?, 60), dtype=float32)\nTensor(\"conv4/BiasAdd:0\", shape=(?, ?, 30, 1), dtype=float32)\nTensor(\"time_step_len:0\", shape=(?,), dtype=int32)\nUse network `LSTM_train` in training\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nE tensorflow/core/common_runtime/direct_session.cc:137] \nInternal: failed initializing StreamExecutor \nfor CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: \nCUDA_ERROR_OUT_OF_MEMORY; total memory reported: 18446744073709551615\nTraceback (most recent call last):\n  File \"./lstm/train_net.py\", line 89, in <module>\n    restore=bool(int(args.restore)))\n  File \"./lstm/../lib/lstm/train.py\", line 187, in train_net\n    with tf.Session(config=config) as sess:\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1176, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 552, in __init__\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\n\n\nI will be grateful to anyone for helping me\nThanks everyone", "body": "### SYSTEM Infomation\r\nubuntu16.04\r\ncuda7.5\r\ncudnn5\r\ngtx1060\r\ntensorflow1.0.1\r\npython3.5\r\nmemory 15.6G ,used 5.3GB\r\n\r\n$ nvidia-smi\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\r\n| 33%   38C    P2    27W / 120W |   6012MiB /  6071MiB |      3%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1536      G   /usr/lib/xorg/Xorg                           273MiB |\r\n|    0      3210      G   compiz                                       115MiB |\r\n|    0      3811      G   ...-token=C6D7A354DD6B35830E1B2860115A47BF    82MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n### run train script get this error:\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nCalled with args:\r\nNamespace(cfg_file='./lstm/lstm.yml', gpu_id=0, max_iters=700000, network_name='LSTM_train', pre_train=None, randomize=False, restore=0, set_cfgs=None)\r\nUsing config:\r\n{'CHARSET': '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\r\n 'EXP_DIR': 'lstm_ctc',\r\n 'FONT': 'fonts/Ubuntu-M.ttf',\r\n 'GPU_ID': 0,\r\n 'IMG_SHAPE': [180, 60],\r\n 'LOG_DIR': 'lstm_ctc',\r\n 'MAX_CHAR_LEN': 6,\r\n 'MAX_LEN': 6,\r\n 'MIN_LEN': 4,\r\n 'NCHANNELS': 1,\r\n 'NCLASSES': 64,\r\n 'NET_NAME': 'LSTM',\r\n 'NUM_FEATURES': 60,\r\n 'POOL_SCALE': 2,\r\n 'RNG_SEED': 3,\r\n 'ROOT_DIR': '/srv/python/lstm_ctc_ocr_with_tf_1.0.1',\r\n 'SPACE_INDEX': 0,\r\n 'SPACE_TOKEN': '',\r\n 'TEST': {},\r\n 'TIME_STEP': 90,\r\n 'TRAIN': {'BATCH_SIZE': 32,\r\n           'DISPLAY': 100,\r\n           'GAMMA': 1.0,\r\n           'LEARNING_RATE': 0.001,\r\n           'LOG_IMAGE_ITERS': 100,\r\n           'MOMENTUM': 0.9,\r\n           'NUM_EPOCHS': 2000,\r\n           'NUM_HID': 128,\r\n           'NUM_LAYERS': 2,\r\n           'SNAPSHOT_INFIX': '',\r\n           'SNAPSHOT_ITERS': 2000,\r\n           'SNAPSHOT_PREFIX': 'lstm',\r\n           'SOLVER': 'RMS',\r\n           'STEPSIZE': 2000,\r\n           'WEIGHT_DECAY': 1e-05},\r\n 'VAL': {'BATCH_SIZE': 128,\r\n         'NUM_EPOCHS': 1000,\r\n         'PRINT_NUM': 5,\r\n         'VAL_STEP': 500}}\r\nOutput will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/output/lstm_ctc`\r\nLogs will be saved to `/srv/python/lstm_ctc_ocr_with_tf_1.0.1/logs/lstm_ctc/lstm_train/2017-11-11-11-13-49`\r\n/gpu:0\r\nTensor(\"data:0\", shape=(?, ?, 60), dtype=float32)\r\nTensor(\"conv4/BiasAdd:0\", shape=(?, ?, 30, 1), dtype=float32)\r\nTensor(\"time_step_len:0\", shape=(?,), dtype=int32)\r\nUse network `LSTM_train` in training\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nE tensorflow/core/common_runtime/direct_session.cc:137] \r\nInternal: failed initializing StreamExecutor \r\nfor CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: \r\nCUDA_ERROR_OUT_OF_MEMORY; total memory reported: 18446744073709551615\r\nTraceback (most recent call last):\r\n  File \"./lstm/train_net.py\", line 89, in <module>\r\n    restore=bool(int(args.restore)))\r\n  File \"./lstm/../lib/lstm/train.py\", line 187, in train_net\r\n    with tf.Session(config=config) as sess:\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1176, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 552, in __init__\r\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n\r\n```\r\n\r\nI will be grateful to anyone for helping me\r\nThanks everyone\r\n\r\n"}