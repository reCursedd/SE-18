{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11438", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11438/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11438/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11438/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11438", "id": 242184010, "node_id": "MDU6SXNzdWUyNDIxODQwMTA=", "number": 11438, "title": "Switching Session to MonitoredTrainingSession Produces Negative Dimension Tensors from Queues", "user": {"login": "RylanSchaeffer", "id": 8942987, "node_id": "MDQ6VXNlcjg5NDI5ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8942987?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RylanSchaeffer", "html_url": "https://github.com/RylanSchaeffer", "followers_url": "https://api.github.com/users/RylanSchaeffer/followers", "following_url": "https://api.github.com/users/RylanSchaeffer/following{/other_user}", "gists_url": "https://api.github.com/users/RylanSchaeffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/RylanSchaeffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RylanSchaeffer/subscriptions", "organizations_url": "https://api.github.com/users/RylanSchaeffer/orgs", "repos_url": "https://api.github.com/users/RylanSchaeffer/repos", "events_url": "https://api.github.com/users/RylanSchaeffer/events{/privacy}", "received_events_url": "https://api.github.com/users/RylanSchaeffer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-07-11T21:07:37Z", "updated_at": "2018-02-05T05:16:04Z", "closed_at": "2017-12-21T04:19:15Z", "author_association": "NONE", "body_html": "<p>I already <a href=\"https://stackoverflow.com/questions/44831580/receiving-negative-input-dimensions-with-tensorflow-monitoredtrainingsession\" rel=\"nofollow\">posted</a> on StackOverflow, but received no response.</p>\n<p>I've made some changes to my code since posting on StackOverflow, but the problem is still the same: the readers and queues I use without a problem with a vanilla <code>tf.Session()</code> work fine, but if I try to switch to a <code>tf.train.MonitoredTrainingSession</code>, I get the following error:</p>\n<p><code>InvalidArgumentError (see above for traceback): Shape [15,-1,4] has negative dimensions [[Node: define_inputs/y = Placeholder[dtype=DT_FLOAT, shape=[15,?,4], _device=\"/job:local/replica:0/task:0/cpu:0\"]()]]</code></p>\n<p>I'm using TensorFlow v1.2.0-5-g435cdfc 1.2.1. Here's my code. This works:</p>\n<pre><code># fix random seed to permit comparison between training runs\ntf.set_random_seed(seed=0)\n\n# define graph\nmodel = import_model()\n\nwith tf.Session() as monitored_sess:\n\n    monitored_sess.run(tf.global_variables_initializer())\n\n    # create coordinator to handle threading\n    coord = tf.train.Coordinator()\n\n    # start threads to enqueue input minibatches for training\n    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\n\n    data = monitored_sess.run([training_data])\n    x, y, x_lengths, y_lengths = data[0]\n\n    # when done, ask the threads to stop\n    coord.request_stop()\n\n    # wait for threads to finish\n    coord.join(threads)\n</code></pre>\n<p>But then, this code doesn't work:</p>\n<pre><code>tf.set_random_seed(seed=0)\n\n# define graph\nmodel = import_model()\n\n# create a one process cluster with an in-process server\nserver = tf.train.Server.create_local_server()\n\n# define hooks for writing summaries and model variables to disk\nhooks = construct_training_hooks(model.summary_op, model.loss, train_log_directory)\n\n# create monitored training session to write model variables and summaries to disk\nwith tf.train.MonitoredTrainingSession(master=server.target,\n                                       config=tf.ConfigProto(allow_soft_placement=True),\n                                       is_chief=True,\n                                       hooks=hooks) as monitored_sess:\n\n    # create coordinator to handle threading\n    coord = tf.train.Coordinator()\n\n    # start threads to enqueue input minibatches for training\n    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\n\n    # train\n    data = monitored_sess.run([training_data])\n    x, y, x_lengths, y_lengths = data[0]\n\n    # when done, ask the threads to stop\n    coord.request_stop()\n\n    # wait for threads to finish\n    coord.join(threads)\n</code></pre>\n<p>The function <code>construct_training_hooks</code> is pretty straightforward:</p>\n<pre><code>def construct_training_hooks(summary_op, loss, train_log_directory):\n    hooks = [tf.train.StopAtStepHook(last_step=tf.flags.FLAGS.max_steps),\n             tf.train.CheckpointSaverHook(checkpoint_dir=train_log_directory,\n                                          saver=tf.train.Saver(),\n                                          save_steps=5),\n             tf.train.SummarySaverHook(output_dir=train_log_directory,\n                                       summary_op=summary_op,\n                                       save_steps=1),\n             tf.train.NanTensorHook(loss_tensor=loss)]\n\n    return hooks\n</code></pre>", "body_text": "I already posted on StackOverflow, but received no response.\nI've made some changes to my code since posting on StackOverflow, but the problem is still the same: the readers and queues I use without a problem with a vanilla tf.Session() work fine, but if I try to switch to a tf.train.MonitoredTrainingSession, I get the following error:\nInvalidArgumentError (see above for traceback): Shape [15,-1,4] has negative dimensions [[Node: define_inputs/y = Placeholder[dtype=DT_FLOAT, shape=[15,?,4], _device=\"/job:local/replica:0/task:0/cpu:0\"]()]]\nI'm using TensorFlow v1.2.0-5-g435cdfc 1.2.1. Here's my code. This works:\n# fix random seed to permit comparison between training runs\ntf.set_random_seed(seed=0)\n\n# define graph\nmodel = import_model()\n\nwith tf.Session() as monitored_sess:\n\n    monitored_sess.run(tf.global_variables_initializer())\n\n    # create coordinator to handle threading\n    coord = tf.train.Coordinator()\n\n    # start threads to enqueue input minibatches for training\n    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\n\n    data = monitored_sess.run([training_data])\n    x, y, x_lengths, y_lengths = data[0]\n\n    # when done, ask the threads to stop\n    coord.request_stop()\n\n    # wait for threads to finish\n    coord.join(threads)\n\nBut then, this code doesn't work:\ntf.set_random_seed(seed=0)\n\n# define graph\nmodel = import_model()\n\n# create a one process cluster with an in-process server\nserver = tf.train.Server.create_local_server()\n\n# define hooks for writing summaries and model variables to disk\nhooks = construct_training_hooks(model.summary_op, model.loss, train_log_directory)\n\n# create monitored training session to write model variables and summaries to disk\nwith tf.train.MonitoredTrainingSession(master=server.target,\n                                       config=tf.ConfigProto(allow_soft_placement=True),\n                                       is_chief=True,\n                                       hooks=hooks) as monitored_sess:\n\n    # create coordinator to handle threading\n    coord = tf.train.Coordinator()\n\n    # start threads to enqueue input minibatches for training\n    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\n\n    # train\n    data = monitored_sess.run([training_data])\n    x, y, x_lengths, y_lengths = data[0]\n\n    # when done, ask the threads to stop\n    coord.request_stop()\n\n    # wait for threads to finish\n    coord.join(threads)\n\nThe function construct_training_hooks is pretty straightforward:\ndef construct_training_hooks(summary_op, loss, train_log_directory):\n    hooks = [tf.train.StopAtStepHook(last_step=tf.flags.FLAGS.max_steps),\n             tf.train.CheckpointSaverHook(checkpoint_dir=train_log_directory,\n                                          saver=tf.train.Saver(),\n                                          save_steps=5),\n             tf.train.SummarySaverHook(output_dir=train_log_directory,\n                                       summary_op=summary_op,\n                                       save_steps=1),\n             tf.train.NanTensorHook(loss_tensor=loss)]\n\n    return hooks", "body": "I already [posted](https://stackoverflow.com/questions/44831580/receiving-negative-input-dimensions-with-tensorflow-monitoredtrainingsession) on StackOverflow, but received no response.\r\n\r\nI've made some changes to my code since posting on StackOverflow, but the problem is still the same: the readers and queues I use without a problem with a vanilla `tf.Session()` work fine, but if I try to switch to a `tf.train.MonitoredTrainingSession`, I get the following error:\r\n\r\n`InvalidArgumentError (see above for traceback): Shape [15,-1,4] has negative dimensions\r\n\t [[Node: define_inputs/y = Placeholder[dtype=DT_FLOAT, shape=[15,?,4], _device=\"/job:local/replica:0/task:0/cpu:0\"]()]]`\r\n\r\nI'm using TensorFlow v1.2.0-5-g435cdfc 1.2.1. Here's my code. This works:\r\n\r\n\r\n    # fix random seed to permit comparison between training runs\r\n    tf.set_random_seed(seed=0)\r\n\r\n    # define graph\r\n    model = import_model()\r\n\r\n    with tf.Session() as monitored_sess:\r\n\r\n        monitored_sess.run(tf.global_variables_initializer())\r\n\r\n        # create coordinator to handle threading\r\n        coord = tf.train.Coordinator()\r\n\r\n        # start threads to enqueue input minibatches for training\r\n        threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\r\n\r\n        data = monitored_sess.run([training_data])\r\n        x, y, x_lengths, y_lengths = data[0]\r\n\r\n        # when done, ask the threads to stop\r\n        coord.request_stop()\r\n\r\n        # wait for threads to finish\r\n        coord.join(threads)\r\n\r\nBut then, this code doesn't work:\r\n\r\n    tf.set_random_seed(seed=0)\r\n\r\n    # define graph\r\n    model = import_model()\r\n\r\n    # create a one process cluster with an in-process server\r\n    server = tf.train.Server.create_local_server()\r\n\r\n    # define hooks for writing summaries and model variables to disk\r\n    hooks = construct_training_hooks(model.summary_op, model.loss, train_log_directory)\r\n\r\n    # create monitored training session to write model variables and summaries to disk\r\n    with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                           config=tf.ConfigProto(allow_soft_placement=True),\r\n                                           is_chief=True,\r\n                                           hooks=hooks) as monitored_sess:\r\n\r\n        # create coordinator to handle threading\r\n        coord = tf.train.Coordinator()\r\n\r\n        # start threads to enqueue input minibatches for training\r\n        threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)\r\n\r\n        # train\r\n        data = monitored_sess.run([training_data])\r\n        x, y, x_lengths, y_lengths = data[0]\r\n\r\n        # when done, ask the threads to stop\r\n        coord.request_stop()\r\n\r\n        # wait for threads to finish\r\n        coord.join(threads)\r\n\r\nThe function `construct_training_hooks` is pretty straightforward:\r\n\r\n\r\n    def construct_training_hooks(summary_op, loss, train_log_directory):\r\n        hooks = [tf.train.StopAtStepHook(last_step=tf.flags.FLAGS.max_steps),\r\n                 tf.train.CheckpointSaverHook(checkpoint_dir=train_log_directory,\r\n                                              saver=tf.train.Saver(),\r\n                                              save_steps=5),\r\n                 tf.train.SummarySaverHook(output_dir=train_log_directory,\r\n                                           summary_op=summary_op,\r\n                                           save_steps=1),\r\n                 tf.train.NanTensorHook(loss_tensor=loss)]\r\n\r\n        return hooks\r\n"}