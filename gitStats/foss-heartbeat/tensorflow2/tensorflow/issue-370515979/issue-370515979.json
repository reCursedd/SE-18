{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23014", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23014/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23014/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23014/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23014", "id": 370515979, "node_id": "MDU6SXNzdWUzNzA1MTU5Nzk=", "number": 23014, "title": "Tensorflow Eager Execution Gradient Calculation slower each epoch", "user": {"login": "Goldesel23", "id": 10371630, "node_id": "MDQ6VXNlcjEwMzcxNjMw", "avatar_url": "https://avatars3.githubusercontent.com/u/10371630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Goldesel23", "html_url": "https://github.com/Goldesel23", "followers_url": "https://api.github.com/users/Goldesel23/followers", "following_url": "https://api.github.com/users/Goldesel23/following{/other_user}", "gists_url": "https://api.github.com/users/Goldesel23/gists{/gist_id}", "starred_url": "https://api.github.com/users/Goldesel23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Goldesel23/subscriptions", "organizations_url": "https://api.github.com/users/Goldesel23/orgs", "repos_url": "https://api.github.com/users/Goldesel23/repos", "events_url": "https://api.github.com/users/Goldesel23/events{/privacy}", "received_events_url": "https://api.github.com/users/Goldesel23/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "akshaym", "id": 122911, "node_id": "MDQ6VXNlcjEyMjkxMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/122911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshaym", "html_url": "https://github.com/akshaym", "followers_url": "https://api.github.com/users/akshaym/followers", "following_url": "https://api.github.com/users/akshaym/following{/other_user}", "gists_url": "https://api.github.com/users/akshaym/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshaym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshaym/subscriptions", "organizations_url": "https://api.github.com/users/akshaym/orgs", "repos_url": "https://api.github.com/users/akshaym/repos", "events_url": "https://api.github.com/users/akshaym/events{/privacy}", "received_events_url": "https://api.github.com/users/akshaym/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "akshaym", "id": 122911, "node_id": "MDQ6VXNlcjEyMjkxMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/122911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akshaym", "html_url": "https://github.com/akshaym", "followers_url": "https://api.github.com/users/akshaym/followers", "following_url": "https://api.github.com/users/akshaym/following{/other_user}", "gists_url": "https://api.github.com/users/akshaym/gists{/gist_id}", "starred_url": "https://api.github.com/users/akshaym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akshaym/subscriptions", "organizations_url": "https://api.github.com/users/akshaym/orgs", "repos_url": "https://api.github.com/users/akshaym/repos", "events_url": "https://api.github.com/users/akshaym/events{/privacy}", "received_events_url": "https://api.github.com/users/akshaym/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-10-16T09:19:04Z", "updated_at": "2018-10-17T22:24:28Z", "closed_at": "2018-10-17T22:24:28Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 18.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: 1.10 binary</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0 / 7.2</li>\n<li><strong>GPU model and memory</strong>: 1080Ti - 11 Gb</li>\n<li>Bazel version - NA</li>\n<li>Exact command to reproduce - NA</li>\n<li>Mobile device - NA</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Hi to all!</p>\n<p>I have been implementing Temporal Ensembling for Semi-Supervised Learning by Laine et al. with eager execution and a couple of GitHub users noticed that the computations of the gradients is taking gradually more time each epoch. I don't see what is causing this. After benchmarking I could confirm this issue, but I have no idea why this should be happening. Is anyone faced this problem with <code>tf.GradientTape()</code> ? Or is this is an issue related to eager execution?</p>\n<p>The code for the loss and gradients is the following:</p>\n<pre><code>def temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\n    \"\"\" Gets the loss for the temporal ensembling model\n    Arguments:\n        X_train_labeled {tensor} -- labeled samples\n        y_train_labeled {tensor} -- labeled train labels\n        X_train_unlabeled {tensor} -- unlabeled samples \n        model {tf.keras.Model} -- temporal ensembling model\n        unsupervised_weight {float} -- weight of the unsupervised loss\n        ensembling_targets {np.array} --  ensembling targets\n    Returns:\n        {tensor} -- predictions for the ensembles\n        {tensor} -- loss value\n    \"\"\"\n\n    z_labeled = model(X_train_labeled)\n    z_unlabeled = model(X_train_unlabeled)\n\n    current_predictions = tf.concat([z_labeled, z_unlabeled], 0)\n\n    return current_predictions, tf.losses.softmax_cross_entropy(\n        y_train_labeled, z_labeled) + unsupervised_weight * (\n            tf.losses.mean_squared_error(ensembling_targets, current_predictions))\n\n\ndef temporal_ensembling_gradients(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\n    \"\"\" Gets the gradients for the temporal ensembling model\n    Arguments:\n        X_train_labeled {tensor} -- labeled samples\n        y_train_labeled {tensor} -- labeled train labels\n        X_train_unlabeled {tensor} -- unlabeled samples \n        model {tf.keras.Model} -- temporal ensembling model\n        unsupervised_weight {float} -- weight of the unsupervised loss\n        ensembling_targets {np.array} --  ensembling targets\n    Returns:\n        {tensor} -- predictions for the ensembles\n        {tensor} -- loss value\n        {tensor} -- gradients for each model variables\n    \"\"\"\n\n    with tf.GradientTape() as tape:\n        ensemble_precitions, loss_value = temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled,\n                                                                   model, unsupervised_weight, ensembling_targets)\n\n    return ensemble_precitions, loss_value, tape.gradient(loss_value, model.variables)\n</code></pre>\n<p>I tested it in multiple machines (and in tensorflow 1.10 and 1.11) and the problem persists.</p>\n<p>The gradient calculation takes gradually more time each epoch. Is something related to my code that is causing this or is this a bug with eager execution?</p>\n<p>Best Regards</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\nTensorFlow installed from (source or binary): 1.10 binary\nPython version: 3.6\nCUDA/cuDNN version: 9.0 / 7.2\nGPU model and memory: 1080Ti - 11 Gb\nBazel version - NA\nExact command to reproduce - NA\nMobile device - NA\n\nDescribe the problem\nHi to all!\nI have been implementing Temporal Ensembling for Semi-Supervised Learning by Laine et al. with eager execution and a couple of GitHub users noticed that the computations of the gradients is taking gradually more time each epoch. I don't see what is causing this. After benchmarking I could confirm this issue, but I have no idea why this should be happening. Is anyone faced this problem with tf.GradientTape() ? Or is this is an issue related to eager execution?\nThe code for the loss and gradients is the following:\ndef temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\n    \"\"\" Gets the loss for the temporal ensembling model\n    Arguments:\n        X_train_labeled {tensor} -- labeled samples\n        y_train_labeled {tensor} -- labeled train labels\n        X_train_unlabeled {tensor} -- unlabeled samples \n        model {tf.keras.Model} -- temporal ensembling model\n        unsupervised_weight {float} -- weight of the unsupervised loss\n        ensembling_targets {np.array} --  ensembling targets\n    Returns:\n        {tensor} -- predictions for the ensembles\n        {tensor} -- loss value\n    \"\"\"\n\n    z_labeled = model(X_train_labeled)\n    z_unlabeled = model(X_train_unlabeled)\n\n    current_predictions = tf.concat([z_labeled, z_unlabeled], 0)\n\n    return current_predictions, tf.losses.softmax_cross_entropy(\n        y_train_labeled, z_labeled) + unsupervised_weight * (\n            tf.losses.mean_squared_error(ensembling_targets, current_predictions))\n\n\ndef temporal_ensembling_gradients(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\n    \"\"\" Gets the gradients for the temporal ensembling model\n    Arguments:\n        X_train_labeled {tensor} -- labeled samples\n        y_train_labeled {tensor} -- labeled train labels\n        X_train_unlabeled {tensor} -- unlabeled samples \n        model {tf.keras.Model} -- temporal ensembling model\n        unsupervised_weight {float} -- weight of the unsupervised loss\n        ensembling_targets {np.array} --  ensembling targets\n    Returns:\n        {tensor} -- predictions for the ensembles\n        {tensor} -- loss value\n        {tensor} -- gradients for each model variables\n    \"\"\"\n\n    with tf.GradientTape() as tape:\n        ensemble_precitions, loss_value = temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled,\n                                                                   model, unsupervised_weight, ensembling_targets)\n\n    return ensemble_precitions, loss_value, tape.gradient(loss_value, model.variables)\n\nI tested it in multiple machines (and in tensorflow 1.10 and 1.11) and the problem persists.\nThe gradient calculation takes gradually more time each epoch. Is something related to my code that is causing this or is this a bug with eager execution?\nBest Regards", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: 1.10 binary\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: 9.0 / 7.2\r\n- **GPU model and memory**: 1080Ti - 11 Gb\r\n- Bazel version - NA\r\n- Exact command to reproduce - NA\r\n- Mobile device - NA\r\n### Describe the problem\r\n\r\nHi to all!\r\n\r\nI have been implementing Temporal Ensembling for Semi-Supervised Learning by Laine et al. with eager execution and a couple of GitHub users noticed that the computations of the gradients is taking gradually more time each epoch. I don't see what is causing this. After benchmarking I could confirm this issue, but I have no idea why this should be happening. Is anyone faced this problem with `tf.GradientTape()` ? Or is this is an issue related to eager execution?\r\n\r\nThe code for the loss and gradients is the following:\r\n\r\n```\r\ndef temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\r\n    \"\"\" Gets the loss for the temporal ensembling model\r\n    Arguments:\r\n        X_train_labeled {tensor} -- labeled samples\r\n        y_train_labeled {tensor} -- labeled train labels\r\n        X_train_unlabeled {tensor} -- unlabeled samples \r\n        model {tf.keras.Model} -- temporal ensembling model\r\n        unsupervised_weight {float} -- weight of the unsupervised loss\r\n        ensembling_targets {np.array} --  ensembling targets\r\n    Returns:\r\n        {tensor} -- predictions for the ensembles\r\n        {tensor} -- loss value\r\n    \"\"\"\r\n\r\n    z_labeled = model(X_train_labeled)\r\n    z_unlabeled = model(X_train_unlabeled)\r\n\r\n    current_predictions = tf.concat([z_labeled, z_unlabeled], 0)\r\n\r\n    return current_predictions, tf.losses.softmax_cross_entropy(\r\n        y_train_labeled, z_labeled) + unsupervised_weight * (\r\n            tf.losses.mean_squared_error(ensembling_targets, current_predictions))\r\n\r\n\r\ndef temporal_ensembling_gradients(X_train_labeled, y_train_labeled, X_train_unlabeled, model, unsupervised_weight, ensembling_targets):\r\n    \"\"\" Gets the gradients for the temporal ensembling model\r\n    Arguments:\r\n        X_train_labeled {tensor} -- labeled samples\r\n        y_train_labeled {tensor} -- labeled train labels\r\n        X_train_unlabeled {tensor} -- unlabeled samples \r\n        model {tf.keras.Model} -- temporal ensembling model\r\n        unsupervised_weight {float} -- weight of the unsupervised loss\r\n        ensembling_targets {np.array} --  ensembling targets\r\n    Returns:\r\n        {tensor} -- predictions for the ensembles\r\n        {tensor} -- loss value\r\n        {tensor} -- gradients for each model variables\r\n    \"\"\"\r\n\r\n    with tf.GradientTape() as tape:\r\n        ensemble_precitions, loss_value = temporal_ensembling_loss(X_train_labeled, y_train_labeled, X_train_unlabeled,\r\n                                                                   model, unsupervised_weight, ensembling_targets)\r\n\r\n    return ensemble_precitions, loss_value, tape.gradient(loss_value, model.variables)\r\n```\r\n\r\nI tested it in multiple machines (and in tensorflow 1.10 and 1.11) and the problem persists. \r\n\r\nThe gradient calculation takes gradually more time each epoch. Is something related to my code that is causing this or is this a bug with eager execution?\r\n\r\nBest Regards"}