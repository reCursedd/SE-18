{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/303357358", "html_url": "https://github.com/tensorflow/tensorflow/issues/10073#issuecomment-303357358", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10073", "id": 303357358, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzM1NzM1OA==", "user": {"login": "KashiErez", "id": 8734262, "node_id": "MDQ6VXNlcjg3MzQyNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8734262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KashiErez", "html_url": "https://github.com/KashiErez", "followers_url": "https://api.github.com/users/KashiErez/followers", "following_url": "https://api.github.com/users/KashiErez/following{/other_user}", "gists_url": "https://api.github.com/users/KashiErez/gists{/gist_id}", "starred_url": "https://api.github.com/users/KashiErez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KashiErez/subscriptions", "organizations_url": "https://api.github.com/users/KashiErez/orgs", "repos_url": "https://api.github.com/users/KashiErez/repos", "events_url": "https://api.github.com/users/KashiErez/events{/privacy}", "received_events_url": "https://api.github.com/users/KashiErez/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-23T10:27:21Z", "updated_at": "2017-05-23T10:27:21Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nThanks for the response.</p>\n<p>You are right, running with nvidia-docker works.</p>\n<p>But it used to work also with docker (just not using the GPU).<br>\nIs there any way to support using docker command line?</p>\n<p>I want to explain the motivation:</p>\n<p>We use CPU for:</p>\n<ul>\n<li>inference (serving) in production</li>\n<li>train &amp; inference unit tests</li>\n<li>train &amp; inference sanity tests</li>\n<li>developer machines</li>\n</ul>\n<p>We use GPU for:</p>\n<ul>\n<li>training in production</li>\n</ul>\n<p>Enabling one docker to run both GPU and CPU makes our development cycle simple.<br>\nOtherwise for each one of our services we will need to maintain 2 docker images - one of CPU and one for GPU.</p>\n<p>Thanks :)<br>\nErez</p>", "body_text": "Hi,\nThanks for the response.\nYou are right, running with nvidia-docker works.\nBut it used to work also with docker (just not using the GPU).\nIs there any way to support using docker command line?\nI want to explain the motivation:\nWe use CPU for:\n\ninference (serving) in production\ntrain & inference unit tests\ntrain & inference sanity tests\ndeveloper machines\n\nWe use GPU for:\n\ntraining in production\n\nEnabling one docker to run both GPU and CPU makes our development cycle simple.\nOtherwise for each one of our services we will need to maintain 2 docker images - one of CPU and one for GPU.\nThanks :)\nErez", "body": "Hi, \r\nThanks for the response. \r\n\r\nYou are right, running with nvidia-docker works.\r\n\r\nBut it used to work also with docker (just not using the GPU).\r\nIs there any way to support using docker command line?\r\n\r\nI want to explain the motivation:\r\n\r\nWe use CPU for:\r\n* inference (serving) in production\r\n* train & inference unit tests\r\n* train & inference sanity tests\r\n* developer machines\r\n\r\nWe use GPU for:\r\n* training in production\r\n\r\nEnabling one docker to run both GPU and CPU makes our development cycle simple.\r\nOtherwise for each one of our services we will need to maintain 2 docker images - one of CPU and one for GPU.\r\n\r\nThanks :)\r\nErez"}