{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/432684581", "html_url": "https://github.com/tensorflow/tensorflow/issues/23033#issuecomment-432684581", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23033", "id": 432684581, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMjY4NDU4MQ==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-24T14:38:06Z", "updated_at": "2018-10-24T14:38:06Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25521604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yifannieudem\">@yifannieudem</a> You can probably use <code>tf.gradients(loss, embeddings)</code> for your case which will give a <code>tf.IndexedSlices</code> object corresponding to the gradients of embeddings. You can also use <code>optimizer.apply_gradients</code> to aggregate gradients for repeating word units.</p>\n<p>Manually calculation using jacobian is another way of doing it, make sure that all the types match.</p>", "body_text": "@yifannieudem You can probably use tf.gradients(loss, embeddings) for your case which will give a tf.IndexedSlices object corresponding to the gradients of embeddings. You can also use optimizer.apply_gradients to aggregate gradients for repeating word units.\nManually calculation using jacobian is another way of doing it, make sure that all the types match.", "body": "@yifannieudem You can probably use `tf.gradients(loss, embeddings)` for your case which will give a `tf.IndexedSlices` object corresponding to the gradients of embeddings. You can also use `optimizer.apply_gradients` to aggregate gradients for repeating word units.\r\n\r\nManually calculation using jacobian is another way of doing it, make sure that all the types match.\r\n\r\n\r\n"}