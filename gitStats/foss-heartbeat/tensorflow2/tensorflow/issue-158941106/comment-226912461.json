{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226912461", "html_url": "https://github.com/tensorflow/tensorflow/issues/2706#issuecomment-226912461", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2706", "id": 226912461, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjkxMjQ2MQ==", "user": {"login": "yuanbyu", "id": 2342391, "node_id": "MDQ6VXNlcjIzNDIzOTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2342391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuanbyu", "html_url": "https://github.com/yuanbyu", "followers_url": "https://api.github.com/users/yuanbyu/followers", "following_url": "https://api.github.com/users/yuanbyu/following{/other_user}", "gists_url": "https://api.github.com/users/yuanbyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuanbyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuanbyu/subscriptions", "organizations_url": "https://api.github.com/users/yuanbyu/orgs", "repos_url": "https://api.github.com/users/yuanbyu/repos", "events_url": "https://api.github.com/users/yuanbyu/events{/privacy}", "received_events_url": "https://api.github.com/users/yuanbyu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-18T01:00:08Z", "updated_at": "2016-06-18T01:00:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>A possible workaround is to make:</p>\n<p>def condition(mem_state_previous, hops):<br>\nz = tf.mul(stories, mem_state_previous)<br>\ne_reshaped = tf.reshape(tf.matmul(z , l1_weights) , [1,-1], name=\"e_reshaped\")<br>\ne_gate = tf.nn.softmax(e_reshaped)<br>\ne_unpacked = tf.unpack( tf.reshape(e_gate, [4,1]))<br>\nargmax_e = tf.to_int32(tf.argmax(e_gate, 1)) #should be 1<br>\nreturn tf.logical_and(tf.less(argmax_e[0], error_position),tf.less(hops,5))</p>\n<p>to be true at least once.</p>", "body_text": "A possible workaround is to make:\ndef condition(mem_state_previous, hops):\nz = tf.mul(stories, mem_state_previous)\ne_reshaped = tf.reshape(tf.matmul(z , l1_weights) , [1,-1], name=\"e_reshaped\")\ne_gate = tf.nn.softmax(e_reshaped)\ne_unpacked = tf.unpack( tf.reshape(e_gate, [4,1]))\nargmax_e = tf.to_int32(tf.argmax(e_gate, 1)) #should be 1\nreturn tf.logical_and(tf.less(argmax_e[0], error_position),tf.less(hops,5))\nto be true at least once.", "body": "A possible workaround is to make:\n\ndef condition(mem_state_previous, hops):  \n            z = tf.mul(stories, mem_state_previous)\n            e_reshaped = tf.reshape(tf.matmul(z , l1_weights) , [1,-1], name=\"e_reshaped\")\n            e_gate = tf.nn.softmax(e_reshaped)\n            e_unpacked = tf.unpack( tf.reshape(e_gate, [4,1]))  \n            argmax_e = tf.to_int32(tf.argmax(e_gate, 1)) #should be 1\n            return tf.logical_and(tf.less(argmax_e[0], error_position),tf.less(hops,5))\n\nto be true at least once.  \n"}