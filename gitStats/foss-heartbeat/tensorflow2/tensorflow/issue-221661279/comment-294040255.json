{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294040255", "html_url": "https://github.com/tensorflow/tensorflow/issues/9194#issuecomment-294040255", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9194", "id": 294040255, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDA0MDI1NQ==", "user": {"login": "lwogulis", "id": 13294147, "node_id": "MDQ6VXNlcjEzMjk0MTQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/13294147?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lwogulis", "html_url": "https://github.com/lwogulis", "followers_url": "https://api.github.com/users/lwogulis/followers", "following_url": "https://api.github.com/users/lwogulis/following{/other_user}", "gists_url": "https://api.github.com/users/lwogulis/gists{/gist_id}", "starred_url": "https://api.github.com/users/lwogulis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lwogulis/subscriptions", "organizations_url": "https://api.github.com/users/lwogulis/orgs", "repos_url": "https://api.github.com/users/lwogulis/repos", "events_url": "https://api.github.com/users/lwogulis/events{/privacy}", "received_events_url": "https://api.github.com/users/lwogulis/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-13T22:42:33Z", "updated_at": "2017-04-13T22:42:33Z", "author_association": "NONE", "body_html": "<p>Thanks! I'll check out the group.</p>\n<p>I'm fairly sure I am using XLA, the code I'm running is modified/simplified from the mnist_softmax_xla example:</p>\n<pre><code>from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys \n\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.python.client import timeline\n\nFLAGS = None\n\n\ndef main(_):\n    config = tf.ConfigProto(log_device_placement=True)\n    jit_level = 0 \n    if FLAGS.xla:\n        # Turns on XLA JIT compilation.\n        jit_level = tf.OptimizerOptions.ON_1\n        print('XLA flag on')\n\n    config.graph_options.optimizer_options.global_jit_level = jit_level\n    run_metadata = tf.RunMetadata()\n    # Creates a session with log_device_placement set to True.\n        # Creates a graph.\n    with tf.device('/job:localhost/replica:0/task:0/device:XLA_XPU:0'):\n        with tf.Session(config=config) as sess:\n       # with tf.device('/device:CPU:0'):\n            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \n                            shape=[2, 3], name='a')\n\n            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \n                            shape=[3, 2], name='b')\n            c = tf.square(tf.tanh(tf.matmul(a, b)))\n        # Runs the op.\n        print(sess.run(c, \n              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n              run_metadata=run_metadata))\n        trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n        with open('timeline.ctf.json', 'w') as trace_file:\n            trace_file.write(trace.generate_chrome_trace_format())\n            trace_file.flush()\n        sess.close()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_dir', type=str, \n            default='/tmp/tensorflow/mnist/input_data',\n            help='Directory for storing input data')\n    parser.add_argument(\n              '--xla', type=bool, default=True, help='Turn xla via JIT on')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n</code></pre>\n<p>I also have manually gone into the code and set VLOG_IS_ON to always return true (that seems to deal with the MIN_LOG_LEVEL issues)</p>", "body_text": "Thanks! I'll check out the group.\nI'm fairly sure I am using XLA, the code I'm running is modified/simplified from the mnist_softmax_xla example:\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys \n\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.python.client import timeline\n\nFLAGS = None\n\n\ndef main(_):\n    config = tf.ConfigProto(log_device_placement=True)\n    jit_level = 0 \n    if FLAGS.xla:\n        # Turns on XLA JIT compilation.\n        jit_level = tf.OptimizerOptions.ON_1\n        print('XLA flag on')\n\n    config.graph_options.optimizer_options.global_jit_level = jit_level\n    run_metadata = tf.RunMetadata()\n    # Creates a session with log_device_placement set to True.\n        # Creates a graph.\n    with tf.device('/job:localhost/replica:0/task:0/device:XLA_XPU:0'):\n        with tf.Session(config=config) as sess:\n       # with tf.device('/device:CPU:0'):\n            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \n                            shape=[2, 3], name='a')\n\n            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \n                            shape=[3, 2], name='b')\n            c = tf.square(tf.tanh(tf.matmul(a, b)))\n        # Runs the op.\n        print(sess.run(c, \n              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n              run_metadata=run_metadata))\n        trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n        with open('timeline.ctf.json', 'w') as trace_file:\n            trace_file.write(trace.generate_chrome_trace_format())\n            trace_file.flush()\n        sess.close()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_dir', type=str, \n            default='/tmp/tensorflow/mnist/input_data',\n            help='Directory for storing input data')\n    parser.add_argument(\n              '--xla', type=bool, default=True, help='Turn xla via JIT on')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n\nI also have manually gone into the code and set VLOG_IS_ON to always return true (that seems to deal with the MIN_LOG_LEVEL issues)", "body": "Thanks! I'll check out the group.\r\n\r\nI'm fairly sure I am using XLA, the code I'm running is modified/simplified from the mnist_softmax_xla example:\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport sys \r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nfrom tensorflow.python.client import timeline\r\n\r\nFLAGS = None\r\n\r\n\r\ndef main(_):\r\n    config = tf.ConfigProto(log_device_placement=True)\r\n    jit_level = 0 \r\n    if FLAGS.xla:\r\n        # Turns on XLA JIT compilation.\r\n        jit_level = tf.OptimizerOptions.ON_1\r\n        print('XLA flag on')\r\n\r\n    config.graph_options.optimizer_options.global_jit_level = jit_level\r\n    run_metadata = tf.RunMetadata()\r\n    # Creates a session with log_device_placement set to True.\r\n        # Creates a graph.\r\n    with tf.device('/job:localhost/replica:0/task:0/device:XLA_XPU:0'):\r\n        with tf.Session(config=config) as sess:\r\n       # with tf.device('/device:CPU:0'):\r\n            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \r\n                            shape=[2, 3], name='a')\r\n\r\n            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], \r\n                            shape=[3, 2], name='b')\r\n            c = tf.square(tf.tanh(tf.matmul(a, b)))\r\n        # Runs the op.\r\n        print(sess.run(c, \r\n              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\r\n              run_metadata=run_metadata))\r\n        trace = timeline.Timeline(step_stats=run_metadata.step_stats)\r\n        with open('timeline.ctf.json', 'w') as trace_file:\r\n            trace_file.write(trace.generate_chrome_trace_format())\r\n            trace_file.flush()\r\n        sess.close()\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--data_dir', type=str, \r\n            default='/tmp/tensorflow/mnist/input_data',\r\n            help='Directory for storing input data')\r\n    parser.add_argument(\r\n              '--xla', type=bool, default=True, help='Turn xla via JIT on')\r\n    FLAGS, unparsed = parser.parse_known_args()\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```\r\nI also have manually gone into the code and set VLOG_IS_ON to always return true (that seems to deal with the MIN_LOG_LEVEL issues)"}