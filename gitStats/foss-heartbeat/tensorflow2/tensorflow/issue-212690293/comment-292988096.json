{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292988096", "html_url": "https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-292988096", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8191", "id": 292988096, "node_id": "MDEyOklzc3VlQ29tbWVudDI5Mjk4ODA5Ng==", "user": {"login": "prashantserai", "id": 10653125, "node_id": "MDQ6VXNlcjEwNjUzMTI1", "avatar_url": "https://avatars3.githubusercontent.com/u/10653125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prashantserai", "html_url": "https://github.com/prashantserai", "followers_url": "https://api.github.com/users/prashantserai/followers", "following_url": "https://api.github.com/users/prashantserai/following{/other_user}", "gists_url": "https://api.github.com/users/prashantserai/gists{/gist_id}", "starred_url": "https://api.github.com/users/prashantserai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prashantserai/subscriptions", "organizations_url": "https://api.github.com/users/prashantserai/orgs", "repos_url": "https://api.github.com/users/prashantserai/repos", "events_url": "https://api.github.com/users/prashantserai/events{/privacy}", "received_events_url": "https://api.github.com/users/prashantserai/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-10T15:38:20Z", "updated_at": "2017-04-10T15:38:20Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3009901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/robmsylvester\">@robmsylvester</a> it did train successfully with a batch size of one too, but failed during decoding in the same way or similar way.. here's a full traceback.. the reason I was thinking of this as a connected error was because of the reference to seq2seq_f (which was one of the modified functions) (the #prashant comment from my code to signify a modified line is part of the trace)</p>\n<pre><code>2017-04-10 11:32:27.447042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.928\npciBusID 0000:42:00.0\nTotal memory: 2.95GiB\nFree memory: 2.88GiB\n2017-04-10 11:32:27.447094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-04-10 11:32:27.447102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-04-10 11:32:27.447118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:42:00.0)\nTraceback (most recent call last):\n  File \"translate.py\", line 322, in &lt;module&gt;\n    tf.app.run()\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"translate.py\", line 317, in main\n    decode()\n  File \"translate.py\", line 248, in decode\n    model = create_model(sess, True)\n  File \"translate.py\", line 136, in create_model\n    dtype=dtype)\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 168, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1203, in model_with_buckets\n    decoder_inputs[:bucket[1]])\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 167, in &lt;lambda&gt;\n    self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 144, in seq2seq_f\n    dtype=dtype) #prashant\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 883, in embedding_attention_seq2seq\n    initial_state_attention=initial_state_attention)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 787, in embedding_attention_decoder\n    initial_state_attention=initial_state_attention)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 686, in attention_decoder\n    cell_output, state = cell(x, state)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 796, in __call__\n    % (len(self.state_size), state))\nValueError: Expected state to be a tuple of length 3, but received: Tensor(\"model_with_buckets/embedding_attention_seq2seq/rnn/gru_cell_4/add:0\", shape=(?, 1024), dtype=float32)\n</code></pre>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2883580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/oxwsds\">@oxwsds</a> does your opinion change on the basis of the full trace above?</p>", "body_text": "@robmsylvester it did train successfully with a batch size of one too, but failed during decoding in the same way or similar way.. here's a full traceback.. the reason I was thinking of this as a connected error was because of the reference to seq2seq_f (which was one of the modified functions) (the #prashant comment from my code to signify a modified line is part of the trace)\n2017-04-10 11:32:27.447042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.928\npciBusID 0000:42:00.0\nTotal memory: 2.95GiB\nFree memory: 2.88GiB\n2017-04-10 11:32:27.447094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-04-10 11:32:27.447102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-04-10 11:32:27.447118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:42:00.0)\nTraceback (most recent call last):\n  File \"translate.py\", line 322, in <module>\n    tf.app.run()\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"translate.py\", line 317, in main\n    decode()\n  File \"translate.py\", line 248, in decode\n    model = create_model(sess, True)\n  File \"translate.py\", line 136, in create_model\n    dtype=dtype)\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 168, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1203, in model_with_buckets\n    decoder_inputs[:bucket[1]])\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 167, in <lambda>\n    self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 144, in seq2seq_f\n    dtype=dtype) #prashant\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 883, in embedding_attention_seq2seq\n    initial_state_attention=initial_state_attention)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 787, in embedding_attention_decoder\n    initial_state_attention=initial_state_attention)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 686, in attention_decoder\n    cell_output, state = cell(x, state)\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 796, in __call__\n    % (len(self.state_size), state))\nValueError: Expected state to be a tuple of length 3, but received: Tensor(\"model_with_buckets/embedding_attention_seq2seq/rnn/gru_cell_4/add:0\", shape=(?, 1024), dtype=float32)\n\n@oxwsds does your opinion change on the basis of the full trace above?", "body": "@robmsylvester it did train successfully with a batch size of one too, but failed during decoding in the same way or similar way.. here's a full traceback.. the reason I was thinking of this as a connected error was because of the reference to seq2seq_f (which was one of the modified functions) (the #prashant comment from my code to signify a modified line is part of the trace)\r\n\r\n```\r\n2017-04-10 11:32:27.447042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: GeForce GTX 780 Ti\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.928\r\npciBusID 0000:42:00.0\r\nTotal memory: 2.95GiB\r\nFree memory: 2.88GiB\r\n2017-04-10 11:32:27.447094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-04-10 11:32:27.447102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-04-10 11:32:27.447118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:42:00.0)\r\nTraceback (most recent call last):\r\n  File \"translate.py\", line 322, in <module>\r\n    tf.app.run()\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"translate.py\", line 317, in main\r\n    decode()\r\n  File \"translate.py\", line 248, in decode\r\n    model = create_model(sess, True)\r\n  File \"translate.py\", line 136, in create_model\r\n    dtype=dtype)\r\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 168, in __init__\r\n    softmax_loss_function=softmax_loss_function)\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1203, in model_with_buckets\r\n    decoder_inputs[:bucket[1]])\r\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 167, in <lambda>\r\n    self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\r\n  File \"/data/data6/scratch/serai/models/tutorials/rnn/translate/seq2seq_model.py\", line 144, in seq2seq_f\r\n    dtype=dtype) #prashant\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 883, in embedding_attention_seq2seq\r\n    initial_state_attention=initial_state_attention)\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 787, in embedding_attention_decoder\r\n    initial_state_attention=initial_state_attention)\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 686, in attention_decoder\r\n    cell_output, state = cell(x, state)\r\n  File \"/homes/3/serai/.conda/envs/tensorflow_r1.0_gpu/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 796, in __call__\r\n    % (len(self.state_size), state))\r\nValueError: Expected state to be a tuple of length 3, but received: Tensor(\"model_with_buckets/embedding_attention_seq2seq/rnn/gru_cell_4/add:0\", shape=(?, 1024), dtype=float32)\r\n```\r\n\r\n@oxwsds does your opinion change on the basis of the full trace above?"}