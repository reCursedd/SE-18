{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/306693622", "html_url": "https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-306693622", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8191", "id": 306693622, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjY5MzYyMg==", "user": {"login": "supermeatboy82", "id": 20217387, "node_id": "MDQ6VXNlcjIwMjE3Mzg3", "avatar_url": "https://avatars0.githubusercontent.com/u/20217387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/supermeatboy82", "html_url": "https://github.com/supermeatboy82", "followers_url": "https://api.github.com/users/supermeatboy82/followers", "following_url": "https://api.github.com/users/supermeatboy82/following{/other_user}", "gists_url": "https://api.github.com/users/supermeatboy82/gists{/gist_id}", "starred_url": "https://api.github.com/users/supermeatboy82/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/supermeatboy82/subscriptions", "organizations_url": "https://api.github.com/users/supermeatboy82/orgs", "repos_url": "https://api.github.com/users/supermeatboy82/repos", "events_url": "https://api.github.com/users/supermeatboy82/events{/privacy}", "received_events_url": "https://api.github.com/users/supermeatboy82/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-07T05:50:50Z", "updated_at": "2017-06-07T05:51:29Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2883580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/oxwsds\">@oxwsds</a> As you said, I change input args cell of tf.contrib.legacy_seq2seq.embedding_attention_seq2seq to two different cell {encoder_cells, decoder_cells}. Finally, I get seq2seq model worked.  After 73200 setps, I get perplexity 5.54.<br>\nThen I run decode part,</p>\n<blockquote>\n<blockquote>\n<p>Who is the president of the United States?<br>\nQui est le pr\u00e9sident des \u00c9tats-Unis ?</p>\n</blockquote>\n</blockquote>\n<p>Problem solved.  Thanks.</p>", "body_text": "@oxwsds As you said, I change input args cell of tf.contrib.legacy_seq2seq.embedding_attention_seq2seq to two different cell {encoder_cells, decoder_cells}. Finally, I get seq2seq model worked.  After 73200 setps, I get perplexity 5.54.\nThen I run decode part,\n\n\nWho is the president of the United States?\nQui est le pr\u00e9sident des \u00c9tats-Unis ?\n\n\nProblem solved.  Thanks.", "body": "@oxwsds As you said, I change input args cell of tf.contrib.legacy_seq2seq.embedding_attention_seq2seq to two different cell {encoder_cells, decoder_cells}. Finally, I get seq2seq model worked.  After 73200 setps, I get perplexity 5.54.\r\nThen I run decode part, \r\n >> Who is the president of the United States?\r\nQui est le pr\u00e9sident des \u00c9tats-Unis ?\r\n\r\nProblem solved.  Thanks."}