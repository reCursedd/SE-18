{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/286647614", "html_url": "https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-286647614", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8191", "id": 286647614, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjY0NzYxNA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-15T05:51:03Z", "updated_at": "2017-03-15T05:51:03Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Use:\n\nmulticell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(INTERNALSIZE),\ninput_keep_prob=pkeep) for _ in range(NLAYERS)], state_is_tuple=False)\n\n\nWhich creates a separate grucell object for each layer.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mar 10, 2017 7:44 AM, \"Tom Wanzek\" ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> &lt;<a href=\"https://github.com/ebrevdo\">https://github.com/ebrevdo</a>&gt; So what would be the suggested\n changes to the Shakepeare RNN to allow it to work with the intermediate\n stable release?\n\n Here is the key architectural section of the code, which now fails with\n build#105:\n\n ## the model (see FAQ in README.md)#\n lr = tf.placeholder(tf.float32, name='lr')  # learning rate\n pkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\n batchsize = tf.placeholder(tf.int32, name='batchsize')\n # inputs\n X = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\n Xo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\n Y_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\n Yo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# input state\n Hin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n # using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n\n onecell = rnn.GRUCell(INTERNALSIZE)\n dropcell = rnn.DropoutWrapper(onecell, input_keep_prob=pkeep)\n multicell = rnn.MultiRNNCell([dropcell for _ in range(NLAYERS)], state_is_tuple=False)\n multicell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)\n Yr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\n\n I do not seem to find any documentation regarding a reuse flag?\n\n Thanks in advance.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"212690293\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8191\" href=\"https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-285702372\">#8191 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim6MOOCbx3RJEJe8PQBDXGVIXTGPmks5rkW_jgaJpZM4MWl4f\">https://github.com/notifications/unsubscribe-auth/ABtim6MOOCbx3RJEJe8PQBDXGVIXTGPmks5rkW_jgaJpZM4MWl4f</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Use:\n\nmulticell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(INTERNALSIZE),\ninput_keep_prob=pkeep) for _ in range(NLAYERS)], state_is_tuple=False)\n\n\nWhich creates a separate grucell object for each layer.\n\u2026\nOn Mar 10, 2017 7:44 AM, \"Tom Wanzek\" ***@***.***> wrote:\n @ebrevdo <https://github.com/ebrevdo> So what would be the suggested\n changes to the Shakepeare RNN to allow it to work with the intermediate\n stable release?\n\n Here is the key architectural section of the code, which now fails with\n build#105:\n\n ## the model (see FAQ in README.md)#\n lr = tf.placeholder(tf.float32, name='lr')  # learning rate\n pkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\n batchsize = tf.placeholder(tf.int32, name='batchsize')\n # inputs\n X = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\n Xo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\n Y_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\n Yo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# input state\n Hin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n # using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n\n onecell = rnn.GRUCell(INTERNALSIZE)\n dropcell = rnn.DropoutWrapper(onecell, input_keep_prob=pkeep)\n multicell = rnn.MultiRNNCell([dropcell for _ in range(NLAYERS)], state_is_tuple=False)\n multicell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)\n Yr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\n\n I do not seem to find any documentation regarding a reuse flag?\n\n Thanks in advance.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#8191 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim6MOOCbx3RJEJe8PQBDXGVIXTGPmks5rkW_jgaJpZM4MWl4f>\n .", "body": "Use:\n\nmulticell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(INTERNALSIZE),\ninput_keep_prob=pkeep) for _ in range(NLAYERS)], state_is_tuple=False)\n\n\nWhich creates a separate grucell object for each layer.\n\n\nOn Mar 10, 2017 7:44 AM, \"Tom Wanzek\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> So what would be the suggested\n> changes to the Shakepeare RNN to allow it to work with the intermediate\n> stable release?\n>\n> Here is the key architectural section of the code, which now fails with\n> build#105:\n>\n> ## the model (see FAQ in README.md)#\n> lr = tf.placeholder(tf.float32, name='lr')  # learning rate\n> pkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\n> batchsize = tf.placeholder(tf.int32, name='batchsize')\n> # inputs\n> X = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\n> Xo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\n> Y_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\n> Yo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]# input state\n> Hin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n> # using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n>\n> onecell = rnn.GRUCell(INTERNALSIZE)\n> dropcell = rnn.DropoutWrapper(onecell, input_keep_prob=pkeep)\n> multicell = rnn.MultiRNNCell([dropcell for _ in range(NLAYERS)], state_is_tuple=False)\n> multicell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)\n> Yr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\n>\n> I do not seem to find any documentation regarding a reuse flag?\n>\n> Thanks in advance.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-285702372>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim6MOOCbx3RJEJe8PQBDXGVIXTGPmks5rkW_jgaJpZM4MWl4f>\n> .\n>\n"}