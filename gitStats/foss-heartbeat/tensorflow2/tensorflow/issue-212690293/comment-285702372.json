{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285702372", "html_url": "https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-285702372", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8191", "id": 285702372, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTcwMjM3Mg==", "user": {"login": "tomwanzek", "id": 16323903, "node_id": "MDQ6VXNlcjE2MzIzOTAz", "avatar_url": "https://avatars1.githubusercontent.com/u/16323903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tomwanzek", "html_url": "https://github.com/tomwanzek", "followers_url": "https://api.github.com/users/tomwanzek/followers", "following_url": "https://api.github.com/users/tomwanzek/following{/other_user}", "gists_url": "https://api.github.com/users/tomwanzek/gists{/gist_id}", "starred_url": "https://api.github.com/users/tomwanzek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tomwanzek/subscriptions", "organizations_url": "https://api.github.com/users/tomwanzek/orgs", "repos_url": "https://api.github.com/users/tomwanzek/repos", "events_url": "https://api.github.com/users/tomwanzek/events{/privacy}", "received_events_url": "https://api.github.com/users/tomwanzek/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-10T15:43:51Z", "updated_at": "2017-03-10T15:43:51Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> So what would be the suggested changes to the Shakepeare RNN to allow it to work with the intermediate stable release?</p>\n<p>Here is the key architectural section of the code, which now fails with build#105:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> the model (see FAQ in README.md)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span></span>\nlr <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>lr<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> learning rate</span>\npkeep <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pkeep<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> dropout parameter</span>\nbatchsize <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>batchsize<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> inputs</span>\nX <span class=\"pl-k\">=</span> tf.placeholder(tf.uint8, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>X<span class=\"pl-pds\">'</span></span>)    <span class=\"pl-c\"><span class=\"pl-c\">#</span> [ BATCHSIZE, SEQLEN ]</span>\nXo <span class=\"pl-k\">=</span> tf.one_hot(X, <span class=\"pl-c1\">ALPHASIZE</span>, <span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">0.0</span>)                 <span class=\"pl-c\"><span class=\"pl-c\">#</span> [ BATCHSIZE, SEQLEN, ALPHASIZE ]</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> expected outputs = same sequence shifted by 1 since we are trying to predict the next character</span>\nY_ <span class=\"pl-k\">=</span> tf.placeholder(tf.uint8, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Y_<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> [ BATCHSIZE, SEQLEN ]</span>\nYo_ <span class=\"pl-k\">=</span> tf.one_hot(Y_, <span class=\"pl-c1\">ALPHASIZE</span>, <span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">0.0</span>)               <span class=\"pl-c\"><span class=\"pl-c\">#</span> [ BATCHSIZE, SEQLEN, ALPHASIZE ]</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> input state</span>\nHin <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">INTERNALSIZE</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">NLAYERS</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Hin<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> [ BATCHSIZE, INTERNALSIZE * NLAYERS]</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> dynamic_rnn infers SEQLEN from the size of the inputs Xo</span>\n\nonecell <span class=\"pl-k\">=</span> rnn.GRUCell(<span class=\"pl-c1\">INTERNALSIZE</span>)\ndropcell <span class=\"pl-k\">=</span> rnn.DropoutWrapper(onecell, <span class=\"pl-v\">input_keep_prob</span><span class=\"pl-k\">=</span>pkeep)\nmulticell <span class=\"pl-k\">=</span> rnn.MultiRNNCell([dropcell <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">NLAYERS</span>)], <span class=\"pl-v\">state_is_tuple</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nmulticell <span class=\"pl-k\">=</span> rnn.DropoutWrapper(multicell, <span class=\"pl-v\">output_keep_prob</span><span class=\"pl-k\">=</span>pkeep)\nYr, H <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(multicell, Xo, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>Hin)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence</span></pre></div>\n<p>I do not seem to find any documentation regarding a <code>reuse</code> flag?</p>\n<p>Thanks in advance.</p>", "body_text": "@ebrevdo So what would be the suggested changes to the Shakepeare RNN to allow it to work with the intermediate stable release?\nHere is the key architectural section of the code, which now fails with build#105:\n#\n# the model (see FAQ in README.md)\n#\nlr = tf.placeholder(tf.float32, name='lr')  # learning rate\npkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\nbatchsize = tf.placeholder(tf.int32, name='batchsize')\n\n# inputs\nX = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\nXo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\nY_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\nYo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n# input state\nHin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n\n# using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times\n# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n\nonecell = rnn.GRUCell(INTERNALSIZE)\ndropcell = rnn.DropoutWrapper(onecell, input_keep_prob=pkeep)\nmulticell = rnn.MultiRNNCell([dropcell for _ in range(NLAYERS)], state_is_tuple=False)\nmulticell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)\nYr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)\n# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]\n# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\nI do not seem to find any documentation regarding a reuse flag?\nThanks in advance.", "body": "@ebrevdo So what would be the suggested changes to the Shakepeare RNN to allow it to work with the intermediate stable release?\r\n\r\nHere is the key architectural section of the code, which now fails with build#105:\r\n```python\r\n#\r\n# the model (see FAQ in README.md)\r\n#\r\nlr = tf.placeholder(tf.float32, name='lr')  # learning rate\r\npkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\r\nbatchsize = tf.placeholder(tf.int32, name='batchsize')\r\n\r\n# inputs\r\nX = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\r\nXo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\r\n# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\r\nY_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\r\nYo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\r\n# input state\r\nHin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\r\n\r\n# using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times\r\n# dynamic_rnn infers SEQLEN from the size of the inputs Xo\r\n\r\nonecell = rnn.GRUCell(INTERNALSIZE)\r\ndropcell = rnn.DropoutWrapper(onecell, input_keep_prob=pkeep)\r\nmulticell = rnn.MultiRNNCell([dropcell for _ in range(NLAYERS)], state_is_tuple=False)\r\nmulticell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)\r\nYr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)\r\n# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]\r\n# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\r\n```\r\nI do not seem to find any documentation regarding a `reuse` flag?\r\n\r\nThanks in advance."}