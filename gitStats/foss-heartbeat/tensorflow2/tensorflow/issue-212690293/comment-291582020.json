{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291582020", "html_url": "https://github.com/tensorflow/tensorflow/issues/8191#issuecomment-291582020", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8191", "id": 291582020, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTU4MjAyMA==", "user": {"login": "robmsylvester", "id": 3009901, "node_id": "MDQ6VXNlcjMwMDk5MDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3009901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robmsylvester", "html_url": "https://github.com/robmsylvester", "followers_url": "https://api.github.com/users/robmsylvester/followers", "following_url": "https://api.github.com/users/robmsylvester/following{/other_user}", "gists_url": "https://api.github.com/users/robmsylvester/gists{/gist_id}", "starred_url": "https://api.github.com/users/robmsylvester/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robmsylvester/subscriptions", "organizations_url": "https://api.github.com/users/robmsylvester/orgs", "repos_url": "https://api.github.com/users/robmsylvester/repos", "events_url": "https://api.github.com/users/robmsylvester/events{/privacy}", "received_events_url": "https://api.github.com/users/robmsylvester/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-04T17:59:13Z", "updated_at": "2017-04-04T17:59:13Z", "author_association": "NONE", "body_html": "<p>Hmmm. One thing that stands out to me is in the referenced legacy seq2seq file:</p>\n<p><code>encoder_cell = copy.deepcopy(cell)</code></p>\n<p>This line appears to be used because the same architecture is used on both the encoder and decoder side. They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.</p>\n<p>What happens if you explicitly create the encoder cell AND the decoder cell in your seq2seq model file and pass both along to the legacy library file, making the small adjustments to the functions and their arguments?</p>", "body_text": "Hmmm. One thing that stands out to me is in the referenced legacy seq2seq file:\nencoder_cell = copy.deepcopy(cell)\nThis line appears to be used because the same architecture is used on both the encoder and decoder side. They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.\nWhat happens if you explicitly create the encoder cell AND the decoder cell in your seq2seq model file and pass both along to the legacy library file, making the small adjustments to the functions and their arguments?", "body": "Hmmm. One thing that stands out to me is in the referenced legacy seq2seq file:\r\n\r\n`encoder_cell = copy.deepcopy(cell)`\r\n\r\nThis line appears to be used because the same architecture is used on both the encoder and decoder side. They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself. \r\n\r\nWhat happens if you explicitly create the encoder cell AND the decoder cell in your seq2seq model file and pass both along to the legacy library file, making the small adjustments to the functions and their arguments?\r\n"}