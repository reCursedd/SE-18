{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20628", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20628/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20628/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20628/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20628", "id": 339236392, "node_id": "MDU6SXNzdWUzMzkyMzYzOTI=", "number": 20628, "title": "prefetch_to_device doesn't overlap copy(HtoD) with computation and also may fail", "user": {"login": "sh1ng", "id": 2821871, "node_id": "MDQ6VXNlcjI4MjE4NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2821871?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sh1ng", "html_url": "https://github.com/sh1ng", "followers_url": "https://api.github.com/users/sh1ng/followers", "following_url": "https://api.github.com/users/sh1ng/following{/other_user}", "gists_url": "https://api.github.com/users/sh1ng/gists{/gist_id}", "starred_url": "https://api.github.com/users/sh1ng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sh1ng/subscriptions", "organizations_url": "https://api.github.com/users/sh1ng/orgs", "repos_url": "https://api.github.com/users/sh1ng/repos", "events_url": "https://api.github.com/users/sh1ng/events{/privacy}", "received_events_url": "https://api.github.com/users/sh1ng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-07-08T15:54:17Z", "updated_at": "2018-11-11T18:39:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Ubuntu 16.04.4 LTS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip3</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.8.0</li>\n<li><strong>Python version</strong>: 3</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:9.0</li>\n<li><strong>GPU model and memory</strong>:GTX 1070</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(shape=[None, 128], dtype=np.float32)\ny = tf.placeholder(shape=[None], dtype=np.float32)\n\nds = tf.data.Dataset.from_tensor_slices((x, y))\nds = ds.repeat()\nds = ds.batch(1024)\n############################################\nprefetch = 1024 # if it's bigger than 512 it results in an error\n############################################\nds = ds.apply(tf.contrib.data.prefetch_to_device(\"/gpu:0\", prefetch))\nit = ds.make_initializable_iterator()\n\nw = tf.get_variable(\n                    name='w',\n                    initializer=tf.contrib.layers.xavier_initializer(),\n                    shape=[128, 1],\n                    dtype=tf.float32)\nb = tf.get_variable(\n                    name='b',\n                    initializer=tf.contrib.layers.xavier_initializer(),\n                    shape=[1],\n                    dtype=tf.float32)\n\noptimizer = tf.train.AdamOptimizer(1e-3)\n\nnext_x, next_y = it.get_next()\nprediction = tf.matmul(next_x, w) + b\ntrain = optimizer.minimize((prediction - next_y)**2)\n\nwith tf.Session() as session:\n    x_val = np.random.normal(size=(1024*1024, 128)).astype(np.float32)\n    y_val = np.random.normal(size=(1024 * 1024)).astype(np.float32)\n    session.run(tf.global_variables_initializer())\n    session.run(it.initializer, feed_dict={x: x_val, y: y_val})\n    for _ in range(1024):\n        session.run(train)\n</code></pre>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\nv1.8.0-0-g93bc2e2072 1.8.0</p>\n<h3>Describe the problem</h3>\n<p>If I specify <code>prefetch</code> size to 128 I don't see any parallel data copy(HtoD) overlapping gpu computation(check screenshot and nvidia profiler report).<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/2821871/42421527-412a3124-82d7-11e8-94e7-1f9114d88cec.png\"><img width=\"1072\" alt=\"screen shot 2018-07-08 at 17 36 25\" src=\"https://user-images.githubusercontent.com/2821871/42421527-412a3124-82d7-11e8-94e7-1f9114d88cec.png\" style=\"max-width:100%;\"></a></p>\n<p>And If I increase it it fails</p>\n<pre><code>$ python3 test.py \n2018-07-08 17:32:18.472300: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-07-08 17:32:18.550265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-07-08 17:32:18.550841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:01:00.0\ntotalMemory: 7.93GiB freeMemory: 7.83GiB\n2018-07-08 17:32:18.550852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-07-08 17:32:18.711860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-07-08 17:32:18.711888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n2018-07-08 17:32:18.711907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n2018-07-08 17:32:18.712052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7568 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-07-08 17:32:25.310286: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:650] failed to record completion event; therefore, failed to create inter-stream dependency\n2018-07-08 17:32:25.310311: I tensorflow/stream_executor/stream.cc:4737] stream 0x1448efe0 did not memcpy host-to-device; source: 0x7f8feae97000\n2018-07-08 17:32:25.310316: E tensorflow/stream_executor/stream.cc:309] Error recording event in stream: error recording CUDA event on stream 0x1448f080: CUDA_ERROR_DEINITIALIZED; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.\n2018-07-08 17:32:25.310323: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\n2018-07-08 17:32:25.310328: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:208] Unexpected Event status: 1\nAborted (core dumped)\n</code></pre>\n<p>It'd be nice to have some canonical examples how to use it.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/2173870/prefetch_on_device.nvvp.zip\">prefetch_on_device.nvvp.zip</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04.4 LTS\nTensorFlow installed from (source or binary): pip3\nTensorFlow version (use command below):1.8.0\nPython version: 3\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:9.0\nGPU model and memory:GTX 1070\nExact command to reproduce:\n\nimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(shape=[None, 128], dtype=np.float32)\ny = tf.placeholder(shape=[None], dtype=np.float32)\n\nds = tf.data.Dataset.from_tensor_slices((x, y))\nds = ds.repeat()\nds = ds.batch(1024)\n############################################\nprefetch = 1024 # if it's bigger than 512 it results in an error\n############################################\nds = ds.apply(tf.contrib.data.prefetch_to_device(\"/gpu:0\", prefetch))\nit = ds.make_initializable_iterator()\n\nw = tf.get_variable(\n                    name='w',\n                    initializer=tf.contrib.layers.xavier_initializer(),\n                    shape=[128, 1],\n                    dtype=tf.float32)\nb = tf.get_variable(\n                    name='b',\n                    initializer=tf.contrib.layers.xavier_initializer(),\n                    shape=[1],\n                    dtype=tf.float32)\n\noptimizer = tf.train.AdamOptimizer(1e-3)\n\nnext_x, next_y = it.get_next()\nprediction = tf.matmul(next_x, w) + b\ntrain = optimizer.minimize((prediction - next_y)**2)\n\nwith tf.Session() as session:\n    x_val = np.random.normal(size=(1024*1024, 128)).astype(np.float32)\n    y_val = np.random.normal(size=(1024 * 1024)).astype(np.float32)\n    session.run(tf.global_variables_initializer())\n    session.run(it.initializer, feed_dict={x: x_val, y: y_val})\n    for _ in range(1024):\n        session.run(train)\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.8.0-0-g93bc2e2072 1.8.0\nDescribe the problem\nIf I specify prefetch size to 128 I don't see any parallel data copy(HtoD) overlapping gpu computation(check screenshot and nvidia profiler report).\n\nAnd If I increase it it fails\n$ python3 test.py \n2018-07-08 17:32:18.472300: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-07-08 17:32:18.550265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-07-08 17:32:18.550841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\npciBusID: 0000:01:00.0\ntotalMemory: 7.93GiB freeMemory: 7.83GiB\n2018-07-08 17:32:18.550852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-07-08 17:32:18.711860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-07-08 17:32:18.711888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n2018-07-08 17:32:18.711907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n2018-07-08 17:32:18.712052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7568 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-07-08 17:32:25.310286: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:650] failed to record completion event; therefore, failed to create inter-stream dependency\n2018-07-08 17:32:25.310311: I tensorflow/stream_executor/stream.cc:4737] stream 0x1448efe0 did not memcpy host-to-device; source: 0x7f8feae97000\n2018-07-08 17:32:25.310316: E tensorflow/stream_executor/stream.cc:309] Error recording event in stream: error recording CUDA event on stream 0x1448f080: CUDA_ERROR_DEINITIALIZED; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.\n2018-07-08 17:32:25.310323: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\n2018-07-08 17:32:25.310328: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:208] Unexpected Event status: 1\nAborted (core dumped)\n\nIt'd be nice to have some canonical examples how to use it.\nprefetch_on_device.nvvp.zip", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04.4 LTS\r\n- **TensorFlow installed from (source or binary)**: pip3\r\n- **TensorFlow version (use command below)**:1.8.0\r\n- **Python version**: 3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:9.0\r\n- **GPU model and memory**:GTX 1070\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = tf.placeholder(shape=[None, 128], dtype=np.float32)\r\ny = tf.placeholder(shape=[None], dtype=np.float32)\r\n\r\nds = tf.data.Dataset.from_tensor_slices((x, y))\r\nds = ds.repeat()\r\nds = ds.batch(1024)\r\n############################################\r\nprefetch = 1024 # if it's bigger than 512 it results in an error\r\n############################################\r\nds = ds.apply(tf.contrib.data.prefetch_to_device(\"/gpu:0\", prefetch))\r\nit = ds.make_initializable_iterator()\r\n\r\nw = tf.get_variable(\r\n                    name='w',\r\n                    initializer=tf.contrib.layers.xavier_initializer(),\r\n                    shape=[128, 1],\r\n                    dtype=tf.float32)\r\nb = tf.get_variable(\r\n                    name='b',\r\n                    initializer=tf.contrib.layers.xavier_initializer(),\r\n                    shape=[1],\r\n                    dtype=tf.float32)\r\n\r\noptimizer = tf.train.AdamOptimizer(1e-3)\r\n\r\nnext_x, next_y = it.get_next()\r\nprediction = tf.matmul(next_x, w) + b\r\ntrain = optimizer.minimize((prediction - next_y)**2)\r\n\r\nwith tf.Session() as session:\r\n    x_val = np.random.normal(size=(1024*1024, 128)).astype(np.float32)\r\n    y_val = np.random.normal(size=(1024 * 1024)).astype(np.float32)\r\n    session.run(tf.global_variables_initializer())\r\n    session.run(it.initializer, feed_dict={x: x_val, y: y_val})\r\n    for _ in range(1024):\r\n        session.run(train)\r\n```\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nv1.8.0-0-g93bc2e2072 1.8.0\r\n\r\n### Describe the problem\r\n\r\nIf I specify `prefetch` size to 128 I don't see any parallel data copy(HtoD) overlapping gpu computation(check screenshot and nvidia profiler report).\r\n<img width=\"1072\" alt=\"screen shot 2018-07-08 at 17 36 25\" src=\"https://user-images.githubusercontent.com/2821871/42421527-412a3124-82d7-11e8-94e7-1f9114d88cec.png\">\r\n\r\n\r\nAnd If I increase it it fails\r\n```\r\n$ python3 test.py \r\n2018-07-08 17:32:18.472300: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-07-08 17:32:18.550265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-07-08 17:32:18.550841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.93GiB freeMemory: 7.83GiB\r\n2018-07-08 17:32:18.550852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-07-08 17:32:18.711860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-07-08 17:32:18.711888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \r\n2018-07-08 17:32:18.711907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \r\n2018-07-08 17:32:18.712052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7568 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-07-08 17:32:25.310286: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:650] failed to record completion event; therefore, failed to create inter-stream dependency\r\n2018-07-08 17:32:25.310311: I tensorflow/stream_executor/stream.cc:4737] stream 0x1448efe0 did not memcpy host-to-device; source: 0x7f8feae97000\r\n2018-07-08 17:32:25.310316: E tensorflow/stream_executor/stream.cc:309] Error recording event in stream: error recording CUDA event on stream 0x1448f080: CUDA_ERROR_DEINITIALIZED; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.\r\n2018-07-08 17:32:25.310323: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\r\n2018-07-08 17:32:25.310328: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:208] Unexpected Event status: 1\r\nAborted (core dumped)\r\n```\r\n\r\nIt'd be nice to have some canonical examples how to use it.\r\n\r\n\r\n[prefetch_on_device.nvvp.zip](https://github.com/tensorflow/tensorflow/files/2173870/prefetch_on_device.nvvp.zip)\r\n"}