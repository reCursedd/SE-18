{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411898704", "html_url": "https://github.com/tensorflow/tensorflow/issues/20628#issuecomment-411898704", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20628", "id": 411898704, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTg5ODcwNA==", "user": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-09T21:12:00Z", "updated_at": "2018-08-09T21:12:00Z", "author_association": "MEMBER", "body_html": "<p>So usually I'd recommend a prefetch buffer size of something in the range of 1-4. 1 should mostly work because you want to pipeline the next computation while the current one is going on. With this large number, you're just creating a lot of memory pressure on the GPU without much benefit.</p>\n<p>Also, can you increase the size of the data that is being transferred over? Make it some really large tensor. Then we might be able to see the overlap. ITs possible that overlap is possible even in this scenario but the copied tensor is small and is competing with other CPU work (not shown on this GPU profile).</p>", "body_text": "So usually I'd recommend a prefetch buffer size of something in the range of 1-4. 1 should mostly work because you want to pipeline the next computation while the current one is going on. With this large number, you're just creating a lot of memory pressure on the GPU without much benefit.\nAlso, can you increase the size of the data that is being transferred over? Make it some really large tensor. Then we might be able to see the overlap. ITs possible that overlap is possible even in this scenario but the copied tensor is small and is competing with other CPU work (not shown on this GPU profile).", "body": "So usually I'd recommend a prefetch buffer size of something in the range of 1-4. 1 should mostly work because you want to pipeline the next computation while the current one is going on. With this large number, you're just creating a lot of memory pressure on the GPU without much benefit. \r\n\r\nAlso, can you increase the size of the data that is being transferred over? Make it some really large tensor. Then we might be able to see the overlap. ITs possible that overlap is possible even in this scenario but the copied tensor is small and is competing with other CPU work (not shown on this GPU profile)."}