{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19303", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19303/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19303/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19303/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19303", "id": 323381183, "node_id": "MDU6SXNzdWUzMjMzODExODM=", "number": 19303, "title": "Model checkpoint issue: serialization error for tf.string", "user": {"login": "pbamotra", "id": 6505165, "node_id": "MDQ6VXNlcjY1MDUxNjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/6505165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pbamotra", "html_url": "https://github.com/pbamotra", "followers_url": "https://api.github.com/users/pbamotra/followers", "following_url": "https://api.github.com/users/pbamotra/following{/other_user}", "gists_url": "https://api.github.com/users/pbamotra/gists{/gist_id}", "starred_url": "https://api.github.com/users/pbamotra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pbamotra/subscriptions", "organizations_url": "https://api.github.com/users/pbamotra/orgs", "repos_url": "https://api.github.com/users/pbamotra/repos", "events_url": "https://api.github.com/users/pbamotra/events{/privacy}", "received_events_url": "https://api.github.com/users/pbamotra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-15T20:59:11Z", "updated_at": "2018-11-20T13:27:52Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>TF version: 1.8<br>\nInstallation: tensorflow/tensorflow:latest-gpu<br>\nOS details:<br>\nDistributor ID:\tUbuntu<br>\nDescription:\tUbuntu 16.04.4 LTS<br>\nRelease:\t16.04<br>\nCodename:\txenial</p>\n<p>AWS instance: p2.xlarge<br>\nGPU details:</p>\n<pre><code>[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 16086859869116902206\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 11285974221\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 13890740079777279899\nphysical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n]\n</code></pre>\n<p>Custom code:</p>\n<div class=\"highlight highlight-source-python\"><pre>use_model <span class=\"pl-k\">=</span> hub.Module(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>http://tfhub.dev/google/universal-sentence-encoder/1<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)<span class=\"pl-bu\">;</span>\nsess.run(tf.global_variables_initializer())<span class=\"pl-bu\">;</span>\nsess.run(tf.tables_initializer())<span class=\"pl-bu\">;</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">USEEmbedding</span>(<span class=\"pl-smi\">x</span>):\n    <span class=\"pl-k\">return</span> use_model(tf.squeeze(tf.cast(x, tf.string)), \n                      <span class=\"pl-v\">signature</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">as_dict</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default<span class=\"pl-pds\">\"</span></span>]\n \ninput_text <span class=\"pl-k\">=</span> layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.string)\nembedding <span class=\"pl-k\">=</span> layers.Lambda(USEEmbedding, <span class=\"pl-v\">output_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">512</span>,))(input_text)\ndense <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">1024</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(embedding)\nbnorm <span class=\"pl-k\">=</span> layers.BatchNormalization()(dense)\npred <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">2000</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>)(bnorm)\n\nmodel <span class=\"pl-k\">=</span> Model(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>[input_text], <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>pred)\n\nmodel.compile(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sparse_categorical_crossentropy<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adam<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\nmodel.summary()\n\ncallbacks <span class=\"pl-k\">=</span> [keras.callbacks.EarlyStopping(<span class=\"pl-v\">monitor</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>val_acc<span class=\"pl-pds\">'</span></span>,\n                                               <span class=\"pl-v\">min_delta</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-3</span>,\n                                               <span class=\"pl-v\">patience</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>,\n                                               <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n                                               <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>auto<span class=\"pl-pds\">'</span></span>),\n             keras.callbacks.ModelCheckpoint(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../models/best-weights.h5<span class=\"pl-pds\">'</span></span>,\n                                                 <span class=\"pl-v\">monitor</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>val_acc<span class=\"pl-pds\">'</span></span>,\n                                                 <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n                                                 <span class=\"pl-v\">save_best_only</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                                                 <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>auto<span class=\"pl-pds\">'</span></span>),\n             keras.callbacks.TensorBoard(<span class=\"pl-v\">log_dir</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>../tb-logs<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">histogram_freq</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n                                         <span class=\"pl-v\">write_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">write_images</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)]\n\ntrain_text <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">'</span> <span class=\"pl-pds\">'</span></span>.join(t.split()[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">20</span>]) <span class=\"pl-k\">for</span> t <span class=\"pl-k\">in</span> train_x.sentences.tolist()]\ntrain_text <span class=\"pl-k\">=</span> np.array(train_text, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">object</span>)[:, np.newaxis]\nvalid_text <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">'</span> <span class=\"pl-pds\">'</span></span>.join(t.split()[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">20</span>]) <span class=\"pl-k\">for</span> t <span class=\"pl-k\">in</span> valid_x.sentences.tolist()]\nvalid_text <span class=\"pl-k\">=</span> np.array(valid_text, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">object</span>)[:, np.newaxis]\n\nmodel.fit(train_text , train[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels<span class=\"pl-pds\">'</span></span>].tolist(),\n          <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>(valid_text, valid[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>labels<span class=\"pl-pds\">'</span></span>].tolist()),\n          <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>,\n          <span class=\"pl-v\">callbacks</span><span class=\"pl-k\">=</span>callbacks, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<pre><code>Error:\n\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-81-e546b70750dc&gt; in &lt;module&gt;()\n      2           validation_data=(valid_text, valid['labels'].tolist()),\n      3           epochs=100, batch_size=256,\n----&gt; 4           callbacks=callbacks, shuffle=True)\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-&gt; 1705                               validation_steps=validation_steps)\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n   1254                             for l, o in zip(out_labels, val_outs):\n   1255                                 epoch_logs['val_' + l] = o\n-&gt; 1256             callbacks.on_epoch_end(epoch, epoch_logs)\n   1257             if callback_model.stop_training:\n   1258                 break\n\n/usr/local/lib/python2.7/dist-packages/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\n     75         logs = logs or {}\n     76         for callback in self.callbacks:\n---&gt; 77             callback.on_epoch_end(epoch, logs)\n     78 \n     79     def on_batch_begin(self, batch, logs=None):\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\n    466               self.model.save_weights(filepath, overwrite=True)\n    467             else:\n--&gt; 468               self.model.save(filepath, overwrite=True)\n    469           else:\n    470             if self.verbose &gt; 0:\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in save(self, filepath, overwrite, include_optimizer)\n   2589         \"\"\"\n   2590         from ..models import save_model\n-&gt; 2591         save_model(self, filepath, overwrite, include_optimizer)\n   2592 \n   2593     def save_weights(self, filepath, overwrite=True):\n\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in save_model(model, filepath, overwrite, include_optimizer)\n    125             'class_name': model.__class__.__name__,\n    126             'config': model.get_config()\n--&gt; 127         }, default=get_json_type).encode('utf8')\n    128 \n    129         model_weights_group = f.create_group('model_weights')\n\n/usr/lib/python2.7/json/__init__.pyc in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\n    249         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n    250         separators=separators, encoding=encoding, default=default,\n--&gt; 251         sort_keys=sort_keys, **kw).encode(obj)\n    252 \n    253 \n\n/usr/lib/python2.7/json/encoder.pyc in encode(self, o)\n    205         # exceptions aren't as detailed.  The list call should be roughly\n    206         # equivalent to the PySequence_Fast that ''.join() would do.\n--&gt; 207         chunks = self.iterencode(o, _one_shot=True)\n    208         if not isinstance(chunks, (list, tuple)):\n    209             chunks = list(chunks)\n\n/usr/lib/python2.7/json/encoder.pyc in iterencode(self, o, _one_shot)\n    268                 self.key_separator, self.item_separator, self.sort_keys,\n    269                 self.skipkeys, _one_shot)\n--&gt; 270         return _iterencode(o, 0)\n    271 \n    272 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in get_json_type(obj)\n    102             return obj.__name__\n    103 \n--&gt; 104         raise TypeError('Not JSON Serializable:', obj)\n    105 \n    106     from . import __version__ as keras_version\n\nTypeError: ('Not JSON Serializable:', tf.string)\n</code></pre>", "body_text": "TF version: 1.8\nInstallation: tensorflow/tensorflow:latest-gpu\nOS details:\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 16.04.4 LTS\nRelease:\t16.04\nCodename:\txenial\nAWS instance: p2.xlarge\nGPU details:\n[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 16086859869116902206\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 11285974221\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 13890740079777279899\nphysical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n]\n\nCustom code:\nuse_model = hub.Module(\"http://tfhub.dev/google/universal-sentence-encoder/1\", trainable=True);\nsess.run(tf.global_variables_initializer());\nsess.run(tf.tables_initializer());\n\ndef USEEmbedding(x):\n    return use_model(tf.squeeze(tf.cast(x, tf.string)), \n                      signature=\"default\", as_dict=True)[\"default\"]\n \ninput_text = layers.Input(shape=(1,), dtype=tf.string)\nembedding = layers.Lambda(USEEmbedding, output_shape=(512,))(input_text)\ndense = layers.Dense(1024, activation='relu')(embedding)\nbnorm = layers.BatchNormalization()(dense)\npred = layers.Dense(2000, activation='softmax')(bnorm)\n\nmodel = Model(inputs=[input_text], outputs=pred)\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n\ncallbacks = [keras.callbacks.EarlyStopping(monitor='val_acc',\n                                               min_delta=1e-3,\n                                               patience=8,\n                                               verbose=0,\n                                               mode='auto'),\n             keras.callbacks.ModelCheckpoint('../models/best-weights.h5',\n                                                 monitor='val_acc',\n                                                 verbose=1,\n                                                 save_best_only=True,\n                                                 mode='auto'),\n             keras.callbacks.TensorBoard(log_dir='../tb-logs', histogram_freq=0,\n                                         write_graph=True, write_images=False)]\n\ntrain_text = [' '.join(t.split()[0:20]) for t in train_x.sentences.tolist()]\ntrain_text = np.array(train_text, dtype=object)[:, np.newaxis]\nvalid_text = [' '.join(t.split()[0:20]) for t in valid_x.sentences.tolist()]\nvalid_text = np.array(valid_text, dtype=object)[:, np.newaxis]\n\nmodel.fit(train_text , train['labels'].tolist(),\n          validation_data=(valid_text, valid['labels'].tolist()),\n          epochs=100, batch_size=256,\n          callbacks=callbacks, shuffle=True)\nError:\n\nTypeError                                 Traceback (most recent call last)\n<ipython-input-81-e546b70750dc> in <module>()\n      2           validation_data=(valid_text, valid['labels'].tolist()),\n      3           epochs=100, batch_size=256,\n----> 4           callbacks=callbacks, shuffle=True)\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-> 1705                               validation_steps=validation_steps)\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n   1254                             for l, o in zip(out_labels, val_outs):\n   1255                                 epoch_logs['val_' + l] = o\n-> 1256             callbacks.on_epoch_end(epoch, epoch_logs)\n   1257             if callback_model.stop_training:\n   1258                 break\n\n/usr/local/lib/python2.7/dist-packages/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\n     75         logs = logs or {}\n     76         for callback in self.callbacks:\n---> 77             callback.on_epoch_end(epoch, logs)\n     78 \n     79     def on_batch_begin(self, batch, logs=None):\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\n    466               self.model.save_weights(filepath, overwrite=True)\n    467             else:\n--> 468               self.model.save(filepath, overwrite=True)\n    469           else:\n    470             if self.verbose > 0:\n\n/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in save(self, filepath, overwrite, include_optimizer)\n   2589         \"\"\"\n   2590         from ..models import save_model\n-> 2591         save_model(self, filepath, overwrite, include_optimizer)\n   2592 \n   2593     def save_weights(self, filepath, overwrite=True):\n\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in save_model(model, filepath, overwrite, include_optimizer)\n    125             'class_name': model.__class__.__name__,\n    126             'config': model.get_config()\n--> 127         }, default=get_json_type).encode('utf8')\n    128 \n    129         model_weights_group = f.create_group('model_weights')\n\n/usr/lib/python2.7/json/__init__.pyc in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\n    249         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n    250         separators=separators, encoding=encoding, default=default,\n--> 251         sort_keys=sort_keys, **kw).encode(obj)\n    252 \n    253 \n\n/usr/lib/python2.7/json/encoder.pyc in encode(self, o)\n    205         # exceptions aren't as detailed.  The list call should be roughly\n    206         # equivalent to the PySequence_Fast that ''.join() would do.\n--> 207         chunks = self.iterencode(o, _one_shot=True)\n    208         if not isinstance(chunks, (list, tuple)):\n    209             chunks = list(chunks)\n\n/usr/lib/python2.7/json/encoder.pyc in iterencode(self, o, _one_shot)\n    268                 self.key_separator, self.item_separator, self.sort_keys,\n    269                 self.skipkeys, _one_shot)\n--> 270         return _iterencode(o, 0)\n    271 \n    272 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in get_json_type(obj)\n    102             return obj.__name__\n    103 \n--> 104         raise TypeError('Not JSON Serializable:', obj)\n    105 \n    106     from . import __version__ as keras_version\n\nTypeError: ('Not JSON Serializable:', tf.string)", "body": "TF version: 1.8\r\nInstallation: tensorflow/tensorflow:latest-gpu\r\nOS details: \r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 16.04.4 LTS\r\nRelease:\t16.04\r\nCodename:\txenial\r\n\r\nAWS instance: p2.xlarge\r\nGPU details:\r\n```\r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 16086859869116902206\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nmemory_limit: 11285974221\r\nlocality {\r\n  bus_id: 1\r\n  links {\r\n  }\r\n}\r\nincarnation: 13890740079777279899\r\nphysical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\r\n]\r\n```\r\n\r\nCustom code:\r\n```python\r\nuse_model = hub.Module(\"http://tfhub.dev/google/universal-sentence-encoder/1\", trainable=True);\r\nsess.run(tf.global_variables_initializer());\r\nsess.run(tf.tables_initializer());\r\n\r\ndef USEEmbedding(x):\r\n    return use_model(tf.squeeze(tf.cast(x, tf.string)), \r\n                      signature=\"default\", as_dict=True)[\"default\"]\r\n \r\ninput_text = layers.Input(shape=(1,), dtype=tf.string)\r\nembedding = layers.Lambda(USEEmbedding, output_shape=(512,))(input_text)\r\ndense = layers.Dense(1024, activation='relu')(embedding)\r\nbnorm = layers.BatchNormalization()(dense)\r\npred = layers.Dense(2000, activation='softmax')(bnorm)\r\n\r\nmodel = Model(inputs=[input_text], outputs=pred)\r\n\r\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\nmodel.summary()\r\n\r\ncallbacks = [keras.callbacks.EarlyStopping(monitor='val_acc',\r\n                                               min_delta=1e-3,\r\n                                               patience=8,\r\n                                               verbose=0,\r\n                                               mode='auto'),\r\n             keras.callbacks.ModelCheckpoint('../models/best-weights.h5',\r\n                                                 monitor='val_acc',\r\n                                                 verbose=1,\r\n                                                 save_best_only=True,\r\n                                                 mode='auto'),\r\n             keras.callbacks.TensorBoard(log_dir='../tb-logs', histogram_freq=0,\r\n                                         write_graph=True, write_images=False)]\r\n\r\ntrain_text = [' '.join(t.split()[0:20]) for t in train_x.sentences.tolist()]\r\ntrain_text = np.array(train_text, dtype=object)[:, np.newaxis]\r\nvalid_text = [' '.join(t.split()[0:20]) for t in valid_x.sentences.tolist()]\r\nvalid_text = np.array(valid_text, dtype=object)[:, np.newaxis]\r\n\r\nmodel.fit(train_text , train['labels'].tolist(),\r\n          validation_data=(valid_text, valid['labels'].tolist()),\r\n          epochs=100, batch_size=256,\r\n          callbacks=callbacks, shuffle=True)\r\n```\r\n\r\n```\r\nError:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-81-e546b70750dc> in <module>()\r\n      2           validation_data=(valid_text, valid['labels'].tolist()),\r\n      3           epochs=100, batch_size=256,\r\n----> 4           callbacks=callbacks, shuffle=True)\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1703                               initial_epoch=initial_epoch,\r\n   1704                               steps_per_epoch=steps_per_epoch,\r\n-> 1705                               validation_steps=validation_steps)\r\n   1706 \r\n   1707     def evaluate(self, x=None, y=None,\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n   1254                             for l, o in zip(out_labels, val_outs):\r\n   1255                                 epoch_logs['val_' + l] = o\r\n-> 1256             callbacks.on_epoch_end(epoch, epoch_logs)\r\n   1257             if callback_model.stop_training:\r\n   1258                 break\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\r\n     75         logs = logs or {}\r\n     76         for callback in self.callbacks:\r\n---> 77             callback.on_epoch_end(epoch, logs)\r\n     78 \r\n     79     def on_batch_begin(self, batch, logs=None):\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/callbacks.pyc in on_epoch_end(self, epoch, logs)\r\n    466               self.model.save_weights(filepath, overwrite=True)\r\n    467             else:\r\n--> 468               self.model.save(filepath, overwrite=True)\r\n    469           else:\r\n    470             if self.verbose > 0:\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in save(self, filepath, overwrite, include_optimizer)\r\n   2589         \"\"\"\r\n   2590         from ..models import save_model\r\n-> 2591         save_model(self, filepath, overwrite, include_optimizer)\r\n   2592 \r\n   2593     def save_weights(self, filepath, overwrite=True):\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in save_model(model, filepath, overwrite, include_optimizer)\r\n    125             'class_name': model.__class__.__name__,\r\n    126             'config': model.get_config()\r\n--> 127         }, default=get_json_type).encode('utf8')\r\n    128 \r\n    129         model_weights_group = f.create_group('model_weights')\r\n\r\n/usr/lib/python2.7/json/__init__.pyc in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\r\n    249         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\r\n    250         separators=separators, encoding=encoding, default=default,\r\n--> 251         sort_keys=sort_keys, **kw).encode(obj)\r\n    252 \r\n    253 \r\n\r\n/usr/lib/python2.7/json/encoder.pyc in encode(self, o)\r\n    205         # exceptions aren't as detailed.  The list call should be roughly\r\n    206         # equivalent to the PySequence_Fast that ''.join() would do.\r\n--> 207         chunks = self.iterencode(o, _one_shot=True)\r\n    208         if not isinstance(chunks, (list, tuple)):\r\n    209             chunks = list(chunks)\r\n\r\n/usr/lib/python2.7/json/encoder.pyc in iterencode(self, o, _one_shot)\r\n    268                 self.key_separator, self.item_separator, self.sort_keys,\r\n    269                 self.skipkeys, _one_shot)\r\n--> 270         return _iterencode(o, 0)\r\n    271 \r\n    272 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/models.pyc in get_json_type(obj)\r\n    102             return obj.__name__\r\n    103 \r\n--> 104         raise TypeError('Not JSON Serializable:', obj)\r\n    105 \r\n    106     from . import __version__ as keras_version\r\n\r\nTypeError: ('Not JSON Serializable:', tf.string)\r\n```"}