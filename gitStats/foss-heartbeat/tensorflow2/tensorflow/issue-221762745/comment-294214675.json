{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294214675", "html_url": "https://github.com/tensorflow/tensorflow/issues/9213#issuecomment-294214675", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9213", "id": 294214675, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDIxNDY3NQ==", "user": {"login": "121onto", "id": 13111271, "node_id": "MDQ6VXNlcjEzMTExMjcx", "avatar_url": "https://avatars0.githubusercontent.com/u/13111271?v=4", "gravatar_id": "", "url": "https://api.github.com/users/121onto", "html_url": "https://github.com/121onto", "followers_url": "https://api.github.com/users/121onto/followers", "following_url": "https://api.github.com/users/121onto/following{/other_user}", "gists_url": "https://api.github.com/users/121onto/gists{/gist_id}", "starred_url": "https://api.github.com/users/121onto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/121onto/subscriptions", "organizations_url": "https://api.github.com/users/121onto/orgs", "repos_url": "https://api.github.com/users/121onto/repos", "events_url": "https://api.github.com/users/121onto/events{/privacy}", "received_events_url": "https://api.github.com/users/121onto/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-14T18:58:34Z", "updated_at": "2017-04-14T18:58:34Z", "author_association": "NONE", "body_html": "<p>The code runs on the GPU after scaling down the model.</p>\n<p>There appears to be significant overhead in starting computations on the GPU.  I can see this when I train an intermediate-size model: Volatile GPU-Util goes to 100%  for a while without completing any evaluations, then Volatile GPU-Util drops to around %30 and the evaluation loop begins running fairly quickly.  This wouldn't be an issue except for the fact that my system is almost completely unusable until Volatile GPU-Util drops back down to 30%.</p>\n<p>I assume overhead is somehow associated with putting data on the GPU.  Can someone explain why this happens?  Is there a way to prevent TensorFlow from hogging all Volatile GPU during the upstart phase?</p>", "body_text": "The code runs on the GPU after scaling down the model.\nThere appears to be significant overhead in starting computations on the GPU.  I can see this when I train an intermediate-size model: Volatile GPU-Util goes to 100%  for a while without completing any evaluations, then Volatile GPU-Util drops to around %30 and the evaluation loop begins running fairly quickly.  This wouldn't be an issue except for the fact that my system is almost completely unusable until Volatile GPU-Util drops back down to 30%.\nI assume overhead is somehow associated with putting data on the GPU.  Can someone explain why this happens?  Is there a way to prevent TensorFlow from hogging all Volatile GPU during the upstart phase?", "body": "The code runs on the GPU after scaling down the model.  \r\n\r\nThere appears to be significant overhead in starting computations on the GPU.  I can see this when I train an intermediate-size model: Volatile GPU-Util goes to 100%  for a while without completing any evaluations, then Volatile GPU-Util drops to around %30 and the evaluation loop begins running fairly quickly.  This wouldn't be an issue except for the fact that my system is almost completely unusable until Volatile GPU-Util drops back down to 30%.\r\n\r\nI assume overhead is somehow associated with putting data on the GPU.  Can someone explain why this happens?  Is there a way to prevent TensorFlow from hogging all Volatile GPU during the upstart phase?"}