{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350843958", "html_url": "https://github.com/tensorflow/tensorflow/issues/15103#issuecomment-350843958", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15103", "id": 350843958, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDg0Mzk1OA==", "user": {"login": "VinceMarron", "id": 24817118, "node_id": "MDQ6VXNlcjI0ODE3MTE4", "avatar_url": "https://avatars3.githubusercontent.com/u/24817118?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VinceMarron", "html_url": "https://github.com/VinceMarron", "followers_url": "https://api.github.com/users/VinceMarron/followers", "following_url": "https://api.github.com/users/VinceMarron/following{/other_user}", "gists_url": "https://api.github.com/users/VinceMarron/gists{/gist_id}", "starred_url": "https://api.github.com/users/VinceMarron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VinceMarron/subscriptions", "organizations_url": "https://api.github.com/users/VinceMarron/orgs", "repos_url": "https://api.github.com/users/VinceMarron/repos", "events_url": "https://api.github.com/users/VinceMarron/events{/privacy}", "received_events_url": "https://api.github.com/users/VinceMarron/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-11T20:12:41Z", "updated_at": "2017-12-11T20:12:41Z", "author_association": "NONE", "body_html": "<p>Ah.. Awesome work on this <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26527\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rryan\">@rryan</a>. Clearly I'm the rookie here (but trying to learn..)</p>\n<p>I very well could be doing something else wrong but appears there is a glitch in 'gathering' from frame indices on gpu in eager mode.</p>\n<p>Example:</p>\n<p>In standard graph mode this code runs just fine:</p>\n<pre><code>import tensorflow as tf\n\nframe_length=256\nframe_step=64\n\n\nsignal = tf.random_uniform((1,16000), minval=-1, maxval=1)\n\nwith tf.device('/gpu:0'):\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \n                                  frame_step=frame_step)\n  with tf.Session() as sess:\n    frames_out = sess.run(frames)\n    \nprint(frames_out[0, :2, :2], frames_out.shape)\n\n</code></pre>\n<blockquote>\n<p>output:<br>\n[[ 0.64405823 -0.69103551]<br>\n[-0.37752914  0.50947428]] (1, 247, 256)</p>\n</blockquote>\n<p>The equivalent code in eager mode, however, produces an error:</p>\n<pre><code>import tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nframe_length=256\nframe_step=64\n\n\nsignal = tf.constant(tf.random_uniform((1,16000), minval=-1, maxval=1))\n\nwith tf.device('/gpu:0'):\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \n                                  frame_step=frame_step)\n    \nprint(frames[0, :2, :2], frames.shape)\n\n</code></pre>\n<blockquote>\n<hr>\n<p>InvalidArgumentError                      Traceback (most recent call last)<br>\n in ()<br>\n12 with tf.device('/gpu:0'):<br>\n13   frames = tf.contrib.signal.frame(signal, frame_length=frame_length,<br>\n---&gt; 14                                   frame_step=frame_step)<br>\n15<br>\n16 print(frames[0, :2, :2], frames.shape)</p>\n<p>~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/contrib/signal/python/ops/shape_ops.py in frame(signal, frame_length, frame_step, pad_end, pad_value, axis, name)<br>\n114     axis = math_ops.range(signal_rank)[axis]<br>\n115<br>\n--&gt; 116     signal_shape = array_ops.shape(signal)<br>\n117     outer_dimensions, length_samples, inner_dimensions = array_ops.split(<br>\n118         signal_shape, [axis, 1, signal_rank - 1 - axis])</p>\n<p>~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape(input, name, out_type)<br>\n276     A <code>Tensor</code> of type <code>out_type</code>.<br>\n277   \"\"\"<br>\n--&gt; 278   return shape_internal(input, name, optimize=True, out_type=out_type)<br>\n279<br>\n280</p>\n<p>~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape_internal(input, name, optimize, out_type)<br>\n304         if optimize and input_shape.is_fully_defined():<br>\n305           return constant(input_shape.as_list(), out_type, name=name)<br>\n--&gt; 306       return gen_array_ops.shape(input, name=name, out_type=out_type)<br>\n307<br>\n308</p>\n<p>~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py in shape(input, out_type, name)<br>\n4479     _attrs = (\"T\", _attr_T, \"out_type\", out_type)<br>\n4480     _result = _execute.execute(b\"Shape\", 1, inputs=_inputs_flat, attrs=_attrs,<br>\n-&gt; 4481                                ctx=_ctx, name=name)<br>\n4482   _execute.record_gradient(<br>\n4483       \"Shape\", _inputs_flat, _attrs, _result, name)</p>\n<p>~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)<br>\n64     else:<br>\n65       message = e.message<br>\n---&gt; 66     six.raise_from(core._status_to_exception(e.code, message), None)<br>\n67   # pylint: enable=protected-access<br>\n68   return tensors</p>\n<p>~/.local/lib/python3.5/site-packages/six.py in raise_from(value, from_value)</p>\n<p>InvalidArgumentError: Tensors on conflicting devices: cannot compute Shape as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Shape] name: frame/Shape/</p>\n</blockquote>\n<p>Using  tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT) works just fine as a work around but I figure there is a small fix to be done to allow this to work entirely on gpu.</p>", "body_text": "Ah.. Awesome work on this @rryan. Clearly I'm the rookie here (but trying to learn..)\nI very well could be doing something else wrong but appears there is a glitch in 'gathering' from frame indices on gpu in eager mode.\nExample:\nIn standard graph mode this code runs just fine:\nimport tensorflow as tf\n\nframe_length=256\nframe_step=64\n\n\nsignal = tf.random_uniform((1,16000), minval=-1, maxval=1)\n\nwith tf.device('/gpu:0'):\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \n                                  frame_step=frame_step)\n  with tf.Session() as sess:\n    frames_out = sess.run(frames)\n    \nprint(frames_out[0, :2, :2], frames_out.shape)\n\n\n\noutput:\n[[ 0.64405823 -0.69103551]\n[-0.37752914  0.50947428]] (1, 247, 256)\n\nThe equivalent code in eager mode, however, produces an error:\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\ntfe.enable_eager_execution()\n\nframe_length=256\nframe_step=64\n\n\nsignal = tf.constant(tf.random_uniform((1,16000), minval=-1, maxval=1))\n\nwith tf.device('/gpu:0'):\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \n                                  frame_step=frame_step)\n    \nprint(frames[0, :2, :2], frames.shape)\n\n\n\n\nInvalidArgumentError                      Traceback (most recent call last)\n in ()\n12 with tf.device('/gpu:0'):\n13   frames = tf.contrib.signal.frame(signal, frame_length=frame_length,\n---> 14                                   frame_step=frame_step)\n15\n16 print(frames[0, :2, :2], frames.shape)\n~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/contrib/signal/python/ops/shape_ops.py in frame(signal, frame_length, frame_step, pad_end, pad_value, axis, name)\n114     axis = math_ops.range(signal_rank)[axis]\n115\n--> 116     signal_shape = array_ops.shape(signal)\n117     outer_dimensions, length_samples, inner_dimensions = array_ops.split(\n118         signal_shape, [axis, 1, signal_rank - 1 - axis])\n~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape(input, name, out_type)\n276     A Tensor of type out_type.\n277   \"\"\"\n--> 278   return shape_internal(input, name, optimize=True, out_type=out_type)\n279\n280\n~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape_internal(input, name, optimize, out_type)\n304         if optimize and input_shape.is_fully_defined():\n305           return constant(input_shape.as_list(), out_type, name=name)\n--> 306       return gen_array_ops.shape(input, name=name, out_type=out_type)\n307\n308\n~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py in shape(input, out_type, name)\n4479     _attrs = (\"T\", _attr_T, \"out_type\", out_type)\n4480     _result = _execute.execute(b\"Shape\", 1, inputs=_inputs_flat, attrs=_attrs,\n-> 4481                                ctx=_ctx, name=name)\n4482   _execute.record_gradient(\n4483       \"Shape\", _inputs_flat, _attrs, _result, name)\n~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n64     else:\n65       message = e.message\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\n67   # pylint: enable=protected-access\n68   return tensors\n~/.local/lib/python3.5/site-packages/six.py in raise_from(value, from_value)\nInvalidArgumentError: Tensors on conflicting devices: cannot compute Shape as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Shape] name: frame/Shape/\n\nUsing  tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT) works just fine as a work around but I figure there is a small fix to be done to allow this to work entirely on gpu.", "body": "Ah.. Awesome work on this @rryan. Clearly I'm the rookie here (but trying to learn..)\r\n\r\nI very well could be doing something else wrong but appears there is a glitch in 'gathering' from frame indices on gpu in eager mode. \r\n\r\nExample:\r\n\r\nIn standard graph mode this code runs just fine:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nframe_length=256\r\nframe_step=64\r\n\r\n\r\nsignal = tf.random_uniform((1,16000), minval=-1, maxval=1)\r\n\r\nwith tf.device('/gpu:0'):\r\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \r\n                                  frame_step=frame_step)\r\n  with tf.Session() as sess:\r\n    frames_out = sess.run(frames)\r\n    \r\nprint(frames_out[0, :2, :2], frames_out.shape)\r\n\r\n```\r\n\r\n> output:\r\n>[[ 0.64405823 -0.69103551]\r\n >[-0.37752914  0.50947428]] (1, 247, 256)\r\n\r\nThe equivalent code in eager mode, however, produces an error:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\nframe_length=256\r\nframe_step=64\r\n\r\n\r\nsignal = tf.constant(tf.random_uniform((1,16000), minval=-1, maxval=1))\r\n\r\nwith tf.device('/gpu:0'):\r\n  frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \r\n                                  frame_step=frame_step)\r\n    \r\nprint(frames[0, :2, :2], frames.shape)\r\n\r\n```\r\n\r\n> ---------------------------------------------------------------------------\r\n> InvalidArgumentError                      Traceback (most recent call last)\r\n> <ipython-input-1-6254609ba767> in <module>()\r\n>      12 with tf.device('/gpu:0'):\r\n>      13   frames = tf.contrib.signal.frame(signal, frame_length=frame_length, \r\n> ---> 14                                   frame_step=frame_step)\r\n>      15 \r\n>      16 print(frames[0, :2, :2], frames.shape)\r\n> \r\n> ~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/contrib/signal/python/ops/shape_ops.py in frame(signal, frame_length, frame_step, pad_end, pad_value, axis, name)\r\n>     114     axis = math_ops.range(signal_rank)[axis]\r\n>     115 \r\n> --> 116     signal_shape = array_ops.shape(signal)\r\n>     117     outer_dimensions, length_samples, inner_dimensions = array_ops.split(\r\n>     118         signal_shape, [axis, 1, signal_rank - 1 - axis])\r\n> \r\n> ~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape(input, name, out_type)\r\n>     276     A `Tensor` of type `out_type`.\r\n>     277   \"\"\"\r\n> --> 278   return shape_internal(input, name, optimize=True, out_type=out_type)\r\n>     279 \r\n>     280 \r\n> \r\n> ~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in shape_internal(input, name, optimize, out_type)\r\n>     304         if optimize and input_shape.is_fully_defined():\r\n>     305           return constant(input_shape.as_list(), out_type, name=name)\r\n> --> 306       return gen_array_ops.shape(input, name=name, out_type=out_type)\r\n>     307 \r\n>     308 \r\n> \r\n> ~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py in shape(input, out_type, name)\r\n>    4479     _attrs = (\"T\", _attr_T, \"out_type\", out_type)\r\n>    4480     _result = _execute.execute(b\"Shape\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n> -> 4481                                ctx=_ctx, name=name)\r\n>    4482   _execute.record_gradient(\r\n>    4483       \"Shape\", _inputs_flat, _attrs, _result, name)\r\n> \r\n> ~/anaconda3/envs/tf_source/lib/python3.5/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      64     else:\r\n>      65       message = e.message\r\n> ---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n>      67   # pylint: enable=protected-access\r\n>      68   return tensors\r\n> \r\n> ~/.local/lib/python3.5/site-packages/six.py in raise_from(value, from_value)\r\n> \r\n> InvalidArgumentError: Tensors on conflicting devices: cannot compute Shape as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(), or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Shape] name: frame/Shape/\r\n\r\n\r\nUsing  tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT) works just fine as a work around but I figure there is a small fix to be done to allow this to work entirely on gpu. \r\n"}