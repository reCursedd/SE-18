{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21066", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21066/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21066/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21066/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/21066", "id": 343747870, "node_id": "MDExOlB1bGxSZXF1ZXN0MjAzMzA2OTM4", "number": 21066, "title": "add Kernel Inception Distance to tf.contrib.gan.eval", "user": {"login": "dougalsutherland", "id": 36478, "node_id": "MDQ6VXNlcjM2NDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/36478?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dougalsutherland", "html_url": "https://github.com/dougalsutherland", "followers_url": "https://api.github.com/users/dougalsutherland/followers", "following_url": "https://api.github.com/users/dougalsutherland/following{/other_user}", "gists_url": "https://api.github.com/users/dougalsutherland/gists{/gist_id}", "starred_url": "https://api.github.com/users/dougalsutherland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dougalsutherland/subscriptions", "organizations_url": "https://api.github.com/users/dougalsutherland/orgs", "repos_url": "https://api.github.com/users/dougalsutherland/repos", "events_url": "https://api.github.com/users/dougalsutherland/events{/privacy}", "received_events_url": "https://api.github.com/users/dougalsutherland/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 987666414, "node_id": "MDU6TGFiZWw5ODc2NjY0MTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/ready%20to%20pull", "name": "ready to pull", "color": "2cd643", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "caisq", "id": 16824702, "node_id": "MDQ6VXNlcjE2ODI0NzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/16824702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caisq", "html_url": "https://github.com/caisq", "followers_url": "https://api.github.com/users/caisq/followers", "following_url": "https://api.github.com/users/caisq/following{/other_user}", "gists_url": "https://api.github.com/users/caisq/gists{/gist_id}", "starred_url": "https://api.github.com/users/caisq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caisq/subscriptions", "organizations_url": "https://api.github.com/users/caisq/orgs", "repos_url": "https://api.github.com/users/caisq/repos", "events_url": "https://api.github.com/users/caisq/events{/privacy}", "received_events_url": "https://api.github.com/users/caisq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 17, "created_at": "2018-07-23T18:38:29Z", "updated_at": "2018-10-16T13:40:06Z", "closed_at": "2018-10-15T16:37:24Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21066", "html_url": "https://github.com/tensorflow/tensorflow/pull/21066", "diff_url": "https://github.com/tensorflow/tensorflow/pull/21066.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/21066.patch"}, "body_html": "<p>The KID is a score similar to the FID, but with an unbiased, asymptotically normal estimator. It was introduced by our paper <a href=\"https://arxiv.org/abs/1801.01401\" rel=\"nofollow\"><em>Demystifying MMD GANs</em></a>; a very similar metric was also recommended by <a href=\"https://arxiv.org/abs/1806.07755\" rel=\"nofollow\"><em>An empirical study on evaluation metrics of generative adversarial networks</em></a>.</p>\n<p>For comparison to the FID, see section 4 (starting page 7) and appendices D/E (starting page 30) of our paper. As noted in the docstrings for the FID here, the FID estimator is biased and you can absolutely only compare estimates based on the same number of samples. But there's no guarantee that you still won't be very misled by the bias even then; in particular, see our Appendix D.2:</p>\n<blockquote>\n<p>This example thus gives a case where, for the dimension and sample sizes at which we actually apply the FID and for somewhat-realistic distributions, comparing two models based on their FID estimates will not only not reliably give the right ordering \u2013 with relatively close true values and high dimensions, this is not too surprising \u2013 but, more distressingly, will <em>reliably give the wrong answer</em>, with misleadingly small variance. This emphasizes that unbiased estimators, like the natural KID estimator, are important for model comparison.</p>\n</blockquote>\n<p>Compared to our original code (<a href=\"https://github.com/mbinkowski/MMD-GAN/blob/master/gan/compute_scores.py\">here</a>), this version uses a slightly different estimator. Both are unbiased, but I think this block variant is more intuitive for general usage; its output is also \"more normal\" and gives a very simple estimate of the variance of the estimator (unlike the asymptotic one we used before, which is <a href=\"https://github.com/mbinkowski/MMD-GAN/blob/master/gan/compute_scores.py#L251\">not a very pretty expression</a>).</p>\n<p>The functions that estimate the variance currently return an estimate as long as there are at least two blocks. This could be a little misleading; it might make sense to refuse to estimate the std if there are fewer than, say, 10 blocks, but I don't know if that added code complexity is worth it.</p>\n<p>xref: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"341626600\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/google/compare_gan/issues/7\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/google/compare_gan/pull/7/hovercard\" href=\"https://github.com/google/compare_gan/pull/7\">google/compare_gan#7</a></p>", "body_text": "The KID is a score similar to the FID, but with an unbiased, asymptotically normal estimator. It was introduced by our paper Demystifying MMD GANs; a very similar metric was also recommended by An empirical study on evaluation metrics of generative adversarial networks.\nFor comparison to the FID, see section 4 (starting page 7) and appendices D/E (starting page 30) of our paper. As noted in the docstrings for the FID here, the FID estimator is biased and you can absolutely only compare estimates based on the same number of samples. But there's no guarantee that you still won't be very misled by the bias even then; in particular, see our Appendix D.2:\n\nThis example thus gives a case where, for the dimension and sample sizes at which we actually apply the FID and for somewhat-realistic distributions, comparing two models based on their FID estimates will not only not reliably give the right ordering \u2013 with relatively close true values and high dimensions, this is not too surprising \u2013 but, more distressingly, will reliably give the wrong answer, with misleadingly small variance. This emphasizes that unbiased estimators, like the natural KID estimator, are important for model comparison.\n\nCompared to our original code (here), this version uses a slightly different estimator. Both are unbiased, but I think this block variant is more intuitive for general usage; its output is also \"more normal\" and gives a very simple estimate of the variance of the estimator (unlike the asymptotic one we used before, which is not a very pretty expression).\nThe functions that estimate the variance currently return an estimate as long as there are at least two blocks. This could be a little misleading; it might make sense to refuse to estimate the std if there are fewer than, say, 10 blocks, but I don't know if that added code complexity is worth it.\nxref: google/compare_gan#7", "body": "The KID is a score similar to the FID, but with an unbiased, asymptotically normal estimator. It was introduced by our paper [_Demystifying MMD GANs_](https://arxiv.org/abs/1801.01401); a very similar metric was also recommended by [_An empirical study on evaluation metrics of generative adversarial networks_](https://arxiv.org/abs/1806.07755).\r\n\r\nFor comparison to the FID, see section 4 (starting page 7) and appendices D/E (starting page 30) of our paper. As noted in the docstrings for the FID here, the FID estimator is biased and you can absolutely only compare estimates based on the same number of samples. But there's no guarantee that you still won't be very misled by the bias even then; in particular, see our Appendix D.2:\r\n\r\n> This example thus gives a case where, for the dimension and sample sizes at which we actually apply the FID and for somewhat-realistic distributions, comparing two models based on their FID estimates will not only not reliably give the right ordering \u2013 with relatively close true values and high dimensions, this is not too surprising \u2013 but, more distressingly, will _reliably give the wrong answer_, with misleadingly small variance. This emphasizes that unbiased estimators, like the natural KID estimator, are important for model comparison.\r\n\r\nCompared to our original code ([here](https://github.com/mbinkowski/MMD-GAN/blob/master/gan/compute_scores.py)), this version uses a slightly different estimator. Both are unbiased, but I think this block variant is more intuitive for general usage; its output is also \"more normal\" and gives a very simple estimate of the variance of the estimator (unlike the asymptotic one we used before, which is [not a very pretty expression](https://github.com/mbinkowski/MMD-GAN/blob/master/gan/compute_scores.py#L251)).\r\n\r\nThe functions that estimate the variance currently return an estimate as long as there are at least two blocks. This could be a little misleading; it might make sense to refuse to estimate the std if there are fewer than, say, 10 blocks, but I don't know if that added code complexity is worth it.\r\n\r\nxref: https://github.com/google/compare_gan/pull/7"}