{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/210682678", "pull_request_review_id": 146950945, "id": 210682678, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMDY4MjY3OA==", "diff_hunk": "@@ -734,3 +741,372 @@ def frechet_classifier_distance_from_activations(real_activations,\n     frechet_classifier_distance,\n     classifier_fn=functools.partial(\n         run_inception, output_tensor=INCEPTION_FINAL_POOL))\n+\n+\n+def kernel_classifier_distance(real_images,\n+                               generated_images,\n+                               classifier_fn,\n+                               num_classifier_batches=1,\n+                               max_block_size=1024,\n+                               dtype=None):\n+  \"\"\"Kernel \"classifier\" distance for evaluating a generative model.\n+\n+  This is based on the Kernel Inception distance, but for an arbitrary\n+  embedding.\n+\n+  This technique is described in detail in https://arxiv.org/abs/1801.01401.\n+  Given two distributions P and Q of activations, this function calculates\n+\n+      E_{X, X' ~ P}[k(X, X')] + E_{Y, Y' ~ Q}[k(Y, Y')]\n+        - 2 E_{X ~ P, Y ~ Q}[k(X, Y)]\n+\n+  where k is the polynomial kernel\n+\n+      k(x, y) = ( x^T y / dimension + 1 )^3.\n+\n+  This captures how different the distributions of real and generated images'\n+  visual features are. Like the Frechet distance (and unlike the Inception\n+  score), this is a true distance and incorporates information about the\n+  target images. Unlike the Frechet score, this function computes an\n+  *unbiased* and asymptotically normal estimator, which makes comparing\n+  estimates across models much more intuitive.\n+\n+  The estimator used takes time quadratic in max_block_size. Larger values of\n+  max_block_size will decrease the variance of the estimator but increase the\n+  computational cost. This differs slightly from the estimator used by the\n+  original paper; it is the block estimator of https://arxiv.org/abs/1307.1954.\n+\n+  NOTE: the blocking code assumes that real_activations and\n+\ufffc generated_activations are both in random order. If real_activations is sorted\n+\ufffc in a meaningful order, the estimator will be biased.\n+\n+  NOTE: This function consumes images, computes their activations, and then\n+  computes the classifier score. If you would like to precompute many\n+  activations for real and generated images for large batches, or to compute\n+  multiple scores based on the same images, please use\n+  kernel_clasifier_distance_from_activations(), which this method also uses.\n+\n+  Args:\n+    real_images: Real images to use to compute Kernel Inception distance.\n+    generated_images: Generated images to use to compute Kernel Inception\n+      distance.\n+    classifier_fn: A function that takes images and produces activations\n+      based on a classifier.\n+    num_classifier_batches: Number of batches to split images in to in order to\n+      efficiently run them through the classifier network.\n+    max_estimator_block_size: integer, default 1024. The distance estimator\n+      splits samples into blocks for computational efficiency. Larger values\n+      are more computationally expensive but decrease the variance of the\n+      distance estimate.\n+    dtype: if not None, coerce activations to this dtype before computations.\n+\n+  Returns:\n+   The Kernel Inception Distance. A floating-point scalar of the same type\n+   as the output of the activations.\n+  \"\"\"\n+  return kernel_classifier_distance_and_std(\n+      real_images, generated_images, classifier_fn,\n+      num_classifier_batches=num_classifier_batches,\n+      max_block_size=max_block_size,\n+      dtype=dtype)[0]\n+\n+\n+kernel_inception_distance = functools.partial(\n+    kernel_classifier_distance,\n+    classifier_fn=functools.partial(\n+        run_inception, output_tensor=INCEPTION_FINAL_POOL))\n+\n+\n+def kernel_classifier_distance_and_std(real_images,\n+                                       generated_images,\n+                                       classifier_fn,\n+                                       num_classifier_batches=1,\n+                                       max_block_size=1024,\n+                                       dtype=None):\n+  \"\"\"Kernel \"classifier\" distance for evaluating a generative model.\n+\n+  This is based on the Kernel Inception distance, but for an arbitrary\n+  embedding. Also returns an estimate of the standard error of the distance\n+  estimator.\n+\n+  This technique is described in detail in https://arxiv.org/abs/1801.01401.\n+  Given two distributions P and Q of activations, this function calculates\n+\n+      E_{X, X' ~ P}[k(X, X')] + E_{Y, Y' ~ Q}[k(Y, Y')]\n+        - 2 E_{X ~ P, Y ~ Q}[k(X, Y)]\n+\n+  where k is the polynomial kernel\n+\n+      k(x, y) = ( x^T y / dimension + 1 )^3.\n+\n+  This captures how different the distributions of real and generated images'\n+  visual features are. Like the Frechet distance (and unlike the Inception\n+  score), this is a true distance and incorporates information about the\n+  target images. Unlike the Frechet score, this function computes an\n+  *unbiased* and asymptotically normal estimator, which makes comparing\n+  estimates across models much more intuitive.\n+\n+  The estimator used takes time quadratic in max_block_size. Larger values of\n+  max_block_size will decrease the variance of the estimator but increase the\n+  computational cost. This differs slightly from the estimator used by the\n+  original paper; it is the block estimator of https://arxiv.org/abs/1307.1954.\n+\n+  NOTE: the blocking code assumes that real_activations and\n+\ufffc generated_activations are both in random order. If real_activations is sorted\n+\ufffc in a meaningful order, the estimator will be biased.", "path": "tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py", "position": null, "original_position": 148, "commit_id": "ef2c1190d6dc7ec8bca911d03ca2c67b8692a293", "original_commit_id": "5e31a27835c60c9510d1c000b851c573e910f378", "user": {"login": "dougalsutherland", "id": 36478, "node_id": "MDQ6VXNlcjM2NDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/36478?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dougalsutherland", "html_url": "https://github.com/dougalsutherland", "followers_url": "https://api.github.com/users/dougalsutherland/followers", "following_url": "https://api.github.com/users/dougalsutherland/following{/other_user}", "gists_url": "https://api.github.com/users/dougalsutherland/gists{/gist_id}", "starred_url": "https://api.github.com/users/dougalsutherland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dougalsutherland/subscriptions", "organizations_url": "https://api.github.com/users/dougalsutherland/orgs", "repos_url": "https://api.github.com/users/dougalsutherland/repos", "events_url": "https://api.github.com/users/dougalsutherland/events{/privacy}", "received_events_url": "https://api.github.com/users/dougalsutherland/received_events", "type": "User", "site_admin": false}, "body": "Fixed these, thanks.", "created_at": "2018-08-16T17:42:13Z", "updated_at": "2018-09-24T12:53:53Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21066#discussion_r210682678", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21066", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/210682678"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21066#discussion_r210682678"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21066"}}, "body_html": "<p>Fixed these, thanks.</p>", "body_text": "Fixed these, thanks.", "in_reply_to_id": 210489265}