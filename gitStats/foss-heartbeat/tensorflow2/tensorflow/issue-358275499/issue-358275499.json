{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22162", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22162/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22162/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22162/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22162", "id": 358275499, "node_id": "MDU6SXNzdWUzNTgyNzU0OTk=", "number": 22162, "title": "tf.map_fn causes error when importing the same graph twice and connecting them", "user": {"login": "stefsietz", "id": 2621937, "node_id": "MDQ6VXNlcjI2MjE5Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2621937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stefsietz", "html_url": "https://github.com/stefsietz", "followers_url": "https://api.github.com/users/stefsietz/followers", "following_url": "https://api.github.com/users/stefsietz/following{/other_user}", "gists_url": "https://api.github.com/users/stefsietz/gists{/gist_id}", "starred_url": "https://api.github.com/users/stefsietz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stefsietz/subscriptions", "organizations_url": "https://api.github.com/users/stefsietz/orgs", "repos_url": "https://api.github.com/users/stefsietz/repos", "events_url": "https://api.github.com/users/stefsietz/events{/privacy}", "received_events_url": "https://api.github.com/users/stefsietz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-09-08T08:13:47Z", "updated_at": "2018-11-23T18:39:38Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 18.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary (pip in conda environment)</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.10.1-0-g4dcfddc5d1 1.10.1</li>\n<li><strong>Python version</strong>: 3.6.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0</li>\n<li><strong>GPU model and memory</strong>: GTX 1070 / 8GB</li>\n<li><strong>Exact command to reproduce</strong>: below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am trying to load the same graph twice (with different variable weights) to perform stage-wise object detection with one connected graph. I import them with different name scopes, but still I get an error message because there is some bug in the tf.map_fn:<br>\n<code>\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid loop structure: Loop \"map/while/while_context\" has more than one LoopCond node: \"graph2/map/while/LoopCond\" and \"graph1/map/while/LoopCond\". This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"</code></p>\n<p>Minimal example to reproduce is below, but to me it ocurred with the faster-rcnn meta architecture from the object detection framework, where the first loop that causes this error is in the \"preprocess\" funtion of \"object_detection.meta_architectures.faster_rcnn_meta_arch.py\" at line 535. When I changed the tf.name_scope from 'Preprocessor' to something else in just one of the graphs, it threw this error from a different usage of the map_fn further down the graph.</p>\n<p>from object_detection.meta_architectures.faster_rcnn_meta_arch.py (line 535):</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">if</span> inputs.dtype <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> tf.float32:\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>`preprocess` expects a tf.float32 tensor<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Preprocessor<span class=\"pl-pds\">'</span></span>): <span class=\"pl-c\"><span class=\"pl-c\">#</span>when I change this in one of the graphs, the error doesn't occur here anymore</span>\n      outputs <span class=\"pl-k\">=</span> shape_utils.static_or_dynamic_map_fn(\n          <span class=\"pl-c1\">self</span>._image_resizer_fn,\n          <span class=\"pl-v\">elems</span><span class=\"pl-k\">=</span>inputs,\n          <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>[tf.float32, tf.int32],\n          <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._parallel_iterations)\n      resized_inputs <span class=\"pl-k\">=</span> outputs[<span class=\"pl-c1\">0</span>]\n      true_image_shapes <span class=\"pl-k\">=</span> outputs[<span class=\"pl-c1\">1</span>]\n      <span class=\"pl-k\">return</span> (<span class=\"pl-c1\">self</span>._feature_extractor.preprocess(resized_inputs),\n              true_image_shapes)</pre></div>\n<p>This would actually be my workaround if this doesn't get fixed, to just rename all the map_fn scopes before training each subgraph.</p>\n<h3>Script to reproduce bug</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">build_map_graph</span>(<span class=\"pl-smi\">name_scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>):\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-k\">with</span> graph.as_default():\n        input_tensor <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">mult</span>(<span class=\"pl-smi\">input</span>):\n            <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.multiply(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">2</span>)\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">input</span>\n\n        <span class=\"pl-k\">with</span> tf.name_scope(name_scope):\n            multiplied <span class=\"pl-k\">=</span> tf.map_fn(mult, input_tensor)\n        out_tensor <span class=\"pl-k\">=</span> tf.identity(multiplied, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">return</span> graph\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">build_simple_graph</span>():\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-k\">with</span> graph.as_default():\n        input_tensor <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n\n        multiplied <span class=\"pl-k\">=</span> tf.multiply(input_tensor, <span class=\"pl-c1\">2</span>)\n        out_tensor <span class=\"pl-k\">=</span> tf.identity(multiplied, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">return</span> graph\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">connect_graphs</span>(<span class=\"pl-smi\">both_are_map_graphs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-smi\">rename_second</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    test_data <span class=\"pl-k\">=</span> np.asarray([[<span class=\"pl-c1\">1.0</span>], [<span class=\"pl-c1\">2.0</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n\n    graph1 <span class=\"pl-k\">=</span> build_map_graph()\n    g1_graph_def <span class=\"pl-k\">=</span> graph1.as_graph_def()\n\n    g2_map_name_scope <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph2_map<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">if</span> rename_second <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>\n    graph2 <span class=\"pl-k\">=</span> build_map_graph(g2_map_name_scope) <span class=\"pl-k\">if</span> both_are_map_graphs <span class=\"pl-k\">else</span> build_simple_graph()\n\n    g2_graph_def <span class=\"pl-k\">=</span> graph2.as_graph_def()\n\n    connected_graph <span class=\"pl-k\">=</span> tf.Graph()\n\n    <span class=\"pl-k\">with</span> connected_graph.as_default():\n        tf.import_graph_def(g1_graph_def, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph1<span class=\"pl-pds\">'</span></span>)\n\n        g1_output_tensor <span class=\"pl-k\">=</span> tf.get_default_graph().get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph1/output:0<span class=\"pl-pds\">'</span></span>)\n        g1_input_tensor <span class=\"pl-k\">=</span> tf.get_default_graph().get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph1/input:0<span class=\"pl-pds\">'</span></span>)\n\n        tf.import_graph_def(g2_graph_def, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph2<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">input_map</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>: g1_output_tensor})\n        g2_output_tensor <span class=\"pl-k\">=</span> tf.get_default_graph().get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>graph2/output:0<span class=\"pl-pds\">'</span></span>)\n\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n            result <span class=\"pl-k\">=</span> sess.run(g2_output_tensor, {g1_input_tensor: test_data})\n            <span class=\"pl-c1\">print</span>(result)\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>runs fine</span>\nconnect_graphs(<span class=\"pl-v\">both_are_map_graphs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nconnect_graphs(<span class=\"pl-v\">both_are_map_graphs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">rename_second</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>throws error</span>\nconnect_graphs(<span class=\"pl-v\">both_are_map_graphs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>Edit:<br>\nchanged connect_graphs(both_are_map_graphs=False, rename_second=True) to connect_graphs(both_are_map_graphs=True, rename_second=True) in the example to better demonstrate the issue.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary (pip in conda environment)\nTensorFlow version (use command below): v1.10.1-0-g4dcfddc5d1 1.10.1\nPython version: 3.6.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0\nGPU model and memory: GTX 1070 / 8GB\nExact command to reproduce: below\n\nDescribe the problem\nI am trying to load the same graph twice (with different variable weights) to perform stage-wise object detection with one connected graph. I import them with different name scopes, but still I get an error message because there is some bug in the tf.map_fn:\n\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid loop structure: Loop \"map/while/while_context\" has more than one LoopCond node: \"graph2/map/while/LoopCond\" and \"graph1/map/while/LoopCond\". This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"\nMinimal example to reproduce is below, but to me it ocurred with the faster-rcnn meta architecture from the object detection framework, where the first loop that causes this error is in the \"preprocess\" funtion of \"object_detection.meta_architectures.faster_rcnn_meta_arch.py\" at line 535. When I changed the tf.name_scope from 'Preprocessor' to something else in just one of the graphs, it threw this error from a different usage of the map_fn further down the graph.\nfrom object_detection.meta_architectures.faster_rcnn_meta_arch.py (line 535):\n    if inputs.dtype is not tf.float32:\n      raise ValueError('`preprocess` expects a tf.float32 tensor')\n    with tf.name_scope('Preprocessor'): #when I change this in one of the graphs, the error doesn't occur here anymore\n      outputs = shape_utils.static_or_dynamic_map_fn(\n          self._image_resizer_fn,\n          elems=inputs,\n          dtype=[tf.float32, tf.int32],\n          parallel_iterations=self._parallel_iterations)\n      resized_inputs = outputs[0]\n      true_image_shapes = outputs[1]\n      return (self._feature_extractor.preprocess(resized_inputs),\n              true_image_shapes)\nThis would actually be my workaround if this doesn't get fixed, to just rename all the map_fn scopes before training each subgraph.\nScript to reproduce bug\nimport tensorflow as tf\nimport numpy as np\n\ndef build_map_graph(name_scope=''):\n    graph = tf.Graph()\n    with graph.as_default():\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\n\n        def mult(input):\n            input = tf.multiply(input, 2)\n            return input\n\n        with tf.name_scope(name_scope):\n            multiplied = tf.map_fn(mult, input_tensor)\n        out_tensor = tf.identity(multiplied, name='output')\n\n    return graph\n\ndef build_simple_graph():\n    graph = tf.Graph()\n    with graph.as_default():\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\n\n        multiplied = tf.multiply(input_tensor, 2)\n        out_tensor = tf.identity(multiplied, name='output')\n\n    return graph\n\n\ndef connect_graphs(both_are_map_graphs=False, rename_second=False):\n    test_data = np.asarray([[1.0], [2.0]], dtype=np.float32)\n\n    graph1 = build_map_graph()\n    g1_graph_def = graph1.as_graph_def()\n\n    g2_map_name_scope = 'graph2_map' if rename_second else ''\n    graph2 = build_map_graph(g2_map_name_scope) if both_are_map_graphs else build_simple_graph()\n\n    g2_graph_def = graph2.as_graph_def()\n\n    connected_graph = tf.Graph()\n\n    with connected_graph.as_default():\n        tf.import_graph_def(g1_graph_def, name='graph1')\n\n        g1_output_tensor = tf.get_default_graph().get_tensor_by_name('graph1/output:0')\n        g1_input_tensor = tf.get_default_graph().get_tensor_by_name('graph1/input:0')\n\n        tf.import_graph_def(g2_graph_def, name='graph2', input_map={'input': g1_output_tensor})\n        g2_output_tensor = tf.get_default_graph().get_tensor_by_name('graph2/output:0')\n\n        with tf.Session() as sess:\n            result = sess.run(g2_output_tensor, {g1_input_tensor: test_data})\n            print(result)\n\n\n#runs fine\nconnect_graphs(both_are_map_graphs=False)\nconnect_graphs(both_are_map_graphs=True, rename_second=True)\n\n#throws error\nconnect_graphs(both_are_map_graphs=True)\nEdit:\nchanged connect_graphs(both_are_map_graphs=False, rename_second=True) to connect_graphs(both_are_map_graphs=True, rename_second=True) in the example to better demonstrate the issue.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary (pip in conda environment)\r\n- **TensorFlow version (use command below)**: v1.10.1-0-g4dcfddc5d1 1.10.1\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX 1070 / 8GB\r\n- **Exact command to reproduce**: below\r\n\r\n\r\n### Describe the problem\r\nI am trying to load the same graph twice (with different variable weights) to perform stage-wise object detection with one connected graph. I import them with different name scopes, but still I get an error message because there is some bug in the tf.map_fn:\r\n```\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid loop structure: Loop \"map/while/while_context\" has more than one LoopCond node: \"graph2/map/while/LoopCond\" and \"graph1/map/while/LoopCond\". This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"```\r\n\r\nMinimal example to reproduce is below, but to me it ocurred with the faster-rcnn meta architecture from the object detection framework, where the first loop that causes this error is in the \"preprocess\" funtion of \"object_detection.meta_architectures.faster_rcnn_meta_arch.py\" at line 535. When I changed the tf.name_scope from 'Preprocessor' to something else in just one of the graphs, it threw this error from a different usage of the map_fn further down the graph.\r\n\r\nfrom object_detection.meta_architectures.faster_rcnn_meta_arch.py (line 535):\r\n```python\r\n    if inputs.dtype is not tf.float32:\r\n      raise ValueError('`preprocess` expects a tf.float32 tensor')\r\n    with tf.name_scope('Preprocessor'): #when I change this in one of the graphs, the error doesn't occur here anymore\r\n      outputs = shape_utils.static_or_dynamic_map_fn(\r\n          self._image_resizer_fn,\r\n          elems=inputs,\r\n          dtype=[tf.float32, tf.int32],\r\n          parallel_iterations=self._parallel_iterations)\r\n      resized_inputs = outputs[0]\r\n      true_image_shapes = outputs[1]\r\n      return (self._feature_extractor.preprocess(resized_inputs),\r\n              true_image_shapes)\r\n```\r\nThis would actually be my workaround if this doesn't get fixed, to just rename all the map_fn scopes before training each subgraph.\r\n\r\n### Script to reproduce bug\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef build_map_graph(name_scope=''):\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        def mult(input):\r\n            input = tf.multiply(input, 2)\r\n            return input\r\n\r\n        with tf.name_scope(name_scope):\r\n            multiplied = tf.map_fn(mult, input_tensor)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\ndef build_simple_graph():\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        multiplied = tf.multiply(input_tensor, 2)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\n\r\ndef connect_graphs(both_are_map_graphs=False, rename_second=False):\r\n    test_data = np.asarray([[1.0], [2.0]], dtype=np.float32)\r\n\r\n    graph1 = build_map_graph()\r\n    g1_graph_def = graph1.as_graph_def()\r\n\r\n    g2_map_name_scope = 'graph2_map' if rename_second else ''\r\n    graph2 = build_map_graph(g2_map_name_scope) if both_are_map_graphs else build_simple_graph()\r\n\r\n    g2_graph_def = graph2.as_graph_def()\r\n\r\n    connected_graph = tf.Graph()\r\n\r\n    with connected_graph.as_default():\r\n        tf.import_graph_def(g1_graph_def, name='graph1')\r\n\r\n        g1_output_tensor = tf.get_default_graph().get_tensor_by_name('graph1/output:0')\r\n        g1_input_tensor = tf.get_default_graph().get_tensor_by_name('graph1/input:0')\r\n\r\n        tf.import_graph_def(g2_graph_def, name='graph2', input_map={'input': g1_output_tensor})\r\n        g2_output_tensor = tf.get_default_graph().get_tensor_by_name('graph2/output:0')\r\n\r\n        with tf.Session() as sess:\r\n            result = sess.run(g2_output_tensor, {g1_input_tensor: test_data})\r\n            print(result)\r\n\r\n\r\n#runs fine\r\nconnect_graphs(both_are_map_graphs=False)\r\nconnect_graphs(both_are_map_graphs=True, rename_second=True)\r\n\r\n#throws error\r\nconnect_graphs(both_are_map_graphs=True)\r\n```\r\n\r\nEdit:\r\nchanged connect_graphs(both_are_map_graphs=False, rename_second=True) to connect_graphs(both_are_map_graphs=True, rename_second=True) in the example to better demonstrate the issue."}