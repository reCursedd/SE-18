{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/229473126", "pull_request_review_id": 169983789, "id": 229473126, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyOTQ3MzEyNg==", "diff_hunk": "@@ -59,6 +59,23 @@ def __init__(self, weight_decay, *args, **kwargs):\n   Note that this extension decays weights BEFORE applying the update based\n   on the gradient, i.e. this extension only has the desired behaviour for\n   optimizers which do not depend on the value of'var' in the update step!\n+  \n+  Note: when applying a decay to the learning rate, be sure to manually apply\n+  the decay to the `weight_decay` as well. For example:\n+\n+  ```python\n+    decay = tf.train.piecewise_constant(tf.train.get_global_step(), \n+                                        [10000, 15000], [1e-1, 1e-2, 1e-3])\n+    lr = 1*decay", "path": "tensorflow/contrib/opt/python/training/weight_decay_optimizers.py", "position": null, "original_position": 11, "commit_id": "71ba0ec86e7cde759006f17979f71e863602182c", "original_commit_id": "59617ccaca8c5980f5418a0b612b040ac8d1afba", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "In TF 2 (and when eager execution is enabled) tf.train.piecewise_constant returns a function which creates a tensor instead of returning a tensor.\r\n\r\nCan you make these be\r\n\r\nlr = decay\r\nwd = lambda: 1e-4 * decay()\r\n\r\n\r\nto be more future proof? (maybe with a \"decay() if callable(decay) else decay\" instead)", "created_at": "2018-10-30T20:27:43Z", "updated_at": "2018-11-15T19:28:49Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/23363#discussion_r229473126", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23363", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/229473126"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23363#discussion_r229473126"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23363"}}, "body_html": "<p>In TF 2 (and when eager execution is enabled) tf.train.piecewise_constant returns a function which creates a tensor instead of returning a tensor.</p>\n<p>Can you make these be</p>\n<p>lr = decay<br>\nwd = lambda: 1e-4 * decay()</p>\n<p>to be more future proof? (maybe with a \"decay() if callable(decay) else decay\" instead)</p>", "body_text": "In TF 2 (and when eager execution is enabled) tf.train.piecewise_constant returns a function which creates a tensor instead of returning a tensor.\nCan you make these be\nlr = decay\nwd = lambda: 1e-4 * decay()\nto be more future proof? (maybe with a \"decay() if callable(decay) else decay\" instead)"}