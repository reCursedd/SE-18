{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/228941308", "html_url": "https://github.com/tensorflow/tensorflow/issues/654#issuecomment-228941308", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/654", "id": 228941308, "node_id": "MDEyOklzc3VlQ29tbWVudDIyODk0MTMwOA==", "user": {"login": "nikitakit", "id": 252225, "node_id": "MDQ6VXNlcjI1MjIyNQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/252225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikitakit", "html_url": "https://github.com/nikitakit", "followers_url": "https://api.github.com/users/nikitakit/followers", "following_url": "https://api.github.com/users/nikitakit/following{/other_user}", "gists_url": "https://api.github.com/users/nikitakit/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikitakit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikitakit/subscriptions", "organizations_url": "https://api.github.com/users/nikitakit/orgs", "repos_url": "https://api.github.com/users/nikitakit/repos", "events_url": "https://api.github.com/users/nikitakit/events{/privacy}", "received_events_url": "https://api.github.com/users/nikitakit/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-28T03:51:26Z", "updated_at": "2016-06-28T03:51:26Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=620601\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/avati\">@avati</a> It appears that your implementation only works on a single example at a time <code>batch_size=1</code>. Is this by accident or by design?</p>\n<p>For example, compare <a href=\"https://github.com/sdlg/nlc/blob/b5088d102752a9c2aa4a923abb17abfb35026d82/nlc_model.py#L202\">your code</a> with <a href=\"https://gist.github.com/nikitakit/6ab61a73b86c50ad88d409bac3c3d09f#file-tf_beam_decoder-py-L121\">mine</a>. Note that your call to <code>top_k</code> is on a flat vector (so if there is a batch size &gt;1, the examples compete with each other), while mine is on a 2D matrix. My code has hacks for allowing <code>batch_size&gt;1</code>, though I have now discovered that it's flawed in a different way.</p>", "body_text": "@avati It appears that your implementation only works on a single example at a time batch_size=1. Is this by accident or by design?\nFor example, compare your code with mine. Note that your call to top_k is on a flat vector (so if there is a batch size >1, the examples compete with each other), while mine is on a 2D matrix. My code has hacks for allowing batch_size>1, though I have now discovered that it's flawed in a different way.", "body": "@avati It appears that your implementation only works on a single example at a time `batch_size=1`. Is this by accident or by design?\n\nFor example, compare [your code](https://github.com/sdlg/nlc/blob/b5088d102752a9c2aa4a923abb17abfb35026d82/nlc_model.py#L202) with [mine](https://gist.github.com/nikitakit/6ab61a73b86c50ad88d409bac3c3d09f#file-tf_beam_decoder-py-L121). Note that your call to `top_k` is on a flat vector (so if there is a batch size >1, the examples compete with each other), while mine is on a 2D matrix. My code has hacks for allowing `batch_size>1`, though I have now discovered that it's flawed in a different way.\n"}