{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264309777", "html_url": "https://github.com/tensorflow/tensorflow/issues/5981#issuecomment-264309777", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5981", "id": 264309777, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDMwOTc3Nw==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-01T22:03:48Z", "updated_at": "2016-12-01T23:27:16Z", "author_association": "MEMBER", "body_html": "<p>Interesting - there is a big perf difference between our internal build and the open source install:</p>\n<p>When I run the internal build, the step time with tracing (and lots of extra logging) is 1.47s.</p>\n<pre><code>I1201 13:50:53.102052   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:53.106980   24865 direct_session.cc:489] Run\nI1201 13:50:53.364928   24865 direct_session.cc:499] Run done\nI1201 13:50:53.364971   24865 direct_session.cc:513] Got trace\nI1201 13:50:53.364982   24865 direct_session.cc:527] Got outputs\nI1201 13:50:53.365004   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:53.365013   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:53.365126   24865 profiling-5981.py:50] Init done.\nI1201 13:50:53.365229   24865 profiling-5981.py:62] sess.run\nI1201 13:50:53.365682   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:53.397088   24865 dso_loader.cc:233] successfully opened CUDA library /google/src/cloud/pbar/triage/google3/third_party/gpus/cuda_7_0/extras/CUPTI/lib64/libcupti.so.7.0.28\nI1201 13:50:53.467417   24865 direct_session.cc:489] Run\nI1201 13:50:54.774907   24865 direct_session.cc:499] Run done\nI1201 13:50:54.781975   24865 direct_session.cc:513] Got trace\nI1201 13:50:54.782018   24865 direct_session.cc:527] Got outputs\nI1201 13:50:54.816643   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:54.920562   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:54.950649   24865 profiling-5981.py:67] sess.run done\nI1201 13:50:54.950703   24865 profiling-5981.py:68] 1.58546686172\nI1201 13:50:54.950723   24865 profiling-5981.py:62] sess.run\nI1201 13:50:54.951195   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:54.951274   24865 direct_session.cc:489] Run\nI1201 13:50:56.217795   24865 direct_session.cc:499] Run done\nI1201 13:50:56.224791   24865 direct_session.cc:513] Got trace\nI1201 13:50:56.224850   24865 direct_session.cc:527] Got outputs\nI1201 13:50:56.263171   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:56.385349   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:56.422490   24865 profiling-5981.py:67] sess.run done\nI1201 13:50:56.422549   24865 profiling-5981.py:68] 1.47181797028\n</code></pre>\n<p>One of the first differences btw internal and external builds that I usually try to rule out is the malloc implementation.  (We use TCMalloc, whereas standard Python is compiled against the regular libc heap).</p>\n<p>I tried using TCMalloc as follows:</p>\n<pre><code>LD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4 python profiling-5981.py\n</code></pre>\n<p>But still see the same step time... perhaps 100ms faster.</p>\n<p>I couldn't see anything obvious running under the CPU profiler either .... will keep looking, since this is a little suspicious.</p>", "body_text": "Interesting - there is a big perf difference between our internal build and the open source install:\nWhen I run the internal build, the step time with tracing (and lots of extra logging) is 1.47s.\nI1201 13:50:53.102052   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:53.106980   24865 direct_session.cc:489] Run\nI1201 13:50:53.364928   24865 direct_session.cc:499] Run done\nI1201 13:50:53.364971   24865 direct_session.cc:513] Got trace\nI1201 13:50:53.364982   24865 direct_session.cc:527] Got outputs\nI1201 13:50:53.365004   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:53.365013   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:53.365126   24865 profiling-5981.py:50] Init done.\nI1201 13:50:53.365229   24865 profiling-5981.py:62] sess.run\nI1201 13:50:53.365682   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:53.397088   24865 dso_loader.cc:233] successfully opened CUDA library /google/src/cloud/pbar/triage/google3/third_party/gpus/cuda_7_0/extras/CUPTI/lib64/libcupti.so.7.0.28\nI1201 13:50:53.467417   24865 direct_session.cc:489] Run\nI1201 13:50:54.774907   24865 direct_session.cc:499] Run done\nI1201 13:50:54.781975   24865 direct_session.cc:513] Got trace\nI1201 13:50:54.782018   24865 direct_session.cc:527] Got outputs\nI1201 13:50:54.816643   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:54.920562   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:54.950649   24865 profiling-5981.py:67] sess.run done\nI1201 13:50:54.950703   24865 profiling-5981.py:68] 1.58546686172\nI1201 13:50:54.950723   24865 profiling-5981.py:62] sess.run\nI1201 13:50:54.951195   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\nI1201 13:50:54.951274   24865 direct_session.cc:489] Run\nI1201 13:50:56.217795   24865 direct_session.cc:499] Run done\nI1201 13:50:56.224791   24865 direct_session.cc:513] Got trace\nI1201 13:50:56.224850   24865 direct_session.cc:527] Got outputs\nI1201 13:50:56.263171   24865 tf_session_helper.cc:521] To NumPy\nI1201 13:50:56.385349   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\nI1201 13:50:56.422490   24865 profiling-5981.py:67] sess.run done\nI1201 13:50:56.422549   24865 profiling-5981.py:68] 1.47181797028\n\nOne of the first differences btw internal and external builds that I usually try to rule out is the malloc implementation.  (We use TCMalloc, whereas standard Python is compiled against the regular libc heap).\nI tried using TCMalloc as follows:\nLD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4 python profiling-5981.py\n\nBut still see the same step time... perhaps 100ms faster.\nI couldn't see anything obvious running under the CPU profiler either .... will keep looking, since this is a little suspicious.", "body": "Interesting - there is a big perf difference between our internal build and the open source install:\r\n\r\nWhen I run the internal build, the step time with tracing (and lots of extra logging) is 1.47s.\r\n```\r\nI1201 13:50:53.102052   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:53.106980   24865 direct_session.cc:489] Run\r\nI1201 13:50:53.364928   24865 direct_session.cc:499] Run done\r\nI1201 13:50:53.364971   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:53.364982   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:53.365004   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:53.365013   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:53.365126   24865 profiling-5981.py:50] Init done.\r\nI1201 13:50:53.365229   24865 profiling-5981.py:62] sess.run\r\nI1201 13:50:53.365682   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:53.397088   24865 dso_loader.cc:233] successfully opened CUDA library /google/src/cloud/pbar/triage/google3/third_party/gpus/cuda_7_0/extras/CUPTI/lib64/libcupti.so.7.0.28\r\nI1201 13:50:53.467417   24865 direct_session.cc:489] Run\r\nI1201 13:50:54.774907   24865 direct_session.cc:499] Run done\r\nI1201 13:50:54.781975   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:54.782018   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:54.816643   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:54.920562   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:54.950649   24865 profiling-5981.py:67] sess.run done\r\nI1201 13:50:54.950703   24865 profiling-5981.py:68] 1.58546686172\r\nI1201 13:50:54.950723   24865 profiling-5981.py:62] sess.run\r\nI1201 13:50:54.951195   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:54.951274   24865 direct_session.cc:489] Run\r\nI1201 13:50:56.217795   24865 direct_session.cc:499] Run done\r\nI1201 13:50:56.224791   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:56.224850   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:56.263171   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:56.385349   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:56.422490   24865 profiling-5981.py:67] sess.run done\r\nI1201 13:50:56.422549   24865 profiling-5981.py:68] 1.47181797028\r\n```\r\n\r\nOne of the first differences btw internal and external builds that I usually try to rule out is the malloc implementation.  (We use TCMalloc, whereas standard Python is compiled against the regular libc heap).\r\n\r\nI tried using TCMalloc as follows:\r\n```\r\nLD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4 python profiling-5981.py\r\n```\r\nBut still see the same step time... perhaps 100ms faster.\r\n\r\nI couldn't see anything obvious running under the CPU profiler either .... will keep looking, since this is a little suspicious.\r\n"}