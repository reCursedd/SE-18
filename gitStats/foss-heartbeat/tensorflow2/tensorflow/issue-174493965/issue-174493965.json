{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4151", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4151/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4151/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4151/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4151", "id": 174493965, "node_id": "MDU6SXNzdWUxNzQ0OTM5NjU=", "number": 4151, "title": "Memory leak when continuously run assign op", "user": {"login": "zhangcx93", "id": 1290074, "node_id": "MDQ6VXNlcjEyOTAwNzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1290074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangcx93", "html_url": "https://github.com/zhangcx93", "followers_url": "https://api.github.com/users/zhangcx93/followers", "following_url": "https://api.github.com/users/zhangcx93/following{/other_user}", "gists_url": "https://api.github.com/users/zhangcx93/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangcx93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangcx93/subscriptions", "organizations_url": "https://api.github.com/users/zhangcx93/orgs", "repos_url": "https://api.github.com/users/zhangcx93/repos", "events_url": "https://api.github.com/users/zhangcx93/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangcx93/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-09-01T10:54:23Z", "updated_at": "2016-09-01T14:05:46Z", "closed_at": "2016-09-01T14:05:46Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 16.04<br>\nInstalled version of CUDA and cuDNN:<br>\n8.0 RC, 5.1 (on GTX 1080)<br>\nIf installed from source, provide<br>\nHEAD: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/a8512e24deeeebe57eb1be14726634e7e6c23545/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/a8512e24deeeebe57eb1be14726634e7e6c23545\"><tt>a8512e2</tt></a><br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Thu Jan 01 00:00:00 1970 (0)<br>\nBuild timestamp: Thu Jan 01 00:00:00 1970 (0)<br>\nBuild timestamp as int: 0</p>\n<h3>Problem:</h3>\n<p>In my application, I need to change value of some variable, and run the minimize in a loop, thus I have to run assign op continuously, which may add new op to graph every time, thus the program become very slow and memory explode.</p>\n<pre><code>sess = tf.Session()\na = tf.Variable(np.ones((5, 10000, 10000, 3)))\nsess.run(tf.initialize_all_variables())\n\nt0 = time.time()\nfor i in range(10000):\n    sess.run(tf.assign(a,np.ones((5, 10000, 10000, 3)) ))\n    t1 = time.time()\n    print(t1-t0)\n    t0 = t1\n</code></pre>\n<p>So is there a method to change the value of Variables without adding an op to graph? Or a way to remove it after(I have a big graph defined before the loop, I don't want to reset all of them and define again with reset_default_graph)?<br>\nAnd since the value assigned to the variable is different all the time, I cannot define the op before the for loop.</p>", "body_text": "Environment info\nOperating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN:\n8.0 RC, 5.1 (on GTX 1080)\nIf installed from source, provide\nHEAD: a8512e2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp as int: 0\nProblem:\nIn my application, I need to change value of some variable, and run the minimize in a loop, thus I have to run assign op continuously, which may add new op to graph every time, thus the program become very slow and memory explode.\nsess = tf.Session()\na = tf.Variable(np.ones((5, 10000, 10000, 3)))\nsess.run(tf.initialize_all_variables())\n\nt0 = time.time()\nfor i in range(10000):\n    sess.run(tf.assign(a,np.ones((5, 10000, 10000, 3)) ))\n    t1 = time.time()\n    print(t1-t0)\n    t0 = t1\n\nSo is there a method to change the value of Variables without adding an op to graph? Or a way to remove it after(I have a big graph defined before the loop, I don't want to reset all of them and define again with reset_default_graph)?\nAnd since the value assigned to the variable is different all the time, I cannot define the op before the for loop.", "body": "### Environment info\n\nOperating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN: \n8.0 RC, 5.1 (on GTX 1080)\nIf installed from source, provide \nHEAD: a8512e24deeeebe57eb1be14726634e7e6c23545\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp as int: 0\n### Problem:\n\nIn my application, I need to change value of some variable, and run the minimize in a loop, thus I have to run assign op continuously, which may add new op to graph every time, thus the program become very slow and memory explode.\n\n```\nsess = tf.Session()\na = tf.Variable(np.ones((5, 10000, 10000, 3)))\nsess.run(tf.initialize_all_variables())\n\nt0 = time.time()\nfor i in range(10000):\n    sess.run(tf.assign(a,np.ones((5, 10000, 10000, 3)) ))\n    t1 = time.time()\n    print(t1-t0)\n    t0 = t1\n```\n\nSo is there a method to change the value of Variables without adding an op to graph? Or a way to remove it after(I have a big graph defined before the loop, I don't want to reset all of them and define again with reset_default_graph)?\nAnd since the value assigned to the variable is different all the time, I cannot define the op before the for loop.\n"}