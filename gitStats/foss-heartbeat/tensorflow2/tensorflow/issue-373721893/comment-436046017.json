{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/436046017", "html_url": "https://github.com/tensorflow/tensorflow/issues/23236#issuecomment-436046017", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23236", "id": 436046017, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjA0NjAxNw==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-05T21:42:27Z", "updated_at": "2018-11-05T21:42:27Z", "author_association": "MEMBER", "body_html": "<p>Ah, I see what is going on. It seems like the bad version is moving a lot of computation to the CPU because of int32 dtypes and colocation constraints. These copies are triggering more memory allocation, which is what you're seeing.</p>\n<p>For example, look at the \"step/model/gather\" node, which runs on the CPU in the bad version and on the GPU on the good version, mostly because the variable is being placed on the CPU in the bad version.</p>\n<p>Essentially, I think a fix is to stop force-placing the init op in the CPU (that is, deindenting the block which starts in <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/5fb8c844512f50ec58fe3b856c8718816d7a504a/tensorflow/python/training/checkpoint_utils.py#L321\">tensorflow/tensorflow/python/training/checkpoint_utils.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 321\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/5fb8c844512f50ec58fe3b856c8718816d7a504a\">5fb8c84</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L321\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"321\"></td>\n          <td id=\"LC321\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> init_op <span class=\"pl-k\">=</span> saveable_objects[<span class=\"pl-c1\">0</span>].restore([restore_op], <span class=\"pl-v\">restored_shapes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n ).</p>\n<p>Can you do this and see if the issue goes away?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=706766\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jpienaar\">@jpienaar</a> for FYI since this smells a lot like a colocation-group bug (which Jacques is working on removing from TF entirely) but is only indirectly so.</p>", "body_text": "Ah, I see what is going on. It seems like the bad version is moving a lot of computation to the CPU because of int32 dtypes and colocation constraints. These copies are triggering more memory allocation, which is what you're seeing.\nFor example, look at the \"step/model/gather\" node, which runs on the CPU in the bad version and on the GPU on the good version, mostly because the variable is being placed on the CPU in the bad version.\nEssentially, I think a fix is to stop force-placing the init op in the CPU (that is, deindenting the block which starts in \n  \n    \n      tensorflow/tensorflow/python/training/checkpoint_utils.py\n    \n    \n         Line 321\n      in\n      5fb8c84\n    \n    \n    \n    \n\n        \n          \n           init_op = saveable_objects[0].restore([restore_op], restored_shapes=None) \n        \n    \n  \n\n ).\nCan you do this and see if the issue goes away?\n@jpienaar for FYI since this smells a lot like a colocation-group bug (which Jacques is working on removing from TF entirely) but is only indirectly so.", "body": "Ah, I see what is going on. It seems like the bad version is moving a lot of computation to the CPU because of int32 dtypes and colocation constraints. These copies are triggering more memory allocation, which is what you're seeing.\r\n\r\nFor example, look at the \"step/model/gather\" node, which runs on the CPU in the bad version and on the GPU on the good version, mostly because the variable is being placed on the CPU in the bad version.\r\n\r\nEssentially, I think a fix is to stop force-placing the init op in the CPU (that is, deindenting the block which starts in https://github.com/tensorflow/tensorflow/blob/5fb8c844512f50ec58fe3b856c8718816d7a504a/tensorflow/python/training/checkpoint_utils.py#L321 ).\r\n\r\nCan you do this and see if the issue goes away?\r\n\r\n@jpienaar for FYI since this smells a lot like a colocation-group bug (which Jacques is working on removing from TF entirely) but is only indirectly so."}