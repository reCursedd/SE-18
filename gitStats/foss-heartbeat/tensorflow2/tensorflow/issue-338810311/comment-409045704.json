{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409045704", "html_url": "https://github.com/tensorflow/tensorflow/issues/20586#issuecomment-409045704", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20586", "id": 409045704, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTA0NTcwNA==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-30T23:33:42Z", "updated_at": "2018-07-30T23:33:42Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2320984\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Bidski\">@Bidski</a> the I agree with you that we should have much better documentation about adding ops to TensorFlow, and on how to write C++ code in the tensorflow project in general. Using the right int64 type is part of it, as is using the right string type (not std::string but tensorflow::string). I also agree that we should fix the current typedefs in the tensorflow codebase to be more precise (as you pointed out, \"int64 = long long\" is ok only on some architectures and compilers, and defining it to be int64_t would be better.</p>\n<p>I'd welcome PRs which clarify our documentation or improve our typedefs.</p>\n<p>I am a little concern about the code complexity vs benefit tradeoff in your pull request. While more precise, it's also more code, and can be wrong in ways that might be difficult for future maintainers to improve. Despite currently leading to broken code, the simple conceptual model of \"1:1 mapping from these types to these enums\" is very debuggable, while the model of \"any type which matches these properties will map to these enums\" can be weird to debug as new types arise (for example, what if there's something which makes the mapping no longer 1:1?).</p>\n<p>The desired use case for these mappings, in the kernel registration path, is for most ops to be registered via the tf-maintained macros TF_CALL_int64, TF_CALL_ALL_TYPES, etc, which are expected to be free of bugs on all platforms we support.</p>\n<p>Does this sound reasonable to you?</p>", "body_text": "@Bidski the I agree with you that we should have much better documentation about adding ops to TensorFlow, and on how to write C++ code in the tensorflow project in general. Using the right int64 type is part of it, as is using the right string type (not std::string but tensorflow::string). I also agree that we should fix the current typedefs in the tensorflow codebase to be more precise (as you pointed out, \"int64 = long long\" is ok only on some architectures and compilers, and defining it to be int64_t would be better.\nI'd welcome PRs which clarify our documentation or improve our typedefs.\nI am a little concern about the code complexity vs benefit tradeoff in your pull request. While more precise, it's also more code, and can be wrong in ways that might be difficult for future maintainers to improve. Despite currently leading to broken code, the simple conceptual model of \"1:1 mapping from these types to these enums\" is very debuggable, while the model of \"any type which matches these properties will map to these enums\" can be weird to debug as new types arise (for example, what if there's something which makes the mapping no longer 1:1?).\nThe desired use case for these mappings, in the kernel registration path, is for most ops to be registered via the tf-maintained macros TF_CALL_int64, TF_CALL_ALL_TYPES, etc, which are expected to be free of bugs on all platforms we support.\nDoes this sound reasonable to you?", "body": "@Bidski the I agree with you that we should have much better documentation about adding ops to TensorFlow, and on how to write C++ code in the tensorflow project in general. Using the right int64 type is part of it, as is using the right string type (not std::string but tensorflow::string). I also agree that we should fix the current typedefs in the tensorflow codebase to be more precise (as you pointed out, \"int64 = long long\" is ok only on some architectures and compilers, and defining it to be int64_t would be better.\r\n\r\nI'd welcome PRs which clarify our documentation or improve our typedefs.\r\n\r\nI am a little concern about the code complexity vs benefit tradeoff in your pull request. While more precise, it's also more code, and can be wrong in ways that might be difficult for future maintainers to improve. Despite currently leading to broken code, the simple conceptual model of \"1:1 mapping from these types to these enums\" is very debuggable, while the model of \"any type which matches these properties will map to these enums\" can be weird to debug as new types arise (for example, what if there's something which makes the mapping no longer 1:1?).\r\n\r\nThe desired use case for these mappings, in the kernel registration path, is for most ops to be registered via the tf-maintained macros TF_CALL_int64, TF_CALL_ALL_TYPES, etc, which are expected to be free of bugs on all platforms we support.\r\n\r\nDoes this sound reasonable to you?"}