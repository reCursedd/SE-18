{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23900", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23900/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23900/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23900/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23900", "id": 383045276, "node_id": "MDU6SXNzdWUzODMwNDUyNzY=", "number": 23900, "title": "No clear_devices in BestExporter", "user": {"login": "SumNeuron", "id": 22868585, "node_id": "MDQ6VXNlcjIyODY4NTg1", "avatar_url": "https://avatars3.githubusercontent.com/u/22868585?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SumNeuron", "html_url": "https://github.com/SumNeuron", "followers_url": "https://api.github.com/users/SumNeuron/followers", "following_url": "https://api.github.com/users/SumNeuron/following{/other_user}", "gists_url": "https://api.github.com/users/SumNeuron/gists{/gist_id}", "starred_url": "https://api.github.com/users/SumNeuron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SumNeuron/subscriptions", "organizations_url": "https://api.github.com/users/SumNeuron/orgs", "repos_url": "https://api.github.com/users/SumNeuron/repos", "events_url": "https://api.github.com/users/SumNeuron/events{/privacy}", "received_events_url": "https://api.github.com/users/SumNeuron/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T10:12:58Z", "updated_at": "2018-11-21T10:12:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):<br>\nYes, please see this <a href=\"https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub\" rel=\"nofollow\">Colab</a></p>\n</li>\n<li>\n<p>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a</p>\n</li>\n<li>\n<p>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a</p>\n</li>\n<li>\n<p>TensorFlow installed from (source or binary): n/a</p>\n</li>\n<li>\n<p>TensorFlow version (use command below): 1.10+</p>\n</li>\n<li>\n<p>Python version: 3.5</p>\n</li>\n<li>\n<p>Bazel version (if compiling from source): n/a</p>\n</li>\n<li>\n<p>GCC/Compiler version (if compiling from source): n/a</p>\n</li>\n<li>\n<p>CUDA/cuDNN version: n/a</p>\n</li>\n<li>\n<p>GPU model and memory: whatever is on Colab</p>\n</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p><strong>Describe the current behavior</strong></p>\n<p>One can not train a distributed-<code>Estimator</code> and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter</p>\n<pre><code>__init__(\n    name='best_exporter',\n    serving_input_receiver_fn=None,\n    event_file_pattern='eval/*.tfevents.*',\n    compare_fn=_loss_smaller,\n    assets_extra=None,\n    as_text=False,\n    exports_to_keep=5\n)\n</code></pre>\n<p>it is apparent that <code>clear_devices</code> is not an option.</p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>Let me easily export and import <code>Estimators</code></p>\n<p><strong>Code to reproduce the issue</strong><br>\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<p>see this <a href=\"https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub\" rel=\"nofollow\">Colab</a><br>\n<strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes, please see this Colab\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\n\n\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\n\n\nTensorFlow installed from (source or binary): n/a\n\n\nTensorFlow version (use command below): 1.10+\n\n\nPython version: 3.5\n\n\nBazel version (if compiling from source): n/a\n\n\nGCC/Compiler version (if compiling from source): n/a\n\n\nCUDA/cuDNN version: n/a\n\n\nGPU model and memory: whatever is on Colab\n\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the current behavior\nOne can not train a distributed-Estimator and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter\n__init__(\n    name='best_exporter',\n    serving_input_receiver_fn=None,\n    event_file_pattern='eval/*.tfevents.*',\n    compare_fn=_loss_smaller,\n    assets_extra=None,\n    as_text=False,\n    exports_to_keep=5\n)\n\nit is apparent that clear_devices is not an option.\nDescribe the expected behavior\nLet me easily export and import Estimators\nCode to reproduce the issue\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\nsee this Colab\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, please see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): n/a\r\n- TensorFlow version (use command below): 1.10+\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: whatever is on Colab\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nOne can not train a distributed-`Estimator` and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter\r\n\r\n```\r\n__init__(\r\n    name='best_exporter',\r\n    serving_input_receiver_fn=None,\r\n    event_file_pattern='eval/*.tfevents.*',\r\n    compare_fn=_loss_smaller,\r\n    assets_extra=None,\r\n    as_text=False,\r\n    exports_to_keep=5\r\n)\r\n```\r\nit is apparent that `clear_devices` is not an option.\r\n\r\n**Describe the expected behavior**\r\n\r\nLet me easily export and import `Estimators`\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"}