{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12818", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12818/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12818/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12818/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12818", "id": 255239454, "node_id": "MDU6SXNzdWUyNTUyMzk0NTQ=", "number": 12818, "title": "[feature request] Any way to control the order of send/recv (host to device data transfer) explicitly?", "user": {"login": "jiazhe0909", "id": 8175586, "node_id": "MDQ6VXNlcjgxNzU1ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8175586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiazhe0909", "html_url": "https://github.com/jiazhe0909", "followers_url": "https://api.github.com/users/jiazhe0909/followers", "following_url": "https://api.github.com/users/jiazhe0909/following{/other_user}", "gists_url": "https://api.github.com/users/jiazhe0909/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiazhe0909/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiazhe0909/subscriptions", "organizations_url": "https://api.github.com/users/jiazhe0909/orgs", "repos_url": "https://api.github.com/users/jiazhe0909/repos", "events_url": "https://api.github.com/users/jiazhe0909/events{/privacy}", "received_events_url": "https://api.github.com/users/jiazhe0909/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-09-05T11:02:48Z", "updated_at": "2018-01-18T19:56:54Z", "closed_at": "2018-01-18T19:56:54Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.2</li>\n<li><strong>Python version</strong>:<br>\n3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.5.2</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n8.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nGTX 1070</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>Overlapping the host to device data transfer with GPU calculation is an important method to improve the performance of inference workload. But I found it very difficult to control the order of data transfers explicitly at this moment. I understand the send/recv operations are added implicitly when the original graph is split/optimized into sub-graphs. I tried to use control dependency + identity/assign operation (as suggested <a href=\"https://github.com/tensorflow/tensorflow/issues/2848\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2848/hovercard\">here</a>) to hand control send/recv order. But it seems impossible to achieve this goal.</p>\n<p>For example,<br>\nIn the following code, we'd like to overlap the H2D memcpy of B-&gt;B_GPU with the matmul calculation.</p>\n<pre><code>import os\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.python.client import session\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import variables\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n\nwith ops.Graph().as_default():\n  with tf.device('/cpu:0'):\n    A = tf.placeholder(tf.float32, shape=(1000, 100), name=\"A\")\n    B = tf.placeholder(tf.float32, shape=(1000, 1000), name=\"B\")\n  with tf.device('/gpu:0'):\n    C = variables.Variable(tf.random_normal([100,1000],stddev=0.1), name=\"C\")\n    A_GPU = tf.identity(A)\n    with tf.control_dependencies([A_GPU]):\n      B_GPU = tf.identity(B)\n      D = tf.add(tf.matmul(A_GPU, C), B_GPU, name=\"D\")\n\n  random_A=np.random.rand(1000,100).astype(np.float32)\n  random_B=np.random.rand(1000,1000).astype(np.float32)\n\n  sess = session.Session()\n  init = tf.global_variables_initializer()\n  sess.run(init)\n\n  for x in range(1,50):\n    output = sess.run(D,feed_dict={A:random_A,B:random_B})\n</code></pre>\n<p>But it turned out that H2D memcpy A-&gt;A_GPU is not ensured to launch first. Actually among the 50 iterations, I noticed the order of transferring A-&gt;A_GPU and transferring B-&gt;B_GPU is randomly performed if we use multiple threads (because the two transfers are handled in different threads, and no-dependency could be built between them).<br>\nIf A-&gt;A_GPU launches first, the matmul op could be overlapped with B-&gt;B-GPU<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8175586/30090954-3f28ef90-92a6-11e7-98ee-2a05e6a7463d.png\"><img src=\"https://user-images.githubusercontent.com/8175586/30090954-3f28ef90-92a6-11e7-98ee-2a05e6a7463d.png\" alt=\"image\" style=\"max-width:100%;\"></a><br>\notherwise, the matmul op has to wait until all H2D memcpys finished.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8175586/30091033-c6b2f988-92a6-11e7-8abb-f41feac3bbf1.png\"><img src=\"https://user-images.githubusercontent.com/8175586/30091033-c6b2f988-92a6-11e7-8abb-f41feac3bbf1.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>Only if we can control the order of send node explicitly, the overlap can be ensured.</p>\n<p>Please let me know if I didn't use the identity operation correctly.</p>\n<p>Thanks.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\n1.2\nPython version:\n3.5\nBazel version (if compiling from source):\n0.5.2\nCUDA/cuDNN version:\n8.0\nGPU model and memory:\nGTX 1070\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nOverlapping the host to device data transfer with GPU calculation is an important method to improve the performance of inference workload. But I found it very difficult to control the order of data transfers explicitly at this moment. I understand the send/recv operations are added implicitly when the original graph is split/optimized into sub-graphs. I tried to use control dependency + identity/assign operation (as suggested here) to hand control send/recv order. But it seems impossible to achieve this goal.\nFor example,\nIn the following code, we'd like to overlap the H2D memcpy of B->B_GPU with the matmul calculation.\nimport os\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.python.client import session\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import variables\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n\nwith ops.Graph().as_default():\n  with tf.device('/cpu:0'):\n    A = tf.placeholder(tf.float32, shape=(1000, 100), name=\"A\")\n    B = tf.placeholder(tf.float32, shape=(1000, 1000), name=\"B\")\n  with tf.device('/gpu:0'):\n    C = variables.Variable(tf.random_normal([100,1000],stddev=0.1), name=\"C\")\n    A_GPU = tf.identity(A)\n    with tf.control_dependencies([A_GPU]):\n      B_GPU = tf.identity(B)\n      D = tf.add(tf.matmul(A_GPU, C), B_GPU, name=\"D\")\n\n  random_A=np.random.rand(1000,100).astype(np.float32)\n  random_B=np.random.rand(1000,1000).astype(np.float32)\n\n  sess = session.Session()\n  init = tf.global_variables_initializer()\n  sess.run(init)\n\n  for x in range(1,50):\n    output = sess.run(D,feed_dict={A:random_A,B:random_B})\n\nBut it turned out that H2D memcpy A->A_GPU is not ensured to launch first. Actually among the 50 iterations, I noticed the order of transferring A->A_GPU and transferring B->B_GPU is randomly performed if we use multiple threads (because the two transfers are handled in different threads, and no-dependency could be built between them).\nIf A->A_GPU launches first, the matmul op could be overlapped with B->B-GPU\n\notherwise, the matmul op has to wait until all H2D memcpys finished.\n\nOnly if we can control the order of send node explicitly, the overlap can be ensured.\nPlease let me know if I didn't use the identity operation correctly.\nThanks.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.2\r\n- **Python version**:\r\n3.5\r\n- **Bazel version (if compiling from source)**:\r\n0.5.2\r\n- **CUDA/cuDNN version**:\r\n8.0\r\n- **GPU model and memory**:\r\nGTX 1070\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nOverlapping the host to device data transfer with GPU calculation is an important method to improve the performance of inference workload. But I found it very difficult to control the order of data transfers explicitly at this moment. I understand the send/recv operations are added implicitly when the original graph is split/optimized into sub-graphs. I tried to use control dependency + identity/assign operation (as suggested [here](https://github.com/tensorflow/tensorflow/issues/2848)) to hand control send/recv order. But it seems impossible to achieve this goal. \r\n\r\nFor example, \r\nIn the following code, we'd like to overlap the H2D memcpy of B->B_GPU with the matmul calculation.\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.python.client import session\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import variables\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\r\n\r\nwith ops.Graph().as_default():\r\n  with tf.device('/cpu:0'):\r\n    A = tf.placeholder(tf.float32, shape=(1000, 100), name=\"A\")\r\n    B = tf.placeholder(tf.float32, shape=(1000, 1000), name=\"B\")\r\n  with tf.device('/gpu:0'):\r\n    C = variables.Variable(tf.random_normal([100,1000],stddev=0.1), name=\"C\")\r\n    A_GPU = tf.identity(A)\r\n    with tf.control_dependencies([A_GPU]):\r\n      B_GPU = tf.identity(B)\r\n      D = tf.add(tf.matmul(A_GPU, C), B_GPU, name=\"D\")\r\n\r\n  random_A=np.random.rand(1000,100).astype(np.float32)\r\n  random_B=np.random.rand(1000,1000).astype(np.float32)\r\n\r\n  sess = session.Session()\r\n  init = tf.global_variables_initializer()\r\n  sess.run(init)\r\n\r\n  for x in range(1,50):\r\n    output = sess.run(D,feed_dict={A:random_A,B:random_B})\r\n```\r\n\r\nBut it turned out that H2D memcpy A->A_GPU is not ensured to launch first. Actually among the 50 iterations, I noticed the order of transferring A->A_GPU and transferring B->B_GPU is randomly performed if we use multiple threads (because the two transfers are handled in different threads, and no-dependency could be built between them). \r\nIf A->A_GPU launches first, the matmul op could be overlapped with B->B-GPU\r\n![image](https://user-images.githubusercontent.com/8175586/30090954-3f28ef90-92a6-11e7-98ee-2a05e6a7463d.png)\r\notherwise, the matmul op has to wait until all H2D memcpys finished.\r\n![image](https://user-images.githubusercontent.com/8175586/30091033-c6b2f988-92a6-11e7-8abb-f41feac3bbf1.png)\r\n\r\nOnly if we can control the order of send node explicitly, the overlap can be ensured.\r\n\r\nPlease let me know if I didn't use the identity operation correctly.\r\n\r\nThanks."}