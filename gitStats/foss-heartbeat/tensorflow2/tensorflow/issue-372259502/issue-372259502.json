{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23136", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23136/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23136/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23136/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23136", "id": 372259502, "node_id": "MDU6SXNzdWUzNzIyNTk1MDI=", "number": 23136, "title": "Estimators Siamese Model Peformance Issue ", "user": {"login": "imranparuk", "id": 10554727, "node_id": "MDQ6VXNlcjEwNTU0NzI3", "avatar_url": "https://avatars3.githubusercontent.com/u/10554727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/imranparuk", "html_url": "https://github.com/imranparuk", "followers_url": "https://api.github.com/users/imranparuk/followers", "following_url": "https://api.github.com/users/imranparuk/following{/other_user}", "gists_url": "https://api.github.com/users/imranparuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/imranparuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/imranparuk/subscriptions", "organizations_url": "https://api.github.com/users/imranparuk/orgs", "repos_url": "https://api.github.com/users/imranparuk/repos", "events_url": "https://api.github.com/users/imranparuk/events{/privacy}", "received_events_url": "https://api.github.com/users/imranparuk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097545817, "node_id": "MDU6TGFiZWwxMDk3NTQ1ODE3", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:apis", "name": "comp:apis", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-20T22:40:29Z", "updated_at": "2018-11-21T19:02:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>tf.esitmators producing poor performance vs TF &amp; Keras.</p>\n<ul>\n<li>\n<p>System information<br>\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04<br>\nTensorFlow installed from (source or binary):<br>\npip3 install --upgrade tensorflow-gpu==1.12.0-rc1<br>\nTensorFlow version: 1.12.0-rc1<br>\nPython version: Python 3.6.5<br>\nInstalled using virtualenv? pip? conda?: pip3<br>\nCUDA/cuDNN version: 9.0 / 7.0.5<br>\nGPU model and memory: nvidia gtx 1050 (Lenovo Laptop)</p>\n</li>\n<li>\n<p>Code to reproduce performance issue:</p>\n</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">from</span> keras.datasets <span class=\"pl-k\">import</span> mnist\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">import</span> random\ntf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">cnn_cnn_model</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Model function for CNN.<span class=\"pl-pds\">\"\"\"</span></span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Flat 1</span>\n    flat_1 <span class=\"pl-k\">=</span> tf.layers.flatten(\n        features,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>flattern<span class=\"pl-pds\">\"</span></span>,\n    )\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> dense 1</span>\n    dense_1 <span class=\"pl-k\">=</span> tf.layers.dense(\n        flat_1,\n        <span class=\"pl-c1\">1024</span>,\n        <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n        <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>dense_1<span class=\"pl-pds\">'</span></span>,\n    )\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> drop 1</span>\n    drop_1 <span class=\"pl-k\">=</span> tf.layers.dropout(\n        dense_1,\n        <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>drop_1<span class=\"pl-pds\">\"</span></span>,\n    )\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> dense 2</span>\n    dense_2 <span class=\"pl-k\">=</span> tf.layers.dense(\n        drop_1,\n        <span class=\"pl-c1\">512</span>,\n        <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span>tf.nn.relu,\n        <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>dense_2<span class=\"pl-pds\">'</span></span>,\n    )\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> drop 2</span>\n    drop_2 <span class=\"pl-k\">=</span> tf.layers.dropout(\n        dense_2,\n        <span class=\"pl-v\">rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>drop_2<span class=\"pl-pds\">\"</span></span>,\n    )\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> dense 3</span>\n    dense_3 <span class=\"pl-k\">=</span> tf.layers.dense(\n        drop_2,\n        <span class=\"pl-c1\">128</span>,\n        <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n        <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>reuse,\n        <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>dense_3<span class=\"pl-pds\">'</span></span>,\n    )\n\n    <span class=\"pl-k\">return</span> dense_3\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">accuracy</span>(<span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">y_pred</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">'''</span>Compute classification accuracy with a fixed threshold on distances.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">'''</span></span>\n\n    <span class=\"pl-k\">return</span> tf.metrics.mean(tf.equal(y_true, tf.cast(y_pred <span class=\"pl-k\">&lt;</span> tf.cast(<span class=\"pl-c1\">0.5</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>), y_true.dtype)))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">compute_accuracy</span>(<span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">y_pred</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">'''</span>Compute classification accuracy with a fixed threshold on distances.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">'''</span></span>\n    pred <span class=\"pl-k\">=</span> y_pred.ravel() <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">0.5</span>\n    <span class=\"pl-k\">return</span> np.mean(pred <span class=\"pl-k\">==</span> y_true)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">my_loss</span>(<span class=\"pl-smi\">dist</span>, <span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">margin</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>):\n\n    y_true <span class=\"pl-k\">=</span> tf.cast(y_true, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    margin <span class=\"pl-k\">=</span> tf.cast(margin, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    dist <span class=\"pl-k\">=</span> tf.cast(dist, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss function</span>\n    loss_pos <span class=\"pl-k\">=</span> tf.multiply(y_true, tf.pow(dist, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>constrastive_loss_1<span class=\"pl-pds\">'</span></span>)\n    loss_neg <span class=\"pl-k\">=</span> tf.multiply(tf.subtract(tf.cast(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>), y_true),\n                           tf.pow(tf.maximum(tf.subtract(margin, dist), <span class=\"pl-c1\">0</span>), <span class=\"pl-c1\">2</span>),\n                           <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>constrastive_loss_2<span class=\"pl-pds\">'</span></span>)\n    loss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.add(loss_neg, loss_pos), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>constrastive_loss<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">return</span> loss\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">euclidean_distance</span>(<span class=\"pl-smi\">x1</span>, <span class=\"pl-smi\">x2</span>):\n    x1 <span class=\"pl-k\">=</span> tf.cast(x1, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    x2 <span class=\"pl-k\">=</span> tf.cast(x2, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    epsilon <span class=\"pl-k\">=</span> tf.cast(<span class=\"pl-c1\">1e-7</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n\n    eucd2 <span class=\"pl-k\">=</span> tf.pow(tf.subtract(x1, x2), <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>eucd2<span class=\"pl-pds\">'</span></span>)\n    eucd2 <span class=\"pl-k\">=</span> tf.reduce_sum(eucd2, <span class=\"pl-c1\">1</span>)\n\n    eucd2 <span class=\"pl-k\">=</span> tf.maximum(eucd2, epsilon)\n    eucd <span class=\"pl-k\">=</span> tf.sqrt(eucd2, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>eucd<span class=\"pl-pds\">'</span></span>)\n\n    <span class=\"pl-k\">return</span> eucd\n\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">create_siamese</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Input Layers</span>\n    input_layer_a <span class=\"pl-k\">=</span> tf.reshape(features[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_1<span class=\"pl-pds\">\"</span></span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>])\n    input_layer_b <span class=\"pl-k\">=</span> tf.reshape(features[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_2<span class=\"pl-pds\">\"</span></span>], [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>])\n\n    <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>siamese<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> scope:\n\n        network_a <span class=\"pl-k\">=</span> cnn_cnn_model(input_layer_a, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        network_b <span class=\"pl-k\">=</span> cnn_cnn_model(input_layer_b, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>:\n        dist <span class=\"pl-k\">=</span> euclidean_distance(network_a, network_b)\n        loss <span class=\"pl-k\">=</span> my_loss(dist, labels)\n\n        optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.001</span>)\n        train_op <span class=\"pl-k\">=</span> optimizer.minimize(\n            <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss,\n            <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>tf.train.get_global_step())\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op)\n\n    <span class=\"pl-k\">elif</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n        predictions <span class=\"pl-k\">=</span> {\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>eucl<span class=\"pl-pds\">\"</span></span>: euclidean_distance(network_a, network_b)\n        }\n\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">create_pairs</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">digit_indices</span>, <span class=\"pl-smi\">num_classes</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">'''</span>Positive and negative pair creation.</span>\n<span class=\"pl-s\">    Alternates between positive and negative pairs.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">'''</span></span>\n    pairs <span class=\"pl-k\">=</span> []\n    labels <span class=\"pl-k\">=</span> []\n    n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">min</span>([<span class=\"pl-c1\">len</span>(digit_indices[d]) <span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_classes)]) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_classes):\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n):\n            z1, z2 <span class=\"pl-k\">=</span> digit_indices[d][i], digit_indices[d][i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>]\n            pairs <span class=\"pl-k\">+=</span> [[x[z1], x[z2]]]\n            inc <span class=\"pl-k\">=</span> random.randrange(<span class=\"pl-c1\">1</span>, num_classes)\n            dn <span class=\"pl-k\">=</span> (d <span class=\"pl-k\">+</span> inc) <span class=\"pl-k\">%</span> num_classes\n            z1, z2 <span class=\"pl-k\">=</span> digit_indices[d][i], digit_indices[dn][i]\n            pairs <span class=\"pl-k\">+=</span> [[x[z1], x[z2]]]\n            labels <span class=\"pl-k\">+=</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>]\n    <span class=\"pl-k\">return</span> np.array(pairs), np.array(labels)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">unused_argv</span>):\n\n    path_ <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/media/imran/bigboy/datasets/my_smallVoxCeleb/updated_datasets/split_datasets/3d_cnn/smallest_dataset.hdf5<span class=\"pl-pds\">'</span></span>\n    num_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> the data, split between train and test sets</span>\n    (x_train, y_train), (x_test, y_test) <span class=\"pl-k\">=</span> mnist.load_data()\n    x_train <span class=\"pl-k\">=</span> x_train.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    x_test <span class=\"pl-k\">=</span> x_test.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    y_train <span class=\"pl-k\">=</span> y_train.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    y_test <span class=\"pl-k\">=</span> y_test.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n\n\n    x_train <span class=\"pl-k\">/=</span> <span class=\"pl-c1\">255</span>\n    x_test <span class=\"pl-k\">/=</span> <span class=\"pl-c1\">255</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> create training+test positive and negative pairs</span>\n    digit_indices <span class=\"pl-k\">=</span> [np.where(y_train <span class=\"pl-k\">==</span> i)[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_classes)]\n    tr_pairs, tr_y <span class=\"pl-k\">=</span> create_pairs(x_train, digit_indices, num_classes)\n\n    digit_indices <span class=\"pl-k\">=</span> [np.where(y_test <span class=\"pl-k\">==</span> i)[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_classes)]\n    te_pairs, te_y <span class=\"pl-k\">=</span> create_pairs(x_test, digit_indices, num_classes)\n\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create the Estimator</span>\n    mnist_classifier <span class=\"pl-k\">=</span> tf.estimator.Estimator(\n      <span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>create_siamese)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Train the model</span>\n    train_input_fn <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n      <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_1<span class=\"pl-pds\">\"</span></span>: tr_pairs[:, <span class=\"pl-c1\">0</span>],\n         <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_2<span class=\"pl-pds\">\"</span></span>: tr_pairs[:, <span class=\"pl-c1\">1</span>]},\n      <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>tr_y,\n      <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>,\n      <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n      <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    test_input_fn_train <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n        <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_1<span class=\"pl-pds\">\"</span></span>: tr_pairs[:, <span class=\"pl-c1\">0</span>],\n           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_2<span class=\"pl-pds\">\"</span></span>: tr_pairs[:, <span class=\"pl-c1\">1</span>]},\n        <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>\n       )\n\n    test_input_fn_test <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n        <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_1<span class=\"pl-pds\">\"</span></span>: te_pairs[:, <span class=\"pl-c1\">0</span>],\n           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_2<span class=\"pl-pds\">\"</span></span>: te_pairs[:, <span class=\"pl-c1\">1</span>]},\n        <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>\n       )\n\n    mnist_classifier.train(\n        <span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>train_input_fn,\n        <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>)\n\n    predictions_test <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(mnist_classifier.predict(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>test_input_fn_test))\n    predictions_train <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(mnist_classifier.predict(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>test_input_fn_train))\n\n    preds_test <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> item <span class=\"pl-k\">in</span> predictions_test:\n        preds_test.append(item[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>eucl<span class=\"pl-pds\">'</span></span>])\n\n    preds_train <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> item <span class=\"pl-k\">in</span> predictions_train:\n        preds_train.append(item[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>eucl<span class=\"pl-pds\">'</span></span>])\n\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Accuracy on train set: <span class=\"pl-pds\">\"</span></span>, compute_accuracy(tr_y, np.array(preds_train)))\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Accuracy on test set: <span class=\"pl-pds\">\"</span></span>, compute_accuracy(te_y, np.array(preds_test)))\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    tf.app.run()</pre></div>\n<p>With Keras model.fit(), this yields:</p>\n<pre><code>Accuracy on training set: 95.70%\nAccuracy on test set: 95.33%\n</code></pre>\n<p>With TF this yields:</p>\n<pre><code>Accuracy on training set: 94.56%\nAccuracy on test set: 94.53%\n</code></pre>\n<p>With tf.estimators this yields:</p>\n<pre><code>Accuracy on training set: 61.32%\nAccuracy on test set: 62.74%\n</code></pre>\n<p>The code for the benchmark code for Keras and TF can be found here:</p>\n<ul>\n<li>Keras:<br>\n<a href=\"https://gist.github.com/imranparuk/25963eb3b2db1540ead684271de6f5a8\">https://gist.github.com/imranparuk/25963eb3b2db1540ead684271de6f5a8</a></li>\n<li>TF:<br>\n<a href=\"https://gist.github.com/imranparuk/4fe48323a006ff030bf2037136db7868\">https://gist.github.com/imranparuk/4fe48323a006ff030bf2037136db7868</a></li>\n</ul>", "body_text": "tf.esitmators producing poor performance vs TF & Keras.\n\n\nSystem information\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\nTensorFlow installed from (source or binary):\npip3 install --upgrade tensorflow-gpu==1.12.0-rc1\nTensorFlow version: 1.12.0-rc1\nPython version: Python 3.6.5\nInstalled using virtualenv? pip? conda?: pip3\nCUDA/cuDNN version: 9.0 / 7.0.5\nGPU model and memory: nvidia gtx 1050 (Lenovo Laptop)\n\n\nCode to reproduce performance issue:\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras.datasets import mnist\n\nimport numpy as np\nimport tensorflow as tf\n\nimport random\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_cnn_model(features, reuse=False):\n    \"\"\"Model function for CNN.\"\"\"\n\n    # Flat 1\n    flat_1 = tf.layers.flatten(\n        features,\n        name=\"flattern\",\n    )\n\n    # dense 1\n    dense_1 = tf.layers.dense(\n        flat_1,\n        1024,\n        activation=tf.nn.relu,\n        reuse=reuse,\n        name='dense_1',\n    )\n\n    # drop 1\n    drop_1 = tf.layers.dropout(\n        dense_1,\n        rate=0.1,\n        name=\"drop_1\",\n    )\n\n    # dense 2\n    dense_2 = tf.layers.dense(\n        drop_1,\n        512,\n        activation=tf.nn.relu,\n        reuse=reuse,\n        name='dense_2',\n    )\n\n    # drop 2\n    drop_2 = tf.layers.dropout(\n        dense_2,\n        rate=0.1,\n        name=\"drop_2\",\n    )\n\n    # dense 3\n    dense_3 = tf.layers.dense(\n        drop_2,\n        128,\n        activation=None,\n        reuse=reuse,\n        name='dense_3',\n    )\n\n    return dense_3\n\n\ndef accuracy(y_true, y_pred):\n    '''Compute classification accuracy with a fixed threshold on distances.\n    '''\n\n    return tf.metrics.mean(tf.equal(y_true, tf.cast(y_pred < tf.cast(0.5, 'float64'), y_true.dtype)))\n\ndef compute_accuracy(y_true, y_pred):\n    '''Compute classification accuracy with a fixed threshold on distances.\n    '''\n    pred = y_pred.ravel() < 0.5\n    return np.mean(pred == y_true)\n\n\ndef my_loss(dist, y_true, margin=1.0):\n\n    y_true = tf.cast(y_true, 'float64')\n    margin = tf.cast(margin, 'float64')\n    dist = tf.cast(dist, 'float64')\n\n    # Loss function\n    loss_pos = tf.multiply(y_true, tf.pow(dist, 2), name='constrastive_loss_1')\n    loss_neg = tf.multiply(tf.subtract(tf.cast(1.0, 'float64'), y_true),\n                           tf.pow(tf.maximum(tf.subtract(margin, dist), 0), 2),\n                           name='constrastive_loss_2')\n    loss = tf.reduce_mean(tf.add(loss_neg, loss_pos), name='constrastive_loss')\n\n    return loss\n\n\ndef euclidean_distance(x1, x2):\n    x1 = tf.cast(x1, 'float64')\n    x2 = tf.cast(x2, 'float64')\n    epsilon = tf.cast(1e-7, 'float64')\n\n    eucd2 = tf.pow(tf.subtract(x1, x2), 2, name='eucd2')\n    eucd2 = tf.reduce_sum(eucd2, 1)\n\n    eucd2 = tf.maximum(eucd2, epsilon)\n    eucd = tf.sqrt(eucd2, name='eucd')\n\n    return eucd\n\n\n\ndef create_siamese(features, labels, mode):\n    # Input Layers\n    input_layer_a = tf.reshape(features[\"x_1\"], [-1, 28, 28])\n    input_layer_b = tf.reshape(features[\"x_2\"], [-1, 28, 28])\n\n    with tf.variable_scope(\"siamese\") as scope:\n\n        network_a = cnn_cnn_model(input_layer_a, reuse=False)\n        network_b = cnn_cnn_model(input_layer_b, reuse=True)\n\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        dist = euclidean_distance(network_a, network_b)\n        loss = my_loss(dist, labels)\n\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    elif mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\n            \"eucl\": euclidean_distance(network_a, network_b)\n        }\n\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n\ndef create_pairs(x, digit_indices, num_classes):\n    '''Positive and negative pair creation.\n    Alternates between positive and negative pairs.\n    '''\n    pairs = []\n    labels = []\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n    for d in range(num_classes):\n        for i in range(n):\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n            pairs += [[x[z1], x[z2]]]\n            inc = random.randrange(1, num_classes)\n            dn = (d + inc) % num_classes\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n            pairs += [[x[z1], x[z2]]]\n            labels += [1, 0]\n    return np.array(pairs), np.array(labels)\n\ndef main(unused_argv):\n\n    path_ = '/media/imran/bigboy/datasets/my_smallVoxCeleb/updated_datasets/split_datasets/3d_cnn/smallest_dataset.hdf5'\n    num_classes = 10\n\n    # the data, split between train and test sets\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.astype('float64')\n    x_test = x_test.astype('float64')\n    y_train = y_train.astype('float64')\n    y_test = y_test.astype('float64')\n\n\n    x_train /= 255\n    x_test /= 255\n\n    # create training+test positive and negative pairs\n    digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n    tr_pairs, tr_y = create_pairs(x_train, digit_indices, num_classes)\n\n    digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n    te_pairs, te_y = create_pairs(x_test, digit_indices, num_classes)\n\n\n    # Create the Estimator\n    mnist_classifier = tf.estimator.Estimator(\n      model_fn=create_siamese)\n\n    # Train the model\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x_1\": tr_pairs[:, 0],\n         \"x_2\": tr_pairs[:, 1]},\n      y=tr_y,\n      batch_size=128,\n      num_epochs=1,\n      shuffle=True)\n\n    test_input_fn_train = tf.estimator.inputs.numpy_input_fn(\n        x={\"x_1\": tr_pairs[:, 0],\n           \"x_2\": tr_pairs[:, 1]},\n        shuffle=False\n       )\n\n    test_input_fn_test = tf.estimator.inputs.numpy_input_fn(\n        x={\"x_1\": te_pairs[:, 0],\n           \"x_2\": te_pairs[:, 1]},\n        shuffle=False\n       )\n\n    mnist_classifier.train(\n        input_fn=train_input_fn,\n        steps=None)\n\n    predictions_test = list(mnist_classifier.predict(input_fn=test_input_fn_test))\n    predictions_train = list(mnist_classifier.predict(input_fn=test_input_fn_train))\n\n    preds_test = []\n    for item in predictions_test:\n        preds_test.append(item['eucl'])\n\n    preds_train = []\n    for item in predictions_train:\n        preds_train.append(item['eucl'])\n\n    print(\"Accuracy on train set: \", compute_accuracy(tr_y, np.array(preds_train)))\n    print(\"Accuracy on test set: \", compute_accuracy(te_y, np.array(preds_test)))\n\n\nif __name__ == \"__main__\":\n    tf.app.run()\nWith Keras model.fit(), this yields:\nAccuracy on training set: 95.70%\nAccuracy on test set: 95.33%\n\nWith TF this yields:\nAccuracy on training set: 94.56%\nAccuracy on test set: 94.53%\n\nWith tf.estimators this yields:\nAccuracy on training set: 61.32%\nAccuracy on test set: 62.74%\n\nThe code for the benchmark code for Keras and TF can be found here:\n\nKeras:\nhttps://gist.github.com/imranparuk/25963eb3b2db1540ead684271de6f5a8\nTF:\nhttps://gist.github.com/imranparuk/4fe48323a006ff030bf2037136db7868", "body": "tf.esitmators producing poor performance vs TF & Keras.  \r\n\r\n* System information\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n    TensorFlow installed from (source or binary):\r\n    pip3 install --upgrade tensorflow-gpu==1.12.0-rc1\r\n    TensorFlow version: 1.12.0-rc1\r\n    Python version: Python 3.6.5 \r\n    Installed using virtualenv? pip? conda?: pip3\r\n    CUDA/cuDNN version: 9.0 / 7.0.5\r\n    GPU model and memory: nvidia gtx 1050 (Lenovo Laptop)\r\n\r\n* Code to reproduce performance issue:\r\n\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom keras.datasets import mnist\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nimport random\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef cnn_cnn_model(features, reuse=False):\r\n    \"\"\"Model function for CNN.\"\"\"\r\n\r\n    # Flat 1\r\n    flat_1 = tf.layers.flatten(\r\n        features,\r\n        name=\"flattern\",\r\n    )\r\n\r\n    # dense 1\r\n    dense_1 = tf.layers.dense(\r\n        flat_1,\r\n        1024,\r\n        activation=tf.nn.relu,\r\n        reuse=reuse,\r\n        name='dense_1',\r\n    )\r\n\r\n    # drop 1\r\n    drop_1 = tf.layers.dropout(\r\n        dense_1,\r\n        rate=0.1,\r\n        name=\"drop_1\",\r\n    )\r\n\r\n    # dense 2\r\n    dense_2 = tf.layers.dense(\r\n        drop_1,\r\n        512,\r\n        activation=tf.nn.relu,\r\n        reuse=reuse,\r\n        name='dense_2',\r\n    )\r\n\r\n    # drop 2\r\n    drop_2 = tf.layers.dropout(\r\n        dense_2,\r\n        rate=0.1,\r\n        name=\"drop_2\",\r\n    )\r\n\r\n    # dense 3\r\n    dense_3 = tf.layers.dense(\r\n        drop_2,\r\n        128,\r\n        activation=None,\r\n        reuse=reuse,\r\n        name='dense_3',\r\n    )\r\n\r\n    return dense_3\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n\r\n    return tf.metrics.mean(tf.equal(y_true, tf.cast(y_pred < tf.cast(0.5, 'float64'), y_true.dtype)))\r\n\r\ndef compute_accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    pred = y_pred.ravel() < 0.5\r\n    return np.mean(pred == y_true)\r\n\r\n\r\ndef my_loss(dist, y_true, margin=1.0):\r\n\r\n    y_true = tf.cast(y_true, 'float64')\r\n    margin = tf.cast(margin, 'float64')\r\n    dist = tf.cast(dist, 'float64')\r\n\r\n    # Loss function\r\n    loss_pos = tf.multiply(y_true, tf.pow(dist, 2), name='constrastive_loss_1')\r\n    loss_neg = tf.multiply(tf.subtract(tf.cast(1.0, 'float64'), y_true),\r\n                           tf.pow(tf.maximum(tf.subtract(margin, dist), 0), 2),\r\n                           name='constrastive_loss_2')\r\n    loss = tf.reduce_mean(tf.add(loss_neg, loss_pos), name='constrastive_loss')\r\n\r\n    return loss\r\n\r\n\r\ndef euclidean_distance(x1, x2):\r\n    x1 = tf.cast(x1, 'float64')\r\n    x2 = tf.cast(x2, 'float64')\r\n    epsilon = tf.cast(1e-7, 'float64')\r\n\r\n    eucd2 = tf.pow(tf.subtract(x1, x2), 2, name='eucd2')\r\n    eucd2 = tf.reduce_sum(eucd2, 1)\r\n\r\n    eucd2 = tf.maximum(eucd2, epsilon)\r\n    eucd = tf.sqrt(eucd2, name='eucd')\r\n\r\n    return eucd\r\n\r\n\r\n\r\ndef create_siamese(features, labels, mode):\r\n    # Input Layers\r\n    input_layer_a = tf.reshape(features[\"x_1\"], [-1, 28, 28])\r\n    input_layer_b = tf.reshape(features[\"x_2\"], [-1, 28, 28])\r\n\r\n    with tf.variable_scope(\"siamese\") as scope:\r\n\r\n        network_a = cnn_cnn_model(input_layer_a, reuse=False)\r\n        network_b = cnn_cnn_model(input_layer_b, reuse=True)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        dist = euclidean_distance(network_a, network_b)\r\n        loss = my_loss(dist, labels)\r\n\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n        train_op = optimizer.minimize(\r\n            loss=loss,\r\n            global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n    elif mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            \"eucl\": euclidean_distance(network_a, network_b)\r\n        }\r\n\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n\r\ndef create_pairs(x, digit_indices, num_classes):\r\n    '''Positive and negative pair creation.\r\n    Alternates between positive and negative pairs.\r\n    '''\r\n    pairs = []\r\n    labels = []\r\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\r\n    for d in range(num_classes):\r\n        for i in range(n):\r\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\r\n            pairs += [[x[z1], x[z2]]]\r\n            inc = random.randrange(1, num_classes)\r\n            dn = (d + inc) % num_classes\r\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\r\n            pairs += [[x[z1], x[z2]]]\r\n            labels += [1, 0]\r\n    return np.array(pairs), np.array(labels)\r\n\r\ndef main(unused_argv):\r\n\r\n    path_ = '/media/imran/bigboy/datasets/my_smallVoxCeleb/updated_datasets/split_datasets/3d_cnn/smallest_dataset.hdf5'\r\n    num_classes = 10\r\n\r\n    # the data, split between train and test sets\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    x_train = x_train.astype('float64')\r\n    x_test = x_test.astype('float64')\r\n    y_train = y_train.astype('float64')\r\n    y_test = y_test.astype('float64')\r\n\r\n\r\n    x_train /= 255\r\n    x_test /= 255\r\n\r\n    # create training+test positive and negative pairs\r\n    digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\r\n    tr_pairs, tr_y = create_pairs(x_train, digit_indices, num_classes)\r\n\r\n    digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\r\n    te_pairs, te_y = create_pairs(x_test, digit_indices, num_classes)\r\n\r\n\r\n    # Create the Estimator\r\n    mnist_classifier = tf.estimator.Estimator(\r\n      model_fn=create_siamese)\r\n\r\n    # Train the model\r\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n      x={\"x_1\": tr_pairs[:, 0],\r\n         \"x_2\": tr_pairs[:, 1]},\r\n      y=tr_y,\r\n      batch_size=128,\r\n      num_epochs=1,\r\n      shuffle=True)\r\n\r\n    test_input_fn_train = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"x_1\": tr_pairs[:, 0],\r\n           \"x_2\": tr_pairs[:, 1]},\r\n        shuffle=False\r\n       )\r\n\r\n    test_input_fn_test = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"x_1\": te_pairs[:, 0],\r\n           \"x_2\": te_pairs[:, 1]},\r\n        shuffle=False\r\n       )\r\n\r\n    mnist_classifier.train(\r\n        input_fn=train_input_fn,\r\n        steps=None)\r\n\r\n    predictions_test = list(mnist_classifier.predict(input_fn=test_input_fn_test))\r\n    predictions_train = list(mnist_classifier.predict(input_fn=test_input_fn_train))\r\n\r\n    preds_test = []\r\n    for item in predictions_test:\r\n        preds_test.append(item['eucl'])\r\n\r\n    preds_train = []\r\n    for item in predictions_train:\r\n        preds_train.append(item['eucl'])\r\n\r\n    print(\"Accuracy on train set: \", compute_accuracy(tr_y, np.array(preds_train)))\r\n    print(\"Accuracy on test set: \", compute_accuracy(te_y, np.array(preds_test)))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```\r\n\r\nWith Keras model.fit(), this yields:\r\n```\r\nAccuracy on training set: 95.70%\r\nAccuracy on test set: 95.33%\r\n```\r\nWith TF this yields:\r\n```\r\nAccuracy on training set: 94.56%\r\nAccuracy on test set: 94.53%\r\n```\r\nWith tf.estimators this yields:\r\n```\r\nAccuracy on training set: 61.32%\r\nAccuracy on test set: 62.74%\r\n```\r\n\r\nThe code for the benchmark code for Keras and TF can be found here:\r\n+ Keras:\r\nhttps://gist.github.com/imranparuk/25963eb3b2db1540ead684271de6f5a8\r\n+ TF:\r\nhttps://gist.github.com/imranparuk/4fe48323a006ff030bf2037136db7868\r\n\r\n"}