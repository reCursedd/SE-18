{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245066737", "html_url": "https://github.com/tensorflow/tensorflow/issues/4132#issuecomment-245066737", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4132", "id": 245066737, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTA2NjczNw==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-06T19:43:52Z", "updated_at": "2016-09-06T19:43:52Z", "author_association": "MEMBER", "body_html": "<p>I've spent some more time on this, and I have not been able to reproduce your original results since last week.  I've seen highly variable behavior in the execution times (on the order of ~2x, not 10x) and it looks like that's mainly due to threadpool contention (at least in my environment).</p>\n<p>Recap: Your model basically tests doing one wide pairwise Op versus a sequential series of narrow pairwise Ops, where the inner loop performs the same number of atomic ops in aggregate.  In wide configuration, there's one iteration on the entire input, in narrow configuration there's many iterations on shorter segments.  In narrow configuration there's only a few threads active in the inner loop.  In wide configuration there may be as many threads active as cores available.</p>\n<p>What I'm seeing is that sometimes there's little thread contention on my test machine and the wide configuration runs slightly faster than narrow, as expected, with low latency.  However, sometimes there's contention from other processes and the wide configuration is much more vulnerable to having one or more closures delayed, so the execution variance is much higher and the mean time also drifts up above that over the narrow configuration.</p>\n<p>I'm going to close this issue unless evidence surfaces that there's a fixable problem.</p>", "body_text": "I've spent some more time on this, and I have not been able to reproduce your original results since last week.  I've seen highly variable behavior in the execution times (on the order of ~2x, not 10x) and it looks like that's mainly due to threadpool contention (at least in my environment).\nRecap: Your model basically tests doing one wide pairwise Op versus a sequential series of narrow pairwise Ops, where the inner loop performs the same number of atomic ops in aggregate.  In wide configuration, there's one iteration on the entire input, in narrow configuration there's many iterations on shorter segments.  In narrow configuration there's only a few threads active in the inner loop.  In wide configuration there may be as many threads active as cores available.\nWhat I'm seeing is that sometimes there's little thread contention on my test machine and the wide configuration runs slightly faster than narrow, as expected, with low latency.  However, sometimes there's contention from other processes and the wide configuration is much more vulnerable to having one or more closures delayed, so the execution variance is much higher and the mean time also drifts up above that over the narrow configuration.\nI'm going to close this issue unless evidence surfaces that there's a fixable problem.", "body": "I've spent some more time on this, and I have not been able to reproduce your original results since last week.  I've seen highly variable behavior in the execution times (on the order of ~2x, not 10x) and it looks like that's mainly due to threadpool contention (at least in my environment).  \n\nRecap: Your model basically tests doing one wide pairwise Op versus a sequential series of narrow pairwise Ops, where the inner loop performs the same number of atomic ops in aggregate.  In wide configuration, there's one iteration on the entire input, in narrow configuration there's many iterations on shorter segments.  In narrow configuration there's only a few threads active in the inner loop.  In wide configuration there may be as many threads active as cores available.\n\nWhat I'm seeing is that sometimes there's little thread contention on my test machine and the wide configuration runs slightly faster than narrow, as expected, with low latency.  However, sometimes there's contention from other processes and the wide configuration is much more vulnerable to having one or more closures delayed, so the execution variance is much higher and the mean time also drifts up above that over the narrow configuration.\n\nI'm going to close this issue unless evidence surfaces that there's a fixable problem.\n"}