{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/395961916", "html_url": "https://github.com/tensorflow/tensorflow/issues/19305#issuecomment-395961916", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19305", "id": 395961916, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTk2MTkxNg==", "user": {"login": "elgehelge", "id": 665484, "node_id": "MDQ6VXNlcjY2NTQ4NA==", "avatar_url": "https://avatars0.githubusercontent.com/u/665484?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elgehelge", "html_url": "https://github.com/elgehelge", "followers_url": "https://api.github.com/users/elgehelge/followers", "following_url": "https://api.github.com/users/elgehelge/following{/other_user}", "gists_url": "https://api.github.com/users/elgehelge/gists{/gist_id}", "starred_url": "https://api.github.com/users/elgehelge/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elgehelge/subscriptions", "organizations_url": "https://api.github.com/users/elgehelge/orgs", "repos_url": "https://api.github.com/users/elgehelge/repos", "events_url": "https://api.github.com/users/elgehelge/events{/privacy}", "received_events_url": "https://api.github.com/users/elgehelge/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-09T11:29:34Z", "updated_at": "2018-06-09T11:29:34Z", "author_association": "NONE", "body_html": "<p>Thanks for getting back <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1184671\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiejw\">@xiejw</a> . This is not about getting it to work for me - I have no problem with that. This is about reporting an issue to help improving TensorFlow and help other people not banging their heads agains the wall.</p>\n<p>Please disregard <code>BATCH_SIZE</code>. It was removed in my process of simplifying the example, but apparently I forgot to move the the definition of this. I have removed this line from the example.</p>\n<p>I guess the root cause of the supposed inconsistency is whether training is stopped when based on the dataset repeat's <code>OutOfRangeError</code> or whether it is based on <code>train_spec.max_steps</code>. On one machine it stops when <code>OutOfRangeError</code> is reached, on another machine it re-initialises the dataset after getting the <code>OutOfRangeError</code> and continues to run until <code>train_spec.max_steps</code>.</p>\n<p>The question is whether this is a feature or a bug?</p>\n<p>It is true that the docstring recommends using only <code>train_spec.max_steps</code>, however, this is with distributed training in mind, which this issue is not about.</p>\n<p>If you still think this is the desired behaviour, feel free to close the issue.</p>", "body_text": "Thanks for getting back @xiejw . This is not about getting it to work for me - I have no problem with that. This is about reporting an issue to help improving TensorFlow and help other people not banging their heads agains the wall.\nPlease disregard BATCH_SIZE. It was removed in my process of simplifying the example, but apparently I forgot to move the the definition of this. I have removed this line from the example.\nI guess the root cause of the supposed inconsistency is whether training is stopped when based on the dataset repeat's OutOfRangeError or whether it is based on train_spec.max_steps. On one machine it stops when OutOfRangeError is reached, on another machine it re-initialises the dataset after getting the OutOfRangeError and continues to run until train_spec.max_steps.\nThe question is whether this is a feature or a bug?\nIt is true that the docstring recommends using only train_spec.max_steps, however, this is with distributed training in mind, which this issue is not about.\nIf you still think this is the desired behaviour, feel free to close the issue.", "body": "Thanks for getting back @xiejw . This is not about getting it to work for me - I have no problem with that. This is about reporting an issue to help improving TensorFlow and help other people not banging their heads agains the wall.\r\n\r\nPlease disregard `BATCH_SIZE`. It was removed in my process of simplifying the example, but apparently I forgot to move the the definition of this. I have removed this line from the example.\r\n\r\nI guess the root cause of the supposed inconsistency is whether training is stopped when based on the dataset repeat's `OutOfRangeError` or whether it is based on `train_spec.max_steps`. On one machine it stops when `OutOfRangeError` is reached, on another machine it re-initialises the dataset after getting the `OutOfRangeError` and continues to run until `train_spec.max_steps`.\r\n\r\nThe question is whether this is a feature or a bug?\r\n\r\nIt is true that the docstring recommends using only `train_spec.max_steps`, however, this is with distributed training in mind, which this issue is not about.\r\n\r\nIf you still think this is the desired behaviour, feel free to close the issue.\r\n\r\n"}