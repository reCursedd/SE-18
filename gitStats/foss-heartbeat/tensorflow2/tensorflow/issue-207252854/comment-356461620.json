{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/356461620", "html_url": "https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-356461620", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7469", "id": 356461620, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjQ2MTYyMA==", "user": {"login": "studentSam0000", "id": 34502974, "node_id": "MDQ6VXNlcjM0NTAyOTc0", "avatar_url": "https://avatars0.githubusercontent.com/u/34502974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/studentSam0000", "html_url": "https://github.com/studentSam0000", "followers_url": "https://api.github.com/users/studentSam0000/followers", "following_url": "https://api.github.com/users/studentSam0000/following{/other_user}", "gists_url": "https://api.github.com/users/studentSam0000/gists{/gist_id}", "starred_url": "https://api.github.com/users/studentSam0000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/studentSam0000/subscriptions", "organizations_url": "https://api.github.com/users/studentSam0000/orgs", "repos_url": "https://api.github.com/users/studentSam0000/repos", "events_url": "https://api.github.com/users/studentSam0000/events{/privacy}", "received_events_url": "https://api.github.com/users/studentSam0000/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-10T00:42:02Z", "updated_at": "2018-01-10T00:42:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8534653\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soloice\">@soloice</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=51059\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cancan101\">@cancan101</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25676211\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tasx0823\">@tasx0823</a> .... Thank you for the lead. Using <code>create_train_op</code> is giving something very close to the validation performance I was expecting. :)</p>\n<p>Btw this is also explained in the documentation :</p>\n<blockquote>\n<p>By default, slim.learning.create_train_op includes all update ops that are<br>\npart of the <code>tf.GraphKeys.UPDATE_OPS</code> collection. Additionally, TF-Slim's<br>\nslim.batch_norm function adds the moving mean and moving variance updates to<br>\nthis collection. Consequently, users who want to use slim.batch_norm will not<br>\nneed to take any additional steps in order to have the moving mean and moving<br>\nvariance updates be computed.</p>\n</blockquote>\n<p>However, I still have two blocks as <code>resnet_v1_50</code> and  <code>resnet_v1_50_1</code> in my TensorBoard visualization. Is this due to the distinct operators in the <code>BatchNorm</code> layer at train and validation times?<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/34502974/34750354-c6aa92f4-f5fa-11e7-83b2-93366223bc19.png\"><img src=\"https://user-images.githubusercontent.com/34502974/34750354-c6aa92f4-f5fa-11e7-83b2-93366223bc19.png\" alt=\"updated graph\" style=\"max-width:100%;\"></a></p>", "body_text": "@soloice @cancan101 @tasx0823 .... Thank you for the lead. Using create_train_op is giving something very close to the validation performance I was expecting. :)\nBtw this is also explained in the documentation :\n\nBy default, slim.learning.create_train_op includes all update ops that are\npart of the tf.GraphKeys.UPDATE_OPS collection. Additionally, TF-Slim's\nslim.batch_norm function adds the moving mean and moving variance updates to\nthis collection. Consequently, users who want to use slim.batch_norm will not\nneed to take any additional steps in order to have the moving mean and moving\nvariance updates be computed.\n\nHowever, I still have two blocks as resnet_v1_50 and  resnet_v1_50_1 in my TensorBoard visualization. Is this due to the distinct operators in the BatchNorm layer at train and validation times?", "body": "@soloice @cancan101 @tasx0823 .... Thank you for the lead. Using `create_train_op` is giving something very close to the validation performance I was expecting. :)\r\n\r\nBtw this is also explained in the documentation : \r\n\r\n> By default, slim.learning.create_train_op includes all update ops that are\r\n> part of the `tf.GraphKeys.UPDATE_OPS` collection. Additionally, TF-Slim's\r\n> slim.batch_norm function adds the moving mean and moving variance updates to\r\n> this collection. Consequently, users who want to use slim.batch_norm will not\r\n> need to take any additional steps in order to have the moving mean and moving\r\n> variance updates be computed. \r\n\r\nHowever, I still have two blocks as `resnet_v1_50` and  `resnet_v1_50_1` in my TensorBoard visualization. Is this due to the distinct operators in the `BatchNorm` layer at train and validation times?\r\n![updated graph](https://user-images.githubusercontent.com/34502974/34750354-c6aa92f4-f5fa-11e7-83b2-93366223bc19.png)\r\n\r\n\r\n\r\n\r\n\r\n"}