{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295680231", "html_url": "https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-295680231", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7469", "id": 295680231, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTY4MDIzMQ==", "user": {"login": "jacky841102", "id": 7688697, "node_id": "MDQ6VXNlcjc2ODg2OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/7688697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacky841102", "html_url": "https://github.com/jacky841102", "followers_url": "https://api.github.com/users/jacky841102/followers", "following_url": "https://api.github.com/users/jacky841102/following{/other_user}", "gists_url": "https://api.github.com/users/jacky841102/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacky841102/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacky841102/subscriptions", "organizations_url": "https://api.github.com/users/jacky841102/orgs", "repos_url": "https://api.github.com/users/jacky841102/repos", "events_url": "https://api.github.com/users/jacky841102/events{/privacy}", "received_events_url": "https://api.github.com/users/jacky841102/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-20T10:51:18Z", "updated_at": "2017-04-20T10:51:18Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8534653\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soloice\">@soloice</a></p>\n<p>I also met similar problem as yours while using <code>slim.batch_norm</code>, and solved by following</p>\n<blockquote>\n<p><strong>Another important thing is</strong>, be sure to use slim.learning.create_train_op to create train op. Do not use tf native tf.train.GradientDescentOptimizer(0.1).minimize(loss).</p>\n</blockquote>\n<p>Thanks a lot! However, do you know the reason why we need to use <code>slim.create_train_op</code> instead of native <code>tf.train.GradientDescentOptimizer(0.1).minimize(loss)</code>?</p>", "body_text": "Hi @soloice\nI also met similar problem as yours while using slim.batch_norm, and solved by following\n\nAnother important thing is, be sure to use slim.learning.create_train_op to create train op. Do not use tf native tf.train.GradientDescentOptimizer(0.1).minimize(loss).\n\nThanks a lot! However, do you know the reason why we need to use slim.create_train_op instead of native tf.train.GradientDescentOptimizer(0.1).minimize(loss)?", "body": "Hi @soloice \r\n\r\nI also met similar problem as yours while using `slim.batch_norm`, and solved by following \r\n\r\n> **Another important thing is**, be sure to use slim.learning.create_train_op to create train op. Do not use tf native tf.train.GradientDescentOptimizer(0.1).minimize(loss).\r\n\r\nThanks a lot! However, do you know the reason why we need to use `slim.create_train_op` instead of native `tf.train.GradientDescentOptimizer(0.1).minimize(loss)`? "}