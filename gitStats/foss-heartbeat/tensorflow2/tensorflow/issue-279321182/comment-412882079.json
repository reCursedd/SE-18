{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412882079", "html_url": "https://github.com/tensorflow/tensorflow/issues/15122#issuecomment-412882079", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15122", "id": 412882079, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjg4MjA3OQ==", "user": {"login": "gaojingwen945", "id": 9261703, "node_id": "MDQ6VXNlcjkyNjE3MDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/9261703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaojingwen945", "html_url": "https://github.com/gaojingwen945", "followers_url": "https://api.github.com/users/gaojingwen945/followers", "following_url": "https://api.github.com/users/gaojingwen945/following{/other_user}", "gists_url": "https://api.github.com/users/gaojingwen945/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaojingwen945/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaojingwen945/subscriptions", "organizations_url": "https://api.github.com/users/gaojingwen945/orgs", "repos_url": "https://api.github.com/users/gaojingwen945/repos", "events_url": "https://api.github.com/users/gaojingwen945/events{/privacy}", "received_events_url": "https://api.github.com/users/gaojingwen945/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-14T14:01:13Z", "updated_at": "2018-08-15T06:56:57Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25754898\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrehentz\">@andrehentz</a> <strong>Sadly the approach you provided (as quoted in the end of this post) in the former comment does not work for me here...</strong></p>\n<p>I retrained my mobilenet_v1_1.0_224_quantized model, and then running with the following command, and it still reports the same error message as posted in the original question. It IS driving me crazy. Do you have any other ideas about this?</p>\n<p>Here's my toco command, where retrained_graph.pb is my retrained model <strong>without freeze</strong> (also, a frozen model after freeze_graph does not work as well, which by the way, really confuses me that <strong>is freeze_graph necessary for converting to tflite?</strong>):</p>\n<p><code>toco \\ --graph_def_file=output_dir/retrained_graph.pb \\ --output_file=output_dir/optimized_graph.tflite \\ --input_format=TENSORFLOW_GRAPHDEF \\ --output_format=TFLITE \\ --inference_type=QUANTIZED_UINT8 \\ --inference_input_type=QUANTIZED_UINT8 \\ --input_array=input \\ --input_shape=1,224,224,3 \\ --output_array=final_result \\ --mean_value=128 \\ --std_dev_values=128 \\ --default_ranges_min=0 \\ --default_ranges_max=6 \\ --logtostderr '--v=2'</code></p>\n<blockquote>\n<p>While full quantized training is still in the works, retraining an existing quantized mobilenet (currently only mobilenet_1.0_224_quantized) should work. You can follow the step in TensorFlow for Poets which I reproduce (slightly modified) here:</p>\n<p>ARCHITECTURE=mobilenet_1.0_224_quantized<br>\nDATA_DIR=~/tensorflow-for-poets-2/tf_files<br>\nTRAINING_DIR=/tmp/tf_files</p>\n<p>python tensorflow/tensorflow/examples/image_retraining/retrain.py \\<br>\n--bottleneck_dir=$TRAINING_DIR/bottlenecks \\<br>\n--how_many_training_steps=500 \\<br>\n--model_dir=$TRAINING_DIR/models \\<br>\n--summaries_dir=$TRAINING_DIR/training_summaries/\"${ARCHITECTURE}\" \\<br>\n--output_graph=$TRAINING_DIR/retrained_graph.pb \\<br>\n--output_labels=$TRAINING_DIR/retrained_labels.txt \\<br>\n--architecture=\"${ARCHITECTURE}\" \\<br>\n--image_dir=$DATA_DIR/flower_photos</p>\n<p>rm -f /$TRAINING_DIR/${ARCHITECTURE}.tflite</p>\n<p>tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\<br>\n--input_file=$TRAINING_DIR/retrained_graph.pb \\<br>\n--input_format=TENSORFLOW_GRAPHDEF \\<br>\n--output_format=TFLITE \\<br>\n--output_file=/$TRAINING_DIR/${ARCHITECTURE}.tflite \\<br>\n--inference_type=QUANTIZED_UINT8 \\<br>\n--input_array=Placeholder \\<br>\n--output_array=final_result \\<br>\n--input_shape=1,224,224,3 \\<br>\n--mean_value=128 \\<br>\n--std_value=128</p>\n<p>That should create two files:</p>\n<p>/tmp/tf_files/mobilenet_1.0_224_quantized.tflite<br>\n/tmp/tf_files/retrained_labels.txt</p>\n<p>which you can use in the original demo app.</p>\n<p>For floating-point inference the link given by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10347096\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ecrasy\">@ecrasy</a> should work.</p>\n</blockquote>", "body_text": "@andrehentz Sadly the approach you provided (as quoted in the end of this post) in the former comment does not work for me here...\nI retrained my mobilenet_v1_1.0_224_quantized model, and then running with the following command, and it still reports the same error message as posted in the original question. It IS driving me crazy. Do you have any other ideas about this?\nHere's my toco command, where retrained_graph.pb is my retrained model without freeze (also, a frozen model after freeze_graph does not work as well, which by the way, really confuses me that is freeze_graph necessary for converting to tflite?):\ntoco \\ --graph_def_file=output_dir/retrained_graph.pb \\ --output_file=output_dir/optimized_graph.tflite \\ --input_format=TENSORFLOW_GRAPHDEF \\ --output_format=TFLITE \\ --inference_type=QUANTIZED_UINT8 \\ --inference_input_type=QUANTIZED_UINT8 \\ --input_array=input \\ --input_shape=1,224,224,3 \\ --output_array=final_result \\ --mean_value=128 \\ --std_dev_values=128 \\ --default_ranges_min=0 \\ --default_ranges_max=6 \\ --logtostderr '--v=2'\n\nWhile full quantized training is still in the works, retraining an existing quantized mobilenet (currently only mobilenet_1.0_224_quantized) should work. You can follow the step in TensorFlow for Poets which I reproduce (slightly modified) here:\nARCHITECTURE=mobilenet_1.0_224_quantized\nDATA_DIR=~/tensorflow-for-poets-2/tf_files\nTRAINING_DIR=/tmp/tf_files\npython tensorflow/tensorflow/examples/image_retraining/retrain.py \\\n--bottleneck_dir=$TRAINING_DIR/bottlenecks \\\n--how_many_training_steps=500 \\\n--model_dir=$TRAINING_DIR/models \\\n--summaries_dir=$TRAINING_DIR/training_summaries/\"${ARCHITECTURE}\" \\\n--output_graph=$TRAINING_DIR/retrained_graph.pb \\\n--output_labels=$TRAINING_DIR/retrained_labels.txt \\\n--architecture=\"${ARCHITECTURE}\" \\\n--image_dir=$DATA_DIR/flower_photos\nrm -f /$TRAINING_DIR/${ARCHITECTURE}.tflite\ntensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\\n--input_file=$TRAINING_DIR/retrained_graph.pb \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--output_file=/$TRAINING_DIR/${ARCHITECTURE}.tflite \\\n--inference_type=QUANTIZED_UINT8 \\\n--input_array=Placeholder \\\n--output_array=final_result \\\n--input_shape=1,224,224,3 \\\n--mean_value=128 \\\n--std_value=128\nThat should create two files:\n/tmp/tf_files/mobilenet_1.0_224_quantized.tflite\n/tmp/tf_files/retrained_labels.txt\nwhich you can use in the original demo app.\nFor floating-point inference the link given by @ecrasy should work.", "body": "@andrehentz **Sadly the approach you provided (as quoted in the end of this post) in the former comment does not work for me here...**\r\n\r\nI retrained my mobilenet_v1_1.0_224_quantized model, and then running with the following command, and it still reports the same error message as posted in the original question. It IS driving me crazy. Do you have any other ideas about this?\r\n\r\nHere's my toco command, where retrained_graph.pb is my retrained model **without freeze** (also, a frozen model after freeze_graph does not work as well, which by the way, really confuses me that **is freeze_graph necessary for converting to tflite?**):\r\n\r\n`toco \\\r\n  --graph_def_file=output_dir/retrained_graph.pb \\\r\n  --output_file=output_dir/optimized_graph.tflite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --inference_input_type=QUANTIZED_UINT8 \\\r\n  --input_array=input \\\r\n  --input_shape=1,224,224,3 \\\r\n  --output_array=final_result \\\r\n  --mean_value=128 \\\r\n  --std_dev_values=128 \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6 \\\r\n  --logtostderr '--v=2'`\r\n\r\n> While full quantized training is still in the works, retraining an existing quantized mobilenet (currently only mobilenet_1.0_224_quantized) should work. You can follow the step in TensorFlow for Poets which I reproduce (slightly modified) here:\r\n> \r\n> ARCHITECTURE=mobilenet_1.0_224_quantized                                                           \r\n> DATA_DIR=~/tensorflow-for-poets-2/tf_files                                                         \r\n> TRAINING_DIR=/tmp/tf_files                                                                         \r\n>                                                                                                    \r\n> python tensorflow/tensorflow/examples/image_retraining/retrain.py \\                                \r\n>   --bottleneck_dir=$TRAINING_DIR/bottlenecks \\                                                     \r\n>   --how_many_training_steps=500 \\                                                                  \r\n>   --model_dir=$TRAINING_DIR/models \\                                                               \r\n>   --summaries_dir=$TRAINING_DIR/training_summaries/\"${ARCHITECTURE}\" \\                             \r\n>   --output_graph=$TRAINING_DIR/retrained_graph.pb \\                                                \r\n>   --output_labels=$TRAINING_DIR/retrained_labels.txt \\                                             \r\n>   --architecture=\"${ARCHITECTURE}\" \\                                                               \r\n>   --image_dir=$DATA_DIR/flower_photos  \r\n> \r\n> rm -f /$TRAINING_DIR/${ARCHITECTURE}.tflite                              \r\n>                         \r\n> tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\                                           \r\n>   --input_file=$TRAINING_DIR/retrained_graph.pb \\                                                  \r\n>   --input_format=TENSORFLOW_GRAPHDEF \\                                                             \r\n>   --output_format=TFLITE \\                                                                         \r\n>   --output_file=/$TRAINING_DIR/${ARCHITECTURE}.tflite \\                                            \r\n>   --inference_type=QUANTIZED_UINT8 \\                                                               \r\n>   --input_array=Placeholder \\                                                                      \r\n>   --output_array=final_result \\                                                                    \r\n>   --input_shape=1,224,224,3 \\                                                                      \r\n>   --mean_value=128 \\                                                                               \r\n>   --std_value=128                                                                                  \r\n> \r\n> That should create two files:\r\n> \r\n> /tmp/tf_files/mobilenet_1.0_224_quantized.tflite\r\n> /tmp/tf_files/retrained_labels.txt\r\n> \r\n> which you can use in the original demo app.\r\n> \r\n> For floating-point inference the link given by @ecrasy should work.\r\n"}