{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350246056", "html_url": "https://github.com/tensorflow/tensorflow/issues/15122#issuecomment-350246056", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15122", "id": 350246056, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDI0NjA1Ng==", "user": {"login": "imxboards", "id": 11689850, "node_id": "MDQ6VXNlcjExNjg5ODUw", "avatar_url": "https://avatars3.githubusercontent.com/u/11689850?v=4", "gravatar_id": "", "url": "https://api.github.com/users/imxboards", "html_url": "https://github.com/imxboards", "followers_url": "https://api.github.com/users/imxboards/followers", "following_url": "https://api.github.com/users/imxboards/following{/other_user}", "gists_url": "https://api.github.com/users/imxboards/gists{/gist_id}", "starred_url": "https://api.github.com/users/imxboards/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/imxboards/subscriptions", "organizations_url": "https://api.github.com/users/imxboards/orgs", "repos_url": "https://api.github.com/users/imxboards/repos", "events_url": "https://api.github.com/users/imxboards/events{/privacy}", "received_events_url": "https://api.github.com/users/imxboards/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-08T11:54:16Z", "updated_at": "2017-12-08T11:54:16Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25754898\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrehentz\">@andrehentz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=326106\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/aselle\">@aselle</a><br>\nI face one problem like below,<br>\nI retain my modes ,and test in pc:<br>\nubuntu@ip-172-31-27-248:~/tensorflow$ python tensorflow/examples/label_image/label_image.py \\</p>\n<blockquote>\n<p>--graph=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb <br>\n--labels=/home/ubuntu/vegetables_train/vegetables_out/labels.txt <br>\n--image=/home/ubuntu/test_photos/3.jpg <br>\n--input_layer=input <br>\n--output_layer=final_result <br>\n--input_mean=128 <br>\n--input_std=128 <br>\n--input_width=224 <br>\n--input_height=224<br>\nxi hong shi 0.99971<br>\nxi qin 0.000140324<br>\nhu luo bo 6.89621e-05<br>\nshang hai qing 3.10927e-05<br>\njian jiao 2.14989e-05<br>\nthe reusult is very nice!</p>\n</blockquote>\n<p>but after I quant the model with:<br>\nbazel-bin/tensorflow/contrib/lite/toco/toco <br>\n--input_format=TENSORFLOW_GRAPHDEF <br>\n--input_file=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb <br>\n--output_format=TFLITE <br>\n--output_file=/home/ubuntu/vegetables_train/vegetables_out/mobilenet_quant_v1_224.tflite <br>\n--input_shapes=1,224,224,3 <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--inference_input_type=QUANTIZED_UINT8 <br>\n--input_arrays=input <br>\n--output_arrays=final_result <br>\n--default_ranges_min=0 <br>\n--default_ranges_max=6 <br>\n--mean_values=128 <br>\n--std_values=128<br>\nput the mobilenet_quant_v1_224.tflite into TfLiteCameraDemo.apk , run TfLiteCameraDemo.apk,it's very very diffcult to  recognition the vegetables,<br>\nI think this because quant to UINT8.<br>\nAnd now I will try FLOAT model ,My question is:How to modify TfLiteCameraDemo app code to support FLOAT lite mode?<br>\npls help!</p>", "body_text": "@andrehentz @aselle\nI face one problem like below,\nI retain my modes ,and test in pc:\nubuntu@ip-172-31-27-248:~/tensorflow$ python tensorflow/examples/label_image/label_image.py \\\n\n--graph=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb \n--labels=/home/ubuntu/vegetables_train/vegetables_out/labels.txt \n--image=/home/ubuntu/test_photos/3.jpg \n--input_layer=input \n--output_layer=final_result \n--input_mean=128 \n--input_std=128 \n--input_width=224 \n--input_height=224\nxi hong shi 0.99971\nxi qin 0.000140324\nhu luo bo 6.89621e-05\nshang hai qing 3.10927e-05\njian jiao 2.14989e-05\nthe reusult is very nice!\n\nbut after I quant the model with:\nbazel-bin/tensorflow/contrib/lite/toco/toco \n--input_format=TENSORFLOW_GRAPHDEF \n--input_file=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb \n--output_format=TFLITE \n--output_file=/home/ubuntu/vegetables_train/vegetables_out/mobilenet_quant_v1_224.tflite \n--input_shapes=1,224,224,3 \n--inference_type=QUANTIZED_UINT8 \n--inference_input_type=QUANTIZED_UINT8 \n--input_arrays=input \n--output_arrays=final_result \n--default_ranges_min=0 \n--default_ranges_max=6 \n--mean_values=128 \n--std_values=128\nput the mobilenet_quant_v1_224.tflite into TfLiteCameraDemo.apk , run TfLiteCameraDemo.apk,it's very very diffcult to  recognition the vegetables,\nI think this because quant to UINT8.\nAnd now I will try FLOAT model ,My question is:How to modify TfLiteCameraDemo app code to support FLOAT lite mode?\npls help!", "body": "@andrehentz @aselle \r\nI face one problem like below,\r\nI retain my modes ,and test in pc:\r\nubuntu@ip-172-31-27-248:~/tensorflow$ python tensorflow/examples/label_image/label_image.py \\\r\n>   --graph=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb \\\r\n>   --labels=/home/ubuntu/vegetables_train/vegetables_out/labels.txt \\\r\n>   --image=/home/ubuntu/test_photos/3.jpg \\\r\n>   --input_layer=input \\\r\n>   --output_layer=final_result \\\r\n>   --input_mean=128 \\\r\n>   --input_std=128 \\\r\n>   --input_width=224 \\\r\n>   --input_height=224\r\nxi hong shi 0.99971\r\nxi qin 0.000140324\r\nhu luo bo 6.89621e-05\r\nshang hai qing 3.10927e-05\r\njian jiao 2.14989e-05\r\nthe reusult is very nice!\r\n\r\n\r\nbut after I quant the model with:\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --input_file=/home/ubuntu/vegetables_train/vegetables_out/vegetables.pb \\\r\n  --output_format=TFLITE \\\r\n  --output_file=/home/ubuntu/vegetables_train/vegetables_out/mobilenet_quant_v1_224.tflite \\\r\n  --input_shapes=1,224,224,3 \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --inference_input_type=QUANTIZED_UINT8 \\\r\n  --input_arrays=input \\\r\n  --output_arrays=final_result \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6 \\\r\n  --mean_values=128 \\\r\n  --std_values=128\r\nput the mobilenet_quant_v1_224.tflite into TfLiteCameraDemo.apk , run TfLiteCameraDemo.apk,it's very very diffcult to  recognition the vegetables,\r\nI think this because quant to UINT8.\r\nAnd now I will try FLOAT model ,My question is:How to modify TfLiteCameraDemo app code to support FLOAT lite mode?\r\npls help!"}