{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/298069753", "html_url": "https://github.com/tensorflow/tensorflow/issues/9487#issuecomment-298069753", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9487", "id": 298069753, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODA2OTc1Mw==", "user": {"login": "sedghi", "id": 7490180, "node_id": "MDQ6VXNlcjc0OTAxODA=", "avatar_url": "https://avatars0.githubusercontent.com/u/7490180?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sedghi", "html_url": "https://github.com/sedghi", "followers_url": "https://api.github.com/users/sedghi/followers", "following_url": "https://api.github.com/users/sedghi/following{/other_user}", "gists_url": "https://api.github.com/users/sedghi/gists{/gist_id}", "starred_url": "https://api.github.com/users/sedghi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sedghi/subscriptions", "organizations_url": "https://api.github.com/users/sedghi/orgs", "repos_url": "https://api.github.com/users/sedghi/repos", "events_url": "https://api.github.com/users/sedghi/events{/privacy}", "received_events_url": "https://api.github.com/users/sedghi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-28T18:16:05Z", "updated_at": "2017-04-28T18:16:05Z", "author_association": "NONE", "body_html": "<p>thanks for the reply, here is my memory usage (free memory available in time)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/7490180/25541440/ab076890-2c1c-11e7-932d-bbe868453f35.png\"><img src=\"https://cloud.githubusercontent.com/assets/7490180/25541440/ab076890-2c1c-11e7-932d-bbe868453f35.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>I noticed those plateaus are when it reaches the last epoch number in the current training and moves to another training with different sets of parameters ( as i said earlier I'm doing a parameter search ), I'm wondering why it cannot free the memory after it reaches the end of the training and then moves to the next training (with different parameter sets).</p>", "body_text": "thanks for the reply, here is my memory usage (free memory available in time)\n\nI noticed those plateaus are when it reaches the last epoch number in the current training and moves to another training with different sets of parameters ( as i said earlier I'm doing a parameter search ), I'm wondering why it cannot free the memory after it reaches the end of the training and then moves to the next training (with different parameter sets).", "body": "thanks for the reply, here is my memory usage (free memory available in time) \r\n\r\n![image](https://cloud.githubusercontent.com/assets/7490180/25541440/ab076890-2c1c-11e7-932d-bbe868453f35.png)\r\n\r\nI noticed those plateaus are when it reaches the last epoch number in the current training and moves to another training with different sets of parameters ( as i said earlier I'm doing a parameter search ), I'm wondering why it cannot free the memory after it reaches the end of the training and then moves to the next training (with different parameter sets). "}