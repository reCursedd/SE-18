{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19241", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19241/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19241/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19241/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19241", "id": 322485922, "node_id": "MDU6SXNzdWUzMjI0ODU5MjI=", "number": 19241, "title": "[Eager] Fix for determining input / output shape of the model prior to Model.fit()", "user": {"login": "titu1994", "id": 3048602, "node_id": "MDQ6VXNlcjMwNDg2MDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3048602?v=4", "gravatar_id": "", "url": "https://api.github.com/users/titu1994", "html_url": "https://github.com/titu1994", "followers_url": "https://api.github.com/users/titu1994/followers", "following_url": "https://api.github.com/users/titu1994/following{/other_user}", "gists_url": "https://api.github.com/users/titu1994/gists{/gist_id}", "starred_url": "https://api.github.com/users/titu1994/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/titu1994/subscriptions", "organizations_url": "https://api.github.com/users/titu1994/orgs", "repos_url": "https://api.github.com/users/titu1994/repos", "events_url": "https://api.github.com/users/titu1994/events{/privacy}", "received_events_url": "https://api.github.com/users/titu1994/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "anj-s", "id": 32556631, "node_id": "MDQ6VXNlcjMyNTU2NjMx", "avatar_url": "https://avatars1.githubusercontent.com/u/32556631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anj-s", "html_url": "https://github.com/anj-s", "followers_url": "https://api.github.com/users/anj-s/followers", "following_url": "https://api.github.com/users/anj-s/following{/other_user}", "gists_url": "https://api.github.com/users/anj-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/anj-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anj-s/subscriptions", "organizations_url": "https://api.github.com/users/anj-s/orgs", "repos_url": "https://api.github.com/users/anj-s/repos", "events_url": "https://api.github.com/users/anj-s/events{/privacy}", "received_events_url": "https://api.github.com/users/anj-s/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "anj-s", "id": 32556631, "node_id": "MDQ6VXNlcjMyNTU2NjMx", "avatar_url": "https://avatars1.githubusercontent.com/u/32556631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anj-s", "html_url": "https://github.com/anj-s", "followers_url": "https://api.github.com/users/anj-s/followers", "following_url": "https://api.github.com/users/anj-s/following{/other_user}", "gists_url": "https://api.github.com/users/anj-s/gists{/gist_id}", "starred_url": "https://api.github.com/users/anj-s/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anj-s/subscriptions", "organizations_url": "https://api.github.com/users/anj-s/orgs", "repos_url": "https://api.github.com/users/anj-s/repos", "events_url": "https://api.github.com/users/anj-s/events{/privacy}", "received_events_url": "https://api.github.com/users/anj-s/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-12T05:59:41Z", "updated_at": "2018-11-14T19:18:11Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10 Home Edition</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Windows binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: Github version 'v1.8.0-0-g93bc2e2072' 1.8.0TF (GPU)</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0 / cuDNN 7.0.5</li>\n<li><strong>GPU model and memory</strong>: NVIDIA GTX 980M</li>\n<li><strong>Exact command to reproduce</strong>: Provided below as a standalone script</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>The issue is that in Eager mode, the two attributes of the Model subclass, <code>inputs</code> and <code>outputs</code> is undetermined until the first call to <code>Model.fit(...)</code>.</p>\n<p>When attempting to determine this prior to fitting the model, in the script at location <strong>tensorflow/python/keras/_impl/keras/engine/training.py</strong>, the entire input dataset <code>X</code> (passed to .fit(...)) is provided as the input <code>x</code> in Line 684 <code>if not self.inputs: self._set_inputs(x)</code> inside <code>_standardize_user_data</code>.</p>\n<p>Due to this, in eager execution mode, this call is deferred to <code>_eager_set_inputs(inputs)</code>. Here, <code>inputs</code> is the entire dataset numpy matrix / tensor, and a <code>Model.call(inputs)</code> is performed at line 909.</p>\n<p>Since the entire dataset is unable to fit in GPU memory for smaller GPU devices, it causes an OOM error.</p>\n<p>However, to determine the input / output shape/s of a model, a single sample tensor is sufficient.</p>\n<p>The below fix shows that the solution is adequate, and can be implemented by simply extracting a single sample of the entire dataset to determine the input / output shape/s of a model during eager execution.</p>\n<p>**Note : **<br>\nIn order to provide indicators to identify where the error occurs, I modified the above mentioned script to print 2 logs to the console, to describe the shape of the \"inputs\" parameter inside <code>_eager_set_inputs(inputs)</code>. The lines <code>Inside training._eager_set_inputs ...</code> and <code>***** Providing entire dataset into call *****</code> are the above logs.</p>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.keras.datasets <span class=\"pl-k\">import</span> mnist\n<span class=\"pl-k\">from</span> tensorflow.contrib.eager.python <span class=\"pl-k\">import</span> tfe\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> enable eager mode</span>\ntf.enable_eager_execution()\ntf.set_random_seed(<span class=\"pl-c1\">0</span>)\nnp.random.seed(<span class=\"pl-c1\">0</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> constants</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>\nepochs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\nnum_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> dataset loading</span>\n(x_train, y_train), (x_test, y_test) <span class=\"pl-k\">=</span> mnist.load_data()\nx_train <span class=\"pl-k\">=</span> x_train.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nx_test <span class=\"pl-k\">=</span> x_test.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nx_train <span class=\"pl-k\">=</span> x_train.reshape((<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>))\nx_test <span class=\"pl-k\">=</span> x_test.reshape((<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one hot encode the labels. convert back to numpy as we cannot use a combination of numpy</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> and tensors as input to keras</span>\ny_train_ohe <span class=\"pl-k\">=</span> tf.one_hot(y_train, <span class=\"pl-v\">depth</span><span class=\"pl-k\">=</span>num_classes).numpy()\ny_test_ohe <span class=\"pl-k\">=</span> tf.one_hot(y_test, <span class=\"pl-v\">depth</span><span class=\"pl-k\">=</span>num_classes).numpy()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x train<span class=\"pl-pds\">'</span></span>, x_train.shape)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>y train<span class=\"pl-pds\">'</span></span>, y_train_ohe.shape)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x test<span class=\"pl-pds\">'</span></span>, x_test.shape)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>y test<span class=\"pl-pds\">'</span></span>, y_test_ohe.shape)\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">CNN</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">keras</span>.<span class=\"pl-e\">Model</span>):\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">num_classes</span>):\n        <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">CNN</span>, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n\n        <span class=\"pl-c1\">self</span>.cnn1 <span class=\"pl-k\">=</span> tf.keras.layers.Conv2D(<span class=\"pl-c1\">16</span>, (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))\n        <span class=\"pl-c1\">self</span>.bn1 <span class=\"pl-k\">=</span> tf.keras.layers.BatchNormalization()\n        <span class=\"pl-c1\">self</span>.cnn2 <span class=\"pl-k\">=</span> tf.keras.layers.Conv2D(<span class=\"pl-c1\">32</span>, (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))\n        <span class=\"pl-c1\">self</span>.bn2 <span class=\"pl-k\">=</span> tf.keras.layers.BatchNormalization()\n        <span class=\"pl-c1\">self</span>.pool <span class=\"pl-k\">=</span> tf.keras.layers.GlobalAveragePooling2D()\n        <span class=\"pl-c1\">self</span>.classifier <span class=\"pl-k\">=</span> tf.keras.layers.Dense(num_classes)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">mask</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Used to print out the input shape of the entire dataset prior to training loop</span>\n        <span class=\"pl-c1\">print</span>(inputs.shape)\n\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.cnn1(inputs)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.bn1(x)\n        x <span class=\"pl-k\">=</span> tf.nn.relu(x)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> layer 1</span>\n        x <span class=\"pl-k\">=</span> tf.nn.relu(<span class=\"pl-c1\">self</span>.bn2(<span class=\"pl-c1\">self</span>.cnn2(x))) <span class=\"pl-c\"><span class=\"pl-c\">#</span> layer 2</span>\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.pool(x)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.classifier(x)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> softmax op does not exist on the gpu, so always use cpu</span>\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n            output <span class=\"pl-k\">=</span> tf.nn.softmax(output)\n\n        <span class=\"pl-k\">return</span> output\n\n\ndevice <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">if</span> tfe.num_gpus() <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>\n\n<span class=\"pl-k\">with</span> tf.device(device):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> build model and optimizer</span>\n    model <span class=\"pl-k\">=</span> CNN(num_classes)\n    model.compile(<span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span>tf.train.AdamOptimizer(<span class=\"pl-c1\">0.001</span>), <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>categorical_crossentropy<span class=\"pl-pds\">'</span></span>,\n                  <span class=\"pl-v\">metrics</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>accuracy<span class=\"pl-pds\">'</span></span>])\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> suggested fix ; can be incorporated inside `_eager_set_inputs` or `_set_input`</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Fix = Use exactly one sample from the provided input dataset to determine </span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> input/output shape/s for the model</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> dummy_x = np.zeros((1, 28, 28, 1))</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> model._set_inputs(dummy_x)</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> train</span>\n    model.fit(x_train, y_train_ohe, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span>epochs,\n              <span class=\"pl-v\">validation_data</span><span class=\"pl-k\">=</span>(x_test, y_test_ohe), <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> evaluate on test set</span>\n    scores <span class=\"pl-k\">=</span> model.evaluate(x_test, y_test_ohe, batch_size, <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Final test loss and accuracy :<span class=\"pl-pds\">\"</span></span>, scores)\n</pre></div>\n<p>Truncated log without the fix : (Only tensor allocation summary dump after OOM is truncated)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">44.208127</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.385242</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: </span>\nname: GeForce <span class=\"pl-c1\">GTX</span> <span class=\"pl-ii\">980M</span> major: <span class=\"pl-c1\">5</span> minor: <span class=\"pl-c1\">2</span> memoryClockRate(GHz): <span class=\"pl-c1\">1.1265</span>\npciBusID: <span class=\"pl-c1\">0000</span>:<span class=\"pl-c1\">0<span class=\"pl-ii\">1</span></span>:<span class=\"pl-c1\">00.0</span>\ntotalMemory: <span class=\"pl-c1\">4.</span><span class=\"pl-ii\">00GiB</span> freeMemory: <span class=\"pl-c1\">3.</span><span class=\"pl-ii\">32GiB</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.385822</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.838116</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.838626</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 </span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.838912</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N </span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">45.839762</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)</span>\nx train (<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\ny train (<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">10</span>)\nx test (<span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\ny test (<span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">10</span>)\n\nInside training._eager_set_inputs ip shape<span class=\"pl-k\">/</span>s [(<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)]  <span class=\"pl-k\">&lt;=</span> Here the <span class=\"pl-c1\">input</span> <span class=\"pl-k\">is</span> the entire dataset\n<span class=\"pl-k\">*****</span> Providing entire dataset into call <span class=\"pl-k\">*****</span>\n(<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">58.125845</span>: W T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 717.77MiB.  Current allocation summary follows.</span>\n\n<span class=\"pl-k\">&lt;&lt;</span><span class=\"pl-k\">&lt;</span> Truncated <span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span>\n\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">22</span>:<span class=\"pl-c1\">58.229153</span>: W T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at fused_batch_norm_op.cc:263 : Resource exhausted: OOM when allocating tensor with shape[60000,16,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc</span>\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">83</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    validation_data<span class=\"pl-k\">=</span>(x_test, y_test_ohe), verbose<span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\engine<span class=\"pl-cce\">\\t</span>raining.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1147</span>, <span class=\"pl-k\">in</span> fit\n    batch_size<span class=\"pl-k\">=</span>batch_size)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\engine<span class=\"pl-cce\">\\t</span>raining.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">685</span>, <span class=\"pl-k\">in</span> _standardize_user_data\n    <span class=\"pl-c1\">self</span>._set_inputs(x)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\engine<span class=\"pl-cce\">\\t</span>raining.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">871</span>, <span class=\"pl-k\">in</span> _set_inputs\n    <span class=\"pl-c1\">self</span>._eager_set_inputs(inputs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\engine<span class=\"pl-cce\">\\t</span>raining.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">914</span>, <span class=\"pl-k\">in</span> _eager_set_inputs\n    ops.convert_to_tensor(inputs, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>K.floatx()))\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">55</span>, <span class=\"pl-k\">in</span> call\n    x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.bn1(x)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\engine<span class=\"pl-cce\">\\b</span>ase_layer.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">314</span>, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>\n    output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">super</span>(Layer, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__call__</span>(inputs, <span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\layers<span class=\"pl-cce\">\\b</span>ase.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">717</span>, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>\n    outputs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.call(inputs, <span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\keras\\_impl\\keras\\layers<span class=\"pl-cce\">\\n</span>ormalization.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">113</span>, <span class=\"pl-k\">in</span> call\n    output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">super</span>(BatchNormalization, <span class=\"pl-c1\">self</span>).call(inputs, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>training)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\layers<span class=\"pl-cce\">\\n</span>ormalization.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">501</span>, <span class=\"pl-k\">in</span> call\n    outputs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._fused_batch_norm(inputs, <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>training)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\layers<span class=\"pl-cce\">\\n</span>ormalization.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">396</span>, <span class=\"pl-k\">in</span> _fused_batch_norm\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\layers\\utils.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">206</span>, <span class=\"pl-k\">in</span> smart_cond\n    pred, true_fn<span class=\"pl-k\">=</span>true_fn, false_fn<span class=\"pl-k\">=</span>false_fn, name<span class=\"pl-k\">=</span>name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python<span class=\"pl-cce\">\\f</span>ramework\\smart_cond.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">56</span>, <span class=\"pl-k\">in</span> smart_cond\n    <span class=\"pl-k\">return</span> false_fn()\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\layers<span class=\"pl-cce\">\\n</span>ormalization.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">393</span>, <span class=\"pl-k\">in</span> _fused_batch_norm_inference\n    data_format<span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._data_format)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\ops<span class=\"pl-cce\">\\n</span>n_impl.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">904</span>, <span class=\"pl-k\">in</span> fused_batch_norm\n    name<span class=\"pl-k\">=</span>name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>D:\\Users\\Yue\\Anaconda3\\lib\\site-packages<span class=\"pl-cce\">\\t</span>ensorflow\\python\\ops\\gen_nn_ops.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">3804</span>, <span class=\"pl-k\">in</span> _fused_batch_norm\n    _six.raise_from(_core._status_to_exception(e.code, message), <span class=\"pl-c1\">None</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;string&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">3</span>, <span class=\"pl-k\">in</span> raise_from\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: <span class=\"pl-c1\">OOM</span> when allocating tensor <span class=\"pl-k\">with</span> shape[<span class=\"pl-c1\">60000</span>,<span class=\"pl-c1\">16</span>,<span class=\"pl-c1\">14</span>,<span class=\"pl-c1\">14</span>] <span class=\"pl-k\">and</span> <span class=\"pl-c1\">type</span> <span class=\"pl-c1\">float</span> on <span class=\"pl-k\">/</span>job:localhost<span class=\"pl-k\">/</span>replica:<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>task:<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>device:<span class=\"pl-c1\">GPU</span>:<span class=\"pl-c1\">0</span> by allocator <span class=\"pl-c1\">GPU_0_bfc</span> [Op:FusedBatchNorm]\n</pre></div>\n<p>Partial log with the aforementioned fix</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">23.607020</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">24.748056</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: </span>\nname: GeForce <span class=\"pl-c1\">GTX</span> <span class=\"pl-ii\">980M</span> major: <span class=\"pl-c1\">5</span> minor: <span class=\"pl-c1\">2</span> memoryClockRate(GHz): <span class=\"pl-c1\">1.1265</span>\npciBusID: <span class=\"pl-c1\">0000</span>:<span class=\"pl-c1\">0<span class=\"pl-ii\">1</span></span>:<span class=\"pl-c1\">00.0</span>\ntotalMemory: <span class=\"pl-c1\">4.</span><span class=\"pl-ii\">00GiB</span> freeMemory: <span class=\"pl-c1\">3.</span><span class=\"pl-ii\">32GiB</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">24.748771</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">25.196921</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:</span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">25.197231</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 </span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">25.197570</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N </span>\n<span class=\"pl-c1\">2018</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">12</span> <span class=\"pl-c1\">00</span>:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">25.197993</span>: I T:\\<span class=\"pl-ii\">src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)</span>\nx train (<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\ny train (<span class=\"pl-c1\">60000</span>, <span class=\"pl-c1\">10</span>)\nx test (<span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\ny test (<span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">10</span>)\n\nInside training._eager_set_inputs ip shape<span class=\"pl-k\">/</span>s [(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)]  <span class=\"pl-k\">&lt;=</span> Here the <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>dataset<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">is</span> the dummy batch\n<span class=\"pl-k\">*****</span> Providing entire dataset into call <span class=\"pl-k\">*****</span>\n(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n\nTrain on <span class=\"pl-c1\">60000</span> samples, validate on <span class=\"pl-c1\">10000</span> samples\nEpoch <span class=\"pl-c1\">1</span><span class=\"pl-k\">/</span><span class=\"pl-c1\">10</span>\n(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>)\n<span class=\"pl-c1\">...</span> repeated <span class=\"pl-k\">for</span> the entire training loop over the batch.</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home Edition\nTensorFlow installed from (source or binary): Windows binary\nTensorFlow version (use command below): Github version 'v1.8.0-0-g93bc2e2072' 1.8.0TF (GPU)\nPython version: 3.5\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA 9.0 / cuDNN 7.0.5\nGPU model and memory: NVIDIA GTX 980M\nExact command to reproduce: Provided below as a standalone script\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nThe issue is that in Eager mode, the two attributes of the Model subclass, inputs and outputs is undetermined until the first call to Model.fit(...).\nWhen attempting to determine this prior to fitting the model, in the script at location tensorflow/python/keras/_impl/keras/engine/training.py, the entire input dataset X (passed to .fit(...)) is provided as the input x in Line 684 if not self.inputs: self._set_inputs(x) inside _standardize_user_data.\nDue to this, in eager execution mode, this call is deferred to _eager_set_inputs(inputs). Here, inputs is the entire dataset numpy matrix / tensor, and a Model.call(inputs) is performed at line 909.\nSince the entire dataset is unable to fit in GPU memory for smaller GPU devices, it causes an OOM error.\nHowever, to determine the input / output shape/s of a model, a single sample tensor is sufficient.\nThe below fix shows that the solution is adequate, and can be implemented by simply extracting a single sample of the entire dataset to determine the input / output shape/s of a model during eager execution.\n**Note : **\nIn order to provide indicators to identify where the error occurs, I modified the above mentioned script to print 2 logs to the console, to describe the shape of the \"inputs\" parameter inside _eager_set_inputs(inputs). The lines Inside training._eager_set_inputs ... and ***** Providing entire dataset into call ***** are the above logs.\nSource code / logs\nimport os\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.datasets import mnist\nfrom tensorflow.contrib.eager.python import tfe\n\n# enable eager mode\ntf.enable_eager_execution()\ntf.set_random_seed(0)\nnp.random.seed(0)\n\n# constants\nbatch_size = 128\nepochs = 10\nnum_classes = 10\n\n# dataset loading\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((-1, 28, 28, 1))\nx_test = x_test.reshape((-1, 28, 28, 1))\n\n# one hot encode the labels. convert back to numpy as we cannot use a combination of numpy\n# and tensors as input to keras\ny_train_ohe = tf.one_hot(y_train, depth=num_classes).numpy()\ny_test_ohe = tf.one_hot(y_test, depth=num_classes).numpy()\n\nprint('x train', x_train.shape)\nprint('y train', y_train_ohe.shape)\nprint('x test', x_test.shape)\nprint('y test', y_test_ohe.shape)\n\nclass CNN(tf.keras.Model):\n\n    def __init__(self, num_classes):\n        super(CNN, self).__init__()\n\n        self.cnn1 = tf.keras.layers.Conv2D(16, (5, 5), padding='same', strides=(2, 2))\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.cnn2 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', strides=(2, 2))\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.classifier = tf.keras.layers.Dense(num_classes)\n\n    def call(self, inputs, training=None, mask=None):\n        # Used to print out the input shape of the entire dataset prior to training loop\n        print(inputs.shape)\n\n        x = self.cnn1(inputs)\n        x = self.bn1(x)\n        x = tf.nn.relu(x)  # layer 1\n        x = tf.nn.relu(self.bn2(self.cnn2(x))) # layer 2\n        x = self.pool(x)\n        output = self.classifier(x)\n\n        # softmax op does not exist on the gpu, so always use cpu\n        with tf.device('/cpu:0'):\n            output = tf.nn.softmax(output)\n\n        return output\n\n\ndevice = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n\nwith tf.device(device):\n    # build model and optimizer\n    model = CNN(num_classes)\n    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    # suggested fix ; can be incorporated inside `_eager_set_inputs` or `_set_input`\n    # Fix = Use exactly one sample from the provided input dataset to determine \n    # input/output shape/s for the model\n\n    # dummy_x = np.zeros((1, 28, 28, 1))\n    # model._set_inputs(dummy_x)\n\n    # train\n    model.fit(x_train, y_train_ohe, batch_size=batch_size, epochs=epochs,\n              validation_data=(x_test, y_test_ohe), verbose=2)\n\n    # evaluate on test set\n    scores = model.evaluate(x_test, y_test_ohe, batch_size, verbose=2)\n    print(\"Final test loss and accuracy :\", scores)\n\nTruncated log without the fix : (Only tensor allocation summary dump after OOM is truncated)\n2018-05-12 00:22:44.208127: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-05-12 00:22:45.385242: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 3.32GiB\n2018-05-12 00:22:45.385822: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-05-12 00:22:45.838116: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-12 00:22:45.838626: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \n2018-05-12 00:22:45.838912: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \n2018-05-12 00:22:45.839762: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\nx train (60000, 28, 28, 1)\ny train (60000, 10)\nx test (10000, 28, 28, 1)\ny test (10000, 10)\n\nInside training._eager_set_inputs ip shape/s [(60000, 28, 28, 1)]  <= Here the input is the entire dataset\n***** Providing entire dataset into call *****\n(60000, 28, 28, 1)\n\n2018-05-12 00:22:58.125845: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 717.77MiB.  Current allocation summary follows.\n\n<<< Truncated >>>\n\n2018-05-12 00:22:58.229153: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at fused_batch_norm_op.cc:263 : Resource exhausted: OOM when allocating tensor with shape[60000,16,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\nTraceback (most recent call last):\n  File \"D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py\", line 83, in <module>\n    validation_data=(x_test, y_test_ohe), verbose=2)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 1147, in fit\n    batch_size=batch_size)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 685, in _standardize_user_data\n    self._set_inputs(x)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 871, in _set_inputs\n    self._eager_set_inputs(inputs)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 914, in _eager_set_inputs\n    ops.convert_to_tensor(inputs, dtype=K.floatx()))\n  File \"D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py\", line 55, in call\n    x = self.bn1(x)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\", line 314, in __call__\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 717, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\normalization.py\", line 113, in call\n    output = super(BatchNormalization, self).call(inputs, training=training)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 501, in call\n    outputs = self._fused_batch_norm(inputs, training=training)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 396, in _fused_batch_norm\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 206, in smart_cond\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 56, in smart_cond\n    return false_fn()\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 393, in _fused_batch_norm_inference\n    data_format=self._data_format)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 904, in fused_batch_norm\n    name=name)\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3804, in _fused_batch_norm\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\n  File \"<string>\", line 3, in raise_from\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[60000,16,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNorm]\n\nPartial log with the aforementioned fix\n2018-05-12 00:27:23.607020: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-05-12 00:27:24.748056: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \nname: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 3.32GiB\n2018-05-12 00:27:24.748771: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-05-12 00:27:25.196921: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-12 00:27:25.197231: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \n2018-05-12 00:27:25.197570: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \n2018-05-12 00:27:25.197993: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\nx train (60000, 28, 28, 1)\ny train (60000, 10)\nx test (10000, 28, 28, 1)\ny test (10000, 10)\n\nInside training._eager_set_inputs ip shape/s [(1, 28, 28, 1)]  <= Here the \"dataset\" is the dummy batch\n***** Providing entire dataset into call *****\n(1, 28, 28, 1)\n\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n(128, 28, 28, 1)\n(128, 28, 28, 1)\n(128, 28, 28, 1)\n(128, 28, 28, 1)\n(128, 28, 28, 1)\n... repeated for the entire training loop over the batch.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Home Edition\r\n- **TensorFlow installed from (source or binary)**: Windows binary\r\n- **TensorFlow version (use command below)**: Github version 'v1.8.0-0-g93bc2e2072' 1.8.0TF (GPU) \r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.0.5\r\n- **GPU model and memory**: NVIDIA GTX 980M\r\n- **Exact command to reproduce**: Provided below as a standalone script\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nThe issue is that in Eager mode, the two attributes of the Model subclass, `inputs` and `outputs` is undetermined until the first call to `Model.fit(...)`.\r\n\r\nWhen attempting to determine this prior to fitting the model, in the script at location **tensorflow/python/keras/_impl/keras/engine/training.py**, the entire input dataset `X` (passed to .fit(...)) is provided as the input `x` in Line 684 `if not self.inputs: self._set_inputs(x)` inside `_standardize_user_data`.\r\n\r\nDue to this, in eager execution mode, this call is deferred to `_eager_set_inputs(inputs)`. Here, `inputs` is the entire dataset numpy matrix / tensor, and a `Model.call(inputs)` is performed at line 909. \r\n\r\nSince the entire dataset is unable to fit in GPU memory for smaller GPU devices, it causes an OOM error.\r\n\r\nHowever, to determine the input / output shape/s of a model, a single sample tensor is sufficient.\r\n\r\nThe below fix shows that the solution is adequate, and can be implemented by simply extracting a single sample of the entire dataset to determine the input / output shape/s of a model during eager execution.\r\n\r\n**Note : **\r\nIn order to provide indicators to identify where the error occurs, I modified the above mentioned script to print 2 logs to the console, to describe the shape of the \"inputs\" parameter inside `_eager_set_inputs(inputs)`. The lines `Inside training._eager_set_inputs ...` and `***** Providing entire dataset into call *****` are the above logs.\r\n\r\n### Source code / logs\r\n\r\n```python\r\nimport os\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.datasets import mnist\r\nfrom tensorflow.contrib.eager.python import tfe\r\n\r\n# enable eager mode\r\ntf.enable_eager_execution()\r\ntf.set_random_seed(0)\r\nnp.random.seed(0)\r\n\r\n# constants\r\nbatch_size = 128\r\nepochs = 10\r\nnum_classes = 10\r\n\r\n# dataset loading\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train.astype('float32') / 255.\r\nx_test = x_test.astype('float32') / 255.\r\nx_train = x_train.reshape((-1, 28, 28, 1))\r\nx_test = x_test.reshape((-1, 28, 28, 1))\r\n\r\n# one hot encode the labels. convert back to numpy as we cannot use a combination of numpy\r\n# and tensors as input to keras\r\ny_train_ohe = tf.one_hot(y_train, depth=num_classes).numpy()\r\ny_test_ohe = tf.one_hot(y_test, depth=num_classes).numpy()\r\n\r\nprint('x train', x_train.shape)\r\nprint('y train', y_train_ohe.shape)\r\nprint('x test', x_test.shape)\r\nprint('y test', y_test_ohe.shape)\r\n\r\nclass CNN(tf.keras.Model):\r\n\r\n    def __init__(self, num_classes):\r\n        super(CNN, self).__init__()\r\n\r\n        self.cnn1 = tf.keras.layers.Conv2D(16, (5, 5), padding='same', strides=(2, 2))\r\n        self.bn1 = tf.keras.layers.BatchNormalization()\r\n        self.cnn2 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', strides=(2, 2))\r\n        self.bn2 = tf.keras.layers.BatchNormalization()\r\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\r\n        self.classifier = tf.keras.layers.Dense(num_classes)\r\n\r\n    def call(self, inputs, training=None, mask=None):\r\n        # Used to print out the input shape of the entire dataset prior to training loop\r\n        print(inputs.shape)\r\n\r\n        x = self.cnn1(inputs)\r\n        x = self.bn1(x)\r\n        x = tf.nn.relu(x)  # layer 1\r\n        x = tf.nn.relu(self.bn2(self.cnn2(x))) # layer 2\r\n        x = self.pool(x)\r\n        output = self.classifier(x)\r\n\r\n        # softmax op does not exist on the gpu, so always use cpu\r\n        with tf.device('/cpu:0'):\r\n            output = tf.nn.softmax(output)\r\n\r\n        return output\r\n\r\n\r\ndevice = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\r\n\r\nwith tf.device(device):\r\n    # build model and optimizer\r\n    model = CNN(num_classes)\r\n    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\n    \r\n    # suggested fix ; can be incorporated inside `_eager_set_inputs` or `_set_input`\r\n    # Fix = Use exactly one sample from the provided input dataset to determine \r\n    # input/output shape/s for the model\r\n\r\n    # dummy_x = np.zeros((1, 28, 28, 1))\r\n    # model._set_inputs(dummy_x)\r\n\r\n    # train\r\n    model.fit(x_train, y_train_ohe, batch_size=batch_size, epochs=epochs,\r\n              validation_data=(x_test, y_test_ohe), verbose=2)\r\n\r\n    # evaluate on test set\r\n    scores = model.evaluate(x_test, y_test_ohe, batch_size, verbose=2)\r\n    print(\"Final test loss and accuracy :\", scores)\r\n\r\n```\r\n\r\nTruncated log without the fix : (Only tensor allocation summary dump after OOM is truncated)\r\n```python\r\n2018-05-12 00:22:44.208127: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-05-12 00:22:45.385242: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \r\nname: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.32GiB\r\n2018-05-12 00:22:45.385822: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-05-12 00:22:45.838116: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-12 00:22:45.838626: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \r\n2018-05-12 00:22:45.838912: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \r\n2018-05-12 00:22:45.839762: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\r\nx train (60000, 28, 28, 1)\r\ny train (60000, 10)\r\nx test (10000, 28, 28, 1)\r\ny test (10000, 10)\r\n\r\nInside training._eager_set_inputs ip shape/s [(60000, 28, 28, 1)]  <= Here the input is the entire dataset\r\n***** Providing entire dataset into call *****\r\n(60000, 28, 28, 1)\r\n\r\n2018-05-12 00:22:58.125845: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 717.77MiB.  Current allocation summary follows.\r\n\r\n<<< Truncated >>>\r\n\r\n2018-05-12 00:22:58.229153: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at fused_batch_norm_op.cc:263 : Resource exhausted: OOM when allocating tensor with shape[60000,16,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py\", line 83, in <module>\r\n    validation_data=(x_test, y_test_ohe), verbose=2)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 1147, in fit\r\n    batch_size=batch_size)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 685, in _standardize_user_data\r\n    self._set_inputs(x)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 871, in _set_inputs\r\n    self._eager_set_inputs(inputs)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 914, in _eager_set_inputs\r\n    ops.convert_to_tensor(inputs, dtype=K.floatx()))\r\n  File \"D:/Users/Yue/PycharmProjects/eager-tutorials/tutorials/04_cnn.py\", line 55, in call\r\n    x = self.bn1(x)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\", line 314, in __call__\r\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 717, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\normalization.py\", line 113, in call\r\n    output = super(BatchNormalization, self).call(inputs, training=training)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 501, in call\r\n    outputs = self._fused_batch_norm(inputs, training=training)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 396, in _fused_batch_norm\r\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\", line 206, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\", line 56, in smart_cond\r\n    return false_fn()\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\", line 393, in _fused_batch_norm_inference\r\n    data_format=self._data_format)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 904, in fused_batch_norm\r\n    name=name)\r\n  File \"D:\\Users\\Yue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3804, in _fused_batch_norm\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[60000,16,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNorm]\r\n\r\n```\r\n\r\nPartial log with the aforementioned fix\r\n```python\r\n2018-05-12 00:27:23.607020: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-05-12 00:27:24.748056: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \r\nname: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.32GiB\r\n2018-05-12 00:27:24.748771: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-05-12 00:27:25.196921: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-12 00:27:25.197231: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \r\n2018-05-12 00:27:25.197570: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \r\n2018-05-12 00:27:25.197993: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\r\nx train (60000, 28, 28, 1)\r\ny train (60000, 10)\r\nx test (10000, 28, 28, 1)\r\ny test (10000, 10)\r\n\r\nInside training._eager_set_inputs ip shape/s [(1, 28, 28, 1)]  <= Here the \"dataset\" is the dummy batch\r\n***** Providing entire dataset into call *****\r\n(1, 28, 28, 1)\r\n\r\nTrain on 60000 samples, validate on 10000 samples\r\nEpoch 1/10\r\n(128, 28, 28, 1)\r\n(128, 28, 28, 1)\r\n(128, 28, 28, 1)\r\n(128, 28, 28, 1)\r\n(128, 28, 28, 1)\r\n... repeated for the entire training loop over the batch.\r\n```\r\n"}