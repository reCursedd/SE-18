{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335205533", "html_url": "https://github.com/tensorflow/tensorflow/issues/13355#issuecomment-335205533", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13355", "id": 335205533, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTIwNTUzMw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-09T16:12:11Z", "updated_at": "2017-10-09T16:12:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is definitely a bug, and it has to do with this line:</p>\n<pre><code>grad_source = _GetGradSource(grad)\n</code></pre>\n<p>the weird \"gradients\" prefix is there so that the TensorArray can differentiate between different calls to <code>tf.gradients</code>: each call to <code>tf.gradients</code> must create a separate gradient TensorArray.  The reason you're getting zeros is that your <code>gradients</code> name prefix is not the same name prefix created by <code>tf.gradients</code> (since <code>gradients</code> is already taken, it's probably creating a name prefix <code>gradients_1</code> - and this difference in prefix is confusing the TensorArray).</p>\n<p>Note that this will work:</p>\n<div class=\"highlight highlight-source-python\"><pre>tf.gradients(y, x, [[[<span class=\"pl-c1\">2.42</span>]]])</pre></div>\n<p>because the grad_ys [[[2.42]]] is converted to a tensor <em>inside</em> the tf.gradients, and will have the appropriate name scope.</p>\n<p>One solution might be to wrap all grad_ys going into <code>tf.gradients</code> in a <code>tf.identity</code> that brings them into the same gradient name scope.  Not sure it's the best solution.</p>", "body_text": "This is definitely a bug, and it has to do with this line:\ngrad_source = _GetGradSource(grad)\n\nthe weird \"gradients\" prefix is there so that the TensorArray can differentiate between different calls to tf.gradients: each call to tf.gradients must create a separate gradient TensorArray.  The reason you're getting zeros is that your gradients name prefix is not the same name prefix created by tf.gradients (since gradients is already taken, it's probably creating a name prefix gradients_1 - and this difference in prefix is confusing the TensorArray).\nNote that this will work:\ntf.gradients(y, x, [[[2.42]]])\nbecause the grad_ys [[[2.42]]] is converted to a tensor inside the tf.gradients, and will have the appropriate name scope.\nOne solution might be to wrap all grad_ys going into tf.gradients in a tf.identity that brings them into the same gradient name scope.  Not sure it's the best solution.", "body": "This is definitely a bug, and it has to do with this line:\r\n```\r\ngrad_source = _GetGradSource(grad)\r\n```\r\nthe weird \"gradients\" prefix is there so that the TensorArray can differentiate between different calls to `tf.gradients`: each call to `tf.gradients` must create a separate gradient TensorArray.  The reason you're getting zeros is that your `gradients` name prefix is not the same name prefix created by `tf.gradients` (since `gradients` is already taken, it's probably creating a name prefix `gradients_1` - and this difference in prefix is confusing the TensorArray).\r\n\r\nNote that this will work:\r\n```python\r\ntf.gradients(y, x, [[[2.42]]])\r\n```\r\nbecause the grad_ys [[[2.42]]] is converted to a tensor *inside* the tf.gradients, and will have the appropriate name scope.\r\n\r\nOne solution might be to wrap all grad_ys going into `tf.gradients` in a `tf.identity` that brings them into the same gradient name scope.  Not sure it's the best solution."}