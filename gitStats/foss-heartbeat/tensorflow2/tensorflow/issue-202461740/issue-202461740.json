{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7011", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7011/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7011/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7011/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7011", "id": 202461740, "node_id": "MDU6SXNzdWUyMDI0NjE3NDA=", "number": 7011, "title": "Is there any method to read HDFS file in a distributed way?", "user": {"login": "xzry6", "id": 9141722, "node_id": "MDQ6VXNlcjkxNDE3MjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9141722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xzry6", "html_url": "https://github.com/xzry6", "followers_url": "https://api.github.com/users/xzry6/followers", "following_url": "https://api.github.com/users/xzry6/following{/other_user}", "gists_url": "https://api.github.com/users/xzry6/gists{/gist_id}", "starred_url": "https://api.github.com/users/xzry6/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xzry6/subscriptions", "organizations_url": "https://api.github.com/users/xzry6/orgs", "repos_url": "https://api.github.com/users/xzry6/repos", "events_url": "https://api.github.com/users/xzry6/events{/privacy}", "received_events_url": "https://api.github.com/users/xzry6/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-01-23T07:18:58Z", "updated_at": "2018-10-17T03:15:15Z", "closed_at": "2017-01-23T23:35:30Z", "author_association": "NONE", "body_html": "<p>I'm working on reading hdfs file in between graph mode.<br>\nI used <code>tf.train.string_input_produce()</code> to read from hdfs and produce the input.</p>\n<p>However, I found that all the workers are reading the whole hdfs file every time fetching a batch.</p>\n<p>I'm wondering if it is a known issue or is there any way in TensorFlow that each worker could just read a part of the file like hadoop MapReduce?</p>", "body_text": "I'm working on reading hdfs file in between graph mode.\nI used tf.train.string_input_produce() to read from hdfs and produce the input.\nHowever, I found that all the workers are reading the whole hdfs file every time fetching a batch.\nI'm wondering if it is a known issue or is there any way in TensorFlow that each worker could just read a part of the file like hadoop MapReduce?", "body": "I'm working on reading hdfs file in between graph mode. \r\nI used `tf.train.string_input_produce()` to read from hdfs and produce the input.\r\n\r\nHowever, I found that all the workers are reading the whole hdfs file every time fetching a batch.\r\n\r\nI'm wondering if it is a known issue or is there any way in TensorFlow that each worker could just read a part of the file like hadoop MapReduce?"}