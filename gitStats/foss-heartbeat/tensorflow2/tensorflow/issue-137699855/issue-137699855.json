{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1350", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1350/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1350/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1350/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1350", "id": 137699855, "node_id": "MDU6SXNzdWUxMzc2OTk4NTU=", "number": 1350, "title": "nan gradients with low memory gpu", "user": {"login": "raingo", "id": 606565, "node_id": "MDQ6VXNlcjYwNjU2NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/606565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raingo", "html_url": "https://github.com/raingo", "followers_url": "https://api.github.com/users/raingo/followers", "following_url": "https://api.github.com/users/raingo/following{/other_user}", "gists_url": "https://api.github.com/users/raingo/gists{/gist_id}", "starred_url": "https://api.github.com/users/raingo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raingo/subscriptions", "organizations_url": "https://api.github.com/users/raingo/orgs", "repos_url": "https://api.github.com/users/raingo/repos", "events_url": "https://api.github.com/users/raingo/events{/privacy}", "received_events_url": "https://api.github.com/users/raingo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2016-03-01T22:03:24Z", "updated_at": "2016-04-26T15:55:17Z", "closed_at": "2016-03-02T00:49:14Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\n<code>3.12.9-201.fc19.x86_64 #1 SMP Wed Jan 29 15:44:35 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux</code></p>\n<p>GPU card info from <code>lspci -v | grep gtx -i</code></p>\n<pre><code>NVIDIA Corporation GK110 [GeForce GTX Titan] (rev a1)\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>pip package installed:<br>\n<code>https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl</code></li>\n<li>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".</li>\n</ol>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally                                                                             \n0.7.1                                                                        \n</code></pre>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>Increase batch size, so that you see the following warning message</li>\n<li>check the gradients, and there are <code>nan</code> values</li>\n<li>decrease batch size, and do the same check. Everything is normal if I don't see the following warning message</li>\n</ol>\n<h3>What have you tried?</h3>\n<ol>\n<li>reduce batch size</li>\n</ol>\n<h3>Logs or other output that would be helpful</h3>\n<pre><code>W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:131] Ran out of memory trying to allocate 1.85GiB. The caller indicates that this is not a failure, but may mean that th\nere could be performance gains if more memory is available.\n</code></pre>", "body_text": "Environment info\nOperating System:\n3.12.9-201.fc19.x86_64 #1 SMP Wed Jan 29 15:44:35 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\nGPU card info from lspci -v | grep gtx -i\nNVIDIA Corporation GK110 [GeForce GTX Titan] (rev a1)\n\nIf installed from binary pip package, provide:\n\npip package installed:\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally                                                                             \n0.7.1                                                                        \n\nSteps to reproduce\n\nIncrease batch size, so that you see the following warning message\ncheck the gradients, and there are nan values\ndecrease batch size, and do the same check. Everything is normal if I don't see the following warning message\n\nWhat have you tried?\n\nreduce batch size\n\nLogs or other output that would be helpful\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:131] Ran out of memory trying to allocate 1.85GiB. The caller indicates that this is not a failure, but may mean that th\nere could be performance gains if more memory is available.", "body": "### Environment info\n\nOperating System: \n`3.12.9-201.fc19.x86_64 #1 SMP Wed Jan 29 15:44:35 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux`\n\nGPU card info from `lspci -v | grep gtx -i`\n\n```\nNVIDIA Corporation GK110 [GeForce GTX Titan] (rev a1)\n```\n\nIf installed from binary pip package, provide:\n1. pip package installed:\n   `https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl`\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n```\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally                                                                              \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally                                                                             \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally                                                                             \n0.7.1                                                                        \n```\n### Steps to reproduce\n1. Increase batch size, so that you see the following warning message\n2. check the gradients, and there are `nan` values\n3. decrease batch size, and do the same check. Everything is normal if I don't see the following warning message\n### What have you tried?\n1. reduce batch size\n### Logs or other output that would be helpful\n\n```\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:131] Ran out of memory trying to allocate 1.85GiB. The caller indicates that this is not a failure, but may mean that th\nere could be performance gains if more memory is available.\n```\n"}