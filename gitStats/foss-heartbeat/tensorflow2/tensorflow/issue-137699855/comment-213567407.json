{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/213567407", "html_url": "https://github.com/tensorflow/tensorflow/issues/1350#issuecomment-213567407", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1350", "id": 213567407, "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzU2NzQwNw==", "user": {"login": "keskival", "id": 818358, "node_id": "MDQ6VXNlcjgxODM1OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/818358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keskival", "html_url": "https://github.com/keskival", "followers_url": "https://api.github.com/users/keskival/followers", "following_url": "https://api.github.com/users/keskival/following{/other_user}", "gists_url": "https://api.github.com/users/keskival/gists{/gist_id}", "starred_url": "https://api.github.com/users/keskival/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keskival/subscriptions", "organizations_url": "https://api.github.com/users/keskival/orgs", "repos_url": "https://api.github.com/users/keskival/repos", "events_url": "https://api.github.com/users/keskival/events{/privacy}", "received_events_url": "https://api.github.com/users/keskival/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-22T19:51:50Z", "updated_at": "2016-04-23T19:41:21Z", "author_association": "NONE", "body_html": "<p>I'm getting the same problem with the newest Tensorflow (0.8.0). For a bigger batch size I get NaN:s even when limiting gradients (could not reproduce with batch size of 1). Following the min and max of all learned variables does not show any explosions. Running the same program on CPU (CUDA_VISIBLE_DEVICES=\"\") does not give the NaNs.<br>\nIt might even have something to do with GPU memory allocation as updating to the newest Tensorflow started giving me out of memory errors, even if it worked without such errors with an older version.<br>\nI'm getting correct 3.0 from the above example, though.<br>\nI have a 4 GB NVidia GPU: NVIDIA Corporation GM204 [GeForce GTX 970](rev a1)</p>\n<p>Seems like the problem was solved by updating the kernel to the newest Ubuntu kernel, the CUDA, the CUDNN and the Tensorflow.</p>", "body_text": "I'm getting the same problem with the newest Tensorflow (0.8.0). For a bigger batch size I get NaN:s even when limiting gradients (could not reproduce with batch size of 1). Following the min and max of all learned variables does not show any explosions. Running the same program on CPU (CUDA_VISIBLE_DEVICES=\"\") does not give the NaNs.\nIt might even have something to do with GPU memory allocation as updating to the newest Tensorflow started giving me out of memory errors, even if it worked without such errors with an older version.\nI'm getting correct 3.0 from the above example, though.\nI have a 4 GB NVidia GPU: NVIDIA Corporation GM204 [GeForce GTX 970](rev a1)\nSeems like the problem was solved by updating the kernel to the newest Ubuntu kernel, the CUDA, the CUDNN and the Tensorflow.", "body": "I'm getting the same problem with the newest Tensorflow (0.8.0). For a bigger batch size I get NaN:s even when limiting gradients (could not reproduce with batch size of 1). Following the min and max of all learned variables does not show any explosions. Running the same program on CPU (CUDA_VISIBLE_DEVICES=\"\") does not give the NaNs.\nIt might even have something to do with GPU memory allocation as updating to the newest Tensorflow started giving me out of memory errors, even if it worked without such errors with an older version.\nI'm getting correct 3.0 from the above example, though.\nI have a 4 GB NVidia GPU: NVIDIA Corporation GM204 [GeForce GTX 970](rev a1)\n\nSeems like the problem was solved by updating the kernel to the newest Ubuntu kernel, the CUDA, the CUDNN and the Tensorflow.\n"}