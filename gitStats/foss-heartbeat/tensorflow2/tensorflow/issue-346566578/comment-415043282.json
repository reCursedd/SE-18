{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415043282", "html_url": "https://github.com/tensorflow/tensorflow/issues/21305#issuecomment-415043282", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21305", "id": 415043282, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTA0MzI4Mg==", "user": {"login": "wuciawe", "id": 6767527, "node_id": "MDQ6VXNlcjY3Njc1Mjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/6767527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wuciawe", "html_url": "https://github.com/wuciawe", "followers_url": "https://api.github.com/users/wuciawe/followers", "following_url": "https://api.github.com/users/wuciawe/following{/other_user}", "gists_url": "https://api.github.com/users/wuciawe/gists{/gist_id}", "starred_url": "https://api.github.com/users/wuciawe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wuciawe/subscriptions", "organizations_url": "https://api.github.com/users/wuciawe/orgs", "repos_url": "https://api.github.com/users/wuciawe/repos", "events_url": "https://api.github.com/users/wuciawe/events{/privacy}", "received_events_url": "https://api.github.com/users/wuciawe/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-22T14:04:20Z", "updated_at": "2018-08-23T10:27:19Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=144114\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rohan100jain\">@rohan100jain</a> I make a minimal example for linear regression. <strong>When the training data is on the local device, only the ps nodes not terminate. When the training data is on the hdfs, it is as what I described above.</strong></p>\n<p>To run the example locally:</p>\n<p>First, run <code>python gen_data.py</code> to generate data. Then, run</p>\n<p><code>python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=ps</code></p>\n<p><code>python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=chief</code></p>\n<p><code>python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=worker</code></p>\n<p><code>python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=evaluator</code></p>\n<p>the code is as follows:</p>\n<p>gen_data.py</p>\n<pre><code>import random\nimport tensorflow as tf\nimport os\n\nif __name__ == \"__main__\":\n    if not os.path.exists(os.path.join('.', 'data')):\n        os.makedirs(os.path.join('.', 'data'))\n    train_out = tf.python_io.TFRecordWriter('data/train.tfrecord')\n    for _ in range(10000):\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\n        y = 3 * x1 - 2 * x2 + 5 * x3\n        example = tf.train.Example(features=tf.train.Features(\n            feature={\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\n            }\n        ))\n        train_out.write(example.SerializeToString())\n    train_out.close()\n    test_out = tf.python_io.TFRecordWriter('data/test.tfrecord')\n    for _ in range(1000):\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\n        y = 3 * x1 - 2 * x2 + 5 * x3\n        example = tf.train.Example(features=tf.train.Features(\n            feature={\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\n            }\n        ))\n        test_out.write(example.SerializeToString())\n    test_out.close()\n\n</code></pre>\n<p>model.py</p>\n<pre><code>import tensorflow as tf\nimport os\nimport json\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string(\"ps_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"chief_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"job_name\", '', \"One of 'ps', 'worker', 'chief', 'evaluator'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\n\ndef input_fn(file_dir, num_epochs, num_workers=1, task_index=0):\n    def _parse_fn(record):\n        features = {\n            \"x\": tf.FixedLenFeature([3], tf.float32),\n            \"y\": tf.FixedLenFeature([1], tf.float32)\n        }\n        parsed = tf.parse_single_example(record, features)\n        label = parsed.pop(\"y\")\n        return parsed, label\n    dataset = tf.data.Dataset.list_files(file_dir, shuffle=False)\n    dataset = dataset.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, cycle_length=1))\n    dataset = dataset.map(_parse_fn, num_parallel_calls=32).prefetch(10)\n    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4, count=num_epochs))\n    if num_workers &gt; 1:\n        dataset = dataset.shard(num_workers, task_index)\n    dataset = dataset.batch(4)\n    iterator = dataset.make_one_shot_iterator()\n    batch_features, batch_labels = iterator.get_next()\n    return batch_features, batch_labels\n\n\ndef set_dist_env():\n    ps_hosts = FLAGS.ps_hosts.split(',')\n    chief_hosts = FLAGS.chief_hosts.split(',')\n    worker_hosts = FLAGS.worker_hosts.split(',')\n    task_index = FLAGS.task_index\n    job_name = FLAGS.job_name\n    tf_config = {\n        'cluster': {'chief': chief_hosts, 'worker': worker_hosts, 'ps': ps_hosts},\n        'task': {'type': job_name, 'index': task_index}\n    }\n    print(json.dumps(tf_config))\n    os.environ['TF_CONFIG'] = json.dumps(tf_config)\n\n\ndef model_fn(features, labels, mode, params=None):\n    x = features[\"x\"]\n    w = tf.get_variable(name='w', dtype=tf.float32, shape=[3, 1], initializer=tf.glorot_normal_initializer())\n    b = tf.get_variable(name='b', dtype=tf.float32, shape=[1], initializer=tf.constant_initializer(0.0))\n    pred = tf.add(b, tf.matmul(x, w))\n    predictions = {\"prediction\": pred}\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        export_outputs = {\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)\n        }\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)\n    error = tf.reduce_mean(tf.square(labels - pred))\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op = tf.train.GradientDescentOptimizer(0.001).minimize(error, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error, train_op=train_op)\n\n\ndef main(_):\n    tr_dir = 'data/train*'\n    va_dir = 'data/test*'\n    set_dist_env()\n    config = tf.estimator.RunConfig().replace(\n        session_config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 32}),\n        log_step_count_steps=10000,\n        save_summary_steps=10000,\n        save_checkpoints_steps=10000)\n    e = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"model\", params={}, config=config)\n    num_workers = len(FLAGS.worker_hosts.split(\",\")) + 1\n    worker_index = 0\n    if FLAGS.job_name == \"worker\":\n        worker_index = int(FLAGS.task_index) + 1\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(tr_dir, num_epochs=9999, num_workers=num_workers, task_index=worker_index), max_steps=200000)\n    feature_spec = {\n        \"x\": tf.FixedLenFeature([3], tf.float32),\n    }\n    serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n    exporters = tf.estimator.LatestExporter(\"linear\", serving_input_receiver_fn)\n    eval_spec = tf.estimator.EvalSpec(\n        input_fn=lambda: input_fn(va_dir, num_epochs=1),\n        steps=1000,\n        start_delay_secs=5,\n        throttle_secs=10,\n        exporters=exporters)\n    tf.estimator.train_and_evaluate(e, train_spec, eval_spec)\n\n\nif __name__ == \"__main__\":\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run()\n\n</code></pre>", "body_text": "@rohan100jain I make a minimal example for linear regression. When the training data is on the local device, only the ps nodes not terminate. When the training data is on the hdfs, it is as what I described above.\nTo run the example locally:\nFirst, run python gen_data.py to generate data. Then, run\npython model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=ps\npython model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=chief\npython model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=worker\npython model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=evaluator\nthe code is as follows:\ngen_data.py\nimport random\nimport tensorflow as tf\nimport os\n\nif __name__ == \"__main__\":\n    if not os.path.exists(os.path.join('.', 'data')):\n        os.makedirs(os.path.join('.', 'data'))\n    train_out = tf.python_io.TFRecordWriter('data/train.tfrecord')\n    for _ in range(10000):\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\n        y = 3 * x1 - 2 * x2 + 5 * x3\n        example = tf.train.Example(features=tf.train.Features(\n            feature={\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\n            }\n        ))\n        train_out.write(example.SerializeToString())\n    train_out.close()\n    test_out = tf.python_io.TFRecordWriter('data/test.tfrecord')\n    for _ in range(1000):\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\n        y = 3 * x1 - 2 * x2 + 5 * x3\n        example = tf.train.Example(features=tf.train.Features(\n            feature={\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\n            }\n        ))\n        test_out.write(example.SerializeToString())\n    test_out.close()\n\n\nmodel.py\nimport tensorflow as tf\nimport os\nimport json\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string(\"ps_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"chief_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", '', \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"job_name\", '', \"One of 'ps', 'worker', 'chief', 'evaluator'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\n\ndef input_fn(file_dir, num_epochs, num_workers=1, task_index=0):\n    def _parse_fn(record):\n        features = {\n            \"x\": tf.FixedLenFeature([3], tf.float32),\n            \"y\": tf.FixedLenFeature([1], tf.float32)\n        }\n        parsed = tf.parse_single_example(record, features)\n        label = parsed.pop(\"y\")\n        return parsed, label\n    dataset = tf.data.Dataset.list_files(file_dir, shuffle=False)\n    dataset = dataset.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, cycle_length=1))\n    dataset = dataset.map(_parse_fn, num_parallel_calls=32).prefetch(10)\n    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4, count=num_epochs))\n    if num_workers > 1:\n        dataset = dataset.shard(num_workers, task_index)\n    dataset = dataset.batch(4)\n    iterator = dataset.make_one_shot_iterator()\n    batch_features, batch_labels = iterator.get_next()\n    return batch_features, batch_labels\n\n\ndef set_dist_env():\n    ps_hosts = FLAGS.ps_hosts.split(',')\n    chief_hosts = FLAGS.chief_hosts.split(',')\n    worker_hosts = FLAGS.worker_hosts.split(',')\n    task_index = FLAGS.task_index\n    job_name = FLAGS.job_name\n    tf_config = {\n        'cluster': {'chief': chief_hosts, 'worker': worker_hosts, 'ps': ps_hosts},\n        'task': {'type': job_name, 'index': task_index}\n    }\n    print(json.dumps(tf_config))\n    os.environ['TF_CONFIG'] = json.dumps(tf_config)\n\n\ndef model_fn(features, labels, mode, params=None):\n    x = features[\"x\"]\n    w = tf.get_variable(name='w', dtype=tf.float32, shape=[3, 1], initializer=tf.glorot_normal_initializer())\n    b = tf.get_variable(name='b', dtype=tf.float32, shape=[1], initializer=tf.constant_initializer(0.0))\n    pred = tf.add(b, tf.matmul(x, w))\n    predictions = {\"prediction\": pred}\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        export_outputs = {\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)\n        }\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)\n    error = tf.reduce_mean(tf.square(labels - pred))\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        train_op = tf.train.GradientDescentOptimizer(0.001).minimize(error, global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error, train_op=train_op)\n\n\ndef main(_):\n    tr_dir = 'data/train*'\n    va_dir = 'data/test*'\n    set_dist_env()\n    config = tf.estimator.RunConfig().replace(\n        session_config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 32}),\n        log_step_count_steps=10000,\n        save_summary_steps=10000,\n        save_checkpoints_steps=10000)\n    e = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"model\", params={}, config=config)\n    num_workers = len(FLAGS.worker_hosts.split(\",\")) + 1\n    worker_index = 0\n    if FLAGS.job_name == \"worker\":\n        worker_index = int(FLAGS.task_index) + 1\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(tr_dir, num_epochs=9999, num_workers=num_workers, task_index=worker_index), max_steps=200000)\n    feature_spec = {\n        \"x\": tf.FixedLenFeature([3], tf.float32),\n    }\n    serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n    exporters = tf.estimator.LatestExporter(\"linear\", serving_input_receiver_fn)\n    eval_spec = tf.estimator.EvalSpec(\n        input_fn=lambda: input_fn(va_dir, num_epochs=1),\n        steps=1000,\n        start_delay_secs=5,\n        throttle_secs=10,\n        exporters=exporters)\n    tf.estimator.train_and_evaluate(e, train_spec, eval_spec)\n\n\nif __name__ == \"__main__\":\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run()", "body": "@rohan100jain I make a minimal example for linear regression. __When the training data is on the local device, only the ps nodes not terminate. When the training data is on the hdfs, it is as what I described above.__\r\n\r\nTo run the example locally:\r\n\r\nFirst, run `python gen_data.py` to generate data. Then, run \r\n\r\n`python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=ps`\r\n\r\n`python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=chief`\r\n\r\n`python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=worker`\r\n\r\n`python model.py --ps_hosts=127.0.0.1:2222 --chief_hosts=127.0.0.1:2223 --worker_hosts=127.0.0.1:2224 --task_index=0 --job_name=evaluator`\r\n\r\nthe code is as follows:\r\n\r\ngen_data.py\r\n```\r\nimport random\r\nimport tensorflow as tf\r\nimport os\r\n\r\nif __name__ == \"__main__\":\r\n    if not os.path.exists(os.path.join('.', 'data')):\r\n        os.makedirs(os.path.join('.', 'data'))\r\n    train_out = tf.python_io.TFRecordWriter('data/train.tfrecord')\r\n    for _ in range(10000):\r\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        y = 3 * x1 - 2 * x2 + 5 * x3\r\n        example = tf.train.Example(features=tf.train.Features(\r\n            feature={\r\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\r\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\r\n            }\r\n        ))\r\n        train_out.write(example.SerializeToString())\r\n    train_out.close()\r\n    test_out = tf.python_io.TFRecordWriter('data/test.tfrecord')\r\n    for _ in range(1000):\r\n        x1 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        x2 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        x3 = (random.randint(1, 10000) - 5000) / 10000.0\r\n        y = 3 * x1 - 2 * x2 + 5 * x3\r\n        example = tf.train.Example(features=tf.train.Features(\r\n            feature={\r\n                'x': tf.train.Feature(float_list=tf.train.FloatList(value=[x1, x2, x3])),\r\n                'y': tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\r\n            }\r\n        ))\r\n        test_out.write(example.SerializeToString())\r\n    test_out.close()\r\n\r\n```\r\n\r\nmodel.py\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport json\r\n\r\nFLAGS = tf.app.flags.FLAGS\r\ntf.app.flags.DEFINE_string(\"ps_hosts\", '', \"Comma-separated list of hostname:port pairs\")\r\ntf.app.flags.DEFINE_string(\"chief_hosts\", '', \"Comma-separated list of hostname:port pairs\")\r\ntf.app.flags.DEFINE_string(\"worker_hosts\", '', \"Comma-separated list of hostname:port pairs\")\r\ntf.app.flags.DEFINE_string(\"job_name\", '', \"One of 'ps', 'worker', 'chief', 'evaluator'\")\r\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\r\n\r\n\r\ndef input_fn(file_dir, num_epochs, num_workers=1, task_index=0):\r\n    def _parse_fn(record):\r\n        features = {\r\n            \"x\": tf.FixedLenFeature([3], tf.float32),\r\n            \"y\": tf.FixedLenFeature([1], tf.float32)\r\n        }\r\n        parsed = tf.parse_single_example(record, features)\r\n        label = parsed.pop(\"y\")\r\n        return parsed, label\r\n    dataset = tf.data.Dataset.list_files(file_dir, shuffle=False)\r\n    dataset = dataset.apply(tf.contrib.data.parallel_interleave(tf.data.TFRecordDataset, cycle_length=1))\r\n    dataset = dataset.map(_parse_fn, num_parallel_calls=32).prefetch(10)\r\n    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=4, count=num_epochs))\r\n    if num_workers > 1:\r\n        dataset = dataset.shard(num_workers, task_index)\r\n    dataset = dataset.batch(4)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    batch_features, batch_labels = iterator.get_next()\r\n    return batch_features, batch_labels\r\n\r\n\r\ndef set_dist_env():\r\n    ps_hosts = FLAGS.ps_hosts.split(',')\r\n    chief_hosts = FLAGS.chief_hosts.split(',')\r\n    worker_hosts = FLAGS.worker_hosts.split(',')\r\n    task_index = FLAGS.task_index\r\n    job_name = FLAGS.job_name\r\n    tf_config = {\r\n        'cluster': {'chief': chief_hosts, 'worker': worker_hosts, 'ps': ps_hosts},\r\n        'task': {'type': job_name, 'index': task_index}\r\n    }\r\n    print(json.dumps(tf_config))\r\n    os.environ['TF_CONFIG'] = json.dumps(tf_config)\r\n\r\n\r\ndef model_fn(features, labels, mode, params=None):\r\n    x = features[\"x\"]\r\n    w = tf.get_variable(name='w', dtype=tf.float32, shape=[3, 1], initializer=tf.glorot_normal_initializer())\r\n    b = tf.get_variable(name='b', dtype=tf.float32, shape=[1], initializer=tf.constant_initializer(0.0))\r\n    pred = tf.add(b, tf.matmul(x, w))\r\n    predictions = {\"prediction\": pred}\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        export_outputs = {\r\n            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)\r\n        }\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)\r\n    error = tf.reduce_mean(tf.square(labels - pred))\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error)\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        train_op = tf.train.GradientDescentOptimizer(0.001).minimize(error, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=error, train_op=train_op)\r\n\r\n\r\ndef main(_):\r\n    tr_dir = 'data/train*'\r\n    va_dir = 'data/test*'\r\n    set_dist_env()\r\n    config = tf.estimator.RunConfig().replace(\r\n        session_config=tf.ConfigProto(device_count={'GPU': 0, 'CPU': 32}),\r\n        log_step_count_steps=10000,\r\n        save_summary_steps=10000,\r\n        save_checkpoints_steps=10000)\r\n    e = tf.estimator.Estimator(model_fn=model_fn, model_dir=\"model\", params={}, config=config)\r\n    num_workers = len(FLAGS.worker_hosts.split(\",\")) + 1\r\n    worker_index = 0\r\n    if FLAGS.job_name == \"worker\":\r\n        worker_index = int(FLAGS.task_index) + 1\r\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(tr_dir, num_epochs=9999, num_workers=num_workers, task_index=worker_index), max_steps=200000)\r\n    feature_spec = {\r\n        \"x\": tf.FixedLenFeature([3], tf.float32),\r\n    }\r\n    serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n    exporters = tf.estimator.LatestExporter(\"linear\", serving_input_receiver_fn)\r\n    eval_spec = tf.estimator.EvalSpec(\r\n        input_fn=lambda: input_fn(va_dir, num_epochs=1),\r\n        steps=1000,\r\n        start_delay_secs=5,\r\n        throttle_secs=10,\r\n        exporters=exporters)\r\n    tf.estimator.train_and_evaluate(e, train_spec, eval_spec)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run()\r\n\r\n```"}