{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10659", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10659/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10659/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10659/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10659", "id": 235345162, "node_id": "MDU6SXNzdWUyMzUzNDUxNjI=", "number": 10659, "title": "seq2seq.dynamic_rnn_decoder not working for multilayered encoder in TF 1.0", "user": {"login": "adakum", "id": 26038604, "node_id": "MDQ6VXNlcjI2MDM4NjA0", "avatar_url": "https://avatars2.githubusercontent.com/u/26038604?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adakum", "html_url": "https://github.com/adakum", "followers_url": "https://api.github.com/users/adakum/followers", "following_url": "https://api.github.com/users/adakum/following{/other_user}", "gists_url": "https://api.github.com/users/adakum/gists{/gist_id}", "starred_url": "https://api.github.com/users/adakum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adakum/subscriptions", "organizations_url": "https://api.github.com/users/adakum/orgs", "repos_url": "https://api.github.com/users/adakum/repos", "events_url": "https://api.github.com/users/adakum/events{/privacy}", "received_events_url": "https://api.github.com/users/adakum/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-06-12T19:47:20Z", "updated_at": "2017-06-19T14:32:48Z", "closed_at": "2017-06-14T14:12:36Z", "author_association": "NONE", "body_html": "<p>I am trying to implement <strong>Multilayer Bidirectional Attention based seq2seq</strong> in <strong>TF 1.0</strong> using <code>**tf.contrib.seq2seq library**</code>.<br>\n<a href=\"https://github.com/adakum/seq2seq/blob/master/seq2seq_model.py\">This is my implementation.</a><br>\nIt works perfectly fine for single layered encoder and decoder but gives error with multi layer.</p>\n<p><code>Error : \"ValueError: Shape must be rank 2 but is rank 4 for 'Decoder/dynamic_rnn_decoder/Decoder/attention_decoder/concat' (op: 'ConcatV2') with input shapes: [?,10], [2,2,?,20], [].\"</code></p>\n<p>The problem is , when running single layer, the encoder just returns <strong>LSTM state tuple</strong>(for 1 layer) but in multi layer it returns an <strong>array of LSTMStateTuple(i.e. one for each layer.)</strong> which is fed into the decoder and creating problem I guess.</p>\n<p>So isn't <code>seq2seq.dynamic_rnn_decoder</code> made to work <code>MultiRNNCell  </code>, i.e. multilayered decoder ?</p>\n<p>Encoder part is running perfectly fine for multi layers and <strong>returning encoder states for each layer</strong>.</p>\n<p>**_If u want to run my implementation :</p>\n<ol>\n<li>clone repo</li>\n<li>switch to tf 1.0 env</li>\n<li>python generate_questions.py</li>\n</ol>\n<p>This will just create computation graph. In case of <code>num_layer=1</code>, graph is created is successfully but fails with <code>num_layer&gt;1</code>._**</p>", "body_text": "I am trying to implement Multilayer Bidirectional Attention based seq2seq in TF 1.0 using **tf.contrib.seq2seq library**.\nThis is my implementation.\nIt works perfectly fine for single layered encoder and decoder but gives error with multi layer.\nError : \"ValueError: Shape must be rank 2 but is rank 4 for 'Decoder/dynamic_rnn_decoder/Decoder/attention_decoder/concat' (op: 'ConcatV2') with input shapes: [?,10], [2,2,?,20], [].\"\nThe problem is , when running single layer, the encoder just returns LSTM state tuple(for 1 layer) but in multi layer it returns an array of LSTMStateTuple(i.e. one for each layer.) which is fed into the decoder and creating problem I guess.\nSo isn't seq2seq.dynamic_rnn_decoder made to work MultiRNNCell  , i.e. multilayered decoder ?\nEncoder part is running perfectly fine for multi layers and returning encoder states for each layer.\n**_If u want to run my implementation :\n\nclone repo\nswitch to tf 1.0 env\npython generate_questions.py\n\nThis will just create computation graph. In case of num_layer=1, graph is created is successfully but fails with num_layer>1._**", "body": "I am trying to implement **Multilayer Bidirectional Attention based seq2seq** in **TF 1.0** using `**tf.contrib.seq2seq library**`. \r\n[This is my implementation.](https://github.com/adakum/seq2seq/blob/master/seq2seq_model.py)\r\nIt works perfectly fine for single layered encoder and decoder but gives error with multi layer. \r\n\r\n`Error : \"ValueError: Shape must be rank 2 but is rank 4 for 'Decoder/dynamic_rnn_decoder/Decoder/attention_decoder/concat' (op: 'ConcatV2') with input shapes: [?,10], [2,2,?,20], [].\"`\r\n\r\nThe problem is , when running single layer, the encoder just returns **LSTM state tuple**(for 1 layer) but in multi layer it returns an **array of LSTMStateTuple(i.e. one for each layer.)** which is fed into the decoder and creating problem I guess. \r\n\r\nSo isn't `seq2seq.dynamic_rnn_decoder` made to work `MultiRNNCell  `, i.e. multilayered decoder ? \r\n\r\nEncoder part is running perfectly fine for multi layers and **returning encoder states for each layer**. \r\n\r\n**_If u want to run my implementation : \r\n1.\tclone repo\r\n2.\tswitch to tf 1.0 env\r\n3.\tpython generate_questions.py \r\n\r\nThis will just create computation graph. In case of `num_layer=1`, graph is created is successfully but fails with `num_layer>1`._**\r\n"}