{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14147", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14147/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14147/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14147/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14147", "id": 270207577, "node_id": "MDU6SXNzdWUyNzAyMDc1Nzc=", "number": 14147, "title": "tf.cast zeroes out input tensor when GPU does not have any free memory", "user": {"login": "mmuneebs", "id": 16750872, "node_id": "MDQ6VXNlcjE2NzUwODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/16750872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmuneebs", "html_url": "https://github.com/mmuneebs", "followers_url": "https://api.github.com/users/mmuneebs/followers", "following_url": "https://api.github.com/users/mmuneebs/following{/other_user}", "gists_url": "https://api.github.com/users/mmuneebs/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmuneebs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmuneebs/subscriptions", "organizations_url": "https://api.github.com/users/mmuneebs/orgs", "repos_url": "https://api.github.com/users/mmuneebs/repos", "events_url": "https://api.github.com/users/mmuneebs/events{/privacy}", "received_events_url": "https://api.github.com/users/mmuneebs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-11-01T06:22:53Z", "updated_at": "2018-01-25T00:14:14Z", "closed_at": "2018-01-25T00:14:13Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: tf-nightly-gpu binary from 10/31/2017</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.3.0-rc1-4007-gc44f67a', '1.5.0-dev20171031')</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA v8, cuDNN v6</li>\n<li><strong>GPU model and memory</strong>: 1080 Ti (11 GB)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>x = tf.cast(tensor, tf.float32)<br>\nx = tf.to_float(tensor)</p>\n<p>Above commands return a tensor with all values of <code>tensor</code> set to zero WHEN:<br>\nThe gpu is in full use by another tensorflow process. I'm trying to cast the tensor from dtype=tf.uint16 to tf.float32, using above commands, but whenever this runs while the gpu is in full use (i.e. I get a CUDA out-of-memory error), the program completes execution normally but the casting commands set the tensor to zeros.<br>\nI upgraded from an older nightly-gpu binary to the current one, but didn't help. User should not try to use an already in-use gpu, but this error should at least be communicated to the user.</p>\n<p>If I set the gpu to a different gpu with available memory, or if I hide all gpus to force it to use CPU, I do not observe this issue.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): tf-nightly-gpu binary from 10/31/2017\nTensorFlow version (use command below): ('v1.3.0-rc1-4007-gc44f67a', '1.5.0-dev20171031')\nPython version: 2.7.12\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: CUDA v8, cuDNN v6\nGPU model and memory: 1080 Ti (11 GB)\nExact command to reproduce:\n\nx = tf.cast(tensor, tf.float32)\nx = tf.to_float(tensor)\nAbove commands return a tensor with all values of tensor set to zero WHEN:\nThe gpu is in full use by another tensorflow process. I'm trying to cast the tensor from dtype=tf.uint16 to tf.float32, using above commands, but whenever this runs while the gpu is in full use (i.e. I get a CUDA out-of-memory error), the program completes execution normally but the casting commands set the tensor to zeros.\nI upgraded from an older nightly-gpu binary to the current one, but didn't help. User should not try to use an already in-use gpu, but this error should at least be communicated to the user.\nIf I set the gpu to a different gpu with available memory, or if I hide all gpus to force it to use CPU, I do not observe this issue.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: tf-nightly-gpu binary from 10/31/2017\r\n- **TensorFlow version (use command below)**: ('v1.3.0-rc1-4007-gc44f67a', '1.5.0-dev20171031')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA v8, cuDNN v6\r\n- **GPU model and memory**: 1080 Ti (11 GB)\r\n- **Exact command to reproduce**:\r\n\r\nx = tf.cast(tensor, tf.float32)\r\nx = tf.to_float(tensor)\r\n\r\nAbove commands return a tensor with all values of `tensor` set to zero WHEN:\r\nThe gpu is in full use by another tensorflow process. I'm trying to cast the tensor from dtype=tf.uint16 to tf.float32, using above commands, but whenever this runs while the gpu is in full use (i.e. I get a CUDA out-of-memory error), the program completes execution normally but the casting commands set the tensor to zeros.\r\nI upgraded from an older nightly-gpu binary to the current one, but didn't help. User should not try to use an already in-use gpu, but this error should at least be communicated to the user.\r\n\r\nIf I set the gpu to a different gpu with available memory, or if I hide all gpus to force it to use CPU, I do not observe this issue."}