{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19290", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19290/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19290/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19290/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19290", "id": 323172446, "node_id": "MDU6SXNzdWUzMjMxNzI0NDY=", "number": 19290, "title": "Multiple TITAN V introduce new error: CUB segmented reduce error", "user": {"login": "ialhashim", "id": 2434978, "node_id": "MDQ6VXNlcjI0MzQ5Nzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/2434978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ialhashim", "html_url": "https://github.com/ialhashim", "followers_url": "https://api.github.com/users/ialhashim/followers", "following_url": "https://api.github.com/users/ialhashim/following{/other_user}", "gists_url": "https://api.github.com/users/ialhashim/gists{/gist_id}", "starred_url": "https://api.github.com/users/ialhashim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ialhashim/subscriptions", "organizations_url": "https://api.github.com/users/ialhashim/orgs", "repos_url": "https://api.github.com/users/ialhashim/repos", "events_url": "https://api.github.com/users/ialhashim/events{/privacy}", "received_events_url": "https://api.github.com/users/ialhashim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-05-15T11:14:57Z", "updated_at": "2018-07-17T13:14:48Z", "closed_at": "2018-07-17T13:14:48Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>Keras code (with tf backend) that works perfectly on multiples of Titan Xp or 1080 Ti and tested on multiple TF versions both on Windows and Ubuntu</li>\n<li>Windows 10</li>\n<li>TensorFlow  1.8.0 (b'v1.8.0-0-g93bc2e2072' 1.8.0)</li>\n<li>Python 3.6.5</li>\n<li>CUDA 9.0/ cuDNN 7.0</li>\n<li>Two TITAN V</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>We upgraded our hardware from two Titan Xp to two Titan V. Running the exact same training script that was running perfectly on two GPUs now produces the error:</p>\n<pre><code>tensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\n</code></pre>\n<p>If we run the same script on a single GPU it runs fine. If we run on two GPUs with batch size '1' it also works fine. This could be a Keras issue, but I don't find anything in the Trackback to indicate that. The training starts but at Epoch 2 it crashes after going over some batches.</p>\n<p>Also, a minor note, the word 'errorinvalid' has no space in between.</p>\n<h3>Source code / logs</h3>\n<p>Full trackback:</p>\n<pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\n         [[Node: loss/DEC_CONV1C_loss/Mean_1 = Mean[T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/truediv\"], keep_dims=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/DEC_CONV1C_loss/Mean, training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/mod)]]\n         [[Node: training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:1\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1072_training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"]()]]\n</code></pre>\n<p>The error prints this twice.</p>", "body_text": "System information\n\nKeras code (with tf backend) that works perfectly on multiples of Titan Xp or 1080 Ti and tested on multiple TF versions both on Windows and Ubuntu\nWindows 10\nTensorFlow  1.8.0 (b'v1.8.0-0-g93bc2e2072' 1.8.0)\nPython 3.6.5\nCUDA 9.0/ cuDNN 7.0\nTwo TITAN V\n\nDescribe the problem\nWe upgraded our hardware from two Titan Xp to two Titan V. Running the exact same training script that was running perfectly on two GPUs now produces the error:\ntensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\n\nIf we run the same script on a single GPU it runs fine. If we run on two GPUs with batch size '1' it also works fine. This could be a Keras issue, but I don't find anything in the Trackback to indicate that. The training starts but at Epoch 2 it crashes after going over some batches.\nAlso, a minor note, the word 'errorinvalid' has no space in between.\nSource code / logs\nFull trackback:\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\n         [[Node: loss/DEC_CONV1C_loss/Mean_1 = Mean[T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/truediv\"], keep_dims=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/DEC_CONV1C_loss/Mean, training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/mod)]]\n         [[Node: training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:1\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1072_training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"]()]]\n\nThe error prints this twice.", "body": "### System information\r\n- Keras code (with tf backend) that works perfectly on multiples of Titan Xp or 1080 Ti and tested on multiple TF versions both on Windows and Ubuntu\r\n- Windows 10\r\n- TensorFlow  1.8.0 (b'v1.8.0-0-g93bc2e2072' 1.8.0)\r\n- Python 3.6.5\r\n- CUDA 9.0/ cuDNN 7.0\r\n- Two TITAN V\r\n\r\n### Describe the problem\r\nWe upgraded our hardware from two Titan Xp to two Titan V. Running the exact same training script that was running perfectly on two GPUs now produces the error:\r\n```\r\ntensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\r\n```\r\n\r\nIf we run the same script on a single GPU it runs fine. If we run on two GPUs with batch size '1' it also works fine. This could be a Keras issue, but I don't find anything in the Trackback to indicate that. The training starts but at Epoch 2 it crashes after going over some batches.\r\n\r\nAlso, a minor note, the word 'errorinvalid' has no space in between.\r\n\r\n### Source code / logs\r\nFull trackback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\\py3tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: CUB segmented reduce errorinvalid configuration argument\r\n         [[Node: loss/DEC_CONV1C_loss/Mean_1 = Mean[T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/truediv\"], keep_dims=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/DEC_CONV1C_loss/Mean, training/Adam/gradients/loss/DEC_CONV1C_loss/Mean_1_grad/mod)]]\r\n         [[Node: training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:1\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1072_training/Adam/gradients/DEC_CONV1C_1/concat_grad/Slice_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"]()]]\r\n```\r\nThe error prints this twice."}