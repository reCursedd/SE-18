{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363948082", "html_url": "https://github.com/tensorflow/tensorflow/issues/2793#issuecomment-363948082", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2793", "id": 363948082, "node_id": "MDEyOklzc3VlQ29tbWVudDM2Mzk0ODA4Mg==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-07T23:31:47Z", "updated_at": "2018-02-07T23:31:47Z", "author_association": "MEMBER", "body_html": "<p>It's easy to implement a clip_gradient \"op\" which acts like identity but clips the gradients using tfe.custom_gradient (which works normally in graph mode). Something like</p>\n<pre><code>@tfe.custom_gradient\ndef clip_gradient(x, clip):\n  def grad(dresult):\n    return [tf.clip_by_norm(dresult, clip)]\n  return x, grad\n</code></pre>", "body_text": "It's easy to implement a clip_gradient \"op\" which acts like identity but clips the gradients using tfe.custom_gradient (which works normally in graph mode). Something like\n@tfe.custom_gradient\ndef clip_gradient(x, clip):\n  def grad(dresult):\n    return [tf.clip_by_norm(dresult, clip)]\n  return x, grad", "body": "It's easy to implement a clip_gradient \"op\" which acts like identity but clips the gradients using tfe.custom_gradient (which works normally in graph mode). Something like\r\n\r\n```\r\n@tfe.custom_gradient\r\ndef clip_gradient(x, clip):\r\n  def grad(dresult):\r\n    return [tf.clip_by_norm(dresult, clip)]\r\n  return x, grad\r\n```"}