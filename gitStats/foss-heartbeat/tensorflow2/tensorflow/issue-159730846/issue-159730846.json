{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2793", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2793/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2793/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2793/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2793", "id": 159730846, "node_id": "MDU6SXNzdWUxNTk3MzA4NDY=", "number": 2793, "title": "Clipping gradient w.r.t. inputs at each time step for RNN/LSTM", "user": {"login": "asheshjain399", "id": 2342194, "node_id": "MDQ6VXNlcjIzNDIxOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2342194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asheshjain399", "html_url": "https://github.com/asheshjain399", "followers_url": "https://api.github.com/users/asheshjain399/followers", "following_url": "https://api.github.com/users/asheshjain399/following{/other_user}", "gists_url": "https://api.github.com/users/asheshjain399/gists{/gist_id}", "starred_url": "https://api.github.com/users/asheshjain399/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asheshjain399/subscriptions", "organizations_url": "https://api.github.com/users/asheshjain399/orgs", "repos_url": "https://api.github.com/users/asheshjain399/repos", "events_url": "https://api.github.com/users/asheshjain399/events{/privacy}", "received_events_url": "https://api.github.com/users/asheshjain399/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-06-10T21:53:17Z", "updated_at": "2018-02-07T23:31:47Z", "closed_at": "2018-02-07T23:31:47Z", "author_association": "NONE", "body_html": "<p>New feature request:</p>\n<p>While training LSTMs, is it often useful to clip the derivates w.r.t the inputs into the LSTM at each time step (<a href=\"http://arxiv.org/pdf/1308.0850v5.pdf\" rel=\"nofollow\">Alex Graves</a>, Sec 2.1). This is different from clipping the overall gradient. Theano supports this feature with <code>theano.gradient.grad_clip(tensor_var)</code>. Can we have a similar feature in tensorflow?</p>", "body_text": "New feature request:\nWhile training LSTMs, is it often useful to clip the derivates w.r.t the inputs into the LSTM at each time step (Alex Graves, Sec 2.1). This is different from clipping the overall gradient. Theano supports this feature with theano.gradient.grad_clip(tensor_var). Can we have a similar feature in tensorflow?", "body": "New feature request:\n\nWhile training LSTMs, is it often useful to clip the derivates w.r.t the inputs into the LSTM at each time step ([Alex Graves](http://arxiv.org/pdf/1308.0850v5.pdf), Sec 2.1). This is different from clipping the overall gradient. Theano supports this feature with `theano.gradient.grad_clip(tensor_var)`. Can we have a similar feature in tensorflow? \n"}