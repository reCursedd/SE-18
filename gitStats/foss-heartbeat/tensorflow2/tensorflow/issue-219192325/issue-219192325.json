{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8949", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8949/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8949/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8949/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8949", "id": 219192325, "node_id": "MDU6SXNzdWUyMTkxOTIzMjU=", "number": 8949, "title": "ResourceExhausted", "user": {"login": "kevinashaw", "id": 7141343, "node_id": "MDQ6VXNlcjcxNDEzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/7141343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinashaw", "html_url": "https://github.com/kevinashaw", "followers_url": "https://api.github.com/users/kevinashaw/followers", "following_url": "https://api.github.com/users/kevinashaw/following{/other_user}", "gists_url": "https://api.github.com/users/kevinashaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinashaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinashaw/subscriptions", "organizations_url": "https://api.github.com/users/kevinashaw/orgs", "repos_url": "https://api.github.com/users/kevinashaw/repos", "events_url": "https://api.github.com/users/kevinashaw/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinashaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-04-04T09:35:45Z", "updated_at": "2017-04-12T01:53:29Z", "closed_at": "2017-04-12T01:53:29Z", "author_association": "NONE", "body_html": "<p>I get the following error when running in GPU on AWS p2-xlarge:</p>\n<pre><code>I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                   279314432\nInUse:                   278784768\nMaxInUse:                278976768\nNumAllocs:                    4097\nMaxAllocSize:             19200000\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\n</code></pre>\n<p>I'm using TensorFlow R0.12.1 and Session code is:</p>\n<pre><code># Launch the graph\nconfig = tf.ConfigProto(log_device_placement=True)\nconfig.gpu_options.allocator_type = 'BFC'\nsess = tf.Session(config = config)\ninit = tf.global_variables_initializer()\nsess.run(init)\ntimestart = datetime.datetime.now() # Start time in seconds\ntimeprev  = datetime.datetime.now() # Start time in seconds\ncountprev = 0\nratelist = []\nboxcarcount = 10\nX_train = X_train.astype(np.float32)  # Cast to float32 from float64\n\nprint(\"Starting training...\")\n# Perform Training steps with \"batch_size\" iterations at each loop\nstep = 1\nwhile step * batch_size &lt;= training_iters:\n    # Note: type(X_train) = float32\n    # Note: type(y_train) = int32\n    # Note: type(step)       = int\n    # Note: type(batch_size) = int\n    batch_xs =         extract_batch_size(X_train, step, batch_size)\n    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)\n\n    # Fit training using batch data\n    output, loss, acc = sess.run(\n        [optimizer, cost, accuracy],\n        feed_dict={\n            Xin   : batch_xs, \n            Ytrue : batch_ys,\n            keep_prob: DO_keep_prob\n        }\n    )\n    train_losses.append(loss)\n    train_accuracies.append(acc)\n</code></pre>\n<p>My question: is there a way to allocate more memory in the GPU?<br>\nThis seems like a really small data set to be using?!?!?<br>\nThanks.</p>", "body_text": "I get the following error when running in GPU on AWS p2-xlarge:\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiB\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \nLimit:                   279314432\nInUse:                   278784768\nMaxInUse:                278976768\nNumAllocs:                    4097\nMaxAllocSize:             19200000\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\n\nI'm using TensorFlow R0.12.1 and Session code is:\n# Launch the graph\nconfig = tf.ConfigProto(log_device_placement=True)\nconfig.gpu_options.allocator_type = 'BFC'\nsess = tf.Session(config = config)\ninit = tf.global_variables_initializer()\nsess.run(init)\ntimestart = datetime.datetime.now() # Start time in seconds\ntimeprev  = datetime.datetime.now() # Start time in seconds\ncountprev = 0\nratelist = []\nboxcarcount = 10\nX_train = X_train.astype(np.float32)  # Cast to float32 from float64\n\nprint(\"Starting training...\")\n# Perform Training steps with \"batch_size\" iterations at each loop\nstep = 1\nwhile step * batch_size <= training_iters:\n    # Note: type(X_train) = float32\n    # Note: type(y_train) = int32\n    # Note: type(step)       = int\n    # Note: type(batch_size) = int\n    batch_xs =         extract_batch_size(X_train, step, batch_size)\n    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)\n\n    # Fit training using batch data\n    output, loss, acc = sess.run(\n        [optimizer, cost, accuracy],\n        feed_dict={\n            Xin   : batch_xs, \n            Ytrue : batch_ys,\n            keep_prob: DO_keep_prob\n        }\n    )\n    train_losses.append(loss)\n    train_accuracies.append(acc)\n\nMy question: is there a way to allocate more memory in the GPU?\nThis seems like a really small data set to be using?!?!?\nThanks.", "body": "I get the following error when running in GPU on AWS p2-xlarge:\r\n```\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: \r\nLimit:                   279314432\r\nInUse:                   278784768\r\nMaxInUse:                278976768\r\nNumAllocs:                    4097\r\nMaxAllocSize:             19200000\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\r\n```\r\nI'm using TensorFlow R0.12.1 and Session code is:\r\n```\r\n# Launch the graph\r\nconfig = tf.ConfigProto(log_device_placement=True)\r\nconfig.gpu_options.allocator_type = 'BFC'\r\nsess = tf.Session(config = config)\r\ninit = tf.global_variables_initializer()\r\nsess.run(init)\r\ntimestart = datetime.datetime.now() # Start time in seconds\r\ntimeprev  = datetime.datetime.now() # Start time in seconds\r\ncountprev = 0\r\nratelist = []\r\nboxcarcount = 10\r\nX_train = X_train.astype(np.float32)  # Cast to float32 from float64\r\n\r\nprint(\"Starting training...\")\r\n# Perform Training steps with \"batch_size\" iterations at each loop\r\nstep = 1\r\nwhile step * batch_size <= training_iters:\r\n    # Note: type(X_train) = float32\r\n    # Note: type(y_train) = int32\r\n    # Note: type(step)       = int\r\n    # Note: type(batch_size) = int\r\n    batch_xs =         extract_batch_size(X_train, step, batch_size)\r\n    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)\r\n\r\n    # Fit training using batch data\r\n    output, loss, acc = sess.run(\r\n        [optimizer, cost, accuracy],\r\n        feed_dict={\r\n            Xin   : batch_xs, \r\n            Ytrue : batch_ys,\r\n            keep_prob: DO_keep_prob\r\n        }\r\n    )\r\n    train_losses.append(loss)\r\n    train_accuracies.append(acc)\r\n```\r\nMy question: is there a way to allocate more memory in the GPU?\r\nThis seems like a really small data set to be using?!?!?\r\nThanks."}