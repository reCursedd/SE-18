{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/393503742", "html_url": "https://github.com/tensorflow/tensorflow/issues/13463#issuecomment-393503742", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13463", "id": 393503742, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MzUwMzc0Mg==", "user": {"login": "john-parton", "id": 2071543, "node_id": "MDQ6VXNlcjIwNzE1NDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2071543?v=4", "gravatar_id": "", "url": "https://api.github.com/users/john-parton", "html_url": "https://github.com/john-parton", "followers_url": "https://api.github.com/users/john-parton/followers", "following_url": "https://api.github.com/users/john-parton/following{/other_user}", "gists_url": "https://api.github.com/users/john-parton/gists{/gist_id}", "starred_url": "https://api.github.com/users/john-parton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/john-parton/subscriptions", "organizations_url": "https://api.github.com/users/john-parton/orgs", "repos_url": "https://api.github.com/users/john-parton/repos", "events_url": "https://api.github.com/users/john-parton/events{/privacy}", "received_events_url": "https://api.github.com/users/john-parton/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-31T11:42:49Z", "updated_at": "2018-05-31T11:44:35Z", "author_association": "NONE", "body_html": "<p>Can we re-open this? I have a minimal example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python</span>\n\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_iterator</span>():\n\n    output_buffer_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\n\n    pattern <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>test.txt.gz<span class=\"pl-pds\">'</span></span>\n\n    filenames <span class=\"pl-k\">=</span> tf.data.Dataset.list_files(pattern).repeat()\n\n    dataset <span class=\"pl-k\">=</span> filenames.apply(\n        tf.contrib.data.parallel_interleave(\n            <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">filename</span>: tf.data.TFRecordDataset(filename, <span class=\"pl-v\">compression_type</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>GZIP<span class=\"pl-pds\">'</span></span>),\n            <span class=\"pl-v\">cycle_length</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>,\n        )\n    )\n\n    dataset <span class=\"pl-k\">=</span> dataset.map(\n        <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">src</span>: tf.string_split([src]).values,\n        <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>\n    ).prefetch(output_buffer_size)\n\n    iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n\n    source <span class=\"pl-k\">=</span> iterator.get_next()\n\n    <span class=\"pl-k\">return</span> iterator, source\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n\n\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n\n    <span class=\"pl-k\">with</span> graph.as_default():\n        iterator, source <span class=\"pl-k\">=</span> get_iterator()\n\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n        table_initializer <span class=\"pl-k\">=</span> tf.tables_initializer()\n        sess.run(table_initializer)\n        sess.run(iterator.initializer)\n        sess.run(tf.global_variables_initializer())\n\n        <span class=\"pl-k\">for</span> __ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n\n            value <span class=\"pl-k\">=</span> sess.run([source])\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>\n<p>Here's the necessary file: <a href=\"https://github.com/tensorflow/tensorflow/files/2058033/test.txt.gz\">test.txt.gz</a></p>\n<p>Here's the output:</p>\n<pre><code>2018-05-31 06:38:55.956213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-05-31 06:38:55.956679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce GTX 680 major: 3 minor: 0 memoryClockRate(GHz): 1.163\npciBusID: 0000:01:00.0\ntotalMemory: 1.95GiB freeMemory: 1.58GiB\n2018-05-31 06:38:55.956700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-05-31 06:38:56.186321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-31 06:38:56.186355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-05-31 06:38:56.186366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-05-31 06:38:56.186483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1355 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 680, pci bus id: 0000:01:00.0, compute capability: 3.0)\nTraceback (most recent call last):\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"example.py\", line 54, in &lt;module&gt;\n    main()\n  File \"example.py\", line 51, in main\n    value = sess.run([source])\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\n    run_metadata_ptr)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\n    run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"example.py\", line 54, in &lt;module&gt;\n    main()\n  File \"example.py\", line 41, in main\n    iterator, source = get_iterator()\n  File \"example.py\", line 30, in get_iterator\n    source = iterator.get_next()\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 373, in get_next\n    name=name)), self._output_types,\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1666, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3417, in create_op\n    op_def=op_def)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1743, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nDataLossError (see above for traceback): corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n</code></pre>\n<p>My production code is a lot more complex, obviously. This is just the \"minimal\" example that was requested. Everything works fine if I use a regular <code>interleave</code> instead of the <code>parallel_interleave</code>.</p>\n<h2>Edit</h2>\n<p>I just tried it with an uncompressed txt and without the <code>compression_type='GZIP'</code> flag and it failed as well.</p>\n<p>Maybe there's something I don't understand about <code>parallel_interleave</code>?</p>\n<p>Thanks for your all your hard work!</p>", "body_text": "Can we re-open this? I have a minimal example:\n#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndef get_iterator():\n\n    output_buffer_size = 1000\n\n    pattern = 'test.txt.gz'\n\n    filenames = tf.data.Dataset.list_files(pattern).repeat()\n\n    dataset = filenames.apply(\n        tf.contrib.data.parallel_interleave(\n            lambda filename: tf.data.TFRecordDataset(filename, compression_type='GZIP'),\n            cycle_length=8,\n        )\n    )\n\n    dataset = dataset.map(\n        lambda src: tf.string_split([src]).values,\n        num_parallel_calls=8\n    ).prefetch(output_buffer_size)\n\n    iterator = dataset.make_initializable_iterator()\n\n    source = iterator.get_next()\n\n    return iterator, source\n\n\ndef main():\n\n\n    graph = tf.Graph()\n\n    with graph.as_default():\n        iterator, source = get_iterator()\n\n    with tf.Session(graph=graph) as sess:\n        table_initializer = tf.tables_initializer()\n        sess.run(table_initializer)\n        sess.run(iterator.initializer)\n        sess.run(tf.global_variables_initializer())\n\n        for __ in range(100):\n\n            value = sess.run([source])\n\nif __name__ == '__main__':\n    main()\nHere's the necessary file: test.txt.gz\nHere's the output:\n2018-05-31 06:38:55.956213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-05-31 06:38:55.956679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce GTX 680 major: 3 minor: 0 memoryClockRate(GHz): 1.163\npciBusID: 0000:01:00.0\ntotalMemory: 1.95GiB freeMemory: 1.58GiB\n2018-05-31 06:38:55.956700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-05-31 06:38:56.186321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-05-31 06:38:56.186355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-05-31 06:38:56.186366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-05-31 06:38:56.186483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 680, pci bus id: 0000:01:00.0, compute capability: 3.0)\nTraceback (most recent call last):\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n    return fn(*args)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"example.py\", line 54, in <module>\n    main()\n  File \"example.py\", line 51, in main\n    value = sess.run([source])\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\n    run_metadata_ptr)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\n    run_metadata)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"example.py\", line 54, in <module>\n    main()\n  File \"example.py\", line 41, in main\n    iterator, source = get_iterator()\n  File \"example.py\", line 30, in get_iterator\n    source = iterator.get_next()\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 373, in get_next\n    name=name)), self._output_types,\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1666, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3417, in create_op\n    op_def=op_def)\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1743, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nDataLossError (see above for traceback): corrupted record at 0\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\nMy production code is a lot more complex, obviously. This is just the \"minimal\" example that was requested. Everything works fine if I use a regular interleave instead of the parallel_interleave.\nEdit\nI just tried it with an uncompressed txt and without the compression_type='GZIP' flag and it failed as well.\nMaybe there's something I don't understand about parallel_interleave?\nThanks for your all your hard work!", "body": "Can we re-open this? I have a minimal example:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef get_iterator():\r\n\r\n    output_buffer_size = 1000\r\n\r\n    pattern = 'test.txt.gz'\r\n\r\n    filenames = tf.data.Dataset.list_files(pattern).repeat()\r\n\r\n    dataset = filenames.apply(\r\n        tf.contrib.data.parallel_interleave(\r\n            lambda filename: tf.data.TFRecordDataset(filename, compression_type='GZIP'),\r\n            cycle_length=8,\r\n        )\r\n    )\r\n\r\n    dataset = dataset.map(\r\n        lambda src: tf.string_split([src]).values,\r\n        num_parallel_calls=8\r\n    ).prefetch(output_buffer_size)\r\n\r\n    iterator = dataset.make_initializable_iterator()\r\n\r\n    source = iterator.get_next()\r\n\r\n    return iterator, source\r\n\r\n\r\ndef main():\r\n\r\n\r\n    graph = tf.Graph()\r\n\r\n    with graph.as_default():\r\n        iterator, source = get_iterator()\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        table_initializer = tf.tables_initializer()\r\n        sess.run(table_initializer)\r\n        sess.run(iterator.initializer)\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        for __ in range(100):\r\n\r\n            value = sess.run([source])\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nHere's the necessary file: [test.txt.gz](https://github.com/tensorflow/tensorflow/files/2058033/test.txt.gz)\r\n\r\nHere's the output:\r\n\r\n```\r\n2018-05-31 06:38:55.956213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-05-31 06:38:55.956679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce GTX 680 major: 3 minor: 0 memoryClockRate(GHz): 1.163\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.95GiB freeMemory: 1.58GiB\r\n2018-05-31 06:38:55.956700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-05-31 06:38:56.186321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-31 06:38:56.186355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-05-31 06:38:56.186366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-05-31 06:38:56.186483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 680, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\nTraceback (most recent call last):\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"example.py\", line 54, in <module>\r\n    main()\r\n  File \"example.py\", line 51, in main\r\n    value = sess.run([source])\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\nCaused by op 'IteratorGetNext', defined at:\r\n  File \"example.py\", line 54, in <module>\r\n    main()\r\n  File \"example.py\", line 41, in main\r\n    iterator, source = get_iterator()\r\n  File \"example.py\", line 30, in get_iterator\r\n    source = iterator.get_next()\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 373, in get_next\r\n    name=name)), self._output_types,\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1666, in iterator_get_next\r\n    output_shapes=output_shapes, name=name)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3417, in create_op\r\n    op_def=op_def)\r\n  File \"/home/john/Code/venv/tensorflow-rnn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1743, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nDataLossError (see above for traceback): corrupted record at 0\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n```\r\n\r\nMy production code is a lot more complex, obviously. This is just the \"minimal\" example that was requested. Everything works fine if I use a regular `interleave` instead of the `parallel_interleave`.\r\n\r\n## Edit\r\n\r\nI just tried it with an uncompressed txt and without the `compression_type='GZIP'` flag and it failed as well.\r\n\r\nMaybe there's something I don't understand about `parallel_interleave`?\r\n\r\nThanks for your all your hard work!"}