{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336102060", "html_url": "https://github.com/tensorflow/tensorflow/issues/13463#issuecomment-336102060", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13463", "id": 336102060, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjEwMjA2MA==", "user": {"login": "huangrandong", "id": 32484109, "node_id": "MDQ6VXNlcjMyNDg0MTA5", "avatar_url": "https://avatars0.githubusercontent.com/u/32484109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huangrandong", "html_url": "https://github.com/huangrandong", "followers_url": "https://api.github.com/users/huangrandong/followers", "following_url": "https://api.github.com/users/huangrandong/following{/other_user}", "gists_url": "https://api.github.com/users/huangrandong/gists{/gist_id}", "starred_url": "https://api.github.com/users/huangrandong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huangrandong/subscriptions", "organizations_url": "https://api.github.com/users/huangrandong/orgs", "repos_url": "https://api.github.com/users/huangrandong/repos", "events_url": "https://api.github.com/users/huangrandong/events{/privacy}", "received_events_url": "https://api.github.com/users/huangrandong/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-12T11:39:39Z", "updated_at": "2017-10-12T11:39:39Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a>  my code is used to put the numpy array into  the TFrecord file and read the it from the same file ,this is my code:</p>\n<h1>create the TFrecord file function:</h1>\n<p>img_tfrecord_name = image_base_name + \".tfrecord\"<br>\nwriter = tf.python_io.TFRecordWriter(new_label_path + img_tfrecord_name)<br>\nlabel_concate = np.concatenate((score_map, x1_offset, y1_offset,<br>\nx2_offset, y2_offset, x3_offset,<br>\ny3_offset, x4_offset, y4_offset), axis = -1)<br>\norg_train_image = cv2.imread(org_train_images_path + img_name)<br>\norg_train_image_resize = cv2.resize(org_train_image,<br>\n(input_image_size, input_image_size))<br>\nassert org_train_image_resize.shape == (512,512,3)<br>\norg_train_image_resize = org_train_image_resize.astype(np.uint8)<br>\norg_train_image_resize_raw = org_train_image_resize.tostring()<br>\nlabel_concate = label_concate.astype(np.float32)<br>\nlabel_concate_raw = label_concate.tostring()<br>\nexample = tf.train.Example(<br>\nfeatures = tf.train.Features(<br>\nfeature = {'image':tf.train.Feature(bytes_list =<br>\ntf.train.BytesList(value[org_train_image_resize_raw])),<br>\n'label':tf.train.Feature(bytes_list = tf.train.BytesList(value=[label_concate_raw]))}))<br>\nserialized = example.SerializeToString()<br>\nwriter.write(serialized)<br>\nprint 'writer  ',img_name,'  DOWN!'<br>\nwriter.close()</p>\n<h1>read the TFrecord file \uff1a</h1>\n<p>def _parse_function_for_train(example_proto):<br>\nfeatures = {'image': tf.FixedLenFeature((), tf.string, default_value=\"\"),<br>\n'label': tf.FixedLenFeature((), tf.string, default_value=\"\")}<br>\nparsed_features = tf.parse_single_example(example_proto, features)<br>\nimage_raw_out = parsed_features['image']<br>\nlabel_raw_out = parsed_features['label']<br>\nimage_out = tf.decode_raw(image_raw_out, tf.uint8)<br>\nlabel_out = tf.decode_raw(label_raw_out, tf.float32)<br>\nimage_out = tf.reshape(image_out, [512, 512, 3])<br>\nlabel_out = tf.reshape(label_out, [128,128,9])<br>\nreturn image_out, label_out</p>\n<p>def CreateTrainDataset():<br>\ntrain_image_label_tfrecord_list = [\"t1.tfrecord\", \"t2.tfrecord\",......]<br>\ntrain_dataset = tf.contrib.data.TFRecordDataset(train_image_label_tfrecord_list)<br>\ntrain_dataset = train_dataset.map(_parse_function_for_train)<br>\nbatched_train_dataset = train_dataset.batch(512)<br>\nreturn batched_train_dataset</p>\n<p>batched_train_dataset = CreateTrainDataset()<br>\niterator = batched_train_dataset.make_initializable_iterator()<br>\nbatch_image, batch_label = iterator.get_next()<br>\nwith tf.Session() as sess:<br>\nsess.run(iterator.initializer)<br>\nWhen the above code run some iterations, the DataLossError will com out</p>", "body_text": "@reedwm  my code is used to put the numpy array into  the TFrecord file and read the it from the same file ,this is my code:\ncreate the TFrecord file function:\nimg_tfrecord_name = image_base_name + \".tfrecord\"\nwriter = tf.python_io.TFRecordWriter(new_label_path + img_tfrecord_name)\nlabel_concate = np.concatenate((score_map, x1_offset, y1_offset,\nx2_offset, y2_offset, x3_offset,\ny3_offset, x4_offset, y4_offset), axis = -1)\norg_train_image = cv2.imread(org_train_images_path + img_name)\norg_train_image_resize = cv2.resize(org_train_image,\n(input_image_size, input_image_size))\nassert org_train_image_resize.shape == (512,512,3)\norg_train_image_resize = org_train_image_resize.astype(np.uint8)\norg_train_image_resize_raw = org_train_image_resize.tostring()\nlabel_concate = label_concate.astype(np.float32)\nlabel_concate_raw = label_concate.tostring()\nexample = tf.train.Example(\nfeatures = tf.train.Features(\nfeature = {'image':tf.train.Feature(bytes_list =\ntf.train.BytesList(value[org_train_image_resize_raw])),\n'label':tf.train.Feature(bytes_list = tf.train.BytesList(value=[label_concate_raw]))}))\nserialized = example.SerializeToString()\nwriter.write(serialized)\nprint 'writer  ',img_name,'  DOWN!'\nwriter.close()\nread the TFrecord file \uff1a\ndef _parse_function_for_train(example_proto):\nfeatures = {'image': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n'label': tf.FixedLenFeature((), tf.string, default_value=\"\")}\nparsed_features = tf.parse_single_example(example_proto, features)\nimage_raw_out = parsed_features['image']\nlabel_raw_out = parsed_features['label']\nimage_out = tf.decode_raw(image_raw_out, tf.uint8)\nlabel_out = tf.decode_raw(label_raw_out, tf.float32)\nimage_out = tf.reshape(image_out, [512, 512, 3])\nlabel_out = tf.reshape(label_out, [128,128,9])\nreturn image_out, label_out\ndef CreateTrainDataset():\ntrain_image_label_tfrecord_list = [\"t1.tfrecord\", \"t2.tfrecord\",......]\ntrain_dataset = tf.contrib.data.TFRecordDataset(train_image_label_tfrecord_list)\ntrain_dataset = train_dataset.map(_parse_function_for_train)\nbatched_train_dataset = train_dataset.batch(512)\nreturn batched_train_dataset\nbatched_train_dataset = CreateTrainDataset()\niterator = batched_train_dataset.make_initializable_iterator()\nbatch_image, batch_label = iterator.get_next()\nwith tf.Session() as sess:\nsess.run(iterator.initializer)\nWhen the above code run some iterations, the DataLossError will com out", "body": "@reedwm  my code is used to put the numpy array into  the TFrecord file and read the it from the same file ,this is my code:\r\n# create the TFrecord file function:\r\nimg_tfrecord_name = image_base_name + \".tfrecord\"\r\nwriter = tf.python_io.TFRecordWriter(new_label_path + img_tfrecord_name)\r\nlabel_concate = np.concatenate((score_map, x1_offset, y1_offset,\r\n                                                x2_offset, y2_offset, x3_offset,\r\n                                                y3_offset, x4_offset, y4_offset), axis = -1)\r\norg_train_image = cv2.imread(org_train_images_path + img_name)\r\norg_train_image_resize = cv2.resize(org_train_image,\r\n                                        (input_image_size, input_image_size))\r\nassert org_train_image_resize.shape == (512,512,3)\r\norg_train_image_resize = org_train_image_resize.astype(np.uint8)\r\norg_train_image_resize_raw = org_train_image_resize.tostring()\r\nlabel_concate = label_concate.astype(np.float32)\r\nlabel_concate_raw = label_concate.tostring()\r\nexample = tf.train.Example(\r\n                     features = tf.train.Features(\r\n                     feature = {'image':tf.train.Feature(bytes_list = \r\n                                       tf.train.BytesList(value[org_train_image_resize_raw])),\r\n                                      'label':tf.train.Feature(bytes_list = tf.train.BytesList(value=[label_concate_raw]))}))\r\nserialized = example.SerializeToString()\r\nwriter.write(serialized)\r\nprint 'writer  ',img_name,'  DOWN!'\r\nwriter.close()\r\n\r\n# read the TFrecord file \uff1a\r\ndef _parse_function_for_train(example_proto):\r\n       features = {'image': tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n                          'label': tf.FixedLenFeature((), tf.string, default_value=\"\")}\r\n        parsed_features = tf.parse_single_example(example_proto, features)\r\n        image_raw_out = parsed_features['image']\r\n        label_raw_out = parsed_features['label']\r\n        image_out = tf.decode_raw(image_raw_out, tf.uint8)\r\n        label_out = tf.decode_raw(label_raw_out, tf.float32)\r\n        image_out = tf.reshape(image_out, [512, 512, 3])\r\n        label_out = tf.reshape(label_out, [128,128,9])\r\n        return image_out, label_out\r\n\r\ndef CreateTrainDataset():\r\n      train_image_label_tfrecord_list = [\"t1.tfrecord\", \"t2.tfrecord\",......]\r\n      train_dataset = tf.contrib.data.TFRecordDataset(train_image_label_tfrecord_list)\r\n      train_dataset = train_dataset.map(_parse_function_for_train)\r\n      batched_train_dataset = train_dataset.batch(512)\r\n      return batched_train_dataset\r\n\r\nbatched_train_dataset = CreateTrainDataset()\r\niterator = batched_train_dataset.make_initializable_iterator()\r\nbatch_image, batch_label = iterator.get_next()\r\nwith tf.Session() as sess:\r\n          sess.run(iterator.initializer)\r\nWhen the above code run some iterations, the DataLossError will com out\r\n\r\n"}