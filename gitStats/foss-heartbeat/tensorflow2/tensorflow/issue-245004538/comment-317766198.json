{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317766198", "html_url": "https://github.com/tensorflow/tensorflow/issues/11709#issuecomment-317766198", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11709", "id": 317766198, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzc2NjE5OA==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-25T15:01:28Z", "updated_at": "2017-07-25T15:01:28Z", "author_association": "MEMBER", "body_html": "<p><code>embedding_lookup</code> and friends should only rely on dynamic partition and other cpu-heavy ops when you have partitioned embedding variables.</p>\n<p>Most of the use cases I've seen for partitioning embedding variables put them on remote parameter servers (since there's no point in sharding locally) and most setups I know of involving parameter servers are more efficient when the partitioned variables are on the CPU than when they are on the GPU.</p>\n<p>Are you using GPU-placed partitioned variables? If so, why?</p>\n<p>I don't think it's easy using our current setup to get rid of dynamic_partition for partitioned embedding lookup.</p>", "body_text": "embedding_lookup and friends should only rely on dynamic partition and other cpu-heavy ops when you have partitioned embedding variables.\nMost of the use cases I've seen for partitioning embedding variables put them on remote parameter servers (since there's no point in sharding locally) and most setups I know of involving parameter servers are more efficient when the partitioned variables are on the CPU than when they are on the GPU.\nAre you using GPU-placed partitioned variables? If so, why?\nI don't think it's easy using our current setup to get rid of dynamic_partition for partitioned embedding lookup.", "body": "`embedding_lookup` and friends should only rely on dynamic partition and other cpu-heavy ops when you have partitioned embedding variables.\r\n\r\nMost of the use cases I've seen for partitioning embedding variables put them on remote parameter servers (since there's no point in sharding locally) and most setups I know of involving parameter servers are more efficient when the partitioned variables are on the CPU than when they are on the GPU.\r\n\r\nAre you using GPU-placed partitioned variables? If so, why?\r\n\r\nI don't think it's easy using our current setup to get rid of dynamic_partition for partitioned embedding lookup."}