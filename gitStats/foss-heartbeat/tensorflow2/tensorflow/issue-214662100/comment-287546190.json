{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/287546190", "html_url": "https://github.com/tensorflow/tensorflow/issues/8463#issuecomment-287546190", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8463", "id": 287546190, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NzU0NjE5MA==", "user": {"login": "ouceduxzk", "id": 2516683, "node_id": "MDQ6VXNlcjI1MTY2ODM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2516683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ouceduxzk", "html_url": "https://github.com/ouceduxzk", "followers_url": "https://api.github.com/users/ouceduxzk/followers", "following_url": "https://api.github.com/users/ouceduxzk/following{/other_user}", "gists_url": "https://api.github.com/users/ouceduxzk/gists{/gist_id}", "starred_url": "https://api.github.com/users/ouceduxzk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ouceduxzk/subscriptions", "organizations_url": "https://api.github.com/users/ouceduxzk/orgs", "repos_url": "https://api.github.com/users/ouceduxzk/repos", "events_url": "https://api.github.com/users/ouceduxzk/events{/privacy}", "received_events_url": "https://api.github.com/users/ouceduxzk/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-18T13:25:05Z", "updated_at": "2017-03-18T13:26:50Z", "author_association": "NONE", "body_html": "<p>version : 1.0.0<br>\nreproducible example :<br>\n`</p>\n<pre><code>reader = tf.TFRecordReader()\n\n_, serialized_example = reader.read(filename_queue_video)\n\n# set the mapping from the fields to data types in the proto\nnum_features = len(self.video_feature_names)\n\nassert num_features &gt; 0, \"self.feature_names is empty!\"\nassert len(self.video_feature_names) == len(self.video_feature_sizes), \\\n\"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\nlen(self.video_feature_names), len(self.video_feature_sizes))\n\nfeature_map = {\"video_id\": tf.FixedLenFeature([], tf.string),\n               \"labels\": tf.VarLenFeature(tf.int64)}\nfor feature_index in range(num_features):\n  feature_map[self.video_feature_names[feature_index]] = tf.FixedLenFeature(\n      [self.video_feature_sizes[feature_index]], tf.float32)\n\nfeatures = tf.parse_single_example(serialized_example,\n                                   features=feature_map)\n</code></pre>\n<p>`<br>\nIn the implementation of parse_single_example, a Dict is returned. However, I would like to have an orderedDict in python</p>", "body_text": "version : 1.0.0\nreproducible example :\n`\nreader = tf.TFRecordReader()\n\n_, serialized_example = reader.read(filename_queue_video)\n\n# set the mapping from the fields to data types in the proto\nnum_features = len(self.video_feature_names)\n\nassert num_features > 0, \"self.feature_names is empty!\"\nassert len(self.video_feature_names) == len(self.video_feature_sizes), \\\n\"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\nlen(self.video_feature_names), len(self.video_feature_sizes))\n\nfeature_map = {\"video_id\": tf.FixedLenFeature([], tf.string),\n               \"labels\": tf.VarLenFeature(tf.int64)}\nfor feature_index in range(num_features):\n  feature_map[self.video_feature_names[feature_index]] = tf.FixedLenFeature(\n      [self.video_feature_sizes[feature_index]], tf.float32)\n\nfeatures = tf.parse_single_example(serialized_example,\n                                   features=feature_map)\n\n`\nIn the implementation of parse_single_example, a Dict is returned. However, I would like to have an orderedDict in python", "body": "version : 1.0.0\r\nreproducible example : \r\n`  \r\n\r\n    reader = tf.TFRecordReader()\r\n\r\n    _, serialized_example = reader.read(filename_queue_video)\r\n\r\n    # set the mapping from the fields to data types in the proto\r\n    num_features = len(self.video_feature_names)\r\n\r\n    assert num_features > 0, \"self.feature_names is empty!\"\r\n    assert len(self.video_feature_names) == len(self.video_feature_sizes), \\\r\n    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\r\n    len(self.video_feature_names), len(self.video_feature_sizes))\r\n\r\n    feature_map = {\"video_id\": tf.FixedLenFeature([], tf.string),\r\n                   \"labels\": tf.VarLenFeature(tf.int64)}\r\n    for feature_index in range(num_features):\r\n      feature_map[self.video_feature_names[feature_index]] = tf.FixedLenFeature(\r\n          [self.video_feature_sizes[feature_index]], tf.float32)\r\n\r\n    features = tf.parse_single_example(serialized_example,\r\n                                       features=feature_map)\r\n`\r\nIn the implementation of parse_single_example, a Dict is returned. However, I would like to have an orderedDict in python"}