{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/267276877", "html_url": "https://github.com/tensorflow/tensorflow/issues/6269#issuecomment-267276877", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6269", "id": 267276877, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NzI3Njg3Nw==", "user": {"login": "EloiZ", "id": 9169511, "node_id": "MDQ6VXNlcjkxNjk1MTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/9169511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EloiZ", "html_url": "https://github.com/EloiZ", "followers_url": "https://api.github.com/users/EloiZ/followers", "following_url": "https://api.github.com/users/EloiZ/following{/other_user}", "gists_url": "https://api.github.com/users/EloiZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/EloiZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EloiZ/subscriptions", "organizations_url": "https://api.github.com/users/EloiZ/orgs", "repos_url": "https://api.github.com/users/EloiZ/repos", "events_url": "https://api.github.com/users/EloiZ/events{/privacy}", "received_events_url": "https://api.github.com/users/EloiZ/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-15T09:17:24Z", "updated_at": "2016-12-15T09:28:34Z", "author_association": "NONE", "body_html": "<p>When i run this code snippet:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np                                                         \n                                                                           \na = tf.placeholder(tf.float32, shape=[2, 4])                                    \nw = tf.Variable(tf.random_uniform([4, 4], -1., 1.), name=\"w\")                   \n\nb = tf.matmul(a, w)                                                             \nc = tf.random_shuffle(b)                                                        \n\nloss = tf.reduce_sum(c)                                                     \nopt = tf.train.GradientDescentOptimizer(0.1).minimize(loss)                     \n                                                                                       \ninit_op = tf.global_variables_initializer()                                     \nwith tf.Session() as sess:                                                      \n    sess.run(init_op)                                                              \n    print(sess.run(opt, feed_dict={a: np.zeros((2, 4))}))\n</code></pre>\n<p>It gives this error:  <code>LookupError: No gradient defined for operation 'RandomShuffle' (op type: RandomShuffle)</code> which seems to mean that we cannot use the <code>RandomShuffle</code> op in a differentiable graph?</p>", "body_text": "When i run this code snippet:\nimport tensorflow as tf\nimport numpy as np                                                         \n                                                                           \na = tf.placeholder(tf.float32, shape=[2, 4])                                    \nw = tf.Variable(tf.random_uniform([4, 4], -1., 1.), name=\"w\")                   \n\nb = tf.matmul(a, w)                                                             \nc = tf.random_shuffle(b)                                                        \n\nloss = tf.reduce_sum(c)                                                     \nopt = tf.train.GradientDescentOptimizer(0.1).minimize(loss)                     \n                                                                                       \ninit_op = tf.global_variables_initializer()                                     \nwith tf.Session() as sess:                                                      \n    sess.run(init_op)                                                              \n    print(sess.run(opt, feed_dict={a: np.zeros((2, 4))}))\n\nIt gives this error:  LookupError: No gradient defined for operation 'RandomShuffle' (op type: RandomShuffle) which seems to mean that we cannot use the RandomShuffle op in a differentiable graph?", "body": "When i run this code snippet: \r\n```                                                            \r\nimport tensorflow as tf\r\nimport numpy as np                                                         \r\n                                                                           \r\na = tf.placeholder(tf.float32, shape=[2, 4])                                    \r\nw = tf.Variable(tf.random_uniform([4, 4], -1., 1.), name=\"w\")                   \r\n\r\nb = tf.matmul(a, w)                                                             \r\nc = tf.random_shuffle(b)                                                        \r\n\r\nloss = tf.reduce_sum(c)                                                     \r\nopt = tf.train.GradientDescentOptimizer(0.1).minimize(loss)                     \r\n                                                                                       \r\ninit_op = tf.global_variables_initializer()                                     \r\nwith tf.Session() as sess:                                                      \r\n    sess.run(init_op)                                                              \r\n    print(sess.run(opt, feed_dict={a: np.zeros((2, 4))}))\r\n```\r\nIt gives this error:  `LookupError: No gradient defined for operation 'RandomShuffle' (op type: RandomShuffle)` which seems to mean that we cannot use the `RandomShuffle` op in a differentiable graph?"}