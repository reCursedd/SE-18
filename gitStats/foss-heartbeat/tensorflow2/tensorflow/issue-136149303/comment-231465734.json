{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231465734", "html_url": "https://github.com/tensorflow/tensorflow/issues/1277#issuecomment-231465734", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1277", "id": 231465734, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTQ2NTczNA==", "user": {"login": "shlens", "id": 13385191, "node_id": "MDQ6VXNlcjEzMzg1MTkx", "avatar_url": "https://avatars1.githubusercontent.com/u/13385191?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shlens", "html_url": "https://github.com/shlens", "followers_url": "https://api.github.com/users/shlens/followers", "following_url": "https://api.github.com/users/shlens/following{/other_user}", "gists_url": "https://api.github.com/users/shlens/gists{/gist_id}", "starred_url": "https://api.github.com/users/shlens/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shlens/subscriptions", "organizations_url": "https://api.github.com/users/shlens/orgs", "repos_url": "https://api.github.com/users/shlens/repos", "events_url": "https://api.github.com/users/shlens/events{/privacy}", "received_events_url": "https://api.github.com/users/shlens/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-08T20:34:33Z", "updated_at": "2016-07-08T20:34:33Z", "author_association": "MEMBER", "body_html": "<p>If this is an issue due to poor handling of running to the end, then yes there is a better way to handle this.<br>\nNamely, one would need to update <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py\">cifar10_multi_gpu_train.py</a> to employ the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py\">Supervisor</a>.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12770037\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sherrym\">@sherrym</a> would be the expert for upgrading this.</p>\n<p>In the mean time, I would regard this error as a \"non-error\" as the training session merely did not shut down properly.</p>", "body_text": "If this is an issue due to poor handling of running to the end, then yes there is a better way to handle this.\nNamely, one would need to update cifar10_multi_gpu_train.py to employ the Supervisor.\n@sherrym would be the expert for upgrading this.\nIn the mean time, I would regard this error as a \"non-error\" as the training session merely did not shut down properly.", "body": "If this is an issue due to poor handling of running to the end, then yes there is a better way to handle this. \nNamely, one would need to update [cifar10_multi_gpu_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py) to employ the [Supervisor](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py).\n\n@sherrym would be the expert for upgrading this.\n\nIn the mean time, I would regard this error as a \"non-error\" as the training session merely did not shut down properly.\n"}