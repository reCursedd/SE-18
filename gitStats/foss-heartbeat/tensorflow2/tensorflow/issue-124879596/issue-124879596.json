{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/686", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/686/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/686/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/686/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/686", "id": 124879596, "node_id": "MDU6SXNzdWUxMjQ4Nzk1OTY=", "number": 686, "title": "tf.Fill has no gradient.  (Was: \"ValueError: No inputs provided\" when creating optimizer, seems like a bug)", "user": {"login": "pmerolla", "id": 3480196, "node_id": "MDQ6VXNlcjM0ODAxOTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/3480196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmerolla", "html_url": "https://github.com/pmerolla", "followers_url": "https://api.github.com/users/pmerolla/followers", "following_url": "https://api.github.com/users/pmerolla/following{/other_user}", "gists_url": "https://api.github.com/users/pmerolla/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmerolla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmerolla/subscriptions", "organizations_url": "https://api.github.com/users/pmerolla/orgs", "repos_url": "https://api.github.com/users/pmerolla/repos", "events_url": "https://api.github.com/users/pmerolla/events{/privacy}", "received_events_url": "https://api.github.com/users/pmerolla/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "dave-andersen", "id": 827870, "node_id": "MDQ6VXNlcjgyNzg3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/827870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-andersen", "html_url": "https://github.com/dave-andersen", "followers_url": "https://api.github.com/users/dave-andersen/followers", "following_url": "https://api.github.com/users/dave-andersen/following{/other_user}", "gists_url": "https://api.github.com/users/dave-andersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-andersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-andersen/subscriptions", "organizations_url": "https://api.github.com/users/dave-andersen/orgs", "repos_url": "https://api.github.com/users/dave-andersen/repos", "events_url": "https://api.github.com/users/dave-andersen/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-andersen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dave-andersen", "id": 827870, "node_id": "MDQ6VXNlcjgyNzg3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/827870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-andersen", "html_url": "https://github.com/dave-andersen", "followers_url": "https://api.github.com/users/dave-andersen/followers", "following_url": "https://api.github.com/users/dave-andersen/following{/other_user}", "gists_url": "https://api.github.com/users/dave-andersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-andersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-andersen/subscriptions", "organizations_url": "https://api.github.com/users/dave-andersen/orgs", "repos_url": "https://api.github.com/users/dave-andersen/repos", "events_url": "https://api.github.com/users/dave-andersen/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-andersen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2016-01-05T02:00:33Z", "updated_at": "2017-02-09T22:02:23Z", "closed_at": "2016-01-13T01:48:33Z", "author_association": "NONE", "body_html": "<p>I am in the process of implementing a version of BinaryConnect in tensorflow, and ran into this weird crash.  I pasted a simple example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.</p>\n<pre><code># Simplified example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\nSEED = None  # Set to None for random seed.\n\n# Network Parameters\nn_image_size = 28\nn_channels = 1\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(tf.types.float32, [batch_size, n_image_size, n_image_size, n_channels])\ny = tf.placeholder(tf.types.float32, [batch_size, n_classes])\n\n#BinaryConnect like projections\ndef project(W):\n    weights = tf.clip_by_value(W,0.1,-0.1)\n    shape = weights.get_shape()\n    rnd = tf.random_uniform(shape, minval=0, maxval=1.0, dtype=tf.float32, seed=None)\n    mx = tf.reduce_max(tf.abs(weights))\n    mx_fill = tf.fill(shape,mx)        \n    w_norm = tf.div(weights,mx_fill)\n    #[-1,1] -&gt; [0,1]\n    w_prob = tf.div(tf.add(w_norm,tf.fill(shape,1.0)),tf.fill(shape,2.0))\n    prob = tf.clip_by_value(w_prob, 0.0, 1.0) \n    draws = tf.greater(rnd,tf.fill(shape,1.0) - prob)\n    w = tf.select(draws,mx_fill,-mx_fill) #This line seems to be the issue\n    #Note that uncommenting below seems work, suggesting the graph is constructed correctly\n    #w = tf.select(draws,mx_fill,weights)\n    return w\n\ndef net_conv(_x, _weights): \n    wconv_proj = project(_weights['layer1'])\n    out1 = tf.nn.relu(tf.nn.conv2d(x, wconv_proj, strides=[1, 1, 1, 1], padding='SAME'))\n    out1p = tf.nn.max_pool(out1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    wfc_proj = project(_weights['layer2'])\n    shape = out1p.get_shape().as_list()\n    reshape = tf.reshape(out1p, [shape[0], shape[1] * shape[2] * shape[3]])\n    out2 = tf.nn.relu(tf.matmul(reshape, wfc_proj))\n\n    return out2\n\nweights_conv = {\n    'layer1': tf.Variable(tf.truncated_normal([5, 5, n_channels, 32], stddev=0.1, seed=SEED)),\n    'layer2': tf.Variable(tf.truncated_normal([14 * 14 * 32, n_classes], stddev=0.1, seed=SEED))\n}\n\npred1  = net_conv(x, weights_conv)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred1, y))\noptimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n</code></pre>", "body_text": "I am in the process of implementing a version of BinaryConnect in tensorflow, and ran into this weird crash.  I pasted a simple example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n# Simplified example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\nSEED = None  # Set to None for random seed.\n\n# Network Parameters\nn_image_size = 28\nn_channels = 1\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(tf.types.float32, [batch_size, n_image_size, n_image_size, n_channels])\ny = tf.placeholder(tf.types.float32, [batch_size, n_classes])\n\n#BinaryConnect like projections\ndef project(W):\n    weights = tf.clip_by_value(W,0.1,-0.1)\n    shape = weights.get_shape()\n    rnd = tf.random_uniform(shape, minval=0, maxval=1.0, dtype=tf.float32, seed=None)\n    mx = tf.reduce_max(tf.abs(weights))\n    mx_fill = tf.fill(shape,mx)        \n    w_norm = tf.div(weights,mx_fill)\n    #[-1,1] -> [0,1]\n    w_prob = tf.div(tf.add(w_norm,tf.fill(shape,1.0)),tf.fill(shape,2.0))\n    prob = tf.clip_by_value(w_prob, 0.0, 1.0) \n    draws = tf.greater(rnd,tf.fill(shape,1.0) - prob)\n    w = tf.select(draws,mx_fill,-mx_fill) #This line seems to be the issue\n    #Note that uncommenting below seems work, suggesting the graph is constructed correctly\n    #w = tf.select(draws,mx_fill,weights)\n    return w\n\ndef net_conv(_x, _weights): \n    wconv_proj = project(_weights['layer1'])\n    out1 = tf.nn.relu(tf.nn.conv2d(x, wconv_proj, strides=[1, 1, 1, 1], padding='SAME'))\n    out1p = tf.nn.max_pool(out1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    wfc_proj = project(_weights['layer2'])\n    shape = out1p.get_shape().as_list()\n    reshape = tf.reshape(out1p, [shape[0], shape[1] * shape[2] * shape[3]])\n    out2 = tf.nn.relu(tf.matmul(reshape, wfc_proj))\n\n    return out2\n\nweights_conv = {\n    'layer1': tf.Variable(tf.truncated_normal([5, 5, n_channels, 32], stddev=0.1, seed=SEED)),\n    'layer2': tf.Variable(tf.truncated_normal([14 * 14 * 32, n_classes], stddev=0.1, seed=SEED))\n}\n\npred1  = net_conv(x, weights_conv)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred1, y))\noptimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)", "body": "I am in the process of implementing a version of BinaryConnect in tensorflow, and ran into this weird crash.  I pasted a simple example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\n```\n# Simplified example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\nSEED = None  # Set to None for random seed.\n\n# Network Parameters\nn_image_size = 28\nn_channels = 1\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(tf.types.float32, [batch_size, n_image_size, n_image_size, n_channels])\ny = tf.placeholder(tf.types.float32, [batch_size, n_classes])\n\n#BinaryConnect like projections\ndef project(W):\n    weights = tf.clip_by_value(W,0.1,-0.1)\n    shape = weights.get_shape()\n    rnd = tf.random_uniform(shape, minval=0, maxval=1.0, dtype=tf.float32, seed=None)\n    mx = tf.reduce_max(tf.abs(weights))\n    mx_fill = tf.fill(shape,mx)        \n    w_norm = tf.div(weights,mx_fill)\n    #[-1,1] -> [0,1]\n    w_prob = tf.div(tf.add(w_norm,tf.fill(shape,1.0)),tf.fill(shape,2.0))\n    prob = tf.clip_by_value(w_prob, 0.0, 1.0) \n    draws = tf.greater(rnd,tf.fill(shape,1.0) - prob)\n    w = tf.select(draws,mx_fill,-mx_fill) #This line seems to be the issue\n    #Note that uncommenting below seems work, suggesting the graph is constructed correctly\n    #w = tf.select(draws,mx_fill,weights)\n    return w\n\ndef net_conv(_x, _weights): \n    wconv_proj = project(_weights['layer1'])\n    out1 = tf.nn.relu(tf.nn.conv2d(x, wconv_proj, strides=[1, 1, 1, 1], padding='SAME'))\n    out1p = tf.nn.max_pool(out1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    wfc_proj = project(_weights['layer2'])\n    shape = out1p.get_shape().as_list()\n    reshape = tf.reshape(out1p, [shape[0], shape[1] * shape[2] * shape[3]])\n    out2 = tf.nn.relu(tf.matmul(reshape, wfc_proj))\n\n    return out2\n\nweights_conv = {\n    'layer1': tf.Variable(tf.truncated_normal([5, 5, n_channels, 32], stddev=0.1, seed=SEED)),\n    'layer2': tf.Variable(tf.truncated_normal([14 * 14 * 32, n_classes], stddev=0.1, seed=SEED))\n}\n\npred1  = net_conv(x, weights_conv)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred1, y))\noptimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n```\n"}