{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263668796", "html_url": "https://github.com/tensorflow/tensorflow/issues/5922#issuecomment-263668796", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5922", "id": 263668796, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzY2ODc5Ng==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-29T19:15:46Z", "updated_at": "2016-11-29T19:15:46Z", "author_association": "MEMBER", "body_html": "<p>This sort of question is better asked on stackoverflow, assuming that it's user error and not a completely broken model.  In order to try to make that distinction, it would be helpful if you would clarify what happened when you trained the model, so we can determine whether training failed, or inference from a correct model is not working.</p>\n<p>Did the training run the expected number of steps without error?  Did the loss decrease as expected?  Did you run evaluations on the training set and a hold-out set and see the expected increases in accuracy during training?    If the training failed, you need to figure out why.</p>\n<p>If training succeed, then the problem must lie in inference.  Again, it would be helpful to know exactly how you invoked inference and what diagnostic messages might have occurred.</p>", "body_text": "This sort of question is better asked on stackoverflow, assuming that it's user error and not a completely broken model.  In order to try to make that distinction, it would be helpful if you would clarify what happened when you trained the model, so we can determine whether training failed, or inference from a correct model is not working.\nDid the training run the expected number of steps without error?  Did the loss decrease as expected?  Did you run evaluations on the training set and a hold-out set and see the expected increases in accuracy during training?    If the training failed, you need to figure out why.\nIf training succeed, then the problem must lie in inference.  Again, it would be helpful to know exactly how you invoked inference and what diagnostic messages might have occurred.", "body": "This sort of question is better asked on stackoverflow, assuming that it's user error and not a completely broken model.  In order to try to make that distinction, it would be helpful if you would clarify what happened when you trained the model, so we can determine whether training failed, or inference from a correct model is not working.\r\n\r\nDid the training run the expected number of steps without error?  Did the loss decrease as expected?  Did you run evaluations on the training set and a hold-out set and see the expected increases in accuracy during training?    If the training failed, you need to figure out why.\r\n\r\nIf training succeed, then the problem must lie in inference.  Again, it would be helpful to know exactly how you invoked inference and what diagnostic messages might have occurred."}