{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438777975", "html_url": "https://github.com/tensorflow/tensorflow/issues/23635#issuecomment-438777975", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23635", "id": 438777975, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODc3Nzk3NQ==", "user": {"login": "gmanrocks99", "id": 44654007, "node_id": "MDQ6VXNlcjQ0NjU0MDA3", "avatar_url": "https://avatars3.githubusercontent.com/u/44654007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gmanrocks99", "html_url": "https://github.com/gmanrocks99", "followers_url": "https://api.github.com/users/gmanrocks99/followers", "following_url": "https://api.github.com/users/gmanrocks99/following{/other_user}", "gists_url": "https://api.github.com/users/gmanrocks99/gists{/gist_id}", "starred_url": "https://api.github.com/users/gmanrocks99/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gmanrocks99/subscriptions", "organizations_url": "https://api.github.com/users/gmanrocks99/orgs", "repos_url": "https://api.github.com/users/gmanrocks99/repos", "events_url": "https://api.github.com/users/gmanrocks99/events{/privacy}", "received_events_url": "https://api.github.com/users/gmanrocks99/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-14T18:58:33Z", "updated_at": "2018-11-14T21:40:18Z", "author_association": "NONE", "body_html": "<p>import numpy as np<br>\nimport tensorflow as tf<br>\nfrom tensorflow.keras.models import Sequential<br>\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout<br>\nfrom tensorflow.keras.optimizers import Adam</p>\n<p>train_data = np.load('train_data.npy')<br>\ntest_data = np.load('test_data.npy')</p>\n<p>train = train_data[:-500]<br>\ntest = train_data[-500:]</p>\n<p>X_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)<br>\nY_train = np.array([i[1] for i in train])</p>\n<p>X_test = np.array([i[0] for i in test]).reshape(-1, 50, 50, 1)<br>\nY_test = np.array([i[1] for i in test])</p>\n<p>tf.reset_default_graph()<br>\nsess = tf.Session()</p>\n<p>model = Sequential()</p>\n<h1>layer1 = conv_2d, filters = 32, filter size = 5, activation = relu</h1>\n<p>model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', ))</p>\n<h1>layer2 = max_pool_2d, kernels = 5</h1>\n<p>model.add(MaxPool2D(pool_size=(5, 5)))</p>\n<h1>layer3 = conv_2d, filters = 64, filter size = 5, activation = relu</h1>\n<p>model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))</p>\n<h1>layer4 = max_pool_2d, kernels = 5</h1>\n<p>model.add(MaxPool2D(pool_size=(5, 5)))</p>\n<h1>layer5 = conv_2d, filters = 128, filter size = 5, activation = relu</h1>\n<p>model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))</p>\n<h1>layer6 = max_pool_2d, kernels = 5</h1>\n<p>model.add(MaxPool2D(pool_size=(5, 5)))</p>\n<h1>layer7 = conv_2d, filters = 64, filter size = 5, activation = relu</h1>\n<p>model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))</p>\n<h1>layer8 = max_pool_2d, kernels = 5</h1>\n<p>model.add(MaxPool2D(pool_size=(5, 5)))</p>\n<h1>layer9 = conv_2d, filters = 32, filter size = 5, activation = relu</h1>\n<p>model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))</p>\n<h1>layer10 = max_pool_2d, kernels = 5</h1>\n<p>model.add(MaxPool2D(pool_size=(5, 5)))</p>\n<h1>layer11 = fully_connected, units = 1024, activation = relu</h1>\n<p>model.add(Dense(units=1024, activation='relu'))</p>\n<h1>layer12 = dropout, keep_probability = 0.8</h1>\n<p>model.add(Dropout(rate=0.8))</p>\n<h1>layer13 = fully_connected, units = 2, activation = softmax</h1>\n<p>model.add(Dense(units=2, activation='softmax'))</p>\n<h1>layer14 = regression, optimizer = adam, learning rate = LR, loss = categorical cross entropy</h1>\n<p>model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])</p>\n<h1>epochs = 1, validation set = (X_test, Y_test), snapshot every 500, progressbar</h1>\n<p>model.fit(x=X_train, y=Y_train, epochs=1, validation_data=(X_test, Y_test), verbose=1)</p>", "body_text": "import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\ntrain_data = np.load('train_data.npy')\ntest_data = np.load('test_data.npy')\ntrain = train_data[:-500]\ntest = train_data[-500:]\nX_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)\nY_train = np.array([i[1] for i in train])\nX_test = np.array([i[0] for i in test]).reshape(-1, 50, 50, 1)\nY_test = np.array([i[1] for i in test])\ntf.reset_default_graph()\nsess = tf.Session()\nmodel = Sequential()\nlayer1 = conv_2d, filters = 32, filter size = 5, activation = relu\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', ))\nlayer2 = max_pool_2d, kernels = 5\nmodel.add(MaxPool2D(pool_size=(5, 5)))\nlayer3 = conv_2d, filters = 64, filter size = 5, activation = relu\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nlayer4 = max_pool_2d, kernels = 5\nmodel.add(MaxPool2D(pool_size=(5, 5)))\nlayer5 = conv_2d, filters = 128, filter size = 5, activation = relu\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nlayer6 = max_pool_2d, kernels = 5\nmodel.add(MaxPool2D(pool_size=(5, 5)))\nlayer7 = conv_2d, filters = 64, filter size = 5, activation = relu\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nlayer8 = max_pool_2d, kernels = 5\nmodel.add(MaxPool2D(pool_size=(5, 5)))\nlayer9 = conv_2d, filters = 32, filter size = 5, activation = relu\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\nlayer10 = max_pool_2d, kernels = 5\nmodel.add(MaxPool2D(pool_size=(5, 5)))\nlayer11 = fully_connected, units = 1024, activation = relu\nmodel.add(Dense(units=1024, activation='relu'))\nlayer12 = dropout, keep_probability = 0.8\nmodel.add(Dropout(rate=0.8))\nlayer13 = fully_connected, units = 2, activation = softmax\nmodel.add(Dense(units=2, activation='softmax'))\nlayer14 = regression, optimizer = adam, learning rate = LR, loss = categorical cross entropy\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nepochs = 1, validation set = (X_test, Y_test), snapshot every 500, progressbar\nmodel.fit(x=X_train, y=Y_train, epochs=1, validation_data=(X_test, Y_test), verbose=1)", "body": "import numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\ntrain_data = np.load('train_data.npy')\r\ntest_data = np.load('test_data.npy')\r\n\r\ntrain = train_data[:-500]\r\ntest = train_data[-500:]\r\n\r\nX_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)\r\nY_train = np.array([i[1] for i in train])\r\n\r\nX_test = np.array([i[0] for i in test]).reshape(-1, 50, 50, 1)\r\nY_test = np.array([i[1] for i in test])\r\n\r\ntf.reset_default_graph()\r\nsess = tf.Session()\r\n\r\nmodel = Sequential()\r\n\r\n# layer1 = conv_2d, filters = 32, filter size = 5, activation = relu\r\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', ))\r\n\r\n# layer2 = max_pool_2d, kernels = 5\r\nmodel.add(MaxPool2D(pool_size=(5, 5)))\r\n\r\n# layer3 = conv_2d, filters = 64, filter size = 5, activation = relu\r\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\r\n\r\n# layer4 = max_pool_2d, kernels = 5\r\nmodel.add(MaxPool2D(pool_size=(5, 5)))\r\n\r\n# layer5 = conv_2d, filters = 128, filter size = 5, activation = relu\r\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\r\n\r\n# layer6 = max_pool_2d, kernels = 5\r\nmodel.add(MaxPool2D(pool_size=(5, 5)))\r\n\r\n# layer7 = conv_2d, filters = 64, filter size = 5, activation = relu\r\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\r\n\r\n# layer8 = max_pool_2d, kernels = 5\r\nmodel.add(MaxPool2D(pool_size=(5, 5)))\r\n\r\n# layer9 = conv_2d, filters = 32, filter size = 5, activation = relu\r\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\r\n\r\n# layer10 = max_pool_2d, kernels = 5\r\nmodel.add(MaxPool2D(pool_size=(5, 5)))\r\n\r\n# layer11 = fully_connected, units = 1024, activation = relu\r\nmodel.add(Dense(units=1024, activation='relu'))\r\n\r\n# layer12 = dropout, keep_probability = 0.8\r\nmodel.add(Dropout(rate=0.8))\r\n\r\n# layer13 = fully_connected, units = 2, activation = softmax\r\nmodel.add(Dense(units=2, activation='softmax'))\r\n\r\n# layer14 = regression, optimizer = adam, learning rate = LR, loss = categorical cross entropy\r\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\n# epochs = 1, validation set = (X_test, Y_test), snapshot every 500, progressbar\r\nmodel.fit(x=X_train, y=Y_train, epochs=1, validation_data=(X_test, Y_test), verbose=1)"}