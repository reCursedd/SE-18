{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22578", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22578/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22578/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22578/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22578", "id": 364704382, "node_id": "MDU6SXNzdWUzNjQ3MDQzODI=", "number": 22578, "title": "Tensorflow top 1 prediction drop on the /example/label_image/label_image.py  with mobile net . ", "user": {"login": "ywang370", "id": 3378175, "node_id": "MDQ6VXNlcjMzNzgxNzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/3378175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ywang370", "html_url": "https://github.com/ywang370", "followers_url": "https://api.github.com/users/ywang370/followers", "following_url": "https://api.github.com/users/ywang370/following{/other_user}", "gists_url": "https://api.github.com/users/ywang370/gists{/gist_id}", "starred_url": "https://api.github.com/users/ywang370/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ywang370/subscriptions", "organizations_url": "https://api.github.com/users/ywang370/orgs", "repos_url": "https://api.github.com/users/ywang370/repos", "events_url": "https://api.github.com/users/ywang370/events{/privacy}", "received_events_url": "https://api.github.com/users/ywang370/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-28T01:05:42Z", "updated_at": "2018-10-06T01:35:34Z", "closed_at": "2018-10-06T01:35:34Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: NO</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Python version</strong>:  2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.17.2</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:  No</li>\n<li><strong>GPU model and memory</strong>: No</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I compared official code for mobilenet v1 on both python and C++ and find some performance drop.<br>\nmodel: <a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\">https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet</a><br>\nI use mobilenet_v1_224</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<p>The model and input data are <strong>EXACTLY SAME</strong></p>\n<p>I doubt the problem is the mean and std in label_image.py but I couldn't make the prediction as same as the above inference.</p>\n<p>The label_image.py comes from tensorflow/example/label_image/label_image.py. Just change inception to mobilenet.</p>\n<pre><code>import tensorflow as tf\ntf_model_path = './frozen_graph.pb'\nwith open(tf_model_path, 'rb') as f:\n    serialized = f.read()\ntf.reset_default_graph()\noriginal_gdef = tf.GraphDef()\noriginal_gdef.ParseFromString(serialized)\n\nimport numpy as np\nimport PIL\nimport requests\nfrom io import BytesIO\nfrom matplotlib.pyplot import imshow\nimg_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'\nresponse = requests.get(img_url)\n%matplotlib inline\nimg = PIL.Image.open(BytesIO(response.content))\nimshow(np.asarray(img))\nimg = img.resize([224,224], PIL.Image.ANTIALIAS)\n\nimg_np = np.array(img).astype(np.float32)\nprint( 'image shape:', img_np.shape)\nprint( 'first few values: ', img_np.flatten()[0:4], 'max value: ', np.amax(img_np))\nimg_tf = np.expand_dims(img_np, axis = 0) #now shape is [1,224,224,3] as required by TF\nimg_tf = (2.0/255.0) * img_tf - 1\n\n\ntf_input_name = 'input:0'\ntf_output_name = 'MobilenetV1/Predictions/Reshape_1:0'\nwith tf.Session(graph = g) as sess:\n    tf_out = sess.run(tf_output_name, \n                      feed_dict={tf_input_name: img_tf})\ntf_out = tf_out.flatten()    \nidx = np.argmax(tf_out)\nlabel_file = 'labels.txt' \nwith open(label_file) as f:\n    labels = f.readlines()\n    \nprint('\\n')\nprint(\"TF prediction class = {}, probability = {}\".format(labels[idx],\n                                            str(tf_out[idx])))\n</code></pre>\n<p>it shows:<br>\nimage shape: (224, 224, 3)<br>\nfirst few values:  [39. 33. 18. 42.] max value:  255.0<br>\nTF prediction class = 208:golden retriever<br>\n, probability = 0.9581951</p>\n<p>#while for when  I use tensorflow/example/label_image/label_image.py the result is different:</p>\n<pre><code>\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef load_graph(model_file):\n  graph = tf.Graph()\n  graph_def = tf.GraphDef()\n\n  with open(model_file, \"rb\") as f:\n    graph_def.ParseFromString(f.read())\n  with graph.as_default():\n    tf.import_graph_def(graph_def)\n\n  return graph\n\n\ndef read_tensor_from_image_file(file_name,\n                                input_height=224,\n                                input_width=224,\n                                input_mean=0,\n                                input_std=255):\n  input_name = \"file_reader\"\n  output_name = \"normalized\"\n  file_reader = tf.read_file(file_name, input_name)\n  if file_name.endswith(\".png\"):\n    image_reader = tf.image.decode_png(\n        file_reader, channels=3, name=\"png_reader\")\n  elif file_name.endswith(\".gif\"):\n    image_reader = tf.squeeze(\n        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n  elif file_name.endswith(\".bmp\"):\n    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n  else:\n    image_reader = tf.image.decode_jpeg(\n        file_reader, channels=3, name=\"jpeg_reader\")\n  float_caster = tf.cast(image_reader, tf.float32)\n  dims_expander = tf.expand_dims(float_caster, 0)\n  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n  normalized = tf.subtract(tf.divide(resized,[input_std]),[input_mean])\n  sess = tf.Session()\n  result = sess.run(normalized)\n\n  return result\n\n\ndef load_labels(label_file):\n  label = []\n  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n  for l in proto_as_ascii_lines:\n    label.append(l.rstrip())\n  return label\n\n\nif __name__ == \"__main__\":\n  file_name = \"./data/test.jpg\"\n  model_file = \\\n    \"./data/frozen_graph.pb\"\n  label_file = \"./data/labels.txt\"\n  input_height = 224\n  input_width = 224\n  input_mean = 1\n  input_std = 255/2\n  input_layer = \"input\"\n  output_layer = \"MobilenetV1/Predictions/Reshape_1\"\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\"--image\", help=\"image to be processed\")\n  parser.add_argument(\"--graph\", help=\"graph/model to be executed\")\n  parser.add_argument(\"--labels\", help=\"name of file containing labels\")\n  parser.add_argument(\"--input_height\", type=int, help=\"input height\")\n  parser.add_argument(\"--input_width\", type=int, help=\"input width\")\n  parser.add_argument(\"--input_mean\", type=int, help=\"input mean\")\n  parser.add_argument(\"--input_std\", type=int, help=\"input std\")\n  parser.add_argument(\"--input_layer\", help=\"name of input layer\")\n  parser.add_argument(\"--output_layer\", help=\"name of output layer\")\n  args = parser.parse_args()\n\n  if args.graph:\n    model_file = args.graph\n  if args.image:\n    file_name = args.image\n  if args.labels:\n    label_file = args.labels\n  if args.input_height:\n    input_height = args.input_height\n  if args.input_width:\n    input_width = args.input_width\n  if args.input_mean:\n    input_mean = args.input_mean\n  if args.input_std:\n    input_std = args.input_std\n  if args.input_layer:\n    input_layer = args.input_layer\n  if args.output_layer:\n    output_layer = args.output_layer\n\n  graph = load_graph(model_file)\n  t = read_tensor_from_image_file(\n      file_name,\n      input_height=input_height,\n      input_width=input_width,\n      input_mean=input_mean,\n      input_std=input_std)\n\n  input_name = \"import/\" + input_layer\n  output_name = \"import/\" + output_layer\n  input_operation = graph.get_operation_by_name(input_name)\n  output_operation = graph.get_operation_by_name(output_name)\n\n  with tf.Session(graph=graph) as sess:\n    results = sess.run(output_operation.outputs[0], {\n        input_operation.outputs[0]: t\n    })\n  results = np.squeeze(results)\n\n  top_k = results.argsort()[-5:][::-1]\n  labels = load_labels(label_file)\n  for i in top_k:\n    print(labels[i], results[i])\n</code></pre>\n<p>`208:golden retriever 0.83966106<br>\n209:Labrador retriever 0.033579364<br>\n213:English setter 0.024712995<br>\n274:dingo, warrigal, warragal, Canis dingo 0.01596725<br>\n217:clumber, clumber spaniel 0.010608253</p>\n<p>if I change std =255 mean=0 it shows 208:golden retriever 0.7953789<br>\n213:English setter 0.03927898<br>\n217:clumber, clumber spaniel 0.028547956<br>\n209:Labrador retriever 0.025497263<br>\n221:Sussex spaniel 0.013308002</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.9.0\nPython version:  2.7\nBazel version (if compiling from source): 0.17.2\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:  No\nGPU model and memory: No\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI compared official code for mobilenet v1 on both python and C++ and find some performance drop.\nmodel: https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\nI use mobilenet_v1_224\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nThe model and input data are EXACTLY SAME\nI doubt the problem is the mean and std in label_image.py but I couldn't make the prediction as same as the above inference.\nThe label_image.py comes from tensorflow/example/label_image/label_image.py. Just change inception to mobilenet.\nimport tensorflow as tf\ntf_model_path = './frozen_graph.pb'\nwith open(tf_model_path, 'rb') as f:\n    serialized = f.read()\ntf.reset_default_graph()\noriginal_gdef = tf.GraphDef()\noriginal_gdef.ParseFromString(serialized)\n\nimport numpy as np\nimport PIL\nimport requests\nfrom io import BytesIO\nfrom matplotlib.pyplot import imshow\nimg_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'\nresponse = requests.get(img_url)\n%matplotlib inline\nimg = PIL.Image.open(BytesIO(response.content))\nimshow(np.asarray(img))\nimg = img.resize([224,224], PIL.Image.ANTIALIAS)\n\nimg_np = np.array(img).astype(np.float32)\nprint( 'image shape:', img_np.shape)\nprint( 'first few values: ', img_np.flatten()[0:4], 'max value: ', np.amax(img_np))\nimg_tf = np.expand_dims(img_np, axis = 0) #now shape is [1,224,224,3] as required by TF\nimg_tf = (2.0/255.0) * img_tf - 1\n\n\ntf_input_name = 'input:0'\ntf_output_name = 'MobilenetV1/Predictions/Reshape_1:0'\nwith tf.Session(graph = g) as sess:\n    tf_out = sess.run(tf_output_name, \n                      feed_dict={tf_input_name: img_tf})\ntf_out = tf_out.flatten()    \nidx = np.argmax(tf_out)\nlabel_file = 'labels.txt' \nwith open(label_file) as f:\n    labels = f.readlines()\n    \nprint('\\n')\nprint(\"TF prediction class = {}, probability = {}\".format(labels[idx],\n                                            str(tf_out[idx])))\n\nit shows:\nimage shape: (224, 224, 3)\nfirst few values:  [39. 33. 18. 42.] max value:  255.0\nTF prediction class = 208:golden retriever\n, probability = 0.9581951\n#while for when  I use tensorflow/example/label_image/label_image.py the result is different:\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef load_graph(model_file):\n  graph = tf.Graph()\n  graph_def = tf.GraphDef()\n\n  with open(model_file, \"rb\") as f:\n    graph_def.ParseFromString(f.read())\n  with graph.as_default():\n    tf.import_graph_def(graph_def)\n\n  return graph\n\n\ndef read_tensor_from_image_file(file_name,\n                                input_height=224,\n                                input_width=224,\n                                input_mean=0,\n                                input_std=255):\n  input_name = \"file_reader\"\n  output_name = \"normalized\"\n  file_reader = tf.read_file(file_name, input_name)\n  if file_name.endswith(\".png\"):\n    image_reader = tf.image.decode_png(\n        file_reader, channels=3, name=\"png_reader\")\n  elif file_name.endswith(\".gif\"):\n    image_reader = tf.squeeze(\n        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n  elif file_name.endswith(\".bmp\"):\n    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n  else:\n    image_reader = tf.image.decode_jpeg(\n        file_reader, channels=3, name=\"jpeg_reader\")\n  float_caster = tf.cast(image_reader, tf.float32)\n  dims_expander = tf.expand_dims(float_caster, 0)\n  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n  normalized = tf.subtract(tf.divide(resized,[input_std]),[input_mean])\n  sess = tf.Session()\n  result = sess.run(normalized)\n\n  return result\n\n\ndef load_labels(label_file):\n  label = []\n  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n  for l in proto_as_ascii_lines:\n    label.append(l.rstrip())\n  return label\n\n\nif __name__ == \"__main__\":\n  file_name = \"./data/test.jpg\"\n  model_file = \\\n    \"./data/frozen_graph.pb\"\n  label_file = \"./data/labels.txt\"\n  input_height = 224\n  input_width = 224\n  input_mean = 1\n  input_std = 255/2\n  input_layer = \"input\"\n  output_layer = \"MobilenetV1/Predictions/Reshape_1\"\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\"--image\", help=\"image to be processed\")\n  parser.add_argument(\"--graph\", help=\"graph/model to be executed\")\n  parser.add_argument(\"--labels\", help=\"name of file containing labels\")\n  parser.add_argument(\"--input_height\", type=int, help=\"input height\")\n  parser.add_argument(\"--input_width\", type=int, help=\"input width\")\n  parser.add_argument(\"--input_mean\", type=int, help=\"input mean\")\n  parser.add_argument(\"--input_std\", type=int, help=\"input std\")\n  parser.add_argument(\"--input_layer\", help=\"name of input layer\")\n  parser.add_argument(\"--output_layer\", help=\"name of output layer\")\n  args = parser.parse_args()\n\n  if args.graph:\n    model_file = args.graph\n  if args.image:\n    file_name = args.image\n  if args.labels:\n    label_file = args.labels\n  if args.input_height:\n    input_height = args.input_height\n  if args.input_width:\n    input_width = args.input_width\n  if args.input_mean:\n    input_mean = args.input_mean\n  if args.input_std:\n    input_std = args.input_std\n  if args.input_layer:\n    input_layer = args.input_layer\n  if args.output_layer:\n    output_layer = args.output_layer\n\n  graph = load_graph(model_file)\n  t = read_tensor_from_image_file(\n      file_name,\n      input_height=input_height,\n      input_width=input_width,\n      input_mean=input_mean,\n      input_std=input_std)\n\n  input_name = \"import/\" + input_layer\n  output_name = \"import/\" + output_layer\n  input_operation = graph.get_operation_by_name(input_name)\n  output_operation = graph.get_operation_by_name(output_name)\n\n  with tf.Session(graph=graph) as sess:\n    results = sess.run(output_operation.outputs[0], {\n        input_operation.outputs[0]: t\n    })\n  results = np.squeeze(results)\n\n  top_k = results.argsort()[-5:][::-1]\n  labels = load_labels(label_file)\n  for i in top_k:\n    print(labels[i], results[i])\n\n`208:golden retriever 0.83966106\n209:Labrador retriever 0.033579364\n213:English setter 0.024712995\n274:dingo, warrigal, warragal, Canis dingo 0.01596725\n217:clumber, clumber spaniel 0.010608253\nif I change std =255 mean=0 it shows 208:golden retriever 0.7953789\n213:English setter 0.03927898\n217:clumber, clumber spaniel 0.028547956\n209:Labrador retriever 0.025497263\n221:Sussex spaniel 0.013308002", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NO\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**: 0.17.2\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:  No\r\n- **GPU model and memory**: No\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI compared official code for mobilenet v1 on both python and C++ and find some performance drop.  \r\nmodel: https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\r\nI use mobilenet_v1_224\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\nThe model and input data are **EXACTLY SAME** \r\n\r\nI doubt the problem is the mean and std in label_image.py but I couldn't make the prediction as same as the above inference. \r\n\r\nThe label_image.py comes from tensorflow/example/label_image/label_image.py. Just change inception to mobilenet. \r\n\r\n```\r\nimport tensorflow as tf\r\ntf_model_path = './frozen_graph.pb'\r\nwith open(tf_model_path, 'rb') as f:\r\n    serialized = f.read()\r\ntf.reset_default_graph()\r\noriginal_gdef = tf.GraphDef()\r\noriginal_gdef.ParseFromString(serialized)\r\n\r\nimport numpy as np\r\nimport PIL\r\nimport requests\r\nfrom io import BytesIO\r\nfrom matplotlib.pyplot import imshow\r\nimg_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'\r\nresponse = requests.get(img_url)\r\n%matplotlib inline\r\nimg = PIL.Image.open(BytesIO(response.content))\r\nimshow(np.asarray(img))\r\nimg = img.resize([224,224], PIL.Image.ANTIALIAS)\r\n\r\nimg_np = np.array(img).astype(np.float32)\r\nprint( 'image shape:', img_np.shape)\r\nprint( 'first few values: ', img_np.flatten()[0:4], 'max value: ', np.amax(img_np))\r\nimg_tf = np.expand_dims(img_np, axis = 0) #now shape is [1,224,224,3] as required by TF\r\nimg_tf = (2.0/255.0) * img_tf - 1\r\n\r\n\r\ntf_input_name = 'input:0'\r\ntf_output_name = 'MobilenetV1/Predictions/Reshape_1:0'\r\nwith tf.Session(graph = g) as sess:\r\n    tf_out = sess.run(tf_output_name, \r\n                      feed_dict={tf_input_name: img_tf})\r\ntf_out = tf_out.flatten()    \r\nidx = np.argmax(tf_out)\r\nlabel_file = 'labels.txt' \r\nwith open(label_file) as f:\r\n    labels = f.readlines()\r\n    \r\nprint('\\n')\r\nprint(\"TF prediction class = {}, probability = {}\".format(labels[idx],\r\n                                            str(tf_out[idx])))\r\n```\r\n\r\nit shows: \r\nimage shape: (224, 224, 3)\r\nfirst few values:  [39. 33. 18. 42.] max value:  255.0\r\nTF prediction class = 208:golden retriever\r\n, probability = 0.9581951\r\n\r\n#while for when  I use tensorflow/example/label_image/label_image.py the result is different:\r\n\r\n```\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef load_graph(model_file):\r\n  graph = tf.Graph()\r\n  graph_def = tf.GraphDef()\r\n\r\n  with open(model_file, \"rb\") as f:\r\n    graph_def.ParseFromString(f.read())\r\n  with graph.as_default():\r\n    tf.import_graph_def(graph_def)\r\n\r\n  return graph\r\n\r\n\r\ndef read_tensor_from_image_file(file_name,\r\n                                input_height=224,\r\n                                input_width=224,\r\n                                input_mean=0,\r\n                                input_std=255):\r\n  input_name = \"file_reader\"\r\n  output_name = \"normalized\"\r\n  file_reader = tf.read_file(file_name, input_name)\r\n  if file_name.endswith(\".png\"):\r\n    image_reader = tf.image.decode_png(\r\n        file_reader, channels=3, name=\"png_reader\")\r\n  elif file_name.endswith(\".gif\"):\r\n    image_reader = tf.squeeze(\r\n        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\r\n  elif file_name.endswith(\".bmp\"):\r\n    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\r\n  else:\r\n    image_reader = tf.image.decode_jpeg(\r\n        file_reader, channels=3, name=\"jpeg_reader\")\r\n  float_caster = tf.cast(image_reader, tf.float32)\r\n  dims_expander = tf.expand_dims(float_caster, 0)\r\n  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\r\n  normalized = tf.subtract(tf.divide(resized,[input_std]),[input_mean])\r\n  sess = tf.Session()\r\n  result = sess.run(normalized)\r\n\r\n  return result\r\n\r\n\r\ndef load_labels(label_file):\r\n  label = []\r\n  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\r\n  for l in proto_as_ascii_lines:\r\n    label.append(l.rstrip())\r\n  return label\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  file_name = \"./data/test.jpg\"\r\n  model_file = \\\r\n    \"./data/frozen_graph.pb\"\r\n  label_file = \"./data/labels.txt\"\r\n  input_height = 224\r\n  input_width = 224\r\n  input_mean = 1\r\n  input_std = 255/2\r\n  input_layer = \"input\"\r\n  output_layer = \"MobilenetV1/Predictions/Reshape_1\"\r\n\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\"--image\", help=\"image to be processed\")\r\n  parser.add_argument(\"--graph\", help=\"graph/model to be executed\")\r\n  parser.add_argument(\"--labels\", help=\"name of file containing labels\")\r\n  parser.add_argument(\"--input_height\", type=int, help=\"input height\")\r\n  parser.add_argument(\"--input_width\", type=int, help=\"input width\")\r\n  parser.add_argument(\"--input_mean\", type=int, help=\"input mean\")\r\n  parser.add_argument(\"--input_std\", type=int, help=\"input std\")\r\n  parser.add_argument(\"--input_layer\", help=\"name of input layer\")\r\n  parser.add_argument(\"--output_layer\", help=\"name of output layer\")\r\n  args = parser.parse_args()\r\n\r\n  if args.graph:\r\n    model_file = args.graph\r\n  if args.image:\r\n    file_name = args.image\r\n  if args.labels:\r\n    label_file = args.labels\r\n  if args.input_height:\r\n    input_height = args.input_height\r\n  if args.input_width:\r\n    input_width = args.input_width\r\n  if args.input_mean:\r\n    input_mean = args.input_mean\r\n  if args.input_std:\r\n    input_std = args.input_std\r\n  if args.input_layer:\r\n    input_layer = args.input_layer\r\n  if args.output_layer:\r\n    output_layer = args.output_layer\r\n\r\n  graph = load_graph(model_file)\r\n  t = read_tensor_from_image_file(\r\n      file_name,\r\n      input_height=input_height,\r\n      input_width=input_width,\r\n      input_mean=input_mean,\r\n      input_std=input_std)\r\n\r\n  input_name = \"import/\" + input_layer\r\n  output_name = \"import/\" + output_layer\r\n  input_operation = graph.get_operation_by_name(input_name)\r\n  output_operation = graph.get_operation_by_name(output_name)\r\n\r\n  with tf.Session(graph=graph) as sess:\r\n    results = sess.run(output_operation.outputs[0], {\r\n        input_operation.outputs[0]: t\r\n    })\r\n  results = np.squeeze(results)\r\n\r\n  top_k = results.argsort()[-5:][::-1]\r\n  labels = load_labels(label_file)\r\n  for i in top_k:\r\n    print(labels[i], results[i])\r\n```\r\n`208:golden retriever 0.83966106\r\n209:Labrador retriever 0.033579364\r\n213:English setter 0.024712995\r\n274:dingo, warrigal, warragal, Canis dingo 0.01596725\r\n217:clumber, clumber spaniel 0.010608253\r\n\r\nif I change std =255 mean=0 it shows 208:golden retriever 0.7953789\r\n213:English setter 0.03927898\r\n217:clumber, clumber spaniel 0.028547956\r\n209:Labrador retriever 0.025497263\r\n221:Sussex spaniel 0.013308002"}