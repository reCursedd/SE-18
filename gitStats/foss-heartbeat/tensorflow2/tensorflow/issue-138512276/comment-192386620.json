{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/192386620", "html_url": "https://github.com/tensorflow/tensorflow/issues/1388#issuecomment-192386620", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1388", "id": 192386620, "node_id": "MDEyOklzc3VlQ29tbWVudDE5MjM4NjYyMA==", "user": {"login": "rdipietro", "id": 5150559, "node_id": "MDQ6VXNlcjUxNTA1NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5150559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdipietro", "html_url": "https://github.com/rdipietro", "followers_url": "https://api.github.com/users/rdipietro/followers", "following_url": "https://api.github.com/users/rdipietro/following{/other_user}", "gists_url": "https://api.github.com/users/rdipietro/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdipietro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdipietro/subscriptions", "organizations_url": "https://api.github.com/users/rdipietro/orgs", "repos_url": "https://api.github.com/users/rdipietro/repos", "events_url": "https://api.github.com/users/rdipietro/events{/privacy}", "received_events_url": "https://api.github.com/users/rdipietro/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-04T18:07:06Z", "updated_at": "2016-03-04T18:07:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>What I ended up doing was collecting the variables of the two models separately and computing separate gradients/minimizing ops for each (after debugging as I had assumed that gradients would stop at fed nodes). Thanks though, now I see why it's expected behavior.</p>", "body_text": "What I ended up doing was collecting the variables of the two models separately and computing separate gradients/minimizing ops for each (after debugging as I had assumed that gradients would stop at fed nodes). Thanks though, now I see why it's expected behavior.", "body": "What I ended up doing was collecting the variables of the two models separately and computing separate gradients/minimizing ops for each (after debugging as I had assumed that gradients would stop at fed nodes). Thanks though, now I see why it's expected behavior.\n"}