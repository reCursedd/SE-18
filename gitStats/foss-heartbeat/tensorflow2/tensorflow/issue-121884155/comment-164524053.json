{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164524053", "html_url": "https://github.com/tensorflow/tensorflow/issues/493#issuecomment-164524053", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/493", "id": 164524053, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDUyNDA1Mw==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-14T18:51:07Z", "updated_at": "2015-12-14T18:51:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5890073\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zcyang\">@zcyang</a>, did you try to use CUDA_VISIBLE_DEVICES to limit the set of GPUs you want to use with TF?</p>\n<p>The current TensorFlow works by going through all the GPUs visible to itself, check which one is compatible and assign a logical index to it. Note that this logical index might be different from your system device index. Then in your graph, you use the TensorFlow logic index to refer to each device. So all the devices will be occupied, regardless which one will be actually used later.</p>\n<p>If you don't want a device to be used by TensorFlow, one solution is to use CUDA_VISIBLE_DEVICES and make it invisible.</p>", "body_text": "@zcyang, did you try to use CUDA_VISIBLE_DEVICES to limit the set of GPUs you want to use with TF?\nThe current TensorFlow works by going through all the GPUs visible to itself, check which one is compatible and assign a logical index to it. Note that this logical index might be different from your system device index. Then in your graph, you use the TensorFlow logic index to refer to each device. So all the devices will be occupied, regardless which one will be actually used later.\nIf you don't want a device to be used by TensorFlow, one solution is to use CUDA_VISIBLE_DEVICES and make it invisible.", "body": "@zcyang, did you try to use CUDA_VISIBLE_DEVICES to limit the set of GPUs you want to use with TF? \n\nThe current TensorFlow works by going through all the GPUs visible to itself, check which one is compatible and assign a logical index to it. Note that this logical index might be different from your system device index. Then in your graph, you use the TensorFlow logic index to refer to each device. So all the devices will be occupied, regardless which one will be actually used later. \n\nIf you don't want a device to be used by TensorFlow, one solution is to use CUDA_VISIBLE_DEVICES and make it invisible. \n"}