{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17128", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17128/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17128/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17128/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17128", "id": 298282009, "node_id": "MDU6SXNzdWUyOTgyODIwMDk=", "number": 17128, "title": "How can I get kernel wait time for GPU", "user": {"login": "sj6077", "id": 2465713, "node_id": "MDQ6VXNlcjI0NjU3MTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2465713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sj6077", "html_url": "https://github.com/sj6077", "followers_url": "https://api.github.com/users/sj6077/followers", "following_url": "https://api.github.com/users/sj6077/following{/other_user}", "gists_url": "https://api.github.com/users/sj6077/gists{/gist_id}", "starred_url": "https://api.github.com/users/sj6077/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sj6077/subscriptions", "organizations_url": "https://api.github.com/users/sj6077/orgs", "repos_url": "https://api.github.com/users/sj6077/repos", "events_url": "https://api.github.com/users/sj6077/events{/privacy}", "received_events_url": "https://api.github.com/users/sj6077/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-19T13:51:09Z", "updated_at": "2018-02-26T19:55:42Z", "closed_at": "2018-02-26T19:55:42Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nr1.5</li>\n<li><strong>Python version</strong>:<br>\n2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.5.4</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n9.0/7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nTitan XP, 12GB</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nYou can collect some of this information using our environment capture script:</li>\n</ul>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>I've tested the code to get kernel queue wait time for GPU, but GPU kernel time is constants even though the number of operations is increased. Instead, the CPU kernel time is changed like below.<br>\nCan I get the information to analyze the results? Moreover, profiling of kernel queue wait time would be useful. Do you have any plan to add that kind of features?</p>\n<p>#ops| GPU kernel time(us)| CPU kernel time (us)<br>\n50 | 1862 | 184<br>\n100 | 1746 | 181<br>\n150 |  1750 | 167<br>\n200 | 1750 | 173<br>\n250 | 1751 | 307<br>\n300 | 1756 | 551<br>\n350 | 1757 | 721<br>\n400 | 1767 | 859<br>\n450 | 1767 | 959</p>\n<h3>Source code / logs</h3>\n<pre><code>```\nopts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\nopts['min_accelerator_micros'] = 1\nrun_metadata = tf.RunMetadata()\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n#config.allow_soft_placement = True\nconfig.inter_op_parallelism_threads=0\nconfig.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\nwith tf.Session(config=config) as sess:\n  sess.run(tf.global_variables_initializer())\n  #sess.run(conv_ops)\n  #print('first itereation ends')\n  #sess.run(conv_ops)\n  sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\n\n  sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\n\nroot_node = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n              tf.get_default_graph(),\n              run_meta=run_metadata,\n              tfprof_options=opts)\n</code></pre>\n<pre><code></code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nsource\nTensorFlow version (use command below):\nr1.5\nPython version:\n2\nBazel version (if compiling from source):\n0.5.4\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\n9.0/7.0\nGPU model and memory:\nTitan XP, 12GB\nExact command to reproduce:\nYou can collect some of this information using our environment capture script:\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nI've tested the code to get kernel queue wait time for GPU, but GPU kernel time is constants even though the number of operations is increased. Instead, the CPU kernel time is changed like below.\nCan I get the information to analyze the results? Moreover, profiling of kernel queue wait time would be useful. Do you have any plan to add that kind of features?\n#ops| GPU kernel time(us)| CPU kernel time (us)\n50 | 1862 | 184\n100 | 1746 | 181\n150 |  1750 | 167\n200 | 1750 | 173\n250 | 1751 | 307\n300 | 1756 | 551\n350 | 1757 | 721\n400 | 1767 | 859\n450 | 1767 | 959\nSource code / logs\n```\nopts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\nopts['min_accelerator_micros'] = 1\nrun_metadata = tf.RunMetadata()\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n#config.allow_soft_placement = True\nconfig.inter_op_parallelism_threads=0\nconfig.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\nwith tf.Session(config=config) as sess:\n  sess.run(tf.global_variables_initializer())\n  #sess.run(conv_ops)\n  #print('first itereation ends')\n  #sess.run(conv_ops)\n  sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\n\n  sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\n\nroot_node = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n              tf.get_default_graph(),\n              run_meta=run_metadata,\n              tfprof_options=opts)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nr1.5\r\n- **Python version**: \r\n2\r\n- **Bazel version (if compiling from source)**:\r\n0.5.4\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0\r\n- **GPU model and memory**:\r\nTitan XP, 12GB\r\n- **Exact command to reproduce**:\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI've tested the code to get kernel queue wait time for GPU, but GPU kernel time is constants even though the number of operations is increased. Instead, the CPU kernel time is changed like below.\r\nCan I get the information to analyze the results? Moreover, profiling of kernel queue wait time would be useful. Do you have any plan to add that kind of features?\r\n\r\n#ops| GPU kernel time(us)| CPU kernel time (us)\r\n50 | 1862 | 184\r\n100 | 1746 | 181\r\n150 |  1750 | 167\r\n200 | 1750 | 173\r\n250 | 1751 | 307\r\n300 | 1756 | 551\r\n350 | 1757 | 721\r\n400 | 1767 | 859\r\n450 | 1767 | 959\r\n\r\n \r\n\r\n### Source code / logs\r\n    ```\r\n    opts = tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY\r\n    opts['min_accelerator_micros'] = 1\r\n    run_metadata = tf.RunMetadata()\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    #config.allow_soft_placement = True\r\n    config.inter_op_parallelism_threads=0\r\n    config.graph_options.optimizer_options.opt_level = tf.OptimizerOptions.L0\r\n    with tf.Session(config=config) as sess:\r\n      sess.run(tf.global_variables_initializer())\r\n      #sess.run(conv_ops)\r\n      #print('first itereation ends')\r\n      #sess.run(conv_ops)\r\n      sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\r\n\r\n      sess.run(conv_ops, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\r\n\r\n    root_node = tf.contrib.tfprof.model_analyzer.print_model_analysis(\r\n                  tf.get_default_graph(),\r\n                  run_meta=run_metadata,\r\n                  tfprof_options=opts)\r\n```"}