{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19949", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19949/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19949/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19949/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19949", "id": 331708980, "node_id": "MDU6SXNzdWUzMzE3MDg5ODA=", "number": 19949, "title": "toco error when converting tensorflow (Alexnet caffe model converted to tensorflow using MMdnn) to tflite", "user": {"login": "rohith-k-sturfee", "id": 39924604, "node_id": "MDQ6VXNlcjM5OTI0NjA0", "avatar_url": "https://avatars1.githubusercontent.com/u/39924604?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohith-k-sturfee", "html_url": "https://github.com/rohith-k-sturfee", "followers_url": "https://api.github.com/users/rohith-k-sturfee/followers", "following_url": "https://api.github.com/users/rohith-k-sturfee/following{/other_user}", "gists_url": "https://api.github.com/users/rohith-k-sturfee/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohith-k-sturfee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohith-k-sturfee/subscriptions", "organizations_url": "https://api.github.com/users/rohith-k-sturfee/orgs", "repos_url": "https://api.github.com/users/rohith-k-sturfee/repos", "events_url": "https://api.github.com/users/rohith-k-sturfee/events{/privacy}", "received_events_url": "https://api.github.com/users/rohith-k-sturfee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-06-12T18:47:52Z", "updated_at": "2018-11-21T21:08:15Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Mac OS High Sierra</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.1</li>\n<li><strong>Python version</strong>: 2.7.15</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Apple LLVM version 9.1.0 (clang-902.0.39.2)</li>\n<li><strong>CUDA/cuDNN version</strong>: No</li>\n<li><strong>GPU model and memory</strong>:No</li>\n<li><strong>Exact command to reproduce</strong>: toco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3</li>\n</ul>\n<p>Hi,</p>\n<p>I have a caffe model (Retrained Alexnet), converted this into tensorflow model using following commands. (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"277994363\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/Microsoft/MMdnn/issues/10\" data-hovercard-type=\"issue\" data-hovercard-url=\"/Microsoft/MMdnn/issues/10/hovercard\" href=\"https://github.com/Microsoft/MMdnn/issues/10\">Microsoft/MMdnn#10</a>)</p>\n<p><code>python -m mmdnn.conversion._script.convertToIR -f caffe -d kit_imagenet -n examples/caffe/models/bvlc_alexnet.prototxt -w examples/caffe/models/bvlc_alexnet.caffemodel</code></p>\n<p><code>python -m mmdnn.conversion._script.IRToCode -f tensorflow --IRModelPath kit_imagenet.pb --dstModelPath kit_imagenet.py -w kit_imagenet.npy</code></p>\n<p>It generated python file kit_imagenet.py and numpy weights kit_imagenet.npy.<br>\nKit_imagenet.py looks like this</p>\n<pre><code>import tensorflow as tf\n__weights_dict = dict()\nis_train = False\n\ndef load_weights(weight_file):\n    import numpy as np\n    if weight_file == None:\n        return\n    try:\n        weights_dict = np.load(weight_file).item()\n    except:\n        weights_dict = np.load(weight_file, encoding='bytes').item()\n    return weights_dict\n\ndef KitModel(weight_file = None):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n\n    data            = tf.placeholder(tf.float32, shape = (None, 227, 227, 3), name = 'input')\n    conv1_pad       = tf.pad(data, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]])\n    conv1           = convolution(conv1_pad, group=1, strides=[4, 4], padding='VALID', name='conv1')\n    relu1           = tf.nn.relu(conv1, name = 'relu1')\n    pool1_pad       = tf.pad(relu1, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool1           = tf.nn.max_pool(pool1_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool1')\n    norm1           = tf.nn.lrn(pool1, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm1')\n    conv2_pad       = tf.pad(norm1, paddings = [[0L, 0L], [2L, 2L], [2L, 2L], [0L, 0L]])\n    conv2           = convolution(conv2_pad, group=2, strides=[1, 1], padding='VALID', name='conv2')\n    relu2           = tf.nn.relu(conv2, name = 'relu2')\n    pool2_pad       = tf.pad(relu2, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool2           = tf.nn.max_pool(pool2_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool2')\n    norm2           = tf.nn.lrn(pool2, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm2')\n    conv3_pad       = tf.pad(norm2, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv3           = convolution(conv3_pad, group=1, strides=[1, 1], padding='VALID', name='conv3')\n    relu3           = tf.nn.relu(conv3, name = 'relu3')\n    conv4_pad       = tf.pad(relu3, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv4           = convolution(conv4_pad, group=2, strides=[1, 1], padding='VALID', name='conv4')\n    relu4           = tf.nn.relu(conv4, name = 'relu4')\n    conv5_pad       = tf.pad(relu4, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv5           = convolution(conv5_pad, group=2, strides=[1, 1], padding='VALID', name='conv5')\n    relu5           = tf.nn.relu(conv5, name = 'relu5')\n    pool5_pad       = tf.pad(relu5, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool5           = tf.nn.max_pool(pool5_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool5')\n    fc6_0           = tf.contrib.layers.flatten(pool5)\n    fc6_1           = tf.layers.dense(fc6_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc6_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc6_1']['bias']), use_bias = True)\n    relu6           = tf.nn.relu(fc6_1, name = 'relu6')\n    fc7_0           = tf.contrib.layers.flatten(relu6)\n    fc7_1           = tf.layers.dense(fc7_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc7_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc7_1']['bias']), use_bias = True)\n    relu7           = tf.nn.relu(fc7_1, name = 'relu7')\n    fc8_indoor_outdoor_0 = tf.contrib.layers.flatten(relu7)\n    fc8_indoor_outdoor_1 = tf.layers.dense(fc8_indoor_outdoor_0, 2, kernel_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['bias']), use_bias = True)\n    prob            = tf.nn.softmax(fc8_indoor_outdoor_1, name = 'output')\n    return data, prob\n\ndef convolution(input, name, group, **kwargs):\n    w = tf.Variable(__weights_dict[name]['weights'], trainable=is_train, name=name + \"_weight\")\n    if group == 1:\n        layer = tf.nn.convolution(input, w, **kwargs)\n    else:\n        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)\n        xs = tf.split(input, num_or_size_splits=group, axis=-1)\n        convolved = [tf.nn.convolution(x, weight, **kwargs) for\n                    (x, weight) in zip(xs, weight_groups)]\n        layer = tf.concat(convolved, axis=-1)\n\n    if 'bias' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name]['bias'], trainable=is_train, name=name + \"_bias\")\n        layer = layer + b\n    return layer\n\n</code></pre>\n<p>I then wrote a script which uses kit_imagenet.py and numpy weights kit_imagenet.npy to create freezed model</p>\n<pre><code>import tensorflow as tf\nfrom freeze_graph import freeze_graph # tensorflow comes up with a tool allowing freeze graph\nfrom kit_imagenet import KitModel\nfrom tensorflow.python.framework import graph_util\nimport os\n\ndata_node, prob_node = KitModel('kit_imagenet.npy')\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\n\nmodel_dir = './saved_model'\nMODEL_NAME = \"inorout\"\n\nsaver = tf.train.Saver()\nsaver.save(sess, os.path.join(model_dir,MODEL_NAME), global_step=0, latest_filename='chkpt_state')\n\ngraph_def = tf.get_default_graph().as_graph_def()\noutput_graph = graph_util.convert_variables_to_constants(sess, graph_def, ['output'])\nwith tf.gfile.GFile(os.path.join(model_dir, MODEL_NAME + '.pb'), 'wb') as f:\n    f.write(output_graph.SerializeToString())\n</code></pre>\n<p>After having freezed model, I converted to optimized version of protobuf using (tensorflow.python.tools.optimize_for_inference ). now i have 'inference_inorout.pb'.</p>\n<p>Now I am trying to converted this optimized version of protobuf to tflite model, but it shows errors!</p>\n<pre><code>\ntoco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3\n2018-06-12 10:53:52.151081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.153847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.161334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.457117: F tensorflow/contrib/lite/toco/tooling_util.cc:842] Check failed: name.substr(colon_pos + 1).find_first_not_of(\"0123456789\") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon\nAbort trap: 6 ```\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS High Sierra\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7.1\nPython version: 2.7.15\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source): Apple LLVM version 9.1.0 (clang-902.0.39.2)\nCUDA/cuDNN version: No\nGPU model and memory:No\nExact command to reproduce: toco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3\n\nHi,\nI have a caffe model (Retrained Alexnet), converted this into tensorflow model using following commands. (Microsoft/MMdnn#10)\npython -m mmdnn.conversion._script.convertToIR -f caffe -d kit_imagenet -n examples/caffe/models/bvlc_alexnet.prototxt -w examples/caffe/models/bvlc_alexnet.caffemodel\npython -m mmdnn.conversion._script.IRToCode -f tensorflow --IRModelPath kit_imagenet.pb --dstModelPath kit_imagenet.py -w kit_imagenet.npy\nIt generated python file kit_imagenet.py and numpy weights kit_imagenet.npy.\nKit_imagenet.py looks like this\nimport tensorflow as tf\n__weights_dict = dict()\nis_train = False\n\ndef load_weights(weight_file):\n    import numpy as np\n    if weight_file == None:\n        return\n    try:\n        weights_dict = np.load(weight_file).item()\n    except:\n        weights_dict = np.load(weight_file, encoding='bytes').item()\n    return weights_dict\n\ndef KitModel(weight_file = None):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n\n    data            = tf.placeholder(tf.float32, shape = (None, 227, 227, 3), name = 'input')\n    conv1_pad       = tf.pad(data, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]])\n    conv1           = convolution(conv1_pad, group=1, strides=[4, 4], padding='VALID', name='conv1')\n    relu1           = tf.nn.relu(conv1, name = 'relu1')\n    pool1_pad       = tf.pad(relu1, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool1           = tf.nn.max_pool(pool1_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool1')\n    norm1           = tf.nn.lrn(pool1, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm1')\n    conv2_pad       = tf.pad(norm1, paddings = [[0L, 0L], [2L, 2L], [2L, 2L], [0L, 0L]])\n    conv2           = convolution(conv2_pad, group=2, strides=[1, 1], padding='VALID', name='conv2')\n    relu2           = tf.nn.relu(conv2, name = 'relu2')\n    pool2_pad       = tf.pad(relu2, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool2           = tf.nn.max_pool(pool2_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool2')\n    norm2           = tf.nn.lrn(pool2, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm2')\n    conv3_pad       = tf.pad(norm2, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv3           = convolution(conv3_pad, group=1, strides=[1, 1], padding='VALID', name='conv3')\n    relu3           = tf.nn.relu(conv3, name = 'relu3')\n    conv4_pad       = tf.pad(relu3, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv4           = convolution(conv4_pad, group=2, strides=[1, 1], padding='VALID', name='conv4')\n    relu4           = tf.nn.relu(conv4, name = 'relu4')\n    conv5_pad       = tf.pad(relu4, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\n    conv5           = convolution(conv5_pad, group=2, strides=[1, 1], padding='VALID', name='conv5')\n    relu5           = tf.nn.relu(conv5, name = 'relu5')\n    pool5_pad       = tf.pad(relu5, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\n    pool5           = tf.nn.max_pool(pool5_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool5')\n    fc6_0           = tf.contrib.layers.flatten(pool5)\n    fc6_1           = tf.layers.dense(fc6_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc6_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc6_1']['bias']), use_bias = True)\n    relu6           = tf.nn.relu(fc6_1, name = 'relu6')\n    fc7_0           = tf.contrib.layers.flatten(relu6)\n    fc7_1           = tf.layers.dense(fc7_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc7_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc7_1']['bias']), use_bias = True)\n    relu7           = tf.nn.relu(fc7_1, name = 'relu7')\n    fc8_indoor_outdoor_0 = tf.contrib.layers.flatten(relu7)\n    fc8_indoor_outdoor_1 = tf.layers.dense(fc8_indoor_outdoor_0, 2, kernel_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['bias']), use_bias = True)\n    prob            = tf.nn.softmax(fc8_indoor_outdoor_1, name = 'output')\n    return data, prob\n\ndef convolution(input, name, group, **kwargs):\n    w = tf.Variable(__weights_dict[name]['weights'], trainable=is_train, name=name + \"_weight\")\n    if group == 1:\n        layer = tf.nn.convolution(input, w, **kwargs)\n    else:\n        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)\n        xs = tf.split(input, num_or_size_splits=group, axis=-1)\n        convolved = [tf.nn.convolution(x, weight, **kwargs) for\n                    (x, weight) in zip(xs, weight_groups)]\n        layer = tf.concat(convolved, axis=-1)\n\n    if 'bias' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name]['bias'], trainable=is_train, name=name + \"_bias\")\n        layer = layer + b\n    return layer\n\n\nI then wrote a script which uses kit_imagenet.py and numpy weights kit_imagenet.npy to create freezed model\nimport tensorflow as tf\nfrom freeze_graph import freeze_graph # tensorflow comes up with a tool allowing freeze graph\nfrom kit_imagenet import KitModel\nfrom tensorflow.python.framework import graph_util\nimport os\n\ndata_node, prob_node = KitModel('kit_imagenet.npy')\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\n\nmodel_dir = './saved_model'\nMODEL_NAME = \"inorout\"\n\nsaver = tf.train.Saver()\nsaver.save(sess, os.path.join(model_dir,MODEL_NAME), global_step=0, latest_filename='chkpt_state')\n\ngraph_def = tf.get_default_graph().as_graph_def()\noutput_graph = graph_util.convert_variables_to_constants(sess, graph_def, ['output'])\nwith tf.gfile.GFile(os.path.join(model_dir, MODEL_NAME + '.pb'), 'wb') as f:\n    f.write(output_graph.SerializeToString())\n\nAfter having freezed model, I converted to optimized version of protobuf using (tensorflow.python.tools.optimize_for_inference ). now i have 'inference_inorout.pb'.\nNow I am trying to converted this optimized version of protobuf to tflite model, but it shows errors!\n\ntoco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3\n2018-06-12 10:53:52.151081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.153847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.161334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\n2018-06-12 10:53:52.457117: F tensorflow/contrib/lite/toco/tooling_util.cc:842] Check failed: name.substr(colon_pos + 1).find_first_not_of(\"0123456789\") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon\nAbort trap: 6 ```", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS High Sierra\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.1\r\n- **Python version**: 2.7.15\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)\r\n- **CUDA/cuDNN version**: No\r\n- **GPU model and memory**:No \r\n- **Exact command to reproduce**: toco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3\r\n\r\nHi,\r\n\r\nI have a caffe model (Retrained Alexnet), converted this into tensorflow model using following commands. (https://github.com/Microsoft/MMdnn/issues/10)\r\n\r\n```python -m mmdnn.conversion._script.convertToIR -f caffe -d kit_imagenet -n examples/caffe/models/bvlc_alexnet.prototxt -w examples/caffe/models/bvlc_alexnet.caffemodel```\r\n\r\n```python -m mmdnn.conversion._script.IRToCode -f tensorflow --IRModelPath kit_imagenet.pb --dstModelPath kit_imagenet.py -w kit_imagenet.npy``` \r\n\r\nIt generated python file kit_imagenet.py and numpy weights kit_imagenet.npy.\r\nKit_imagenet.py looks like this\r\n```\r\nimport tensorflow as tf\r\n__weights_dict = dict()\r\nis_train = False\r\n\r\ndef load_weights(weight_file):\r\n    import numpy as np\r\n    if weight_file == None:\r\n        return\r\n    try:\r\n        weights_dict = np.load(weight_file).item()\r\n    except:\r\n        weights_dict = np.load(weight_file, encoding='bytes').item()\r\n    return weights_dict\r\n\r\ndef KitModel(weight_file = None):\r\n    global __weights_dict\r\n    __weights_dict = load_weights(weight_file)\r\n\r\n    data            = tf.placeholder(tf.float32, shape = (None, 227, 227, 3), name = 'input')\r\n    conv1_pad       = tf.pad(data, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]])\r\n    conv1           = convolution(conv1_pad, group=1, strides=[4, 4], padding='VALID', name='conv1')\r\n    relu1           = tf.nn.relu(conv1, name = 'relu1')\r\n    pool1_pad       = tf.pad(relu1, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\r\n    pool1           = tf.nn.max_pool(pool1_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool1')\r\n    norm1           = tf.nn.lrn(pool1, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm1')\r\n    conv2_pad       = tf.pad(norm1, paddings = [[0L, 0L], [2L, 2L], [2L, 2L], [0L, 0L]])\r\n    conv2           = convolution(conv2_pad, group=2, strides=[1, 1], padding='VALID', name='conv2')\r\n    relu2           = tf.nn.relu(conv2, name = 'relu2')\r\n    pool2_pad       = tf.pad(relu2, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\r\n    pool2           = tf.nn.max_pool(pool2_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool2')\r\n    norm2           = tf.nn.lrn(pool2, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm2')\r\n    conv3_pad       = tf.pad(norm2, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\r\n    conv3           = convolution(conv3_pad, group=1, strides=[1, 1], padding='VALID', name='conv3')\r\n    relu3           = tf.nn.relu(conv3, name = 'relu3')\r\n    conv4_pad       = tf.pad(relu3, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\r\n    conv4           = convolution(conv4_pad, group=2, strides=[1, 1], padding='VALID', name='conv4')\r\n    relu4           = tf.nn.relu(conv4, name = 'relu4')\r\n    conv5_pad       = tf.pad(relu4, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])\r\n    conv5           = convolution(conv5_pad, group=2, strides=[1, 1], padding='VALID', name='conv5')\r\n    relu5           = tf.nn.relu(conv5, name = 'relu5')\r\n    pool5_pad       = tf.pad(relu5, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))\r\n    pool5           = tf.nn.max_pool(pool5_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool5')\r\n    fc6_0           = tf.contrib.layers.flatten(pool5)\r\n    fc6_1           = tf.layers.dense(fc6_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc6_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc6_1']['bias']), use_bias = True)\r\n    relu6           = tf.nn.relu(fc6_1, name = 'relu6')\r\n    fc7_0           = tf.contrib.layers.flatten(relu6)\r\n    fc7_1           = tf.layers.dense(fc7_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc7_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc7_1']['bias']), use_bias = True)\r\n    relu7           = tf.nn.relu(fc7_1, name = 'relu7')\r\n    fc8_indoor_outdoor_0 = tf.contrib.layers.flatten(relu7)\r\n    fc8_indoor_outdoor_1 = tf.layers.dense(fc8_indoor_outdoor_0, 2, kernel_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['bias']), use_bias = True)\r\n    prob            = tf.nn.softmax(fc8_indoor_outdoor_1, name = 'output')\r\n    return data, prob\r\n\r\ndef convolution(input, name, group, **kwargs):\r\n    w = tf.Variable(__weights_dict[name]['weights'], trainable=is_train, name=name + \"_weight\")\r\n    if group == 1:\r\n        layer = tf.nn.convolution(input, w, **kwargs)\r\n    else:\r\n        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)\r\n        xs = tf.split(input, num_or_size_splits=group, axis=-1)\r\n        convolved = [tf.nn.convolution(x, weight, **kwargs) for\r\n                    (x, weight) in zip(xs, weight_groups)]\r\n        layer = tf.concat(convolved, axis=-1)\r\n\r\n    if 'bias' in __weights_dict[name]:\r\n        b = tf.Variable(__weights_dict[name]['bias'], trainable=is_train, name=name + \"_bias\")\r\n        layer = layer + b\r\n    return layer\r\n\r\n```\r\n\r\n\r\nI then wrote a script which uses kit_imagenet.py and numpy weights kit_imagenet.npy to create freezed model\r\n```\r\nimport tensorflow as tf\r\nfrom freeze_graph import freeze_graph # tensorflow comes up with a tool allowing freeze graph\r\nfrom kit_imagenet import KitModel\r\nfrom tensorflow.python.framework import graph_util\r\nimport os\r\n\r\ndata_node, prob_node = KitModel('kit_imagenet.npy')\r\nsess = tf.InteractiveSession()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nmodel_dir = './saved_model'\r\nMODEL_NAME = \"inorout\"\r\n\r\nsaver = tf.train.Saver()\r\nsaver.save(sess, os.path.join(model_dir,MODEL_NAME), global_step=0, latest_filename='chkpt_state')\r\n\r\ngraph_def = tf.get_default_graph().as_graph_def()\r\noutput_graph = graph_util.convert_variables_to_constants(sess, graph_def, ['output'])\r\nwith tf.gfile.GFile(os.path.join(model_dir, MODEL_NAME + '.pb'), 'wb') as f:\r\n    f.write(output_graph.SerializeToString())\r\n```\r\n\r\nAfter having freezed model, I converted to optimized version of protobuf using (tensorflow.python.tools.optimize_for_inference ). now i have 'inference_inorout.pb'.\r\n\r\nNow I am trying to converted this optimized version of protobuf to tflite model, but it shows errors!\r\n\r\n```\r\n\r\ntoco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3\r\n2018-06-12 10:53:52.151081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\r\n2018-06-12 10:53:52.153847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\r\n2018-06-12 10:53:52.161334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2\r\n2018-06-12 10:53:52.457117: F tensorflow/contrib/lite/toco/tooling_util.cc:842] Check failed: name.substr(colon_pos + 1).find_first_not_of(\"0123456789\") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon\r\nAbort trap: 6 ```\r\n"}