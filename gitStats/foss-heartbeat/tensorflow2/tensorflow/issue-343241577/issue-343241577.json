{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21001", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21001/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21001/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21001/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21001", "id": 343241577, "node_id": "MDU6SXNzdWUzNDMyNDE1Nzc=", "number": 21001, "title": "Error during tf.evaluate when running on TPU: RuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar ", "user": {"login": "mrezak", "id": 4903456, "node_id": "MDQ6VXNlcjQ5MDM0NTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/4903456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrezak", "html_url": "https://github.com/mrezak", "followers_url": "https://api.github.com/users/mrezak/followers", "following_url": "https://api.github.com/users/mrezak/following{/other_user}", "gists_url": "https://api.github.com/users/mrezak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrezak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrezak/subscriptions", "organizations_url": "https://api.github.com/users/mrezak/orgs", "repos_url": "https://api.github.com/users/mrezak/repos", "events_url": "https://api.github.com/users/mrezak/events{/privacy}", "received_events_url": "https://api.github.com/users/mrezak/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "angersson", "id": 32465472, "node_id": "MDQ6VXNlcjMyNDY1NDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/32465472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angersson", "html_url": "https://github.com/angersson", "followers_url": "https://api.github.com/users/angersson/followers", "following_url": "https://api.github.com/users/angersson/following{/other_user}", "gists_url": "https://api.github.com/users/angersson/gists{/gist_id}", "starred_url": "https://api.github.com/users/angersson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angersson/subscriptions", "organizations_url": "https://api.github.com/users/angersson/orgs", "repos_url": "https://api.github.com/users/angersson/repos", "events_url": "https://api.github.com/users/angersson/events{/privacy}", "received_events_url": "https://api.github.com/users/angersson/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-07-20T20:42:58Z", "updated_at": "2018-08-01T20:50:05Z", "closed_at": "2018-08-01T20:50:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Google Cloud Platform (Linux Debian)</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.9</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: NA (TPU)</li>\n<li><strong>GPU model and memory</strong>: NA (TPU)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using TPU on GCP to train my model. My model is fully TPU compatible and the training on TPU works as expected when I run <code>model.train(train_input, steps=num_steps)</code>. However, when I want to evaluate the model using <code>train_costs = lfads.evaluate(train_input, name='train_data', steps=100)</code> I get the following error:</p>\n<p><code>RuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)</code></p>\n<p>I constructed the <code>eval_metrics</code> in <code>TPUEstimatorSpec</code> as described in the MNIST example passing a tuple of (metric_fn, [tensors]) as</p>\n<pre><code>def m_fn(input):\n       return {'test':tf.metrics.mean(input)}\ntpu_eval_metrics = (m_fn, [rec_costs])\n</code></pre>\n<p>I used the same <code>input_fn</code> both for train and evaluate. I also used the same <code>TPUEstimatorSpec</code> line in my <code>model_fn</code> for training/evaluation. I cannot figure out what is causing this error and didn't have any luck searching online.</p>\n<p><strong>Note:</strong> I tested the same code but for CPU/GPU and did not run into any errors during evaluation</p>\n<h3>Source code / logs</h3>\n<p><code>RuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)</code></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud Platform (Linux Debian)\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary):Binary\nTensorFlow version (use command below):1.9\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: NA (TPU)\nGPU model and memory: NA (TPU)\nExact command to reproduce:\n\nDescribe the problem\nI am using TPU on GCP to train my model. My model is fully TPU compatible and the training on TPU works as expected when I run model.train(train_input, steps=num_steps). However, when I want to evaluate the model using train_costs = lfads.evaluate(train_input, name='train_data', steps=100) I get the following error:\nRuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)\nI constructed the eval_metrics in TPUEstimatorSpec as described in the MNIST example passing a tuple of (metric_fn, [tensors]) as\ndef m_fn(input):\n       return {'test':tf.metrics.mean(input)}\ntpu_eval_metrics = (m_fn, [rec_costs])\n\nI used the same input_fn both for train and evaluate. I also used the same TPUEstimatorSpec line in my model_fn for training/evaluation. I cannot figure out what is causing this error and didn't have any luck searching online.\nNote: I tested the same code but for CPU/GPU and did not run into any errors during evaluation\nSource code / logs\nRuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Cloud Platform (Linux Debian)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:Binary\r\n- **TensorFlow version (use command below)**:1.9\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: NA (TPU)\r\n- **GPU model and memory**: NA (TPU)\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI am using TPU on GCP to train my model. My model is fully TPU compatible and the training on TPU works as expected when I run `model.train(train_input, steps=num_steps)`. However, when I want to evaluate the model using `train_costs = lfads.evaluate(train_input, name='train_data', steps=100)` I get the following error:\r\n\r\n`RuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)`\r\n\r\nI constructed the `eval_metrics` in `TPUEstimatorSpec` as described in the MNIST example passing a tuple of (metric_fn, [tensors]) as\r\n```\r\ndef m_fn(input):\r\n       return {'test':tf.metrics.mean(input)}\r\ntpu_eval_metrics = (m_fn, [rec_costs])\r\n```\r\n\r\n\r\nI used the same `input_fn` both for train and evaluate. I also used the same `TPUEstimatorSpec` line in my `model_fn` for training/evaluation. I cannot figure out what is causing this error and didn't have any luck searching online. \r\n\r\n**Note:** I tested the same code but for CPU/GPU and did not run into any errors during evaluation\r\n\r\n### Source code / logs\r\n`RuntimeError: All tensors outfed from TPU should preserve batch size dimension, but got scalar Tensor(\"OutfeedDequeueTuple:0\", shape=(), dtype=float32, device=/job:worker/task:0/device:TPU:0)`\r\n"}