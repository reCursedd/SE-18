{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/240196916", "html_url": "https://github.com/tensorflow/tensorflow/issues/3821#issuecomment-240196916", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3821", "id": 240196916, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MDE5NjkxNg==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-16T18:38:55Z", "updated_at": "2016-08-16T18:41:04Z", "author_association": "NONE", "body_html": "<p>For Training:</p>\n<pre><code>import Input\nimport Process\n\nimport time\nimport numpy as np\nimport os\n\nimport tensorflow as tf\nfrom datetime import datetime\n\nFLAGS = tf.app.flags.FLAGS\n\ndef train():\n    with tf.Session() as sess:\n        images, labels = Process.inputs()\n\n        forward_propgation_results = Process.forward_propagation(images)\n\n        train_loss, cost = Process.error(forward_propgation_results, labels)\n\n        image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n        summary_op = tf.merge_all_summaries()\n\n        init = tf.initialize_all_variables()\n\n        saver = tf.train.Saver()\n\n        sess.run(init)\n\n        saver = tf.train.Saver(tf.all_variables())\n\n        tf.train.start_queue_runners(sess = sess)\n\n        train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n        for step in range(100):\n            start_time = time.time()\n            print(sess.run([train_loss, cost]))\n            duration = time.time() - start_time\n            if step % 1 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n\n                if step % 2 == 0:\n                    checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step = step)\n\n\ndef main(argv = None):\n    train()\n\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>For Eval:</p>\n<pre><code>import main\nimport Process\nimport Input\n\neval_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"\ncheckpoint_dir = \"/Users/Zanhuang/Desktop/NNP\"\n\n\ndef evaluate():\n  with tf.Graph().as_default() as g:\n    images, labels = Process.eval_inputs()\n    forward_propgation_results = Process.forward_propagation(images)\n    init_op = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)\n\n  with tf.Session(graph = g) as sess:\n    tf.train.start_queue_runners(sess = sess)\n    sess.run(init_op)\n    saver.restore(sess, eval_dir)\n    for i in range(100):\n        print(sess.run(top_k_op))\n\ndef main(argv = None):\n    evaluate()\n\nif __name__ == '__main__':\n  tf.app.run()\n</code></pre>\n<p>The results of find is:</p>\n<p>/Users/Zanhuang/Desktop/NNP/<br>\n/Users/Zanhuang/Desktop/NNP//.DS_Store<br>\n/Users/Zanhuang/Desktop/NNP//checkpoint<br>\n/Users/Zanhuang/Desktop/NNP//DATA_PREPARE<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/.DS_Store<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/enput.py<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cacer_Data1.bin<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data1.bin<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data2.bin<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data3.bin<br>\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data4.bin</p>", "body_text": "For Training:\nimport Input\nimport Process\n\nimport time\nimport numpy as np\nimport os\n\nimport tensorflow as tf\nfrom datetime import datetime\n\nFLAGS = tf.app.flags.FLAGS\n\ndef train():\n    with tf.Session() as sess:\n        images, labels = Process.inputs()\n\n        forward_propgation_results = Process.forward_propagation(images)\n\n        train_loss, cost = Process.error(forward_propgation_results, labels)\n\n        image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n        summary_op = tf.merge_all_summaries()\n\n        init = tf.initialize_all_variables()\n\n        saver = tf.train.Saver()\n\n        sess.run(init)\n\n        saver = tf.train.Saver(tf.all_variables())\n\n        tf.train.start_queue_runners(sess = sess)\n\n        train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n        for step in range(100):\n            start_time = time.time()\n            print(sess.run([train_loss, cost]))\n            duration = time.time() - start_time\n            if step % 1 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n\n                if step % 2 == 0:\n                    checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step = step)\n\n\ndef main(argv = None):\n    train()\n\nif __name__ == '__main__':\n  tf.app.run()\n\nFor Eval:\nimport main\nimport Process\nimport Input\n\neval_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"\ncheckpoint_dir = \"/Users/Zanhuang/Desktop/NNP\"\n\n\ndef evaluate():\n  with tf.Graph().as_default() as g:\n    images, labels = Process.eval_inputs()\n    forward_propgation_results = Process.forward_propagation(images)\n    init_op = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)\n\n  with tf.Session(graph = g) as sess:\n    tf.train.start_queue_runners(sess = sess)\n    sess.run(init_op)\n    saver.restore(sess, eval_dir)\n    for i in range(100):\n        print(sess.run(top_k_op))\n\ndef main(argv = None):\n    evaluate()\n\nif __name__ == '__main__':\n  tf.app.run()\n\nThe results of find is:\n/Users/Zanhuang/Desktop/NNP/\n/Users/Zanhuang/Desktop/NNP//.DS_Store\n/Users/Zanhuang/Desktop/NNP//checkpoint\n/Users/Zanhuang/Desktop/NNP//DATA_PREPARE\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/.DS_Store\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/enput.py\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cacer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data2.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data3.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data4.bin", "body": "For Training:\n\n```\nimport Input\nimport Process\n\nimport time\nimport numpy as np\nimport os\n\nimport tensorflow as tf\nfrom datetime import datetime\n\nFLAGS = tf.app.flags.FLAGS\n\ndef train():\n    with tf.Session() as sess:\n        images, labels = Process.inputs()\n\n        forward_propgation_results = Process.forward_propagation(images)\n\n        train_loss, cost = Process.error(forward_propgation_results, labels)\n\n        image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n        summary_op = tf.merge_all_summaries()\n\n        init = tf.initialize_all_variables()\n\n        saver = tf.train.Saver()\n\n        sess.run(init)\n\n        saver = tf.train.Saver(tf.all_variables())\n\n        tf.train.start_queue_runners(sess = sess)\n\n        train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n        for step in range(100):\n            start_time = time.time()\n            print(sess.run([train_loss, cost]))\n            duration = time.time() - start_time\n            if step % 1 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n\n                if step % 2 == 0:\n                    checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step = step)\n\n\ndef main(argv = None):\n    train()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nFor Eval:\n\n```\nimport main\nimport Process\nimport Input\n\neval_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"\ncheckpoint_dir = \"/Users/Zanhuang/Desktop/NNP\"\n\n\ndef evaluate():\n  with tf.Graph().as_default() as g:\n    images, labels = Process.eval_inputs()\n    forward_propgation_results = Process.forward_propagation(images)\n    init_op = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)\n\n  with tf.Session(graph = g) as sess:\n    tf.train.start_queue_runners(sess = sess)\n    sess.run(init_op)\n    saver.restore(sess, eval_dir)\n    for i in range(100):\n        print(sess.run(top_k_op))\n\ndef main(argv = None):\n    evaluate()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nThe results of find is:\n\n/Users/Zanhuang/Desktop/NNP/\n/Users/Zanhuang/Desktop/NNP//.DS_Store\n/Users/Zanhuang/Desktop/NNP//checkpoint\n/Users/Zanhuang/Desktop/NNP//DATA_PREPARE\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/.DS_Store\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/enput.py\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cacer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data2.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data3.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data4.bin\n"}