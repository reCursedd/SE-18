{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226046447", "html_url": "https://github.com/tensorflow/tensorflow/issues/2255#issuecomment-226046447", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255", "id": 226046447, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjA0NjQ0Nw==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-14T23:24:39Z", "updated_at": "2016-06-14T23:29:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If both the function that you are computing and the variables that you differentiate with respect to are real, then the gradients must be real, even if there were intermediate complex calculations involved.<br>\nYou can see this from the following argument:</p>\n<ul>\n<li>If both the differentiated function and the variables are real, then we can construct a fully real function by simply keeping track of the real and imaginary part separately</li>\n<li>The gradient of such a real function must necessarily be real (as there were no complex calculations involved)</li>\n<li>Because the real version of our function produces identical results to the original (complex) one, the gradients of the two functions must be the same, and therefore they must be real.</li>\n</ul>\n<p>Apart from that, it looks like <code>tf.gradients</code> only returns complex numbers if the diff variables are complex at the moment.<br>\nMaybe some of the variables that you differentiate by are still complex?</p>\n<p><strong>Edit:</strong> Another argument to see that the gradients must be real is the definition of the derivative:</p>\n<pre><code>lim h\u21920 (f(x + h) - f(x)) / h\n</code></pre>\n<p>As all variables here (<code>f</code>, <code>x</code> and <code>h</code>) are real, the result must be real as well</p>", "body_text": "If both the function that you are computing and the variables that you differentiate with respect to are real, then the gradients must be real, even if there were intermediate complex calculations involved.\nYou can see this from the following argument:\n\nIf both the differentiated function and the variables are real, then we can construct a fully real function by simply keeping track of the real and imaginary part separately\nThe gradient of such a real function must necessarily be real (as there were no complex calculations involved)\nBecause the real version of our function produces identical results to the original (complex) one, the gradients of the two functions must be the same, and therefore they must be real.\n\nApart from that, it looks like tf.gradients only returns complex numbers if the diff variables are complex at the moment.\nMaybe some of the variables that you differentiate by are still complex?\nEdit: Another argument to see that the gradients must be real is the definition of the derivative:\nlim h\u21920 (f(x + h) - f(x)) / h\n\nAs all variables here (f, x and h) are real, the result must be real as well", "body": "If both the function that you are computing and the variables that you differentiate with respect to are real, then the gradients must be real, even if there were intermediate complex calculations involved.\nYou can see this from the following argument:\n- If both the differentiated function and the variables are real, then we can construct a fully real function by simply keeping track of the real and imaginary part separately\n- The gradient of such a real function must necessarily be real (as there were no complex calculations involved)\n- Because the real version of our function produces identical results to the original (complex) one, the gradients of the two functions must be the same, and therefore they must be real.\n\nApart from that, it looks like `tf.gradients` only returns complex numbers if the diff variables are complex at the moment. \nMaybe some of the variables that you differentiate by are still complex?\n\n**Edit:** Another argument to see that the gradients must be real is the definition of the derivative:\n\n```\nlim h\u21920 (f(x + h) - f(x)) / h\n```\n\nAs all variables here (`f`, `x` and `h`) are real, the result must be real as well\n"}