{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2255", "id": 153518419, "node_id": "MDU6SXNzdWUxNTM1MTg0MTk=", "number": 2255, "title": "Calculating Gradients Through tf.complex64 Numbers", "user": {"login": "NickShahML", "id": 14891677, "node_id": "MDQ6VXNlcjE0ODkxNjc3", "avatar_url": "https://avatars2.githubusercontent.com/u/14891677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NickShahML", "html_url": "https://github.com/NickShahML", "followers_url": "https://api.github.com/users/NickShahML/followers", "following_url": "https://api.github.com/users/NickShahML/following{/other_user}", "gists_url": "https://api.github.com/users/NickShahML/gists{/gist_id}", "starred_url": "https://api.github.com/users/NickShahML/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NickShahML/subscriptions", "organizations_url": "https://api.github.com/users/NickShahML/orgs", "repos_url": "https://api.github.com/users/NickShahML/repos", "events_url": "https://api.github.com/users/NickShahML/events{/privacy}", "received_events_url": "https://api.github.com/users/NickShahML/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "yuanbyu", "id": 2342391, "node_id": "MDQ6VXNlcjIzNDIzOTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2342391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuanbyu", "html_url": "https://github.com/yuanbyu", "followers_url": "https://api.github.com/users/yuanbyu/followers", "following_url": "https://api.github.com/users/yuanbyu/following{/other_user}", "gists_url": "https://api.github.com/users/yuanbyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuanbyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuanbyu/subscriptions", "organizations_url": "https://api.github.com/users/yuanbyu/orgs", "repos_url": "https://api.github.com/users/yuanbyu/repos", "events_url": "https://api.github.com/users/yuanbyu/events{/privacy}", "received_events_url": "https://api.github.com/users/yuanbyu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yuanbyu", "id": 2342391, "node_id": "MDQ6VXNlcjIzNDIzOTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2342391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuanbyu", "html_url": "https://github.com/yuanbyu", "followers_url": "https://api.github.com/users/yuanbyu/followers", "following_url": "https://api.github.com/users/yuanbyu/following{/other_user}", "gists_url": "https://api.github.com/users/yuanbyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuanbyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuanbyu/subscriptions", "organizations_url": "https://api.github.com/users/yuanbyu/orgs", "repos_url": "https://api.github.com/users/yuanbyu/repos", "events_url": "https://api.github.com/users/yuanbyu/events{/privacy}", "received_events_url": "https://api.github.com/users/yuanbyu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 25, "created_at": "2016-05-06T19:09:00Z", "updated_at": "2016-06-15T10:57:41Z", "closed_at": "2016-05-29T20:29:40Z", "author_association": "NONE", "body_html": "<p>Hey TF,</p>\n<p>Its very nice that you support so many complex number calculations like <code>tf.complex_abs</code> and <code>fft</code>. I am trying replicate this <a href=\"http://arxiv.org/abs/1602.03032\" rel=\"nofollow\">Associative LSTM paper </a>where complex numbers are needed.</p>\n<p>However, when I try to calculate the gradient using <code>tf.gradient</code>, I get the traceback below. Is it not possible to calculate the gradient if complex numbers are used with type <code>tf.complex64</code>? If not, this would be an incredibly useful feature as there are several new RNN papers that require complex numbers to be used.</p>\n<p>I am initializing a <code>tf.complex64</code> dtype weight matrix as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>      <span class=\"pl-k\">if</span> complex_weights: \n        a <span class=\"pl-k\">=</span> tf.truncated_normal([total_arg_size, output_size], <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>)\n        weight_matrix <span class=\"pl-k\">=</span> tf.Variable(tf.complex(a,a), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Complex_Weight<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>Perhaps I'm missing something or not writing the code properly. I have TF 0.8 installed.</p>\n<div class=\"highlight highlight-source-python\"><pre>    gradients <span class=\"pl-k\">=</span> tf.gradients(<span class=\"pl-c1\">self</span>.average_mean_loss, params)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">481</span>, <span class=\"pl-k\">in</span> gradients\n    in_grads <span class=\"pl-k\">=</span> _AsList(grad_fn(op, <span class=\"pl-k\">*</span>out_grads))\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">414</span>, <span class=\"pl-k\">in</span> _DivGrad\n    <span class=\"pl-k\">return</span> (array_ops.reshape(math_ops.reduce_sum(grad <span class=\"pl-k\">/</span> y, rx), sx),\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">526</span>, <span class=\"pl-k\">in</span> r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>y.dtype.base_dtype, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">566</span>, <span class=\"pl-k\">in</span> convert_to_tensor\n    ret = conversion_func(value, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name, <span class=\"pl-v\">as_ref</span><span class=\"pl-k\">=</span>as_ref)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">94</span>, <span class=\"pl-k\">in</span> _IndexedSlicesToTensor\n    name=name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1759</span>, <span class=\"pl-k\">in</span> unsorted_segment_sum\n    num_segments<span class=\"pl-k\">=</span>num_segments, name<span class=\"pl-k\">=</span>name)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">486</span>, <span class=\"pl-k\">in</span> apply_op\n    _Attr(op_def, input_arg.type_attr))\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">59</span>, <span class=\"pl-k\">in</span> _SatisfiesTypeConstraint\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>, <span class=\"pl-pds\">\"</span></span>.join(dtypes.as_dtype(x).name <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> allowed_list)))\n<span class=\"pl-c1\">TypeError</span>: DataType complex64 <span class=\"pl-k\">for</span> attr <span class=\"pl-s\"><span class=\"pl-pds\">'</span>T<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">not</span> <span class=\"pl-k\">in</span> <span class=\"pl-c1\">list</span> of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16<span class=\"pl-bu\">```</span>\n</pre></div>", "body_text": "Hey TF,\nIts very nice that you support so many complex number calculations like tf.complex_abs and fft. I am trying replicate this Associative LSTM paper where complex numbers are needed.\nHowever, when I try to calculate the gradient using tf.gradient, I get the traceback below. Is it not possible to calculate the gradient if complex numbers are used with type tf.complex64? If not, this would be an incredibly useful feature as there are several new RNN papers that require complex numbers to be used.\nI am initializing a tf.complex64 dtype weight matrix as follows:\n      if complex_weights: \n        a = tf.truncated_normal([total_arg_size, output_size], stddev=0.1)\n        weight_matrix = tf.Variable(tf.complex(a,a), name=\"Complex_Weight\")\nPerhaps I'm missing something or not writing the code properly. I have TF 0.8 installed.\n    gradients = tf.gradients(self.average_mean_loss, params)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 414, in _DivGrad\n    return (array_ops.reshape(math_ops.reduce_sum(grad / y, rx), sx),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 526, in r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=\"x\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 94, in _IndexedSlicesToTensor\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1759, in unsorted_segment_sum\n    num_segments=num_segments, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 486, in apply_op\n    _Attr(op_def, input_arg.type_attr))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 59, in _SatisfiesTypeConstraint\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16```", "body": "Hey TF,\n\nIts very nice that you support so many complex number calculations like `tf.complex_abs` and `fft`. I am trying replicate this [Associative LSTM paper ](http://arxiv.org/abs/1602.03032)where complex numbers are needed. \n\nHowever, when I try to calculate the gradient using `tf.gradient`, I get the traceback below. Is it not possible to calculate the gradient if complex numbers are used with type `tf.complex64`? If not, this would be an incredibly useful feature as there are several new RNN papers that require complex numbers to be used. \n\nI am initializing a `tf.complex64` dtype weight matrix as follows:\n\n``` python\n      if complex_weights: \n        a = tf.truncated_normal([total_arg_size, output_size], stddev=0.1)\n        weight_matrix = tf.Variable(tf.complex(a,a), name=\"Complex_Weight\")\n```\n\nPerhaps I'm missing something or not writing the code properly. I have TF 0.8 installed. \n\n`````` python\n    gradients = tf.gradients(self.average_mean_loss, params)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 414, in _DivGrad\n    return (array_ops.reshape(math_ops.reduce_sum(grad / y, rx), sx),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 526, in r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=\"x\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 94, in _IndexedSlicesToTensor\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1759, in unsorted_segment_sum\n    num_segments=num_segments, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 486, in apply_op\n    _Attr(op_def, input_arg.type_attr))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 59, in _SatisfiesTypeConstraint\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16```\n\n``````\n"}