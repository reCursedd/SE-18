{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/225208874", "html_url": "https://github.com/tensorflow/tensorflow/issues/2255#issuecomment-225208874", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2255", "id": 225208874, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNTIwODg3NA==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-10T15:08:40Z", "updated_at": "2016-06-10T15:30:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><del>That's strange, as MatMul has support for <code>complex64</code>, although only on the CPU.<br>\nMaybe you are somehow forcing the op to execute on the GPU?<br>\nCurrently complex support is a bit poor for GPU ops, as discussed in this issue: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L219\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L219</a></del></p>\n<p><strong>Edit:</strong> Sorry, I totally misread the backtrace (need more <g-emoji class=\"g-emoji\" alias=\"coffee\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/2615.png\">\u2615\ufe0f</g-emoji>).<br>\nThe <code>MatMul</code> is actually the input and it's the optimization framework that's complaining about its dtype.<br>\nI'm not sure whether it makes sense to run an optimization with complex parameters or a complex loss function.<br>\nIt would probably make sense to parameterize your complex variables in terms of real variables, as in</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">1</span>.)\ny <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">1</span>.)\nz <span class=\"pl-k\">=</span> tf.complex(x, y)</pre></div>\n<p>and then optimize in terms of <code>x</code> and <code>y</code>, and to make sure that the loss function and its gradients are real as well.</p>", "body_text": "That's strange, as MatMul has support for complex64, although only on the CPU.\nMaybe you are somehow forcing the op to execute on the GPU?\nCurrently complex support is a bit poor for GPU ops, as discussed in this issue: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L219\nEdit: Sorry, I totally misread the backtrace (need more \u2615\ufe0f).\nThe MatMul is actually the input and it's the optimization framework that's complaining about its dtype.\nI'm not sure whether it makes sense to run an optimization with complex parameters or a complex loss function.\nIt would probably make sense to parameterize your complex variables in terms of real variables, as in\nx = tf.Variable(1.)\ny = tf.Variable(1.)\nz = tf.complex(x, y)\nand then optimize in terms of x and y, and to make sure that the loss function and its gradients are real as well.", "body": "~~That's strange, as MatMul has support for `complex64`, although only on the CPU.\nMaybe you are somehow forcing the op to execute on the GPU?\nCurrently complex support is a bit poor for GPU ops, as discussed in this issue: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L219~~\n\n**Edit:** Sorry, I totally misread the backtrace (need more :coffee:).\nThe `MatMul` is actually the input and it's the optimization framework that's complaining about its dtype.\nI'm not sure whether it makes sense to run an optimization with complex parameters or a complex loss function.\nIt would probably make sense to parameterize your complex variables in terms of real variables, as in\n\n``` python\nx = tf.Variable(1.)\ny = tf.Variable(1.)\nz = tf.complex(x, y)\n```\n\nand then optimize in terms of `x` and `y`, and to make sure that the loss function and its gradients are real as well.\n"}