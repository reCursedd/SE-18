{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/51340691", "pull_request_review_id": null, "id": 51340691, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzQwNjkx", "diff_hunk": "@@ -0,0 +1,142 @@\n+#!/usr/bin/env bash\n+# Copyright 2016 Google Inc. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+# Build the Python PIP installation package for TensorFlow\n+# and run the Python unit tests from the source code on the installation\n+#\n+# When executing the Python unit tests, the script obeys three environment\n+# variables: PY_TEST_WHITELIST, PY_TEST_BLACKLIST and PY_TEST_GPU_BLACKLIST\n+#\n+# To select only a subset of the Python tests to run, set the environment\n+# variable PY_TEST_WHITELIST, e.g.,\n+#   PY_TEST_WHITELIST=\"tensorflow/python/kernel_tests/shape_ops_test.py\"\n+# Separate the tests with a colon (:). Leave this environment variable empty\n+# to disable the whitelist.\n+#\n+# You can also ignore a set of the tests by using the environment variable\n+# PY_TEST_BLACKLIST. For example, you can include in PY_TEST_BLACKLIST the\n+# tests that depend on Python modules in TensorFlow source that are not\n+# exported publicly.\n+#\n+# In addition, you can put blacklist for only GPU build inthe environment\n+# variable PY_TEST_GPU_BLACKLIST.\n+#\n+\n+echo \"PY_TEST_BLACKLIST: ${PY_TEST_BLACKLIST}\"\n+echo \"PY_TEST_GPU_BLACKLIST: ${PY_TEST_GPU_BLACKLIST}\"\n+\n+# Get the command line arguments\n+CONTAINER_TYPE=$( echo \"$1\" | tr '[:upper:]' '[:lower:]' )\n+\n+# Append GPU-only test blacklist\n+if [[ ${CONTAINER_TYPE} == \"gpu\" ]]; then\n+  PY_TEST_BLACKLIST=\"${PY_TEST_BLACKLIST}:${PY_TEST_GPU_BLACKLIST}\"\n+fi\n+\n+cd /tensorflow &&\n+\n+# Build the pip package\n+PIP_BUILD_TARGET=\"//tensorflow/tools/pip_package:build_pip_package\"\n+if [[ ${CONTAINER_TYPE} == \"cpu\" ]]; then\n+  bazel build -c opt ${PIP_BUILD_TARGET}\n+elif [[ ${CONTAINER_TYPE} == \"gpu\" ]]; then\n+  bazel build -c opt --config=cuda ${PIP_BUILD_TARGET}\n+else\n+  echo \"Unrecognized container type: ${CONTAINER_TYPE}\"\n+  exit 1\n+fi\n+\n+# Install\n+rm -rf _python_build &&\n+mkdir _python_build &&\n+cd _python_build &&\n+ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/* \\\n+  . &&\n+ln -s ../tensorflow/tools/pip_package/* . &&\n+python setup.py develop &&\n+\n+# Run tests\n+cd .. &&\n+ALL_PY_TESTS=`find tensorflow/python -name \"*_test.py\" | xargs` &&\n+PY_TEST_COUNT=`echo ${ALL_PY_TESTS} | wc -w`\n+\n+PY_TEST_DIR=${HOME}/tf_py_tests\n+\n+rm -rf ${PY_TEST_DIR} &&\n+mkdir ${PY_TEST_DIR} &&\n+\n+\n+# Iterate through all the Python unit test files using the installation\n+COUNTER=0\n+SKIP_COUNTER=0\n+for TEST_FILE_PATH in ${ALL_PY_TESTS}; do\n+  ((COUNTER++))\n+\n+  # Copy to a separate directory to guard against the possibility of picking up \n+  # modules in the source directory \n+  cp ${TEST_FILE_PATH} ${PY_TEST_DIR}/ &&\n+\n+  # If PY_TEST_WHITELIST is not empty, only the white-listed tests will be run\n+  if [[ ! -z ${PY_TEST_WHITELIST} ]] && \\\n+     [[ ! ${PY_TEST_WHITELIST} == *\"${TEST_FILE_PATH}\"* ]]; then\n+    ((SKIP_COUNTER++))\n+    echo \"Skipping non-whitelisted test: ${TEST_FILE_PATH}\"\n+    continue\n+  fi\n+\n+  # If the test is in the black list, skip it\n+  if [[ ${PY_TEST_BLACKLIST} == *\"${TEST_FILE_PATH}\"* ]]; then\n+    ((SKIP_COUNTER++))\n+    echo \"Skipping blacklisted test: ${TEST_FILE_PATH}\"\n+    continue\n+  fi\n+\n+  echo \"===============================================================\"\n+  echo \"Running Python test on install #${COUNTER} of ${PY_TEST_COUNT}:\"\n+  echo \"  ${TEST_FILE_PATH}\"\n+  echo \"===============================================================\"\n+  echo \"\"\n+\n+  TEST_FILE_BASENAME=`basename \"${TEST_FILE_PATH}\"`\n+\n+  TEST_OUTPUT=${PY_TEST_DIR}/${TEST_FILE_BASENAME}.out\n+\n+  python ${PY_TEST_DIR}/${TEST_FILE_BASENAME} 2>&1 | \\\n+    tee ${TEST_OUTPUT}  &&\n+\n+  # Check for OK or failure status of the test output and exit with code 1\n+  # if failure is seen\n+  OK_LINE=`grep \"^OK\" ${TEST_OUTPUT}`\n+  FAIL_LINE=`grep \"^> FAILED\" ${TEST_OUTPUT}`\n+  if [[ ! -z ${OK_LINE} ]] && [[ -z ${FAIL_LINE} ]]; then\n+    echo \"\"\n+    echo \"Python test on install succeeded: ${TEST_FILE_PATH}\"\n+    echo \"\"\n+  else\n+    echo \"\"\n+    echo \"Python test on install FAILED: ${TEST_FILE_PATH}\"\n+    exit 1", "path": "tensorflow/tools/ci_build/builds/test_on_install.sh", "position": null, "original_position": 131, "commit_id": "da2202dec6befe480b5bae3971a0c5cab15d74ea", "original_commit_id": "c65665cf5fce4b7cb1ea8f8d713e12e11330b125", "user": {"login": "jendap", "id": 567848, "node_id": "MDQ6VXNlcjU2Nzg0OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/567848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jendap", "html_url": "https://github.com/jendap", "followers_url": "https://api.github.com/users/jendap/followers", "following_url": "https://api.github.com/users/jendap/following{/other_user}", "gists_url": "https://api.github.com/users/jendap/gists{/gist_id}", "starred_url": "https://api.github.com/users/jendap/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jendap/subscriptions", "organizations_url": "https://api.github.com/users/jendap/orgs", "repos_url": "https://api.github.com/users/jendap/repos", "events_url": "https://api.github.com/users/jendap/events{/privacy}", "received_events_url": "https://api.github.com/users/jendap/received_events", "type": "User", "site_admin": false}, "body": "It is usually better to run all tests to see which fail rather then give up after the first. (unless run time is important)\n", "created_at": "2016-01-30T05:19:34Z", "updated_at": "2016-02-04T04:43:38Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/939#discussion_r51340691", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/939", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/51340691"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/939#discussion_r51340691"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/939"}}, "body_html": "<p>It is usually better to run all tests to see which fail rather then give up after the first. (unless run time is important)</p>", "body_text": "It is usually better to run all tests to see which fail rather then give up after the first. (unless run time is important)"}