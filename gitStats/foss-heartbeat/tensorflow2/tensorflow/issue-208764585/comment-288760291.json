{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288760291", "html_url": "https://github.com/tensorflow/tensorflow/issues/7679#issuecomment-288760291", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7679", "id": 288760291, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODc2MDI5MQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-23T15:40:07Z", "updated_at": "2017-03-23T15:40:07Z", "author_association": "MEMBER", "body_html": "<p>I have been negligent in updating.  Testing, documentation, and code clean up is going well.  We are putting in a strong effort to release in early April.  I believe people internally think I have lost my mind in attempting to manage expectations externally.  It may be my cold medication speaking, but I want to be clear what I care about most is getting this code out so the users of TensorFlow can train their models faster and be more efficiently.  I am working get to some documentation created as well, as having example code is not always useful without some explanation.   To answer <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20574558\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AlvinChen13\">@AlvinChen13</a> 's question.  For the K80 the numbers I used an AWS p2.8xlarge and recently on GCE with 8 K80s GPUs.  Both setups are one server with 8 GPUs.  Keep in mind these numbers may still be improving and this is not an official post, this is very informal although public.</p>\n<ul>\n<li>Inceptionv3 K80s had a speed up of 7.5x using synthetic data and 7.34x using real data from 1 GPU to 8 GPUs</li>\n<li>InceptionV3 P100s has a speed up of 7.4x (7.37) using synthetic data and 7.2x using real data from 1 GPU to 8 GPUs.</li>\n</ul>\n<p>I used a batch-size of 32 per GPU to match some of the other bechmarks.</p>\n<p>The 58x from 1 GPU to 64 GPUs was 8 server each with 8 K80 GPUs using AWS p2.8xLarge instances with the standard Enhanced Networking.  Again 32 was the batch-size per GPU.  We used Ubuntu 16.04 as well as Amazon Linux to see if there was a difference.  There is no real difference as long as you install the Enhanced Networking on Ubuntu 16.04.  I wrote up some <a href=\"https://github.com/tfboyd/tf-tools/tree/master/install\">installation instructions</a> for both operating systems and a poorly written <a href=\"http://mediocrethoughts.ghost.io/2017/03/04/installing-tensorflow-on-aws/\" rel=\"nofollow\">blog post</a> on my single post lame blog.  :-)</p>\n<p>I also ran ResNet-50, ResNet-152, AlexNet (batch 128 and 512) and we will be running VGG-16.  I believe that covers the most popular image-classification models, and the techniques should apply to other models.</p>", "body_text": "I have been negligent in updating.  Testing, documentation, and code clean up is going well.  We are putting in a strong effort to release in early April.  I believe people internally think I have lost my mind in attempting to manage expectations externally.  It may be my cold medication speaking, but I want to be clear what I care about most is getting this code out so the users of TensorFlow can train their models faster and be more efficiently.  I am working get to some documentation created as well, as having example code is not always useful without some explanation.   To answer @AlvinChen13 's question.  For the K80 the numbers I used an AWS p2.8xlarge and recently on GCE with 8 K80s GPUs.  Both setups are one server with 8 GPUs.  Keep in mind these numbers may still be improving and this is not an official post, this is very informal although public.\n\nInceptionv3 K80s had a speed up of 7.5x using synthetic data and 7.34x using real data from 1 GPU to 8 GPUs\nInceptionV3 P100s has a speed up of 7.4x (7.37) using synthetic data and 7.2x using real data from 1 GPU to 8 GPUs.\n\nI used a batch-size of 32 per GPU to match some of the other bechmarks.\nThe 58x from 1 GPU to 64 GPUs was 8 server each with 8 K80 GPUs using AWS p2.8xLarge instances with the standard Enhanced Networking.  Again 32 was the batch-size per GPU.  We used Ubuntu 16.04 as well as Amazon Linux to see if there was a difference.  There is no real difference as long as you install the Enhanced Networking on Ubuntu 16.04.  I wrote up some installation instructions for both operating systems and a poorly written blog post on my single post lame blog.  :-)\nI also ran ResNet-50, ResNet-152, AlexNet (batch 128 and 512) and we will be running VGG-16.  I believe that covers the most popular image-classification models, and the techniques should apply to other models.", "body": "I have been negligent in updating.  Testing, documentation, and code clean up is going well.  We are putting in a strong effort to release in early April.  I believe people internally think I have lost my mind in attempting to manage expectations externally.  It may be my cold medication speaking, but I want to be clear what I care about most is getting this code out so the users of TensorFlow can train their models faster and be more efficiently.  I am working get to some documentation created as well, as having example code is not always useful without some explanation.   To answer @AlvinChen13 's question.  For the K80 the numbers I used an AWS p2.8xlarge and recently on GCE with 8 K80s GPUs.  Both setups are one server with 8 GPUs.  Keep in mind these numbers may still be improving and this is not an official post, this is very informal although public.  \r\n\r\n- Inceptionv3 K80s had a speed up of 7.5x using synthetic data and 7.34x using real data from 1 GPU to 8 GPUs\r\n- InceptionV3 P100s has a speed up of 7.4x (7.37) using synthetic data and 7.2x using real data from 1 GPU to 8 GPUs.\r\n\r\nI used a batch-size of 32 per GPU to match some of the other bechmarks.\r\n\r\nThe 58x from 1 GPU to 64 GPUs was 8 server each with 8 K80 GPUs using AWS p2.8xLarge instances with the standard Enhanced Networking.  Again 32 was the batch-size per GPU.  We used Ubuntu 16.04 as well as Amazon Linux to see if there was a difference.  There is no real difference as long as you install the Enhanced Networking on Ubuntu 16.04.  I wrote up some [installation instructions](https://github.com/tfboyd/tf-tools/tree/master/install) for both operating systems and a poorly written [blog post](http://mediocrethoughts.ghost.io/2017/03/04/installing-tensorflow-on-aws/) on my single post lame blog.  :-)\r\n\r\nI also ran ResNet-50, ResNet-152, AlexNet (batch 128 and 512) and we will be running VGG-16.  I believe that covers the most popular image-classification models, and the techniques should apply to other models.   "}