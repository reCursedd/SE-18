{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8431", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8431/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8431/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8431/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8431", "id": 214370261, "node_id": "MDU6SXNzdWUyMTQzNzAyNjE=", "number": 8431, "title": "dilated convoluton uses a lot of memory", "user": {"login": "AndreasMadsen", "id": 505333, "node_id": "MDQ6VXNlcjUwNTMzMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/505333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndreasMadsen", "html_url": "https://github.com/AndreasMadsen", "followers_url": "https://api.github.com/users/AndreasMadsen/followers", "following_url": "https://api.github.com/users/AndreasMadsen/following{/other_user}", "gists_url": "https://api.github.com/users/AndreasMadsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndreasMadsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndreasMadsen/subscriptions", "organizations_url": "https://api.github.com/users/AndreasMadsen/orgs", "repos_url": "https://api.github.com/users/AndreasMadsen/repos", "events_url": "https://api.github.com/users/AndreasMadsen/events{/privacy}", "received_events_url": "https://api.github.com/users/AndreasMadsen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2017-03-15T12:12:04Z", "updated_at": "2018-03-12T18:36:59Z", "closed_at": "2018-03-11T21:40:46Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<ul>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"184108165\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5083\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5083/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5083\">#5083</a></li>\n</ul>\n<h3>Environment info</h3>\n<p>Operating System: <code>Linux hpclogin2 2.6.32-642.15.1.el6.x86_64 #1 SMP Thu Feb 23 11:19:57 CST 2017 x86_64 x86_64 x86_64 GNU/Linux</code></p>\n<p>Installed version of CUDA and cuDNN: 8.0 and 5.1</p>\n<details>\n<summary>(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):</summary>\n```\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so -&gt; libcublas.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0 -&gt; libcublas.so.8.0.27\n-rwxr-xr-x 1 sebo root  38838688 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0.27\n-rw-r--r-- 1 sebo root  49345532 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_device.a\n-rw-r--r-- 1 sebo root  45050574 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_static.a\n-rw-r--r-- 1 sebo root    560184 Sep  1  2016 /appl/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27\n-rwxr-xr-x 1 sebo root    394472 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 sebo root    737516 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 sebo root        15 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so -&gt; libcufft.so.8.0\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0 -&gt; libcufft.so.8.0.27\n-rwxr-xr-x 1 sebo root 146745600 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0.27\n-rw-r--r-- 1 sebo root 129655446 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft_static.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so -&gt; libcufftw.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0 -&gt; libcufftw.so.8.0.27\n-rwxr-xr-x 1 sebo root    456424 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0.27\n-rw-r--r-- 1 sebo root     42134 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw_static.a\nlrwxrwxrwx 1 sebo root        17 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so -&gt; libcuinj64.so.8.0\nlrwxrwxrwx 1 sebo root        20 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0 -&gt; libcuinj64.so.8.0.27\n-rwxr-xr-x 1 sebo root   6459464 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0.27\n-rw-r--r-- 1 sebo root   1649302 Sep  1  2016 /appl/cuda/8.0/lib64/libculibos.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so -&gt; libcurand.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0 -&gt; libcurand.so.8.0.27\n-rwxr-xr-x 1 sebo root  59057024 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0.27\n-rw-r--r-- 1 sebo root  59273876 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand_static.a\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so -&gt; libcusolver.so.8.0\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0 -&gt; libcusolver.so.8.0.27\n-rwxr-xr-x 1 sebo root  52380368 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0.27\n-rw-r--r-- 1 sebo root  22313722 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver_static.a\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so -&gt; libcusparse.so.8.0\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0 -&gt; libcusparse.so.8.0.27\n-rwxr-xr-x 1 sebo root  42976296 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0.27\n-rw-r--r-- 1 sebo root  51604078 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse_static.a\n```\n</details>\n<br>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>): 168d188168b30b204099f21e456151752d7fb718</li>\n<li>The output of <code>bazel version</code>: <code>0.4.3</code></li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> sugartensor <span class=\"pl-k\">as</span> stf\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_variable</span>(<span class=\"pl-smi\">name</span>, <span class=\"pl-smi\">in_dim</span>, <span class=\"pl-smi\">out_dim</span>, <span class=\"pl-smi\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-k\">if</span> size <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n        shape <span class=\"pl-k\">=</span> (in_dim, out_dim)\n    <span class=\"pl-k\">else</span>:\n        shape <span class=\"pl-k\">=</span> (size, in_dim, out_dim)\n\n    w <span class=\"pl-k\">=</span> tf.get_variable(name, shape, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_uniform_initializer(\n                            <span class=\"pl-v\">minval</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span>np.sqrt(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">/</span> (in_dim <span class=\"pl-k\">*</span> size)),\n                            <span class=\"pl-v\">maxval</span><span class=\"pl-k\">=</span>np.sqrt(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">/</span> (in_dim <span class=\"pl-k\">*</span> size))\n                        ))\n    <span class=\"pl-k\">return</span> w\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> build forward pass</span>\nembedding <span class=\"pl-k\">=</span> get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>embed<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">892</span>)\nembedding_inv <span class=\"pl-k\">=</span> get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>embed-inv<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">892</span>, <span class=\"pl-c1\">128</span>)\n\ndata <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>x<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">160</span>, <span class=\"pl-c1\">200</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\noutput <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(embedding, data)\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">60</span>):\n    Wi <span class=\"pl-k\">=</span> get_variable(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">W</span><span class=\"pl-c1\">{</span>i<span class=\"pl-c1\">}</span><span class=\"pl-pds\">'</span>, <span class=\"pl-c1\">892</span>, <span class=\"pl-c1\">892</span>, <span class=\"pl-c1\">5</span>)\n    output <span class=\"pl-k\">=</span> tf.nn.convolution(<span class=\"pl-v\">input</span><span class=\"pl-k\">=</span>output, <span class=\"pl-v\">filter</span><span class=\"pl-k\">=</span>Wi,\n                               <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">dilation_rate</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">16</span>],\n                               <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>aconv1d<span class=\"pl-pds\">'</span></span>)\n    output <span class=\"pl-k\">=</span> tf.nn.relu(output)\n\nlogits <span class=\"pl-k\">=</span> tf.reshape(tf.matmul(tf.reshape(output, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">892</span>]), embedding_inv),\n                    [<span class=\"pl-c1\">160</span>, <span class=\"pl-c1\">200</span>, <span class=\"pl-c1\">128</span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> optimize for the idendity function</span>\nloss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    <span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>data, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits\n))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> create update ops</span>\noptimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer()\ngrad_and_vars <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss, tf.trainable_variables())\nupdate_ops <span class=\"pl-k\">=</span> optimizer.apply_gradients(grad_and_vars)\n\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n        loss_result <span class=\"pl-k\">=</span> sess.run([loss, update_ops], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{\n            data: np.random.randint(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">160</span>, <span class=\"pl-c1\">200</span>))\n        })[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">iteration </span><span class=\"pl-c1\">{</span>i<span class=\"pl-c1\">}</span><span class=\"pl-s\"> complete: </span><span class=\"pl-c1\">{</span>loss_result<span class=\"pl-c1\">}</span><span class=\"pl-pds\">'</span>)</pre></div>\n<p>This example is perhaps too theoretical to be discussed from a practical application perspective. The actual application is the <a href=\"https://arxiv.org/abs/1610.10099\" rel=\"nofollow\">ByteNet</a> model, the implementation is very similar to <a href=\"https://github.com/buriburisuri/ByteNet\">https://github.com/buriburisuri/ByteNet</a>. The ByteNet model stacks multiple one-dimensional-dilated-convolutions (30), because each of them uses <code>space_to_batch</code> they use a lot of memory.</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>I've implemented one-dimensional-masked-dilated-convolutions using <code>tf.scan</code>, this uses much less memory but is also slower.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>\n<ul>\n<li>The error log from the actual application: <a href=\"https://gist.github.com/AndreasMadsen/91e49e13f0085ececbef0f80c830c5af\">https://gist.github.com/AndreasMadsen/91e49e13f0085ececbef0f80c830c5af</a> (note that this happens after 21334 iterations/14 hours, so there may also be a garbage collection issue)</li>\n<li>The error log from the simplified example: <a href=\"https://gist.github.com/AndreasMadsen/94f5100aff697cdf5ff6c26f90a6dad7\">https://gist.github.com/AndreasMadsen/94f5100aff697cdf5ff6c26f90a6dad7</a></li>\n</ul>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\n#5083\n\nEnvironment info\nOperating System: Linux hpclogin2 2.6.32-642.15.1.el6.x86_64 #1 SMP Thu Feb 23 11:19:57 CST 2017 x86_64 x86_64 x86_64 GNU/Linux\nInstalled version of CUDA and cuDNN: 8.0 and 5.1\n\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n```\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so -> libcublas.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0 -> libcublas.so.8.0.27\n-rwxr-xr-x 1 sebo root  38838688 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0.27\n-rw-r--r-- 1 sebo root  49345532 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_device.a\n-rw-r--r-- 1 sebo root  45050574 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_static.a\n-rw-r--r-- 1 sebo root    560184 Sep  1  2016 /appl/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 sebo root    394472 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 sebo root    737516 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart_static.a\nlrwxrwxrwx 1 sebo root        15 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so -> libcufft.so.8.0\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0 -> libcufft.so.8.0.27\n-rwxr-xr-x 1 sebo root 146745600 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0.27\n-rw-r--r-- 1 sebo root 129655446 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft_static.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so -> libcufftw.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0 -> libcufftw.so.8.0.27\n-rwxr-xr-x 1 sebo root    456424 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0.27\n-rw-r--r-- 1 sebo root     42134 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw_static.a\nlrwxrwxrwx 1 sebo root        17 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so -> libcuinj64.so.8.0\nlrwxrwxrwx 1 sebo root        20 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0 -> libcuinj64.so.8.0.27\n-rwxr-xr-x 1 sebo root   6459464 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0.27\n-rw-r--r-- 1 sebo root   1649302 Sep  1  2016 /appl/cuda/8.0/lib64/libculibos.a\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so -> libcurand.so.8.0\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0 -> libcurand.so.8.0.27\n-rwxr-xr-x 1 sebo root  59057024 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0.27\n-rw-r--r-- 1 sebo root  59273876 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand_static.a\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so -> libcusolver.so.8.0\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0 -> libcusolver.so.8.0.27\n-rwxr-xr-x 1 sebo root  52380368 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0.27\n-rw-r--r-- 1 sebo root  22313722 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver_static.a\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so -> libcusparse.so.8.0\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0 -> libcusparse.so.8.0.27\n-rwxr-xr-x 1 sebo root  42976296 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0.27\n-rw-r--r-- 1 sebo root  51604078 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse_static.a\n```\n\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD): 168d188168b30b204099f21e456151752d7fb718\nThe output of bazel version: 0.4.3\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport numpy as np\nimport sugartensor as stf\nimport tensorflow as tf\n\n\ndef get_variable(name, in_dim, out_dim, size=None):\n    if size is None:\n        size = 1\n        shape = (in_dim, out_dim)\n    else:\n        shape = (size, in_dim, out_dim)\n\n    w = tf.get_variable(name, shape, dtype=tf.float32,\n                        initializer=tf.random_uniform_initializer(\n                            minval=-np.sqrt(1 / (in_dim * size)),\n                            maxval=np.sqrt(1 / (in_dim * size))\n                        ))\n    return w\n\n# build forward pass\nembedding = get_variable('embed', 128, 892)\nembedding_inv = get_variable('embed-inv', 892, 128)\n\ndata = tf.placeholder(name='x', shape=(160, 200), dtype=tf.int32)\noutput = tf.nn.embedding_lookup(embedding, data)\n\nfor i in range(60):\n    Wi = get_variable(f'W{i}', 892, 892, 5)\n    output = tf.nn.convolution(input=output, filter=Wi,\n                               padding='SAME', dilation_rate=[16],\n                               name='aconv1d')\n    output = tf.nn.relu(output)\n\nlogits = tf.reshape(tf.matmul(tf.reshape(output, [-1, 892]), embedding_inv),\n                    [160, 200, 128])\n\n# optimize for the idendity function\nloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    labels=data, logits=logits\n))\n\n# create update ops\noptimizer = tf.train.AdamOptimizer()\ngrad_and_vars = optimizer.compute_gradients(loss, tf.trainable_variables())\nupdate_ops = optimizer.apply_gradients(grad_and_vars)\n\nconfig = tf.ConfigProto(allow_soft_placement=True)\nwith tf.Session(config=config) as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for i in range(1000):\n        loss_result = sess.run([loss, update_ops], feed_dict={\n            data: np.random.randint(0, 128, size=(160, 200))\n        })[0]\n        print(f'iteration {i} complete: {loss_result}')\nThis example is perhaps too theoretical to be discussed from a practical application perspective. The actual application is the ByteNet model, the implementation is very similar to https://github.com/buriburisuri/ByteNet. The ByteNet model stacks multiple one-dimensional-dilated-convolutions (30), because each of them uses space_to_batch they use a lot of memory.\nWhat other attempted solutions have you tried?\nI've implemented one-dimensional-masked-dilated-convolutions using tf.scan, this uses much less memory but is also slower.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\n\nThe error log from the actual application: https://gist.github.com/AndreasMadsen/91e49e13f0085ececbef0f80c830c5af (note that this happens after 21334 iterations/14 hours, so there may also be a garbage collection issue)\nThe error log from the simplified example: https://gist.github.com/AndreasMadsen/94f5100aff697cdf5ff6c26f90a6dad7", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n* https://github.com/tensorflow/tensorflow/issues/5083 \r\n\r\n### Environment info\r\nOperating System: `Linux hpclogin2 2.6.32-642.15.1.el6.x86_64 #1 SMP Thu Feb 23 11:19:57 CST 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\nInstalled version of CUDA and cuDNN: 8.0 and 5.1\r\n<details>\r\n<summary>(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):</summary>\r\n```\r\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so -> libcublas.so.8.0\r\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0 -> libcublas.so.8.0.27\r\n-rwxr-xr-x 1 sebo root  38838688 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0.27\r\n-rw-r--r-- 1 sebo root  49345532 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_device.a\r\n-rw-r--r-- 1 sebo root  45050574 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_static.a\r\n-rw-r--r-- 1 sebo root    560184 Sep  1  2016 /appl/cuda/8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\r\n-rwxr-xr-x 1 sebo root    394472 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0.27\r\n-rw-r--r-- 1 sebo root    737516 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 sebo root        15 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so -> libcufft.so.8.0\r\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0 -> libcufft.so.8.0.27\r\n-rwxr-xr-x 1 sebo root 146745600 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0.27\r\n-rw-r--r-- 1 sebo root 129655446 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft_static.a\r\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so -> libcufftw.so.8.0\r\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0 -> libcufftw.so.8.0.27\r\n-rwxr-xr-x 1 sebo root    456424 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0.27\r\n-rw-r--r-- 1 sebo root     42134 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw_static.a\r\nlrwxrwxrwx 1 sebo root        17 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so -> libcuinj64.so.8.0\r\nlrwxrwxrwx 1 sebo root        20 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0 -> libcuinj64.so.8.0.27\r\n-rwxr-xr-x 1 sebo root   6459464 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0.27\r\n-rw-r--r-- 1 sebo root   1649302 Sep  1  2016 /appl/cuda/8.0/lib64/libculibos.a\r\nlrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so -> libcurand.so.8.0\r\nlrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0 -> libcurand.so.8.0.27\r\n-rwxr-xr-x 1 sebo root  59057024 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0.27\r\n-rw-r--r-- 1 sebo root  59273876 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand_static.a\r\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so -> libcusolver.so.8.0\r\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0 -> libcusolver.so.8.0.27\r\n-rwxr-xr-x 1 sebo root  52380368 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0.27\r\n-rw-r--r-- 1 sebo root  22313722 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver_static.a\r\nlrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so -> libcusparse.so.8.0\r\nlrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0 -> libcusparse.so.8.0.27\r\n-rwxr-xr-x 1 sebo root  42976296 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0.27\r\n-rw-r--r-- 1 sebo root  51604078 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse_static.a\r\n```\r\n</details>\r\n<br>\r\n\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`): 168d188168b30b204099f21e456151752d7fb718\r\n2. The output of `bazel version`: `0.4.3`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```py\r\nimport numpy as np\r\nimport sugartensor as stf\r\nimport tensorflow as tf\r\n\r\n\r\ndef get_variable(name, in_dim, out_dim, size=None):\r\n    if size is None:\r\n        size = 1\r\n        shape = (in_dim, out_dim)\r\n    else:\r\n        shape = (size, in_dim, out_dim)\r\n\r\n    w = tf.get_variable(name, shape, dtype=tf.float32,\r\n                        initializer=tf.random_uniform_initializer(\r\n                            minval=-np.sqrt(1 / (in_dim * size)),\r\n                            maxval=np.sqrt(1 / (in_dim * size))\r\n                        ))\r\n    return w\r\n\r\n# build forward pass\r\nembedding = get_variable('embed', 128, 892)\r\nembedding_inv = get_variable('embed-inv', 892, 128)\r\n\r\ndata = tf.placeholder(name='x', shape=(160, 200), dtype=tf.int32)\r\noutput = tf.nn.embedding_lookup(embedding, data)\r\n\r\nfor i in range(60):\r\n    Wi = get_variable(f'W{i}', 892, 892, 5)\r\n    output = tf.nn.convolution(input=output, filter=Wi,\r\n                               padding='SAME', dilation_rate=[16],\r\n                               name='aconv1d')\r\n    output = tf.nn.relu(output)\r\n\r\nlogits = tf.reshape(tf.matmul(tf.reshape(output, [-1, 892]), embedding_inv),\r\n                    [160, 200, 128])\r\n\r\n# optimize for the idendity function\r\nloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n    labels=data, logits=logits\r\n))\r\n\r\n# create update ops\r\noptimizer = tf.train.AdamOptimizer()\r\ngrad_and_vars = optimizer.compute_gradients(loss, tf.trainable_variables())\r\nupdate_ops = optimizer.apply_gradients(grad_and_vars)\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement=True)\r\nwith tf.Session(config=config) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(1000):\r\n        loss_result = sess.run([loss, update_ops], feed_dict={\r\n            data: np.random.randint(0, 128, size=(160, 200))\r\n        })[0]\r\n        print(f'iteration {i} complete: {loss_result}')\r\n```\r\n\r\nThis example is perhaps too theoretical to be discussed from a practical application perspective. The actual application is the [ByteNet](https://arxiv.org/abs/1610.10099) model, the implementation is very similar to https://github.com/buriburisuri/ByteNet. The ByteNet model stacks multiple one-dimensional-dilated-convolutions (30), because each of them uses `space_to_batch` they use a lot of memory.\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nI've implemented one-dimensional-masked-dilated-convolutions using `tf.scan`, this uses much less memory but is also slower.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n* The error log from the actual application: https://gist.github.com/AndreasMadsen/91e49e13f0085ececbef0f80c830c5af (note that this happens after 21334 iterations/14 hours, so there may also be a garbage collection issue)\r\n* The error log from the simplified example: https://gist.github.com/AndreasMadsen/94f5100aff697cdf5ff6c26f90a6dad7"}