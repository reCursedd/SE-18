{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281455866", "html_url": "https://github.com/tensorflow/tensorflow/issues/7403#issuecomment-281455866", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7403", "id": 281455866, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTQ1NTg2Ng==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-21T19:37:43Z", "updated_at": "2017-02-21T19:37:43Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3997997\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/persiyanov\">@persiyanov</a> I think to understand this you need to understand better how the tensorflow gradients code works.</p>\n<p>Right now when you request a gradient for a loss wrt to a variable tf will walk back the graph calling the gradient functions for all ops. The gradient of an op is a function of the gradient of its outputs (by the chain rule). For an op with multiple outputs the gradient will depend on both of them, additively. If one output was not used in the model, TF will put a zero tensor in there, so we can compute the value of the gradient function correctly.</p>\n<p>So if you have a model which only uses the normal output of the softmax cross entropy and you try to take the gradient, because the gradient of the softmax cross entropy was not used in the graph TF will put a zero in there. When you try to take just the second derivative, similarly a zero will be provided as the downstream gradient of the first output, and the function is again mathematically correct.</p>", "body_text": "@persiyanov I think to understand this you need to understand better how the tensorflow gradients code works.\nRight now when you request a gradient for a loss wrt to a variable tf will walk back the graph calling the gradient functions for all ops. The gradient of an op is a function of the gradient of its outputs (by the chain rule). For an op with multiple outputs the gradient will depend on both of them, additively. If one output was not used in the model, TF will put a zero tensor in there, so we can compute the value of the gradient function correctly.\nSo if you have a model which only uses the normal output of the softmax cross entropy and you try to take the gradient, because the gradient of the softmax cross entropy was not used in the graph TF will put a zero in there. When you try to take just the second derivative, similarly a zero will be provided as the downstream gradient of the first output, and the function is again mathematically correct.", "body": "@persiyanov I think to understand this you need to understand better how the tensorflow gradients code works.\r\n\r\nRight now when you request a gradient for a loss wrt to a variable tf will walk back the graph calling the gradient functions for all ops. The gradient of an op is a function of the gradient of its outputs (by the chain rule). For an op with multiple outputs the gradient will depend on both of them, additively. If one output was not used in the model, TF will put a zero tensor in there, so we can compute the value of the gradient function correctly.\r\n\r\nSo if you have a model which only uses the normal output of the softmax cross entropy and you try to take the gradient, because the gradient of the softmax cross entropy was not used in the graph TF will put a zero in there. When you try to take just the second derivative, similarly a zero will be provided as the downstream gradient of the first output, and the function is again mathematically correct."}