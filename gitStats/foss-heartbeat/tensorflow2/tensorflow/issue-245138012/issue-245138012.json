{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11721", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11721/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11721/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11721/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11721", "id": 245138012, "node_id": "MDU6SXNzdWUyNDUxMzgwMTI=", "number": 11721, "title": "Memory Leak from Training Step", "user": {"login": "JamesKostas", "id": 22646371, "node_id": "MDQ6VXNlcjIyNjQ2Mzcx", "avatar_url": "https://avatars3.githubusercontent.com/u/22646371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JamesKostas", "html_url": "https://github.com/JamesKostas", "followers_url": "https://api.github.com/users/JamesKostas/followers", "following_url": "https://api.github.com/users/JamesKostas/following{/other_user}", "gists_url": "https://api.github.com/users/JamesKostas/gists{/gist_id}", "starred_url": "https://api.github.com/users/JamesKostas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JamesKostas/subscriptions", "organizations_url": "https://api.github.com/users/JamesKostas/orgs", "repos_url": "https://api.github.com/users/JamesKostas/repos", "events_url": "https://api.github.com/users/JamesKostas/events{/privacy}", "received_events_url": "https://api.github.com/users/JamesKostas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-07-24T16:34:32Z", "updated_at": "2017-09-20T17:58:09Z", "closed_at": "2017-09-20T17:57:53Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes, although my code is somewhat based on the MNIST deep learning tutorial.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 14.04 VERSION=\"14.04.5 LTS, Trusty Tahr\"</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nInstalled via the VirtualEnv method</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.1 and 1.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nCUDA Version 8.0.44</li>\n<li><strong>GPU model and memory</strong>:<br>\nGeForce GTX 780M 4GB</li>\n<li><strong>Exact command to reproduce</strong>:<br>\n<code>self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>This is very similar to <a href=\"https://github.com/tensorflow/tensorflow/issues/9590\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/9590/hovercard\">the bug report I submitted here</a>, but is a bit of a slower leak and is present in both TF 1.1 and 1.2.  I have finalized my graph.  Using the architecture described by <a href=\"https://arxiv.org/pdf/1311.2901v3.pdf\" rel=\"nofollow\">Zeiler et al., 2013 (ZF Net)</a>, batch sizes of 64, and 224x224 grayscale (1 channel) input, it leaks approximately 4GB after approximately 3000 batches.  This makes it unworkable, for say, 80 epochs of ImageNet training.  I have confirmed that the leak either does not occur or is much less severe (hard to tell which) if I comment out the training line (i.e. still do all of my preprocessing and loading).</p>\n<p>As directed in that last linked issue, I tried to call sess.run with<br>\noptions=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata<br>\nand start the program with<br>\nenv TF_CPP_MIN_VLOG_LEVEL=1 python deep_learning_main.py</p>\n<p>but the amount of spew was enormous, and it won't respond to keyboard interrupts (I have to kill the job).  If that info would be helpful, how do I go about recording/saving this information properly to upload and help you all debug?</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/1170372/1_08.zip\">1_08.zip</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes, although my code is somewhat based on the MNIST deep learning tutorial.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 14.04 VERSION=\"14.04.5 LTS, Trusty Tahr\"\nTensorFlow installed from (source or binary):\nInstalled via the VirtualEnv method\nTensorFlow version (use command below):\n1.1 and 1.2\nBazel version (if compiling from source):\nCUDA/cuDNN version:\nCUDA Version 8.0.44\nGPU model and memory:\nGeForce GTX 780M 4GB\nExact command to reproduce:\nself.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})\n\nDescribe the problem\nThis is very similar to the bug report I submitted here, but is a bit of a slower leak and is present in both TF 1.1 and 1.2.  I have finalized my graph.  Using the architecture described by Zeiler et al., 2013 (ZF Net), batch sizes of 64, and 224x224 grayscale (1 channel) input, it leaks approximately 4GB after approximately 3000 batches.  This makes it unworkable, for say, 80 epochs of ImageNet training.  I have confirmed that the leak either does not occur or is much less severe (hard to tell which) if I comment out the training line (i.e. still do all of my preprocessing and loading).\nAs directed in that last linked issue, I tried to call sess.run with\noptions=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata\nand start the program with\nenv TF_CPP_MIN_VLOG_LEVEL=1 python deep_learning_main.py\nbut the amount of spew was enormous, and it won't respond to keyboard interrupts (I have to kill the job).  If that info would be helpful, how do I go about recording/saving this information properly to upload and help you all debug?\n1_08.zip", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, although my code is somewhat based on the MNIST deep learning tutorial.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04 VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n- **TensorFlow installed from (source or binary)**:\r\nInstalled via the VirtualEnv method\r\n- **TensorFlow version (use command below)**:\r\n1.1 and 1.2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCUDA Version 8.0.44\r\n- **GPU model and memory**:\r\nGeForce GTX 780M 4GB\r\n- **Exact command to reproduce**:\r\n`self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})`\r\n\r\n### Describe the problem\r\n\r\nThis is very similar to [the bug report I submitted here](https://github.com/tensorflow/tensorflow/issues/9590), but is a bit of a slower leak and is present in both TF 1.1 and 1.2.  I have finalized my graph.  Using the architecture described by [Zeiler et al., 2013 (ZF Net)](https://arxiv.org/pdf/1311.2901v3.pdf), batch sizes of 64, and 224x224 grayscale (1 channel) input, it leaks approximately 4GB after approximately 3000 batches.  This makes it unworkable, for say, 80 epochs of ImageNet training.  I have confirmed that the leak either does not occur or is much less severe (hard to tell which) if I comment out the training line (i.e. still do all of my preprocessing and loading).\r\n\r\n\r\nAs directed in that last linked issue, I tried to call sess.run with \r\noptions=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata\r\nand start the program with \r\nenv TF_CPP_MIN_VLOG_LEVEL=1 python deep_learning_main.py\r\n\r\nbut the amount of spew was enormous, and it won't respond to keyboard interrupts (I have to kill the job).  If that info would be helpful, how do I go about recording/saving this information properly to upload and help you all debug?\r\n\r\n[1_08.zip](https://github.com/tensorflow/tensorflow/files/1170372/1_08.zip)"}