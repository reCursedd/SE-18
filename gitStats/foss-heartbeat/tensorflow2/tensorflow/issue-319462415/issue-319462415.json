{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19020", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19020/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19020/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19020/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19020", "id": 319462415, "node_id": "MDU6SXNzdWUzMTk0NjI0MTU=", "number": 19020, "title": "tf.data leaves hash table not initialized", "user": {"login": "cherishlc", "id": 13269703, "node_id": "MDQ6VXNlcjEzMjY5NzAz", "avatar_url": "https://avatars0.githubusercontent.com/u/13269703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cherishlc", "html_url": "https://github.com/cherishlc", "followers_url": "https://api.github.com/users/cherishlc/followers", "following_url": "https://api.github.com/users/cherishlc/following{/other_user}", "gists_url": "https://api.github.com/users/cherishlc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cherishlc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cherishlc/subscriptions", "organizations_url": "https://api.github.com/users/cherishlc/orgs", "repos_url": "https://api.github.com/users/cherishlc/repos", "events_url": "https://api.github.com/users/cherishlc/events{/privacy}", "received_events_url": "https://api.github.com/users/cherishlc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-02T08:40:08Z", "updated_at": "2018-05-02T13:45:57Z", "closed_at": "2018-05-02T13:45:57Z", "author_association": "NONE", "body_html": "<p>tensorflow version: 1.6</p>\n<h3>bug description:</h3>\n<p>when using hash_table in \"tensorflow.python.ops.gen_lookup_ops\"  in tf.data.Dataset.map function<br>\nbecause  tf.data.Dataset.map do not use the default graph, the hash_table can not be initialized.</p>\n<h3>Exception:</h3>\n<p>FailedPreconditionError (see above for traceback): Table not initialized.</p>\n<h3>code:</h3>\n<p>from <strong>future</strong> import absolute_import, division, print_function<br>\nimport tensorflow as tf<br>\ntry:<br>\nfrom tensorflow.python.ops.gen_lookup_ops import hash_table as _hash_table<br>\nfrom tensorflow.python.ops.gen_lookup_ops import initialize_table as _initialize_table<br>\nfrom tensorflow.python.ops.gen_lookup_ops import initialize_table_from_text_file as _initialize_table_from_text_file<br>\nfrom tensorflow.python.ops.gen_lookup_ops import lookup_table_find as _lookup_table_find<br>\nfrom tensorflow.python.ops.gen_lookup_ops import lookup_table_size as _lookup_table_size<br>\nexcept:<br>\nfrom tensorflow.python.ops.gen_lookup_ops import _hash_table<br>\nfrom tensorflow.python.ops.gen_lookup_ops import _initialize_table<br>\nfrom tensorflow.python.ops.gen_lookup_ops import _initialize_table_from_text_file<br>\nfrom tensorflow.python.ops.gen_lookup_ops import _lookup_table_find<br>\nfrom tensorflow.python.ops.gen_lookup_ops import _lookup_table_size</p>\n<p>def look_up(input_tensor, look_up_table_ref, default_value=tf.constant(0, dtype=tf.int64), name=None):<br>\ni_shape = input_tensor.get_shape()<br>\nr = _lookup_table_find(look_up_table_ref, keys=input_tensor, default_value=default_value)<br>\nr.set_shape(i_shape)<br>\nreturn r</p>\n<p>def string2int64_via_map(input_tensor, keys, values, default_value=0, table_ref=None):<br>\nfrom tensorflow.python.framework import ops<br>\nwith tf.name_scope('string2int64_via_map'):<br>\nkey_type = tf.string<br>\nvalue_type = tf.int64<br>\nkeys = tf.convert_to_tensor(keys, dtype=key_type)<br>\nvalues = tf.convert_to_tensor(values, dtype=value_type)<br>\ndefault_value = tf.convert_to_tensor(default_value, dtype=value_type)<br>\nif(table_ref is None):<br>\ntable_ref = _hash_table(key_dtype=key_type, value_dtype=value_type)<br>\ninit_op = _initialize_table(table_ref, keys, values)<br>\nops.add_to_collection(ops.GraphKeys.TABLE_INITIALIZERS, init_op)<br>\nindices = _lookup_table_find(table_ref, keys=input_tensor, default_value=default_value)</p>\n<pre><code>    print(\"graph in string2int64_via_map: \\t%s\" % tf.get_default_graph())\n    return indices, table_ref\n</code></pre>\n<p>def __test_string2int64_via_map():<br>\n''' this function works well<br>\n'''<br>\nprint('__test_string2int64_via_map()')<br>\nkeys = ['s1', 's2', 's3']<br>\nvalues = [10, 20, 30]<br>\ninput_tensor = ['s2', 's4', 's6', 's8', 's3']<br>\ndefault_value = 0</p>\n<pre><code>indices, _ = string2int64_via_map(input_tensor, keys, values, default_value)\nwith tf.Session() as sess:\n    sess.run(tf.tables_initializer())\n    rr = sess.run(indices)\n    print(rr)\n    import sys\n    sys.stdout.flush()\n</code></pre>\n<p>def test_dataset_using_hashmap():<br>\nfeatures = ['s1', 's2', 's3']<br>\nlabels = [0, 1, 2]<br>\nsess = tf.Session()</p>\n<pre><code>def mapfun_works(txt, label):\n    return (tf.string_join([\"prefix:\", txt], separator=''), label)\n\ndef mapfun_using_hash_table(txt, label):\n    keys = ['s1', 's2', 's3']\n    values = [10, 20, 30]\n    default_value = 0\n    indices, _ = string2int64_via_map(txt, keys, values, default_value)\n    return (indices, label)\n    \nmapfunc = mapfun_using_hash_table  # change to mapfun1 works\n\ndef train_input_fn(features, labels, batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n    dataset = dataset.shuffle(10).repeat().batch(batch_size)\n    dataset = dataset.map(mapfunc, num_parallel_calls=1)\n    return dataset\n\ndataset = train_input_fn(features, labels, batch_size=4)\nit = dataset.make_initializable_iterator()\nsess.run(it.initializer)\nsess.run(tf.tables_initializer())  # not work because the hash table is in another graph\n\nprint(\"graph in main: \\t\\t\\t%s\" % tf.get_default_graph())\nprint(sess.run(it.get_next()))\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\n__test_string2int64_via_map()<br>\nprint('\\n------------------------------\\n')<br>\ntest_dataset_using_hashmap()</p>", "body_text": "tensorflow version: 1.6\nbug description:\nwhen using hash_table in \"tensorflow.python.ops.gen_lookup_ops\"  in tf.data.Dataset.map function\nbecause  tf.data.Dataset.map do not use the default graph, the hash_table can not be initialized.\nException:\nFailedPreconditionError (see above for traceback): Table not initialized.\ncode:\nfrom future import absolute_import, division, print_function\nimport tensorflow as tf\ntry:\nfrom tensorflow.python.ops.gen_lookup_ops import hash_table as _hash_table\nfrom tensorflow.python.ops.gen_lookup_ops import initialize_table as _initialize_table\nfrom tensorflow.python.ops.gen_lookup_ops import initialize_table_from_text_file as _initialize_table_from_text_file\nfrom tensorflow.python.ops.gen_lookup_ops import lookup_table_find as _lookup_table_find\nfrom tensorflow.python.ops.gen_lookup_ops import lookup_table_size as _lookup_table_size\nexcept:\nfrom tensorflow.python.ops.gen_lookup_ops import _hash_table\nfrom tensorflow.python.ops.gen_lookup_ops import _initialize_table\nfrom tensorflow.python.ops.gen_lookup_ops import _initialize_table_from_text_file\nfrom tensorflow.python.ops.gen_lookup_ops import _lookup_table_find\nfrom tensorflow.python.ops.gen_lookup_ops import _lookup_table_size\ndef look_up(input_tensor, look_up_table_ref, default_value=tf.constant(0, dtype=tf.int64), name=None):\ni_shape = input_tensor.get_shape()\nr = _lookup_table_find(look_up_table_ref, keys=input_tensor, default_value=default_value)\nr.set_shape(i_shape)\nreturn r\ndef string2int64_via_map(input_tensor, keys, values, default_value=0, table_ref=None):\nfrom tensorflow.python.framework import ops\nwith tf.name_scope('string2int64_via_map'):\nkey_type = tf.string\nvalue_type = tf.int64\nkeys = tf.convert_to_tensor(keys, dtype=key_type)\nvalues = tf.convert_to_tensor(values, dtype=value_type)\ndefault_value = tf.convert_to_tensor(default_value, dtype=value_type)\nif(table_ref is None):\ntable_ref = _hash_table(key_dtype=key_type, value_dtype=value_type)\ninit_op = _initialize_table(table_ref, keys, values)\nops.add_to_collection(ops.GraphKeys.TABLE_INITIALIZERS, init_op)\nindices = _lookup_table_find(table_ref, keys=input_tensor, default_value=default_value)\n    print(\"graph in string2int64_via_map: \\t%s\" % tf.get_default_graph())\n    return indices, table_ref\n\ndef __test_string2int64_via_map():\n''' this function works well\n'''\nprint('__test_string2int64_via_map()')\nkeys = ['s1', 's2', 's3']\nvalues = [10, 20, 30]\ninput_tensor = ['s2', 's4', 's6', 's8', 's3']\ndefault_value = 0\nindices, _ = string2int64_via_map(input_tensor, keys, values, default_value)\nwith tf.Session() as sess:\n    sess.run(tf.tables_initializer())\n    rr = sess.run(indices)\n    print(rr)\n    import sys\n    sys.stdout.flush()\n\ndef test_dataset_using_hashmap():\nfeatures = ['s1', 's2', 's3']\nlabels = [0, 1, 2]\nsess = tf.Session()\ndef mapfun_works(txt, label):\n    return (tf.string_join([\"prefix:\", txt], separator=''), label)\n\ndef mapfun_using_hash_table(txt, label):\n    keys = ['s1', 's2', 's3']\n    values = [10, 20, 30]\n    default_value = 0\n    indices, _ = string2int64_via_map(txt, keys, values, default_value)\n    return (indices, label)\n    \nmapfunc = mapfun_using_hash_table  # change to mapfun1 works\n\ndef train_input_fn(features, labels, batch_size):\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n    dataset = dataset.shuffle(10).repeat().batch(batch_size)\n    dataset = dataset.map(mapfunc, num_parallel_calls=1)\n    return dataset\n\ndataset = train_input_fn(features, labels, batch_size=4)\nit = dataset.make_initializable_iterator()\nsess.run(it.initializer)\nsess.run(tf.tables_initializer())  # not work because the hash table is in another graph\n\nprint(\"graph in main: \\t\\t\\t%s\" % tf.get_default_graph())\nprint(sess.run(it.get_next()))\n\nif name == 'main':\n__test_string2int64_via_map()\nprint('\\n------------------------------\\n')\ntest_dataset_using_hashmap()", "body": "tensorflow version: 1.6\r\n\r\n### bug description: \r\n  when using hash_table in \"tensorflow.python.ops.gen_lookup_ops\"  in tf.data.Dataset.map function\r\nbecause  tf.data.Dataset.map do not use the default graph, the hash_table can not be initialized.\r\n\r\n### Exception: \r\n  FailedPreconditionError (see above for traceback): Table not initialized.\r\n\r\n### code:\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\ntry:\r\n    from tensorflow.python.ops.gen_lookup_ops import hash_table as _hash_table\r\n    from tensorflow.python.ops.gen_lookup_ops import initialize_table as _initialize_table\r\n    from tensorflow.python.ops.gen_lookup_ops import initialize_table_from_text_file as _initialize_table_from_text_file\r\n    from tensorflow.python.ops.gen_lookup_ops import lookup_table_find as _lookup_table_find\r\n    from tensorflow.python.ops.gen_lookup_ops import lookup_table_size as _lookup_table_size\r\nexcept:\r\n    from tensorflow.python.ops.gen_lookup_ops import _hash_table\r\n    from tensorflow.python.ops.gen_lookup_ops import _initialize_table\r\n    from tensorflow.python.ops.gen_lookup_ops import _initialize_table_from_text_file\r\n    from tensorflow.python.ops.gen_lookup_ops import _lookup_table_find\r\n    from tensorflow.python.ops.gen_lookup_ops import _lookup_table_size    \r\n\r\ndef look_up(input_tensor, look_up_table_ref, default_value=tf.constant(0, dtype=tf.int64), name=None):\r\n    i_shape = input_tensor.get_shape()\r\n    r = _lookup_table_find(look_up_table_ref, keys=input_tensor, default_value=default_value)\r\n    r.set_shape(i_shape)\r\n    return r\r\n\r\ndef string2int64_via_map(input_tensor, keys, values, default_value=0, table_ref=None): \r\n    from tensorflow.python.framework import ops\r\n    with tf.name_scope('string2int64_via_map'):\r\n        key_type = tf.string\r\n        value_type = tf.int64\r\n        keys = tf.convert_to_tensor(keys, dtype=key_type)\r\n        values = tf.convert_to_tensor(values, dtype=value_type)\r\n        default_value = tf.convert_to_tensor(default_value, dtype=value_type)\r\n        if(table_ref is None):\r\n            table_ref = _hash_table(key_dtype=key_type, value_dtype=value_type)\r\n        init_op = _initialize_table(table_ref, keys, values)\r\n        ops.add_to_collection(ops.GraphKeys.TABLE_INITIALIZERS, init_op)\r\n        indices = _lookup_table_find(table_ref, keys=input_tensor, default_value=default_value)\r\n        \r\n        print(\"graph in string2int64_via_map: \\t%s\" % tf.get_default_graph())\r\n        return indices, table_ref\r\n\r\n\r\ndef __test_string2int64_via_map():\r\n    ''' this function works well\r\n    '''\r\n    print('__test_string2int64_via_map()')\r\n    keys = ['s1', 's2', 's3']\r\n    values = [10, 20, 30]\r\n    input_tensor = ['s2', 's4', 's6', 's8', 's3']\r\n    default_value = 0\r\n    \r\n    indices, _ = string2int64_via_map(input_tensor, keys, values, default_value)\r\n    with tf.Session() as sess:\r\n        sess.run(tf.tables_initializer())\r\n        rr = sess.run(indices)\r\n        print(rr)\r\n        import sys\r\n        sys.stdout.flush()\r\n\r\ndef test_dataset_using_hashmap():\r\n    features = ['s1', 's2', 's3']\r\n    labels = [0, 1, 2]\r\n    sess = tf.Session()\r\n    \r\n    def mapfun_works(txt, label):\r\n        return (tf.string_join([\"prefix:\", txt], separator=''), label)\r\n    \r\n    def mapfun_using_hash_table(txt, label):\r\n        keys = ['s1', 's2', 's3']\r\n        values = [10, 20, 30]\r\n        default_value = 0\r\n        indices, _ = string2int64_via_map(txt, keys, values, default_value)\r\n        return (indices, label)\r\n        \r\n    mapfunc = mapfun_using_hash_table  # change to mapfun1 works\r\n    \r\n    def train_input_fn(features, labels, batch_size):\r\n        dataset = tf.data.Dataset.from_tensor_slices((features, labels))\r\n        dataset = dataset.shuffle(10).repeat().batch(batch_size)\r\n        dataset = dataset.map(mapfunc, num_parallel_calls=1)\r\n        return dataset\r\n    \r\n    dataset = train_input_fn(features, labels, batch_size=4)\r\n    it = dataset.make_initializable_iterator()\r\n    sess.run(it.initializer)\r\n    sess.run(tf.tables_initializer())  # not work because the hash table is in another graph\r\n    \r\n    print(\"graph in main: \\t\\t\\t%s\" % tf.get_default_graph())\r\n    print(sess.run(it.get_next()))\r\n\r\n\r\nif __name__ == '__main__':\r\n    __test_string2int64_via_map()\r\n    print('\\n------------------------------\\n')\r\n    test_dataset_using_hashmap()\r\n\r\n"}