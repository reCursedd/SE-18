{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22274", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22274/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22274/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22274/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22274", "id": 360282489, "node_id": "MDU6SXNzdWUzNjAyODI0ODk=", "number": 22274, "title": "CollectiveAllReduceStrategy fails with CPU-only workers", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yuefengz", "id": 1647833, "node_id": "MDQ6VXNlcjE2NDc4MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1647833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuefengz", "html_url": "https://github.com/yuefengz", "followers_url": "https://api.github.com/users/yuefengz/followers", "following_url": "https://api.github.com/users/yuefengz/following{/other_user}", "gists_url": "https://api.github.com/users/yuefengz/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuefengz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuefengz/subscriptions", "organizations_url": "https://api.github.com/users/yuefengz/orgs", "repos_url": "https://api.github.com/users/yuefengz/repos", "events_url": "https://api.github.com/users/yuefengz/events{/privacy}", "received_events_url": "https://api.github.com/users/yuefengz/received_events", "type": "User", "site_admin": false}, {"login": "dubey", "id": 2314265, "node_id": "MDQ6VXNlcjIzMTQyNjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/2314265?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dubey", "html_url": "https://github.com/dubey", "followers_url": "https://api.github.com/users/dubey/followers", "following_url": "https://api.github.com/users/dubey/following{/other_user}", "gists_url": "https://api.github.com/users/dubey/gists{/gist_id}", "starred_url": "https://api.github.com/users/dubey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dubey/subscriptions", "organizations_url": "https://api.github.com/users/dubey/orgs", "repos_url": "https://api.github.com/users/dubey/repos", "events_url": "https://api.github.com/users/dubey/events{/privacy}", "received_events_url": "https://api.github.com/users/dubey/received_events", "type": "User", "site_admin": false}, {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-09-14T12:22:05Z", "updated_at": "2018-09-20T23:46:36Z", "closed_at": "2018-09-20T23:46:36Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: macOS High Sierra</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: tf-nightly</li>\n<li><strong>TensorFlow version (use command below)</strong>: ('v1.9.0-rc2-4081-g626bc997c2', '1.11.0-dev20180913')</li>\n<li><strong>Python version</strong>: Python 2.7.15</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: <a href=\"https://gist.github.com/df3df82f7ae8f47b6288fc42eb8c8b17\">https://gist.github.com/df3df82f7ae8f47b6288fc42eb8c8b17</a></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Invoke <code>tf.estimator.train_and_evaluate</code> with <code>CollectiveAllReduceStrategy</code> fails on CPU-only worker nodes, with the following message:</p>\n<pre><code>InternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\n</code></pre>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow.contrib.distribute <span class=\"pl-k\">import</span> CollectiveAllReduceStrategy\n<span class=\"pl-k\">from</span> tensorflow.contrib.distribute <span class=\"pl-k\">import</span> DistributeConfig\n\ndistribution <span class=\"pl-k\">=</span> CollectiveAllReduceStrategy(<span class=\"pl-v\">num_gpus_per_worker</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\nconfig <span class=\"pl-k\">=</span> tf.estimator.RunConfig(\n    <span class=\"pl-v\">experimental_distribute</span><span class=\"pl-k\">=</span>DistributeConfig(\n        <span class=\"pl-v\">train_distribute</span><span class=\"pl-k\">=</span>distribution,\n        <span class=\"pl-v\">remote_cluster</span><span class=\"pl-k\">=</span>{\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>worker<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>localhost:5000<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>localhost:5001<span class=\"pl-pds\">'</span></span>],\n        },\n    )\n)\n\nestimator <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_fn, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\n\ntf.estimator.train_and_evaluate(<span class=\"pl-v\">estimator</span><span class=\"pl-k\">=</span>estimator, <span class=\"pl-v\">train_spec</span><span class=\"pl-k\">=</span>train_spec, <span class=\"pl-v\">eval_spec</span><span class=\"pl-k\">=</span>eval_spec)</pre></div>\n<pre><code>INFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': {'worker': ['localhost:5000', 'localhost:5001']}, '_model_dir': '/var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=&lt;tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810&gt;, eval_distribute=None, remote_cluster={'worker': ['localhost:5000', 'localhost:5001']}), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': &lt;tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810&gt;, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ['/job:worker/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ['/job:worker/task:1']\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\n}\n\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\n}\n\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Initialize system\nINFO:tensorflow:Initialize system\nINFO:tensorflow:Saving checkpoints for 0 into /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6/model.ckpt.\n\nException in thread Thread-5:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\n    worker_fn(strategy)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\n    hooks=list(train_spec.hooks))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\n    saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\n    raise six.reraise(*original_exc_info)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\n    run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\n    raise type(e)(node_def, op, message)\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:1/device:CPU:0\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"]()]]\n\nException in thread Thread-4:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\n    worker_fn(strategy)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\n    hooks=list(train_spec.hooks))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\n    saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\n    raise six.reraise(*original_exc_info)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\n    run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\n    raise type(e)(node_def, op, message)\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]\n</code></pre>\n<p>PS: thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1647833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuefengz\">@yuefengz</a> for today's introduction of multi-node distribution strategy in TF Roadshow 2018@Beijing <g-emoji class=\"g-emoji\" alias=\"laughing\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f606.png\">\ud83d\ude06</g-emoji></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): tf-nightly\nTensorFlow version (use command below): ('v1.9.0-rc2-4081-g626bc997c2', '1.11.0-dev20180913')\nPython version: Python 2.7.15\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: https://gist.github.com/df3df82f7ae8f47b6288fc42eb8c8b17\n\nDescribe the problem\nInvoke tf.estimator.train_and_evaluate with CollectiveAllReduceStrategy fails on CPU-only worker nodes, with the following message:\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\n\nSource code / logs\nfrom tensorflow.contrib.distribute import CollectiveAllReduceStrategy\nfrom tensorflow.contrib.distribute import DistributeConfig\n\ndistribution = CollectiveAllReduceStrategy(num_gpus_per_worker=0)\n\nconfig = tf.estimator.RunConfig(\n    experimental_distribute=DistributeConfig(\n        train_distribute=distribution,\n        remote_cluster={\n            'worker': ['localhost:5000', 'localhost:5001'],\n        },\n    )\n)\n\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n\ntf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': {'worker': ['localhost:5000', 'localhost:5001']}, '_model_dir': '/var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810>, eval_distribute=None, remote_cluster={'worker': ['localhost:5000', 'localhost:5001']}), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810>, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ['/job:worker/task:0']\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ['/job:worker/task:1']\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\n}\n\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\nallow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n    scoped_allocator_optimization: ON\n    scoped_allocator_opts {\n      enable_op: \"CollectiveReduce\"\n    }\n  }\n}\nisolate_session_state: true\nexperimental {\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\n}\n\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Initialize system\nINFO:tensorflow:Initialize system\nINFO:tensorflow:Saving checkpoints for 0 into /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6/model.ckpt.\n\nException in thread Thread-5:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\n    worker_fn(strategy)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\n    hooks=list(train_spec.hooks))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\n    saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\n    raise six.reraise(*original_exc_info)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\n    run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\n    raise type(e)(node_def, op, message)\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:1/device:CPU:0\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"]()]]\n\nException in thread Thread-4:\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n    self.run()\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\n    worker_fn(strategy)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\n    hooks=list(train_spec.hooks))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\n    saving_listeners)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\n    raise six.reraise(*original_exc_info)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\n    run_metadata=run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\n    run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\n    raise type(e)(node_def, op, message)\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]\n\nPS: thanks @yuefengz for today's introduction of multi-node distribution strategy in TF Roadshow 2018@Beijing \ud83d\ude06", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: tf-nightly\r\n- **TensorFlow version (use command below)**: ('v1.9.0-rc2-4081-g626bc997c2', '1.11.0-dev20180913')\r\n- **Python version**: Python 2.7.15\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: https://gist.github.com/df3df82f7ae8f47b6288fc42eb8c8b17\r\n\r\n### Describe the problem\r\nInvoke `tf.estimator.train_and_evaluate` with `CollectiveAllReduceStrategy` fails on CPU-only worker nodes, with the following message:\r\n\r\n```\r\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\r\n```\r\n\r\n### Source code / logs\r\n\r\n```python\r\nfrom tensorflow.contrib.distribute import CollectiveAllReduceStrategy\r\nfrom tensorflow.contrib.distribute import DistributeConfig\r\n\r\ndistribution = CollectiveAllReduceStrategy(num_gpus_per_worker=0)\r\n\r\nconfig = tf.estimator.RunConfig(\r\n    experimental_distribute=DistributeConfig(\r\n        train_distribute=distribution,\r\n        remote_cluster={\r\n            'worker': ['localhost:5000', 'localhost:5001'],\r\n        },\r\n    )\r\n)\r\n\r\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n\r\ntf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\r\n```\r\n```\r\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\r\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': {'worker': ['localhost:5000', 'localhost:5001']}, '_model_dir': '/var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810>, eval_distribute=None, remote_cluster={'worker': ['localhost:5000', 'localhost:5001']}), '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x123f09810>, '_master': '', '_distribute_coordinator_mode': 'standalone_client'}\r\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\r\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ['/job:worker/task:0']\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['localhost:5000', 'localhost:5001']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ['/job:worker/task:1']\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n    scoped_allocator_optimization: ON\r\n    scoped_allocator_opts {\r\n      enable_op: \"CollectiveReduce\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\nexperimental {\r\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\r\n}\r\n\r\nINFO:tensorflow:Collective All-reduce invoked with batches size = 2, num_workers = 2\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:1\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n    scoped_allocator_optimization: ON\r\n    scoped_allocator_opts {\r\n      enable_op: \"CollectiveReduce\"\r\n    }\r\n  }\r\n}\r\nisolate_session_state: true\r\nexperimental {\r\n  collective_group_leader: \"/job:worker/replica:0/task:0\"\r\n}\r\n\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Initialize system\r\nINFO:tensorflow:Initialize system\r\nINFO:tensorflow:Saving checkpoints for 0 into /var/folders/gn/sjntndrs1fs22kfr302697mr0000gn/T/tmpeIE_x6/model.ckpt.\r\n\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\r\n    worker_fn(strategy)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\r\n    hooks=list(train_spec.hooks))\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:1/device:CPU:0\r\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"]()]]\r\n\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\r\n    worker_fn(strategy)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/distribute/estimator_training.py\", line 232, in _worker_fn\r\n    hooks=list(train_spec.hooks))\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1178, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1325, in _train_model_distributed\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1148, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1239, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1224, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1296, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1306, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nInternalError: ScopedAllocatorMgr not supported on device /job:worker/replica:0/task:0/device:CPU:0\r\n\t [[{{node scoped_allocator_1}} = _ScopedAllocator[T=DT_FLOAT, expected_call_count=2, id=1, sa_name=\"scoped_allocator_1\", shape=[17], shapes=[[1,1], [1]], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\nPS: thanks @yuefengz for today's introduction of multi-node distribution strategy in TF Roadshow 2018@Beijing \ud83d\ude06"}