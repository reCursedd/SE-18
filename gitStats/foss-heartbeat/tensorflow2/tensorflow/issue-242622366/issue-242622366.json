{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11471", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11471/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11471/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11471/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11471", "id": 242622366, "node_id": "MDU6SXNzdWUyNDI2MjIzNjY=", "number": 11471, "title": "XLA crash on Wasserstein GAN", "user": {"login": "Randl", "id": 3028543, "node_id": "MDQ6VXNlcjMwMjg1NDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/3028543?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Randl", "html_url": "https://github.com/Randl", "followers_url": "https://api.github.com/users/Randl/followers", "following_url": "https://api.github.com/users/Randl/following{/other_user}", "gists_url": "https://api.github.com/users/Randl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Randl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Randl/subscriptions", "organizations_url": "https://api.github.com/users/Randl/orgs", "repos_url": "https://api.github.com/users/Randl/repos", "events_url": "https://api.github.com/users/Randl/events{/privacy}", "received_events_url": "https://api.github.com/users/Randl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jlebar", "id": 150663, "node_id": "MDQ6VXNlcjE1MDY2Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/150663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlebar", "html_url": "https://github.com/jlebar", "followers_url": "https://api.github.com/users/jlebar/followers", "following_url": "https://api.github.com/users/jlebar/following{/other_user}", "gists_url": "https://api.github.com/users/jlebar/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlebar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlebar/subscriptions", "organizations_url": "https://api.github.com/users/jlebar/orgs", "repos_url": "https://api.github.com/users/jlebar/repos", "events_url": "https://api.github.com/users/jlebar/events{/privacy}", "received_events_url": "https://api.github.com/users/jlebar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-07-13T08:23:38Z", "updated_at": "2017-12-20T19:46:21Z", "closed_at": "2017-12-20T19:46:21Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: TensorFlow installed from source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.2.0-1382-g708cbaf 1.2.0</li>\n<li><strong>Python version</strong>:  Python 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 8 / cudnn 6</li>\n<li><strong>GPU model and memory</strong>: 2x1080 Ti, 12 Gb</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When I'm running this code: <a href=\"https://github.com/Randl/WassersteinGAN.tensorflow\">https://github.com/Randl/WassersteinGAN.tensorflow</a> with XLA, I get the following error message:</p>\n<pre><code>LLVM ERROR: Cannot select: 0x7f4c300d4878: i16,ch = AtomicCmpSwap&lt;Volatile LDST1[%_fusion.typed16(addrspace=1)]&gt; 0x7f4c30093858, 0x7f4c300d5098, 0x7f4c300d5168, 0x7f4c300e6c20\n  0x7f4c300d5098: i64,ch = CopyFromReg 0x7f4c30093858, Register:i64 %vreg0\n    0x7f4c300d5100: i64 = Register %vreg0\n  0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\n    0x7f4c300d56b0: i16 = Register %vreg3\n  0x7f4c300e6c20: i16 = and 0x7f4c300d5168, 0x7f4c300d5370\n    0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\n      0x7f4c300d56b0: i16 = Register %vreg3\n    0x7f4c300d5370: i16 = AssertZext 0x7f4c300d4c20, ValueType:ch:i1\n      0x7f4c300d4c20: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg1\n        0x7f4c300d4948: i16 = Register %vreg1\nIn function: _fusion__1\n*** Error in `python3': free(): invalid size: 0x00007f4ac8091fe0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f4e6c2507e5]\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f4e6c25937a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f4e6c25d53c]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0x6b98aa)[0x7f4a9f3f48aa]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xdb80e)[0x7f4a9ee1680e]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xc034b)[0x7f4a9edfb34b]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(__cuda_CallJitEntryPoint+0xdcc)[0x7f4a9edf1aec]\n/usr/lib/nvidia-375/libnvidia-fatbinaryloader.so.375.66(fatBinaryCtl_Compile+0x302)[0x7f4df0b125c2]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a1ee2)[0x7f4e07c31ee2]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a2a63)[0x7f4e07c32a63]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a3133)[0x7f4e07c33133]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0xcf7b3)[0x7f4e07b5f7b3]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(cuModuleLoadDataEx+0x75)[0x7f4e07c77055]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x4d0b7ba)[0x7f4e1370d7ba]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0xff)[0x7f4e139e998f]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x2d)[0x7f4e139e977d]\n</code></pre>\n<p>Without XLA it works OK.</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): TensorFlow installed from source\nTensorFlow version (use command below): v1.2.0-1382-g708cbaf 1.2.0\nPython version:  Python 3.5.2\nBazel version (if compiling from source):\nCUDA/cuDNN version: CUDA 8 / cudnn 6\nGPU model and memory: 2x1080 Ti, 12 Gb\n\nDescribe the problem\nWhen I'm running this code: https://github.com/Randl/WassersteinGAN.tensorflow with XLA, I get the following error message:\nLLVM ERROR: Cannot select: 0x7f4c300d4878: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7f4c30093858, 0x7f4c300d5098, 0x7f4c300d5168, 0x7f4c300e6c20\n  0x7f4c300d5098: i64,ch = CopyFromReg 0x7f4c30093858, Register:i64 %vreg0\n    0x7f4c300d5100: i64 = Register %vreg0\n  0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\n    0x7f4c300d56b0: i16 = Register %vreg3\n  0x7f4c300e6c20: i16 = and 0x7f4c300d5168, 0x7f4c300d5370\n    0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\n      0x7f4c300d56b0: i16 = Register %vreg3\n    0x7f4c300d5370: i16 = AssertZext 0x7f4c300d4c20, ValueType:ch:i1\n      0x7f4c300d4c20: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg1\n        0x7f4c300d4948: i16 = Register %vreg1\nIn function: _fusion__1\n*** Error in `python3': free(): invalid size: 0x00007f4ac8091fe0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f4e6c2507e5]\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f4e6c25937a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f4e6c25d53c]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0x6b98aa)[0x7f4a9f3f48aa]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xdb80e)[0x7f4a9ee1680e]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xc034b)[0x7f4a9edfb34b]\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(__cuda_CallJitEntryPoint+0xdcc)[0x7f4a9edf1aec]\n/usr/lib/nvidia-375/libnvidia-fatbinaryloader.so.375.66(fatBinaryCtl_Compile+0x302)[0x7f4df0b125c2]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a1ee2)[0x7f4e07c31ee2]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a2a63)[0x7f4e07c32a63]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a3133)[0x7f4e07c33133]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0xcf7b3)[0x7f4e07b5f7b3]\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(cuModuleLoadDataEx+0x75)[0x7f4e07c77055]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x4d0b7ba)[0x7f4e1370d7ba]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0xff)[0x7f4e139e998f]\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x2d)[0x7f4e139e977d]\n\nWithout XLA it works OK.", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: TensorFlow installed from source\r\n- **TensorFlow version (use command below)**: v1.2.0-1382-g708cbaf 1.2.0\r\n- **Python version**:  Python 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 8 / cudnn 6\r\n- **GPU model and memory**: 2x1080 Ti, 12 Gb\r\n### Describe the problem\r\nWhen I'm running this code: https://github.com/Randl/WassersteinGAN.tensorflow with XLA, I get the following error message:\r\n```\r\nLLVM ERROR: Cannot select: 0x7f4c300d4878: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7f4c30093858, 0x7f4c300d5098, 0x7f4c300d5168, 0x7f4c300e6c20\r\n  0x7f4c300d5098: i64,ch = CopyFromReg 0x7f4c30093858, Register:i64 %vreg0\r\n    0x7f4c300d5100: i64 = Register %vreg0\r\n  0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\r\n    0x7f4c300d56b0: i16 = Register %vreg3\r\n  0x7f4c300e6c20: i16 = and 0x7f4c300d5168, 0x7f4c300d5370\r\n    0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3\r\n      0x7f4c300d56b0: i16 = Register %vreg3\r\n    0x7f4c300d5370: i16 = AssertZext 0x7f4c300d4c20, ValueType:ch:i1\r\n      0x7f4c300d4c20: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg1\r\n        0x7f4c300d4948: i16 = Register %vreg1\r\nIn function: _fusion__1\r\n*** Error in `python3': free(): invalid size: 0x00007f4ac8091fe0 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f4e6c2507e5]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f4e6c25937a]\r\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f4e6c25d53c]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0x6b98aa)[0x7f4a9f3f48aa]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xdb80e)[0x7f4a9ee1680e]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xc034b)[0x7f4a9edfb34b]\r\n/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(__cuda_CallJitEntryPoint+0xdcc)[0x7f4a9edf1aec]\r\n/usr/lib/nvidia-375/libnvidia-fatbinaryloader.so.375.66(fatBinaryCtl_Compile+0x302)[0x7f4df0b125c2]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a1ee2)[0x7f4e07c31ee2]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a2a63)[0x7f4e07c32a63]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a3133)[0x7f4e07c33133]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0xcf7b3)[0x7f4e07b5f7b3]\r\n/usr/lib/x86_64-linux-gnu/libcuda.so.1(cuModuleLoadDataEx+0x75)[0x7f4e07c77055]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x4d0b7ba)[0x7f4e1370d7ba]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0xff)[0x7f4e139e998f]\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x2d)[0x7f4e139e977d]\r\n```\r\n\r\nWithout XLA it works OK.\r\n"}