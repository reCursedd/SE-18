{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7145", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7145/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7145/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7145/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7145", "id": 203961090, "node_id": "MDU6SXNzdWUyMDM5NjEwOTA=", "number": 7145, "title": "GPU not registrering after pip update to 0.12 from 0.10", "user": {"login": "stillwalker1234", "id": 8694103, "node_id": "MDQ6VXNlcjg2OTQxMDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8694103?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stillwalker1234", "html_url": "https://github.com/stillwalker1234", "followers_url": "https://api.github.com/users/stillwalker1234/followers", "following_url": "https://api.github.com/users/stillwalker1234/following{/other_user}", "gists_url": "https://api.github.com/users/stillwalker1234/gists{/gist_id}", "starred_url": "https://api.github.com/users/stillwalker1234/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stillwalker1234/subscriptions", "organizations_url": "https://api.github.com/users/stillwalker1234/orgs", "repos_url": "https://api.github.com/users/stillwalker1234/repos", "events_url": "https://api.github.com/users/stillwalker1234/events{/privacy}", "received_events_url": "https://api.github.com/users/stillwalker1234/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-01-30T09:31:36Z", "updated_at": "2017-01-30T10:17:20Z", "closed_at": "2017-01-30T10:17:20Z", "author_association": "NONE", "body_html": "<p>Since upgrading via pip, tensorflow does not use my GPU.</p>\n<pre><code>&gt;&gt;&gt; from tensorflow.python.client import device_lib\n&gt;&gt;&gt; [x.name for x in device_lib.list_local_devices()]\n['/cpu:0']\n&gt;&gt;&gt;\n</code></pre>\n<p>Device looks correctly installed</p>\n<pre><code>/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 970\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    5.2\n  Total amount of global memory:                 4036 MBytes (4231528448 bytes)\n  (13) Multiprocessors, (128) CUDA Cores/MP:     1664 CUDA Cores\n  GPU Max Clock rate:                            1216 MHz (1.22 GHz)\n  Memory Clock rate:                             3505 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 1835008 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     No\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 970\nResult = PASS\n</code></pre>\n<p>Theano works fine</p>\n<pre><code>&gt; python -c \"import theano\"\nUsing gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5105)\n</code></pre>\n<p>Added the following to ~/.bashrc</p>\n<pre><code>export CUDA_HOME=/usr/local/cuda-8.0\nexport CUDA_ROOT=/usr/local/cuda-8.0\nexport PATH=$PATH:$CUDA_ROOT/bin\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_ROOT/lib64:$CUDA_ROOT/extras/CUPTI/lib64\n</code></pre>\n<p>Anybody have an idea how to figure this out? I could off cause try to re-install everything, but I would rather figure out why this isn't working.</p>\n<p>thanks in advance :)</p>\n<p>NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.</p>\n<p>For general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>None</p>\n<h3>Environment info</h3>\n<p>Operating System:</p>\n<p>Ubuntu 16.04</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>Cuda 8.0, cuDNN 5.1</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<p>0.12.1</p>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>)</li>\n<li>The output of <code>bazel version</code></li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<h3>What other attempted solutions have you tried?</h3>\n<p>reinstalling cuDNN</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "Since upgrading via pip, tensorflow does not use my GPU.\n>>> from tensorflow.python.client import device_lib\n>>> [x.name for x in device_lib.list_local_devices()]\n['/cpu:0']\n>>>\n\nDevice looks correctly installed\n/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 970\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    5.2\n  Total amount of global memory:                 4036 MBytes (4231528448 bytes)\n  (13) Multiprocessors, (128) CUDA Cores/MP:     1664 CUDA Cores\n  GPU Max Clock rate:                            1216 MHz (1.22 GHz)\n  Memory Clock rate:                             3505 Mhz\n  Memory Bus Width:                              256-bit\n  L2 Cache Size:                                 1835008 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\n  Run time limit on kernels:                     No\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 970\nResult = PASS\n\nTheano works fine\n> python -c \"import theano\"\nUsing gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5105)\n\nAdded the following to ~/.bashrc\nexport CUDA_HOME=/usr/local/cuda-8.0\nexport CUDA_ROOT=/usr/local/cuda-8.0\nexport PATH=$PATH:$CUDA_ROOT/bin\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_ROOT/lib64:$CUDA_ROOT/extras/CUPTI/lib64\n\nAnybody have an idea how to figure this out? I could off cause try to re-install everything, but I would rather figure out why this isn't working.\nthanks in advance :)\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nNone\nEnvironment info\nOperating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nCuda 8.0, cuDNN 5.1\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n0.12.1\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD)\nThe output of bazel version\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nWhat other attempted solutions have you tried?\nreinstalling cuDNN\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "Since upgrading via pip, tensorflow does not use my GPU.\r\n\r\n```\r\n>>> from tensorflow.python.client import device_lib\r\n>>> [x.name for x in device_lib.list_local_devices()]\r\n['/cpu:0']\r\n>>>\r\n```\r\n\r\nDevice looks correctly installed\r\n```\r\n/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 970\"\r\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\r\n  CUDA Capability Major/Minor version number:    5.2\r\n  Total amount of global memory:                 4036 MBytes (4231528448 bytes)\r\n  (13) Multiprocessors, (128) CUDA Cores/MP:     1664 CUDA Cores\r\n  GPU Max Clock rate:                            1216 MHz (1.22 GHz)\r\n  Memory Clock rate:                             3505 Mhz\r\n  Memory Bus Width:                              256-bit\r\n  L2 Cache Size:                                 1835008 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     No\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 970\r\nResult = PASS\r\n```\r\n\r\nTheano works fine\r\n\r\n```\r\n> python -c \"import theano\"\r\nUsing gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5105)\r\n```\r\n\r\nAdded the following to ~/.bashrc\r\n```\r\nexport CUDA_HOME=/usr/local/cuda-8.0\r\nexport CUDA_ROOT=/usr/local/cuda-8.0\r\nexport PATH=$PATH:$CUDA_ROOT/bin\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_ROOT/lib64:$CUDA_ROOT/extras/CUPTI/lib64\r\n```\r\n\r\nAnybody have an idea how to figure this out? I could off cause try to re-install everything, but I would rather figure out why this isn't working.\r\n\r\nthanks in advance :)\r\n \r\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nNone\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nUbuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nCuda 8.0, cuDNN 5.1\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\n0.12.1\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nreinstalling cuDNN\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}