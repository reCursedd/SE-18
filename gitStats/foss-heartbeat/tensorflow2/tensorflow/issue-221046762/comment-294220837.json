{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294220837", "html_url": "https://github.com/tensorflow/tensorflow/issues/9141#issuecomment-294220837", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9141", "id": 294220837, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDIyMDgzNw==", "user": {"login": "Caenorst", "id": 10882588, "node_id": "MDQ6VXNlcjEwODgyNTg4", "avatar_url": "https://avatars1.githubusercontent.com/u/10882588?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Caenorst", "html_url": "https://github.com/Caenorst", "followers_url": "https://api.github.com/users/Caenorst/followers", "following_url": "https://api.github.com/users/Caenorst/following{/other_user}", "gists_url": "https://api.github.com/users/Caenorst/gists{/gist_id}", "starred_url": "https://api.github.com/users/Caenorst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Caenorst/subscriptions", "organizations_url": "https://api.github.com/users/Caenorst/orgs", "repos_url": "https://api.github.com/users/Caenorst/repos", "events_url": "https://api.github.com/users/Caenorst/events{/privacy}", "received_events_url": "https://api.github.com/users/Caenorst/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-14T19:34:25Z", "updated_at": "2017-04-14T19:34:25Z", "author_association": "NONE", "body_html": "<p>Also, even for the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fused_batch_norm_op.cc#L248\">fused batch norm implementation</a> they actually transform the data_format from NCHW to NHWC before applying the CuDNN batch normalization.</p>\n<p>While bias_add can natively support NCHW and NHWC (there are both \"BiasNHWCKernel\" and \"BiasNCHWKernel\"), I have no idea if there is a speed difference between both.</p>\n<p>I guess a kind of \"broadcast_mul\" in the same manner than \"bias_add\" would be useful, for many case (batch renorm being one of them).</p>", "body_text": "Also, even for the fused batch norm implementation they actually transform the data_format from NCHW to NHWC before applying the CuDNN batch normalization.\nWhile bias_add can natively support NCHW and NHWC (there are both \"BiasNHWCKernel\" and \"BiasNCHWKernel\"), I have no idea if there is a speed difference between both.\nI guess a kind of \"broadcast_mul\" in the same manner than \"bias_add\" would be useful, for many case (batch renorm being one of them).", "body": "Also, even for the [fused batch norm implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fused_batch_norm_op.cc#L248) they actually transform the data_format from NCHW to NHWC before applying the CuDNN batch normalization.\r\n\r\nWhile bias_add can natively support NCHW and NHWC (there are both \"BiasNHWCKernel\" and \"BiasNCHWKernel\"), I have no idea if there is a speed difference between both.\r\n\r\nI guess a kind of \"broadcast_mul\" in the same manner than \"bias_add\" would be useful, for many case (batch renorm being one of them)."}