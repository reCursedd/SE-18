{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19113", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19113/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19113/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19113/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19113", "id": 320591468, "node_id": "MDU6SXNzdWUzMjA1OTE0Njg=", "number": 19113, "title": "[AdamOptimizer]Failed precondition: Attempting to use uninitialized value model_2/beta1_power", "user": {"login": "estelll", "id": 13480669, "node_id": "MDQ6VXNlcjEzNDgwNjY5", "avatar_url": "https://avatars2.githubusercontent.com/u/13480669?v=4", "gravatar_id": "", "url": "https://api.github.com/users/estelll", "html_url": "https://github.com/estelll", "followers_url": "https://api.github.com/users/estelll/followers", "following_url": "https://api.github.com/users/estelll/following{/other_user}", "gists_url": "https://api.github.com/users/estelll/gists{/gist_id}", "starred_url": "https://api.github.com/users/estelll/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/estelll/subscriptions", "organizations_url": "https://api.github.com/users/estelll/orgs", "repos_url": "https://api.github.com/users/estelll/repos", "events_url": "https://api.github.com/users/estelll/events{/privacy}", "received_events_url": "https://api.github.com/users/estelll/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelisard", "id": 5376757, "node_id": "MDQ6VXNlcjUzNzY3NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5376757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelisard", "html_url": "https://github.com/michaelisard", "followers_url": "https://api.github.com/users/michaelisard/followers", "following_url": "https://api.github.com/users/michaelisard/following{/other_user}", "gists_url": "https://api.github.com/users/michaelisard/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelisard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelisard/subscriptions", "organizations_url": "https://api.github.com/users/michaelisard/orgs", "repos_url": "https://api.github.com/users/michaelisard/repos", "events_url": "https://api.github.com/users/michaelisard/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelisard/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-06T13:11:12Z", "updated_at": "2018-05-23T01:51:21Z", "closed_at": "2018-05-23T01:51:21Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu</li>\n<li><strong>TensorFlow version (use command below)</strong>: r1.3</li>\n<li><strong>Python version</strong>: 3.6</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I write a model class that use a AdamOptimizer to update the parameters. It is a joint model so that there are two losses. It works well as I update all the parameters by the joint loss. But then I want to updated a subset of parameters by each of the loss respectively, that is , I had to call the apply_gradients() <strong>twice</strong>, it raised errors when I restore the model from .ckpt file: 'Failed precondition: Attempting to use uninitialized value model_2/beta1_power'.</p>\n<h3>Source code / logs</h3>\n<p>This is the original source code when I update the model with the whole loss.</p>\n<pre><code>\ttaggingloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.tag, logits = self.tagginglogits))\n\tclassifyloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.label, logits = self.logits))\n\tself.loss = (1 - alpha) * classifyloss + alpha * taggingloss\n\t# Gradients\n\tparams = tf.trainable_variables()\n\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n\tgradient = tf.gradients(self.loss, params)\n\tclipped_gradients, norm = tf.clip_by_global_norm(gradient, max_gradient_norm)\n\tself.gradient_norm = norm\n\tself.update = opt.apply_gradients(zip(clipped_gradients, params), global_step = self.global_step)\n\tsave_list = params\n\tsave_list.append(self.global_step)\n\tself.saver = tf.train.Saver(save_list)\n</code></pre>\n<p>then I  revised it into:</p>\n<pre><code>\t# Gradients\n\tparams = tf.trainable_variables()\n\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n\ttag_gradient = tf.gradients(taggingloss, params)\n\ttag_clipped_gradients, tag_norm = tf.clip_by_global_norm(tag_gradient, max_gradient_norm)\n\tself.tag_gradient_norm = tag_norm\n\tself.tag_update = opt.apply_gradients(zip(tag_clipped_gradients, params), global_step = self.global_step)\n\t\n\tclassify_gradient = tf.gradients(classifyloss, params)\n\tclassify_clipped_gradients, classify_norm = tf.clip_by_global_norm(classify_gradient, max_gradient_norm)\n\tself.classify_gradient_norm = classify_norm\n\tself.classify_update = opt.apply_gradients(zip(classify_clipped_gradients, params), global_step = self.global_step)\n\n\tsave_list = tf.trainable_variables()\n\tsave_list.append(self.global_step)\n\tself.saver = tf.train.Saver(save_list)\n</code></pre>\n<p>The rest are all the same, except that, I used to run the self.update operation in the train() call. Now I first run self.tag_update in the tagging() call and then run self.classify_update in the train() call.</p>\n<p>I have read the closed issue of <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"211731271\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8057\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8057/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8057\">#8057</a>. it said in it that</p>\n<blockquote>\n<p>I understood here such a thing: variables beta1_power and beta2_power are specific to each call to apply_gradients, but not to the whole graph. So if we want to call apply_gradients twice, two separate pairs of beta accumulators should be created, even if both calls are made within the single graph. This does not fit into the concept of \"graph slots\". Definitely, we should separate these slots by graphs, but we cannot simply key these slots by graphs only.</p>\n</blockquote>\n<p>But I still have no idea how ti fix it.</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu\nTensorFlow version (use command below): r1.3\nPython version: 3.6\n\nDescribe the problem\nI write a model class that use a AdamOptimizer to update the parameters. It is a joint model so that there are two losses. It works well as I update all the parameters by the joint loss. But then I want to updated a subset of parameters by each of the loss respectively, that is , I had to call the apply_gradients() twice, it raised errors when I restore the model from .ckpt file: 'Failed precondition: Attempting to use uninitialized value model_2/beta1_power'.\nSource code / logs\nThis is the original source code when I update the model with the whole loss.\n\ttaggingloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.tag, logits = self.tagginglogits))\n\tclassifyloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.label, logits = self.logits))\n\tself.loss = (1 - alpha) * classifyloss + alpha * taggingloss\n\t# Gradients\n\tparams = tf.trainable_variables()\n\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n\tgradient = tf.gradients(self.loss, params)\n\tclipped_gradients, norm = tf.clip_by_global_norm(gradient, max_gradient_norm)\n\tself.gradient_norm = norm\n\tself.update = opt.apply_gradients(zip(clipped_gradients, params), global_step = self.global_step)\n\tsave_list = params\n\tsave_list.append(self.global_step)\n\tself.saver = tf.train.Saver(save_list)\n\nthen I  revised it into:\n\t# Gradients\n\tparams = tf.trainable_variables()\n\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n\ttag_gradient = tf.gradients(taggingloss, params)\n\ttag_clipped_gradients, tag_norm = tf.clip_by_global_norm(tag_gradient, max_gradient_norm)\n\tself.tag_gradient_norm = tag_norm\n\tself.tag_update = opt.apply_gradients(zip(tag_clipped_gradients, params), global_step = self.global_step)\n\t\n\tclassify_gradient = tf.gradients(classifyloss, params)\n\tclassify_clipped_gradients, classify_norm = tf.clip_by_global_norm(classify_gradient, max_gradient_norm)\n\tself.classify_gradient_norm = classify_norm\n\tself.classify_update = opt.apply_gradients(zip(classify_clipped_gradients, params), global_step = self.global_step)\n\n\tsave_list = tf.trainable_variables()\n\tsave_list.append(self.global_step)\n\tself.saver = tf.train.Saver(save_list)\n\nThe rest are all the same, except that, I used to run the self.update operation in the train() call. Now I first run self.tag_update in the tagging() call and then run self.classify_update in the train() call.\nI have read the closed issue of #8057. it said in it that\n\nI understood here such a thing: variables beta1_power and beta2_power are specific to each call to apply_gradients, but not to the whole graph. So if we want to call apply_gradients twice, two separate pairs of beta accumulators should be created, even if both calls are made within the single graph. This does not fit into the concept of \"graph slots\". Definitely, we should separate these slots by graphs, but we cannot simply key these slots by graphs only.\n\nBut I still have no idea how ti fix it.", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu\r\n- **TensorFlow version (use command below)**: r1.3\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\nI write a model class that use a AdamOptimizer to update the parameters. It is a joint model so that there are two losses. It works well as I update all the parameters by the joint loss. But then I want to updated a subset of parameters by each of the loss respectively, that is , I had to call the apply_gradients() **twice**, it raised errors when I restore the model from .ckpt file: 'Failed precondition: Attempting to use uninitialized value model_2/beta1_power'.\r\n\r\n\r\n### Source code / logs\r\nThis is the original source code when I update the model with the whole loss.\r\n\r\n\t\ttaggingloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.tag, logits = self.tagginglogits))\r\n\t\tclassifyloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.label, logits = self.logits))\r\n\t\tself.loss = (1 - alpha) * classifyloss + alpha * taggingloss\r\n\t\t# Gradients\r\n\t\tparams = tf.trainable_variables()\r\n\t\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\r\n\t\tgradient = tf.gradients(self.loss, params)\r\n\t\tclipped_gradients, norm = tf.clip_by_global_norm(gradient, max_gradient_norm)\r\n\t\tself.gradient_norm = norm\r\n\t\tself.update = opt.apply_gradients(zip(clipped_gradients, params), global_step = self.global_step)\r\n\t\tsave_list = params\r\n\t\tsave_list.append(self.global_step)\r\n\t\tself.saver = tf.train.Saver(save_list)\r\n\r\nthen I  revised it into:\r\n\r\n\t\t# Gradients\r\n\t\tparams = tf.trainable_variables()\r\n\t\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\r\n\t\ttag_gradient = tf.gradients(taggingloss, params)\r\n\t\ttag_clipped_gradients, tag_norm = tf.clip_by_global_norm(tag_gradient, max_gradient_norm)\r\n\t\tself.tag_gradient_norm = tag_norm\r\n\t\tself.tag_update = opt.apply_gradients(zip(tag_clipped_gradients, params), global_step = self.global_step)\r\n\t\t\r\n\t\tclassify_gradient = tf.gradients(classifyloss, params)\r\n\t\tclassify_clipped_gradients, classify_norm = tf.clip_by_global_norm(classify_gradient, max_gradient_norm)\r\n\t\tself.classify_gradient_norm = classify_norm\r\n\t\tself.classify_update = opt.apply_gradients(zip(classify_clipped_gradients, params), global_step = self.global_step)\r\n\r\n\t\tsave_list = tf.trainable_variables()\r\n\t\tsave_list.append(self.global_step)\r\n\t\tself.saver = tf.train.Saver(save_list)\r\n\r\nThe rest are all the same, except that, I used to run the self.update operation in the train() call. Now I first run self.tag_update in the tagging() call and then run self.classify_update in the train() call.\r\n\r\nI have read the closed issue of https://github.com/tensorflow/tensorflow/issues/8057. it said in it that \r\n\r\n> I understood here such a thing: variables beta1_power and beta2_power are specific to each call to apply_gradients, but not to the whole graph. So if we want to call apply_gradients twice, two separate pairs of beta accumulators should be created, even if both calls are made within the single graph. This does not fit into the concept of \"graph slots\". Definitely, we should separate these slots by graphs, but we cannot simply key these slots by graphs only.\r\n\r\nBut I still have no idea how ti fix it."}