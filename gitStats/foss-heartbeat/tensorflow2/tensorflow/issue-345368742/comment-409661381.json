{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409661381", "html_url": "https://github.com/tensorflow/tensorflow/issues/21192#issuecomment-409661381", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21192", "id": 409661381, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTY2MTM4MQ==", "user": {"login": "aroraakshit", "id": 30349184, "node_id": "MDQ6VXNlcjMwMzQ5MTg0", "avatar_url": "https://avatars1.githubusercontent.com/u/30349184?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aroraakshit", "html_url": "https://github.com/aroraakshit", "followers_url": "https://api.github.com/users/aroraakshit/followers", "following_url": "https://api.github.com/users/aroraakshit/following{/other_user}", "gists_url": "https://api.github.com/users/aroraakshit/gists{/gist_id}", "starred_url": "https://api.github.com/users/aroraakshit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aroraakshit/subscriptions", "organizations_url": "https://api.github.com/users/aroraakshit/orgs", "repos_url": "https://api.github.com/users/aroraakshit/repos", "events_url": "https://api.github.com/users/aroraakshit/events{/privacy}", "received_events_url": "https://api.github.com/users/aroraakshit/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-01T17:46:01Z", "updated_at": "2018-08-01T17:47:23Z", "author_association": "NONE", "body_html": "<p>To my knowledge, it is precisely the same error. I visualized the graph on TensorBoard, it is the same node that's giving the error, you can find the graph <a href=\"https://github.com/aroraakshit/cast_issue_poc_/blob/master/TensorBoard_vis.png\">here</a>. (You may want to download it for checking it properly)</p>\n<p>Here is the server side log upon a single request:</p>\n<pre><code>2018-07-31 17:50:15.878264: I tensorflow_serving/model_servers/main.cc:323] Running ModelServer at 0.0.0.0:9000 ...\n2018-07-31 17:55:12.725076: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1295] OP_REQUIRES failed at cast_op.cc:77 : Unimplemented: Cast int64 to string is not supported\n2018-07-31 17:55:12.725149: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:696] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\n</code></pre>\n<p>Here is the client side error trace:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 193, in _blocking_unary_unary\n    credentials=_credentials(protocol_options))\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 500, in __call__\n    return _end_unary_response_blocking(state, call, False, None)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 434, in _end_unary_response_blocking\n    raise _Rendezvous(state, None, None, deadline)\ngrpc._channel._Rendezvous: &lt;_Rendezvous of RPC that terminated with (StatusCode.UNIMPLEMENTED, Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]])&gt;\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 59, in &lt;module&gt;\n    run(args.host, args.port, args.input, args.model, args.signature_name)\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 41, in run\n    result = stub.Classify(request, 10.0)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 309, in __call__\n    self._request_serializer, self._response_deserializer)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 195, in _blocking_unary_unary\n    raise _abortion_error(rpc_error_call)\ngrpc.framework.interfaces.face.face.LocalError: LocalError(code=StatusCode.UNIMPLEMENTED, details=\"Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\")\n</code></pre>", "body_text": "To my knowledge, it is precisely the same error. I visualized the graph on TensorBoard, it is the same node that's giving the error, you can find the graph here. (You may want to download it for checking it properly)\nHere is the server side log upon a single request:\n2018-07-31 17:50:15.878264: I tensorflow_serving/model_servers/main.cc:323] Running ModelServer at 0.0.0.0:9000 ...\n2018-07-31 17:55:12.725076: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1295] OP_REQUIRES failed at cast_op.cc:77 : Unimplemented: Cast int64 to string is not supported\n2018-07-31 17:55:12.725149: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:696] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\n\nHere is the client side error trace:\nTraceback (most recent call last):\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 193, in _blocking_unary_unary\n    credentials=_credentials(protocol_options))\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 500, in __call__\n    return _end_unary_response_blocking(state, call, False, None)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 434, in _end_unary_response_blocking\n    raise _Rendezvous(state, None, None, deadline)\ngrpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with (StatusCode.UNIMPLEMENTED, Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]])>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 59, in <module>\n    run(args.host, args.port, args.input, args.model, args.signature_name)\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 41, in run\n    result = stub.Classify(request, 10.0)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 309, in __call__\n    self._request_serializer, self._response_deserializer)\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 195, in _blocking_unary_unary\n    raise _abortion_error(rpc_error_call)\ngrpc.framework.interfaces.face.face.LocalError: LocalError(code=StatusCode.UNIMPLEMENTED, details=\"Cast int64 to string is not supported\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\")", "body": "To my knowledge, it is precisely the same error. I visualized the graph on TensorBoard, it is the same node that's giving the error, you can find the graph [here](https://github.com/aroraakshit/cast_issue_poc_/blob/master/TensorBoard_vis.png). (You may want to download it for checking it properly)\r\n\r\nHere is the server side log upon a single request:\r\n```\r\n2018-07-31 17:50:15.878264: I tensorflow_serving/model_servers/main.cc:323] Running ModelServer at 0.0.0.0:9000 ...\r\n2018-07-31 17:55:12.725076: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1295] OP_REQUIRES failed at cast_op.cc:77 : Unimplemented: Cast int64 to string is not supported\r\n2018-07-31 17:55:12.725149: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:696] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported\r\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\r\n```\r\n\r\nHere is the client side error trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 193, in _blocking_unary_unary\r\n    credentials=_credentials(protocol_options))\r\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 500, in __call__\r\n    return _end_unary_response_blocking(state, call, False, None)\r\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/_channel.py\", line 434, in _end_unary_response_blocking\r\n    raise _Rendezvous(state, None, None, deadline)\r\ngrpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with (StatusCode.UNIMPLEMENTED, Cast int64 to string is not supported\r\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]])>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 59, in <module>\r\n    run(args.host, args.port, args.input, args.model, args.signature_name)\r\n  File \"/storage/test_env/cast_issue_poc_/client.py\", line 41, in run\r\n    result = stub.Classify(request, 10.0)\r\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 309, in __call__\r\n    self._request_serializer, self._response_deserializer)\r\n  File \"/home/mldev/venv/lib/python3.5/site-packages/grpc/beta/_client_adaptations.py\", line 195, in _blocking_unary_unary\r\n    raise _abortion_error(rpc_error_call)\r\ngrpc.framework.interfaces.face.face.LocalError: LocalError(code=StatusCode.UNIMPLEMENTED, details=\"Cast int64 to string is not supported\r\n\t [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _output_shapes=[[8]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ArgMax)]]\")\r\n```"}