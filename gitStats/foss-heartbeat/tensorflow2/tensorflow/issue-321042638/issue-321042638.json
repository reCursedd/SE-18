{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19136", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19136/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19136/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19136/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/19136", "id": 321042638, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg2NTI2Njgx", "number": 19136, "title": "Setting default openmp settings for MKL kernels", "user": {"login": "jbobba", "id": 21375855, "node_id": "MDQ6VXNlcjIxMzc1ODU1", "avatar_url": "https://avatars1.githubusercontent.com/u/21375855?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbobba", "html_url": "https://github.com/jbobba", "followers_url": "https://api.github.com/users/jbobba/followers", "following_url": "https://api.github.com/users/jbobba/following{/other_user}", "gists_url": "https://api.github.com/users/jbobba/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbobba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbobba/subscriptions", "organizations_url": "https://api.github.com/users/jbobba/orgs", "repos_url": "https://api.github.com/users/jbobba/repos", "events_url": "https://api.github.com/users/jbobba/events{/privacy}", "received_events_url": "https://api.github.com/users/jbobba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2018-05-08T04:58:51Z", "updated_at": "2018-06-13T17:21:15Z", "closed_at": "2018-05-22T19:03:25Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19136", "html_url": "https://github.com/tensorflow/tensorflow/pull/19136", "diff_url": "https://github.com/tensorflow/tensorflow/pull/19136.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/19136.patch"}, "body_html": "<p>Requesting feedback on ways to set default openmp parameters</p>\n<p>Currently, we recommend users set these through environment variables but are looking at ways to set reasonable values automatically from within tensorflow. A few questions that I would appreciate your feedback on -</p>\n<ol>\n<li>Is it ok to use 'setenv' to set values for KMP_BLOCKTIME and OMP_PROC_BIND? There are no openmp standard APIs to programmatically set them.</li>\n<li>For 'setenv' to correctly set Openmp settings, the code has to execute before the openmp library is loaded i.e before any call to openmp in the program. Since MKL optimizations are the only users of openmp, we have ensured that this is the case for now. Is there a better place for this code?</li>\n<li>We would like to avoid placing computations on hyperthreads that compete for resources on the same CPU physical core. Looking for suggestions on getting the number of hyperthreads per core in a portable manner. <a href=\"https://www.open-mpi.org/projects/hwloc/\" rel=\"nofollow\">https://www.open-mpi.org/projects/hwloc/</a> looks like a good option. Are you OK with bringing it into tensorflow?</li>\n<li>Is it ok to ignore the intra_op config parameter while setting number of openmp threads? Ideally, we would like to use that parameter to guide MKL kernel parallelism as well but there seem to be cases (e.g., tf_cnn_benchmarks) where intra_op is set to a very low number by default.</li>\n</ol>", "body_text": "Requesting feedback on ways to set default openmp parameters\nCurrently, we recommend users set these through environment variables but are looking at ways to set reasonable values automatically from within tensorflow. A few questions that I would appreciate your feedback on -\n\nIs it ok to use 'setenv' to set values for KMP_BLOCKTIME and OMP_PROC_BIND? There are no openmp standard APIs to programmatically set them.\nFor 'setenv' to correctly set Openmp settings, the code has to execute before the openmp library is loaded i.e before any call to openmp in the program. Since MKL optimizations are the only users of openmp, we have ensured that this is the case for now. Is there a better place for this code?\nWe would like to avoid placing computations on hyperthreads that compete for resources on the same CPU physical core. Looking for suggestions on getting the number of hyperthreads per core in a portable manner. https://www.open-mpi.org/projects/hwloc/ looks like a good option. Are you OK with bringing it into tensorflow?\nIs it ok to ignore the intra_op config parameter while setting number of openmp threads? Ideally, we would like to use that parameter to guide MKL kernel parallelism as well but there seem to be cases (e.g., tf_cnn_benchmarks) where intra_op is set to a very low number by default.", "body": "Requesting feedback on ways to set default openmp parameters\r\n\r\nCurrently, we recommend users set these through environment variables but are looking at ways to set reasonable values automatically from within tensorflow. A few questions that I would appreciate your feedback on -\r\n1) Is it ok to use 'setenv' to set values for KMP_BLOCKTIME and OMP_PROC_BIND? There are no openmp standard APIs to programmatically set them. \r\n2) For 'setenv' to correctly set Openmp settings, the code has to execute before the openmp library is loaded i.e before any call to openmp in the program. Since MKL optimizations are the only users of openmp, we have ensured that this is the case for now. Is there a better place for this code? \r\n3) We would like to avoid placing computations on hyperthreads that compete for resources on the same CPU physical core. Looking for suggestions on getting the number of hyperthreads per core in a portable manner. https://www.open-mpi.org/projects/hwloc/ looks like a good option. Are you OK with bringing it into tensorflow? \r\n4) Is it ok to ignore the intra_op config parameter while setting number of openmp threads? Ideally, we would like to use that parameter to guide MKL kernel parallelism as well but there seem to be cases (e.g., tf_cnn_benchmarks) where intra_op is set to a very low number by default. "}