{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426822607", "html_url": "https://github.com/tensorflow/tensorflow/issues/21962#issuecomment-426822607", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21962", "id": 426822607, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjgyMjYwNw==", "user": {"login": "alanchiao", "id": 4323109, "node_id": "MDQ6VXNlcjQzMjMxMDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/4323109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanchiao", "html_url": "https://github.com/alanchiao", "followers_url": "https://api.github.com/users/alanchiao/followers", "following_url": "https://api.github.com/users/alanchiao/following{/other_user}", "gists_url": "https://api.github.com/users/alanchiao/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanchiao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanchiao/subscriptions", "organizations_url": "https://api.github.com/users/alanchiao/orgs", "repos_url": "https://api.github.com/users/alanchiao/repos", "events_url": "https://api.github.com/users/alanchiao/events{/privacy}", "received_events_url": "https://api.github.com/users/alanchiao/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-03T22:18:17Z", "updated_at": "2018-10-03T22:46:53Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26728802\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/niruyadla\">@niruyadla</a> : I'm assuming float models wouldn't serve your need. The models you see now are all floating point models.</p>\n<p>Are you trying to understand the effects of post-training quantization on LSTMs (e.g. how much the outputs differ in various models, latency) or the logic in our EvalHybrid kernels (ex: by running things through via gdb)?</p>\n<p>If it's the above, this would be a feature request to maintain sample speech models (float and quantized) that run on TFLite for the sake of directly seeing the effects of post-training quantization (beyond what's publicly listed on blog posts, etc.).</p>\n<ul>\n<li>This wouldn't be for creating demos (since we've modified the models so that they wouldn't work as well).</li>\n<li>This wouldn't be for easily creating TFLite models from Tensorflow (since easy LSTM conversion support through TOCO is still lacking).</li>\n</ul>\n<p>Let me know what you think. Thanks!</p>", "body_text": "@niruyadla : I'm assuming float models wouldn't serve your need. The models you see now are all floating point models.\nAre you trying to understand the effects of post-training quantization on LSTMs (e.g. how much the outputs differ in various models, latency) or the logic in our EvalHybrid kernels (ex: by running things through via gdb)?\nIf it's the above, this would be a feature request to maintain sample speech models (float and quantized) that run on TFLite for the sake of directly seeing the effects of post-training quantization (beyond what's publicly listed on blog posts, etc.).\n\nThis wouldn't be for creating demos (since we've modified the models so that they wouldn't work as well).\nThis wouldn't be for easily creating TFLite models from Tensorflow (since easy LSTM conversion support through TOCO is still lacking).\n\nLet me know what you think. Thanks!", "body": "@niruyadla : I'm assuming float models wouldn't serve your need. The models you see now are all floating point models. \r\n\r\nAre you trying to understand the effects of post-training quantization on LSTMs (e.g. how much the outputs differ in various models, latency) or the logic in our EvalHybrid kernels (ex: by running things through via gdb)?\r\n\r\nIf it's the above, this would be a feature request to maintain sample speech models (float and quantized) that run on TFLite for the sake of directly seeing the effects of post-training quantization (beyond what's publicly listed on blog posts, etc.). \r\n- This wouldn't be for creating demos (since we've modified the models so that they wouldn't work as well).\r\n- This wouldn't be for easily creating TFLite models from Tensorflow (since easy LSTM conversion support through TOCO is still lacking).\r\n\r\nLet me know what you think. Thanks!  "}