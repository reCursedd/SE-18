{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15952", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15952/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15952/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15952/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15952", "id": 286814592, "node_id": "MDU6SXNzdWUyODY4MTQ1OTI=", "number": 15952, "title": "LSTM in eager is 15 slower than in tensorflow on CPU", "user": {"login": "idavydov", "id": 671660, "node_id": "MDQ6VXNlcjY3MTY2MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/671660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/idavydov", "html_url": "https://github.com/idavydov", "followers_url": "https://api.github.com/users/idavydov/followers", "following_url": "https://api.github.com/users/idavydov/following{/other_user}", "gists_url": "https://api.github.com/users/idavydov/gists{/gist_id}", "starred_url": "https://api.github.com/users/idavydov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/idavydov/subscriptions", "organizations_url": "https://api.github.com/users/idavydov/orgs", "repos_url": "https://api.github.com/users/idavydov/repos", "events_url": "https://api.github.com/users/idavydov/events{/privacy}", "received_events_url": "https://api.github.com/users/idavydov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-08T17:05:42Z", "updated_at": "2018-01-08T18:52:53Z", "closed_at": "2018-01-08T18:52:53Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.3.0-rc1-6744-gf99275a 1.6.0-dev20180105</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: none</li>\n<li><strong>GPU model and memory</strong>: none</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>git clone https://gist.github.com/idavydov/1060b3fae833af436cdad11913c9e7e1\ncd 1060b3fae833af436cdad11913c9e7e1\ntime python lstm_test_tensorflow.py\ntime python lstm_test_eager.py\n</code></pre>\n<h3>Describe the problem</h3>\n<p>LSTM in eager seeems to work 15 times slower than LSTM in tensorflow, when running on CPU (<code>tf.nn.dynamic_rnn</code>).  Tensorflow time: 9s, eager time: 149s.</p>\n<h3>Source code / logs</h3>\n<h2>lstm_test_tensorflow.py</h2>\n<pre><code>#!/usr/bin/env python\nimport numpy as np\nimport tensorflow as tf\n\n\n# use 1 CPU\nconf=tf.ConfigProto(\n    intra_op_parallelism_threads=1,\n    inter_op_parallelism_threads=1)\n\nn_iter = 100\n\nn_layers = 2\n\nbatch_size = 32\nseq_len = 1000\ninput_dim = 7\ndata = np.random.uniform(size=(batch_size, seq_len, input_dim))\n\nx = tf.placeholder(tf.float32, shape=(batch_size, seq_len, input_dim))\n\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\nrnn_outputs, final_state = tf.nn.dynamic_rnn(multicell, x, dtype=tf.float32)\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session(config=conf) as sess:\n    sess.run(init)\n    for _ in range(n_iter):\n        sess.run(rnn_outputs, {x: data})\n</code></pre>\n<h2>lstm_test_eager.py</h2>\n<pre><code>#!/usr/bin/env python\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\n# use 1 CPU\nconf=tf.ConfigProto(\n    intra_op_parallelism_threads=1,\n    inter_op_parallelism_threads=1)\n\ntfe.enable_eager_execution(conf)\n\nn_iter = 100\n\nn_layers = 2\n\nbatch_size = 32\nseq_len = 1000\ninput_dim = 7\ndata = tf.random_uniform((batch_size, seq_len, input_dim))\n\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\n\n\nfor _ in range(n_iter):\n    tf.nn.dynamic_rnn(multicell, data, dtype=tf.float32)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.3.0-rc1-6744-gf99275a 1.6.0-dev20180105\nPython version: 3.5.2\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: none\nGPU model and memory: none\nExact command to reproduce:\n\ngit clone https://gist.github.com/idavydov/1060b3fae833af436cdad11913c9e7e1\ncd 1060b3fae833af436cdad11913c9e7e1\ntime python lstm_test_tensorflow.py\ntime python lstm_test_eager.py\n\nDescribe the problem\nLSTM in eager seeems to work 15 times slower than LSTM in tensorflow, when running on CPU (tf.nn.dynamic_rnn).  Tensorflow time: 9s, eager time: 149s.\nSource code / logs\nlstm_test_tensorflow.py\n#!/usr/bin/env python\nimport numpy as np\nimport tensorflow as tf\n\n\n# use 1 CPU\nconf=tf.ConfigProto(\n    intra_op_parallelism_threads=1,\n    inter_op_parallelism_threads=1)\n\nn_iter = 100\n\nn_layers = 2\n\nbatch_size = 32\nseq_len = 1000\ninput_dim = 7\ndata = np.random.uniform(size=(batch_size, seq_len, input_dim))\n\nx = tf.placeholder(tf.float32, shape=(batch_size, seq_len, input_dim))\n\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\nrnn_outputs, final_state = tf.nn.dynamic_rnn(multicell, x, dtype=tf.float32)\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session(config=conf) as sess:\n    sess.run(init)\n    for _ in range(n_iter):\n        sess.run(rnn_outputs, {x: data})\n\nlstm_test_eager.py\n#!/usr/bin/env python\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\n# use 1 CPU\nconf=tf.ConfigProto(\n    intra_op_parallelism_threads=1,\n    inter_op_parallelism_threads=1)\n\ntfe.enable_eager_execution(conf)\n\nn_iter = 100\n\nn_layers = 2\n\nbatch_size = 32\nseq_len = 1000\ninput_dim = 7\ndata = tf.random_uniform((batch_size, seq_len, input_dim))\n\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\n\n\nfor _ in range(n_iter):\n    tf.nn.dynamic_rnn(multicell, data, dtype=tf.float32)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-6744-gf99275a 1.6.0-dev20180105\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: \r\n\r\n```\r\ngit clone https://gist.github.com/idavydov/1060b3fae833af436cdad11913c9e7e1\r\ncd 1060b3fae833af436cdad11913c9e7e1\r\ntime python lstm_test_tensorflow.py\r\ntime python lstm_test_eager.py\r\n```\r\n\r\n### Describe the problem\r\nLSTM in eager seeems to work 15 times slower than LSTM in tensorflow, when running on CPU (`tf.nn.dynamic_rnn`).  Tensorflow time: 9s, eager time: 149s.\r\n\r\n### Source code / logs\r\n## lstm_test_tensorflow.py\r\n```\r\n#!/usr/bin/env python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n# use 1 CPU\r\nconf=tf.ConfigProto(\r\n    intra_op_parallelism_threads=1,\r\n    inter_op_parallelism_threads=1)\r\n\r\nn_iter = 100\r\n\r\nn_layers = 2\r\n\r\nbatch_size = 32\r\nseq_len = 1000\r\ninput_dim = 7\r\ndata = np.random.uniform(size=(batch_size, seq_len, input_dim))\r\n\r\nx = tf.placeholder(tf.float32, shape=(batch_size, seq_len, input_dim))\r\n\r\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\r\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\r\nrnn_outputs, final_state = tf.nn.dynamic_rnn(multicell, x, dtype=tf.float32)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session(config=conf) as sess:\r\n    sess.run(init)\r\n    for _ in range(n_iter):\r\n        sess.run(rnn_outputs, {x: data})\r\n```\r\n\r\n## lstm_test_eager.py\r\n```\r\n#!/usr/bin/env python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\n# use 1 CPU\r\nconf=tf.ConfigProto(\r\n    intra_op_parallelism_threads=1,\r\n    inter_op_parallelism_threads=1)\r\n\r\ntfe.enable_eager_execution(conf)\r\n\r\nn_iter = 100\r\n\r\nn_layers = 2\r\n\r\nbatch_size = 32\r\nseq_len = 1000\r\ninput_dim = 7\r\ndata = tf.random_uniform((batch_size, seq_len, input_dim))\r\n\r\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\r\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\r\n\r\n\r\nfor _ in range(n_iter):\r\n    tf.nn.dynamic_rnn(multicell, data, dtype=tf.float32)\r\n```"}