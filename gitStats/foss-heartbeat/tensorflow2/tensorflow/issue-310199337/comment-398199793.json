{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/398199793", "html_url": "https://github.com/tensorflow/tensorflow/issues/18139#issuecomment-398199793", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18139", "id": 398199793, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODE5OTc5Mw==", "user": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-18T21:21:22Z", "updated_at": "2018-06-18T21:21:22Z", "author_association": "MEMBER", "body_html": "<p>Euguene can you take a look?</p>\n<p>The library code is pretty old, but relevant line seems to be  and I was able to dig it out at <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/seq2seq/python/ops/attention_decoder_fn.py\">https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/seq2seq/python/ops/attention_decoder_fn.py</a></p>\n<p>My understand was that calling the function should have added it to the graph at train time, so it puzzling a bit that on restore it cant find it.</p>", "body_text": "Euguene can you take a look?\nThe library code is pretty old, but relevant line seems to be  and I was able to dig it out at https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/seq2seq/python/ops/attention_decoder_fn.py\nMy understand was that calling the function should have added it to the graph at train time, so it puzzling a bit that on restore it cant find it.", "body": "Euguene can you take a look?\r\n\r\nThe library code is pretty old, but relevant line seems to be  and I was able to dig it out at https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/seq2seq/python/ops/attention_decoder_fn.py\r\n\r\nMy understand was that calling the function should have added it to the graph at train time, so it puzzling a bit that on restore it cant find it.\r\n\r\n"}