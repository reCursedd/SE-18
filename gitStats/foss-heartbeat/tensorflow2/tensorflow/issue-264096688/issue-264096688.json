{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13600", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13600/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13600/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13600/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13600", "id": 264096688, "node_id": "MDU6SXNzdWUyNjQwOTY2ODg=", "number": 13600, "title": "LayerNormBasicLSTMCell causes `bias key not found in checkpoint` when layer_norm=False", "user": {"login": "bxshi", "id": 1314883, "node_id": "MDQ6VXNlcjEzMTQ4ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1314883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bxshi", "html_url": "https://github.com/bxshi", "followers_url": "https://api.github.com/users/bxshi/followers", "following_url": "https://api.github.com/users/bxshi/following{/other_user}", "gists_url": "https://api.github.com/users/bxshi/gists{/gist_id}", "starred_url": "https://api.github.com/users/bxshi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bxshi/subscriptions", "organizations_url": "https://api.github.com/users/bxshi/orgs", "repos_url": "https://api.github.com/users/bxshi/repos", "events_url": "https://api.github.com/users/bxshi/events{/privacy}", "received_events_url": "https://api.github.com/users/bxshi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ericdnielsen", "id": 17646533, "node_id": "MDQ6VXNlcjE3NjQ2NTMz", "avatar_url": "https://avatars1.githubusercontent.com/u/17646533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericdnielsen", "html_url": "https://github.com/ericdnielsen", "followers_url": "https://api.github.com/users/ericdnielsen/followers", "following_url": "https://api.github.com/users/ericdnielsen/following{/other_user}", "gists_url": "https://api.github.com/users/ericdnielsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericdnielsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericdnielsen/subscriptions", "organizations_url": "https://api.github.com/users/ericdnielsen/orgs", "repos_url": "https://api.github.com/users/ericdnielsen/repos", "events_url": "https://api.github.com/users/ericdnielsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ericdnielsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ericdnielsen", "id": 17646533, "node_id": "MDQ6VXNlcjE3NjQ2NTMz", "avatar_url": "https://avatars1.githubusercontent.com/u/17646533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericdnielsen", "html_url": "https://github.com/ericdnielsen", "followers_url": "https://api.github.com/users/ericdnielsen/followers", "following_url": "https://api.github.com/users/ericdnielsen/following{/other_user}", "gists_url": "https://api.github.com/users/ericdnielsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericdnielsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericdnielsen/subscriptions", "organizations_url": "https://api.github.com/users/ericdnielsen/orgs", "repos_url": "https://api.github.com/users/ericdnielsen/repos", "events_url": "https://api.github.com/users/ericdnielsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ericdnielsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-10-10T04:35:52Z", "updated_at": "2017-11-22T06:37:09Z", "closed_at": "2017-10-31T02:09:31Z", "author_association": "NONE", "body_html": "<p>When initializing <code>LayerNormBasicLSTMCell</code>, it has a parameter <code>layer_norm</code> which controls whether we want to enable layer norm or not. I assume <code>layer_norm=True</code> should be set during training and <code>layer_norm=False</code> for evaluation. However, if I use this in an Estimator, due to the following line</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/a2d9b3bf5f9e96bf459074d079b01e1c74b25afa/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1331\">tensorflow/tensorflow/contrib/rnn/python/ops/rnn_cell.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 1331\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/a2d9b3bf5f9e96bf459074d079b01e1c74b25afa\">a2d9b3b</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L1331\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"1331\"></td>\n          <td id=\"LC1331\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">self</span>._layer_norm: </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>it will not initialize the <code>bias</code> term because <code>layer_norm=True</code>, resulting in a <code>NotFoundError</code> when loading the saved checkpoint with <code>layer_norm=False</code>.</p>\n<p>What should be the expected behavior of this? Should this cell applies the bias anyway regardless the <code>layer_norm</code>? If we do not use the bias during training, I see no points to use it during inference.</p>", "body_text": "When initializing LayerNormBasicLSTMCell, it has a parameter layer_norm which controls whether we want to enable layer norm or not. I assume layer_norm=True should be set during training and layer_norm=False for evaluation. However, if I use this in an Estimator, due to the following line\n\n  \n    \n      tensorflow/tensorflow/contrib/rnn/python/ops/rnn_cell.py\n    \n    \n         Line 1331\n      in\n      a2d9b3b\n    \n    \n    \n    \n\n        \n          \n           if not self._layer_norm: \n        \n    \n  \n\n\nit will not initialize the bias term because layer_norm=True, resulting in a NotFoundError when loading the saved checkpoint with layer_norm=False.\nWhat should be the expected behavior of this? Should this cell applies the bias anyway regardless the layer_norm? If we do not use the bias during training, I see no points to use it during inference.", "body": "When initializing `LayerNormBasicLSTMCell`, it has a parameter `layer_norm` which controls whether we want to enable layer norm or not. I assume `layer_norm=True` should be set during training and `layer_norm=False` for evaluation. However, if I use this in an Estimator, due to the following line\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/a2d9b3bf5f9e96bf459074d079b01e1c74b25afa/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1331\r\n\r\nit will not initialize the `bias` term because `layer_norm=True`, resulting in a `NotFoundError` when loading the saved checkpoint with `layer_norm=False`.\r\n\r\nWhat should be the expected behavior of this? Should this cell applies the bias anyway regardless the `layer_norm`? If we do not use the bias during training, I see no points to use it during inference.\r\n\r\n"}