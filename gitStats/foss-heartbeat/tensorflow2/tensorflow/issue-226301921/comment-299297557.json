{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299297557", "html_url": "https://github.com/tensorflow/tensorflow/issues/9664#issuecomment-299297557", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9664", "id": 299297557, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTI5NzU1Nw==", "user": {"login": "andrewharp", "id": 3376817, "node_id": "MDQ6VXNlcjMzNzY4MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3376817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewharp", "html_url": "https://github.com/andrewharp", "followers_url": "https://api.github.com/users/andrewharp/followers", "following_url": "https://api.github.com/users/andrewharp/following{/other_user}", "gists_url": "https://api.github.com/users/andrewharp/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewharp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewharp/subscriptions", "organizations_url": "https://api.github.com/users/andrewharp/orgs", "repos_url": "https://api.github.com/users/andrewharp/repos", "events_url": "https://api.github.com/users/andrewharp/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewharp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-04T20:19:48Z", "updated_at": "2017-05-04T20:20:02Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=161459\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/petewarden\">@petewarden</a> can correct me if I'm off base here, but I don't believe float16 support is something we're currently targeting on mobile.</p>\n<p>Most of our attention on mobile is focused on quantized 8bit support, which should give you even better size gains and possibly performance as well. Support for quantizing graphs can be found in the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md\">transform_graph</a> tool.</p>", "body_text": "@petewarden can correct me if I'm off base here, but I don't believe float16 support is something we're currently targeting on mobile.\nMost of our attention on mobile is focused on quantized 8bit support, which should give you even better size gains and possibly performance as well. Support for quantizing graphs can be found in the transform_graph tool.", "body": "@petewarden can correct me if I'm off base here, but I don't believe float16 support is something we're currently targeting on mobile.\r\n\r\nMost of our attention on mobile is focused on quantized 8bit support, which should give you even better size gains and possibly performance as well. Support for quantizing graphs can be found in the [transform_graph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md) tool."}