{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2163", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2163/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2163/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2163/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2163", "id": 151794601, "node_id": "MDU6SXNzdWUxNTE3OTQ2MDE=", "number": 2163, "title": "Floating point exception when computing gradients", "user": {"login": "altaetran", "id": 6753285, "node_id": "MDQ6VXNlcjY3NTMyODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/6753285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/altaetran", "html_url": "https://github.com/altaetran", "followers_url": "https://api.github.com/users/altaetran/followers", "following_url": "https://api.github.com/users/altaetran/following{/other_user}", "gists_url": "https://api.github.com/users/altaetran/gists{/gist_id}", "starred_url": "https://api.github.com/users/altaetran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/altaetran/subscriptions", "organizations_url": "https://api.github.com/users/altaetran/orgs", "repos_url": "https://api.github.com/users/altaetran/repos", "events_url": "https://api.github.com/users/altaetran/events{/privacy}", "received_events_url": "https://api.github.com/users/altaetran/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2016-04-29T05:14:13Z", "updated_at": "2017-02-09T22:02:16Z", "closed_at": "2016-05-05T05:58:04Z", "author_association": "NONE", "body_html": "<p>Hi tensorflow developer team!</p>\n<p>I just wanted to first let you know that I really appreciate all the work you are putting into this amazing open source system. It has been a terrific system for me so far. However, I have come into a roadblock when using the tf.gather function in gradients.</p>\n<p>I am using</p>\n<h3>Environment info</h3>\n<p>Operating System: CentOS</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\nCUDA version 7.5<br>\ncuDNN version 7.0 (64 bit)<br>\ntensorflow/0.8.0-gpu version</p>\n<h3>Steps to reproduce</h3>\n<p>I obtain a floating point exception when I run the following code</p>\n<p><code>A_ph = tf.placeholder(tf.float32, shape=(None, 2))</code><br>\n<code>ind_ph = tf.placeholder(tf.int32, shape=(None, 2))</code></p>\n<p><code>gather = tf.gather(A_ph, ind_ph)</code><br>\n<code>redsum = tf.reduce_sum(gather, 1)</code><br>\n<code>l2 = tf.reduce_sum(redsum)</code></p>\n<p><code>A = np.array([[0,0],[0,0],[0,0]])</code><br>\n<code>ind = np.zeros((0,2))</code></p>\n<p><code>grad_op = tf.gradients(l2, A_ph)</code></p>\n<p><code>out = sess.run(grad_op, feed_dict={A_ph:A, ind_ph:ind})</code></p>\n<h3>What have you tried?</h3>\n<p>If you replace ind with a non-empty array, such as [[0,1]] it works fine.</p>\n<p>I suspect that the output of redsum = [], which makes l2 disconnected from A_ph for the given ind. Fed forward to computing l2, I get the correct value of 0.0 (since there is nothing to be summed). However, for backpropagation of gradients, I think the output of redsum=[] chokes the algorithm, and causes it to evaluate some illegal operation using an empty tensor, instead of just backpropagating 0.0.</p>\n<p>Are there any solutions to this problem currently? In my use of this computation, I won't know ahead of time whether or not the intermediate computations produce [](empty tensor), but I also want to be able to get the correct gradients when this happens. Thank you so much for your consideration!</p>", "body_text": "Hi tensorflow developer team!\nI just wanted to first let you know that I really appreciate all the work you are putting into this amazing open source system. It has been a terrific system for me so far. However, I have come into a roadblock when using the tf.gather function in gradients.\nI am using\nEnvironment info\nOperating System: CentOS\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nCUDA version 7.5\ncuDNN version 7.0 (64 bit)\ntensorflow/0.8.0-gpu version\nSteps to reproduce\nI obtain a floating point exception when I run the following code\nA_ph = tf.placeholder(tf.float32, shape=(None, 2))\nind_ph = tf.placeholder(tf.int32, shape=(None, 2))\ngather = tf.gather(A_ph, ind_ph)\nredsum = tf.reduce_sum(gather, 1)\nl2 = tf.reduce_sum(redsum)\nA = np.array([[0,0],[0,0],[0,0]])\nind = np.zeros((0,2))\ngrad_op = tf.gradients(l2, A_ph)\nout = sess.run(grad_op, feed_dict={A_ph:A, ind_ph:ind})\nWhat have you tried?\nIf you replace ind with a non-empty array, such as [[0,1]] it works fine.\nI suspect that the output of redsum = [], which makes l2 disconnected from A_ph for the given ind. Fed forward to computing l2, I get the correct value of 0.0 (since there is nothing to be summed). However, for backpropagation of gradients, I think the output of redsum=[] chokes the algorithm, and causes it to evaluate some illegal operation using an empty tensor, instead of just backpropagating 0.0.\nAre there any solutions to this problem currently? In my use of this computation, I won't know ahead of time whether or not the intermediate computations produce [](empty tensor), but I also want to be able to get the correct gradients when this happens. Thank you so much for your consideration!", "body": "Hi tensorflow developer team! \n\nI just wanted to first let you know that I really appreciate all the work you are putting into this amazing open source system. It has been a terrific system for me so far. However, I have come into a roadblock when using the tf.gather function in gradients.\n\nI am using\n### Environment info\n\nOperating System: CentOS\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nCUDA version 7.5\ncuDNN version 7.0 (64 bit)\ntensorflow/0.8.0-gpu version\n### Steps to reproduce\n\nI obtain a floating point exception when I run the following code\n\n`A_ph = tf.placeholder(tf.float32, shape=(None, 2))`\n`ind_ph = tf.placeholder(tf.int32, shape=(None, 2))`\n\n`gather = tf.gather(A_ph, ind_ph)`\n`redsum = tf.reduce_sum(gather, 1)`\n`l2 = tf.reduce_sum(redsum)`\n\n`A = np.array([[0,0],[0,0],[0,0]])`\n`ind = np.zeros((0,2))`\n\n`grad_op = tf.gradients(l2, A_ph)`\n\n`out = sess.run(grad_op, feed_dict={A_ph:A, ind_ph:ind})`\n### What have you tried?\n\nIf you replace ind with a non-empty array, such as [[0,1]] it works fine. \n\nI suspect that the output of redsum = [], which makes l2 disconnected from A_ph for the given ind. Fed forward to computing l2, I get the correct value of 0.0 (since there is nothing to be summed). However, for backpropagation of gradients, I think the output of redsum=[] chokes the algorithm, and causes it to evaluate some illegal operation using an empty tensor, instead of just backpropagating 0.0. \n\nAre there any solutions to this problem currently? In my use of this computation, I won't know ahead of time whether or not the intermediate computations produce [](empty tensor), but I also want to be able to get the correct gradients when this happens. Thank you so much for your consideration! \n"}