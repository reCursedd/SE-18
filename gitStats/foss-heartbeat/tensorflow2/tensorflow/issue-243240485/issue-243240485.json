{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11534", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11534/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11534/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11534/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11534", "id": 243240485, "node_id": "MDU6SXNzdWUyNDMyNDA0ODU=", "number": 11534, "title": "[FeatureRequest] make categorical_x_entropy broadcastable", "user": {"login": "khaotik", "id": 6271084, "node_id": "MDQ6VXNlcjYyNzEwODQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6271084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/khaotik", "html_url": "https://github.com/khaotik", "followers_url": "https://api.github.com/users/khaotik/followers", "following_url": "https://api.github.com/users/khaotik/following{/other_user}", "gists_url": "https://api.github.com/users/khaotik/gists{/gist_id}", "starred_url": "https://api.github.com/users/khaotik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/khaotik/subscriptions", "organizations_url": "https://api.github.com/users/khaotik/orgs", "repos_url": "https://api.github.com/users/khaotik/repos", "events_url": "https://api.github.com/users/khaotik/events{/privacy}", "received_events_url": "https://api.github.com/users/khaotik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-07-16T13:43:37Z", "updated_at": "2018-03-27T19:56:15Z", "closed_at": "2018-03-27T19:56:15Z", "author_association": "NONE", "body_html": "<p>For example:</p>\n<pre><code>&gt;&gt;&gt; x = tf.placeholder('float32', [4,5,6])\n&gt;&gt;&gt; y = tf.placeholder('float32', [1,5,6])\n&gt;&gt;&gt; z = tf.nn.softmax_cross_entropy_with_logits(labels=x, logits=y)\nTraceback (most recent call last):\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n  File \"/home/khaotik/anaconda3/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1594, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2380, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\n</code></pre>\n<p>But, intuitively, I'd like to broadcast <code>y</code> into shape <code>[4,5,6]</code> in the above code.</p>\n<p>It's not too hard to get a workaround such as using <code>tf.tile</code>. However it would consume more precious GPU memory.</p>", "body_text": "For example:\n>>> x = tf.placeholder('float32', [4,5,6])\n>>> y = tf.placeholder('float32', [1,5,6])\n>>> z = tf.nn.softmax_cross_entropy_with_logits(labels=x, logits=y)\nTraceback (most recent call last):\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n  File \"/home/khaotik/anaconda3/lib/python3.6/contextlib.py\", line 89, in __exit__\n    next(self.gen)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1594, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2380, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\n\nBut, intuitively, I'd like to broadcast y into shape [4,5,6] in the above code.\nIt's not too hard to get a workaround such as using tf.tile. However it would consume more precious GPU memory.", "body": "For example:\r\n\r\n```\r\n>>> x = tf.placeholder('float32', [4,5,6])\r\n>>> y = tf.placeholder('float32', [1,5,6])\r\n>>> z = tf.nn.softmax_cross_entropy_with_logits(labels=x, logits=y)\r\nTraceback (most recent call last):\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 671, in _call_cpp_shape_fn_impl\r\n    input_tensors_as_shapes, status)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1594, in softmax_cross_entropy_with_logits\r\n    precise_logits, labels, name=name)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2380, in _softmax_cross_entropy_with_logits\r\n    features=features, labels=labels, name=name)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].\r\n```\r\n\r\nBut, intuitively, I'd like to broadcast `y` into shape `[4,5,6]` in the above code.\r\n\r\nIt's not too hard to get a workaround such as using `tf.tile`. However it would consume more precious GPU memory."}