{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/74981098", "pull_request_review_id": null, "id": 74981098, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc0OTgxMDk4", "diff_hunk": "@@ -0,0 +1,612 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This file contains a set of different implementations of the two-dimensional\n+// convolution operation. The standard TensorFlow Conv2d kernel uses EigenTensor\n+// to implement the computation, but here there are a variety of different ways\n+// of producing the same result. These methods are designed to be easier to\n+// understand and connect to other libraries, so that we can take advantage of\n+// platforms that have specialized implementations of GEMM for example.\n+//\n+// The basic interface is a Conv functor object that's templated by the types\n+// of the data it will be operating on, and is passed in the arguments needed to\n+// calculate the convolution. The simplest implementation of this functor is\n+// ReferenceConvFunctor, which is a readable but slow reference version.\n+//\n+// A faster version uses the approach of packing image patches into a matrix\n+// before calling a matrix multiply, the Im2ColConvFunctor. In turn, this can\n+// use a variety of different methods to calculate the matrix multiplication,\n+// or GEMM. The simplest but slowest is the ReferenceGemmFunctor, but the\n+// FastGemmFunctor will use whatever optimized libraries are available. By\n+// default it uses Eigen, but on Apple platforms it will take advantage of the\n+// system's Accelerate BLAS library to get better performance than the standard\n+// TensorFlow convolution kernel.\n+//\n+// The version actually used is defined at the bottom of this file using the\n+// REGISTER_KERNEL_BUILDER() macro. To try out different implementations (for\n+// example to switch to a reference one for easier debugging) you can swap out\n+// the default functors in that call.\n+//\n+// The registration itself is guarded with the USE_GEMM_FOR_CONV macro. The iOS\n+// makefile build defines this, but if you want to enable this implementation\n+// and disable the standard EigenTensor one in other build setups, you'll need\n+// to define it there too.\n+\n+#include <string.h>\n+#include <map>\n+#include <vector>\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/numeric_op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/resource_mgr.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_slice.h\"\n+#include \"tensorflow/core/kernels/bounds_check.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+\n+#if defined(__APPLE__)\n+#include <Accelerate/Accelerate.h>\n+#define USE_ACCELERATE_GEMM\n+#endif  // __APPLE__\n+\n+namespace tensorflow {\n+\n+namespace {\n+// This function implements the convolution operation in as simple a form as\n+// possible. It won't give great performance, but it is very useful for\n+// stepping through and instrumenting for debugging, creating minimal benchmarks\n+// to prototype with, and sharing with teams that want to run this outside of\n+// our environment.\n+// With that in mind, I've avoided using anything except pretty standard C++\n+// types. This is especially noticeable in the data access through raw array\n+// indexing. It's deliberate in this case though, since it makes the underlying\n+// memory order very explicit, which is important for both inspecting memory\n+// contents during debugging and for specifying what we expect to others.\n+// The memory layout of the data is, from biggest stride to smallest:\n+// input_data = [input_batches, input_height, input_width, input_depth]\n+// filter_data = [filter_height, filter_width, input_depth, filter_count]\n+// output_data = [input_batches, output_height, output_width, filter_count]\n+template <class T1, class T2, class T3>\n+class ReferenceConvFunctor {\n+ public:\n+  void operator()(OpKernelContext* context, const T1* input_data,\n+                  int input_batches, int input_height, int input_width,\n+                  int input_depth, const T2* filter_data, int filter_height,\n+                  int filter_width, int filter_count, int stride_rows,\n+                  int stride_cols, Padding padding, T3* output_data,\n+                  int output_height, int output_width) {\n+    // The two different padding modes we support can be a bit confusing. SAME\n+    // means we're trying to produce an output image that's the same size as the\n+    // input. It's complicated by stride, which shrinks the output image by a\n+    // a factor, but it means we end up sampling from outside the borders of the\n+    // input. These out-of-bounds values are read as zeroes. VALID means only\n+    // produce output values where the filters can read all their values from\n+    // within the input image. It effectively removes the margins of the output\n+    // image compared to the one produced by SAME. Stride complicates this\n+    // definition though, because it can result in the right and bottom filter\n+    // patches sampling from outside the borders if it's greater than 1.\n+    // Most of the logic for sorting this all out is done before this function,\n+    // when we calculate the output size, but the positioning of the origin of\n+    // the filters is different between the two modes, since SAME positions the\n+    // first filter off the edge of the input.\n+    int filter_left_offset;\n+    int filter_top_offset;\n+    if (padding == VALID) {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - input_width + 1) /\n+          2;\n+      filter_top_offset = ((output_height - 1) * stride_rows + filter_height -\n+                           input_height + 1) /\n+                          2;\n+    } else {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - input_width) / 2;\n+      filter_top_offset =\n+          ((output_height - 1) * stride_rows + filter_height - input_height) /\n+          2;\n+    }\n+\n+    // If we've got multiple images in our input, work through each of them.\n+    for (int batch = 0; batch < input_batches; ++batch) {\n+      // Walk through all the output image values, sliding the filter to\n+      // different\n+      // positions in the input.\n+      for (int out_y = 0; out_y < output_height; ++out_y) {\n+        for (int out_x = 0; out_x < output_width; ++out_x) {\n+          // Each filter kernel produces one output channel.\n+          for (int out_channel = 0; out_channel < filter_count; ++out_channel) {\n+            // We're going to calculate a single output value, which means we\n+            // need to multiply a three dimensional kernel of weights against\n+            // the current location within the input image.\n+            /*\n+             *-------------------------------...\n+             |\\ ^\n+             | \\in_depth\n+             |  \\ v\n+             |   *-------------------------------...\n+             |   |            ^\n+             |   |       in_y_origin\n+             |   |            v   \\\n+             |   |<in_x_origin>*---*^\n+             |   |            \\|   |filter_height\n+             .   |             *---*v\n+             .   |             <--->\n+             .         filter_width\n+             .\n+            */\n+            const int in_x_origin = (out_x * stride_cols) - filter_left_offset;\n+            const int in_y_origin = (out_y * stride_rows) - filter_top_offset;\n+            T3 total(0);\n+            for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n+              for (int filter_x = 0; filter_x < filter_width; ++filter_x) {\n+                for (int in_channel = 0; in_channel < input_depth;\n+                     ++in_channel) {\n+                  const int in_x = in_x_origin + filter_x;\n+                  const int in_y = in_y_origin + filter_y;\n+                  T1 input_value;\n+                  // If the location is outside the bounds of the input image,\n+                  // use zero as a default value.\n+                  if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&\n+                      (in_y < input_height)) {\n+                    input_value =\n+                        input_data[(batch * input_height * input_width *\n+                                    input_depth) +\n+                                   (in_y * input_width * input_depth) +\n+                                   (in_x * input_depth) + in_channel];\n+                  } else {\n+                    input_value = T1(0);\n+                  }\n+                  const T2 filter_value =\n+                      filter_data[(filter_y * filter_width * input_depth *\n+                                   filter_count) +\n+                                  (filter_x * input_depth * filter_count) +\n+                                  (in_channel * filter_count) + out_channel];\n+                  total += (input_value * filter_value);\n+                }\n+              }\n+            }\n+            output_data[(batch * output_height * output_width * filter_count) +\n+                        (out_y * output_width * filter_count) +\n+                        (out_x * filter_count) + out_channel] = total;\n+          }\n+        }\n+      }\n+    }\n+  }\n+};\n+\n+// A readable but slow implementation of matrix multiplication, useful for\n+// debugging and understanding the algorithm. Use instead of FastGemmFunctor in\n+// the Im2ColConvFunctor template definition inside the op registration to\n+// enable. Assumes row-major ordering of the values in memory.\n+template <class T1, class T2, class T3>\n+class ReferenceGemmFunctor {\n+ public:\n+  void operator()(size_t m, size_t n, size_t k, const T1* a, size_t lda,\n+                  const T2* b, size_t ldb, T3* c, size_t ldc) {\n+    const size_t a_i_stride = lda;\n+    const size_t a_l_stride = 1;\n+    const size_t b_j_stride = 1;\n+    const size_t b_l_stride = ldb;\n+    const size_t c_i_stride = ldc;\n+    const size_t c_j_stride = 1;\n+    size_t i, j, l;\n+    for (j = 0; j < n; j++) {\n+      for (i = 0; i < m; i++) {\n+        T3 total(0);\n+        for (l = 0; l < k; l++) {\n+          const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));\n+          const T1 a_value = a[a_index];\n+          const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));\n+          const T2 b_value = b[b_index];\n+          total += (a_value * b_value);\n+        }\n+        const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));\n+        c[c_index] = total;\n+      }\n+    }\n+  }\n+};\n+\n+// Uses the optimized Eigen library to implement the matrix multiplication\n+// required by the Im2ColConvFunctor class.\n+template <class T1, class T2, class T3>\n+class FastGemmFunctor {\n+ public:\n+  void operator()(size_t m, size_t n, size_t k, const T1* a, size_t lda,\n+                  const T2* b, size_t ldb, T3* c, size_t ldc) {\n+    Eigen::Map<const Eigen::Matrix<T1, Eigen::Dynamic, Eigen::Dynamic,\n+                                   Eigen::RowMajor>>\n+        a_matrix(a, m, k);\n+    Eigen::Map<const Eigen::Matrix<T2, Eigen::Dynamic, Eigen::Dynamic,\n+                                   Eigen::RowMajor>>\n+        b_matrix(b, k, n);\n+    Eigen::Map<", "path": "tensorflow/core/kernels/conv_ops_using_gemm.cc", "position": null, "original_position": 239, "commit_id": "38c644f32971c2a17fd0ca6ad9e09fdfb36d1b19", "original_commit_id": "1de99caa7c5967f768f5fb4cd0cab287ecccde41", "user": {"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}, "body": "Maybe typedef these: \n\npublic:\n  typedef Eigen::Map<const Eigen::Matrix<T2, Eigen::Dynamic, Eigen::Dynamic,\n\ufffc                                   Eigen::RowMajor>> ConstMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<T3, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> MatrixMap\n   void operator()(size_t m, size_t n, size_t k, const T1\\* a, size_t lda,\n\ufffc +                  const T2\\* b, size_t ldb, T3\\* c, size_t ldc) {\n        ConstMatrix a_matrix(a, m, x);\n         ...  \n\ufffc                                 \n", "created_at": "2016-08-16T17:29:33Z", "updated_at": "2016-08-23T01:49:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r74981098", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/74981098"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r74981098"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778"}}, "body_html": "<p>Maybe typedef these:</p>\n<p>public:<br>\ntypedef Eigen::Map&lt;const Eigen::Matrix&lt;T2, Eigen::Dynamic, Eigen::Dynamic,<br>\n\ufffc                                   Eigen::RowMajor&gt;&gt; ConstMatrixMap;<br>\ntypedef Eigen::Map&lt;Eigen::Matrix&lt;T3, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;&gt; MatrixMap<br>\nvoid operator()(size_t m, size_t n, size_t k, const T1* a, size_t lda,<br>\n\ufffc +                  const T2* b, size_t ldb, T3* c, size_t ldc) {<br>\nConstMatrix a_matrix(a, m, x);<br>\n...<br>\n\ufffc</p>", "body_text": "Maybe typedef these:\npublic:\ntypedef Eigen::Map<const Eigen::Matrix<T2, Eigen::Dynamic, Eigen::Dynamic,\n\ufffc                                   Eigen::RowMajor>> ConstMatrixMap;\ntypedef Eigen::Map<Eigen::Matrix<T3, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>> MatrixMap\nvoid operator()(size_t m, size_t n, size_t k, const T1* a, size_t lda,\n\ufffc +                  const T2* b, size_t ldb, T3* c, size_t ldc) {\nConstMatrix a_matrix(a, m, x);\n...\n\ufffc"}