{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75196837", "pull_request_review_id": null, "id": 75196837, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc1MTk2ODM3", "diff_hunk": "@@ -0,0 +1,612 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This file contains a set of different implementations of the two-dimensional\n+// convolution operation. The standard TensorFlow Conv2d kernel uses EigenTensor\n+// to implement the computation, but here there are a variety of different ways\n+// of producing the same result. These methods are designed to be easier to\n+// understand and connect to other libraries, so that we can take advantage of\n+// platforms that have specialized implementations of GEMM for example.\n+//\n+// The basic interface is a Conv functor object that's templated by the types\n+// of the data it will be operating on, and is passed in the arguments needed to\n+// calculate the convolution. The simplest implementation of this functor is\n+// ReferenceConvFunctor, which is a readable but slow reference version.\n+//\n+// A faster version uses the approach of packing image patches into a matrix\n+// before calling a matrix multiply, the Im2ColConvFunctor. In turn, this can\n+// use a variety of different methods to calculate the matrix multiplication,\n+// or GEMM. The simplest but slowest is the ReferenceGemmFunctor, but the\n+// FastGemmFunctor will use whatever optimized libraries are available. By\n+// default it uses Eigen, but on Apple platforms it will take advantage of the\n+// system's Accelerate BLAS library to get better performance than the standard\n+// TensorFlow convolution kernel.\n+//\n+// The version actually used is defined at the bottom of this file using the\n+// REGISTER_KERNEL_BUILDER() macro. To try out different implementations (for\n+// example to switch to a reference one for easier debugging) you can swap out\n+// the default functors in that call.\n+//\n+// The registration itself is guarded with the USE_GEMM_FOR_CONV macro. The iOS\n+// makefile build defines this, but if you want to enable this implementation\n+// and disable the standard EigenTensor one in other build setups, you'll need\n+// to define it there too.\n+\n+#include <string.h>\n+#include <map>\n+#include <vector>\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/numeric_op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/resource_mgr.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_slice.h\"\n+#include \"tensorflow/core/kernels/bounds_check.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+\n+#if defined(__APPLE__)\n+#include <Accelerate/Accelerate.h>\n+#define USE_ACCELERATE_GEMM\n+#endif  // __APPLE__\n+", "path": "tensorflow/core/kernels/conv_ops_using_gemm.cc", "position": 66, "original_position": 66, "commit_id": "38c644f32971c2a17fd0ca6ad9e09fdfb36d1b19", "original_commit_id": "1de99caa7c5967f768f5fb4cd0cab287ecccde41", "user": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "body": "We've discussed this off-line. The ideal solution is to run all our tests with multiple implementations, but it's not clear how to do that right now. I've manually run the complete set of OS X tests with all the functor combinations, and they pass, so that may be the best approach for now\n", "created_at": "2016-08-17T20:09:49Z", "updated_at": "2016-08-23T01:49:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r75196837", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75196837"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r75196837"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778"}}, "body_html": "<p>We've discussed this off-line. The ideal solution is to run all our tests with multiple implementations, but it's not clear how to do that right now. I've manually run the complete set of OS X tests with all the functor combinations, and they pass, so that may be the best approach for now</p>", "body_text": "We've discussed this off-line. The ideal solution is to run all our tests with multiple implementations, but it's not clear how to do that right now. I've manually run the complete set of OS X tests with all the functor combinations, and they pass, so that may be the best approach for now"}