{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75197675", "pull_request_review_id": null, "id": 75197675, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc1MTk3Njc1", "diff_hunk": "@@ -0,0 +1,612 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This file contains a set of different implementations of the two-dimensional\n+// convolution operation. The standard TensorFlow Conv2d kernel uses EigenTensor\n+// to implement the computation, but here there are a variety of different ways\n+// of producing the same result. These methods are designed to be easier to\n+// understand and connect to other libraries, so that we can take advantage of\n+// platforms that have specialized implementations of GEMM for example.\n+//\n+// The basic interface is a Conv functor object that's templated by the types\n+// of the data it will be operating on, and is passed in the arguments needed to\n+// calculate the convolution. The simplest implementation of this functor is\n+// ReferenceConvFunctor, which is a readable but slow reference version.\n+//\n+// A faster version uses the approach of packing image patches into a matrix\n+// before calling a matrix multiply, the Im2ColConvFunctor. In turn, this can\n+// use a variety of different methods to calculate the matrix multiplication,\n+// or GEMM. The simplest but slowest is the ReferenceGemmFunctor, but the\n+// FastGemmFunctor will use whatever optimized libraries are available. By\n+// default it uses Eigen, but on Apple platforms it will take advantage of the\n+// system's Accelerate BLAS library to get better performance than the standard\n+// TensorFlow convolution kernel.\n+//\n+// The version actually used is defined at the bottom of this file using the\n+// REGISTER_KERNEL_BUILDER() macro. To try out different implementations (for\n+// example to switch to a reference one for easier debugging) you can swap out\n+// the default functors in that call.\n+//\n+// The registration itself is guarded with the USE_GEMM_FOR_CONV macro. The iOS\n+// makefile build defines this, but if you want to enable this implementation\n+// and disable the standard EigenTensor one in other build setups, you'll need\n+// to define it there too.\n+\n+#include <string.h>\n+#include <map>\n+#include <vector>\n+#include \"tensorflow/core/framework/common_shape_fns.h\"\n+#include \"tensorflow/core/framework/numeric_op.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/resource_mgr.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/tensor_slice.h\"\n+#include \"tensorflow/core/kernels/bounds_check.h\"\n+#include \"tensorflow/core/util/padding.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+\n+#if defined(__APPLE__)\n+#include <Accelerate/Accelerate.h>\n+#define USE_ACCELERATE_GEMM\n+#endif  // __APPLE__\n+\n+namespace tensorflow {\n+\n+namespace {\n+// This function implements the convolution operation in as simple a form as\n+// possible. It won't give great performance, but it is very useful for\n+// stepping through and instrumenting for debugging, creating minimal benchmarks\n+// to prototype with, and sharing with teams that want to run this outside of\n+// our environment.\n+// With that in mind, I've avoided using anything except pretty standard C++\n+// types. This is especially noticeable in the data access through raw array\n+// indexing. It's deliberate in this case though, since it makes the underlying\n+// memory order very explicit, which is important for both inspecting memory\n+// contents during debugging and for specifying what we expect to others.\n+// The memory layout of the data is, from biggest stride to smallest:\n+// input_data = [input_batches, input_height, input_width, input_depth]\n+// filter_data = [filter_height, filter_width, input_depth, filter_count]\n+// output_data = [input_batches, output_height, output_width, filter_count]\n+template <class T1, class T2, class T3>\n+class ReferenceConvFunctor {\n+ public:\n+  void operator()(OpKernelContext* context, const T1* input_data,\n+                  int input_batches, int input_height, int input_width,\n+                  int input_depth, const T2* filter_data, int filter_height,\n+                  int filter_width, int filter_count, int stride_rows,\n+                  int stride_cols, Padding padding, T3* output_data,\n+                  int output_height, int output_width) {\n+    // The two different padding modes we support can be a bit confusing. SAME\n+    // means we're trying to produce an output image that's the same size as the\n+    // input. It's complicated by stride, which shrinks the output image by a\n+    // a factor, but it means we end up sampling from outside the borders of the\n+    // input. These out-of-bounds values are read as zeroes. VALID means only\n+    // produce output values where the filters can read all their values from\n+    // within the input image. It effectively removes the margins of the output\n+    // image compared to the one produced by SAME. Stride complicates this\n+    // definition though, because it can result in the right and bottom filter\n+    // patches sampling from outside the borders if it's greater than 1.\n+    // Most of the logic for sorting this all out is done before this function,\n+    // when we calculate the output size, but the positioning of the origin of\n+    // the filters is different between the two modes, since SAME positions the\n+    // first filter off the edge of the input.\n+    int filter_left_offset;\n+    int filter_top_offset;\n+    if (padding == VALID) {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - input_width + 1) /\n+          2;\n+      filter_top_offset = ((output_height - 1) * stride_rows + filter_height -\n+                           input_height + 1) /\n+                          2;\n+    } else {\n+      filter_left_offset =\n+          ((output_width - 1) * stride_cols + filter_width - input_width) / 2;\n+      filter_top_offset =\n+          ((output_height - 1) * stride_rows + filter_height - input_height) /\n+          2;\n+    }\n+\n+    // If we've got multiple images in our input, work through each of them.\n+    for (int batch = 0; batch < input_batches; ++batch) {\n+      // Walk through all the output image values, sliding the filter to\n+      // different\n+      // positions in the input.", "path": "tensorflow/core/kernels/conv_ops_using_gemm.cc", "position": null, "original_position": 128, "commit_id": "38c644f32971c2a17fd0ca6ad9e09fdfb36d1b19", "original_commit_id": "1de99caa7c5967f768f5fb4cd0cab287ecccde41", "user": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "body": "Done.\n", "created_at": "2016-08-17T20:14:40Z", "updated_at": "2016-08-23T01:49:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r75197675", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/75197675"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3778#discussion_r75197675"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3778"}}, "body_html": "<p>Done.</p>", "body_text": "Done."}