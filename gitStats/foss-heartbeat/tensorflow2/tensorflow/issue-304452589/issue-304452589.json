{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17650", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17650/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17650/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17650/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17650", "id": 304452589, "node_id": "MDU6SXNzdWUzMDQ0NTI1ODk=", "number": 17650, "title": "Allow tf.estimator.train_and_evaluate evaluation frequency in steps", "user": {"login": "skycoop", "id": 8099614, "node_id": "MDQ6VXNlcjgwOTk2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8099614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skycoop", "html_url": "https://github.com/skycoop", "followers_url": "https://api.github.com/users/skycoop/followers", "following_url": "https://api.github.com/users/skycoop/following{/other_user}", "gists_url": "https://api.github.com/users/skycoop/gists{/gist_id}", "starred_url": "https://api.github.com/users/skycoop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skycoop/subscriptions", "organizations_url": "https://api.github.com/users/skycoop/orgs", "repos_url": "https://api.github.com/users/skycoop/repos", "events_url": "https://api.github.com/users/skycoop/events{/privacy}", "received_events_url": "https://api.github.com/users/skycoop/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": {"login": "xiejw", "id": 1184671, "node_id": "MDQ6VXNlcjExODQ2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1184671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiejw", "html_url": "https://github.com/xiejw", "followers_url": "https://api.github.com/users/xiejw/followers", "following_url": "https://api.github.com/users/xiejw/following{/other_user}", "gists_url": "https://api.github.com/users/xiejw/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiejw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiejw/subscriptions", "organizations_url": "https://api.github.com/users/xiejw/orgs", "repos_url": "https://api.github.com/users/xiejw/repos", "events_url": "https://api.github.com/users/xiejw/events{/privacy}", "received_events_url": "https://api.github.com/users/xiejw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "xiejw", "id": 1184671, "node_id": "MDQ6VXNlcjExODQ2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1184671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiejw", "html_url": "https://github.com/xiejw", "followers_url": "https://api.github.com/users/xiejw/followers", "following_url": "https://api.github.com/users/xiejw/following{/other_user}", "gists_url": "https://api.github.com/users/xiejw/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiejw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiejw/subscriptions", "organizations_url": "https://api.github.com/users/xiejw/orgs", "repos_url": "https://api.github.com/users/xiejw/repos", "events_url": "https://api.github.com/users/xiejw/events{/privacy}", "received_events_url": "https://api.github.com/users/xiejw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 24, "created_at": "2018-03-12T16:47:38Z", "updated_at": "2018-11-14T19:15:51Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:  <code>v1.6.0-0-gd2e24b6039 1.6.0</code></li>\n<li><strong>Python version</strong>: Python 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0</li>\n<li><strong>GPU model and memory</strong>: GTX 1080/1080Ti, P100</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>We're using <code>tf.estimator.train_and_evaluate</code> for running our training, but we're running into an issue with getting it to run evaluation at the correct frequency. Because the training input pipeline is fully reset after evaluation, we're attempting to follow the docs recommendation of running evaluation after an epoch or two.</p>\n<p>This is a problem for us because we can only figure out how to set the evaluation frequency using <code>tf.estimator.EvalSpec.throttle_secs</code>, which runs evaluation every <code>throttle_secs</code> seconds (since our evaluation takes less time than <code>throttle_secs</code>).  We run on a few different hardware platforms and configurations that all alter the training speed, so the only way to ensure that we perform evaluation after finishing an epoch is to calculate a value for <code>throttle_secs</code> that incorporates that training's training speed. This is obviously suboptimal compared to setting the evaluation frequency in steps rather than seconds.</p>\n<p>Here are the approaches to solving this problem that I've been able to find after a little poking around:</p>\n<ol>\n<li>Prevent evaluations triggered by <code>throttle_secs</code> passing from saving a new checkpoint, and only run if there is a new checkpoint. This lets the user specify <code>tf.estimator.RunConfig.save_checkpoints_steps</code> to set the evaluation frequency. This is actually how I thought <code>throttle_secs</code> worked based on my reading of the documentation</li>\n<li>Allow the user to set <code>throttle_steps</code> as a part of the <code>EvalSpec</code>. This value would could be used by the <code>SecondOrStepTimer</code> to run the evaluation based on how many steps have elapsed instead of seconds.</li>\n</ol>\n<p>I'd be willing to submit a PR with either fix, but I'm not sure which one would be correct/best, so I'd appreciate any feedback or alternate solutions <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below):  v1.6.0-0-gd2e24b6039 1.6.0\nPython version: Python 3.5.2\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0/7.0\nGPU model and memory: GTX 1080/1080Ti, P100\nExact command to reproduce: N/A\n\nDescribe the problem\nWe're using tf.estimator.train_and_evaluate for running our training, but we're running into an issue with getting it to run evaluation at the correct frequency. Because the training input pipeline is fully reset after evaluation, we're attempting to follow the docs recommendation of running evaluation after an epoch or two.\nThis is a problem for us because we can only figure out how to set the evaluation frequency using tf.estimator.EvalSpec.throttle_secs, which runs evaluation every throttle_secs seconds (since our evaluation takes less time than throttle_secs).  We run on a few different hardware platforms and configurations that all alter the training speed, so the only way to ensure that we perform evaluation after finishing an epoch is to calculate a value for throttle_secs that incorporates that training's training speed. This is obviously suboptimal compared to setting the evaluation frequency in steps rather than seconds.\nHere are the approaches to solving this problem that I've been able to find after a little poking around:\n\nPrevent evaluations triggered by throttle_secs passing from saving a new checkpoint, and only run if there is a new checkpoint. This lets the user specify tf.estimator.RunConfig.save_checkpoints_steps to set the evaluation frequency. This is actually how I thought throttle_secs worked based on my reading of the documentation\nAllow the user to set throttle_steps as a part of the EvalSpec. This value would could be used by the SecondOrStepTimer to run the evaluation based on how many steps have elapsed instead of seconds.\n\nI'd be willing to submit a PR with either fix, but I'm not sure which one would be correct/best, so I'd appreciate any feedback or alternate solutions \ud83d\ude04", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**:  `v1.6.0-0-gd2e24b6039 1.6.0`\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GTX 1080/1080Ti, P100\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nWe're using `tf.estimator.train_and_evaluate` for running our training, but we're running into an issue with getting it to run evaluation at the correct frequency. Because the training input pipeline is fully reset after evaluation, we're attempting to follow the docs recommendation of running evaluation after an epoch or two. \r\n\r\nThis is a problem for us because we can only figure out how to set the evaluation frequency using `tf.estimator.EvalSpec.throttle_secs`, which runs evaluation every `throttle_secs` seconds (since our evaluation takes less time than `throttle_secs`).  We run on a few different hardware platforms and configurations that all alter the training speed, so the only way to ensure that we perform evaluation after finishing an epoch is to calculate a value for `throttle_secs` that incorporates that training's training speed. This is obviously suboptimal compared to setting the evaluation frequency in steps rather than seconds.\r\n\r\nHere are the approaches to solving this problem that I've been able to find after a little poking around:\r\n\r\n1. Prevent evaluations triggered by `throttle_secs` passing from saving a new checkpoint, and only run if there is a new checkpoint. This lets the user specify `tf.estimator.RunConfig.save_checkpoints_steps` to set the evaluation frequency. This is actually how I thought `throttle_secs` worked based on my reading of the documentation\r\n2. Allow the user to set `throttle_steps` as a part of the `EvalSpec`. This value would could be used by the `SecondOrStepTimer` to run the evaluation based on how many steps have elapsed instead of seconds.\r\n\r\n\r\nI'd be willing to submit a PR with either fix, but I'm not sure which one would be correct/best, so I'd appreciate any feedback or alternate solutions :smile: "}