{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17033", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17033/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17033/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17033/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17033", "id": 297369583, "node_id": "MDU6SXNzdWUyOTczNjk1ODM=", "number": 17033, "title": "cuda error on import", "user": {"login": "basirshariat", "id": 10917454, "node_id": "MDQ6VXNlcjEwOTE3NDU0", "avatar_url": "https://avatars3.githubusercontent.com/u/10917454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/basirshariat", "html_url": "https://github.com/basirshariat", "followers_url": "https://api.github.com/users/basirshariat/followers", "following_url": "https://api.github.com/users/basirshariat/following{/other_user}", "gists_url": "https://api.github.com/users/basirshariat/gists{/gist_id}", "starred_url": "https://api.github.com/users/basirshariat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/basirshariat/subscriptions", "organizations_url": "https://api.github.com/users/basirshariat/orgs", "repos_url": "https://api.github.com/users/basirshariat/repos", "events_url": "https://api.github.com/users/basirshariat/events{/privacy}", "received_events_url": "https://api.github.com/users/basirshariat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-02-15T08:57:12Z", "updated_at": "2018-04-10T18:32:17Z", "closed_at": "2018-04-10T18:32:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: yes</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Fedora 16.04</li>\n<li><strong>TensorFlow installed from</strong>: binary</li>\n<li><strong>TensorFlow version</strong>: v1.4.0-19-ga52c8d9, 1.4.1</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: cuda_8.0.61,  cudnnv5</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX TITAN X ,   12207MiB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>We have a computer cluster that some of the machines have GPU and others don't. I have installed tensorflow-gpu-1.4 from wheel file in a virtualenv in a folder on the file-server which means that it is accessible on all the machines in the cluster.<br>\nMy program is a distributed software which means that some of the tasks are done on all the cluster nodes. (data generation and configuration) and the machine learning part is only done on the machines with GPU. I activate the aforementioned virtualenv before running the servers on nodes of the cluster so all the nodes are running inside the same virtual environment.<br>\nOn the machines that have a GPU when I import tensorflow everything works fine, but when I import the tensorflow on the machines that do not have the gpu (and Cuda is not installed on them) I get following error:</p>\n<blockquote>\n<p>In [1]: import tensorflow as tf<br>\nImportError                               Traceback (most recent call last)<br>\n in ()<br>\n----&gt; 1 import tensorflow as tf</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/<strong>init</strong>.py in ()<br>\n22<br>\n23 # pylint: disable=wildcard-import<br>\n---&gt; 24 from tensorflow.python import *<br>\n25 # pylint: enable=wildcard-import<br>\n26</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/<strong>init</strong>.py in ()<br>\n47 import numpy as np<br>\n48<br>\n---&gt; 49 from tensorflow.python import pywrap_tensorflow<br>\n50<br>\n51 # Protocol buffers</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in ()<br>\n70 for some common reasons and solutions.  Include the entire stack trace<br>\n71 above this error message when asking for help.\"\"\" % traceback.format_exc()<br>\n---&gt; 72   raise ImportError(msg)<br>\n73<br>\n74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long</p>\n<p>ImportError: Traceback (most recent call last):<br>\nFile \"virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <br>\nfrom tensorflow.python.pywrap_tensorflow_internal import *<br>\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <br>\n_pywrap_tensorflow_internal = swig_import_helper()<br>\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper<br>\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)<br>\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory</p>\n<p>Failed to load the native TensorFlow runtime.</p>\n<p>See <a href=\"https://www.tensorflow.org/install/install_sources#common_installation_problems\" rel=\"nofollow\">https://www.tensorflow.org/install/install_sources#common_installation_problems</a></p>\n<p>for some common reasons and solutions.  Include the entire stack trace<br>\nabove this error message when asking for help.</p>\n</blockquote>\n<p>I am aware that tensorflow-gpu is statically linked to the Cuda libraries and I installed a local version of Cuda using the runfile in a folder on the file-server (accessible to all the nodes) and added its path to the LD_LIBRARY_PATH and PATH and now importing tf gives me the following error:</p>\n<blockquote>\n<p>2018-02-15 01:41:58.519693: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU</p>\n</blockquote>\n<blockquote>\n<p>supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA<br>\n2018-02-15 01:41:58.519972: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)<br>\n2018-02-15 01:41:58.520007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: maserati<br>\n2018-02-15 01:41:58.520017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: maserati<br>\n2018-02-15 01:41:58.520140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program<br>\n2018-02-15 01:41:58.520167: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.111  Tue Dec 19 23:51:45 PST 2017<br>\nGCC version:  gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC)<br>\n\"\"\"<br>\n2018-02-15 01:41:58.520191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 384.111.0</p>\n</blockquote>\n<p>And when i run a hello world script it gives me the following error (which clearly means it cant run anything on gpu because of previous error):</p>\n<blockquote>\n<p>In [5]: with tf.device(\"/GPU:0\"):<br>\n...:     hello = tf.constant('Hello, TensorFlow!')<br>\n...:     sess = tf.Session()<br>\n...:     print(sess.run(hello))<br>\n...:<br>\nInvalidArgumentError                      Traceback (most recent call last)<br>\n in ()<br>\n2     hello = tf.constant('Hello, TensorFlow!')<br>\n3     sess = tf.Session()<br>\n----&gt; 4     print(sess.run(hello))<br>\n5</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)<br>\n887     try:<br>\n888       result = self._run(None, fetches, feed_dict, options_ptr,<br>\n--&gt; 889                          run_metadata_ptr)<br>\n890       if run_metadata:<br>\n891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)<br>\n1118     if final_fetches or final_targets or (handle and feed_dict_tensor):<br>\n1119       results = self._do_run(handle, final_targets, final_fetches,<br>\n-&gt; 1120                              feed_dict_tensor, options, run_metadata)<br>\n1121     else:<br>\n1122       results = []</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)<br>\n1315     if handle is None:<br>\n1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,<br>\n-&gt; 1317                            options, run_metadata)<br>\n1318     else:<br>\n1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)</p>\n<p>/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)<br>\n1334         except KeyError:<br>\n1335           pass<br>\n-&gt; 1336       raise type(e)(node_def, op, message)<br>\n1337<br>\n1338   def _extend_graph(self):</p>\n<p>InvalidArgumentError: Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.<br>\n[[Node: Const_1 = Const<a href=\"\">dtype=DT_STRING, value=Tensor&lt;type: string shape: [] values: Hello, TensorFlow!&gt;, _device=\"/device:GPU:0\"</a>]]</p>\n<p>Caused by op u'Const_1', defined at:<br>\nFile \"/virtualenv/bin/ipython\", line 11, in <br>\nsys.exit(start_ipython())<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/<strong>init</strong>.py\", line 119, in start_ipython<br>\nreturn launch_new_instance(argv=argv, **kwargs)<br>\nFile \"/virtualenv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance<br>\napp.start()<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/ipapp.py\", line 355, in start<br>\nself.shell.mainloop()<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 493, in mainloop<br>\nself.interact()<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 484, in interact<br>\nself.run_cell(code, store_history=True)<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell<br>\ninteractivity=interactivity, compiler=compiler, result=result)<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes<br>\nif self.run_code(code, result):<br>\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code<br>\nexec(code_obj, self.user_global_ns, self.user_ns)<br>\nFile \"\", line 2, in <br>\nhello = tf.constant('Hello, TensorFlow!')<br>\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant<br>\nname=name).outputs[0]<br>\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op<br>\nop_def=op_def)<br>\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.<br>\n[[Node: Const_1 = Const<a href=\"\">dtype=DT_STRING, value=Tensor&lt;type: string shape: [] values: Hello, TensorFlow!&gt;, _device=\"/device:GPU:0\"</a>]]</p>\n</blockquote>\n<p>I dont wan't/ can't install cuda on non-gpu machines is there any work around for this issue?</p>", "body_text": "System information\n\nHave I written custom code: yes\nOS Platform and Distribution: Linux Fedora 16.04\nTensorFlow installed from: binary\nTensorFlow version: v1.4.0-19-ga52c8d9, 1.4.1\nPython version: 2.7\nBazel version: N/A\nCUDA/cuDNN version: cuda_8.0.61,  cudnnv5\nGPU model and memory: GeForce GTX TITAN X ,   12207MiB\nExact command to reproduce:\n\nWe have a computer cluster that some of the machines have GPU and others don't. I have installed tensorflow-gpu-1.4 from wheel file in a virtualenv in a folder on the file-server which means that it is accessible on all the machines in the cluster.\nMy program is a distributed software which means that some of the tasks are done on all the cluster nodes. (data generation and configuration) and the machine learning part is only done on the machines with GPU. I activate the aforementioned virtualenv before running the servers on nodes of the cluster so all the nodes are running inside the same virtual environment.\nOn the machines that have a GPU when I import tensorflow everything works fine, but when I import the tensorflow on the machines that do not have the gpu (and Cuda is not installed on them) I get following error:\n\nIn [1]: import tensorflow as tf\nImportError                               Traceback (most recent call last)\n in ()\n----> 1 import tensorflow as tf\n/virtualenv/lib/python2.7/site-packages/tensorflow/init.py in ()\n22\n23 # pylint: disable=wildcard-import\n---> 24 from tensorflow.python import *\n25 # pylint: enable=wildcard-import\n26\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/init.py in ()\n47 import numpy as np\n48\n---> 49 from tensorflow.python import pywrap_tensorflow\n50\n51 # Protocol buffers\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in ()\n70 for some common reasons and solutions.  Include the entire stack trace\n71 above this error message when asking for help.\"\"\" % traceback.format_exc()\n---> 72   raise ImportError(msg)\n73\n74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\nImportError: Traceback (most recent call last):\nFile \"virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in \nfrom tensorflow.python.pywrap_tensorflow_internal import *\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in \n_pywrap_tensorflow_internal = swig_import_helper()\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n\nI am aware that tensorflow-gpu is statically linked to the Cuda libraries and I installed a local version of Cuda using the runfile in a folder on the file-server (accessible to all the nodes) and added its path to the LD_LIBRARY_PATH and PATH and now importing tf gives me the following error:\n\n2018-02-15 01:41:58.519693: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU\n\n\nsupports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2018-02-15 01:41:58.519972: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)\n2018-02-15 01:41:58.520007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: maserati\n2018-02-15 01:41:58.520017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: maserati\n2018-02-15 01:41:58.520140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n2018-02-15 01:41:58.520167: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.111  Tue Dec 19 23:51:45 PST 2017\nGCC version:  gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC)\n\"\"\"\n2018-02-15 01:41:58.520191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 384.111.0\n\nAnd when i run a hello world script it gives me the following error (which clearly means it cant run anything on gpu because of previous error):\n\nIn [5]: with tf.device(\"/GPU:0\"):\n...:     hello = tf.constant('Hello, TensorFlow!')\n...:     sess = tf.Session()\n...:     print(sess.run(hello))\n...:\nInvalidArgumentError                      Traceback (most recent call last)\n in ()\n2     hello = tf.constant('Hello, TensorFlow!')\n3     sess = tf.Session()\n----> 4     print(sess.run(hello))\n5\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n887     try:\n888       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 889                          run_metadata_ptr)\n890       if run_metadata:\n891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\n1119       results = self._do_run(handle, final_targets, final_fetches,\n-> 1120                              feed_dict_tensor, options, run_metadata)\n1121     else:\n1122       results = []\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n1315     if handle is None:\n1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n-> 1317                            options, run_metadata)\n1318     else:\n1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\n/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n1334         except KeyError:\n1335           pass\n-> 1336       raise type(e)(node_def, op, message)\n1337\n1338   def _extend_graph(self):\nInvalidArgumentError: Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n[[Node: Const_1 = Constdtype=DT_STRING, value=Tensor<type: string shape: [] values: Hello, TensorFlow!>, _device=\"/device:GPU:0\"]]\nCaused by op u'Const_1', defined at:\nFile \"/virtualenv/bin/ipython\", line 11, in \nsys.exit(start_ipython())\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/init.py\", line 119, in start_ipython\nreturn launch_new_instance(argv=argv, **kwargs)\nFile \"/virtualenv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\napp.start()\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/ipapp.py\", line 355, in start\nself.shell.mainloop()\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 493, in mainloop\nself.interact()\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 484, in interact\nself.run_cell(code, store_history=True)\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\ninteractivity=interactivity, compiler=compiler, result=result)\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\nif self.run_code(code, result):\nFile \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\nexec(code_obj, self.user_global_ns, self.user_ns)\nFile \"\", line 2, in \nhello = tf.constant('Hello, TensorFlow!')\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\nname=name).outputs[0]\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\nop_def=op_def)\nFile \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n[[Node: Const_1 = Constdtype=DT_STRING, value=Tensor<type: string shape: [] values: Hello, TensorFlow!>, _device=\"/device:GPU:0\"]]\n\nI dont wan't/ can't install cuda on non-gpu machines is there any work around for this issue?", "body": "### System information\r\n- **Have I written custom code**: yes\r\n- **OS Platform and Distribution**: Linux Fedora 16.04\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: v1.4.0-19-ga52c8d9, 1.4.1\r\n- **Python version**: 2.7\r\n- **Bazel version**: N/A\r\n- **CUDA/cuDNN version**: cuda_8.0.61,  cudnnv5\r\n- **GPU model and memory**: GeForce GTX TITAN X ,   12207MiB\r\n- **Exact command to reproduce**:\r\n\r\nWe have a computer cluster that some of the machines have GPU and others don't. I have installed tensorflow-gpu-1.4 from wheel file in a virtualenv in a folder on the file-server which means that it is accessible on all the machines in the cluster. \r\nMy program is a distributed software which means that some of the tasks are done on all the cluster nodes. (data generation and configuration) and the machine learning part is only done on the machines with GPU. I activate the aforementioned virtualenv before running the servers on nodes of the cluster so all the nodes are running inside the same virtual environment.  \r\nOn the machines that have a GPU when I import tensorflow everything works fine, but when I import the tensorflow on the machines that do not have the gpu (and Cuda is not installed on them) I get following error:   \r\n\r\n> In [1]: import tensorflow as tf\r\n> ImportError                               Traceback (most recent call last)\r\n> <ipython-input-1-64156d691fe5> in <module>()\r\n> ----> 1 import tensorflow as tf\r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\r\n>      22 \r\n>      23 # pylint: disable=wildcard-import\r\n> ---> 24 from tensorflow.python import *\r\n>      25 # pylint: enable=wildcard-import\r\n>      26 \r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\r\n>      47 import numpy as np\r\n>      48 \r\n> ---> 49 from tensorflow.python import pywrap_tensorflow\r\n>      50 \r\n>      51 # Protocol buffers\r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n>      70 for some common reasons and solutions.  Include the entire stack trace\r\n>      71 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n> ---> 72   raise ImportError(msg)\r\n>      73 \r\n>      74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n> \r\n> ImportError: Traceback (most recent call last):\r\n>   File \"virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n>     from tensorflow.python.pywrap_tensorflow_internal import *\r\n>   File \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n>     _pywrap_tensorflow_internal = swig_import_helper()\r\n>   File \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> ImportError: libcuda.so.1: cannot open shared object file: No such file or directory\r\n> \r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n> \r\n> for some common reasons and solutions.  Include the entire stack trace\r\n> above this error message when asking for help.\r\n\r\nI am aware that tensorflow-gpu is statically linked to the Cuda libraries and I installed a local version of Cuda using the runfile in a folder on the file-server (accessible to all the nodes) and added its path to the LD_LIBRARY_PATH and PATH and now importing tf gives me the following error:\r\n\r\n> 2018-02-15 01:41:58.519693: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU \r\n\r\n> supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n> 2018-02-15 01:41:58.519972: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)\r\n> 2018-02-15 01:41:58.520007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: maserati\r\n> 2018-02-15 01:41:58.520017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: maserati\r\n> 2018-02-15 01:41:58.520140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n> 2018-02-15 01:41:58.520167: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.111  Tue Dec 19 23:51:45 PST 2017\r\n> GCC version:  gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC) \r\n> \"\"\"\r\n> 2018-02-15 01:41:58.520191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 384.111.0\r\n\r\nAnd when i run a hello world script it gives me the following error (which clearly means it cant run anything on gpu because of previous error):\r\n\r\n> In [5]: with tf.device(\"/GPU:0\"):\r\n>    ...:     hello = tf.constant('Hello, TensorFlow!')\r\n>    ...:     sess = tf.Session()\r\n>    ...:     print(sess.run(hello))\r\n>    ...:     \r\n> InvalidArgumentError                      Traceback (most recent call last)\r\n> <ipython-input-5-4fc1d9ca141a> in <module>()\r\n>       2     hello = tf.constant('Hello, TensorFlow!')\r\n>       3     sess = tf.Session()\r\n> ----> 4     print(sess.run(hello))\r\n>       5 \r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n>     887     try:\r\n>     888       result = self._run(None, fetches, feed_dict, options_ptr,\r\n> --> 889                          run_metadata_ptr)\r\n>     890       if run_metadata:\r\n>     891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n>    1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n>    1119       results = self._do_run(handle, final_targets, final_fetches,\r\n> -> 1120                              feed_dict_tensor, options, run_metadata)\r\n>    1121     else:\r\n>    1122       results = []\r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n>    1315     if handle is None:\r\n>    1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n> -> 1317                            options, run_metadata)\r\n>    1318     else:\r\n>    1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n> \r\n> /virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n>    1334         except KeyError:\r\n>    1335           pass\r\n> -> 1336       raise type(e)(node_def, op, message)\r\n>    1337 \r\n>    1338   def _extend_graph(self):\r\n> \r\n> InvalidArgumentError: Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n> \t [[Node: Const_1 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: Hello, TensorFlow!>, _device=\"/device:GPU:0\"]()]]\r\n> \r\n> Caused by op u'Const_1', defined at:\r\n>   File \"/virtualenv/bin/ipython\", line 11, in <module>\r\n>     sys.exit(start_ipython())\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/__init__.py\", line 119, in start_ipython\r\n>     return launch_new_instance(argv=argv, **kwargs)\r\n>   File \"/virtualenv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n>     app.start()\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/ipapp.py\", line 355, in start\r\n>     self.shell.mainloop()\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 493, in mainloop\r\n>     self.interact()\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py\", line 484, in interact\r\n>     self.run_cell(code, store_history=True)\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n>     interactivity=interactivity, compiler=compiler, result=result)\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n>     if self.run_code(code, result):\r\n>   File \"/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n>     exec(code_obj, self.user_global_ns, self.user_ns)\r\n>   File \"<ipython-input-5-4fc1d9ca141a>\", line 2, in <module>\r\n>     hello = tf.constant('Hello, TensorFlow!')\r\n>   File \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\r\n>     name=name).outputs[0]\r\n>   File \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n>     op_def=op_def)\r\n>   File \"/virtualenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n>     self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n> \r\n> InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Const_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n> \t [[Node: Const_1 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: Hello, TensorFlow!>, _device=\"/device:GPU:0\"]()]]\r\n\r\nI dont wan't/ can't install cuda on non-gpu machines is there any work around for this issue?"}