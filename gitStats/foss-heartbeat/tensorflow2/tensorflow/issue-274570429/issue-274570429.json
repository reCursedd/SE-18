{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14624", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14624/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14624/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14624/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14624", "id": 274570429, "node_id": "MDU6SXNzdWUyNzQ1NzA0Mjk=", "number": 14624, "title": "Bug: using regularizer for shared variables in tf.cond branches ", "user": {"login": "wyli", "id": 831580, "node_id": "MDQ6VXNlcjgzMTU4MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/831580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wyli", "html_url": "https://github.com/wyli", "followers_url": "https://api.github.com/users/wyli/followers", "following_url": "https://api.github.com/users/wyli/following{/other_user}", "gists_url": "https://api.github.com/users/wyli/gists{/gist_id}", "starred_url": "https://api.github.com/users/wyli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wyli/subscriptions", "organizations_url": "https://api.github.com/users/wyli/orgs", "repos_url": "https://api.github.com/users/wyli/repos", "events_url": "https://api.github.com/users/wyli/events{/privacy}", "received_events_url": "https://api.github.com/users/wyli/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-16T16:05:16Z", "updated_at": "2018-02-24T14:27:03Z", "closed_at": "2017-12-05T18:07:27Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug or a feature request.</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Mac OS X 10.13.1</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3.0</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Setting the <code>regularizer</code> of a shared variable in <code>tf.cond</code> branches gives an unexpected behaviour - only one copy of the regularization op is added to <code>tf.GraphKeys.REGULARIZATION_LOSSES</code>. This is different from adding operations to a collection explicitly. And optimizing the regularization loss doesn't raise an error.</p>\n<h3>Source code</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.layers.python.layers <span class=\"pl-k\">import</span> regularizers\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">regularised_model</span>(<span class=\"pl-smi\">is_training</span>):\n    scope_name <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>foo<span class=\"pl-pds\">'</span></span>\n    <span class=\"pl-k\">with</span> tf.variable_scope(scope_name) <span class=\"pl-k\">as</span> scope:\n        <span class=\"pl-k\">if</span> is_training:\n            scope.reuse_variables()\n        y <span class=\"pl-k\">=</span> tf.get_variable(\n            <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>y<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(),\n            <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">1.0</span>),\n            <span class=\"pl-v\">regularizer</span><span class=\"pl-k\">=</span>regularizers.l2_regularizer(<span class=\"pl-v\">scale</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>scope_name))\n        reg <span class=\"pl-k\">=</span> tf.nn.l2_loss(y) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">0.1</span>\n        tf.add_to_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>test_collection<span class=\"pl-pds\">'</span></span>, reg)\n    <span class=\"pl-k\">return</span> y\n\nbinary_flag <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.bool, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>())\ny_cond <span class=\"pl-k\">=</span> tf.cond(binary_flag,\n                 <span class=\"pl-k\">lambda</span>: regularised_model(<span class=\"pl-c1\">False</span>),\n                 <span class=\"pl-k\">lambda</span>: regularised_model(<span class=\"pl-c1\">True</span>))\n\nreg_loss <span class=\"pl-k\">=</span> tf.get_collection(tf.GraphKeys.<span class=\"pl-c1\">REGULARIZATION_LOSSES</span>)\n<span class=\"pl-k\">assert</span>(<span class=\"pl-c1\">len</span>(reg_loss) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">1</span>)\noutput <span class=\"pl-k\">=</span> y_cond <span class=\"pl-k\">+</span> reg_loss[<span class=\"pl-c1\">0</span>]\nopt <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-c1\">0.1</span>).minimize(output)\n\nreg_test <span class=\"pl-k\">=</span> tf.get_collection(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>test_collection<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">assert</span>(<span class=\"pl-c1\">len</span>(reg_test) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">2</span>)\noutput_reg_true <span class=\"pl-k\">=</span> y_cond <span class=\"pl-k\">+</span> reg_test[<span class=\"pl-c1\">0</span>]\noutput_reg_false <span class=\"pl-k\">=</span> y_cond <span class=\"pl-k\">+</span> reg_test[<span class=\"pl-c1\">1</span>]\n\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    <span class=\"pl-c1\">print</span>(sess.run(output_reg_true, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">True</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1.05</span>\n    <span class=\"pl-c1\">print</span>(sess.run(output_reg_false, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">False</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1.05</span>\n\n    <span class=\"pl-c1\">print</span>(sess.run(output, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">True</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1.05</span>\n    \n    <span class=\"pl-c1\">print</span>(sess.run([opt], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">True</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> [None]</span>\n    <span class=\"pl-c1\">print</span>(sess.run([opt], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">False</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> [None]</span>\n\n    <span class=\"pl-c1\">print</span>(sess.run(output, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{binary_flag: <span class=\"pl-c1\">False</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Error: Retval[0] does not have value</span>\n</pre></div>\n<h3>Log</h3>\n<pre><code>1.05\n1.05\n1.05\n[None]\n[None]\nTraceback (most recent call last):\n  File \"test_tf_cond.py\", line 43, in &lt;module&gt;\n    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug or a feature request.\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.13.1\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.3.0\nPython version: 2.7\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce:\n\nDescribe the problem\nSetting the regularizer of a shared variable in tf.cond branches gives an unexpected behaviour - only one copy of the regularization op is added to tf.GraphKeys.REGULARIZATION_LOSSES. This is different from adding operations to a collection explicitly. And optimizing the regularization loss doesn't raise an error.\nSource code\nimport tensorflow as tf\nfrom tensorflow.contrib.layers.python.layers import regularizers\n\n\ndef regularised_model(is_training):\n    scope_name = 'foo'\n    with tf.variable_scope(scope_name) as scope:\n        if is_training:\n            scope.reuse_variables()\n        y = tf.get_variable(\n            name='y', shape=(),\n            initializer=tf.constant_initializer(1.0),\n            regularizer=regularizers.l2_regularizer(scale=0.1, scope=scope_name))\n        reg = tf.nn.l2_loss(y) * 0.1\n        tf.add_to_collection('test_collection', reg)\n    return y\n\nbinary_flag = tf.placeholder(dtype=tf.bool, shape=())\ny_cond = tf.cond(binary_flag,\n                 lambda: regularised_model(False),\n                 lambda: regularised_model(True))\n\nreg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\nassert(len(reg_loss) == 1)\noutput = y_cond + reg_loss[0]\nopt = tf.train.AdamOptimizer(0.1).minimize(output)\n\nreg_test = tf.get_collection('test_collection')\nassert(len(reg_test) == 2)\noutput_reg_true = y_cond + reg_test[0]\noutput_reg_false = y_cond + reg_test[1]\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(sess.run(output_reg_true, feed_dict={binary_flag: True})) # 1.05\n    print(sess.run(output_reg_false, feed_dict={binary_flag: False})) # 1.05\n\n    print(sess.run(output, feed_dict={binary_flag: True})) # 1.05\n    \n    print(sess.run([opt], feed_dict={binary_flag: True})) # [None]\n    print(sess.run([opt], feed_dict={binary_flag: False})) # [None]\n\n    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value\n\nLog\n1.05\n1.05\n1.05\n[None]\n[None]\nTraceback (most recent call last):\n  File \"test_tf_cond.py\", line 43, in <module>\n    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n    options, run_metadata)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nSetting the `regularizer` of a shared variable in `tf.cond` branches gives an unexpected behaviour - only one copy of the regularization op is added to `tf.GraphKeys.REGULARIZATION_LOSSES`. This is different from adding operations to a collection explicitly. And optimizing the regularization loss doesn't raise an error.\r\n\r\n\r\n### Source code\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.layers.python.layers import regularizers\r\n\r\n\r\ndef regularised_model(is_training):\r\n    scope_name = 'foo'\r\n    with tf.variable_scope(scope_name) as scope:\r\n        if is_training:\r\n            scope.reuse_variables()\r\n        y = tf.get_variable(\r\n            name='y', shape=(),\r\n            initializer=tf.constant_initializer(1.0),\r\n            regularizer=regularizers.l2_regularizer(scale=0.1, scope=scope_name))\r\n        reg = tf.nn.l2_loss(y) * 0.1\r\n        tf.add_to_collection('test_collection', reg)\r\n    return y\r\n\r\nbinary_flag = tf.placeholder(dtype=tf.bool, shape=())\r\ny_cond = tf.cond(binary_flag,\r\n                 lambda: regularised_model(False),\r\n                 lambda: regularised_model(True))\r\n\r\nreg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\r\nassert(len(reg_loss) == 1)\r\noutput = y_cond + reg_loss[0]\r\nopt = tf.train.AdamOptimizer(0.1).minimize(output)\r\n\r\nreg_test = tf.get_collection('test_collection')\r\nassert(len(reg_test) == 2)\r\noutput_reg_true = y_cond + reg_test[0]\r\noutput_reg_false = y_cond + reg_test[1]\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(output_reg_true, feed_dict={binary_flag: True})) # 1.05\r\n    print(sess.run(output_reg_false, feed_dict={binary_flag: False})) # 1.05\r\n\r\n    print(sess.run(output, feed_dict={binary_flag: True})) # 1.05\r\n    \r\n    print(sess.run([opt], feed_dict={binary_flag: True})) # [None]\r\n    print(sess.run([opt], feed_dict={binary_flag: False})) # [None]\r\n\r\n    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value\r\n\r\n```\r\n### Log\r\n```\r\n1.05\r\n1.05\r\n1.05\r\n[None]\r\n[None]\r\nTraceback (most recent call last):\r\n  File \"test_tf_cond.py\", line 43, in <module>\r\n    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n```"}