{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20510", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20510/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20510/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20510/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20510", "id": 337834229, "node_id": "MDU6SXNzdWUzMzc4MzQyMjk=", "number": 20510, "title": "Memory Leak", "user": {"login": "matthew894", "id": 40792522, "node_id": "MDQ6VXNlcjQwNzkyNTIy", "avatar_url": "https://avatars0.githubusercontent.com/u/40792522?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthew894", "html_url": "https://github.com/matthew894", "followers_url": "https://api.github.com/users/matthew894/followers", "following_url": "https://api.github.com/users/matthew894/following{/other_user}", "gists_url": "https://api.github.com/users/matthew894/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthew894/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthew894/subscriptions", "organizations_url": "https://api.github.com/users/matthew894/orgs", "repos_url": "https://api.github.com/users/matthew894/repos", "events_url": "https://api.github.com/users/matthew894/events{/privacy}", "received_events_url": "https://api.github.com/users/matthew894/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "skye", "id": 88808, "node_id": "MDQ6VXNlcjg4ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/88808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skye", "html_url": "https://github.com/skye", "followers_url": "https://api.github.com/users/skye/followers", "following_url": "https://api.github.com/users/skye/following{/other_user}", "gists_url": "https://api.github.com/users/skye/gists{/gist_id}", "starred_url": "https://api.github.com/users/skye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skye/subscriptions", "organizations_url": "https://api.github.com/users/skye/orgs", "repos_url": "https://api.github.com/users/skye/repos", "events_url": "https://api.github.com/users/skye/events{/privacy}", "received_events_url": "https://api.github.com/users/skye/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-07-03T10:16:04Z", "updated_at": "2018-09-28T20:42:02Z", "closed_at": "2018-09-28T20:42:01Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nYes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 7</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nAnaconda</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nb'unknown' 1.8.0<br>\nCuDNN - None<br>\nGPU-Integrated</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Memory Leak when running my code</p>\n<h3>Source code / logs</h3>\n<p><code>import numpy as np</code><br>\n<code>import os</code><br>\n<code>import tensorflow as tf</code><br>\n<code>tf.enable_eager_execution()</code><br>\n<code>import tensorflow.contrib.eager as tfe</code><br>\n<code>import csv as csv</code></p>\n<p><code>import matplotlib.pyplot as plt</code><br>\n<code>from tensorflow.contrib.opt.python.training.elastic_average_optimizer import *</code><br>\n<code>import keras as keras</code></p>\n<p><code>def parse_csv(line):</code><br>\n<code>  example_defaults = [[0.], [0.], [0.], [0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.], [0]] # sets field types</code></p>\n<p><code>  parsed_line = tf.decode_csv(line, example_defaults)</code></p>\n<p><code>  # First 4 fields are features, combine into single tensor</code><br>\n<code>  features = tf.reshape(parsed_line[:-1], shape=(50,))</code><br>\n<code>  # Last field is the label</code><br>\n<code>  label = tf.reshape(parsed_line[-1], shape=())</code><br>\n<code>  return features, label</code></p>\n<p><code>train_dataset = tf.data.TextLineDataset(fileid + \"train\")</code><br>\n<code>train_dataset = train_dataset.map(parse_csv)</code><br>\n<code>train_dataset = train_dataset.shuffle(buffer_size=1000)</code><br>\n<code>train_dataset = train_dataset.batch(16)</code></p>\n<p><code>model = tf.keras.Sequential([</code><br>\n<code> tf.keras.layers.Dense(100, input_shape=(50,)),  # input shape required</code><br>\n<code> tf.keras.layers.Dense(2000),</code><br>\n<code>  tf.keras.layers.Dense(2000),</code><br>\n<code>  tf.keras.layers.Dense(200,activation = 'sigmoid'),</code><br>\n<code>  tf.keras.layers.Dense(200),</code><br>\n<code> tf.keras.layers.Dense(2000),</code><br>\n<code>tf.keras.layers.Dense(200),</code><br>\n<code> tf.keras.layers.Dense(2)</code></p>\n<p><code>])</code><br>\n<code>print (model.summary)</code></p>\n<p><code>def loss(model, x, y):</code><br>\n<code>  y_ = model(x)</code><br>\n<code>  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)</code></p>\n<p><code>def grad(model, inputs, targets):</code></p>\n<p><code>    with tf.GradientTape() as tape:</code></p>\n<p><code>       loss_value = loss(model, inputs, targets)</code></p>\n<p><code>  return tape.gradient(loss_value, model.variables)   </code></p>\n<p><code>optimizer = tf.train.AdamOptimizer(learning_rate = 0.0010)</code><br>\n<code>train_loss_results = []</code><br>\n<code>train_accuracy_results = []</code><br>\n<code>test_loss_results = []</code><br>\n<code>test_accuracy_results = []</code><br>\n<code>num_epochs = 2000</code></p>\n<p><code>for epoch in range(num_epochs):</code><br>\n<code>  epoch_loss_avg = tfe.metrics.Mean()</code><br>\n<code>  epoch_accuracy = tfe.metrics.Accuracy()</code></p>\n<p><code>  train_dataset = train_dataset.shuffle(16)</code><br>\n<code> #  Training loop - using batches of 32</code><br>\n<code> for x, y in train_dataset:</code><br>\n<code>  #   Optimize the model</code><br>\n<code>  grads = grad(model, x, y)</code><br>\n<code>  optimizer.apply_gradients(zip(grads, model.variables),</code><br>\n<code>                   global_step=tf.train.get_or_create_global_step())</code></p>\n<p><code>  #   Track progress</code><br>\n<code>    epoch_loss_avg(loss(model, x, y))  # add current batch loss</code><br>\n<code>     #compare predicted label to actual label</code><br>\n<code>    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)</code></p>\n<p><code>  # end epoch</code><br>\n<code>  train_loss_results.append(epoch_loss_avg.result())</code><br>\n<code>  train_accuracy_results.append(epoch_accuracy.result())</code></p>\n<p><code> if epoch % 1 == 0: print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_loss_avg.result(), epoch_accuracy.result()))</code></p>\n<p><code>  test_dataset = tf.data.TextLineDataset(fileid + \"test\") test_dataset = test_dataset.map(parse_csv) test_dataset = test_dataset.shuffle(buffer_size=1000) test_dataset = test_dataset.batch(32)</code></p>\n<p><code> test_accuracy = tfe.metrics.Accuracy()</code></p>\n<p><code> for (x, y) in test_dataset: prediction = tf.argmax(model(x), axis=1, output_type=tf.int32) test_accuracy(prediction, y)</code></p>\n<p><code>  print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result())) train_dataset = tf.data.TextLineDataset(fileid + \"train\") train_dataset = train_dataset.map(parse_csv) train_dataset = train_dataset.batch(32)</code></p>\n<p><code>del optimizer</code></p>\n<p><code>test_dataset = tf.data.TextLineDataset(fileid + \"test\")</code><br>\n<code>test_dataset = test_dataset.map(parse_csv)</code><br>\n<code>test_dataset = test_dataset.shuffle(buffer_size=1000)</code><br>\n<code>test_dataset = test_dataset.batch(32)</code></p>\n<p><code>test_accuracy = tfe.metrics.Accuracy()</code></p>\n<p><code>for (x, y) in test_dataset:</code><br>\n<code> prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)</code><br>\n<code>  test_accuracy(prediction, y)</code></p>\n<p><code>print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))</code></p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nYes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 7\nTensorFlow installed from (source or binary):\nAnaconda\nTensorFlow version (use command below):\nb'unknown' 1.8.0\nCuDNN - None\nGPU-Integrated\n\nDescribe the problem\nMemory Leak when running my code\nSource code / logs\nimport numpy as np\nimport os\nimport tensorflow as tf\ntf.enable_eager_execution()\nimport tensorflow.contrib.eager as tfe\nimport csv as csv\nimport matplotlib.pyplot as plt\nfrom tensorflow.contrib.opt.python.training.elastic_average_optimizer import *\nimport keras as keras\ndef parse_csv(line):\n  example_defaults = [[0.], [0.], [0.], [0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.], [0]] # sets field types\n  parsed_line = tf.decode_csv(line, example_defaults)\n  # First 4 fields are features, combine into single tensor\n  features = tf.reshape(parsed_line[:-1], shape=(50,))\n  # Last field is the label\n  label = tf.reshape(parsed_line[-1], shape=())\n  return features, label\ntrain_dataset = tf.data.TextLineDataset(fileid + \"train\")\ntrain_dataset = train_dataset.map(parse_csv)\ntrain_dataset = train_dataset.shuffle(buffer_size=1000)\ntrain_dataset = train_dataset.batch(16)\nmodel = tf.keras.Sequential([\n tf.keras.layers.Dense(100, input_shape=(50,)),  # input shape required\n tf.keras.layers.Dense(2000),\n  tf.keras.layers.Dense(2000),\n  tf.keras.layers.Dense(200,activation = 'sigmoid'),\n  tf.keras.layers.Dense(200),\n tf.keras.layers.Dense(2000),\ntf.keras.layers.Dense(200),\n tf.keras.layers.Dense(2)\n])\nprint (model.summary)\ndef loss(model, x, y):\n  y_ = model(x)\n  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\ndef grad(model, inputs, targets):\n    with tf.GradientTape() as tape:\n       loss_value = loss(model, inputs, targets)\n  return tape.gradient(loss_value, model.variables)   \noptimizer = tf.train.AdamOptimizer(learning_rate = 0.0010)\ntrain_loss_results = []\ntrain_accuracy_results = []\ntest_loss_results = []\ntest_accuracy_results = []\nnum_epochs = 2000\nfor epoch in range(num_epochs):\n  epoch_loss_avg = tfe.metrics.Mean()\n  epoch_accuracy = tfe.metrics.Accuracy()\n  train_dataset = train_dataset.shuffle(16)\n #  Training loop - using batches of 32\n for x, y in train_dataset:\n  #   Optimize the model\n  grads = grad(model, x, y)\n  optimizer.apply_gradients(zip(grads, model.variables),\n                   global_step=tf.train.get_or_create_global_step())\n  #   Track progress\n    epoch_loss_avg(loss(model, x, y))  # add current batch loss\n     #compare predicted label to actual label\n    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n  # end epoch\n  train_loss_results.append(epoch_loss_avg.result())\n  train_accuracy_results.append(epoch_accuracy.result())\n if epoch % 1 == 0: print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_loss_avg.result(), epoch_accuracy.result()))\n  test_dataset = tf.data.TextLineDataset(fileid + \"test\") test_dataset = test_dataset.map(parse_csv) test_dataset = test_dataset.shuffle(buffer_size=1000) test_dataset = test_dataset.batch(32)\n test_accuracy = tfe.metrics.Accuracy()\n for (x, y) in test_dataset: prediction = tf.argmax(model(x), axis=1, output_type=tf.int32) test_accuracy(prediction, y)\n  print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result())) train_dataset = tf.data.TextLineDataset(fileid + \"train\") train_dataset = train_dataset.map(parse_csv) train_dataset = train_dataset.batch(32)\ndel optimizer\ntest_dataset = tf.data.TextLineDataset(fileid + \"test\")\ntest_dataset = test_dataset.map(parse_csv)\ntest_dataset = test_dataset.shuffle(buffer_size=1000)\ntest_dataset = test_dataset.batch(32)\ntest_accuracy = tfe.metrics.Accuracy()\nfor (x, y) in test_dataset:\n prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)\n  test_accuracy(prediction, y)\nprint(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 7\r\n- **TensorFlow installed from (source or binary)**:\r\nAnaconda\r\n- **TensorFlow version (use command below)**:\r\nb'unknown' 1.8.0\r\nCuDNN - None\r\nGPU-Integrated\r\n### Describe the problem\r\nMemory Leak when running my code \r\n\r\n### Source code / logs\r\n`import numpy as np`\r\n`import os`\r\n`import tensorflow as tf`\r\n`tf.enable_eager_execution()`\r\n`import tensorflow.contrib.eager as tfe`\r\n`import csv as csv`\r\n\r\n`import matplotlib.pyplot as plt`\r\n`from tensorflow.contrib.opt.python.training.elastic_average_optimizer import *`\r\n`import keras as keras`\r\n\r\n\r\n\r\n`def parse_csv(line):`\r\n`  example_defaults = [[0.], [0.], [0.], [0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.], [0]] # sets field types`\r\n  \r\n`  parsed_line = tf.decode_csv(line, example_defaults)`\r\n  \r\n`  # First 4 fields are features, combine into single tensor`\r\n`  features = tf.reshape(parsed_line[:-1], shape=(50,))`\r\n`  # Last field is the label`\r\n`  label = tf.reshape(parsed_line[-1], shape=())`\r\n`  return features, label`\r\n   \r\n`train_dataset = tf.data.TextLineDataset(fileid + \"train\")`\r\n`train_dataset = train_dataset.map(parse_csv)`\r\n`train_dataset = train_dataset.shuffle(buffer_size=1000)`\r\n`train_dataset = train_dataset.batch(16)`\r\n\r\n`model = tf.keras.Sequential([`\r\n ` tf.keras.layers.Dense(100, input_shape=(50,)),  # input shape required`\r\n ` tf.keras.layers.Dense(2000),`\r\n`  tf.keras.layers.Dense(2000),`\r\n`  tf.keras.layers.Dense(200,activation = 'sigmoid'),`\r\n`  tf.keras.layers.Dense(200),`\r\n ` tf.keras.layers.Dense(2000),`\r\n  `tf.keras.layers.Dense(200),`\r\n ` tf.keras.layers.Dense(2)`\r\n  \r\n`])`\r\n`print (model.summary)`\r\n\r\n\r\n`def loss(model, x, y):`\r\n`  y_ = model(x)`\r\n`  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)`\r\n\r\n`def grad(model, inputs, targets):`\r\n\r\n`    with tf.GradientTape() as tape:`\r\n    \r\n `       loss_value = loss(model, inputs, targets)`\r\n  \r\n `   return tape.gradient(loss_value, model.variables)    `\r\n\r\n`optimizer = tf.train.AdamOptimizer(learning_rate = 0.0010)`\r\n`train_loss_results = []`\r\n`train_accuracy_results = []`\r\n`test_loss_results = []`\r\n`test_accuracy_results = []`\r\n`num_epochs = 2000`\r\n\r\n`for epoch in range(num_epochs):`\r\n`  epoch_loss_avg = tfe.metrics.Mean()`\r\n`  epoch_accuracy = tfe.metrics.Accuracy()`\r\n  \r\n\r\n`  train_dataset = train_dataset.shuffle(16)`\r\n` #  Training loop - using batches of 32`\r\n` for x, y in train_dataset:`\r\n`  #   Optimize the model`\r\n  `  grads = grad(model, x, y)`\r\n  `  optimizer.apply_gradients(zip(grads, model.variables),`\r\n           `                   global_step=tf.train.get_or_create_global_step())`\r\n\r\n`  #   Track progress`\r\n`    epoch_loss_avg(loss(model, x, y))  # add current batch loss`\r\n`     #compare predicted label to actual label`\r\n`    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)`\r\n \r\n`  # end epoch`\r\n`  train_loss_results.append(epoch_loss_avg.result())`\r\n`  train_accuracy_results.append(epoch_accuracy.result())`\r\n  \r\n` if epoch % 1 == 0:\r\n    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\r\n                                                                epoch_loss_avg.result(),\r\n                                                                epoch_accuracy.result()))`\r\n  \r\n`  test_dataset = tf.data.TextLineDataset(fileid + \"test\")\r\n  test_dataset = test_dataset.map(parse_csv)\r\n  test_dataset = test_dataset.shuffle(buffer_size=1000)\r\n  test_dataset = test_dataset.batch(32)`\r\n  \r\n ` test_accuracy = tfe.metrics.Accuracy()`\r\n  \r\n ` for (x, y) in test_dataset:\r\n      prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)\r\n      test_accuracy(prediction, y)`\r\n      \r\n`  print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))\r\n  train_dataset = tf.data.TextLineDataset(fileid + \"train\")\r\n  train_dataset = train_dataset.map(parse_csv)\r\n  train_dataset = train_dataset.batch(32)`\r\n  \r\n\r\n\r\n`del optimizer`\r\n\r\n`test_dataset = tf.data.TextLineDataset(fileid + \"test\")`\r\n`test_dataset = test_dataset.map(parse_csv)`\r\n`test_dataset = test_dataset.shuffle(buffer_size=1000)`\r\n`test_dataset = test_dataset.batch(32)`\r\n\r\n`test_accuracy = tfe.metrics.Accuracy()`\r\n\r\n`for (x, y) in test_dataset:`\r\n ` prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)`\r\n`  test_accuracy(prediction, y)`\r\n\r\n`print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))`\r\n\r\n\r\n\r\n"}