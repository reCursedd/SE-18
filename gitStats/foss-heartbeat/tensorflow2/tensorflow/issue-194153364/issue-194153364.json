{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6170", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6170/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6170/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6170/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6170", "id": 194153364, "node_id": "MDU6SXNzdWUxOTQxNTMzNjQ=", "number": 6170, "title": "training process dies without warning", "user": {"login": "riklopfer", "id": 413300, "node_id": "MDQ6VXNlcjQxMzMwMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/413300?v=4", "gravatar_id": "", "url": "https://api.github.com/users/riklopfer", "html_url": "https://github.com/riklopfer", "followers_url": "https://api.github.com/users/riklopfer/followers", "following_url": "https://api.github.com/users/riklopfer/following{/other_user}", "gists_url": "https://api.github.com/users/riklopfer/gists{/gist_id}", "starred_url": "https://api.github.com/users/riklopfer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/riklopfer/subscriptions", "organizations_url": "https://api.github.com/users/riklopfer/orgs", "repos_url": "https://api.github.com/users/riklopfer/repos", "events_url": "https://api.github.com/users/riklopfer/events{/privacy}", "received_events_url": "https://api.github.com/users/riklopfer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-12-07T20:01:13Z", "updated_at": "2016-12-07T20:41:56Z", "closed_at": "2016-12-07T20:29:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have two GPUs. I start an LSTM training process on one GPU by masking CUDA_VISIBLE_DEVICES in the python script:</p>\n<div class=\"highlight highlight-source-python\"><pre>gpu_id<span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>0<span class=\"pl-pds\">'</span></span>\nos.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> gpu_id</pre></div>\n<p>I then start a second training process using the same technique, but with <code>gpu_id='1'</code>. Shortly after launching the second training process, the first one dies without any message.</p>\n<p>Each invocation looks something like this</p>\n<div class=\"highlight highlight-source-shell\"><pre>nohup python train.py .... <span class=\"pl-k\">&gt;&amp;</span> train.log <span class=\"pl-k\">&amp;</span></pre></div>\n<p>When I do the same thing without redirecting to a file, I see simply <code>Killed</code></p>\n<p>This only happens when I try to run two training processes. I am able to run training and evaluation at the same time on different cards.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Nothing looks similar.</p>\n<h3>Environment info</h3>\n<p>Operating System: CentOS 7</p>\n<p>Installed version of CUDA and cuDNN:<br>\nCUDA = 8.0 cuDNN = 5.1</p>\n<p>(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\n<a href=\"https://paste.debian.net/901121/\" rel=\"nofollow\">https://paste.debian.net/901121/</a></p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed: <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl</a></li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.<br>\n0.11.0</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<h3>What other attempted solutions have you tried?</h3>\n<ul>\n<li>I tried setting CUDA_VISIBLE_DEVICES from the command line before starting the training script. e.g. <code>CUDA_VISIBLE_DEVICES=0</code></li>\n</ul>\n<h3>Logs or other output that would be helpful</h3>\n<p>Driver Version: 367.48</p>", "body_text": "I have two GPUs. I start an LSTM training process on one GPU by masking CUDA_VISIBLE_DEVICES in the python script:\ngpu_id='0'\nos.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\nI then start a second training process using the same technique, but with gpu_id='1'. Shortly after launching the second training process, the first one dies without any message.\nEach invocation looks something like this\nnohup python train.py .... >& train.log &\nWhen I do the same thing without redirecting to a file, I see simply Killed\nThis only happens when I try to run two training processes. I am able to run training and evaluation at the same time on different cards.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nNothing looks similar.\nEnvironment info\nOperating System: CentOS 7\nInstalled version of CUDA and cuDNN:\nCUDA = 8.0 cuDNN = 5.1\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nhttps://paste.debian.net/901121/\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n0.11.0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nWhat other attempted solutions have you tried?\n\nI tried setting CUDA_VISIBLE_DEVICES from the command line before starting the training script. e.g. CUDA_VISIBLE_DEVICES=0\n\nLogs or other output that would be helpful\nDriver Version: 367.48", "body": "I have two GPUs. I start an LSTM training process on one GPU by masking CUDA_VISIBLE_DEVICES in the python script:\r\n\r\n```python\r\ngpu_id='0'\r\nos.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\r\n```\r\nI then start a second training process using the same technique, but with `gpu_id='1'`. Shortly after launching the second training process, the first one dies without any message. \r\n\r\nEach invocation looks something like this\r\n\r\n```bash\r\nnohup python train.py .... >& train.log &\r\n```\r\n\r\nWhen I do the same thing without redirecting to a file, I see simply `Killed`\r\n\r\nThis only happens when I try to run two training processes. I am able to run training and evaluation at the same time on different cards. \r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nNothing looks similar. \r\n\r\n### Environment info\r\nOperating System: CentOS 7\r\n\r\nInstalled version of CUDA and cuDNN: \r\nCUDA = 8.0 cuDNN = 5.1\r\n\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): \r\nhttps://paste.debian.net/901121/\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n0.11.0\r\n\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n*  I tried setting CUDA_VISIBLE_DEVICES from the command line before starting the training script. e.g. `CUDA_VISIBLE_DEVICES=0`\r\n\r\n### Logs or other output that would be helpful\r\nDriver Version: 367.48\r\n\r\n"}