{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2575", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2575/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2575/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2575/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2575", "id": 157422551, "node_id": "MDU6SXNzdWUxNTc0MjI1NTE=", "number": 2575, "title": "while loop endless loop", "user": {"login": "HanyuGuo", "id": 14354442, "node_id": "MDQ6VXNlcjE0MzU0NDQy", "avatar_url": "https://avatars2.githubusercontent.com/u/14354442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HanyuGuo", "html_url": "https://github.com/HanyuGuo", "followers_url": "https://api.github.com/users/HanyuGuo/followers", "following_url": "https://api.github.com/users/HanyuGuo/following{/other_user}", "gists_url": "https://api.github.com/users/HanyuGuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/HanyuGuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HanyuGuo/subscriptions", "organizations_url": "https://api.github.com/users/HanyuGuo/orgs", "repos_url": "https://api.github.com/users/HanyuGuo/repos", "events_url": "https://api.github.com/users/HanyuGuo/events{/privacy}", "received_events_url": "https://api.github.com/users/HanyuGuo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-05-30T02:46:55Z", "updated_at": "2016-10-05T02:55:53Z", "closed_at": "2016-06-01T17:11:29Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: CentOS 7</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\nCPU version</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n<li>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".</li>\n</ol>\n<p>0.8.0</p>\n<h3>Steps to reproduce</h3>\n<p>I am using TensorFlow to implement a network that needs to use <code>tf.while_loop()</code></p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nclass model(object):\n    def __init__(self):\n        self.argmax_ep_gate_array = [ tf.placeholder(tf.int32, [None]) for _ in range(10)]\n        argmax_ep_gate_array_concat = tf.concat(0, self.argmax_ep_gate_array)\n        story_len = tf.constant(7)\n        starter = tf.constant(0)\n        z = []\n        def body(hops):\n            hops = tf.add(hops,1)\n            z.append(hops)\n            return hops\n        def condition(hops):\n            return tf.logical_and(tf.less(tf.gather(argmax_ep_gate_array_concat, hops),story_len),tf.less(hops,tf.constant(20)))\n\n        self.gate_index = tf.while_loop(condition,body,[starter])\n        self.z=tf.concat(0,z)\n\n    def step(self, sess):\n        feed={}\n        for i in range(10):\n            feed[self.argmax_ep_gate_array[i].name]=[i]\n        print (sess.run([self.gate_index,self.z],feed))\nwith tf.Session() as sess:\n    while_loop = model()\n    sess.run(tf.initialize_all_variables())\n    while_loop.step(sess)\n\n</code></pre>\n<h3>What have you tried?</h3>\n<p>I find that If I want to sess.run() any variable in the body() that is not returned, tensorflow would stuck into endless loop.<br>\nThe above example is trivial, but it reveals something. In the real case, I am using <code>tf.while_loop()</code> running a RNN which includes y= wx+b something like that, but the <code>w</code> and <code>b</code> are not returned after while loop. In the forward network, it works fine. However, if I run the back propagation, the program would stuck into endless loop. I suppose the code above reproducing my issue, because back propagation do need to modify <code>w</code> and <code>b</code>. Or is there any way to handle this issue?</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).<br>\nNo logs, Just stuck into endless loop</p>", "body_text": "Environment info\nOperating System: CentOS 7\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nCPU version\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\n\n0.8.0\nSteps to reproduce\nI am using TensorFlow to implement a network that needs to use tf.while_loop()\nimport tensorflow as tf\nimport numpy as np\nclass model(object):\n    def __init__(self):\n        self.argmax_ep_gate_array = [ tf.placeholder(tf.int32, [None]) for _ in range(10)]\n        argmax_ep_gate_array_concat = tf.concat(0, self.argmax_ep_gate_array)\n        story_len = tf.constant(7)\n        starter = tf.constant(0)\n        z = []\n        def body(hops):\n            hops = tf.add(hops,1)\n            z.append(hops)\n            return hops\n        def condition(hops):\n            return tf.logical_and(tf.less(tf.gather(argmax_ep_gate_array_concat, hops),story_len),tf.less(hops,tf.constant(20)))\n\n        self.gate_index = tf.while_loop(condition,body,[starter])\n        self.z=tf.concat(0,z)\n\n    def step(self, sess):\n        feed={}\n        for i in range(10):\n            feed[self.argmax_ep_gate_array[i].name]=[i]\n        print (sess.run([self.gate_index,self.z],feed))\nwith tf.Session() as sess:\n    while_loop = model()\n    sess.run(tf.initialize_all_variables())\n    while_loop.step(sess)\n\n\nWhat have you tried?\nI find that If I want to sess.run() any variable in the body() that is not returned, tensorflow would stuck into endless loop.\nThe above example is trivial, but it reveals something. In the real case, I am using tf.while_loop() running a RNN which includes y= wx+b something like that, but the w and b are not returned after while loop. In the forward network, it works fine. However, if I run the back propagation, the program would stuck into endless loop. I suppose the code above reproducing my issue, because back propagation do need to modify w and b. Or is there any way to handle this issue?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).\nNo logs, Just stuck into endless loop", "body": "### Environment info\n\nOperating System: CentOS 7\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nCPU version\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n0.8.0\n### Steps to reproduce\n\nI am using TensorFlow to implement a network that needs to use `tf.while_loop()`\n\n```\nimport tensorflow as tf\nimport numpy as np\nclass model(object):\n    def __init__(self):\n        self.argmax_ep_gate_array = [ tf.placeholder(tf.int32, [None]) for _ in range(10)]\n        argmax_ep_gate_array_concat = tf.concat(0, self.argmax_ep_gate_array)\n        story_len = tf.constant(7)\n        starter = tf.constant(0)\n        z = []\n        def body(hops):\n            hops = tf.add(hops,1)\n            z.append(hops)\n            return hops\n        def condition(hops):\n            return tf.logical_and(tf.less(tf.gather(argmax_ep_gate_array_concat, hops),story_len),tf.less(hops,tf.constant(20)))\n\n        self.gate_index = tf.while_loop(condition,body,[starter])\n        self.z=tf.concat(0,z)\n\n    def step(self, sess):\n        feed={}\n        for i in range(10):\n            feed[self.argmax_ep_gate_array[i].name]=[i]\n        print (sess.run([self.gate_index,self.z],feed))\nwith tf.Session() as sess:\n    while_loop = model()\n    sess.run(tf.initialize_all_variables())\n    while_loop.step(sess)\n\n```\n### What have you tried?\n\nI find that If I want to sess.run() any variable in the body() that is not returned, tensorflow would stuck into endless loop. \nThe above example is trivial, but it reveals something. In the real case, I am using `tf.while_loop()` running a RNN which includes y= wx+b something like that, but the `w` and `b` are not returned after while loop. In the forward network, it works fine. However, if I run the back propagation, the program would stuck into endless loop. I suppose the code above reproducing my issue, because back propagation do need to modify `w` and `b`. Or is there any way to handle this issue? \n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nNo logs, Just stuck into endless loop\n"}