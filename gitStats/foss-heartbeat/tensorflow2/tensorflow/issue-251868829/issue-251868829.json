{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12480", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12480/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12480/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12480/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12480", "id": 251868829, "node_id": "MDU6SXNzdWUyNTE4Njg4Mjk=", "number": 12480, "title": "Use Tensorflow in conjunction with PyTorch/Theano", "user": {"login": "windweller", "id": 4699797, "node_id": "MDQ6VXNlcjQ2OTk3OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4699797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/windweller", "html_url": "https://github.com/windweller", "followers_url": "https://api.github.com/users/windweller/followers", "following_url": "https://api.github.com/users/windweller/following{/other_user}", "gists_url": "https://api.github.com/users/windweller/gists{/gist_id}", "starred_url": "https://api.github.com/users/windweller/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/windweller/subscriptions", "organizations_url": "https://api.github.com/users/windweller/orgs", "repos_url": "https://api.github.com/users/windweller/repos", "events_url": "https://api.github.com/users/windweller/events{/privacy}", "received_events_url": "https://api.github.com/users/windweller/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-22T07:56:07Z", "updated_at": "2017-08-22T22:55:36Z", "closed_at": "2017-08-22T14:38:49Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 0.12.1</li>\n<li><strong>Python version</strong>: 2.7.10</li>\n<li><strong>Bazel version (if compiling from source)</strong>: None</li>\n<li><strong>CUDA/cuDNN version</strong>: 5.1</li>\n<li><strong>GPU model and memory</strong>: 1080-Ti</li>\n<li><strong>Exact command to reproduce</strong>: None</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to use Tensorflow in conjunction with PyTorch (I built the model in Tensorflow to generate vector representations and PyTorch trains on top of those). However, the problem is that PyTorch runs out of memory because TF will replicate the model in ALL available CUDA devices. In this case CUDA_VISIBLE_DEVICES is not helpful, and I tried GPU device tf.device(\"/gpu:0\") but Tensorflow still fills up all GPUs' memory.</p>\n<p>Is there some way to actually limit Tensorflow's GPU usage to one and free up the other for other DL libraries like PyTorch or Theano?</p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 0.12.1\nPython version: 2.7.10\nBazel version (if compiling from source): None\nCUDA/cuDNN version: 5.1\nGPU model and memory: 1080-Ti\nExact command to reproduce: None\n\nDescribe the problem\nI'm trying to use Tensorflow in conjunction with PyTorch (I built the model in Tensorflow to generate vector representations and PyTorch trains on top of those). However, the problem is that PyTorch runs out of memory because TF will replicate the model in ALL available CUDA devices. In this case CUDA_VISIBLE_DEVICES is not helpful, and I tried GPU device tf.device(\"/gpu:0\") but Tensorflow still fills up all GPUs' memory.\nIs there some way to actually limit Tensorflow's GPU usage to one and free up the other for other DL libraries like PyTorch or Theano?", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 0.12.1\r\n- **Python version**: 2.7.10\r\n- **Bazel version (if compiling from source)**: None\r\n- **CUDA/cuDNN version**: 5.1\r\n- **GPU model and memory**: 1080-Ti\r\n- **Exact command to reproduce**: None\r\n\r\n### Describe the problem\r\nI'm trying to use Tensorflow in conjunction with PyTorch (I built the model in Tensorflow to generate vector representations and PyTorch trains on top of those). However, the problem is that PyTorch runs out of memory because TF will replicate the model in ALL available CUDA devices. In this case CUDA_VISIBLE_DEVICES is not helpful, and I tried GPU device tf.device(\"/gpu:0\") but Tensorflow still fills up all GPUs' memory.\r\n\r\nIs there some way to actually limit Tensorflow's GPU usage to one and free up the other for other DL libraries like PyTorch or Theano?"}