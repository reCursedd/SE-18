{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/441057414", "html_url": "https://github.com/tensorflow/tensorflow/issues/18652#issuecomment-441057414", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18652", "id": 441057414, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTA1NzQxNA==", "user": {"login": "LukeAI", "id": 43993778, "node_id": "MDQ6VXNlcjQzOTkzNzc4", "avatar_url": "https://avatars3.githubusercontent.com/u/43993778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LukeAI", "html_url": "https://github.com/LukeAI", "followers_url": "https://api.github.com/users/LukeAI/followers", "following_url": "https://api.github.com/users/LukeAI/following{/other_user}", "gists_url": "https://api.github.com/users/LukeAI/gists{/gist_id}", "starred_url": "https://api.github.com/users/LukeAI/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LukeAI/subscriptions", "organizations_url": "https://api.github.com/users/LukeAI/orgs", "repos_url": "https://api.github.com/users/LukeAI/repos", "events_url": "https://api.github.com/users/LukeAI/events{/privacy}", "received_events_url": "https://api.github.com/users/LukeAI/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-22T15:07:47Z", "updated_at": "2018-11-22T15:07:47Z", "author_association": "NONE", "body_html": "<p>Hi all, I'm having the same issue - did anybody find a workaround?<br>\nIt takes a very long time on the first run but is very quick on subsequent runs. If I relaunch the container then it goes back to being very slow for one run. I get very similar output/behaviour if I run the same code using the Anaconda distribution of tensorflow.</p>\n<p>System information</p>\n<pre><code>    Code:\nimport time\nstart_time = time.time()\nimport tensorflow as tf\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nprint(sess.run(c))\ntimer = time.time()\nprint(timer - start_time)\n\nOutput:\n\n~$ docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\nroot@7ee18dae8673:/notebooks# python\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \n[GCC 5.4.0 20160609] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import time\n&gt;&gt;&gt; start_time = time.time()\n&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n&gt;&gt;&gt; b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n&gt;&gt;&gt; c = tf.matmul(a, b)\n&gt;&gt;&gt; sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n2018-11-22 14:52:07.974293: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-22 14:52:08.052892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-22 14:52:08.053603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \nname: Quadro M1000M major: 5 minor: 0 memoryClockRate(GHz): 1.0715\npciBusID: 0000:01:00.0\ntotalMemory: 1.96GiB freeMemory: 1.70GiB\n2018-11-22 14:52:08.053621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n2018-11-22 14:56:17.618342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-22 14:56:17.618385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n2018-11-22 14:56:17.618395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n2018-11-22 14:56:17.618726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1447 MB memory) -&gt; physical GPU (device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\n2018-11-22 14:56:17.619285: I tensorflow/core/common_runtime/direct_session.cc:307] Device mapping:\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\n\n&gt;&gt;&gt; print(sess.run(c))\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620406: I tensorflow/core/common_runtime/placer.cc:927] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620431: I tensorflow/core/common_runtime/placer.cc:927] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620470: I tensorflow/core/common_runtime/placer.cc:927] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0\n[[22. 28.]\n [49. 64.]]\n&gt;&gt;&gt; timer = time.time()\n&gt;&gt;&gt; print(timer - start_time)\n250.8216381072998\n\n\n    OS Platform and Distribution:\ndocker on Ubuntu 16.04\n\n    TensorFlow installed from (source or binary):\n    binary / docker\n\n    TensorFlow version:\n    tensorflow-gpu 1.12\n\n    Python version:\n3.5\n\n    Bazel Version:\n    N/A\n\n    CUDA/cuDNN version:\n10.0\n\n    GPU model and memory:\n    NVIDIA Quadro M1000M with 2004MiB memory - 8GB system RAM\n\n    **Exact command to reproduce:**\n: docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\n: python\n: &lt;script above&gt;\n</code></pre>", "body_text": "Hi all, I'm having the same issue - did anybody find a workaround?\nIt takes a very long time on the first run but is very quick on subsequent runs. If I relaunch the container then it goes back to being very slow for one run. I get very similar output/behaviour if I run the same code using the Anaconda distribution of tensorflow.\nSystem information\n    Code:\nimport time\nstart_time = time.time()\nimport tensorflow as tf\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nprint(sess.run(c))\ntimer = time.time()\nprint(timer - start_time)\n\nOutput:\n\n~$ docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\nroot@7ee18dae8673:/notebooks# python\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \n[GCC 5.4.0 20160609] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import time\n>>> start_time = time.time()\n>>> import tensorflow as tf\n>>> a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n>>> b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n>>> c = tf.matmul(a, b)\n>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n2018-11-22 14:52:07.974293: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-22 14:52:08.052892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-22 14:52:08.053603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \nname: Quadro M1000M major: 5 minor: 0 memoryClockRate(GHz): 1.0715\npciBusID: 0000:01:00.0\ntotalMemory: 1.96GiB freeMemory: 1.70GiB\n2018-11-22 14:52:08.053621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n2018-11-22 14:56:17.618342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-22 14:56:17.618385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n2018-11-22 14:56:17.618395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n2018-11-22 14:56:17.618726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1447 MB memory) -> physical GPU (device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\n2018-11-22 14:56:17.619285: I tensorflow/core/common_runtime/direct_session.cc:307] Device mapping:\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\n\n>>> print(sess.run(c))\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620406: I tensorflow/core/common_runtime/placer.cc:927] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620431: I tensorflow/core/common_runtime/placer.cc:927] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n2018-11-22 14:56:17.620470: I tensorflow/core/common_runtime/placer.cc:927] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0\n[[22. 28.]\n [49. 64.]]\n>>> timer = time.time()\n>>> print(timer - start_time)\n250.8216381072998\n\n\n    OS Platform and Distribution:\ndocker on Ubuntu 16.04\n\n    TensorFlow installed from (source or binary):\n    binary / docker\n\n    TensorFlow version:\n    tensorflow-gpu 1.12\n\n    Python version:\n3.5\n\n    Bazel Version:\n    N/A\n\n    CUDA/cuDNN version:\n10.0\n\n    GPU model and memory:\n    NVIDIA Quadro M1000M with 2004MiB memory - 8GB system RAM\n\n    **Exact command to reproduce:**\n: docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\n: python\n: <script above>", "body": "Hi all, I'm having the same issue - did anybody find a workaround?\r\nIt takes a very long time on the first run but is very quick on subsequent runs. If I relaunch the container then it goes back to being very slow for one run. I get very similar output/behaviour if I run the same code using the Anaconda distribution of tensorflow.\r\n\r\nSystem information\r\n\r\n```\r\n    Code:\r\nimport time\r\nstart_time = time.time()\r\nimport tensorflow as tf\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\nprint(sess.run(c))\r\ntimer = time.time()\r\nprint(timer - start_time)\r\n\r\nOutput:\r\n\r\n~$ docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\r\nroot@7ee18dae8673:/notebooks# python\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import time\r\n>>> start_time = time.time()\r\n>>> import tensorflow as tf\r\n>>> a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n>>> b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n>>> c = tf.matmul(a, b)\r\n>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n2018-11-22 14:52:07.974293: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-11-22 14:52:08.052892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-11-22 14:52:08.053603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: Quadro M1000M major: 5 minor: 0 memoryClockRate(GHz): 1.0715\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.96GiB freeMemory: 1.70GiB\r\n2018-11-22 14:52:08.053621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-11-22 14:56:17.618342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-22 14:56:17.618385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-22 14:56:17.618395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-22 14:56:17.618726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1447 MB memory) -> physical GPU (device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n2018-11-22 14:56:17.619285: I tensorflow/core/common_runtime/direct_session.cc:307] Device mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n\r\n>>> print(sess.run(c))\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\r\n2018-11-22 14:56:17.620406: I tensorflow/core/common_runtime/placer.cc:927] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0\r\na: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\n2018-11-22 14:56:17.620431: I tensorflow/core/common_runtime/placer.cc:927] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0\r\nb: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\n2018-11-22 14:56:17.620470: I tensorflow/core/common_runtime/placer.cc:927] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0\r\n[[22. 28.]\r\n [49. 64.]]\r\n>>> timer = time.time()\r\n>>> print(timer - start_time)\r\n250.8216381072998\r\n\r\n\r\n    OS Platform and Distribution:\r\ndocker on Ubuntu 16.04\r\n\r\n    TensorFlow installed from (source or binary):\r\n    binary / docker\r\n\r\n    TensorFlow version:\r\n    tensorflow-gpu 1.12\r\n\r\n    Python version:\r\n3.5\r\n\r\n    Bazel Version:\r\n    N/A\r\n\r\n    CUDA/cuDNN version:\r\n10.0\r\n\r\n    GPU model and memory:\r\n    NVIDIA Quadro M1000M with 2004MiB memory - 8GB system RAM\r\n\r\n    **Exact command to reproduce:**\r\n: docker run --runtime=nvidia -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-py3 bash\r\n: python\r\n: <script above>\r\n```"}