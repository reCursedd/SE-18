{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/159148385", "html_url": "https://github.com/tensorflow/tensorflow/issues/212#issuecomment-159148385", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/212", "id": 159148385, "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTE0ODM4NQ==", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-24T04:46:03Z", "updated_at": "2015-11-24T04:46:03Z", "author_association": "MEMBER", "body_html": "<p>Hi cinjon,</p>\n<p>Sorry for the delay. I was thinking a bit about what you're doing and it took me a while to wrap my mind about it, but I think I can see why the first model loads ok but the second does not.</p>\n<p>Here is how I see it. Both model1 and model2 have a saver, right? Created like this:</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-c1\">self</span>.saver <span class=\"pl-k\">=</span> tf.train.Saver(tf.all_variables())</pre></div>\n<p>This is ok for the first model, as it saves only the variables belonging to it. But -- because of the use of tf.all_variables() -- the second model with save both itself and model1. Does that make sense?</p>\n<p>I see 2 ways to correct that. For one, you could filter the variables saved in model2 to start with the prefix you're giving it. Another, and I think better way, is to remove the saver from the 2 models entirely, and have it only once in your main loop - after you've created both models. Then you'll have only a single checkpoint file and you can still use tf.all_variables() without the risk of forgetting anything, and it should all work.</p>\n<p>Hope that helps!</p>\n<p>Lukasz</p>", "body_text": "Hi cinjon,\nSorry for the delay. I was thinking a bit about what you're doing and it took me a while to wrap my mind about it, but I think I can see why the first model loads ok but the second does not.\nHere is how I see it. Both model1 and model2 have a saver, right? Created like this:\n  self.saver = tf.train.Saver(tf.all_variables())\nThis is ok for the first model, as it saves only the variables belonging to it. But -- because of the use of tf.all_variables() -- the second model with save both itself and model1. Does that make sense?\nI see 2 ways to correct that. For one, you could filter the variables saved in model2 to start with the prefix you're giving it. Another, and I think better way, is to remove the saver from the 2 models entirely, and have it only once in your main loop - after you've created both models. Then you'll have only a single checkpoint file and you can still use tf.all_variables() without the risk of forgetting anything, and it should all work.\nHope that helps!\nLukasz", "body": "Hi cinjon,\n\nSorry for the delay. I was thinking a bit about what you're doing and it took me a while to wrap my mind about it, but I think I can see why the first model loads ok but the second does not.\n\nHere is how I see it. Both model1 and model2 have a saver, right? Created like this:\n\n``` python\n  self.saver = tf.train.Saver(tf.all_variables())\n```\n\nThis is ok for the first model, as it saves only the variables belonging to it. But -- because of the use of tf.all_variables() -- the second model with save both itself and model1. Does that make sense?\n\nI see 2 ways to correct that. For one, you could filter the variables saved in model2 to start with the prefix you're giving it. Another, and I think better way, is to remove the saver from the 2 models entirely, and have it only once in your main loop - after you've created both models. Then you'll have only a single checkpoint file and you can still use tf.all_variables() without the risk of forgetting anything, and it should all work.\n\nHope that helps!\n\nLukasz\n"}