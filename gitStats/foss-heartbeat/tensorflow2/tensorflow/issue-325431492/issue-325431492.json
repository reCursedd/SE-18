{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19475", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19475/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19475/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19475/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19475", "id": 325431492, "node_id": "MDU6SXNzdWUzMjU0MzE0OTI=", "number": 19475, "title": "transform_graph obfuscate_names error in Windows 10", "user": {"login": "ktsumura", "id": 21131880, "node_id": "MDQ6VXNlcjIxMTMxODgw", "avatar_url": "https://avatars0.githubusercontent.com/u/21131880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktsumura", "html_url": "https://github.com/ktsumura", "followers_url": "https://api.github.com/users/ktsumura/followers", "following_url": "https://api.github.com/users/ktsumura/following{/other_user}", "gists_url": "https://api.github.com/users/ktsumura/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktsumura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktsumura/subscriptions", "organizations_url": "https://api.github.com/users/ktsumura/orgs", "repos_url": "https://api.github.com/users/ktsumura/repos", "events_url": "https://api.github.com/users/ktsumura/events{/privacy}", "received_events_url": "https://api.github.com/users/ktsumura/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-22T19:27:24Z", "updated_at": "2018-08-02T17:25:35Z", "closed_at": "2018-08-02T17:25:35Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.7.1</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: Not used</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Visual Studio 2015 (MSBuild.exe)</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.1, cuDNN 7.0.5</li>\n<li><strong>GPU model and memory</strong>: NVIDIA GeForce GTX 1070</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<ol>\n<li>Open cmd</li>\n<li>Go to the directory where a saved model is stored.</li>\n<li>Run the following command<br>\nPATH\\TO\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph --in_graph=saved_model.pb --out_graph=saved_model_2.pb --inputs=\"image:0\" --outputs=\"probability:0\" --transforms=\"obfuscate_names\"</li>\n</ol>\n<h3>Describe the problem</h3>\n<p>I had the following error after running the command.</p>\n<p>[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:1: Invalid control characters encountered in text.<br>\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Interpreting non ascii codepoint 192.<br>\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Expected identifier, got: \u2514<br>\n2018-05-22 13:39:08.760764: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:200] Loading graph 'saved_model.pb' failed with Can't parse saved_model.pb as binary proto<br>\n(both text and binary parsing failed for file saved_model.pb)<br>\n2018-05-22 13:39:08.767541: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:202] usage: D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph<br>\nFlags:<br>\n--in_graph=\"\"                           string  input graph file name<br>\n--out_graph=\"\"                          string  output graph file name<br>\n--inputs=\"\"                             string  inputs<br>\n--outputs=\"\"                            string  outputs<br>\n--transforms=\"\"                         string  list of transforms<br>\n--output_as_text=false                  bool    whether to write the graph in text protobuf format</p>\n<p>Transforms are:<br>\nadd_default_attributes<br>\nbackport_concatv2<br>\nbackport_tensor_array_v3<br>\nflatten_atrous_conv<br>\nfold_batch_norms<br>\nfold_constants<br>\nfold_old_batch_norms<br>\nfreeze_requantization_ranges<br>\nfuse_pad_and_conv<br>\nfuse_resize_and_conv<br>\nfuse_resize_pad_and_conv<br>\ninsert_logging<br>\nmerge_duplicate_nodes<br>\nobfuscate_names<br>\nquantize_nodes<br>\nquantize_weights<br>\nremove_attribute<br>\nremove_control_dependencies<br>\nremove_device<br>\nremove_nodes<br>\nrename_attribute<br>\nrename_op<br>\nround_weights<br>\nset_device<br>\nsort_by_execution_order<br>\nsparsify_gather<br>\nstrip_unused_nodes</p>\n<h3>Source code / logs</h3>\n<p>I created a saved model using Estimator. The following shows how I create a saved model.</p>\n<pre><code>        # Get warm start settings\n        wss = self._get_warm_start_settings()\n\n        # Create a estimator w/ or w/o warm start\n        estimator = tf.estimator.Estimator(\n            model_fn=NetTrainer.model_fn,\n            model_dir=self.model_path,\n            params={\n                'net_id': str(self.net_id)\n            },\n            config=tf.estimator.RunConfig(\n                save_checkpoints_steps=training_config.CHECKPOINTS_STEPS,\n                save_summary_steps=training_config.SUMMARY_STEPS,\n                keep_checkpoint_max=training_config.KEEP_CHENCKPOINT_MAX\n            ),\n            warm_start_from=wss)\n\n        for lp in list(range(0, training_config.NUM_TRAINING_EVALUATION_CYCLES)):\n                              \n            # Train the model\n            estimator.train(\n                input_fn=lambda:self.train_input_fn(training_db_reader_state),\n                steps=training_config.TRAINING_STEPS,\n                max_steps=None)\n\n            # Evaluate the model\n            eval_result = estimator.evaluate(\n                input_fn=lambda:self.eval_input_fn(evaluation_db_reader_state))\n              \n            tf.logging.info('training-evaluation cycle: {:d}'.format(lp))\n            tf.logging.info('global_step: {global_step:d}'.format(**eval_result))\n            tf.logging.info('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))\n            \n        # Export the model\n        image_shape = self._get_image_shape(include_batch=True, batch_size=1);\n        feature_spec = {config.IMAGE_KEY: tf.placeholder(tf.float32, shape=image_shape, name=config.IMAGE_KEY)}\n        serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec, default_batch_size=1)\n\n        estimator.export_savedmodel(\n            export_dir_base=self.saved_model_path,\n            serving_input_receiver_fn=serving_input_receiver_fn,\n            strip_default_attrs=True)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): v1.7.1\nPython version: 3.6\nBazel version (if compiling from source): Not used\nGCC/Compiler version (if compiling from source): Visual Studio 2015 (MSBuild.exe)\nCUDA/cuDNN version: CUDA 9.1, cuDNN 7.0.5\nGPU model and memory: NVIDIA GeForce GTX 1070\nExact command to reproduce:\n\n\nOpen cmd\nGo to the directory where a saved model is stored.\nRun the following command\nPATH\\TO\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph --in_graph=saved_model.pb --out_graph=saved_model_2.pb --inputs=\"image:0\" --outputs=\"probability:0\" --transforms=\"obfuscate_names\"\n\nDescribe the problem\nI had the following error after running the command.\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:1: Invalid control characters encountered in text.\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Interpreting non ascii codepoint 192.\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Expected identifier, got: \u2514\n2018-05-22 13:39:08.760764: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:200] Loading graph 'saved_model.pb' failed with Can't parse saved_model.pb as binary proto\n(both text and binary parsing failed for file saved_model.pb)\n2018-05-22 13:39:08.767541: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:202] usage: D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph\nFlags:\n--in_graph=\"\"                           string  input graph file name\n--out_graph=\"\"                          string  output graph file name\n--inputs=\"\"                             string  inputs\n--outputs=\"\"                            string  outputs\n--transforms=\"\"                         string  list of transforms\n--output_as_text=false                  bool    whether to write the graph in text protobuf format\nTransforms are:\nadd_default_attributes\nbackport_concatv2\nbackport_tensor_array_v3\nflatten_atrous_conv\nfold_batch_norms\nfold_constants\nfold_old_batch_norms\nfreeze_requantization_ranges\nfuse_pad_and_conv\nfuse_resize_and_conv\nfuse_resize_pad_and_conv\ninsert_logging\nmerge_duplicate_nodes\nobfuscate_names\nquantize_nodes\nquantize_weights\nremove_attribute\nremove_control_dependencies\nremove_device\nremove_nodes\nrename_attribute\nrename_op\nround_weights\nset_device\nsort_by_execution_order\nsparsify_gather\nstrip_unused_nodes\nSource code / logs\nI created a saved model using Estimator. The following shows how I create a saved model.\n        # Get warm start settings\n        wss = self._get_warm_start_settings()\n\n        # Create a estimator w/ or w/o warm start\n        estimator = tf.estimator.Estimator(\n            model_fn=NetTrainer.model_fn,\n            model_dir=self.model_path,\n            params={\n                'net_id': str(self.net_id)\n            },\n            config=tf.estimator.RunConfig(\n                save_checkpoints_steps=training_config.CHECKPOINTS_STEPS,\n                save_summary_steps=training_config.SUMMARY_STEPS,\n                keep_checkpoint_max=training_config.KEEP_CHENCKPOINT_MAX\n            ),\n            warm_start_from=wss)\n\n        for lp in list(range(0, training_config.NUM_TRAINING_EVALUATION_CYCLES)):\n                              \n            # Train the model\n            estimator.train(\n                input_fn=lambda:self.train_input_fn(training_db_reader_state),\n                steps=training_config.TRAINING_STEPS,\n                max_steps=None)\n\n            # Evaluate the model\n            eval_result = estimator.evaluate(\n                input_fn=lambda:self.eval_input_fn(evaluation_db_reader_state))\n              \n            tf.logging.info('training-evaluation cycle: {:d}'.format(lp))\n            tf.logging.info('global_step: {global_step:d}'.format(**eval_result))\n            tf.logging.info('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))\n            \n        # Export the model\n        image_shape = self._get_image_shape(include_batch=True, batch_size=1);\n        feature_spec = {config.IMAGE_KEY: tf.placeholder(tf.float32, shape=image_shape, name=config.IMAGE_KEY)}\n        serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec, default_batch_size=1)\n\n        estimator.export_savedmodel(\n            export_dir_base=self.saved_model_path,\n            serving_input_receiver_fn=serving_input_receiver_fn,\n            strip_default_attrs=True)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: source \r\n- **TensorFlow version (use command below)**: v1.7.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: Not used\r\n- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015 (MSBuild.exe)\r\n- **CUDA/cuDNN version**: CUDA 9.1, cuDNN 7.0.5\r\n- **GPU model and memory**: NVIDIA GeForce GTX 1070\r\n- **Exact command to reproduce**:\r\n1. Open cmd\r\n2. Go to the directory where a saved model is stored.\r\n2. Run the following command\r\nPATH\\TO\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph --in_graph=saved_model.pb --out_graph=saved_model_2.pb --inputs=\"image:0\" --outputs=\"probability:0\" --transforms=\"obfuscate_names\"\r\n\r\n### Describe the problem\r\nI had the following error after running the command.\r\n\r\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:1: Invalid control characters encountered in text.\r\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Interpreting non ascii codepoint 192.\r\n[libprotobuf ERROR D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\protobuf\\src\\protobuf\\src\\google\\protobuf\\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Expected identifier, got: \u2514\r\n2018-05-22 13:39:08.760764: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:200] Loading graph 'saved_model.pb' failed with Can't parse saved_model.pb as binary proto\r\n         (both text and binary parsing failed for file saved_model.pb)\r\n2018-05-22 13:39:08.767541: E D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:202] usage: D:\\workspace_tensorflow_source\\tensorflow-1.7.1\\tensorflow\\contrib\\cmake\\build_cuda_v9.1\\Release\\transform_graph\r\nFlags:\r\n        --in_graph=\"\"                           string  input graph file name\r\n        --out_graph=\"\"                          string  output graph file name\r\n        --inputs=\"\"                             string  inputs\r\n        --outputs=\"\"                            string  outputs\r\n        --transforms=\"\"                         string  list of transforms\r\n        --output_as_text=false                  bool    whether to write the graph in text protobuf format\r\n\r\nTransforms are:\r\nadd_default_attributes\r\nbackport_concatv2\r\nbackport_tensor_array_v3\r\nflatten_atrous_conv\r\nfold_batch_norms\r\nfold_constants\r\nfold_old_batch_norms\r\nfreeze_requantization_ranges\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\ninsert_logging\r\nmerge_duplicate_nodes\r\nobfuscate_names\r\nquantize_nodes\r\nquantize_weights\r\nremove_attribute\r\nremove_control_dependencies\r\nremove_device\r\nremove_nodes\r\nrename_attribute\r\nrename_op\r\nround_weights\r\nset_device\r\nsort_by_execution_order\r\nsparsify_gather\r\nstrip_unused_nodes\r\n\r\n### Source code / logs\r\nI created a saved model using Estimator. The following shows how I create a saved model.\r\n\r\n            # Get warm start settings\r\n            wss = self._get_warm_start_settings()\r\n\r\n            # Create a estimator w/ or w/o warm start\r\n            estimator = tf.estimator.Estimator(\r\n                model_fn=NetTrainer.model_fn,\r\n                model_dir=self.model_path,\r\n                params={\r\n                    'net_id': str(self.net_id)\r\n                },\r\n                config=tf.estimator.RunConfig(\r\n                    save_checkpoints_steps=training_config.CHECKPOINTS_STEPS,\r\n                    save_summary_steps=training_config.SUMMARY_STEPS,\r\n                    keep_checkpoint_max=training_config.KEEP_CHENCKPOINT_MAX\r\n                ),\r\n                warm_start_from=wss)\r\n \r\n            for lp in list(range(0, training_config.NUM_TRAINING_EVALUATION_CYCLES)):\r\n                                  \r\n                # Train the model\r\n                estimator.train(\r\n                    input_fn=lambda:self.train_input_fn(training_db_reader_state),\r\n                    steps=training_config.TRAINING_STEPS,\r\n                    max_steps=None)\r\n  \r\n                # Evaluate the model\r\n                eval_result = estimator.evaluate(\r\n                    input_fn=lambda:self.eval_input_fn(evaluation_db_reader_state))\r\n                  \r\n                tf.logging.info('training-evaluation cycle: {:d}'.format(lp))\r\n                tf.logging.info('global_step: {global_step:d}'.format(**eval_result))\r\n                tf.logging.info('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))\r\n                \r\n            # Export the model\r\n            image_shape = self._get_image_shape(include_batch=True, batch_size=1);\r\n            feature_spec = {config.IMAGE_KEY: tf.placeholder(tf.float32, shape=image_shape, name=config.IMAGE_KEY)}\r\n            serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec, default_batch_size=1)\r\n\r\n            estimator.export_savedmodel(\r\n                export_dir_base=self.saved_model_path,\r\n                serving_input_receiver_fn=serving_input_receiver_fn,\r\n                strip_default_attrs=True)\r\n\r\n\r\n"}