{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/146119285", "pull_request_review_id": 71020950, "id": 146119285, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NjExOTI4NQ==", "diff_hunk": "@@ -75,34 +67,86 @@ class BincountOp : public OpKernel {\n           for (int64 i = start_ind; i < limit_ind; i++) {\n             int32 value = arr(i);\n             if (value < size) {\n-              if (has_weights) {\n-                partial_bins(worker_id, value) += weights(i);\n-              } else {\n-                // Complex numbers don't support \"++\".\n-                partial_bins(worker_id, value) += T(1);\n-              }\n+              // Complex numbers don't support \"++\".\n+              partial_bins(worker_id, value) += T(1);\n             }\n           }\n         });\n-    TensorShape output_shape({size});\n-    Tensor* output_t;\n-    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output_t));\n+\n     // Sum the partial bins along the 0th axis.\n     Eigen::array<int, 1> reduce_dims({0});\n-    output_t->flat<T>().device(ctx->eigen_cpu_device()) =\n-        partial_bins.sum(reduce_dims);\n+    output.device(context->eigen_cpu_device()) = partial_bins.sum(reduce_dims);\n+    return Status::OK();\n   }\n };\n \n-#define REGISTER(TYPE)                                               \\\n+}  // namespace functor\n+\n+template <typename Device, typename T>\n+class BincountOp : public OpKernel {\n+ public:\n+  explicit BincountOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}\n+\n+  void Compute(OpKernelContext* ctx) override {\n+    const Tensor& arr_t = ctx->input(0);\n+    const Tensor& size_tensor = ctx->input(1);\n+    const Tensor& weights_t = ctx->input(2);\n+\n+    int32 size = size_tensor.scalar<int32>()();\n+    OP_REQUIRES(ctx, size >= 0, errors::InvalidArgument(\n+                                    \"size (\", size, \") must be non-negative\"));\n+\n+    const bool has_weights = weights_t.NumElements() > 0;\n+    OP_REQUIRES(ctx, !(has_weights && arr_t.shape() != weights_t.shape()),\n+                errors::InvalidArgument(\n+                    \"If weights are passed, they must have the same shape (\" +\n+                    weights_t.shape().DebugString() + \") as arr (\" +\n+                    arr_t.shape().DebugString() + \")\"));\n+    const auto arr = arr_t.flat<int32>();\n+    const auto weights = weights_t.flat<T>();\n+\n+    if (weights.size() == 0) {\n+      Tensor* output_t;\n+      OP_REQUIRES_OK(ctx,\n+                     ctx->allocate_output(0, TensorShape({size}), &output_t));\n+      auto output = output_t->flat<T>();\n+      OP_REQUIRES_OK(\n+          ctx, functor::BincountFunctor<Device, T>::Compute(ctx, arr, output));\n+    } else {\n+      TensorShape output_shape;\n+      output_shape.AddDim(size);\n+\n+      Tensor* output = nullptr;\n+      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output));\n+      auto output_flat = output->flat_outer_dims<T>();\n+\n+      functor::UnsortedSegmentSumFunctor<Device, T, int32>()(\n+          ctx, ctx->template eigen_device<Device>(), size, arr_t.shape(), arr,\n+          weights.size(), weights.data(), output_flat);\n+    }\n+  }\n+};\n+\n+#define REGISTER_KERNELS(type)                                       \\\n   REGISTER_KERNEL_BUILDER(                                           \\\n-      Name(\"Bincount\").Device(DEVICE_CPU).TypeConstraint<TYPE>(\"T\"), \\\n-      BincountOp<TYPE>)\n+      Name(\"Bincount\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n+      BincountOp<CPUDevice, type>)\n+\n+TF_CALL_NUMBER_TYPES(REGISTER_KERNELS);\n+#undef REGISTER_KERNELS\n+\n+#if GOOGLE_CUDA\n+\n+#define REGISTER_KERNELS(type)                            \\\n+  REGISTER_KERNEL_BUILDER(Name(\"Bincount\")                \\\n+                              .Device(DEVICE_GPU)         \\\n+                              .HostMemory(\"size\")         \\\n+                              .TypeConstraint<type>(\"T\"), \\\n+                          BincountOp<GPUDevice, type>)\n \n-TF_CALL_NUMBER_TYPES(REGISTER);\n+TF_CALL_float(REGISTER_KERNELS);", "path": "tensorflow/core/kernels/bincount_op.cc", "position": null, "original_position": 175, "commit_id": "95ec3de3c5b4baeed1d6db825f48289f7a4d1bbf", "original_commit_id": "a1efcaaf6d1a783170eae7387e19957667e24145", "user": {"login": "yongtang", "id": 6932348, "node_id": "MDQ6VXNlcjY5MzIzNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6932348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongtang", "html_url": "https://github.com/yongtang", "followers_url": "https://api.github.com/users/yongtang/followers", "following_url": "https://api.github.com/users/yongtang/following{/other_user}", "gists_url": "https://api.github.com/users/yongtang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongtang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongtang/subscriptions", "organizations_url": "https://api.github.com/users/yongtang/orgs", "repos_url": "https://api.github.com/users/yongtang/repos", "events_url": "https://api.github.com/users/yongtang/events{/privacy}", "received_events_url": "https://api.github.com/users/yongtang/received_events", "type": "User", "site_admin": false}, "body": "Thanks. Done. Though on my dev machine it seems only int32 and float works. Might be because `sm = 20`? I added int32 to the list. Don't know if additional registration works with a different dev machine or not.", "created_at": "2017-10-22T01:05:12Z", "updated_at": "2017-11-05T16:19:59Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13813#discussion_r146119285", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13813", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/146119285"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13813#discussion_r146119285"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13813"}}, "body_html": "<p>Thanks. Done. Though on my dev machine it seems only int32 and float works. Might be because <code>sm = 20</code>? I added int32 to the list. Don't know if additional registration works with a different dev machine or not.</p>", "body_text": "Thanks. Done. Though on my dev machine it seems only int32 and float works. Might be because sm = 20? I added int32 to the list. Don't know if additional registration works with a different dev machine or not.", "in_reply_to_id": 146070787}