{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22130", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22130/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22130/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22130/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22130", "id": 357879979, "node_id": "MDU6SXNzdWUzNTc4Nzk5Nzk=", "number": 22130, "title": "HLO serialization insufficiently validated on deserialization (e.g. for xrt)", "user": {"login": "Keno", "id": 1291671, "node_id": "MDQ6VXNlcjEyOTE2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1291671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keno", "html_url": "https://github.com/Keno", "followers_url": "https://api.github.com/users/Keno/followers", "following_url": "https://api.github.com/users/Keno/following{/other_user}", "gists_url": "https://api.github.com/users/Keno/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keno/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keno/subscriptions", "organizations_url": "https://api.github.com/users/Keno/orgs", "repos_url": "https://api.github.com/users/Keno/repos", "events_url": "https://api.github.com/users/Keno/events{/privacy}", "received_events_url": "https://api.github.com/users/Keno/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, {"login": "denisvnukov", "id": 2170371, "node_id": "MDQ6VXNlcjIxNzAzNzE=", "avatar_url": "https://avatars0.githubusercontent.com/u/2170371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/denisvnukov", "html_url": "https://github.com/denisvnukov", "followers_url": "https://api.github.com/users/denisvnukov/followers", "following_url": "https://api.github.com/users/denisvnukov/following{/other_user}", "gists_url": "https://api.github.com/users/denisvnukov/gists{/gist_id}", "starred_url": "https://api.github.com/users/denisvnukov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/denisvnukov/subscriptions", "organizations_url": "https://api.github.com/users/denisvnukov/orgs", "repos_url": "https://api.github.com/users/denisvnukov/repos", "events_url": "https://api.github.com/users/denisvnukov/events{/privacy}", "received_events_url": "https://api.github.com/users/denisvnukov/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-09-07T00:47:04Z", "updated_at": "2018-11-13T01:31:39Z", "closed_at": "2018-10-17T21:51:04Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 17.10</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/bc7c47ccddbf351d17b0d2d61cde3d48e2d530d6/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/bc7c47ccddbf351d17b0d2d61cde3d48e2d530d6\"><tt>bc7c47c</tt></a></li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 7.2.0</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: See below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The new xrt ops expose serialized HLO Snapshots as an interface over the distributed TF interface. Some validation of the serialization is performed and returned as an error to the TF client. However, other format errors lead to assertions instead, killing the TF server and requiring a restart. It would be desirable to instead validate the HLO more thoroughly and return any errors to the client.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5376757\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/michaelisard\">@michaelisard</a></p>\n<h3>Source code / logs</h3>\n<p>I have four minimal example HLO modules that trigger assertions that I encountered when using xrt. Though I encountered them using <code>xrt</code>, I'll be using <code>//tensorflow/compiler/xla/tools:replay_computation_cpu</code> for easy reproducability in these examples. For each of these examples, I'll show the textual hlo (if dump_computation_to_text was able to process the pb), the .pbtext of the HloSnapshot, and the output of <code>replay_computation_cpu</code>. To reproduce,</p>\n<pre><code>cd tensorflow\nprotoc --encode=xla.HloSnapshot -I=$PWD $PWD/tensorflow/compiler/xrt/xrt.proto &lt; x.pbtext &gt; x.pb\n./bazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu x.pb\n</code></pre>\n<p>where x.pbtext is the textual pb from this issue.</p>\n<h4>Add operation with missing parameters:</h4>\n<pre><code>HloModule test\n\nENTRY comp {\n  ROOT op = f64[] add()\n}\n</code></pre>\n<pre><code>hlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"op\"\n        opcode: \"add\"\n        shape {\n          element_type: F64\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n      }\n      root_id: 2\n    }\n    program_shape {\n      result {\n        element_type: F64\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<pre><code>bazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu ~/XLAHacks.jl/op_missing_args.pb\n2018-09-06 20:18:45.853017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:18:45.854635: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x556b26f45230 executing computations on platform Host. Devices:\n2018-09-06 20:18:45.854662: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2018-09-06 20:18:45.854726: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:18:45.855744: F tensorflow/compiler/xla/service/hlo_instruction.cc:1931] Check failed: 2 == operand_count() (2 vs. 0)\nAborted\n</code></pre>\n<h4>Parameter reference when function has no parameters</h4>\n<pre><code>HloModule test\n\nENTRY comp {\n  ROOT op = f64[] parameter(0)\n}\n</code></pre>\n<pre><code>hlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"op\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n      }\n      root_id: 2\n    }\n    program_shape {\n      result {\n        element_type: F64\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<pre><code>2018-09-06 20:20:29.529757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:20:29.531397: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x562efc8c8230 executing computations on platform Host. Devices:\n2018-09-06 20:20:29.531425: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2018-09-06 20:20:29.531492: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\nSegmentation fault\n</code></pre>\n<h4>Parameter reference out of bounds</h4>\n<p>Basically an add of parameters 1, 2 for a one parameter function (i.e. I had an off by one in my parameter numbers):</p>\n<pre><code>hlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"parameter0\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        parameter_number: 1\n      }\n      instructions {\n        name: \"parameter1\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        parameter_number: 2\n        id: 1\n      }\n      instructions {\n        name: \"add2\"\n        opcode: \"add\"\n        shape {\n          element_type: F32\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n        operand_ids: 0\n        operand_ids: 1\n      }\n      root_id: 2\n    }\n    program_shape {\n      parameters {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n      parameters {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n      result {\n        element_type: F32\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<pre><code>2018-09-06 20:25:29.866942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:25:29.868569: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x560a8b2b7230 executing computations on platform Host. Devices:\n2018-09-06 20:25:29.868598: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2018-09-06 20:25:29.868667: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:25:29.869118: F tensorflow/compiler/xla/service/hlo_computation.cc:78] Check failed: param_no &gt;= 0 &amp;&amp; param_no &lt; parameter_count\nERROR: invalid parameter number.  Expected [0, 2), got 2\nAborted\n</code></pre>\n<h4>Missing dot dimension numbers</h4>\n<pre><code>HloModule test\n\nENTRY comp {\n  parameter0 = f64[2,2]{0,1} parameter(0)\n  parameter1 = f64[2,2]{0,1} parameter(1)\n  ROOT dot2 = f64[1]{0} dot(parameter0, parameter1)\n}\n</code></pre>\n<pre><code>hlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"parameter0\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 2\n          dimensions: 2\n          layout {\n            minor_to_major: 0\n            minor_to_major: 1\n            format: DENSE\n          }\n        }\n      }\n      instructions {\n        name: \"parameter1\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 2\n          dimensions: 2\n          layout {\n            minor_to_major: 0\n            minor_to_major: 1\n            format: DENSE\n          }\n        }\n        parameter_number: 1\n        id: 1\n      }\n      instructions {\n        name: \"dot2\"\n        opcode: \"dot\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        id: 2\n        operand_ids: 0\n        operand_ids: 1\n      }\n      root_id: 2\n    }\n    program_shape {\n      parameters {\n        element_type: F64\n        dimensions: 2\n        dimensions: 2\n        layout {\n          minor_to_major: 0\n          minor_to_major: 1\n          format: DENSE\n        }\n      }\n      parameters {\n        element_type: F64\n        dimensions: 2\n        dimensions: 2\n        layout {\n          minor_to_major: 0\n          minor_to_major: 1\n          format: DENSE\n        }\n      }\n      result {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<pre><code>2018-09-06 20:30:04.934720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:30:04.936398: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x55fd5deeb230 executing computations on platform Host. Devices:\n2018-09-06 20:30:04.936426: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;\n2018-09-06 20:30:04.936502: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:30:04.937560: F ./tensorflow/compiler/xla/service/hlo_instruction.h:1105] Check failed: dot_dimension_numbers_ != nullptr\nAborted\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): bc7c47c\nPython version: N/A\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): 7.2.0\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: See below\n\nDescribe the problem\nThe new xrt ops expose serialized HLO Snapshots as an interface over the distributed TF interface. Some validation of the serialization is performed and returned as an error to the TF client. However, other format errors lead to assertions instead, killing the TF server and requiring a restart. It would be desirable to instead validate the HLO more thoroughly and return any errors to the client.\ncc @michaelisard\nSource code / logs\nI have four minimal example HLO modules that trigger assertions that I encountered when using xrt. Though I encountered them using xrt, I'll be using //tensorflow/compiler/xla/tools:replay_computation_cpu for easy reproducability in these examples. For each of these examples, I'll show the textual hlo (if dump_computation_to_text was able to process the pb), the .pbtext of the HloSnapshot, and the output of replay_computation_cpu. To reproduce,\ncd tensorflow\nprotoc --encode=xla.HloSnapshot -I=$PWD $PWD/tensorflow/compiler/xrt/xrt.proto < x.pbtext > x.pb\n./bazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu x.pb\n\nwhere x.pbtext is the textual pb from this issue.\nAdd operation with missing parameters:\nHloModule test\n\nENTRY comp {\n  ROOT op = f64[] add()\n}\n\nhlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"op\"\n        opcode: \"add\"\n        shape {\n          element_type: F64\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n      }\n      root_id: 2\n    }\n    program_shape {\n      result {\n        element_type: F64\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n\nbazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu ~/XLAHacks.jl/op_missing_args.pb\n2018-09-06 20:18:45.853017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:18:45.854635: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x556b26f45230 executing computations on platform Host. Devices:\n2018-09-06 20:18:45.854662: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\n2018-09-06 20:18:45.854726: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:18:45.855744: F tensorflow/compiler/xla/service/hlo_instruction.cc:1931] Check failed: 2 == operand_count() (2 vs. 0)\nAborted\n\nParameter reference when function has no parameters\nHloModule test\n\nENTRY comp {\n  ROOT op = f64[] parameter(0)\n}\n\nhlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"op\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n      }\n      root_id: 2\n    }\n    program_shape {\n      result {\n        element_type: F64\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n\n2018-09-06 20:20:29.529757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:20:29.531397: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x562efc8c8230 executing computations on platform Host. Devices:\n2018-09-06 20:20:29.531425: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\n2018-09-06 20:20:29.531492: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\nSegmentation fault\n\nParameter reference out of bounds\nBasically an add of parameters 1, 2 for a one parameter function (i.e. I had an off by one in my parameter numbers):\nhlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"parameter0\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        parameter_number: 1\n      }\n      instructions {\n        name: \"parameter1\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        parameter_number: 2\n        id: 1\n      }\n      instructions {\n        name: \"add2\"\n        opcode: \"add\"\n        shape {\n          element_type: F32\n          layout {\n            format: DENSE\n          }\n        }\n        id: 2\n        operand_ids: 0\n        operand_ids: 1\n      }\n      root_id: 2\n    }\n    program_shape {\n      parameters {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n      parameters {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n      result {\n        element_type: F32\n        layout {\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n\n2018-09-06 20:25:29.866942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:25:29.868569: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x560a8b2b7230 executing computations on platform Host. Devices:\n2018-09-06 20:25:29.868598: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\n2018-09-06 20:25:29.868667: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:25:29.869118: F tensorflow/compiler/xla/service/hlo_computation.cc:78] Check failed: param_no >= 0 && param_no < parameter_count\nERROR: invalid parameter number.  Expected [0, 2), got 2\nAborted\n\nMissing dot dimension numbers\nHloModule test\n\nENTRY comp {\n  parameter0 = f64[2,2]{0,1} parameter(0)\n  parameter1 = f64[2,2]{0,1} parameter(1)\n  ROOT dot2 = f64[1]{0} dot(parameter0, parameter1)\n}\n\nhlo {\n  hlo_module {\n    name: \"test\"\n    entry_computation_name: \"op\"\n    computations {\n      name: \"comp\"\n      instructions {\n        name: \"parameter0\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 2\n          dimensions: 2\n          layout {\n            minor_to_major: 0\n            minor_to_major: 1\n            format: DENSE\n          }\n        }\n      }\n      instructions {\n        name: \"parameter1\"\n        opcode: \"parameter\"\n        shape {\n          element_type: F64\n          dimensions: 2\n          dimensions: 2\n          layout {\n            minor_to_major: 0\n            minor_to_major: 1\n            format: DENSE\n          }\n        }\n        parameter_number: 1\n        id: 1\n      }\n      instructions {\n        name: \"dot2\"\n        opcode: \"dot\"\n        shape {\n          element_type: F64\n          dimensions: 1\n          layout {\n            minor_to_major: 0\n            format: DENSE\n          }\n        }\n        id: 2\n        operand_ids: 0\n        operand_ids: 1\n      }\n      root_id: 2\n    }\n    program_shape {\n      parameters {\n        element_type: F64\n        dimensions: 2\n        dimensions: 2\n        layout {\n          minor_to_major: 0\n          minor_to_major: 1\n          format: DENSE\n        }\n      }\n      parameters {\n        element_type: F64\n        dimensions: 2\n        dimensions: 2\n        layout {\n          minor_to_major: 0\n          minor_to_major: 1\n          format: DENSE\n        }\n      }\n      result {\n        element_type: F64\n        dimensions: 1\n        layout {\n          minor_to_major: 0\n          format: DENSE\n        }\n      }\n    }\n  }\n}\n\n2018-09-06 20:30:04.934720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n2018-09-06 20:30:04.936398: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x55fd5deeb230 executing computations on platform Host. Devices:\n2018-09-06 20:30:04.936426: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\n2018-09-06 20:30:04.936502: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\n2018-09-06 20:30:04.937560: F ./tensorflow/compiler/xla/service/hlo_instruction.h:1105] Check failed: dot_dimension_numbers_ != nullptr\nAborted", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: bc7c47ccddbf351d17b0d2d61cde3d48e2d530d6\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below \r\n\r\n### Describe the problem\r\nThe new xrt ops expose serialized HLO Snapshots as an interface over the distributed TF interface. Some validation of the serialization is performed and returned as an error to the TF client. However, other format errors lead to assertions instead, killing the TF server and requiring a restart. It would be desirable to instead validate the HLO more thoroughly and return any errors to the client.\r\n\r\ncc @michaelisard \r\n\r\n### Source code / logs\r\nI have four minimal example HLO modules that trigger assertions that I encountered when using xrt. Though I encountered them using `xrt`, I'll be using `//tensorflow/compiler/xla/tools:replay_computation_cpu` for easy reproducability in these examples. For each of these examples, I'll show the textual hlo (if dump_computation_to_text was able to process the pb), the .pbtext of the HloSnapshot, and the output of `replay_computation_cpu`. To reproduce,\r\n\r\n```\r\ncd tensorflow\r\nprotoc --encode=xla.HloSnapshot -I=$PWD $PWD/tensorflow/compiler/xrt/xrt.proto < x.pbtext > x.pb\r\n./bazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu x.pb\r\n```\r\n\r\nwhere x.pbtext is the textual pb from this issue.\r\n\r\n#### Add operation with missing parameters:\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  ROOT op = f64[] add()\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"op\"\r\n        opcode: \"add\"\r\n        shape {\r\n          element_type: F64\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      result {\r\n        element_type: F64\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\nbazel-bin/tensorflow/compiler/xla/tools/replay_computation_cpu ~/XLAHacks.jl/op_missing_args.pb\r\n2018-09-06 20:18:45.853017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:18:45.854635: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x556b26f45230 executing computations on platform Host. Devices:\r\n2018-09-06 20:18:45.854662: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:18:45.854726: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:18:45.855744: F tensorflow/compiler/xla/service/hlo_instruction.cc:1931] Check failed: 2 == operand_count() (2 vs. 0)\r\nAborted\r\n```\r\n\r\n#### Parameter reference when function has no parameters\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  ROOT op = f64[] parameter(0)\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"op\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      result {\r\n        element_type: F64\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:20:29.529757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:20:29.531397: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x562efc8c8230 executing computations on platform Host. Devices:\r\n2018-09-06 20:20:29.531425: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:20:29.531492: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\nSegmentation fault\r\n```\r\n\r\n#### Parameter reference out of bounds\r\nBasically an add of parameters 1, 2 for a one parameter function (i.e. I had an off by one in my parameter numbers):\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"parameter0\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 1\r\n      }\r\n      instructions {\r\n        name: \"parameter1\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 2\r\n        id: 1\r\n      }\r\n      instructions {\r\n        name: \"add2\"\r\n        opcode: \"add\"\r\n        shape {\r\n          element_type: F32\r\n          layout {\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n        operand_ids: 0\r\n        operand_ids: 1\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n      result {\r\n        element_type: F32\r\n        layout {\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:25:29.866942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:25:29.868569: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x560a8b2b7230 executing computations on platform Host. Devices:\r\n2018-09-06 20:25:29.868598: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:25:29.868667: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:25:29.869118: F tensorflow/compiler/xla/service/hlo_computation.cc:78] Check failed: param_no >= 0 && param_no < parameter_count\r\nERROR: invalid parameter number.  Expected [0, 2), got 2\r\nAborted\r\n```\r\n\r\n#### Missing dot dimension numbers\r\n```\r\nHloModule test\r\n\r\nENTRY comp {\r\n  parameter0 = f64[2,2]{0,1} parameter(0)\r\n  parameter1 = f64[2,2]{0,1} parameter(1)\r\n  ROOT dot2 = f64[1]{0} dot(parameter0, parameter1)\r\n}\r\n```\r\n\r\n```\r\nhlo {\r\n  hlo_module {\r\n    name: \"test\"\r\n    entry_computation_name: \"op\"\r\n    computations {\r\n      name: \"comp\"\r\n      instructions {\r\n        name: \"parameter0\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 2\r\n          dimensions: 2\r\n          layout {\r\n            minor_to_major: 0\r\n            minor_to_major: 1\r\n            format: DENSE\r\n          }\r\n        }\r\n      }\r\n      instructions {\r\n        name: \"parameter1\"\r\n        opcode: \"parameter\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 2\r\n          dimensions: 2\r\n          layout {\r\n            minor_to_major: 0\r\n            minor_to_major: 1\r\n            format: DENSE\r\n          }\r\n        }\r\n        parameter_number: 1\r\n        id: 1\r\n      }\r\n      instructions {\r\n        name: \"dot2\"\r\n        opcode: \"dot\"\r\n        shape {\r\n          element_type: F64\r\n          dimensions: 1\r\n          layout {\r\n            minor_to_major: 0\r\n            format: DENSE\r\n          }\r\n        }\r\n        id: 2\r\n        operand_ids: 0\r\n        operand_ids: 1\r\n      }\r\n      root_id: 2\r\n    }\r\n    program_shape {\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 2\r\n        dimensions: 2\r\n        layout {\r\n          minor_to_major: 0\r\n          minor_to_major: 1\r\n          format: DENSE\r\n        }\r\n      }\r\n      parameters {\r\n        element_type: F64\r\n        dimensions: 2\r\n        dimensions: 2\r\n        layout {\r\n          minor_to_major: 0\r\n          minor_to_major: 1\r\n          format: DENSE\r\n        }\r\n      }\r\n      result {\r\n        element_type: F64\r\n        dimensions: 1\r\n        layout {\r\n          minor_to_major: 0\r\n          format: DENSE\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\n2018-09-06 20:30:04.934720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2018-09-06 20:30:04.936398: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x55fd5deeb230 executing computations on platform Host. Devices:\r\n2018-09-06 20:30:04.936426: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-09-06 20:30:04.936502: I tensorflow/compiler/xla/tools/replay_computation.cc:272] Compiling 1 modules in parallel.\r\n2018-09-06 20:30:04.937560: F ./tensorflow/compiler/xla/service/hlo_instruction.h:1105] Check failed: dot_dimension_numbers_ != nullptr\r\nAborted\r\n```"}