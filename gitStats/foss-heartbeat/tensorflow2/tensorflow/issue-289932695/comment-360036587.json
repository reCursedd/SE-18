{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360036587", "html_url": "https://github.com/tensorflow/tensorflow/issues/16239#issuecomment-360036587", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16239", "id": 360036587, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDAzNjU4Nw==", "user": {"login": "ghostplant", "id": 12099308, "node_id": "MDQ6VXNlcjEyMDk5MzA4", "avatar_url": "https://avatars2.githubusercontent.com/u/12099308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghostplant", "html_url": "https://github.com/ghostplant", "followers_url": "https://api.github.com/users/ghostplant/followers", "following_url": "https://api.github.com/users/ghostplant/following{/other_user}", "gists_url": "https://api.github.com/users/ghostplant/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghostplant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghostplant/subscriptions", "organizations_url": "https://api.github.com/users/ghostplant/orgs", "repos_url": "https://api.github.com/users/ghostplant/repos", "events_url": "https://api.github.com/users/ghostplant/events{/privacy}", "received_events_url": "https://api.github.com/users/ghostplant/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-24T06:46:02Z", "updated_at": "2018-01-24T06:46:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a></p>\n<p>On linux, we can just replace its underlay symbol link of cuMemAlloc_v2, which doesn't require to recompile Tensorflow project, but it is just for temporary experiment.</p>\n<p>File <code>main.c</code></p>\n<div class=\"highlight highlight-source-shell\"><pre>/<span class=\"pl-k\">*</span>\nCompiling and Run Example:\n\n1) gcc main.c -o replace.so -I/usr/local/cuda/include -L/usr/local/cuda/lib -shared -fPIC -lcudart -lcuda -ldl\n\n2) LD_PRELOAD=<span class=\"pl-s\"><span class=\"pl-pds\">`</span>pwd<span class=\"pl-pds\">`</span></span>/replace.so python3 mnist_cnn.py   <span class=\"pl-c\"><span class=\"pl-c\">#</span> to run keras examples with replaced API</span>\n\n3) nvidia-smi <span class=\"pl-k\">|</span> grep -i def   <span class=\"pl-c\"><span class=\"pl-c\">#</span> to see memory cost</span>\n<span class=\"pl-k\">*</span>/\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>include &lt;stdio.h&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>include &lt;assert.h&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>include &lt;cuda.h&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>include &lt;cuda_runtime.h&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>include &lt;dlfcn.h&gt;</span>\n\nCUresult cuMemAlloc_v2(CUdeviceptr <span class=\"pl-k\">*</span>dptr, size_t bytes){\n  printf(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuMemAlloc_v2 =&gt; bytes = %zd\\n<span class=\"pl-pds\">\"</span></span>, bytes)<span class=\"pl-k\">;</span>\n  static void <span class=\"pl-k\">*</span>hd = NULL<span class=\"pl-k\">;</span>\n  <span class=\"pl-k\">if</span> (<span class=\"pl-k\">!</span>hd)\n    assert<span class=\"pl-s\"><span class=\"pl-pds\">((</span>hd <span class=\"pl-k\">=</span> dlopen(\"<span class=\"pl-k\">/</span>usr<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>cuda<span class=\"pl-k\">/</span>lib<span class=\"pl-c1\">64</span><span class=\"pl-k\">/</span>libcudart.so.<span class=\"pl-c1\">8</span>.<span class=\"pl-c1\">0</span>\"<span class=\"pl-k\">,</span> RTLD_LAZY<span class=\"pl-pds\">))</span></span> <span class=\"pl-k\">!</span>= NULL)<span class=\"pl-k\">;</span>\n  <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">((</span>int(<span class=\"pl-k\">*</span>)(void<span class=\"pl-k\">**,</span> size_t<span class=\"pl-k\">,</span> int<span class=\"pl-pds\">))</span></span>dlsym(hd, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cudaMallocManaged<span class=\"pl-pds\">\"</span></span>))<span class=\"pl-s\"><span class=\"pl-pds\">((</span>void<span class=\"pl-k\">**</span>)dptr<span class=\"pl-k\">,</span> bytes<span class=\"pl-k\">,</span> cudaMemAttachGlobal);</span>\n<span class=\"pl-s\">}</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">CUresult cuMemFree_v<span class=\"pl-c1\">2</span>(CUdeviceptr dptr) {</span>\n<span class=\"pl-s\">  assert(<span class=\"pl-c1\">0</span>);</span>\n<span class=\"pl-s\">  return CUDA_SUCCESS;</span>\n<span class=\"pl-s\">}</span></pre></div>", "body_text": "@zheng-xq\nOn linux, we can just replace its underlay symbol link of cuMemAlloc_v2, which doesn't require to recompile Tensorflow project, but it is just for temporary experiment.\nFile main.c\n/*\nCompiling and Run Example:\n\n1) gcc main.c -o replace.so -I/usr/local/cuda/include -L/usr/local/cuda/lib -shared -fPIC -lcudart -lcuda -ldl\n\n2) LD_PRELOAD=`pwd`/replace.so python3 mnist_cnn.py   # to run keras examples with replaced API\n\n3) nvidia-smi | grep -i def   # to see memory cost\n*/\n\n#include <stdio.h>\n#include <assert.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <dlfcn.h>\n\nCUresult cuMemAlloc_v2(CUdeviceptr *dptr, size_t bytes){\n  printf(\"cuMemAlloc_v2 => bytes = %zd\\n\", bytes);\n  static void *hd = NULL;\n  if (!hd)\n    assert((hd = dlopen(\"/usr/local/cuda/lib64/libcudart.so.8.0\", RTLD_LAZY)) != NULL);\n  return ((int(*)(void**, size_t, int))dlsym(hd, \"cudaMallocManaged\"))((void**)dptr, bytes, cudaMemAttachGlobal);\n}\n\nCUresult cuMemFree_v2(CUdeviceptr dptr) {\n  assert(0);\n  return CUDA_SUCCESS;\n}", "body": "@zheng-xq \r\n\r\nOn linux, we can just replace its underlay symbol link of cuMemAlloc_v2, which doesn't require to recompile Tensorflow project, but it is just for temporary experiment.\r\n\r\n\r\nFile `main.c`\r\n```sh\r\n/*\r\nCompiling and Run Example:\r\n\r\n1) gcc main.c -o replace.so -I/usr/local/cuda/include -L/usr/local/cuda/lib -shared -fPIC -lcudart -lcuda -ldl\r\n\r\n2) LD_PRELOAD=`pwd`/replace.so python3 mnist_cnn.py   # to run keras examples with replaced API\r\n\r\n3) nvidia-smi | grep -i def   # to see memory cost\r\n*/\r\n\r\n#include <stdio.h>\r\n#include <assert.h>\r\n#include <cuda.h>\r\n#include <cuda_runtime.h>\r\n#include <dlfcn.h>\r\n\r\nCUresult cuMemAlloc_v2(CUdeviceptr *dptr, size_t bytes){\r\n  printf(\"cuMemAlloc_v2 => bytes = %zd\\n\", bytes);\r\n  static void *hd = NULL;\r\n  if (!hd)\r\n    assert((hd = dlopen(\"/usr/local/cuda/lib64/libcudart.so.8.0\", RTLD_LAZY)) != NULL);\r\n  return ((int(*)(void**, size_t, int))dlsym(hd, \"cudaMallocManaged\"))((void**)dptr, bytes, cudaMemAttachGlobal);\r\n}\r\n\r\nCUresult cuMemFree_v2(CUdeviceptr dptr) {\r\n  assert(0);\r\n  return CUDA_SUCCESS;\r\n}\r\n```"}