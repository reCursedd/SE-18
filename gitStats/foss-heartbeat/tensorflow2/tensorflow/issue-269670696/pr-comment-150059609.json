{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/150059609", "pull_request_review_id": 75554030, "id": 150059609, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDA1OTYwOQ==", "diff_hunk": "@@ -0,0 +1,190 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/reader_base.h\"\n+#include \"tensorflow/core/framework/reader_op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/strings/numbers.h\"\n+#include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/lib/strings/strcat.h\"\n+\n+#include \"src-cpp/rdkafkacpp.h\"\n+\n+namespace tensorflow {\n+\n+class KafkaReader : public ReaderBase {\n+ public:\n+  KafkaReader(const string& servers, const string& group, const bool eof,\n+              const string& name)\n+      : ReaderBase(strings::StrCat(\"KafkaReader '\", name, \"'\")),\n+        servers_(servers),\n+        group_(group),\n+        eof_(eof) {}\n+\n+  Status OnWorkStartedLocked() override {\n+    std::vector<string> parts = str_util::Split(current_work(), \":\");\n+    if (parts.size() < 1) {\n+      return errors::InvalidArgument(\"Invalid parameters: \", current_work());\n+    }\n+    string topic = parts[0];\n+    int32 partition = 0;\n+    if (parts.size() > 1) {\n+      if (!strings::safe_strto32(parts[1], &partition)) {\n+        return errors::InvalidArgument(\"Invalid parameters: \", current_work());\n+      }\n+    }\n+    int64 offset = 0;\n+    if (parts.size() > 2) {\n+      if (!strings::safe_strto64(parts[2], &offset)) {\n+        return errors::InvalidArgument(\"Invalid parameters: \", current_work());\n+      }\n+    }\n+\n+    topic_partition_.reset(\n+        RdKafka::TopicPartition::create(topic, partition, offset));\n+\n+    offset_ = topic_partition_->offset();\n+    limit_ = -1;\n+    if (parts.size() > 3) {\n+      if (!strings::safe_strto64(parts[3], &limit_)) {\n+        return errors::InvalidArgument(\"Invalid parameters: \", current_work());\n+      }\n+    }\n+\n+    std::unique_ptr<RdKafka::Conf> conf(\n+        RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL));\n+    std::unique_ptr<RdKafka::Conf> topic_conf(\n+        RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC));\n+\n+    std::string errstr;\n+\n+    RdKafka::Conf::ConfResult result =\n+        conf->set(\"default_topic_conf\", topic_conf.get(), errstr);\n+    if (result != RdKafka::Conf::CONF_OK) {\n+      return errors::Internal(\"Failed to set default_topic_conf:\", errstr);\n+    }\n+\n+    result = conf->set(\"bootstrap.servers\", servers_, errstr);\n+    if (result != RdKafka::Conf::CONF_OK) {\n+      return errors::Internal(\"Failed to set bootstrap.servers \", servers_, \":\",\n+                              errstr);\n+    }\n+    result = conf->set(\"group.id\", group_, errstr);\n+    if (result != RdKafka::Conf::CONF_OK) {\n+      return errors::Internal(\"Failed to set group.id \", group_, \":\", errstr);\n+    }\n+\n+    consumer_.reset(RdKafka::KafkaConsumer::create(conf.get(), errstr));\n+    if (!consumer_.get()) {\n+      return errors::Internal(\"Failed to create consumer:\", errstr);\n+    }\n+\n+    std::vector<RdKafka::TopicPartition*> partitions;\n+    partitions.emplace_back(topic_partition_.get());\n+    RdKafka::ErrorCode err = consumer_->assign(partitions);\n+    if (err != RdKafka::ERR_NO_ERROR) {\n+      return errors::Internal(\n+          \"Failed to assign partition [\", topic_partition_->topic(), \", \",\n+          topic_partition_->partition(), \", \", topic_partition_->offset(), \"]:\",\n+          RdKafka::err2str(err));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Status OnWorkFinishedLocked() override {\n+    consumer_->unassign();\n+    consumer_->close();\n+    consumer_.reset(nullptr);\n+    return Status::OK();\n+  }\n+\n+  Status ReadLocked(string* key, string* value, bool* produced,\n+                    bool* at_end) override {\n+    if (limit_ >= 0 &&\n+        (topic_partition_->offset() >= limit_ || offset_ >= limit_)) {\n+      *at_end = true;\n+      return Status::OK();\n+    }\n+    while (true) {\n+      std::unique_ptr<RdKafka::Message> message(consumer_->consume(1000));", "path": "tensorflow/contrib/kafka/kernels/kafka_reader_ops.cc", "position": null, "original_position": 127, "commit_id": "5825de14a1c9bc89ab48c19860d4e048e2cceb78", "original_commit_id": "081489e7f623d70dc2a62e5d97d6118586156465", "user": {"login": "terrytangyuan", "id": 4269898, "node_id": "MDQ6VXNlcjQyNjk4OTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/4269898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terrytangyuan", "html_url": "https://github.com/terrytangyuan", "followers_url": "https://api.github.com/users/terrytangyuan/followers", "following_url": "https://api.github.com/users/terrytangyuan/following{/other_user}", "gists_url": "https://api.github.com/users/terrytangyuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/terrytangyuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terrytangyuan/subscriptions", "organizations_url": "https://api.github.com/users/terrytangyuan/orgs", "repos_url": "https://api.github.com/users/terrytangyuan/repos", "events_url": "https://api.github.com/users/terrytangyuan/events{/privacy}", "received_events_url": "https://api.github.com/users/terrytangyuan/received_events", "type": "User", "site_admin": false}, "body": "Not too familiar with `rdkafkacpp` but any reasons behind this hard-coded 1000? Is this a standard practice?", "created_at": "2017-11-09T19:15:26Z", "updated_at": "2018-01-26T03:22:40Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14098#discussion_r150059609", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14098", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/150059609"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14098#discussion_r150059609"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14098"}}, "body_html": "<p>Not too familiar with <code>rdkafkacpp</code> but any reasons behind this hard-coded 1000? Is this a standard practice?</p>", "body_text": "Not too familiar with rdkafkacpp but any reasons behind this hard-coded 1000? Is this a standard practice?"}