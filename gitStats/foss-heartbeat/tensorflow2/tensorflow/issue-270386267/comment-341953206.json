{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341953206", "html_url": "https://github.com/tensorflow/tensorflow/issues/14158#issuecomment-341953206", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14158", "id": 341953206, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTk1MzIwNg==", "user": {"login": "eli99999", "id": 13930252, "node_id": "MDQ6VXNlcjEzOTMwMjUy", "avatar_url": "https://avatars3.githubusercontent.com/u/13930252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eli99999", "html_url": "https://github.com/eli99999", "followers_url": "https://api.github.com/users/eli99999/followers", "following_url": "https://api.github.com/users/eli99999/following{/other_user}", "gists_url": "https://api.github.com/users/eli99999/gists{/gist_id}", "starred_url": "https://api.github.com/users/eli99999/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eli99999/subscriptions", "organizations_url": "https://api.github.com/users/eli99999/orgs", "repos_url": "https://api.github.com/users/eli99999/repos", "events_url": "https://api.github.com/users/eli99999/events{/privacy}", "received_events_url": "https://api.github.com/users/eli99999/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-05T06:57:55Z", "updated_at": "2017-11-05T06:57:55Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4453739\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bobeo\">@bobeo</a> thanks,<br>\nI looked into it, and it seems that there is  a problem with the bazel compilation<br>\ni changed the models a few time and then did the ops_to_register.h process,<br>\neach time the ops_to_register.h file changed but the libtensorflow_inference.so  does not.<br>\nI tried all sort of bazel clean and bazel dump, and not chaned the resulted  libtensorflow_inference.so<br>\nso i think that either there is some issue with the bazel caching or that the  bug is in the print_selective_registration_header process</p>\n<p>i'm working on ubuntu 16.04<br>\nbazel 0.7.0<br>\ntf 1.4</p>", "body_text": "@bobeo thanks,\nI looked into it, and it seems that there is  a problem with the bazel compilation\ni changed the models a few time and then did the ops_to_register.h process,\neach time the ops_to_register.h file changed but the libtensorflow_inference.so  does not.\nI tried all sort of bazel clean and bazel dump, and not chaned the resulted  libtensorflow_inference.so\nso i think that either there is some issue with the bazel caching or that the  bug is in the print_selective_registration_header process\ni'm working on ubuntu 16.04\nbazel 0.7.0\ntf 1.4", "body": "@bobeo thanks,\r\nI looked into it, and it seems that there is  a problem with the bazel compilation\r\ni changed the models a few time and then did the ops_to_register.h process, \r\neach time the ops_to_register.h file changed but the libtensorflow_inference.so  does not.\r\nI tried all sort of bazel clean and bazel dump, and not chaned the resulted  libtensorflow_inference.so\r\nso i think that either there is some issue with the bazel caching or that the  bug is in the print_selective_registration_header process\r\n\r\ni'm working on ubuntu 16.04\r\nbazel 0.7.0\r\ntf 1.4\r\n\r\n"}