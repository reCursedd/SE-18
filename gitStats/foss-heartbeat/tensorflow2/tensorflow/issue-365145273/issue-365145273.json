{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22618", "id": 365145273, "node_id": "MDU6SXNzdWUzNjUxNDUyNzM=", "number": 22618, "title": "cannot make learning rate as variable when using keras model to estimator", "user": {"login": "vbvg2008", "id": 27377212, "node_id": "MDQ6VXNlcjI3Mzc3MjEy", "avatar_url": "https://avatars3.githubusercontent.com/u/27377212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vbvg2008", "html_url": "https://github.com/vbvg2008", "followers_url": "https://api.github.com/users/vbvg2008/followers", "following_url": "https://api.github.com/users/vbvg2008/following{/other_user}", "gists_url": "https://api.github.com/users/vbvg2008/gists{/gist_id}", "starred_url": "https://api.github.com/users/vbvg2008/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vbvg2008/subscriptions", "organizations_url": "https://api.github.com/users/vbvg2008/orgs", "repos_url": "https://api.github.com/users/vbvg2008/repos", "events_url": "https://api.github.com/users/vbvg2008/events{/privacy}", "received_events_url": "https://api.github.com/users/vbvg2008/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-09-29T16:15:23Z", "updated_at": "2018-11-02T01:07:57Z", "closed_at": "2018-11-02T01:07:57Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip install</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.11.0-cpu-py3</li>\n<li><strong>Python version</strong>:3.6.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>: run the code provided below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I was trying to make learning rate a variable and control it using hook during training, however, it gives me the following error &lt;Tensor(\"Variable/read:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"dense/kernel:0\", shape=(), dtype=resource).&gt;</p>\n<p>PS: when I define the estimator through the generic \"model_fn\" instead of keras, variable learning rate can work.  Therefore, I believe the issue comes from tf.keras.estimator.model_to_estimator</p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(x_in, x_out)\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): pip install\nTensorFlow version (use command below): 1.11.0-cpu-py3\nPython version:3.6.5\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce: run the code provided below\n\nDescribe the problem\nI was trying to make learning rate a variable and control it using hook during training, however, it gives me the following error <Tensor(\"Variable/read:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"dense/kernel:0\", shape=(), dtype=resource).>\nPS: when I define the estimator through the generic \"model_fn\" instead of keras, variable learning rate can work.  Therefore, I believe the issue comes from tf.keras.estimator.model_to_estimator\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(x_in, x_out)\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\n    optimizer = tf.train.GradientDescentOptimizer(lr)\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: pip install\r\n- **TensorFlow version (use command below)**: 1.11.0-cpu-py3\r\n- **Python version**:3.6.5\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA \r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: run the code provided below \r\n\r\n### Describe the problem\r\nI was trying to make learning rate a variable and control it using hook during training, however, it gives me the following error <Tensor(\"Variable/read:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"dense/kernel:0\", shape=(), dtype=resource).>\r\n\r\nPS: when I define the estimator through the generic \"model_fn\" instead of keras, variable learning rate can work.  Therefore, I believe the issue comes from tf.keras.estimator.model_to_estimator\r\n\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef estimator_fn():\r\n    x_in = tf.keras.layers.Input(shape=[10])\r\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\r\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    model = tf.keras.models.Model(x_in, x_out)\r\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\r\n    optimizer = tf.train.GradientDescentOptimizer(lr)\r\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\r\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\r\n    return estimator\r\n\r\ndef input_fn():\r\n    np.random.seed(100)\r\n    x = np.random.random((1024, 10))\r\n    y = np.random.randint(2, size=(1024, 1))\r\n    x = tf.cast(x, tf.float32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(1024)\r\n    return dataset\r\n  \r\nmodel_estimator = estimator_fn()\r\nmodel_estimator.train(input_fn=input_fn, steps=1000)\r\n```"}