{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/426778971", "html_url": "https://github.com/tensorflow/tensorflow/issues/22618#issuecomment-426778971", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618", "id": 426778971, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNjc3ODk3MQ==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-03T19:58:23Z", "updated_at": "2018-10-03T19:58:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=27377212\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vbvg2008\">@vbvg2008</a> You can make learning rate a variable, try using <code>keras.optimizers</code> instead. Just modified your code as below and executed it without running into error.</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom keras import optimizers\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(x_in, x_out)\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\n    optimizer = keras.optimizers.SGD(lr, momentum=0.0, decay=0.0, nesterov=False)\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)\n</code></pre>", "body_text": "@vbvg2008 You can make learning rate a variable, try using keras.optimizers instead. Just modified your code as below and executed it without running into error.\nimport tensorflow as tf\nimport numpy as np\nfrom keras import optimizers\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(x_in, x_out)\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\n    optimizer = keras.optimizers.SGD(lr, momentum=0.0, decay=0.0, nesterov=False)\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)", "body": "@vbvg2008 You can make learning rate a variable, try using `keras.optimizers` instead. Just modified your code as below and executed it without running into error.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom keras import optimizers\r\n\r\ndef estimator_fn():\r\n    x_in = tf.keras.layers.Input(shape=[10])\r\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\r\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    model = tf.keras.models.Model(x_in, x_out)\r\n    lr = tf.Variable(0.1, trainable=False, dtype=tf.float32)\r\n    optimizer = keras.optimizers.SGD(lr, momentum=0.0, decay=0.0, nesterov=False)\r\n    model.compile(loss='binary_crossentropy', optimizer= optimizer)\r\n    estimator = tf.keras.estimator.model_to_estimator(keras_model = model)\r\n    return estimator\r\n\r\ndef input_fn():\r\n    np.random.seed(100)\r\n    x = np.random.random((1024, 10))\r\n    y = np.random.randint(2, size=(1024, 1))\r\n    x = tf.cast(x, tf.float32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(1024)\r\n    return dataset\r\n  \r\nmodel_estimator = estimator_fn()\r\nmodel_estimator.train(input_fn=input_fn, steps=1000)\r\n```"}