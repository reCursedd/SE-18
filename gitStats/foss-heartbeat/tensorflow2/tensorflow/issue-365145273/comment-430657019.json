{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/430657019", "html_url": "https://github.com/tensorflow/tensorflow/issues/22618#issuecomment-430657019", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22618", "id": 430657019, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDY1NzAxOQ==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T14:43:29Z", "updated_at": "2018-10-20T05:00:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=27377212\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vbvg2008\">@vbvg2008</a> For multi-gpu training you can add the following to the code:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.keras.utils import multi_gpu_model\nimport numpy as np\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    with tf.device('/cpu:0'):\n        model = tf.keras.models.Model(x_in, x_out)\n    num_gpu = 2\n    parallel_model = multi_gpu_model(model, gpus=num_gpu)\n    \n    lr = tf.Variable(0.1, trainable=True, dtype=tf.float32)\n    optimizer = tf.keras.optimizers.SGD(0.01, momentum=0.0, decay=0.0, nesterov=False)\n    parallel_model.model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model =  parallel_model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)\n</code></pre>", "body_text": "@vbvg2008 For multi-gpu training you can add the following to the code:\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.keras.utils import multi_gpu_model\nimport numpy as np\n\ndef estimator_fn():\n    x_in = tf.keras.layers.Input(shape=[10])\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    with tf.device('/cpu:0'):\n        model = tf.keras.models.Model(x_in, x_out)\n    num_gpu = 2\n    parallel_model = multi_gpu_model(model, gpus=num_gpu)\n    \n    lr = tf.Variable(0.1, trainable=True, dtype=tf.float32)\n    optimizer = tf.keras.optimizers.SGD(0.01, momentum=0.0, decay=0.0, nesterov=False)\n    parallel_model.model.compile(loss='binary_crossentropy', optimizer= optimizer)\n    estimator = tf.keras.estimator.model_to_estimator(keras_model =  parallel_model)\n    return estimator\n\ndef input_fn():\n    np.random.seed(100)\n    x = np.random.random((1024, 10))\n    y = np.random.randint(2, size=(1024, 1))\n    x = tf.cast(x, tf.float32)\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.repeat()\n    dataset = dataset.batch(1024)\n    return dataset\n  \nmodel_estimator = estimator_fn()\nmodel_estimator.train(input_fn=input_fn, steps=1000)", "body": "@vbvg2008 For multi-gpu training you can add the following to the code:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.keras.utils import multi_gpu_model\r\nimport numpy as np\r\n\r\ndef estimator_fn():\r\n    x_in = tf.keras.layers.Input(shape=[10])\r\n    x = tf.keras.layers.Dense(16, activation='relu')(x_in)\r\n    x_out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    with tf.device('/cpu:0'):\r\n        model = tf.keras.models.Model(x_in, x_out)\r\n    num_gpu = 2\r\n    parallel_model = multi_gpu_model(model, gpus=num_gpu)\r\n    \r\n    lr = tf.Variable(0.1, trainable=True, dtype=tf.float32)\r\n    optimizer = tf.keras.optimizers.SGD(0.01, momentum=0.0, decay=0.0, nesterov=False)\r\n    parallel_model.model.compile(loss='binary_crossentropy', optimizer= optimizer)\r\n    estimator = tf.keras.estimator.model_to_estimator(keras_model =  parallel_model)\r\n    return estimator\r\n\r\ndef input_fn():\r\n    np.random.seed(100)\r\n    x = np.random.random((1024, 10))\r\n    y = np.random.randint(2, size=(1024, 1))\r\n    x = tf.cast(x, tf.float32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(1024)\r\n    return dataset\r\n  \r\nmodel_estimator = estimator_fn()\r\nmodel_estimator.train(input_fn=input_fn, steps=1000)\r\n```"}