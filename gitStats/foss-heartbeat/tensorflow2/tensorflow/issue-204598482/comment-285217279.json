{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285217279", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-285217279", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 285217279, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTIxNzI3OQ==", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-09T00:39:40Z", "updated_at": "2017-03-09T00:40:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> Also even if you can just treat the dimensions of the filter weight matrix as opaque during training, inference may happen on another device, etc that isn't GPU based so the weights must be converted somewhere.</p>\n<p>The <a href=\"https://www.tensorflow.org/extend/tool_developers/#weight_formats\" rel=\"nofollow\">docs for TF</a> state:</p>\n<blockquote>\n<p>The ordering of convolution weight values is often tricky to deal with when converting between different frameworks. In TensorFlow, the filter weights for the Conv2D operation are stored on the second input, and are expected to be in the order [filter_height, filter_width, input_depth, output_depth], where filter_count increasing by one means moving to an adjacent value in memory.</p>\n</blockquote>\n<p>that being said, pending answers to the perf question, I am thinking of opening a feature request to add a <code>weight_format</code> along the lines of <code>data_format</code> to Conv2D. This will allow various kernel implementers to store weights more efficiently (and mark them as such for down the road conversions).</p>\n<p>In addition to cuDNN, BNNS (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"161807205\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3001\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3001/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3001\">#3001</a>) also uses that same format.</p>", "body_text": "@yaroslavvb Also even if you can just treat the dimensions of the filter weight matrix as opaque during training, inference may happen on another device, etc that isn't GPU based so the weights must be converted somewhere.\nThe docs for TF state:\n\nThe ordering of convolution weight values is often tricky to deal with when converting between different frameworks. In TensorFlow, the filter weights for the Conv2D operation are stored on the second input, and are expected to be in the order [filter_height, filter_width, input_depth, output_depth], where filter_count increasing by one means moving to an adjacent value in memory.\n\nthat being said, pending answers to the perf question, I am thinking of opening a feature request to add a weight_format along the lines of data_format to Conv2D. This will allow various kernel implementers to store weights more efficiently (and mark them as such for down the road conversions).\nIn addition to cuDNN, BNNS (#3001) also uses that same format.", "body": "@yaroslavvb Also even if you can just treat the dimensions of the filter weight matrix as opaque during training, inference may happen on another device, etc that isn't GPU based so the weights must be converted somewhere. \r\n\r\nThe [docs for TF](https://www.tensorflow.org/extend/tool_developers/#weight_formats) state: \r\n>The ordering of convolution weight values is often tricky to deal with when converting between different frameworks. In TensorFlow, the filter weights for the Conv2D operation are stored on the second input, and are expected to be in the order [filter_height, filter_width, input_depth, output_depth], where filter_count increasing by one means moving to an adjacent value in memory.\r\n\r\nthat being said, pending answers to the perf question, I am thinking of opening a feature request to add a `weight_format` along the lines of `data_format` to Conv2D. This will allow various kernel implementers to store weights more efficiently (and mark them as such for down the road conversions).\r\n\r\nIn addition to cuDNN, BNNS (https://github.com/tensorflow/tensorflow/issues/3001) also uses that same format."}