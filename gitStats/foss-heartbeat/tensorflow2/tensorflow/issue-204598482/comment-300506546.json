{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300506546", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-300506546", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 300506546, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDUwNjU0Ng==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-10T14:49:35Z", "updated_at": "2017-05-10T14:49:35Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3028543\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Randl\">@Randl</a>   I have not tested it but if they wrapped this in a with device CPU I suspect it would make a huge difference based on helping a few people recently.</p>\n<p>images, labels = cifar10_input.inputs(False, FLAGS.data_dir, FLAGS.batch_size)</p>\n<p>It would make a big difference in all of the tests that used CIFAR that did not place the input pipeline on the CPU.  The AlexNet numbers on the benchmarks we published looked good.  Wrapping the input pipeline in the with device CPU has resulted in huge (as in 4x+) performance increases for people.  And on the positive side if you use Estimators it does this for you by default.  You give it the input function and it makes sure it is placed on the CPU.  Since they just modified the CIFAR example, which did not wrap the input pipeline in the CPU (our bad for sure), I am pretty confident of the performance boost.  On another issue someone doubted the boost and was shocked they got I think 4x or more increase in images per second.</p>", "body_text": "@Randl   I have not tested it but if they wrapped this in a with device CPU I suspect it would make a huge difference based on helping a few people recently.\nimages, labels = cifar10_input.inputs(False, FLAGS.data_dir, FLAGS.batch_size)\nIt would make a big difference in all of the tests that used CIFAR that did not place the input pipeline on the CPU.  The AlexNet numbers on the benchmarks we published looked good.  Wrapping the input pipeline in the with device CPU has resulted in huge (as in 4x+) performance increases for people.  And on the positive side if you use Estimators it does this for you by default.  You give it the input function and it makes sure it is placed on the CPU.  Since they just modified the CIFAR example, which did not wrap the input pipeline in the CPU (our bad for sure), I am pretty confident of the performance boost.  On another issue someone doubted the boost and was shocked they got I think 4x or more increase in images per second.", "body": "@Randl   I have not tested it but if they wrapped this in a with device CPU I suspect it would make a huge difference based on helping a few people recently.  \r\n\r\nimages, labels = cifar10_input.inputs(False, FLAGS.data_dir, FLAGS.batch_size)\r\n\r\nIt would make a big difference in all of the tests that used CIFAR that did not place the input pipeline on the CPU.  The AlexNet numbers on the benchmarks we published looked good.  Wrapping the input pipeline in the with device CPU has resulted in huge (as in 4x+) performance increases for people.  And on the positive side if you use Estimators it does this for you by default.  You give it the input function and it makes sure it is placed on the CPU.  Since they just modified the CIFAR example, which did not wrap the input pipeline in the CPU (our bad for sure), I am pretty confident of the performance boost.  On another issue someone doubted the boost and was shocked they got I think 4x or more increase in images per second.  \r\n"}