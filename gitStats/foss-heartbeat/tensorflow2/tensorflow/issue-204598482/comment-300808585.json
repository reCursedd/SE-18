{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300808585", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-300808585", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 300808585, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDgwODU4NQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-11T14:34:44Z", "updated_at": "2017-05-11T14:34:44Z", "author_association": "MEMBER", "body_html": "<p>ResNet (I assume 50) was not a dramatic as I saw ~170ms and then after adding the with CPU and the WINOGRAD NONFUSED flag I was getting 150ms or so.  Again I have no idea if everyone is using the same ResNet.  When NVIDIA does these tests they check the FLOPS used to make sure they are similar between the platforms.  Making sure the models are exact seems painful.  Again my goal is that people doing research and work are following best practices and getting decent performance.  I bet there are a couple (not much more than that) more tweaks I can make to the code and I am pretty novice.</p>\n<div class=\"highlight highlight-source-shell\"><pre>toby@tfbelwar:<span class=\"pl-k\">~</span>/hongkong_bench/dlbench/tools/tensorflow/cnn/resnet_tf_10$ TF_ENABLE_WINOGRAD_NONFUSED=1 python resnet_cifar10.py --data_dir=/home/toby/CIFAR-10/cifar-10-batches-bin\n2017-05-11 07:26:26.859794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node <span class=\"pl-c1\">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-05-11 07:26:26.860125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:907] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.835\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 7.26GiB\n2017-05-11 07:26:26.860140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:928] DMA: 0 \n2017-05-11 07:26:26.860144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] 0:   Y \n2017-05-11 07:26:26.860155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:997] Creating TensorFlow device (/gpu:0) -<span class=\"pl-k\">&gt;</span> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nmin_queue_examples:  20000\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Images: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>shuffle_batch:0<span class=\"pl-pds\">'</span></span> shape=(128, 32, 32, 3) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale1/block9/Relu:0<span class=\"pl-pds\">'</span></span> shape=(128, 32, 32, 16) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale2/block1/B/batchnorm/add_1:0<span class=\"pl-pds\">'</span></span> shape=(128, 16, 16, 32) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>stride: <span class=\"pl-pds\">'</span></span>, 2)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale2/block1/shortcut/avg_pool:0<span class=\"pl-pds\">'</span></span> shape=(128, 16, 16, 16) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale2/block1/shortcut/Pad:0<span class=\"pl-pds\">'</span></span> shape=(128, 16, 16, 32) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale2/block9/Relu:0<span class=\"pl-pds\">'</span></span> shape=(128, 16, 16, 32) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale3/block1/B/batchnorm/add_1:0<span class=\"pl-pds\">'</span></span> shape=(128, 8, 8, 64) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>stride: <span class=\"pl-pds\">'</span></span>, 2)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale3/block1/shortcut/avg_pool:0<span class=\"pl-pds\">'</span></span> shape=(128, 8, 8, 32) dtype=float<span class=\"pl-k\">32&gt;</span>)\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>shortcut: <span class=\"pl-pds\">'</span></span>, <span class=\"pl-k\">&lt;</span>tf.Tensor <span class=\"pl-s\"><span class=\"pl-pds\">'</span>scale3/block1/shortcut/Pad:0<span class=\"pl-pds\">'</span></span> shape=(128, 8, 8, 64) dtype=float<span class=\"pl-k\">32&gt;</span>)\n2017-05-11 07:26:42.052644: step 0, loss = 4.66 (51.4 examples/sec<span class=\"pl-k\">;</span> 2.490 sec/batch)\n2017-05-11 07:26:56.862701: step 100, loss = 1.65 (855.0 examples/sec<span class=\"pl-k\">;</span> 0.150 sec/batch)\n2017-05-11 07:27:11.718538: step 200, loss = 1.40 (853.8 examples/sec<span class=\"pl-k\">;</span> 0.150 sec/batch)\n2017-05-11 07:27:26.637125: step 300, loss = 1.51 (883.9 examples/sec<span class=\"pl-k\">;</span> 0.145 sec/batch)\n2017-05-11 07:27:41.486478: step 400, loss = 1.34 (879.2 examples/sec<span class=\"pl-k\">;</span> 0.146 sec/batch)\n</pre></div>\n<p>I was not CPU maxed but there might be a small gain with a better CPU.  My GTX 1080 might also be clocked higher, I did not read their settings.  I also use my GTX as my main display but I doubt that matters in this case.</p>", "body_text": "ResNet (I assume 50) was not a dramatic as I saw ~170ms and then after adding the with CPU and the WINOGRAD NONFUSED flag I was getting 150ms or so.  Again I have no idea if everyone is using the same ResNet.  When NVIDIA does these tests they check the FLOPS used to make sure they are similar between the platforms.  Making sure the models are exact seems painful.  Again my goal is that people doing research and work are following best practices and getting decent performance.  I bet there are a couple (not much more than that) more tweaks I can make to the code and I am pretty novice.\ntoby@tfbelwar:~/hongkong_bench/dlbench/tools/tensorflow/cnn/resnet_tf_10$ TF_ENABLE_WINOGRAD_NONFUSED=1 python resnet_cifar10.py --data_dir=/home/toby/CIFAR-10/cifar-10-batches-bin\n2017-05-11 07:26:26.859794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-05-11 07:26:26.860125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:907] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.835\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 7.26GiB\n2017-05-11 07:26:26.860140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:928] DMA: 0 \n2017-05-11 07:26:26.860144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] 0:   Y \n2017-05-11 07:26:26.860155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:997] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\nmin_queue_examples:  20000\n('Images: ', <tf.Tensor 'shuffle_batch:0' shape=(128, 32, 32, 3) dtype=float32>)\n('shortcut: ', <tf.Tensor 'scale1/block9/Relu:0' shape=(128, 32, 32, 16) dtype=float32>)\n('x: ', <tf.Tensor 'scale2/block1/B/batchnorm/add_1:0' shape=(128, 16, 16, 32) dtype=float32>)\n('stride: ', 2)\n('shortcut: ', <tf.Tensor 'scale2/block1/shortcut/avg_pool:0' shape=(128, 16, 16, 16) dtype=float32>)\n('shortcut: ', <tf.Tensor 'scale2/block1/shortcut/Pad:0' shape=(128, 16, 16, 32) dtype=float32>)\n('shortcut: ', <tf.Tensor 'scale2/block9/Relu:0' shape=(128, 16, 16, 32) dtype=float32>)\n('x: ', <tf.Tensor 'scale3/block1/B/batchnorm/add_1:0' shape=(128, 8, 8, 64) dtype=float32>)\n('stride: ', 2)\n('shortcut: ', <tf.Tensor 'scale3/block1/shortcut/avg_pool:0' shape=(128, 8, 8, 32) dtype=float32>)\n('shortcut: ', <tf.Tensor 'scale3/block1/shortcut/Pad:0' shape=(128, 8, 8, 64) dtype=float32>)\n2017-05-11 07:26:42.052644: step 0, loss = 4.66 (51.4 examples/sec; 2.490 sec/batch)\n2017-05-11 07:26:56.862701: step 100, loss = 1.65 (855.0 examples/sec; 0.150 sec/batch)\n2017-05-11 07:27:11.718538: step 200, loss = 1.40 (853.8 examples/sec; 0.150 sec/batch)\n2017-05-11 07:27:26.637125: step 300, loss = 1.51 (883.9 examples/sec; 0.145 sec/batch)\n2017-05-11 07:27:41.486478: step 400, loss = 1.34 (879.2 examples/sec; 0.146 sec/batch)\n\nI was not CPU maxed but there might be a small gain with a better CPU.  My GTX 1080 might also be clocked higher, I did not read their settings.  I also use my GTX as my main display but I doubt that matters in this case.", "body": "ResNet (I assume 50) was not a dramatic as I saw ~170ms and then after adding the with CPU and the WINOGRAD NONFUSED flag I was getting 150ms or so.  Again I have no idea if everyone is using the same ResNet.  When NVIDIA does these tests they check the FLOPS used to make sure they are similar between the platforms.  Making sure the models are exact seems painful.  Again my goal is that people doing research and work are following best practices and getting decent performance.  I bet there are a couple (not much more than that) more tweaks I can make to the code and I am pretty novice.  \r\n\r\n```bash\r\ntoby@tfbelwar:~/hongkong_bench/dlbench/tools/tensorflow/cnn/resnet_tf_10$ TF_ENABLE_WINOGRAD_NONFUSED=1 python resnet_cifar10.py --data_dir=/home/toby/CIFAR-10/cifar-10-batches-bin\r\n2017-05-11 07:26:26.859794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-05-11 07:26:26.860125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:907] Found device 0 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.835\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.91GiB\r\nFree memory: 7.26GiB\r\n2017-05-11 07:26:26.860140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:928] DMA: 0 \r\n2017-05-11 07:26:26.860144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:938] 0:   Y \r\n2017-05-11 07:26:26.860155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:997] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\r\nmin_queue_examples:  20000\r\n('Images: ', <tf.Tensor 'shuffle_batch:0' shape=(128, 32, 32, 3) dtype=float32>)\r\n('shortcut: ', <tf.Tensor 'scale1/block9/Relu:0' shape=(128, 32, 32, 16) dtype=float32>)\r\n('x: ', <tf.Tensor 'scale2/block1/B/batchnorm/add_1:0' shape=(128, 16, 16, 32) dtype=float32>)\r\n('stride: ', 2)\r\n('shortcut: ', <tf.Tensor 'scale2/block1/shortcut/avg_pool:0' shape=(128, 16, 16, 16) dtype=float32>)\r\n('shortcut: ', <tf.Tensor 'scale2/block1/shortcut/Pad:0' shape=(128, 16, 16, 32) dtype=float32>)\r\n('shortcut: ', <tf.Tensor 'scale2/block9/Relu:0' shape=(128, 16, 16, 32) dtype=float32>)\r\n('x: ', <tf.Tensor 'scale3/block1/B/batchnorm/add_1:0' shape=(128, 8, 8, 64) dtype=float32>)\r\n('stride: ', 2)\r\n('shortcut: ', <tf.Tensor 'scale3/block1/shortcut/avg_pool:0' shape=(128, 8, 8, 32) dtype=float32>)\r\n('shortcut: ', <tf.Tensor 'scale3/block1/shortcut/Pad:0' shape=(128, 8, 8, 64) dtype=float32>)\r\n2017-05-11 07:26:42.052644: step 0, loss = 4.66 (51.4 examples/sec; 2.490 sec/batch)\r\n2017-05-11 07:26:56.862701: step 100, loss = 1.65 (855.0 examples/sec; 0.150 sec/batch)\r\n2017-05-11 07:27:11.718538: step 200, loss = 1.40 (853.8 examples/sec; 0.150 sec/batch)\r\n2017-05-11 07:27:26.637125: step 300, loss = 1.51 (883.9 examples/sec; 0.145 sec/batch)\r\n2017-05-11 07:27:41.486478: step 400, loss = 1.34 (879.2 examples/sec; 0.146 sec/batch)\r\n\r\n```\r\nI was not CPU maxed but there might be a small gain with a better CPU.  My GTX 1080 might also be clocked higher, I did not read their settings.  I also use my GTX as my main display but I doubt that matters in this case.  \r\n\r\n\r\n"}