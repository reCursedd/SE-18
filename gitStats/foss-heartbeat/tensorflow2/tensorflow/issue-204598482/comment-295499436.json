{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/295499436", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-295499436", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 295499436, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NTQ5OTQzNg==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-19T23:54:12Z", "updated_at": "2017-04-19T23:54:12Z", "author_association": "MEMBER", "body_html": "<p>Benchmark results (TensorFlow not comparison to other platforms) and code should be posted late next week, which will help get us all on the same set of scripts.  I have done some PyTorch testing with real data on image-classification models and did not see a significant difference in my very informal testing.  I found TensorFlow to be slightly faster with real data, but am not a PyTorch expert.  I did notice that the VGG16 model loss goes to NaN after a few steps, which then results in a speedup but I was not sure if I did something wrong or if it was the model.  Beyond that PyTorch had some issues with their input pipeline with models that process images very quickly, e.g. something like Alexnet with batch size of 512, but that did not seem like a huge deal.  If there is something specific let me know, I did not see pytorch referenced in this thread and only recall the VGG16 thread.  If it it looks like it would lead to a TensorFlow speedup then it is a worth while investigation for the community.</p>", "body_text": "Benchmark results (TensorFlow not comparison to other platforms) and code should be posted late next week, which will help get us all on the same set of scripts.  I have done some PyTorch testing with real data on image-classification models and did not see a significant difference in my very informal testing.  I found TensorFlow to be slightly faster with real data, but am not a PyTorch expert.  I did notice that the VGG16 model loss goes to NaN after a few steps, which then results in a speedup but I was not sure if I did something wrong or if it was the model.  Beyond that PyTorch had some issues with their input pipeline with models that process images very quickly, e.g. something like Alexnet with batch size of 512, but that did not seem like a huge deal.  If there is something specific let me know, I did not see pytorch referenced in this thread and only recall the VGG16 thread.  If it it looks like it would lead to a TensorFlow speedup then it is a worth while investigation for the community.", "body": "Benchmark results (TensorFlow not comparison to other platforms) and code should be posted late next week, which will help get us all on the same set of scripts.  I have done some PyTorch testing with real data on image-classification models and did not see a significant difference in my very informal testing.  I found TensorFlow to be slightly faster with real data, but am not a PyTorch expert.  I did notice that the VGG16 model loss goes to NaN after a few steps, which then results in a speedup but I was not sure if I did something wrong or if it was the model.  Beyond that PyTorch had some issues with their input pipeline with models that process images very quickly, e.g. something like Alexnet with batch size of 512, but that did not seem like a huge deal.  If there is something specific let me know, I did not see pytorch referenced in this thread and only recall the VGG16 thread.  If it it looks like it would lead to a TensorFlow speedup then it is a worth while investigation for the community.  \r\n"}