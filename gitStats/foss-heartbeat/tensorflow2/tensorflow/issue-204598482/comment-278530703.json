{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/278530703", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-278530703", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 278530703, "node_id": "MDEyOklzc3VlQ29tbWVudDI3ODUzMDcwMw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-09T02:42:18Z", "updated_at": "2017-02-09T02:42:18Z", "author_association": "MEMBER", "body_html": "<p>Hi Randl,</p>\n<p>Thank you for the information.  We are working through the benchmark and days away from publishing a performance guide.  There are a couple things that I noticed at a glance with the code they are using.  Before I mention them I want to stress that this is code that was published in the TensorFlow repo and I am not shifting blame.  Now some things to look for:</p>\n<ul>\n<li>Loading data with feed_dict as such:  <code>sess.run([train_op, average_op], feed_dict=feed_dict).</code><br>\nThis is almost the slowest possible approach and is often used in examples.</li>\n<li>Allowing the preprocessing (of say images) to end up on the GPU.  This happens if it is not placed on the CPU.  This can result in 6x+ increased performance.</li>\n</ul>\n<p>There are other little tweaks but with just the two \"tricks\" above I suspect a few of the benchmarks you listed would improve dramatically.  There are other tweaks but using TF 1.0+ and the above techniques would help a lot.</p>\n<p>I will leave this open until I can post some numbers and possibly get someone to post a PR to the benchmark project.</p>\n<p>Thank you again for following up and opening a new issue.</p>", "body_text": "Hi Randl,\nThank you for the information.  We are working through the benchmark and days away from publishing a performance guide.  There are a couple things that I noticed at a glance with the code they are using.  Before I mention them I want to stress that this is code that was published in the TensorFlow repo and I am not shifting blame.  Now some things to look for:\n\nLoading data with feed_dict as such:  sess.run([train_op, average_op], feed_dict=feed_dict).\nThis is almost the slowest possible approach and is often used in examples.\nAllowing the preprocessing (of say images) to end up on the GPU.  This happens if it is not placed on the CPU.  This can result in 6x+ increased performance.\n\nThere are other little tweaks but with just the two \"tricks\" above I suspect a few of the benchmarks you listed would improve dramatically.  There are other tweaks but using TF 1.0+ and the above techniques would help a lot.\nI will leave this open until I can post some numbers and possibly get someone to post a PR to the benchmark project.\nThank you again for following up and opening a new issue.", "body": "Hi Randl,\r\n\r\nThank you for the information.  We are working through the benchmark and days away from publishing a performance guide.  There are a couple things that I noticed at a glance with the code they are using.  Before I mention them I want to stress that this is code that was published in the TensorFlow repo and I am not shifting blame.  Now some things to look for:\r\n\r\n- Loading data with feed_dict as such:  `sess.run([train_op, average_op], feed_dict=feed_dict).` \r\nThis is almost the slowest possible approach and is often used in examples.\r\n- Allowing the preprocessing (of say images) to end up on the GPU.  This happens if it is not placed on the CPU.  This can result in 6x+ increased performance.\r\n\r\nThere are other little tweaks but with just the two \"tricks\" above I suspect a few of the benchmarks you listed would improve dramatically.  There are other tweaks but using TF 1.0+ and the above techniques would help a lot.  \r\n\r\nI will leave this open until I can post some numbers and possibly get someone to post a PR to the benchmark project.  \r\n\r\nThank you again for following up and opening a new issue.\r\n\r\n\r\n"}