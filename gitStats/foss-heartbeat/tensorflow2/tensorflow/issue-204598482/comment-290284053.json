{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290284053", "html_url": "https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-290284053", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7187", "id": 290284053, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDI4NDA1Mw==", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-30T02:29:11Z", "updated_at": "2017-03-30T04:28:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=551151\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Yangqing\">@Yangqing</a> What exactly is the \"workspace size\" that you are referring to, and what is it defaulted to? I see some stuff <a href=\"https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/stream_executor/cuda/cuda_dnn.cc#L1832-L1833\">here</a>, but don't really see it documented. Further how often / when is the optimal algorithm chosen?  Is <code>TF_CUDNN_WORKSPACE_LIMIT_IN_MB</code> what you are talking about? The default is 4GB which seems &gt;&gt; size you listed.</p>\n<p>Might be cool to offer some sort of verbose logging about the tuning options along the lines of <a href=\"https://github.com/szagoruyko/cudnn.torch/blob/master/README.md#modes\">torch7</a>.</p>\n<p>Also why does TensorFlow use cudnnGet* instead of cudnnFind* (I would think specifically the <code>cudnnFind...Ex</code> variety)?</p>", "body_text": "@Yangqing What exactly is the \"workspace size\" that you are referring to, and what is it defaulted to? I see some stuff here, but don't really see it documented. Further how often / when is the optimal algorithm chosen?  Is TF_CUDNN_WORKSPACE_LIMIT_IN_MB what you are talking about? The default is 4GB which seems >> size you listed.\nMight be cool to offer some sort of verbose logging about the tuning options along the lines of torch7.\nAlso why does TensorFlow use cudnnGet* instead of cudnnFind* (I would think specifically the cudnnFind...Ex variety)?", "body": "@Yangqing What exactly is the \"workspace size\" that you are referring to, and what is it defaulted to? I see some stuff [here](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/stream_executor/cuda/cuda_dnn.cc#L1832-L1833), but don't really see it documented. Further how often / when is the optimal algorithm chosen?  Is `TF_CUDNN_WORKSPACE_LIMIT_IN_MB` what you are talking about? The default is 4GB which seems >> size you listed.\r\n\r\nMight be cool to offer some sort of verbose logging about the tuning options along the lines of [torch7](https://github.com/szagoruyko/cudnn.torch/blob/master/README.md#modes).\r\n\r\nAlso why does TensorFlow use cudnnGet* instead of cudnnFind* (I would think specifically the `cudnnFind...Ex` variety)?"}