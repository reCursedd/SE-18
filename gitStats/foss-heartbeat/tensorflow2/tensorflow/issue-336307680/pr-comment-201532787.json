{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/201532787", "pull_request_review_id": 136053447, "id": 201532787, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMTUzMjc4Nw==", "diff_hunk": "@@ -1567,47 +1712,105 @@ tensorflow::Status ConvertBinary(Converter& ctx,\n     return tensorflow::errors::FailedPrecondition(\n         \"Binary ops require two tensor input, at \" + node_def.name());\n \n-  if (inputs.at(0).is_weights() && inputs.at(1).is_weights())\n-    return ConstantFoldBinary(ctx, node_def, inputs, outputs);\n+  // Constant folding should have been done by TensorFlow\n \n-  if (inputs.at(0).is_tensor() && inputs.at(1).is_weights())\n-    return BinaryTensorOpWeight(ctx, node_def, inputs.at(0).tensor(),\n-                                inputs.at(1).weights(), outputs);\n+  if (inputs.at(0).is_weights() && inputs.at(1).is_weights())\n+    return tensorflow::errors::Unimplemented(\n+        \"Constant folding is falled back to TensorFlow, binary op received \"\n+        \"both input as constant at: \" +\n+        node_def.name());\n \n-  if (inputs.at(0).is_weights() && inputs.at(1).is_tensor())\n-    return BinaryTensorOpWeight(ctx, node_def, inputs.at(1).tensor(),\n-                                inputs.at(0).weights(), outputs);\n+  // Try to convert into Scale layer first (for better performance)\n+  // Since scale layer supports restricted broadcast policy and op types, we\n+  // allow failure and try to handle it through Elementwise op\n+  // (BinaryTensorOpTensor)\n+  if (inputs.at(0).is_tensor() && inputs.at(1).is_weights()) {\n+    auto status = BinaryTensorOpWeight(ctx, node_def, inputs.at(0).tensor(),\n+                                       inputs.at(1).weights(), false, outputs);\n+#if NV_TENSORRT_MAJOR == 3\n+    TF_RETURN_IF_ERROR(status);", "path": "tensorflow/contrib/tensorrt/convert/convert_nodes.cc", "position": null, "original_position": 918, "commit_id": "2de343c329ff252ed0cb419f29c3ce3765b3da84", "original_commit_id": "4902f909d206fe6ca669b8f8a060f18b32f184e0", "user": {"login": "jjsjann123", "id": 3709243, "node_id": "MDQ6VXNlcjM3MDkyNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3709243?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jjsjann123", "html_url": "https://github.com/jjsjann123", "followers_url": "https://api.github.com/users/jjsjann123/followers", "following_url": "https://api.github.com/users/jjsjann123/following{/other_user}", "gists_url": "https://api.github.com/users/jjsjann123/gists{/gist_id}", "starred_url": "https://api.github.com/users/jjsjann123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jjsjann123/subscriptions", "organizations_url": "https://api.github.com/users/jjsjann123/orgs", "repos_url": "https://api.github.com/users/jjsjann123/repos", "events_url": "https://api.github.com/users/jjsjann123/events{/privacy}", "received_events_url": "https://api.github.com/users/jjsjann123/received_events", "type": "User", "site_admin": false}, "body": "For performance consideration, we prefer to use BinaryTensorOpWeight ( Scale layer in TRT ). But there are cases that this conversion might fail (transpose, broadcasting on batch, etc), which BinaryTensorOpTensor could catch.\r\n\r\nBut this is only applicable in TRT 4.0 thanks to the Constant layer added in TRT 4.0.", "created_at": "2018-07-11T00:10:00Z", "updated_at": "2018-07-11T18:33:32Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20350#discussion_r201532787", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20350", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/201532787"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20350#discussion_r201532787"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20350"}}, "body_html": "<p>For performance consideration, we prefer to use BinaryTensorOpWeight ( Scale layer in TRT ). But there are cases that this conversion might fail (transpose, broadcasting on batch, etc), which BinaryTensorOpTensor could catch.</p>\n<p>But this is only applicable in TRT 4.0 thanks to the Constant layer added in TRT 4.0.</p>", "body_text": "For performance consideration, we prefer to use BinaryTensorOpWeight ( Scale layer in TRT ). But there are cases that this conversion might fail (transpose, broadcasting on batch, etc), which BinaryTensorOpTensor could catch.\nBut this is only applicable in TRT 4.0 thanks to the Constant layer added in TRT 4.0.", "in_reply_to_id": 201479751}