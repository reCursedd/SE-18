{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/250318939", "html_url": "https://github.com/tensorflow/tensorflow/issues/3028#issuecomment-250318939", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3028", "id": 250318939, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MDMxODkzOQ==", "user": {"login": "amolchanov86", "id": 9425205, "node_id": "MDQ6VXNlcjk0MjUyMDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9425205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amolchanov86", "html_url": "https://github.com/amolchanov86", "followers_url": "https://api.github.com/users/amolchanov86/followers", "following_url": "https://api.github.com/users/amolchanov86/following{/other_user}", "gists_url": "https://api.github.com/users/amolchanov86/gists{/gist_id}", "starred_url": "https://api.github.com/users/amolchanov86/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amolchanov86/subscriptions", "organizations_url": "https://api.github.com/users/amolchanov86/orgs", "repos_url": "https://api.github.com/users/amolchanov86/repos", "events_url": "https://api.github.com/users/amolchanov86/events{/privacy}", "received_events_url": "https://api.github.com/users/amolchanov86/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-28T22:21:47Z", "updated_at": "2016-09-28T22:21:47Z", "author_association": "NONE", "body_html": "<p>What did you compare to ? Did you compare to original dense multiplication<br>\n(without sparsity flags) ?<br>\nPS: btw, there is matmultiplication of dense on sparse tensors instead of<br>\nembedding_lookup<br>\ntf.sparse_tensor_dense_matmul<br>\n<a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/python/sparse_ops.html#sparse_tensor_dense_matmul\" rel=\"nofollow\">https://www.tensorflow.org/versions/r0.10/api_docs/python/sparse_ops.html#sparse_tensor_dense_matmul</a></p>\n<p>On 27 September 2016 at 01:41, Young H. Oh <a href=\"mailto:notifications@github.com\">notifications@github.com</a> wrote:</p>\n<blockquote>\n<p>This work <a href=\"https://github.com/garion9013/impl-pruning-TF\">https://github.com/garion9013/impl-pruning-TF</a> actually<br>\nimplements iterative pruning (part of Deep compression) on TF.<br>\n<em>embedding_lookup_sparse</em> operation is used to do sparse matrix<br>\nmultiplication.<br>\nI've got some of speedups with this prototype, but it's somewhat mediocre.<br>\nI think it's because small size of the model and sparse matrix format that<br>\nTF uses as a default (COO).</p>\n<p>\u2014<br>\nYou are receiving this because you authored the thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"162172718\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3028\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3028/hovercard?comment_id=249802651&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/3028#issuecomment-249802651\">#3028 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AI_RNags9isvjZuEr84HNccCwXSbNbO8ks5quNbHgaJpZM4I94Gy\">https://github.com/notifications/unsubscribe-auth/AI_RNags9isvjZuEr84HNccCwXSbNbO8ks5quNbHgaJpZM4I94Gy</a><br>\n.</p>\n</blockquote>\n<h2></h2>\n<p>Best regards,<br>\nArtem Molchanov.</p>", "body_text": "What did you compare to ? Did you compare to original dense multiplication\n(without sparsity flags) ?\nPS: btw, there is matmultiplication of dense on sparse tensors instead of\nembedding_lookup\ntf.sparse_tensor_dense_matmul\nhttps://www.tensorflow.org/versions/r0.10/api_docs/python/sparse_ops.html#sparse_tensor_dense_matmul\nOn 27 September 2016 at 01:41, Young H. Oh notifications@github.com wrote:\n\nThis work https://github.com/garion9013/impl-pruning-TF actually\nimplements iterative pruning (part of Deep compression) on TF.\nembedding_lookup_sparse operation is used to do sparse matrix\nmultiplication.\nI've got some of speedups with this prototype, but it's somewhat mediocre.\nI think it's because small size of the model and sparse matrix format that\nTF uses as a default (COO).\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\n#3028 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AI_RNags9isvjZuEr84HNccCwXSbNbO8ks5quNbHgaJpZM4I94Gy\n.\n\n\nBest regards,\nArtem Molchanov.", "body": "What did you compare to ? Did you compare to original dense multiplication\n(without sparsity flags) ?\nPS: btw, there is matmultiplication of dense on sparse tensors instead of\nembedding_lookup\ntf.sparse_tensor_dense_matmul\nhttps://www.tensorflow.org/versions/r0.10/api_docs/python/sparse_ops.html#sparse_tensor_dense_matmul\n\nOn 27 September 2016 at 01:41, Young H. Oh notifications@github.com wrote:\n\n> This work https://github.com/garion9013/impl-pruning-TF actually\n> implements iterative pruning (part of Deep compression) on TF.\n> _embedding_lookup_sparse_ operation is used to do sparse matrix\n> multiplication.\n> I've got some of speedups with this prototype, but it's somewhat mediocre.\n> I think it's because small size of the model and sparse matrix format that\n> TF uses as a default (COO).\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3028#issuecomment-249802651,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AI_RNags9isvjZuEr84HNccCwXSbNbO8ks5quNbHgaJpZM4I94Gy\n> .\n\n## \n\nBest regards,\nArtem Molchanov.\n"}