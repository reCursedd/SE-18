{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3420", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3420/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3420/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3420/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3420", "id": 166631842, "node_id": "MDU6SXNzdWUxNjY2MzE4NDI=", "number": 3420, "title": "Running Bidirectional RNN cells on parallel", "user": {"login": "ASDen", "id": 124146, "node_id": "MDQ6VXNlcjEyNDE0Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/124146?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ASDen", "html_url": "https://github.com/ASDen", "followers_url": "https://api.github.com/users/ASDen/followers", "following_url": "https://api.github.com/users/ASDen/following{/other_user}", "gists_url": "https://api.github.com/users/ASDen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ASDen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ASDen/subscriptions", "organizations_url": "https://api.github.com/users/ASDen/orgs", "repos_url": "https://api.github.com/users/ASDen/repos", "events_url": "https://api.github.com/users/ASDen/events{/privacy}", "received_events_url": "https://api.github.com/users/ASDen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 21, "created_at": "2016-07-20T17:02:03Z", "updated_at": "2016-08-20T04:46:43Z", "closed_at": "2016-08-20T04:46:43Z", "author_association": "NONE", "body_html": "<p>is there any method to run Bidirectional RNNs on parallel as they should (they have no dependency on each other)<br>\nI noticed that stacking 2 LSTM layer has the exact same performance as bidirection LSTM (BLSTM)<br>\neven 4 stacked LSTM has same performance as 2 parallel BLSTMs (which simply means  that TF runtime doesn't parallelize BLSTMs at all, I also notice the same behavior on both the CPU and the GPU)</p>\n<p>Note: I am using small cells that are trivial to fit simultaneously</p>\n<p>Thanks,</p>", "body_text": "is there any method to run Bidirectional RNNs on parallel as they should (they have no dependency on each other)\nI noticed that stacking 2 LSTM layer has the exact same performance as bidirection LSTM (BLSTM)\neven 4 stacked LSTM has same performance as 2 parallel BLSTMs (which simply means  that TF runtime doesn't parallelize BLSTMs at all, I also notice the same behavior on both the CPU and the GPU)\nNote: I am using small cells that are trivial to fit simultaneously\nThanks,", "body": "is there any method to run Bidirectional RNNs on parallel as they should (they have no dependency on each other)\nI noticed that stacking 2 LSTM layer has the exact same performance as bidirection LSTM (BLSTM)\neven 4 stacked LSTM has same performance as 2 parallel BLSTMs (which simply means  that TF runtime doesn't parallelize BLSTMs at all, I also notice the same behavior on both the CPU and the GPU)\n\nNote: I am using small cells that are trivial to fit simultaneously\n\nThanks,\n"}