{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238912241", "html_url": "https://github.com/tensorflow/tensorflow/issues/3420#issuecomment-238912241", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3420", "id": 238912241, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODkxMjI0MQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-10T15:54:06Z", "updated_at": "2016-08-10T15:54:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=124146\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ASDen\">@ASDen</a> apologies; in fact, there is no execution barrier because the following can be run in parallel:</p>\n<p>chunk 1:<br>\nreverse x<br>\ny_rev = lstm(x_rev)<br>\ny_bak = reverse y_rev</p>\n<p>chunk 2:<br>\ny_fw = lstm(x)</p>\n<p>then you need to wait for both of these chunks to finish before you can concat them.</p>\n<p>dynamic bidirectional rnn doesn't even bother with the concat - you get both pieces and can concat them if you wish.</p>\n<p>right now, running the fw &amp; reverse on multiple GPUs would require creating a special device setter and calling bidirectional rnn within that context.  see, e.g., the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/device_setter.py\">replica_device_setter</a> function, the result of which you would pass to tf.device.</p>", "body_text": "@ASDen apologies; in fact, there is no execution barrier because the following can be run in parallel:\nchunk 1:\nreverse x\ny_rev = lstm(x_rev)\ny_bak = reverse y_rev\nchunk 2:\ny_fw = lstm(x)\nthen you need to wait for both of these chunks to finish before you can concat them.\ndynamic bidirectional rnn doesn't even bother with the concat - you get both pieces and can concat them if you wish.\nright now, running the fw & reverse on multiple GPUs would require creating a special device setter and calling bidirectional rnn within that context.  see, e.g., the replica_device_setter function, the result of which you would pass to tf.device.", "body": "@ASDen apologies; in fact, there is no execution barrier because the following can be run in parallel:\n\nchunk 1:\nreverse x\ny_rev = lstm(x_rev)\ny_bak = reverse y_rev\n\nchunk 2:\ny_fw = lstm(x)\n\nthen you need to wait for both of these chunks to finish before you can concat them.\n\ndynamic bidirectional rnn doesn't even bother with the concat - you get both pieces and can concat them if you wish.\n\nright now, running the fw & reverse on multiple GPUs would require creating a special device setter and calling bidirectional rnn within that context.  see, e.g., the [replica_device_setter](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/device_setter.py) function, the result of which you would pass to tf.device.\n"}