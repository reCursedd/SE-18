{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399013418", "html_url": "https://github.com/tensorflow/tensorflow/issues/19812#issuecomment-399013418", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19812", "id": 399013418, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTAxMzQxOA==", "user": {"login": "Twice22", "id": 7197622, "node_id": "MDQ6VXNlcjcxOTc2MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/7197622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Twice22", "html_url": "https://github.com/Twice22", "followers_url": "https://api.github.com/users/Twice22/followers", "following_url": "https://api.github.com/users/Twice22/following{/other_user}", "gists_url": "https://api.github.com/users/Twice22/gists{/gist_id}", "starred_url": "https://api.github.com/users/Twice22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Twice22/subscriptions", "organizations_url": "https://api.github.com/users/Twice22/orgs", "repos_url": "https://api.github.com/users/Twice22/repos", "events_url": "https://api.github.com/users/Twice22/events{/privacy}", "received_events_url": "https://api.github.com/users/Twice22/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-21T08:05:42Z", "updated_at": "2018-06-21T08:05:42Z", "author_association": "NONE", "body_html": "<p>Hey.</p>\n<p>I didn't look too much into the paper you mentioned, but it seems that, if I'm not mistaken, that Theano implementation is based on the \"naive\" idea. See <a href=\"https://github.com/Theano/Theano/blob/master/theano/sandbox/multinomial.py\">perform</a> function at line 155. I didn't take the time to look at the GPU implementation <a href=\"https://github.com/Theano/Theano/blob/master/theano/gpuarray/multinomial.py\">here</a>.</p>\n<p>Here is some benchmarks I did using numpy, C++ and I've also tried CUDA but didn't manage to fully implement it:</p>\n<p>All the Benchmarks are more or less based on the same set-up (the random numbers associated to the<br>\ncounts are sampled in <strong>[2000, 3500]</strong>. For this reason the numbers to sample might vary from one experiment to another one but on average the time remains the same).</p>\n<p>My CPU: Intel(R) Xeon(R) E3-1505M v6 @ 3.00Ghz<br>\nMy GPU (Cuda compatible): Quadro M1200, Driver: 390.65</p>\n<ul>\n<li>Theano: 0.0025s</li>\n<li>TensorFlow [actual code]: 0.045s</li>\n<li>TensorFlow [my version]: 0.015s</li>\n<li>Numpy code: 0.62s</li>\n<li>C++ [Compile with Ox]: 0.25s</li>\n<li>CUDA  [couldn't make it work]</li>\n</ul>\n<p><strong>Numpy version:</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">vmultinomial</span>(<span class=\"pl-smi\">counts</span>, <span class=\"pl-smi\">pvals</span>):\n    N, K <span class=\"pl-k\">=</span> pvals.shape\n    Z <span class=\"pl-k\">=</span> np.zeros_like(pvals, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>)\n    cumsum <span class=\"pl-k\">=</span> np.cumsum(pvals, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>float64<span class=\"pl-pds\">'</span></span>)\n    \n    <span class=\"pl-k\">for</span> n <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(N):\n        size_ <span class=\"pl-k\">=</span> counts[n]\n        rnd_numbers <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>size_)\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(counts[n]):\n            Z[n, np.searchsorted(cumsum[n], rnd_numbers[i])] <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n    \n    <span class=\"pl-k\">return</span> Z\n\nnb_distribution <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n\nu <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">2000</span>, <span class=\"pl-c1\">3500</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>nb_distribution)\nprobsn <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(nb_distribution, <span class=\"pl-c1\">30</span>))\nprobsn <span class=\"pl-k\">/=</span> np.sum(probsn, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)[:, <span class=\"pl-c1\">None</span>]\n\nstart_t <span class=\"pl-k\">=</span> time.time()\nres <span class=\"pl-k\">=</span> vmultinomial(u, probsn)\n<span class=\"pl-c1\">print</span>(time.time() <span class=\"pl-k\">-</span> start_t)</pre></div>\n<p>**C++ code: **</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>stdafx.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>Eigen/Dense<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>algorithm<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>random<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>vector<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>chrono<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">std</span><span class=\"pl-k\">;</span>\n<span class=\"pl-k\">using</span> Eigen::MatrixXd;\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">std</span>::chrono<span class=\"pl-k\">;</span>\n\n\n<span class=\"pl-k\">static</span> vector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-en\">random_uniform</span>(<span class=\"pl-c1\">size_t</span> size, <span class=\"pl-k\">int</span> inf, <span class=\"pl-k\">int</span> sup) {\n\t<span class=\"pl-k\">static</span> uniform_int_distribution&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">distribution</span>(inf, sup);\n\t<span class=\"pl-k\">static</span> default_random_engine generator;\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> allocate a vector of size size</span>\n\tvector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">data</span>(size);\n\t<span class=\"pl-c1\">generate</span>(data.<span class=\"pl-c1\">begin</span>(), data.<span class=\"pl-c1\">end</span>(), []() { <span class=\"pl-k\">return</span> <span class=\"pl-c1\">distribution</span>(generator); });\n\n\t<span class=\"pl-k\">return</span> data;\n}\n\n<span class=\"pl-k\">static</span> vector&lt;<span class=\"pl-k\">double</span>&gt; <span class=\"pl-en\">double_random_uniform</span>(<span class=\"pl-c1\">size_t</span> size) {\n\t<span class=\"pl-k\">static</span> uniform_real_distribution&lt;<span class=\"pl-k\">double</span>&gt; <span class=\"pl-c1\">distribution</span>(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">1.0</span>);\n\t<span class=\"pl-k\">static</span> default_random_engine generator;\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> allocate a vector of size size</span>\n\tvector&lt;<span class=\"pl-k\">double</span>&gt; <span class=\"pl-c1\">data</span>(size);\n\t<span class=\"pl-c1\">generate</span>(data.<span class=\"pl-c1\">begin</span>(), data.<span class=\"pl-c1\">end</span>(), []() { <span class=\"pl-k\">return</span> <span class=\"pl-c1\">distribution</span>(generator); });\n\n\t<span class=\"pl-k\">return</span> data;\n}\n\nMatrixXd <span class=\"pl-en\">probs_mat</span>(<span class=\"pl-c1\">size_t</span> rows, <span class=\"pl-c1\">size_t</span> cols) {\n\tMatrixXd m = (<span class=\"pl-c1\">MatrixXd::Random</span>(rows, cols) + <span class=\"pl-c1\">MatrixXd::Constant</span>(rows, cols, <span class=\"pl-c1\">1</span>.)) / <span class=\"pl-c1\">2</span>;\n\tMatrixXd m2 = m.<span class=\"pl-c1\">rowwise</span>().<span class=\"pl-c1\">sum</span>();\n\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; rows; i++) {\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; cols; j++) {\n\t\t\t<span class=\"pl-c1\">m</span>(i, j) /= <span class=\"pl-c1\">m2</span>(i);\n\t\t}\n\t}\n\t\n\t<span class=\"pl-k\">return</span> m;\n}\n\nMatrixXd <span class=\"pl-en\">cumsum</span>(MatrixXd pvals) {\n\t<span class=\"pl-k\">int</span> N = pvals.<span class=\"pl-c1\">rows</span>(), K = pvals.<span class=\"pl-c1\">cols</span>();\n\tMatrixXd <span class=\"pl-smi\">Z</span>(N, K);\n\n\t#<span class=\"pl-k\">pragma</span> omp parallel for\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++) {\n\t\t<span class=\"pl-k\">double</span> sum = <span class=\"pl-c1\">0</span>;\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; K; j++) {\n\t\t\tsum += <span class=\"pl-c1\">pvals</span>(i, j);\n\t\t\t<span class=\"pl-c1\">Z</span>(i, j) = sum;\n\t\t}\n\t}\n\n\t<span class=\"pl-k\">return</span> Z;\n}\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">searchsorted</span>(MatrixXd csum, <span class=\"pl-k\">double</span> rnd) {\n\t<span class=\"pl-k\">int</span> beg = <span class=\"pl-c1\">0</span>, end = csum.<span class=\"pl-c1\">size</span>();\n\n\t<span class=\"pl-k\">while</span> (beg &lt;= end) {\n\t\t<span class=\"pl-k\">int</span> mid = (beg + end) / <span class=\"pl-c1\">2</span>;\n\t\t<span class=\"pl-k\">if</span> (<span class=\"pl-c1\">csum</span>(mid) &lt; rnd) {\n\t\t\tbeg = mid + <span class=\"pl-c1\">1</span>;\n\t\t}\n\t\t<span class=\"pl-k\">else</span> {\n\t\t\tend = mid - <span class=\"pl-c1\">1</span>;\n\t\t}\n\t}\n\t<span class=\"pl-k\">return</span> beg;\n}\n\n\nMatrixXd <span class=\"pl-en\">multinomial</span>(vector&lt;<span class=\"pl-k\">int</span>&gt; counts, MatrixXd probs) {\n\t<span class=\"pl-k\">int</span> N = probs.<span class=\"pl-c1\">rows</span>(), K = probs.<span class=\"pl-c1\">cols</span>();\n\tMatrixXd Z = <span class=\"pl-c1\">MatrixXd::Zero</span>(N, K);\n\n\tMatrixXd csum = <span class=\"pl-c1\">cumsum</span>(probs);\n\t\n#<span class=\"pl-k\">pragma</span> omp parallel for\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; N; i++) {\n\t\t<span class=\"pl-k\">int</span> length = counts[i];\n\t\tvector&lt;<span class=\"pl-k\">double</span>&gt; rnd_numbers = <span class=\"pl-c1\">double_random_uniform</span>(length);\n\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; length; j++) {\n\t\t\t<span class=\"pl-c1\">Z</span>(i, <span class=\"pl-c1\">searchsorted</span>(csum.<span class=\"pl-c1\">row</span>(i), rnd_numbers[j])) += <span class=\"pl-c1\">1</span>;\n\t\t}\n\t}\n\t<span class=\"pl-k\">return</span> Z;\n}\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>()\n{\n\t<span class=\"pl-k\">int</span> nb_samples = <span class=\"pl-c1\">100</span>, pvals = <span class=\"pl-c1\">30</span>;\n\t<span class=\"pl-k\">int</span> low = <span class=\"pl-c1\">2000</span>, high = <span class=\"pl-c1\">3500</span>;\n\tvector&lt;<span class=\"pl-k\">int</span>&gt; counts = <span class=\"pl-c1\">random_uniform</span>(nb_samples, low, high);\n\tMatrixXd probs = <span class=\"pl-c1\">probs_mat</span>(nb_samples, pvals);\n\t\n\n\thigh_resolution_clock::time_point t1 = <span class=\"pl-c1\">high_resolution_clock::now</span>();\n\tMatrixXd csum = <span class=\"pl-c1\">multinomial</span>(counts, probs);\n\thigh_resolution_clock::time_point t2 = <span class=\"pl-c1\">high_resolution_clock::now</span>();\n\n\t<span class=\"pl-k\">auto</span> duration = duration_cast&lt;microseconds&gt;(t2 - t1).<span class=\"pl-c1\">count</span>();\n\n\tcout &lt;&lt; duration &lt;&lt; endl;\n\t<span class=\"pl-c1\">system</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>pause<span class=\"pl-pds\">\"</span></span>);\n}</pre></div>\n<p><strong>CUDA attempt:</strong></p>\n<div class=\"highlight highlight-source-cuda-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>math.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda_runtime.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>device_launch_parameters.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>stdio.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>ctime<span class=\"pl-pds\">&gt;</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/device_vector.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/transform.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/iterator/counting_iterator.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/random.h<span class=\"pl-pds\">&gt;</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>cublas_v2.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>curand.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/functional.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/iterator/counting_iterator.h<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>thrust/iterator/constant_iterator.h<span class=\"pl-pds\">&gt;</span></span>\n\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">std</span><span class=\"pl-k\">;</span>\n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">thrust</span><span class=\"pl-k\">;</span>\n\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">prg</span>\n{\n\t<span class=\"pl-k\">int</span> a, b;\n\n\t<span class=\"pl-k\">__host__</span> <span class=\"pl-k\">__device__</span>\n\t\t<span class=\"pl-en\">prg</span>(<span class=\"pl-k\">int</span> _a = <span class=\"pl-c1\">0</span>, <span class=\"pl-k\">int</span> _b = <span class=\"pl-c1\">1</span>) : a(_a), b(_b) {};\n\n\t<span class=\"pl-k\">__host__</span> <span class=\"pl-k\">__device__</span>\n\t\t<span class=\"pl-k\">int</span> <span class=\"pl-en\">operator</span>()(<span class=\"pl-k\">const</span> <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> n) <span class=\"pl-k\">const</span>\n\t{\n\t\tdefault_random_engine rng;\n\t\tuniform_int_distribution&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">dist</span>(a, b);\n\t\trng.<span class=\"pl-c1\">discard</span>(n);\n\n\t\t<span class=\"pl-k\">return</span> <span class=\"pl-c1\">dist</span>(rng);\n\t}\n};\n\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">float_prg</span>\n{\n\t<span class=\"pl-k\">int</span> a, b;\n\n\t<span class=\"pl-k\">__host__</span> <span class=\"pl-k\">__device__</span>\n\t\t<span class=\"pl-en\">float_prg</span>(<span class=\"pl-k\">float</span> _a = <span class=\"pl-c1\">0.0</span>, <span class=\"pl-k\">float</span> _b = <span class=\"pl-c1\">1.0</span>) : a(_a), b(_b) {};\n\n\t<span class=\"pl-k\">__host__</span> <span class=\"pl-k\">__device__</span>\n\t\t<span class=\"pl-k\">float</span> <span class=\"pl-en\">operator</span>()(<span class=\"pl-k\">const</span> <span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span> n) <span class=\"pl-k\">const</span>\n\t{\n\t\tdefault_random_engine rng;\n\t\tuniform_real_distribution&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-c1\">dist</span>(a, b);\n\t\trng.<span class=\"pl-c1\">discard</span>(n);\n\n\t\t<span class=\"pl-k\">return</span> <span class=\"pl-c1\">dist</span>(rng);\n\t}\n};\n\n\n<span class=\"pl-k\">static</span> device_vector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-en\">random_uniform</span>(<span class=\"pl-c1\">size_t</span> size, <span class=\"pl-k\">int</span> inf, <span class=\"pl-k\">int</span> sup) {\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> allocate a vector of size size</span>\n\tdevice_vector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">data</span>(size);\n\tcounting_iterator&lt;<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">index_sequence_begin</span>(<span class=\"pl-c1\">0</span>);\n\n\t<span class=\"pl-c1\">transform</span>(index_sequence_begin, index_sequence_begin + size, data.<span class=\"pl-c1\">begin</span>(), <span class=\"pl-c1\">prg</span>(inf, sup));\n\n\t<span class=\"pl-k\">return</span> data;\n}\n\n<span class=\"pl-k\">__host__</span> <span class=\"pl-k\">__device__</span>\n<span class=\"pl-k\">static</span> device_vector&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-en\">double_random_uniform</span>(<span class=\"pl-c1\">size_t</span> size) {\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> allocate a vector of size size</span>\n\tdevice_vector&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-c1\">data</span>(size);\n\tcounting_iterator&lt;<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">index_sequence_begin</span>(<span class=\"pl-c1\">0</span>);\n\n\t<span class=\"pl-c1\">transform</span>(index_sequence_begin, index_sequence_begin + size, data.<span class=\"pl-c1\">begin</span>(), <span class=\"pl-c1\">float_prg</span>(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">1.0</span>));\n\n\t<span class=\"pl-k\">return</span> data;\n}\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> don't care if this function doesn't use CUDA, I don't eval</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> its performance</span>\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">normalize_l1</span>(device_vector&lt;<span class=\"pl-k\">float</span>&gt; &amp;A, <span class=\"pl-k\">int</span> rows, <span class=\"pl-k\">int</span> cols) {\n\t<span class=\"pl-k\">float</span> *row_sum = (<span class=\"pl-k\">float</span> *)<span class=\"pl-c1\">malloc</span>(rows * <span class=\"pl-k\">sizeof</span>(<span class=\"pl-k\">float</span>));\n\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; rows; ++i) {\n\t\t<span class=\"pl-k\">float</span> sum = <span class=\"pl-c1\">0</span>.<span class=\"pl-c1\">0f</span>;\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; cols; ++j) {\n\t\t\tsum += A[cols*i + j];\n\t\t}\n\t\trow_sum[i] = sum;\n\t}\n\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> r = <span class=\"pl-c1\">0</span>; r &lt; rows; ++r) {\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> c = <span class=\"pl-c1\">0</span>; c &lt; cols; ++c) {\n\t\t\tA[r*cols + c] /= row_sum[r];\n\t\t}\n\t}\n}\n\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">GPU_fill_rand</span>(device_vector&lt;<span class=\"pl-k\">float</span>&gt; &amp;A, <span class=\"pl-k\">int</span> nr_rows_A, <span class=\"pl-k\">int</span> nr_cols_A) {\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> Create a pseudo-random number generator</span>\n\tcurandGenerator_t prng;\n\t<span class=\"pl-c1\">curandCreateGenerator</span>(&amp;prng, CURAND_RNG_PSEUDO_DEFAULT);\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> Set the seed for the random number generator using the system clock</span>\n\t<span class=\"pl-c1\">curandSetPseudoRandomGeneratorSeed</span>(prng, (<span class=\"pl-k\">unsigned</span> <span class=\"pl-k\">long</span> <span class=\"pl-k\">long</span>) <span class=\"pl-c1\">clock</span>());\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> Fill the array with random numbers on the device</span>\n\t<span class=\"pl-c1\">curandGenerateUniform</span>(prng, <span class=\"pl-c1\">raw_pointer_cast</span>(&amp;A[<span class=\"pl-c1\">0</span>]), nr_rows_A * nr_cols_A);\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> normalize the matrix</span>\n\t<span class=\"pl-c1\">normalize_l1</span>(A, nr_rows_A, nr_cols_A);\n\n}\n\n<span class=\"pl-k\">template</span>&lt;<span class=\"pl-k\">class</span> <span class=\"pl-en\">T</span>&gt;\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">print_matrix</span>(<span class=\"pl-k\">const</span> device_vector&lt;T&gt; &amp;A, <span class=\"pl-k\">int</span> nr_rows_A, <span class=\"pl-k\">int</span> nr_cols_A) {\n\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">0</span>; i &lt; nr_rows_A; ++i) {\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; nr_cols_A; ++j) {\n\t\t\tcout &lt;&lt; A[i * nr_cols_A + j] &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> <span class=\"pl-pds\">\"</span></span>;\n\t\t}\n\t\tcout &lt;&lt; endl;\n\t}\n\tcout &lt;&lt; endl;\n}\n\n<span class=\"pl-k\">__device__</span>\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">searchsorted</span>(<span class=\"pl-k\">float</span>* csum, <span class=\"pl-k\">int</span> beg, <span class=\"pl-k\">int</span> end, <span class=\"pl-k\">double</span> rnd) {\n\n\t<span class=\"pl-k\">while</span> (beg &lt;= end) {\n\t\t<span class=\"pl-k\">int</span> mid = (beg + end) / <span class=\"pl-c1\">2</span>;\n\t\t<span class=\"pl-k\">if</span> (csum[mid] &lt; rnd) {\n\t\t\tbeg = mid + <span class=\"pl-c1\">1</span>;\n\t\t}\n\t\t<span class=\"pl-k\">else</span> {\n\t\t\tend = mid - <span class=\"pl-c1\">1</span>;\n\t\t}\n\t}\n\t<span class=\"pl-k\">return</span> beg;\n}\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> compute the cumulative sum over the row of the input matrix Z</span>\n<span class=\"pl-k\">void</span> <span class=\"pl-en\">cumsum</span>(device_vector&lt;<span class=\"pl-k\">float</span>&gt; &amp;Z, <span class=\"pl-k\">int</span> N, <span class=\"pl-k\">int</span> K) {\n\n\tdevice_vector&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-c1\">cumProb</span>(N*K, <span class=\"pl-c1\">0</span>.);\n\tdevice_vector&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-c1\">sub</span>(N*K);\n\n\t<span class=\"pl-c1\">inclusive_scan</span>(Z.<span class=\"pl-c1\">begin</span>(), Z.<span class=\"pl-c1\">end</span>(), Z.<span class=\"pl-c1\">begin</span>());\n\n\t<span class=\"pl-c1\">transform</span>(<span class=\"pl-c1\">make_counting_iterator</span>(<span class=\"pl-c1\">0</span>), <span class=\"pl-c1\">make_counting_iterator</span>(N*K), <span class=\"pl-c1\">make_constant_iterator</span>(K), sub.<span class=\"pl-c1\">begin</span>(), thrust::divides&lt;<span class=\"pl-k\">int</span>&gt;());\n\n\t<span class=\"pl-c1\">transform</span>(Z.<span class=\"pl-c1\">begin</span>(), Z.<span class=\"pl-c1\">end</span>(), sub.<span class=\"pl-c1\">begin</span>(), Z.<span class=\"pl-c1\">begin</span>(), thrust::minus&lt;<span class=\"pl-k\">float</span>&gt;());\n}\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> Try to transform kernel into global function. Failed</span>\n<span class=\"pl-k\">__global__</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">kernel</span>(<span class=\"pl-k\">int</span>* Z, <span class=\"pl-k\">int</span>* counts, <span class=\"pl-k\">float</span>* ptr_probs, <span class=\"pl-k\">int</span> N, <span class=\"pl-k\">int</span> K) {\n\t<span class=\"pl-k\">int</span> idx = <span class=\"pl-c1\">threadIdx</span>.<span class=\"pl-smi\">x</span> + <span class=\"pl-c1\">blockIdx</span>.<span class=\"pl-smi\">x</span> * <span class=\"pl-c1\">blockDim</span>.<span class=\"pl-smi\">x</span>;\n\t<span class=\"pl-k\">int</span> stride = <span class=\"pl-c1\">blockDim</span>.<span class=\"pl-smi\">x</span> * <span class=\"pl-c1\">gridDim</span>.<span class=\"pl-smi\">x</span>;\n\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = idx; i &lt; N; i += stride) {\n\t\t<span class=\"pl-k\">int</span> length = counts[i];\n\t\tdevice_vector&lt;<span class=\"pl-k\">float</span>&gt; rnd_numbers = <span class=\"pl-c1\">double_random_uniform</span>(length);\n\t\t<span class=\"pl-k\">float</span>* ptr_rnd_numbers = <span class=\"pl-c1\">raw_pointer_cast</span>(rnd_numbers.<span class=\"pl-c1\">data</span>());\n\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> j = <span class=\"pl-c1\">0</span>; j &lt; length; j++) {\n\t\t\tZ[<span class=\"pl-c1\">searchsorted</span>(ptr_probs, i*K, (i + <span class=\"pl-c1\">1</span>)*K, ptr_rnd_numbers[j])] += <span class=\"pl-c1\">1</span>;\n\t\t}\n\t}\n}\n\ndevice_vector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-en\">multinomial</span>(device_vector&lt;<span class=\"pl-k\">int</span>&gt; &amp;counts, device_vector&lt;<span class=\"pl-k\">float</span>&gt; probs, <span class=\"pl-k\">int</span> N, <span class=\"pl-k\">int</span> K) {\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> probs -&gt; cumulative sum over rows</span>\n\t<span class=\"pl-c1\">cumsum</span>(probs, N, K);\n\tdevice_vector&lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">Z</span>(N*K, <span class=\"pl-c1\">0</span>);\n\n\t<span class=\"pl-k\">int</span>* ptr_counts = <span class=\"pl-c1\">raw_pointer_cast</span>(counts.<span class=\"pl-c1\">data</span>());\n\t<span class=\"pl-k\">float</span>* ptr_probs = <span class=\"pl-c1\">raw_pointer_cast</span>(probs.<span class=\"pl-c1\">data</span>());\n\n\tkernel<span class=\"pl-k\">&lt;&lt;&lt; <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">64</span> &gt;&gt;&gt;</span>(<span class=\"pl-c1\">raw_pointer_cast</span>(Z.<span class=\"pl-c1\">data</span>()), ptr_counts, ptr_probs, N, K);\n\n\t<span class=\"pl-k\">return</span> Z;\n}\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">void</span>)\n{\n\n\t<span class=\"pl-k\">int</span> nb_samples = <span class=\"pl-c1\">3</span>, pvals = <span class=\"pl-c1\">4</span>;\n\t<span class=\"pl-k\">int</span> low = <span class=\"pl-c1\">2000</span>, high = <span class=\"pl-c1\">3500</span>;\n\t\n\tdevice_vector&lt;<span class=\"pl-k\">int</span>&gt; counts = <span class=\"pl-c1\">random_uniform</span>(nb_samples, low, high);\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> Allocate 1 matrix on GPU</span>\n\tdevice_vector&lt;<span class=\"pl-k\">float</span>&gt; <span class=\"pl-c1\">d_probs</span>(nb_samples * pvals);\n\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> fill d_probs with random number s.t sum(rows) = 1</span>\n\t<span class=\"pl-c1\">GPU_fill_rand</span>(d_probs, nb_samples, pvals);\n\n\tdevice_vector&lt;<span class=\"pl-k\">int</span>&gt; res = <span class=\"pl-c1\">multinomial</span>(counts, d_probs, nb_samples, pvals);\n\n\t<span class=\"pl-c1\">print_matrix</span>(res, nb_samples, pvals);\n\n\t<span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>The idea for the CUDA implementation would be to use multiple threads to parallelize the double loop in the multinomial function. I think that should speed up the process quite a bit? I think having a x100 speed-up as compare to the simple CPU C++ implementation is reachable ?</p>", "body_text": "Hey.\nI didn't look too much into the paper you mentioned, but it seems that, if I'm not mistaken, that Theano implementation is based on the \"naive\" idea. See perform function at line 155. I didn't take the time to look at the GPU implementation here.\nHere is some benchmarks I did using numpy, C++ and I've also tried CUDA but didn't manage to fully implement it:\nAll the Benchmarks are more or less based on the same set-up (the random numbers associated to the\ncounts are sampled in [2000, 3500]. For this reason the numbers to sample might vary from one experiment to another one but on average the time remains the same).\nMy CPU: Intel(R) Xeon(R) E3-1505M v6 @ 3.00Ghz\nMy GPU (Cuda compatible): Quadro M1200, Driver: 390.65\n\nTheano: 0.0025s\nTensorFlow [actual code]: 0.045s\nTensorFlow [my version]: 0.015s\nNumpy code: 0.62s\nC++ [Compile with Ox]: 0.25s\nCUDA  [couldn't make it work]\n\nNumpy version:\nimport numpy as np\nimport time\n\ndef vmultinomial(counts, pvals):\n    N, K = pvals.shape\n    Z = np.zeros_like(pvals, dtype='int32')\n    cumsum = np.cumsum(pvals, axis=1, dtype='float64')\n    \n    for n in range(N):\n        size_ = counts[n]\n        rnd_numbers = np.random.uniform(size=size_)\n        for i in range(counts[n]):\n            Z[n, np.searchsorted(cumsum[n], rnd_numbers[i])] += 1\n    \n    return Z\n\nnb_distribution = 100\n\nu = np.random.randint(2000, 3500, size=nb_distribution)\nprobsn = np.random.uniform(size=(nb_distribution, 30))\nprobsn /= np.sum(probsn, axis=1)[:, None]\n\nstart_t = time.time()\nres = vmultinomial(u, probsn)\nprint(time.time() - start_t)\n**C++ code: **\n#include \"stdafx.h\"\n#include <iostream>\n#include <Eigen/Dense>\n#include <algorithm>\n#include <iostream>\n#include <random>\n#include <vector>\n#include <chrono>\n\nusing namespace std;\nusing Eigen::MatrixXd;\nusing namespace std::chrono;\n\n\nstatic vector<int> random_uniform(size_t size, int inf, int sup) {\n\tstatic uniform_int_distribution<int> distribution(inf, sup);\n\tstatic default_random_engine generator;\n\n\t// allocate a vector of size size\n\tvector<int> data(size);\n\tgenerate(data.begin(), data.end(), []() { return distribution(generator); });\n\n\treturn data;\n}\n\nstatic vector<double> double_random_uniform(size_t size) {\n\tstatic uniform_real_distribution<double> distribution(0.0, 1.0);\n\tstatic default_random_engine generator;\n\n\t// allocate a vector of size size\n\tvector<double> data(size);\n\tgenerate(data.begin(), data.end(), []() { return distribution(generator); });\n\n\treturn data;\n}\n\nMatrixXd probs_mat(size_t rows, size_t cols) {\n\tMatrixXd m = (MatrixXd::Random(rows, cols) + MatrixXd::Constant(rows, cols, 1.)) / 2;\n\tMatrixXd m2 = m.rowwise().sum();\n\n\tfor (int i = 0; i < rows; i++) {\n\t\tfor (int j = 0; j < cols; j++) {\n\t\t\tm(i, j) /= m2(i);\n\t\t}\n\t}\n\t\n\treturn m;\n}\n\nMatrixXd cumsum(MatrixXd pvals) {\n\tint N = pvals.rows(), K = pvals.cols();\n\tMatrixXd Z(N, K);\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tdouble sum = 0;\n\t\tfor (int j = 0; j < K; j++) {\n\t\t\tsum += pvals(i, j);\n\t\t\tZ(i, j) = sum;\n\t\t}\n\t}\n\n\treturn Z;\n}\n\nint searchsorted(MatrixXd csum, double rnd) {\n\tint beg = 0, end = csum.size();\n\n\twhile (beg <= end) {\n\t\tint mid = (beg + end) / 2;\n\t\tif (csum(mid) < rnd) {\n\t\t\tbeg = mid + 1;\n\t\t}\n\t\telse {\n\t\t\tend = mid - 1;\n\t\t}\n\t}\n\treturn beg;\n}\n\n\nMatrixXd multinomial(vector<int> counts, MatrixXd probs) {\n\tint N = probs.rows(), K = probs.cols();\n\tMatrixXd Z = MatrixXd::Zero(N, K);\n\n\tMatrixXd csum = cumsum(probs);\n\t\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tint length = counts[i];\n\t\tvector<double> rnd_numbers = double_random_uniform(length);\n\n\t\tfor (int j = 0; j < length; j++) {\n\t\t\tZ(i, searchsorted(csum.row(i), rnd_numbers[j])) += 1;\n\t\t}\n\t}\n\treturn Z;\n}\n\nint main()\n{\n\tint nb_samples = 100, pvals = 30;\n\tint low = 2000, high = 3500;\n\tvector<int> counts = random_uniform(nb_samples, low, high);\n\tMatrixXd probs = probs_mat(nb_samples, pvals);\n\t\n\n\thigh_resolution_clock::time_point t1 = high_resolution_clock::now();\n\tMatrixXd csum = multinomial(counts, probs);\n\thigh_resolution_clock::time_point t2 = high_resolution_clock::now();\n\n\tauto duration = duration_cast<microseconds>(t2 - t1).count();\n\n\tcout << duration << endl;\n\tsystem(\"pause\");\n}\nCUDA attempt:\n#include <iostream>\n#include <math.h>\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include <stdio.h>\n#include <ctime>\n\n#include <thrust/device_vector.h>\n#include <thrust/transform.h>\n#include <thrust/iterator/counting_iterator.h>\n#include <thrust/random.h>\n\n#include <cublas_v2.h>\n#include <curand.h>\n#include <thrust/functional.h>\n#include <thrust/iterator/counting_iterator.h>\n#include <thrust/iterator/constant_iterator.h>\n\nusing namespace std;\nusing namespace thrust;\n\nstruct prg\n{\n\tint a, b;\n\n\t__host__ __device__\n\t\tprg(int _a = 0, int _b = 1) : a(_a), b(_b) {};\n\n\t__host__ __device__\n\t\tint operator()(const unsigned int n) const\n\t{\n\t\tdefault_random_engine rng;\n\t\tuniform_int_distribution<int> dist(a, b);\n\t\trng.discard(n);\n\n\t\treturn dist(rng);\n\t}\n};\n\nstruct float_prg\n{\n\tint a, b;\n\n\t__host__ __device__\n\t\tfloat_prg(float _a = 0.0, float _b = 1.0) : a(_a), b(_b) {};\n\n\t__host__ __device__\n\t\tfloat operator()(const unsigned int n) const\n\t{\n\t\tdefault_random_engine rng;\n\t\tuniform_real_distribution<float> dist(a, b);\n\t\trng.discard(n);\n\n\t\treturn dist(rng);\n\t}\n};\n\n\nstatic device_vector<int> random_uniform(size_t size, int inf, int sup) {\n\n\t// allocate a vector of size size\n\tdevice_vector<int> data(size);\n\tcounting_iterator<unsigned int> index_sequence_begin(0);\n\n\ttransform(index_sequence_begin, index_sequence_begin + size, data.begin(), prg(inf, sup));\n\n\treturn data;\n}\n\n__host__ __device__\nstatic device_vector<float> double_random_uniform(size_t size) {\n\t// allocate a vector of size size\n\tdevice_vector<float> data(size);\n\tcounting_iterator<unsigned int> index_sequence_begin(0);\n\n\ttransform(index_sequence_begin, index_sequence_begin + size, data.begin(), float_prg(0.0, 1.0));\n\n\treturn data;\n}\n\n// don't care if this function doesn't use CUDA, I don't eval\n// its performance\nvoid normalize_l1(device_vector<float> &A, int rows, int cols) {\n\tfloat *row_sum = (float *)malloc(rows * sizeof(float));\n\n\tfor (int i = 0; i < rows; ++i) {\n\t\tfloat sum = 0.0f;\n\t\tfor (int j = 0; j < cols; ++j) {\n\t\t\tsum += A[cols*i + j];\n\t\t}\n\t\trow_sum[i] = sum;\n\t}\n\n\tfor (int r = 0; r < rows; ++r) {\n\t\tfor (int c = 0; c < cols; ++c) {\n\t\t\tA[r*cols + c] /= row_sum[r];\n\t\t}\n\t}\n}\n\nvoid GPU_fill_rand(device_vector<float> &A, int nr_rows_A, int nr_cols_A) {\n\t// Create a pseudo-random number generator\n\tcurandGenerator_t prng;\n\tcurandCreateGenerator(&prng, CURAND_RNG_PSEUDO_DEFAULT);\n\n\t// Set the seed for the random number generator using the system clock\n\tcurandSetPseudoRandomGeneratorSeed(prng, (unsigned long long) clock());\n\n\t// Fill the array with random numbers on the device\n\tcurandGenerateUniform(prng, raw_pointer_cast(&A[0]), nr_rows_A * nr_cols_A);\n\n\t// normalize the matrix\n\tnormalize_l1(A, nr_rows_A, nr_cols_A);\n\n}\n\ntemplate<class T>\nvoid print_matrix(const device_vector<T> &A, int nr_rows_A, int nr_cols_A) {\n\n\tfor (int i = 0; i < nr_rows_A; ++i) {\n\t\tfor (int j = 0; j < nr_cols_A; ++j) {\n\t\t\tcout << A[i * nr_cols_A + j] << \" \";\n\t\t}\n\t\tcout << endl;\n\t}\n\tcout << endl;\n}\n\n__device__\nint searchsorted(float* csum, int beg, int end, double rnd) {\n\n\twhile (beg <= end) {\n\t\tint mid = (beg + end) / 2;\n\t\tif (csum[mid] < rnd) {\n\t\t\tbeg = mid + 1;\n\t\t}\n\t\telse {\n\t\t\tend = mid - 1;\n\t\t}\n\t}\n\treturn beg;\n}\n\n// compute the cumulative sum over the row of the input matrix Z\nvoid cumsum(device_vector<float> &Z, int N, int K) {\n\n\tdevice_vector<float> cumProb(N*K, 0.);\n\tdevice_vector<float> sub(N*K);\n\n\tinclusive_scan(Z.begin(), Z.end(), Z.begin());\n\n\ttransform(make_counting_iterator(0), make_counting_iterator(N*K), make_constant_iterator(K), sub.begin(), thrust::divides<int>());\n\n\ttransform(Z.begin(), Z.end(), sub.begin(), Z.begin(), thrust::minus<float>());\n}\n\n// Try to transform kernel into global function. Failed\n__global__ void kernel(int* Z, int* counts, float* ptr_probs, int N, int K) {\n\tint idx = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor (int i = idx; i < N; i += stride) {\n\t\tint length = counts[i];\n\t\tdevice_vector<float> rnd_numbers = double_random_uniform(length);\n\t\tfloat* ptr_rnd_numbers = raw_pointer_cast(rnd_numbers.data());\n\n\t\tfor (int j = 0; j < length; j++) {\n\t\t\tZ[searchsorted(ptr_probs, i*K, (i + 1)*K, ptr_rnd_numbers[j])] += 1;\n\t\t}\n\t}\n}\n\ndevice_vector<int> multinomial(device_vector<int> &counts, device_vector<float> probs, int N, int K) {\n\t// probs -> cumulative sum over rows\n\tcumsum(probs, N, K);\n\tdevice_vector<int> Z(N*K, 0);\n\n\tint* ptr_counts = raw_pointer_cast(counts.data());\n\tfloat* ptr_probs = raw_pointer_cast(probs.data());\n\n\tkernel<<< 32, 64 >>>(raw_pointer_cast(Z.data()), ptr_counts, ptr_probs, N, K);\n\n\treturn Z;\n}\n\nint main(void)\n{\n\n\tint nb_samples = 3, pvals = 4;\n\tint low = 2000, high = 3500;\n\t\n\tdevice_vector<int> counts = random_uniform(nb_samples, low, high);\n\n\t// Allocate 1 matrix on GPU\n\tdevice_vector<float> d_probs(nb_samples * pvals);\n\n\t// fill d_probs with random number s.t sum(rows) = 1\n\tGPU_fill_rand(d_probs, nb_samples, pvals);\n\n\tdevice_vector<int> res = multinomial(counts, d_probs, nb_samples, pvals);\n\n\tprint_matrix(res, nb_samples, pvals);\n\n\treturn 0;\n}\nThe idea for the CUDA implementation would be to use multiple threads to parallelize the double loop in the multinomial function. I think that should speed up the process quite a bit? I think having a x100 speed-up as compare to the simple CPU C++ implementation is reachable ?", "body": "Hey.\r\n\r\nI didn't look too much into the paper you mentioned, but it seems that, if I'm not mistaken, that Theano implementation is based on the \"naive\" idea. See [perform](https://github.com/Theano/Theano/blob/master/theano/sandbox/multinomial.py) function at line 155. I didn't take the time to look at the GPU implementation [here](https://github.com/Theano/Theano/blob/master/theano/gpuarray/multinomial.py).\r\n\r\nHere is some benchmarks I did using numpy, C++ and I've also tried CUDA but didn't manage to fully implement it:\r\n\r\nAll the Benchmarks are more or less based on the same set-up (the random numbers associated to the \r\ncounts are sampled in **[2000, 3500]**. For this reason the numbers to sample might vary from one experiment to another one but on average the time remains the same).\r\n\r\nMy CPU: Intel(R) Xeon(R) E3-1505M v6 @ 3.00Ghz\r\nMy GPU (Cuda compatible): Quadro M1200, Driver: 390.65\r\n\r\n- Theano: 0.0025s\r\n- TensorFlow [actual code]: 0.045s\r\n- TensorFlow [my version]: 0.015s\r\n- Numpy code: 0.62s\r\n- C++ [Compile with Ox]: 0.25s\r\n- CUDA  [couldn't make it work]\r\n\r\n**Numpy version:**\r\n\r\n```python\r\nimport numpy as np\r\nimport time\r\n\r\ndef vmultinomial(counts, pvals):\r\n    N, K = pvals.shape\r\n    Z = np.zeros_like(pvals, dtype='int32')\r\n    cumsum = np.cumsum(pvals, axis=1, dtype='float64')\r\n    \r\n    for n in range(N):\r\n        size_ = counts[n]\r\n        rnd_numbers = np.random.uniform(size=size_)\r\n        for i in range(counts[n]):\r\n            Z[n, np.searchsorted(cumsum[n], rnd_numbers[i])] += 1\r\n    \r\n    return Z\r\n\r\nnb_distribution = 100\r\n\r\nu = np.random.randint(2000, 3500, size=nb_distribution)\r\nprobsn = np.random.uniform(size=(nb_distribution, 30))\r\nprobsn /= np.sum(probsn, axis=1)[:, None]\r\n\r\nstart_t = time.time()\r\nres = vmultinomial(u, probsn)\r\nprint(time.time() - start_t)\r\n```\r\n\r\n**C++ code: **\r\n\r\n```cpp\r\n#include \"stdafx.h\"\r\n#include <iostream>\r\n#include <Eigen/Dense>\r\n#include <algorithm>\r\n#include <iostream>\r\n#include <random>\r\n#include <vector>\r\n#include <chrono>\r\n\r\nusing namespace std;\r\nusing Eigen::MatrixXd;\r\nusing namespace std::chrono;\r\n\r\n\r\nstatic vector<int> random_uniform(size_t size, int inf, int sup) {\r\n\tstatic uniform_int_distribution<int> distribution(inf, sup);\r\n\tstatic default_random_engine generator;\r\n\r\n\t// allocate a vector of size size\r\n\tvector<int> data(size);\r\n\tgenerate(data.begin(), data.end(), []() { return distribution(generator); });\r\n\r\n\treturn data;\r\n}\r\n\r\nstatic vector<double> double_random_uniform(size_t size) {\r\n\tstatic uniform_real_distribution<double> distribution(0.0, 1.0);\r\n\tstatic default_random_engine generator;\r\n\r\n\t// allocate a vector of size size\r\n\tvector<double> data(size);\r\n\tgenerate(data.begin(), data.end(), []() { return distribution(generator); });\r\n\r\n\treturn data;\r\n}\r\n\r\nMatrixXd probs_mat(size_t rows, size_t cols) {\r\n\tMatrixXd m = (MatrixXd::Random(rows, cols) + MatrixXd::Constant(rows, cols, 1.)) / 2;\r\n\tMatrixXd m2 = m.rowwise().sum();\r\n\r\n\tfor (int i = 0; i < rows; i++) {\r\n\t\tfor (int j = 0; j < cols; j++) {\r\n\t\t\tm(i, j) /= m2(i);\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn m;\r\n}\r\n\r\nMatrixXd cumsum(MatrixXd pvals) {\r\n\tint N = pvals.rows(), K = pvals.cols();\r\n\tMatrixXd Z(N, K);\r\n\r\n\t#pragma omp parallel for\r\n\tfor (int i = 0; i < N; i++) {\r\n\t\tdouble sum = 0;\r\n\t\tfor (int j = 0; j < K; j++) {\r\n\t\t\tsum += pvals(i, j);\r\n\t\t\tZ(i, j) = sum;\r\n\t\t}\r\n\t}\r\n\r\n\treturn Z;\r\n}\r\n\r\nint searchsorted(MatrixXd csum, double rnd) {\r\n\tint beg = 0, end = csum.size();\r\n\r\n\twhile (beg <= end) {\r\n\t\tint mid = (beg + end) / 2;\r\n\t\tif (csum(mid) < rnd) {\r\n\t\t\tbeg = mid + 1;\r\n\t\t}\r\n\t\telse {\r\n\t\t\tend = mid - 1;\r\n\t\t}\r\n\t}\r\n\treturn beg;\r\n}\r\n\r\n\r\nMatrixXd multinomial(vector<int> counts, MatrixXd probs) {\r\n\tint N = probs.rows(), K = probs.cols();\r\n\tMatrixXd Z = MatrixXd::Zero(N, K);\r\n\r\n\tMatrixXd csum = cumsum(probs);\r\n\t\r\n#pragma omp parallel for\r\n\tfor (int i = 0; i < N; i++) {\r\n\t\tint length = counts[i];\r\n\t\tvector<double> rnd_numbers = double_random_uniform(length);\r\n\r\n\t\tfor (int j = 0; j < length; j++) {\r\n\t\t\tZ(i, searchsorted(csum.row(i), rnd_numbers[j])) += 1;\r\n\t\t}\r\n\t}\r\n\treturn Z;\r\n}\r\n\r\nint main()\r\n{\r\n\tint nb_samples = 100, pvals = 30;\r\n\tint low = 2000, high = 3500;\r\n\tvector<int> counts = random_uniform(nb_samples, low, high);\r\n\tMatrixXd probs = probs_mat(nb_samples, pvals);\r\n\t\r\n\r\n\thigh_resolution_clock::time_point t1 = high_resolution_clock::now();\r\n\tMatrixXd csum = multinomial(counts, probs);\r\n\thigh_resolution_clock::time_point t2 = high_resolution_clock::now();\r\n\r\n\tauto duration = duration_cast<microseconds>(t2 - t1).count();\r\n\r\n\tcout << duration << endl;\r\n\tsystem(\"pause\");\r\n}\r\n```\r\n\r\n**CUDA attempt:**\r\n```cuda\r\n#include <iostream>\r\n#include <math.h>\r\n#include \"cuda_runtime.h\"\r\n#include \"device_launch_parameters.h\"\r\n#include <stdio.h>\r\n#include <ctime>\r\n\r\n#include <thrust/device_vector.h>\r\n#include <thrust/transform.h>\r\n#include <thrust/iterator/counting_iterator.h>\r\n#include <thrust/random.h>\r\n\r\n#include <cublas_v2.h>\r\n#include <curand.h>\r\n#include <thrust/functional.h>\r\n#include <thrust/iterator/counting_iterator.h>\r\n#include <thrust/iterator/constant_iterator.h>\r\n\r\nusing namespace std;\r\nusing namespace thrust;\r\n\r\nstruct prg\r\n{\r\n\tint a, b;\r\n\r\n\t__host__ __device__\r\n\t\tprg(int _a = 0, int _b = 1) : a(_a), b(_b) {};\r\n\r\n\t__host__ __device__\r\n\t\tint operator()(const unsigned int n) const\r\n\t{\r\n\t\tdefault_random_engine rng;\r\n\t\tuniform_int_distribution<int> dist(a, b);\r\n\t\trng.discard(n);\r\n\r\n\t\treturn dist(rng);\r\n\t}\r\n};\r\n\r\nstruct float_prg\r\n{\r\n\tint a, b;\r\n\r\n\t__host__ __device__\r\n\t\tfloat_prg(float _a = 0.0, float _b = 1.0) : a(_a), b(_b) {};\r\n\r\n\t__host__ __device__\r\n\t\tfloat operator()(const unsigned int n) const\r\n\t{\r\n\t\tdefault_random_engine rng;\r\n\t\tuniform_real_distribution<float> dist(a, b);\r\n\t\trng.discard(n);\r\n\r\n\t\treturn dist(rng);\r\n\t}\r\n};\r\n\r\n\r\nstatic device_vector<int> random_uniform(size_t size, int inf, int sup) {\r\n\r\n\t// allocate a vector of size size\r\n\tdevice_vector<int> data(size);\r\n\tcounting_iterator<unsigned int> index_sequence_begin(0);\r\n\r\n\ttransform(index_sequence_begin, index_sequence_begin + size, data.begin(), prg(inf, sup));\r\n\r\n\treturn data;\r\n}\r\n\r\n__host__ __device__\r\nstatic device_vector<float> double_random_uniform(size_t size) {\r\n\t// allocate a vector of size size\r\n\tdevice_vector<float> data(size);\r\n\tcounting_iterator<unsigned int> index_sequence_begin(0);\r\n\r\n\ttransform(index_sequence_begin, index_sequence_begin + size, data.begin(), float_prg(0.0, 1.0));\r\n\r\n\treturn data;\r\n}\r\n\r\n// don't care if this function doesn't use CUDA, I don't eval\r\n// its performance\r\nvoid normalize_l1(device_vector<float> &A, int rows, int cols) {\r\n\tfloat *row_sum = (float *)malloc(rows * sizeof(float));\r\n\r\n\tfor (int i = 0; i < rows; ++i) {\r\n\t\tfloat sum = 0.0f;\r\n\t\tfor (int j = 0; j < cols; ++j) {\r\n\t\t\tsum += A[cols*i + j];\r\n\t\t}\r\n\t\trow_sum[i] = sum;\r\n\t}\r\n\r\n\tfor (int r = 0; r < rows; ++r) {\r\n\t\tfor (int c = 0; c < cols; ++c) {\r\n\t\t\tA[r*cols + c] /= row_sum[r];\r\n\t\t}\r\n\t}\r\n}\r\n\r\nvoid GPU_fill_rand(device_vector<float> &A, int nr_rows_A, int nr_cols_A) {\r\n\t// Create a pseudo-random number generator\r\n\tcurandGenerator_t prng;\r\n\tcurandCreateGenerator(&prng, CURAND_RNG_PSEUDO_DEFAULT);\r\n\r\n\t// Set the seed for the random number generator using the system clock\r\n\tcurandSetPseudoRandomGeneratorSeed(prng, (unsigned long long) clock());\r\n\r\n\t// Fill the array with random numbers on the device\r\n\tcurandGenerateUniform(prng, raw_pointer_cast(&A[0]), nr_rows_A * nr_cols_A);\r\n\r\n\t// normalize the matrix\r\n\tnormalize_l1(A, nr_rows_A, nr_cols_A);\r\n\r\n}\r\n\r\ntemplate<class T>\r\nvoid print_matrix(const device_vector<T> &A, int nr_rows_A, int nr_cols_A) {\r\n\r\n\tfor (int i = 0; i < nr_rows_A; ++i) {\r\n\t\tfor (int j = 0; j < nr_cols_A; ++j) {\r\n\t\t\tcout << A[i * nr_cols_A + j] << \" \";\r\n\t\t}\r\n\t\tcout << endl;\r\n\t}\r\n\tcout << endl;\r\n}\r\n\r\n__device__\r\nint searchsorted(float* csum, int beg, int end, double rnd) {\r\n\r\n\twhile (beg <= end) {\r\n\t\tint mid = (beg + end) / 2;\r\n\t\tif (csum[mid] < rnd) {\r\n\t\t\tbeg = mid + 1;\r\n\t\t}\r\n\t\telse {\r\n\t\t\tend = mid - 1;\r\n\t\t}\r\n\t}\r\n\treturn beg;\r\n}\r\n\r\n// compute the cumulative sum over the row of the input matrix Z\r\nvoid cumsum(device_vector<float> &Z, int N, int K) {\r\n\r\n\tdevice_vector<float> cumProb(N*K, 0.);\r\n\tdevice_vector<float> sub(N*K);\r\n\r\n\tinclusive_scan(Z.begin(), Z.end(), Z.begin());\r\n\r\n\ttransform(make_counting_iterator(0), make_counting_iterator(N*K), make_constant_iterator(K), sub.begin(), thrust::divides<int>());\r\n\r\n\ttransform(Z.begin(), Z.end(), sub.begin(), Z.begin(), thrust::minus<float>());\r\n}\r\n\r\n// Try to transform kernel into global function. Failed\r\n__global__ void kernel(int* Z, int* counts, float* ptr_probs, int N, int K) {\r\n\tint idx = threadIdx.x + blockIdx.x * blockDim.x;\r\n\tint stride = blockDim.x * gridDim.x;\r\n\r\n\tfor (int i = idx; i < N; i += stride) {\r\n\t\tint length = counts[i];\r\n\t\tdevice_vector<float> rnd_numbers = double_random_uniform(length);\r\n\t\tfloat* ptr_rnd_numbers = raw_pointer_cast(rnd_numbers.data());\r\n\r\n\t\tfor (int j = 0; j < length; j++) {\r\n\t\t\tZ[searchsorted(ptr_probs, i*K, (i + 1)*K, ptr_rnd_numbers[j])] += 1;\r\n\t\t}\r\n\t}\r\n}\r\n\r\ndevice_vector<int> multinomial(device_vector<int> &counts, device_vector<float> probs, int N, int K) {\r\n\t// probs -> cumulative sum over rows\r\n\tcumsum(probs, N, K);\r\n\tdevice_vector<int> Z(N*K, 0);\r\n\r\n\tint* ptr_counts = raw_pointer_cast(counts.data());\r\n\tfloat* ptr_probs = raw_pointer_cast(probs.data());\r\n\r\n\tkernel<<< 32, 64 >>>(raw_pointer_cast(Z.data()), ptr_counts, ptr_probs, N, K);\r\n\r\n\treturn Z;\r\n}\r\n\r\nint main(void)\r\n{\r\n\r\n\tint nb_samples = 3, pvals = 4;\r\n\tint low = 2000, high = 3500;\r\n\t\r\n\tdevice_vector<int> counts = random_uniform(nb_samples, low, high);\r\n\r\n\t// Allocate 1 matrix on GPU\r\n\tdevice_vector<float> d_probs(nb_samples * pvals);\r\n\r\n\t// fill d_probs with random number s.t sum(rows) = 1\r\n\tGPU_fill_rand(d_probs, nb_samples, pvals);\r\n\r\n\tdevice_vector<int> res = multinomial(counts, d_probs, nb_samples, pvals);\r\n\r\n\tprint_matrix(res, nb_samples, pvals);\r\n\r\n\treturn 0;\r\n}\r\n```\r\n\r\nThe idea for the CUDA implementation would be to use multiple threads to parallelize the double loop in the multinomial function. I think that should speed up the process quite a bit? I think having a x100 speed-up as compare to the simple CPU C++ implementation is reachable ?\r\n"}