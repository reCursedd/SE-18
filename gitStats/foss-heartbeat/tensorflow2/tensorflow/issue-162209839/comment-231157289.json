{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231157289", "html_url": "https://github.com/tensorflow/tensorflow/pull/3031#issuecomment-231157289", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3031", "id": 231157289, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTE1NzI4OQ==", "user": {"login": "concretevitamin", "id": 592670, "node_id": "MDQ6VXNlcjU5MjY3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/592670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/concretevitamin", "html_url": "https://github.com/concretevitamin", "followers_url": "https://api.github.com/users/concretevitamin/followers", "following_url": "https://api.github.com/users/concretevitamin/following{/other_user}", "gists_url": "https://api.github.com/users/concretevitamin/gists{/gist_id}", "starred_url": "https://api.github.com/users/concretevitamin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/concretevitamin/subscriptions", "organizations_url": "https://api.github.com/users/concretevitamin/orgs", "repos_url": "https://api.github.com/users/concretevitamin/repos", "events_url": "https://api.github.com/users/concretevitamin/events{/privacy}", "received_events_url": "https://api.github.com/users/concretevitamin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-07T17:56:56Z", "updated_at": "2016-07-07T17:56:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Sorry for the delay.</p>\n<p>I don't quite understand why <code>tf.gather()</code> comes into place here, given the two new requirements?</p>\n<p>Here's one potential solution -- I haven't thought through the details! -- recall <code>indicies : [NNZ, NDIM]</code> and <code>values : [NNZ]</code>.</p>\n<p>We first unpack/split <code>indices</code> into <code>[NNZ, 1, ..., 1]</code> with <code>NDIM</code> ones in the end.  We concatenate it with <code>values</code>, obtaining a tensor with shape <code>[NNZ] + [1]*NDIM + [1]</code>.</p>\n<p>Now we call <code>tf.transpose()</code> on this concatenated tensor, with <code>perm = [0] + user_perm + [NDIM + 1]</code>, namely we permute the middle indices.  Finally, transform the shape back and split again.</p>\n<p>If this doesn't work, perhaps we'll need a C++ native kernel.</p>", "body_text": "Sorry for the delay.\nI don't quite understand why tf.gather() comes into place here, given the two new requirements?\nHere's one potential solution -- I haven't thought through the details! -- recall indicies : [NNZ, NDIM] and values : [NNZ].\nWe first unpack/split indices into [NNZ, 1, ..., 1] with NDIM ones in the end.  We concatenate it with values, obtaining a tensor with shape [NNZ] + [1]*NDIM + [1].\nNow we call tf.transpose() on this concatenated tensor, with perm = [0] + user_perm + [NDIM + 1], namely we permute the middle indices.  Finally, transform the shape back and split again.\nIf this doesn't work, perhaps we'll need a C++ native kernel.", "body": "Sorry for the delay.\n\nI don't quite understand why `tf.gather()` comes into place here, given the two new requirements?\n\nHere's one potential solution -- I haven't thought through the details! -- recall `indicies : [NNZ, NDIM]` and `values : [NNZ]`.  \n\nWe first unpack/split `indices` into `[NNZ, 1, ..., 1]` with `NDIM` ones in the end.  We concatenate it with `values`, obtaining a tensor with shape `[NNZ] + [1]*NDIM + [1]`.  \n\nNow we call `tf.transpose()` on this concatenated tensor, with `perm = [0] + user_perm + [NDIM + 1]`, namely we permute the middle indices.  Finally, transform the shape back and split again.  \n\nIf this doesn't work, perhaps we'll need a C++ native kernel.\n"}