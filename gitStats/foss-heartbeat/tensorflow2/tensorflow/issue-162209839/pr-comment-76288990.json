{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76288990", "pull_request_review_id": null, "id": 76288990, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc2Mjg4OTkw", "diff_hunk": "@@ -1582,3 +1583,49 @@ def _SparseSparseMaximumMinimumShape(op):  # pylint: disable=invalid-name\n   op.inputs[4].get_shape().assert_has_rank(1)  # b_values\n   op.inputs[5].get_shape().assert_has_rank(1)  # b_shape\n   return [tensor_shape.unknown_shape(2), tensor_shape.unknown_shape(1)]\n+\n+\n+def sparse_transpose(sp_input, perm=None, name=None):\n+  \"\"\"Transposes a `SparseTensor`\n+\n+  The returned tensor's dimension i will correspond to the input dimension\n+  `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n+  the rank of the input tensor. Hence by default, this operation performs a\n+  regular matrix transpose on 2-D input Tensors.\n+\n+  For example, if `sp_input` has shape `[4, 5]` and `indices` / `values`:\n+\n+      [0, 3]: b\n+      [0, 1]: a\n+      [3, 1]: d\n+      [2, 0]: c\n+\n+  then the output will be a `SparseTensor` of shape `[5, 4]` and\n+  `indices` / `values`:\n+\n+      [0, 2]: c\n+      [1, 0]: a\n+      [1, 3]: d\n+      [3, 0]: b\n+\n+  Args:\n+    sp_input: The input `SparseTensor`.\n+    perm: A permutation of the dimensions of `sp_input`.\n+    name: A name prefix for the returned tensors (optional)\n+  Returns:\n+    A transposed `SparseTensor`.\n+\n+  Raises:\n+    TypeError: If `sp_input` is not a `SparseTensor`.\n+  \"\"\"\n+  with ops.op_scope([sp_input], name, \"SparseTranspose\") as name:", "path": "tensorflow/python/ops/sparse_ops.py", "position": 47, "original_position": 47, "commit_id": "226d459c3fa53807263bf66cf848b7225184e6e2", "original_commit_id": "c596b33257abf584aaaedff3a6268cabe3c67cef", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "@maniteja123 You are right, let's keep it as a separate function for now. I think if you extend the tests to cover rank > 2 tensors, we should be good. Maybe it would be easier to generate random sparse tensors and use tf.sparse_tensor_to_dense(t) to convert it to dense, transpose the dense and compare with the \"densified\" version of the output from your function. See e.g. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_ops_test.py#L721\n", "created_at": "2016-08-25T17:33:18Z", "updated_at": "2016-08-26T06:11:15Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/3031#discussion_r76288990", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3031", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/76288990"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/3031#discussion_r76288990"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3031"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6291963\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/maniteja123\">@maniteja123</a> You are right, let's keep it as a separate function for now. I think if you extend the tests to cover rank &gt; 2 tensors, we should be good. Maybe it would be easier to generate random sparse tensors and use tf.sparse_tensor_to_dense(t) to convert it to dense, transpose the dense and compare with the \"densified\" version of the output from your function. See e.g. <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_ops_test.py#L721\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_ops_test.py#L721</a></p>", "body_text": "@maniteja123 You are right, let's keep it as a separate function for now. I think if you extend the tests to cover rank > 2 tensors, we should be good. Maybe it would be easier to generate random sparse tensors and use tf.sparse_tensor_to_dense(t) to convert it to dense, transpose the dense and compare with the \"densified\" version of the output from your function. See e.g. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_ops_test.py#L721", "in_reply_to_id": 74337198}