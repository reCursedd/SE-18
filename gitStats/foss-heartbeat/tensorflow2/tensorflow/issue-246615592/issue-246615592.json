{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11894", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11894/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11894/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11894/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11894", "id": 246615592, "node_id": "MDU6SXNzdWUyNDY2MTU1OTI=", "number": 11894, "title": "Slow Hessian", "user": {"login": "amehrjou", "id": 17348736, "node_id": "MDQ6VXNlcjE3MzQ4NzM2", "avatar_url": "https://avatars2.githubusercontent.com/u/17348736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amehrjou", "html_url": "https://github.com/amehrjou", "followers_url": "https://api.github.com/users/amehrjou/followers", "following_url": "https://api.github.com/users/amehrjou/following{/other_user}", "gists_url": "https://api.github.com/users/amehrjou/gists{/gist_id}", "starred_url": "https://api.github.com/users/amehrjou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amehrjou/subscriptions", "organizations_url": "https://api.github.com/users/amehrjou/orgs", "repos_url": "https://api.github.com/users/amehrjou/repos", "events_url": "https://api.github.com/users/amehrjou/events{/privacy}", "received_events_url": "https://api.github.com/users/amehrjou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-07-30T23:14:18Z", "updated_at": "2018-01-18T19:36:56Z", "closed_at": "2018-01-18T19:36:56Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: I have written custom code</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: 4.4.0-47-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116013936\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/68\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/68/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/68\">#68</a>-Ubuntu and Also macOS Sierra 10.12.3 (CPU only)</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: cuda/8.0 and cudnn/5.1</li>\n<li><strong>GPU model and memory</strong>: 12GB, memory:100GB</li>\n<li><strong>Exact command to reproduce</strong>: tf.hessians(ys,xs)</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>The command tf.hessians(ys, xs) is used to add nodes to the graph in order to compute hessians of ys with respect to xs where both ys and xs are list of tensors. Currently computing hessian with respect to a vector is not possible. The trick is to unstack the input tensor (x) into a list of one dimensional tensors (xs) and compute hessian with respect to each of them separately then stack them together. Tensorflow gets stuck in the phase of graph construction even when the dimension of x (length of list xs) is about one hundred. In the implementation of Hessian in gradients_impl.py the second derivative is implemented as the derivative of partial derivative with respect to each member of xs. I guess the slowness of graph construction is due to this line:</p>\n<p>_hess = [gradients(_gradient, x, **kwargs)[0] for _gradient in _gradients]</p>\n<p>which may add several unnecessary intermediate nodes with overlapping functionality to the graph due to the for loop. Is there any way other than looping over input dimensions that efficiently constructs the graph in a reasonable time?</p>\n<h3>Source code / logs</h3>\n<p>This source code can simulate the problem:<br>\nimport tensorflow as tf<br>\nimport numpy as np<br>\nin_dimension = 256<br>\nx = tf.placeholder(tf.float32, shape=(1, in_dimension))<br>\nx_list = tf.unstack(x, axis=1)<br>\nxx= tf.stack(x_list, axis=1)<br>\ny = tf.pow(xx,3)<br>\nhess = tf.hessians(y, x_list)<br>\nsess = tf.Session()<br>\nprint(sess.run(hess, feed_dict={x : np.random.normal(0, 1, size=(1, in_dimension))}))</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): I have written custom code\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 4.4.0-47-generic #68-Ubuntu and Also macOS Sierra 10.12.3 (CPU only)\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1\nPython version: 3.6\nBazel version (if compiling from source):\nCUDA/cuDNN version: cuda/8.0 and cudnn/5.1\nGPU model and memory: 12GB, memory:100GB\nExact command to reproduce: tf.hessians(ys,xs)\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nThe command tf.hessians(ys, xs) is used to add nodes to the graph in order to compute hessians of ys with respect to xs where both ys and xs are list of tensors. Currently computing hessian with respect to a vector is not possible. The trick is to unstack the input tensor (x) into a list of one dimensional tensors (xs) and compute hessian with respect to each of them separately then stack them together. Tensorflow gets stuck in the phase of graph construction even when the dimension of x (length of list xs) is about one hundred. In the implementation of Hessian in gradients_impl.py the second derivative is implemented as the derivative of partial derivative with respect to each member of xs. I guess the slowness of graph construction is due to this line:\n_hess = [gradients(_gradient, x, **kwargs)[0] for _gradient in _gradients]\nwhich may add several unnecessary intermediate nodes with overlapping functionality to the graph due to the for loop. Is there any way other than looping over input dimensions that efficiently constructs the graph in a reasonable time?\nSource code / logs\nThis source code can simulate the problem:\nimport tensorflow as tf\nimport numpy as np\nin_dimension = 256\nx = tf.placeholder(tf.float32, shape=(1, in_dimension))\nx_list = tf.unstack(x, axis=1)\nxx= tf.stack(x_list, axis=1)\ny = tf.pow(xx,3)\nhess = tf.hessians(y, x_list)\nsess = tf.Session()\nprint(sess.run(hess, feed_dict={x : np.random.normal(0, 1, size=(1, in_dimension))}))", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have written custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.4.0-47-generic #68-Ubuntu and Also macOS Sierra 10.12.3 (CPU only) \r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: cuda/8.0 and cudnn/5.1\r\n- **GPU model and memory**: 12GB, memory:100GB\r\n- **Exact command to reproduce**: tf.hessians(ys,xs)\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nThe command tf.hessians(ys, xs) is used to add nodes to the graph in order to compute hessians of ys with respect to xs where both ys and xs are list of tensors. Currently computing hessian with respect to a vector is not possible. The trick is to unstack the input tensor (x) into a list of one dimensional tensors (xs) and compute hessian with respect to each of them separately then stack them together. Tensorflow gets stuck in the phase of graph construction even when the dimension of x (length of list xs) is about one hundred. In the implementation of Hessian in gradients_impl.py the second derivative is implemented as the derivative of partial derivative with respect to each member of xs. I guess the slowness of graph construction is due to this line:\r\n\r\n_hess = [gradients(_gradient, x, **kwargs)[0] for _gradient in _gradients]\r\n\r\nwhich may add several unnecessary intermediate nodes with overlapping functionality to the graph due to the for loop. Is there any way other than looping over input dimensions that efficiently constructs the graph in a reasonable time?\r\n\r\n### Source code / logs\r\nThis source code can simulate the problem:\r\nimport tensorflow as tf\r\nimport numpy as np\r\nin_dimension = 256\r\nx = tf.placeholder(tf.float32, shape=(1, in_dimension))\r\nx_list = tf.unstack(x, axis=1)\r\nxx= tf.stack(x_list, axis=1)\r\ny = tf.pow(xx,3)\r\nhess = tf.hessians(y, x_list)\r\nsess = tf.Session()\r\nprint(sess.run(hess, feed_dict={x : np.random.normal(0, 1, size=(1, in_dimension))}))\r\n"}