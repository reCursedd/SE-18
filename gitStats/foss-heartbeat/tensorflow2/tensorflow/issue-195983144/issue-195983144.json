{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6353", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6353/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6353/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6353/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/6353", "id": 195983144, "node_id": "MDExOlB1bGxSZXF1ZXN0OTgyODAwOTk=", "number": 6353, "title": "online add worker to  Running a distributed training session", "user": {"login": "guoying1030", "id": 17998982, "node_id": "MDQ6VXNlcjE3OTk4OTgy", "avatar_url": "https://avatars2.githubusercontent.com/u/17998982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guoying1030", "html_url": "https://github.com/guoying1030", "followers_url": "https://api.github.com/users/guoying1030/followers", "following_url": "https://api.github.com/users/guoying1030/following{/other_user}", "gists_url": "https://api.github.com/users/guoying1030/gists{/gist_id}", "starred_url": "https://api.github.com/users/guoying1030/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guoying1030/subscriptions", "organizations_url": "https://api.github.com/users/guoying1030/orgs", "repos_url": "https://api.github.com/users/guoying1030/repos", "events_url": "https://api.github.com/users/guoying1030/events{/privacy}", "received_events_url": "https://api.github.com/users/guoying1030/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2016-12-16T05:20:14Z", "updated_at": "2016-12-18T04:30:33Z", "closed_at": "2016-12-16T18:19:06Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6353", "html_url": "https://github.com/tensorflow/tensorflow/pull/6353", "diff_url": "https://github.com/tensorflow/tensorflow/pull/6353.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/6353.patch"}, "body_html": "<p>When you use distributed tensorflow for training tasks, if you start your quest, it has been running for a long time. At this point you find that the number of workers to start too little, so can not be a good convergence.</p>\n<p>At this point, you should increase the worker online to the distributed training tasks.</p>\n<p>example:</p>\n<h1>On ps0.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 0</p>\n<h1>On ps1.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 1</p>\n<h1>On worker0.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 0</p>\n<h1>On worker1.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 1</p>\n<p>When you start, then, you need to increase worker2.example.com:2222, should do so:</p>\n<h1>Write a python script:,note must call all ps servers</h1>\n<p>import tensorflow as tf<br>\ndef main (_):<br>\n\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps0.example.com:2222') as sess:<br>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')</p>\n<p>\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps1.example.com:2222') as sess:<br>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')</p>\n<p>if <strong>name</strong> == \"<strong>main</strong>\":<br>\n\u00a0\u00a0\u00a0\u00a0tf.app.run ()</p>\n<p>Then  run  this  python script:,</p>\n<h1>On worker2.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = worker --task_index = 2</p>\n<p>#Then you can see worrker has started training</p>\n<p>#If ps  nodes in the cluster restart, remember to start with the worker2.</p>\n<p>For example ps0 restart, you must start:</p>\n<h1>On ps0.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 0</p>\n<p>if  ps1 restart, you must start:</p>\n<h1>On ps1.example.com:</h1>\n<p>$ python trainer.py <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 <br>\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 1</p>\n<p>Can continue to train.</p>", "body_text": "When you use distributed tensorflow for training tasks, if you start your quest, it has been running for a long time. At this point you find that the number of workers to start too little, so can not be a good convergence.\nAt this point, you should increase the worker online to the distributed training tasks.\nexample:\nOn ps0.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 0\nOn ps1.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 1\nOn worker0.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 0\nOn worker1.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 1\nWhen you start, then, you need to increase worker2.example.com:2222, should do so:\nWrite a python script:,note must call all ps servers\nimport tensorflow as tf\ndef main (_):\n\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps0.example.com:2222') as sess:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')\n\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps1.example.com:2222') as sess:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')\nif name == \"main\":\n\u00a0\u00a0\u00a0\u00a0tf.app.run ()\nThen  run  this  python script:,\nOn worker2.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = worker --task_index = 2\n#Then you can see worrker has started training\n#If ps  nodes in the cluster restart, remember to start with the worker2.\nFor example ps0 restart, you must start:\nOn ps0.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 0\nif  ps1 restart, you must start:\nOn ps1.example.com:\n$ python trainer.py \n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 1\nCan continue to train.", "body": "When you use distributed tensorflow for training tasks, if you start your quest, it has been running for a long time. At this point you find that the number of workers to start too little, so can not be a good convergence.\r\n\r\nAt this point, you should increase the worker online to the distributed training tasks.\r\n\r\nexample:\r\n# On ps0.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 0\r\n# On ps1.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = ps --task_index = 1\r\n# On worker0.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 0\r\n# On worker1.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--job_name = worker --task_index = 1\r\n\r\nWhen you start, then, you need to increase worker2.example.com:2222, should do so:\r\n\r\n# Write a python script:,note must call all ps servers\r\nimport tensorflow as tf\r\ndef main (_):\r\n\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps0.example.com:2222') as sess:\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')\r\n\r\n\r\n\u00a0\u00a0\u00a0\u00a0with tf.Session ('grpc: //ps1.example.com:2222') as sess:\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sess.add_onlineworker (2, 'worker2.example.com: 2222')\r\n\r\nif __name__ == \"__main__\":\r\n\u00a0\u00a0\u00a0\u00a0tf.app.run ()\r\n\r\nThen  run  this  python script:,\r\n\r\n# On worker2.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = worker --task_index = 2\r\n\r\n\r\n#Then you can see worrker has started training\r\n\r\n#If ps  nodes in the cluster restart, remember to start with the worker2.\r\n\r\nFor example ps0 restart, you must start:\r\n# On ps0.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 0\r\n\r\nif  ps1 restart, you must start:\r\n# On ps1.example.com:\r\n$ python trainer.py \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \\\r\n\u00a0\u00a0\u00a0\u00a0--worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222, \\\r\n\u00a0\u00a0\u00a0\u00a0\u00a0--worker2.example.com:2222 --job_name = ps --task_index = 1\r\n\r\n\r\n\r\n\r\nCan continue to train."}