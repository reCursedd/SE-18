{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310159451", "html_url": "https://github.com/tensorflow/tensorflow/issues/10769#issuecomment-310159451", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10769", "id": 310159451, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDE1OTQ1MQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-21T18:04:39Z", "updated_at": "2017-06-21T18:04:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm not sure exactly what TensorBoard is visualizing, but it <a href=\"https://github.com/tensorflow/tensorboard/blob/6aa3dba050c7a89e826051443a836f07c2e82913/tensorboard/plugins/graphs/tf_graph_common/graph.ts#L427\">looks like</a> it's summing up the <code>total_bytes</code> fields from some subset of the nodes in a graph. These values represent the sum of all bytes <em>allocated</em> during the execution of an op, but don't account for when those bytes are <em>deallocated</em>. Therefore it's perfectly reasonable for them to sum to a larger value than the total memory in a device.</p>", "body_text": "I'm not sure exactly what TensorBoard is visualizing, but it looks like it's summing up the total_bytes fields from some subset of the nodes in a graph. These values represent the sum of all bytes allocated during the execution of an op, but don't account for when those bytes are deallocated. Therefore it's perfectly reasonable for them to sum to a larger value than the total memory in a device.", "body": "I'm not sure exactly what TensorBoard is visualizing, but it [looks like](https://github.com/tensorflow/tensorboard/blob/6aa3dba050c7a89e826051443a836f07c2e82913/tensorboard/plugins/graphs/tf_graph_common/graph.ts#L427) it's summing up the `total_bytes` fields from some subset of the nodes in a graph. These values represent the sum of all bytes *allocated* during the execution of an op, but don't account for when those bytes are *deallocated*. Therefore it's perfectly reasonable for them to sum to a larger value than the total memory in a device."}