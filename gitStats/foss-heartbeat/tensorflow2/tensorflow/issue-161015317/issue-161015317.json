{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2944", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2944/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2944/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2944/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2944", "id": 161015317, "node_id": "MDU6SXNzdWUxNjEwMTUzMTc=", "number": 2944, "title": "Errors while running Translate.py sample code with multiple GPUS", "user": {"login": "suraj1990", "id": 5551707, "node_id": "MDQ6VXNlcjU1NTE3MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5551707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suraj1990", "html_url": "https://github.com/suraj1990", "followers_url": "https://api.github.com/users/suraj1990/followers", "following_url": "https://api.github.com/users/suraj1990/following{/other_user}", "gists_url": "https://api.github.com/users/suraj1990/gists{/gist_id}", "starred_url": "https://api.github.com/users/suraj1990/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suraj1990/subscriptions", "organizations_url": "https://api.github.com/users/suraj1990/orgs", "repos_url": "https://api.github.com/users/suraj1990/repos", "events_url": "https://api.github.com/users/suraj1990/events{/privacy}", "received_events_url": "https://api.github.com/users/suraj1990/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-06-18T09:12:29Z", "updated_at": "2016-06-30T05:22:59Z", "closed_at": "2016-06-30T05:22:59Z", "author_association": "NONE", "body_html": "<p>GitHub issues are for bugs / installation problems / feature requests.<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu</p>\n<p>Installed version of CUDA and cuDNN: 7.5 and 7<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>. 0.8</li>\n</ol>\n<p>If installed from sources, provide the commit hash:</p>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>running the translate.py example<br>\n2.Crashes while creating models after tokenizing the training data.</li>\n</ol>\n<p>The sample code seems to run fine with single GPU of 4 GB memory. I am using AWS GPU instances. But it works fine for basic values, ie vocab size of 40000 and size of 512. I want to train on a vocab size of 500000 and size of 1024. This is the reason why I opted to go for 4 GPUs now.<br>\n(In AWS terms, g2.2xlarge to g2.8xlarge).<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5551707/16170060/c599bef8-3562-11e6-9723-4a38999c6a43.png\"><img src=\"https://cloud.githubusercontent.com/assets/5551707/16170060/c599bef8-3562-11e6-9723-4a38999c6a43.png\" alt=\"g2-8xlarge-crash\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5551707/16170062/d7a121fe-3562-11e6-928e-3270ebaa44b9.png\"><img src=\"https://cloud.githubusercontent.com/assets/5551707/16170062/d7a121fe-3562-11e6-928e-3270ebaa44b9.png\" alt=\"nvidia-smi-details\" style=\"max-width:100%;\"></a></p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>", "body_text": "GitHub issues are for bugs / installation problems / feature requests.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nEnvironment info\nOperating System: Ubuntu\nInstalled version of CUDA and cuDNN: 7.5 and 7\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\". 0.8\n\nIf installed from sources, provide the commit hash:\nSteps to reproduce\n\nrunning the translate.py example\n2.Crashes while creating models after tokenizing the training data.\n\nThe sample code seems to run fine with single GPU of 4 GB memory. I am using AWS GPU instances. But it works fine for basic values, ie vocab size of 40000 and size of 512. I want to train on a vocab size of 500000 and size of 1024. This is the reason why I opted to go for 4 GPUs now.\n(In AWS terms, g2.2xlarge to g2.8xlarge).\n\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu\n\nInstalled version of CUDA and cuDNN: 7.5 and 7\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. 0.8\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. running the translate.py example\n   2.Crashes while creating models after tokenizing the training data.\n\nThe sample code seems to run fine with single GPU of 4 GB memory. I am using AWS GPU instances. But it works fine for basic values, ie vocab size of 40000 and size of 512. I want to train on a vocab size of 500000 and size of 1024. This is the reason why I opted to go for 4 GPUs now. \n(In AWS terms, g2.2xlarge to g2.8xlarge). \n![g2-8xlarge-crash](https://cloud.githubusercontent.com/assets/5551707/16170060/c599bef8-3562-11e6-9723-4a38999c6a43.png)\n![nvidia-smi-details](https://cloud.githubusercontent.com/assets/5551707/16170062/d7a121fe-3562-11e6-928e-3270ebaa44b9.png)\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n"}