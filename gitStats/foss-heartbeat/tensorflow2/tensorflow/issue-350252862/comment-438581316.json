{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438581316", "html_url": "https://github.com/tensorflow/tensorflow/issues/21587#issuecomment-438581316", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21587", "id": 438581316, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODU4MTMxNg==", "user": {"login": "scotthuang1989", "id": 5325686, "node_id": "MDQ6VXNlcjUzMjU2ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5325686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scotthuang1989", "html_url": "https://github.com/scotthuang1989", "followers_url": "https://api.github.com/users/scotthuang1989/followers", "following_url": "https://api.github.com/users/scotthuang1989/following{/other_user}", "gists_url": "https://api.github.com/users/scotthuang1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/scotthuang1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scotthuang1989/subscriptions", "organizations_url": "https://api.github.com/users/scotthuang1989/orgs", "repos_url": "https://api.github.com/users/scotthuang1989/repos", "events_url": "https://api.github.com/users/scotthuang1989/events{/privacy}", "received_events_url": "https://api.github.com/users/scotthuang1989/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-14T08:39:00Z", "updated_at": "2018-11-14T08:39:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4527536\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tranhungnghiep\">@tranhungnghiep</a> , if you check source code of tf.losses.get_regularization_loss.  you will find that this function also get regularization loss from <strong>REGULARIZATION_LOSSES</strong> collection</p>\n<p><code>ops.get_collection(ops.GraphKeys.REGULARIZATION_LOSSES, scope)</code></p>\n<p>As I mentioned in my comment above ,  keras layer don't add regularization loss to this collection. I am able to fix this, but I am not sure if this is the design or a bug?</p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a></p>\n<p>I check source code of tf.keras, if I add a regularizer to a layer, the only thing tf.keras do is add regularizer loss to <strong>self._losses</strong> of <strong>Layer</strong> class:</p>\n<pre><code>tensorflow/python/keras/engine/base_layer.py:\n\nclass Layer(checkpointable.CheckpointableBase):\n      .....................\n      def add_loss(self, losses, inputs=None):\n           .....................\n           self._losses += losses\n</code></pre>\n<p>if I train this graph with keras API, keras will collect all losses when I compile model. But this will not work if I train with native tensorflow API.</p>\n<p>In the native tensorflow implementation, tensorflow will add regularizer loss to this collection:</p>\n<p><strong>REGULARIZATION_LOSSES</strong></p>\n<pre><code>tensorflow\\python\\layers\\base.py:\n\n  def add_loss(self, losses, inputs=None):\n    previous_losses_length = len(self._losses)\n    super(Layer, self).add_loss(losses, inputs=inputs)\n    # TODO(fchollet): deprecate collection below.\n    new_losses = self._losses[previous_losses_length:]\n    _add_elements_to_collection(new_losses, ops.GraphKeys.REGULARIZATION_LOSSES)\n</code></pre>\n<p>Is my understanding correct, or I did it in a wrong way? If this is a bug I think it is very easy to fix.</p>\n</blockquote>", "body_text": "@tranhungnghiep , if you check source code of tf.losses.get_regularization_loss.  you will find that this function also get regularization loss from REGULARIZATION_LOSSES collection\nops.get_collection(ops.GraphKeys.REGULARIZATION_LOSSES, scope)\nAs I mentioned in my comment above ,  keras layer don't add regularization loss to this collection. I am able to fix this, but I am not sure if this is the design or a bug?\n\n@fchollet\nI check source code of tf.keras, if I add a regularizer to a layer, the only thing tf.keras do is add regularizer loss to self._losses of Layer class:\ntensorflow/python/keras/engine/base_layer.py:\n\nclass Layer(checkpointable.CheckpointableBase):\n      .....................\n      def add_loss(self, losses, inputs=None):\n           .....................\n           self._losses += losses\n\nif I train this graph with keras API, keras will collect all losses when I compile model. But this will not work if I train with native tensorflow API.\nIn the native tensorflow implementation, tensorflow will add regularizer loss to this collection:\nREGULARIZATION_LOSSES\ntensorflow\\python\\layers\\base.py:\n\n  def add_loss(self, losses, inputs=None):\n    previous_losses_length = len(self._losses)\n    super(Layer, self).add_loss(losses, inputs=inputs)\n    # TODO(fchollet): deprecate collection below.\n    new_losses = self._losses[previous_losses_length:]\n    _add_elements_to_collection(new_losses, ops.GraphKeys.REGULARIZATION_LOSSES)\n\nIs my understanding correct, or I did it in a wrong way? If this is a bug I think it is very easy to fix.", "body": "@tranhungnghiep , if you check source code of tf.losses.get_regularization_loss.  you will find that this function also get regularization loss from **REGULARIZATION_LOSSES** collection\r\n\r\n`ops.get_collection(ops.GraphKeys.REGULARIZATION_LOSSES, scope)`\r\n\r\nAs I mentioned in my comment above ,  keras layer don't add regularization loss to this collection. I am able to fix this, but I am not sure if this is the design or a bug?\r\n\r\n\r\n> @fchollet\r\n> \r\n> I check source code of tf.keras, if I add a regularizer to a layer, the only thing tf.keras do is add regularizer loss to **self._losses** of **Layer** class:\r\n> \r\n> ```\r\n> tensorflow/python/keras/engine/base_layer.py:\r\n> \r\n> class Layer(checkpointable.CheckpointableBase):\r\n>       .....................\r\n>       def add_loss(self, losses, inputs=None):\r\n>            .....................\r\n>            self._losses += losses\r\n> ```\r\n> if I train this graph with keras API, keras will collect all losses when I compile model. But this will not work if I train with native tensorflow API.\r\n> \r\n> In the native tensorflow implementation, tensorflow will add regularizer loss to this collection:\r\n> \r\n> **REGULARIZATION_LOSSES**\r\n> \r\n> ```\r\n> tensorflow\\python\\layers\\base.py:\r\n> \r\n>   def add_loss(self, losses, inputs=None):\r\n>     previous_losses_length = len(self._losses)\r\n>     super(Layer, self).add_loss(losses, inputs=inputs)\r\n>     # TODO(fchollet): deprecate collection below.\r\n>     new_losses = self._losses[previous_losses_length:]\r\n>     _add_elements_to_collection(new_losses, ops.GraphKeys.REGULARIZATION_LOSSES)\r\n> ```\r\n> Is my understanding correct, or I did it in a wrong way? If this is a bug I think it is very easy to fix.\r\n\r\n"}