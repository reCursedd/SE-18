{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/167671438", "html_url": "https://github.com/tensorflow/tensorflow/issues/601#issuecomment-167671438", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/601", "id": 167671438, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NzY3MTQzOA==", "user": {"login": "dcunited001", "id": 782627, "node_id": "MDQ6VXNlcjc4MjYyNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/782627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcunited001", "html_url": "https://github.com/dcunited001", "followers_url": "https://api.github.com/users/dcunited001/followers", "following_url": "https://api.github.com/users/dcunited001/following{/other_user}", "gists_url": "https://api.github.com/users/dcunited001/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcunited001/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcunited001/subscriptions", "organizations_url": "https://api.github.com/users/dcunited001/orgs", "repos_url": "https://api.github.com/users/dcunited001/repos", "events_url": "https://api.github.com/users/dcunited001/events{/privacy}", "received_events_url": "https://api.github.com/users/dcunited001/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-28T22:37:19Z", "updated_at": "2015-12-28T22:37:19Z", "author_association": "NONE", "body_html": "<p>in addition to this, i logged my output when running <code>docker build . -t tf/tf</code>. I can upload that to a gist or something, if it would help.  i think there's something wrong with my host system.</p>\n<p>from inside the container, <code>ls -ll /dev/nvidia*</code> gives me:</p>\n<pre><code>root@f206ea45c11e:~# ls -ll /dev/nvidia*\ncrw-rw-rw- 1 root root 195,   0 Dec 28 22:17 /dev/nvidia0\ncrw-rw-rw- 1 root root 195, 255 Dec 28 22:17 /dev/nvidiactl\n</code></pre>\n<p>my docker container arguments from <code>./docker_run_gpu.sh</code> include: <code>/lib/modules/3.19.0-32-generic:/lib/modules/3.19.0-32-generic</code>, though i'm not sure this is required.  it was required for me to add this to the shell script in order to make the folder accessible within the container.  now it seems to be accessible (and the nvidia &amp; nvidia-uvm driver files are included) and I'm no longer seeing the following error when i run tensorflow:</p>\n<pre><code>modprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\n</code></pre>\n<p>instead, i'm seeing:</p>\n<pre><code>modprobe: FATAL: Module nvidia-uvm not found.\n</code></pre>\n<p>i'm still getting <code>CUDA_ERROR_UNKNOWN</code> when running MNIST Convolutional from inside the container:</p>\n<pre><code>modprobe: FATAL: Module nvidia-uvm not found.\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.68\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: \nInitialized!\nEpoch 0.00\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\n</code></pre>\n<p><code>nvidia-smi</code> tells me only ~200MB of GPU RAM are being used, but my CPU's are being hammered.</p>", "body_text": "in addition to this, i logged my output when running docker build . -t tf/tf. I can upload that to a gist or something, if it would help.  i think there's something wrong with my host system.\nfrom inside the container, ls -ll /dev/nvidia* gives me:\nroot@f206ea45c11e:~# ls -ll /dev/nvidia*\ncrw-rw-rw- 1 root root 195,   0 Dec 28 22:17 /dev/nvidia0\ncrw-rw-rw- 1 root root 195, 255 Dec 28 22:17 /dev/nvidiactl\n\nmy docker container arguments from ./docker_run_gpu.sh include: /lib/modules/3.19.0-32-generic:/lib/modules/3.19.0-32-generic, though i'm not sure this is required.  it was required for me to add this to the shell script in order to make the folder accessible within the container.  now it seems to be accessible (and the nvidia & nvidia-uvm driver files are included) and I'm no longer seeing the following error when i run tensorflow:\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\n\ninstead, i'm seeing:\nmodprobe: FATAL: Module nvidia-uvm not found.\n\ni'm still getting CUDA_ERROR_UNKNOWN when running MNIST Convolutional from inside the container:\nmodprobe: FATAL: Module nvidia-uvm not found.\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.68\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: \nInitialized!\nEpoch 0.00\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\n\nnvidia-smi tells me only ~200MB of GPU RAM are being used, but my CPU's are being hammered.", "body": "in addition to this, i logged my output when running `docker build . -t tf/tf`. I can upload that to a gist or something, if it would help.  i think there's something wrong with my host system.\n\nfrom inside the container, `ls -ll /dev/nvidia*` gives me:\n\n```\nroot@f206ea45c11e:~# ls -ll /dev/nvidia*\ncrw-rw-rw- 1 root root 195,   0 Dec 28 22:17 /dev/nvidia0\ncrw-rw-rw- 1 root root 195, 255 Dec 28 22:17 /dev/nvidiactl\n```\n\nmy docker container arguments from `./docker_run_gpu.sh` include: `/lib/modules/3.19.0-32-generic:/lib/modules/3.19.0-32-generic`, though i'm not sure this is required.  it was required for me to add this to the shell script in order to make the folder accessible within the container.  now it seems to be accessible (and the nvidia & nvidia-uvm driver files are included) and I'm no longer seeing the following error when i run tensorflow:\n\n```\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\n```\n\ninstead, i'm seeing:\n\n```\nmodprobe: FATAL: Module nvidia-uvm not found.\n```\n\ni'm still getting `CUDA_ERROR_UNKNOWN` when running MNIST Convolutional from inside the container:\n\n```\nmodprobe: FATAL: Module nvidia-uvm not found.\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: f206ea45c11e\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.68\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: \nInitialized!\nEpoch 0.00\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\n```\n\n`nvidia-smi` tells me only ~200MB of GPU RAM are being used, but my CPU's are being hammered.  \n"}