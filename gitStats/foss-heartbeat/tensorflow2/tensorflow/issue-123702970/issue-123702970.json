{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/601", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/601/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/601/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/601/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/601", "id": 123702970, "node_id": "MDU6SXNzdWUxMjM3MDI5NzA=", "number": 601, "title": "failed call to cuInit: CUDA_ERROR_UNKNOWN after Docker build on Macbook Pro (Late 2013) with Linux", "user": {"login": "dcunited001", "id": 782627, "node_id": "MDQ6VXNlcjc4MjYyNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/782627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcunited001", "html_url": "https://github.com/dcunited001", "followers_url": "https://api.github.com/users/dcunited001/followers", "following_url": "https://api.github.com/users/dcunited001/following{/other_user}", "gists_url": "https://api.github.com/users/dcunited001/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcunited001/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcunited001/subscriptions", "organizations_url": "https://api.github.com/users/dcunited001/orgs", "repos_url": "https://api.github.com/users/dcunited001/repos", "events_url": "https://api.github.com/users/dcunited001/events{/privacy}", "received_events_url": "https://api.github.com/users/dcunited001/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284463744, "node_id": "MDU6TGFiZWwyODQ0NjM3NDQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cuda", "name": "cuda", "color": "f7c6c7", "default": false}, {"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2015-12-23T18:18:08Z", "updated_at": "2017-06-22T10:46:17Z", "closed_at": "2016-12-27T07:23:59Z", "author_association": "NONE", "body_html": "<p>This issue is similar to to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"119958629\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/394\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/394/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/394\">#394</a>. I believe i'm seeing it because tensorflow can't find <code>libcuda.so</code>.</p>\n<p>I know that my <code>libcuda.so</code> can be found in <code>/usr/lib/x86_64-linux-gnu/</code>, but is this accessible to the compiler and to python without further configuration?  I tried adding it to my docker user's <code>$LD_LIBRARY_PATH</code>, but that did not fix the problem.</p>\n<p>I'm running on:</p>\n<ul>\n<li>Macbook Pro (Late 2013) Hardware</li>\n<li>Mint 17</li>\n<li>3.0 Compute Capability</li>\n<li>CUDA 7.0 &amp; cuDNN 2.0</li>\n<li>running docker service under a docker user &amp; group.  no sudo access for docker user.</li>\n</ul>\n<p>on host os, values for <code>$CUDA_SO</code> and <code>$DEVICES</code> that are passed into <code>./docker_run_gpu.sh</code> are:</p>\n<pre><code>$ export CUDA_SO=$(\\ls /usr/lib/x86_64-linux-gnu/libcuda* | xargs -I{} echo '-v {}:{}')\n$ export DEVICES=$(\\ls /dev/nvidia* | xargs -I{} echo '--device {}:{}')\n\n$ echo $CUDA_SO\n-v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.68:/usr/lib/x86_64-linux-gnu/libcuda.so.352.68\n\n$ echo $DEVICES\n--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl\n</code></pre>\n<p>I customized <code>Dockerfile.devel-gpu</code> as below.  I prepended <code>TF_CUDA_COMPUTE_CAPABILITIES=3.0</code> and  <code>TF_UNOFFICIAL_SETTING=1</code> for the <code>./configure</code> step.</p>\n<p>Should I add the <code>libcuda.so</code> path to <code>ENV LD_LIBRARY_PATH</code>?</p>\n<div class=\"highlight highlight-source-dockerfile\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> ........</span>\n\n<span class=\"pl-k\">RUN</span> git clone --recursive https://github.com/tensorflow/tensorflow.git &amp;&amp; \\\n    cd tensorflow &amp;&amp; \\\n    git checkout 0.6.0\n<span class=\"pl-k\">WORKDIR</span> /tensorflow\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Configure the build for our CUDA configuration.</span>\n<span class=\"pl-k\">ENV</span> CUDA_TOOLKIT_PATH /usr/local/cuda\n<span class=\"pl-k\">ENV</span> CUDNN_INSTALL_PATH /usr/local/cuda\n<span class=\"pl-k\">ENV</span> TF_NEED_CUDA 1\n\n<span class=\"pl-k\">RUN</span> TF_CUDA_COMPUTE_CAPABILITIES=3.0 TF_UNOFFICIAL_SETTING=1 ./configure &amp;&amp; \\\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package &amp;&amp; \\\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &amp;&amp; \\\n    pip install --upgrade /tmp/pip/tensorflow-*.whl\n\n<span class=\"pl-k\">WORKDIR</span> /root\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Set up CUDA variables</span>\n<span class=\"pl-k\">ENV</span> CUDA_PATH /usr/local/cuda\n<span class=\"pl-k\">ENV</span> LD_LIBRARY_PATH /usr/local/cuda/lib64\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> TensorBoard</span>\n<span class=\"pl-k\">EXPOSE</span> 6006\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> IPython</span>\n<span class=\"pl-k\">EXPOSE</span> 8888\n\n<span class=\"pl-k\">RUN</span> [<span class=\"pl-s\">\"/bin/bash\"</span>]</pre></div>\n<p>Then I built the image and ran it with <code>./docker_run_gpu.sh tf/tf</code></p>\n<p>Started tensorflow with: <code>python -m tensorflow.models.image.mnist.convolutional</code></p>\n<p>And I'm getting <code>failed call to cuInit: CUDA_ERROR_UNKNOWN</code> when tensorflow starts up. But this is after reporting that it <code>successfully opened CUDA library libcuda.so locally</code>.</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\n\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)\n</code></pre>", "body_text": "This issue is similar to to #394. I believe i'm seeing it because tensorflow can't find libcuda.so.\nI know that my libcuda.so can be found in /usr/lib/x86_64-linux-gnu/, but is this accessible to the compiler and to python without further configuration?  I tried adding it to my docker user's $LD_LIBRARY_PATH, but that did not fix the problem.\nI'm running on:\n\nMacbook Pro (Late 2013) Hardware\nMint 17\n3.0 Compute Capability\nCUDA 7.0 & cuDNN 2.0\nrunning docker service under a docker user & group.  no sudo access for docker user.\n\non host os, values for $CUDA_SO and $DEVICES that are passed into ./docker_run_gpu.sh are:\n$ export CUDA_SO=$(\\ls /usr/lib/x86_64-linux-gnu/libcuda* | xargs -I{} echo '-v {}:{}')\n$ export DEVICES=$(\\ls /dev/nvidia* | xargs -I{} echo '--device {}:{}')\n\n$ echo $CUDA_SO\n-v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.68:/usr/lib/x86_64-linux-gnu/libcuda.so.352.68\n\n$ echo $DEVICES\n--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl\n\nI customized Dockerfile.devel-gpu as below.  I prepended TF_CUDA_COMPUTE_CAPABILITIES=3.0 and  TF_UNOFFICIAL_SETTING=1 for the ./configure step.\nShould I add the libcuda.so path to ENV LD_LIBRARY_PATH?\n# ........\n\nRUN git clone --recursive https://github.com/tensorflow/tensorflow.git && \\\n    cd tensorflow && \\\n    git checkout 0.6.0\nWORKDIR /tensorflow\n\n# Configure the build for our CUDA configuration.\nENV CUDA_TOOLKIT_PATH /usr/local/cuda\nENV CUDNN_INSTALL_PATH /usr/local/cuda\nENV TF_NEED_CUDA 1\n\nRUN TF_CUDA_COMPUTE_CAPABILITIES=3.0 TF_UNOFFICIAL_SETTING=1 ./configure && \\\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package && \\\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\n    pip install --upgrade /tmp/pip/tensorflow-*.whl\n\nWORKDIR /root\n\n# Set up CUDA variables\nENV CUDA_PATH /usr/local/cuda\nENV LD_LIBRARY_PATH /usr/local/cuda/lib64\n\n# TensorBoard\nEXPOSE 6006\n# IPython\nEXPOSE 8888\n\nRUN [\"/bin/bash\"]\nThen I built the image and ran it with ./docker_run_gpu.sh tf/tf\nStarted tensorflow with: python -m tensorflow.models.image.mnist.convolutional\nAnd I'm getting failed call to cuInit: CUDA_ERROR_UNKNOWN when tensorflow starts up. But this is after reporting that it successfully opened CUDA library libcuda.so locally.\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\n\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)", "body": "This issue is similar to to #394. I believe i'm seeing it because tensorflow can't find `libcuda.so`.\n\nI know that my `libcuda.so` can be found in `/usr/lib/x86_64-linux-gnu/`, but is this accessible to the compiler and to python without further configuration?  I tried adding it to my docker user's `$LD_LIBRARY_PATH`, but that did not fix the problem. \n\nI'm running on:\n- Macbook Pro (Late 2013) Hardware\n- Mint 17\n- 3.0 Compute Capability\n- CUDA 7.0 & cuDNN 2.0 \n- running docker service under a docker user & group.  no sudo access for docker user.\n\non host os, values for `$CUDA_SO` and `$DEVICES` that are passed into `./docker_run_gpu.sh` are:\n\n```\n$ export CUDA_SO=$(\\ls /usr/lib/x86_64-linux-gnu/libcuda* | xargs -I{} echo '-v {}:{}')\n$ export DEVICES=$(\\ls /dev/nvidia* | xargs -I{} echo '--device {}:{}')\n\n$ echo $CUDA_SO\n-v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.68:/usr/lib/x86_64-linux-gnu/libcuda.so.352.68\n\n$ echo $DEVICES\n--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl\n```\n\nI customized `Dockerfile.devel-gpu` as below.  I prepended `TF_CUDA_COMPUTE_CAPABILITIES=3.0` and  `TF_UNOFFICIAL_SETTING=1` for the `./configure` step.  \n\nShould I add the `libcuda.so` path to `ENV LD_LIBRARY_PATH`?\n\n``` Dockerfile\n# ........\n\nRUN git clone --recursive https://github.com/tensorflow/tensorflow.git && \\\n    cd tensorflow && \\\n    git checkout 0.6.0\nWORKDIR /tensorflow\n\n# Configure the build for our CUDA configuration.\nENV CUDA_TOOLKIT_PATH /usr/local/cuda\nENV CUDNN_INSTALL_PATH /usr/local/cuda\nENV TF_NEED_CUDA 1\n\nRUN TF_CUDA_COMPUTE_CAPABILITIES=3.0 TF_UNOFFICIAL_SETTING=1 ./configure && \\\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package && \\\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\n    pip install --upgrade /tmp/pip/tensorflow-*.whl\n\nWORKDIR /root\n\n# Set up CUDA variables\nENV CUDA_PATH /usr/local/cuda\nENV LD_LIBRARY_PATH /usr/local/cuda/lib64\n\n# TensorBoard\nEXPOSE 6006\n# IPython\nEXPOSE 8888\n\nRUN [\"/bin/bash\"]\n```\n\nThen I built the image and ran it with `./docker_run_gpu.sh tf/tf`\n\nStarted tensorflow with: `python -m tensorflow.models.image.mnist.convolutional`\n\nAnd I'm getting `failed call to cuInit: CUDA_ERROR_UNKNOWN` when tensorflow starts up. But this is after reporting that it `successfully opened CUDA library libcuda.so locally`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\n\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/3.19.0-32-generic/modules.dep.bin'\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 24b008aee65f\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.68  Tue Dec  1 17:24:11 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)\n```\n"}