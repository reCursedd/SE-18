{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14430", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14430/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14430/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14430/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14430", "id": 272799275, "node_id": "MDU6SXNzdWUyNzI3OTkyNzU=", "number": 14430, "title": "Some errors in docker tf notebooks", "user": {"login": "cinqs", "id": 8960811, "node_id": "MDQ6VXNlcjg5NjA4MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8960811?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cinqs", "html_url": "https://github.com/cinqs", "followers_url": "https://api.github.com/users/cinqs/followers", "following_url": "https://api.github.com/users/cinqs/following{/other_user}", "gists_url": "https://api.github.com/users/cinqs/gists{/gist_id}", "starred_url": "https://api.github.com/users/cinqs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cinqs/subscriptions", "organizations_url": "https://api.github.com/users/cinqs/orgs", "repos_url": "https://api.github.com/users/cinqs/repos", "events_url": "https://api.github.com/users/cinqs/events{/privacy}", "received_events_url": "https://api.github.com/users/cinqs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-10T02:24:25Z", "updated_at": "2017-11-10T05:18:55Z", "closed_at": "2017-11-10T05:18:55Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:CentOS 7</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: docker images</li>\n<li><strong>TensorFlow version (use command below)</strong>: latest</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>it is just a documentation problem.</p>\n<p>in <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb</a></p>\n<p>in section <strong>the code again</strong>, in the comments:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Perform gradient descent. </span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> This essentially just updates weights, like weights += grads * learning_rate</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> using the partial derivative of the loss with respect to the</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> weights. It's the direction we want to go to move toward lower error.</span>\n    update_weights <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</pre></div>\n<p>I do think to update weights, you should use <code>weights := weights - grads * learning_rate</code>, I think using <code>+=</code> is not a right choice</p>\n<p>And another one is also in this section, you should use <code>bias_with_x</code> instead of <code>x_with_bias</code></p>\n<p>That's all.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS 7\nTensorFlow installed from (source or binary): docker images\nTensorFlow version (use command below): latest\n\nDescribe the problem\nit is just a documentation problem.\nin https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb\nin section the code again, in the comments:\n    # Perform gradient descent. \n    # This essentially just updates weights, like weights += grads * learning_rate\n    # using the partial derivative of the loss with respect to the\n    # weights. It's the direction we want to go to move toward lower error.\n    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\nI do think to update weights, you should use weights := weights - grads * learning_rate, I think using += is not a right choice\nAnd another one is also in this section, you should use bias_with_x instead of x_with_bias\nThat's all.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS 7\r\n- **TensorFlow installed from (source or binary)**: docker images\r\n- **TensorFlow version (use command below)**: latest\r\n\r\n### Describe the problem\r\n\r\nit is just a documentation problem.\r\n\r\nin https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb\r\n\r\nin section **the code again**, in the comments:\r\n\r\n```py\r\n    # Perform gradient descent. \r\n    # This essentially just updates weights, like weights += grads * learning_rate\r\n    # using the partial derivative of the loss with respect to the\r\n    # weights. It's the direction we want to go to move toward lower error.\r\n    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\r\n```\r\nI do think to update weights, you should use `weights := weights - grads * learning_rate`, I think using `+=` is not a right choice\r\n\r\nAnd another one is also in this section, you should use `bias_with_x` instead of `x_with_bias`\r\n\r\nThat's all."}