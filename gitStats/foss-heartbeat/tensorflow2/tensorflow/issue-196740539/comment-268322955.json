{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/268322955", "html_url": "https://github.com/tensorflow/tensorflow/issues/6422#issuecomment-268322955", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6422", "id": 268322955, "node_id": "MDEyOklzc3VlQ29tbWVudDI2ODMyMjk1NQ==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-20T18:42:43Z", "updated_at": "2016-12-20T18:44:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> Using different optimizer instances for different variables would lead to the problem of computing the same gradients multiple times and probably some other issues. Might also not work as intended with an optimizer like Adam.</p>\n<p>What I'm essentially asking for the is the ability to scale a gradient on a per neuron basis with a mask, or as in the use case of individual layers having their own learning rate, a scalar.</p>\n<p>Simple example:<br>\nSome layer contains 5 neurons and you apply this mask: [1 1 2 1 1] to it, when doing backprop the middle neuron gets updated with twice the learning rate. Though in practice the learning rate will just be made 1 and the mask will specify it.</p>\n<p>Also it may prove interesting and perhaps even valuable to instead of adjusting the learning rate, actually adjust the gradient itself which would also flow backward - this is not at all obvious how to do in TF.</p>", "body_text": "@vrv Using different optimizer instances for different variables would lead to the problem of computing the same gradients multiple times and probably some other issues. Might also not work as intended with an optimizer like Adam.\nWhat I'm essentially asking for the is the ability to scale a gradient on a per neuron basis with a mask, or as in the use case of individual layers having their own learning rate, a scalar.\nSimple example:\nSome layer contains 5 neurons and you apply this mask: [1 1 2 1 1] to it, when doing backprop the middle neuron gets updated with twice the learning rate. Though in practice the learning rate will just be made 1 and the mask will specify it.\nAlso it may prove interesting and perhaps even valuable to instead of adjusting the learning rate, actually adjust the gradient itself which would also flow backward - this is not at all obvious how to do in TF.", "body": "@vrv Using different optimizer instances for different variables would lead to the problem of computing the same gradients multiple times and probably some other issues. Might also not work as intended with an optimizer like Adam.\r\n\r\nWhat I'm essentially asking for the is the ability to scale a gradient on a per neuron basis with a mask, or as in the use case of individual layers having their own learning rate, a scalar.\r\n\r\nSimple example:\r\nSome layer contains 5 neurons and you apply this mask: [1 1 2 1 1] to it, when doing backprop the middle neuron gets updated with twice the learning rate. Though in practice the learning rate will just be made 1 and the mask will specify it.\r\n\r\nAlso it may prove interesting and perhaps even valuable to instead of adjusting the learning rate, actually adjust the gradient itself which would also flow backward - this is not at all obvious how to do in TF.\r\n"}