{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/268332359", "html_url": "https://github.com/tensorflow/tensorflow/issues/6422#issuecomment-268332359", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6422", "id": 268332359, "node_id": "MDEyOklzc3VlQ29tbWVudDI2ODMzMjM1OQ==", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-20T19:20:08Z", "updated_at": "2016-12-20T19:20:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>@alexmonroe87 an example where using different optimizer instances doesn't work would be useful -- I don't think we'd compute the same gradients multiple times if every variable is associated with one optimizer.  \"Might not work as intended\" is not sufficient evidence for a new feature request :).</p>\n<p>As for your mask idea, you can do that today:  Let's say you have a single variable you want to optimize with a mask, using a GradientDescentOptimizer (for simplicity).  Here's my untested semi-TF code:</p>\n<pre><code>    v = tf.Variable(...)\n\n    # Define your mask here, matching the shape of the variable.  E.g., could be [1.0, 1.0, 2.0, 1.0, 1.0]\n    # if 'v' was a vector of 5.\n    mask = tf.constant(..., dtype=tf.float32)\n\n    # Base learning rate\n    optimizer = tf.GradientDescentOptimizer(learning_rate)\n\n    # Compute the gradients and have them returned\n    grads_and_vars = optimizer.compute_gradients(loss, var_list=[v], ...)\n\n    # Scale the gradient by the mask you want\n    masked_grad_and_vars = [(tf.multiply(mask, g), v) for g, v in grads_and_vars]\n    \n    # Apply the scaled gradient\n    optimizer.apply_gradients(masked_grad_and_vars)\n</code></pre>\n<p>The only difference between this and normal code is the addition of the 'mask' and the 'masked_grad_and_vars'.  Everything else is the same.</p>\n<p>Can you explain why this wouldn't work for you?</p>", "body_text": "@alexmonroe87 an example where using different optimizer instances doesn't work would be useful -- I don't think we'd compute the same gradients multiple times if every variable is associated with one optimizer.  \"Might not work as intended\" is not sufficient evidence for a new feature request :).\nAs for your mask idea, you can do that today:  Let's say you have a single variable you want to optimize with a mask, using a GradientDescentOptimizer (for simplicity).  Here's my untested semi-TF code:\n    v = tf.Variable(...)\n\n    # Define your mask here, matching the shape of the variable.  E.g., could be [1.0, 1.0, 2.0, 1.0, 1.0]\n    # if 'v' was a vector of 5.\n    mask = tf.constant(..., dtype=tf.float32)\n\n    # Base learning rate\n    optimizer = tf.GradientDescentOptimizer(learning_rate)\n\n    # Compute the gradients and have them returned\n    grads_and_vars = optimizer.compute_gradients(loss, var_list=[v], ...)\n\n    # Scale the gradient by the mask you want\n    masked_grad_and_vars = [(tf.multiply(mask, g), v) for g, v in grads_and_vars]\n    \n    # Apply the scaled gradient\n    optimizer.apply_gradients(masked_grad_and_vars)\n\nThe only difference between this and normal code is the addition of the 'mask' and the 'masked_grad_and_vars'.  Everything else is the same.\nCan you explain why this wouldn't work for you?", "body": "@alexmonroe87 an example where using different optimizer instances doesn't work would be useful -- I don't think we'd compute the same gradients multiple times if every variable is associated with one optimizer.  \"Might not work as intended\" is not sufficient evidence for a new feature request :).\r\n\r\nAs for your mask idea, you can do that today:  Let's say you have a single variable you want to optimize with a mask, using a GradientDescentOptimizer (for simplicity).  Here's my untested semi-TF code:\r\n\r\n```\r\n    v = tf.Variable(...)\r\n\r\n    # Define your mask here, matching the shape of the variable.  E.g., could be [1.0, 1.0, 2.0, 1.0, 1.0]\r\n    # if 'v' was a vector of 5.\r\n    mask = tf.constant(..., dtype=tf.float32)\r\n\r\n    # Base learning rate\r\n    optimizer = tf.GradientDescentOptimizer(learning_rate)\r\n\r\n    # Compute the gradients and have them returned\r\n    grads_and_vars = optimizer.compute_gradients(loss, var_list=[v], ...)\r\n\r\n    # Scale the gradient by the mask you want\r\n    masked_grad_and_vars = [(tf.multiply(mask, g), v) for g, v in grads_and_vars]\r\n    \r\n    # Apply the scaled gradient\r\n    optimizer.apply_gradients(masked_grad_and_vars)\r\n```\r\n\r\nThe only difference between this and normal code is the addition of the 'mask' and the 'masked_grad_and_vars'.  Everything else is the same.\r\n\r\nCan you explain why this wouldn't work for you?"}