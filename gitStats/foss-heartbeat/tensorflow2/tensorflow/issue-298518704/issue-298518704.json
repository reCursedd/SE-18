{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17148", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17148/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17148/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17148/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/17148", "id": 298518704, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcwMTM0OTY4", "number": 17148, "title": "fix: Error on we feed float16 values into BeamSearchDecoder", "user": {"login": "halhorn", "id": 4395870, "node_id": "MDQ6VXNlcjQzOTU4NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/4395870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/halhorn", "html_url": "https://github.com/halhorn", "followers_url": "https://api.github.com/users/halhorn/followers", "following_url": "https://api.github.com/users/halhorn/following{/other_user}", "gists_url": "https://api.github.com/users/halhorn/gists{/gist_id}", "starred_url": "https://api.github.com/users/halhorn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/halhorn/subscriptions", "organizations_url": "https://api.github.com/users/halhorn/orgs", "repos_url": "https://api.github.com/users/halhorn/repos", "events_url": "https://api.github.com/users/halhorn/events{/privacy}", "received_events_url": "https://api.github.com/users/halhorn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-02-20T09:12:01Z", "updated_at": "2018-02-24T01:38:52Z", "closed_at": "2018-02-23T22:41:07Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17148", "html_url": "https://github.com/tensorflow/tensorflow/pull/17148", "diff_url": "https://github.com/tensorflow/tensorflow/pull/17148.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/17148.patch"}, "body_html": "<p>I tried to feed float16 values into BeamSearchDecoder. Then <code>Type Error</code> occurred.</p>\n<p>The cause is that:</p>\n<ol>\n<li><code>_mask_probs</code> in beam_search_decoder calls <code>array_ops.one_hot()</code> and the <code>on_value</code> arg is <code>0.</code>.</li>\n<li><code>one_hot</code> in array_ops infers the <code>dtype</code> of <code>on_value</code> from the value <code>0.</code></li>\n<li><code>dtype</code> of <code>on_value</code> becomes <code>tf.float32</code></li>\n<li>then raises <code>TypeError: dtype &lt;dtype: 'float32'&gt; of on_value does not match dtype parameter &lt;dtype: 'float16'&gt;</code></li>\n</ol>\n<p>The main cause is that <code>array_ops.one_hot</code> gets value <code>0.</code> but the <code>dtype</code> is unknown, so I convert the value <code>0.</code> into tensor that has right <code>dtype</code> before it is fed to <code>one_hot</code>.</p>\n<h1>Code that raises error</h1>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n\n<span class=\"pl-c1\">FL_TYPE</span> <span class=\"pl-k\">=</span> tf.float16  <span class=\"pl-c\"><span class=\"pl-c\">#</span> error does not occur if FL_TYPE is tf.float32</span>\nhidden_dim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">16</span>\nvocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nbeam_width <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.GRUCell(hidden_dim)\n    embeddings <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[vocab_size, hidden_dim], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FL_TYPE</span>))\n    output_layer <span class=\"pl-k\">=</span> layers_core.Dense(vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n    decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BeamSearchDecoder(\n        <span class=\"pl-v\">cell</span><span class=\"pl-k\">=</span>cell,\n        <span class=\"pl-v\">embedding</span><span class=\"pl-k\">=</span>embeddings,\n        <span class=\"pl-v\">start_tokens</span><span class=\"pl-k\">=</span>tf.ones([<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32),\n        <span class=\"pl-v\">end_token</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">99</span>,\n        <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>tf.random_uniform(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[beam_width, hidden_dim], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FL_TYPE</span>),\n        <span class=\"pl-v\">beam_width</span><span class=\"pl-k\">=</span>beam_width,\n        <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>output_layer,\n    )\n    decoder_outputs, _, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n        <span class=\"pl-v\">decoder</span><span class=\"pl-k\">=</span>decoder,\n        <span class=\"pl-v\">maximum_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">20</span>,\n         <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>generator_decode<span class=\"pl-pds\">'</span></span>\n    )\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(decoder_outputs)</pre></div>\n<p>output is bellow</p>\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-14-321fa872acec&gt; in &lt;module&gt;()\n     24         decoder=decoder,\n     25         maximum_iterations=20,\n---&gt; 26          scope='generator_decode'\n     27     )\n     28 \n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\n    307         ],\n    308         parallel_iterations=parallel_iterations,\n--&gt; 309         swap_memory=swap_memory)\n    310 \n    311     final_outputs_ta = res[1]\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\n   2932         swap_memory=swap_memory)\n   2933     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\n-&gt; 2934     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n   2935     if maximum_iterations is not None:\n   2936       return result[1]\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\n   2718       self.Enter()\n   2719       original_body_result, exit_vars = self._BuildLoop(\n-&gt; 2720           pred, body, original_loop_vars, loop_vars, shape_invariants)\n   2721     finally:\n   2722       self.Exit()\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\n   2660         flat_sequence=vars_for_body_with_tensor_arrays)\n   2661     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n-&gt; 2662     body_result = body(*packed_vars_for_body)\n   2663     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n   2664     if not nest.is_sequence(body_result):\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\n    252       \"\"\"\n    253       (next_outputs, decoder_state, next_inputs,\n--&gt; 254        decoder_finished) = decoder.step(time, inputs, state)\n    255       if decoder.tracks_own_finished:\n    256         next_finished = decoder_finished\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)\n    497           beam_width=beam_width,\n    498           end_token=end_token,\n--&gt; 499           length_penalty_weight=length_penalty_weight)\n    500 \n    501       finished = beam_search_state.finished\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _beam_search_step(time, logits, next_cell_state, beam_state, batch_size, beam_width, end_token, length_penalty_weight)\n    539   # Final Shape: [batch_size, beam_width, vocab_size]\n    540   step_log_probs = nn_ops.log_softmax(logits)\n--&gt; 541   step_log_probs = _mask_probs(step_log_probs, end_token, previously_finished)\n    542   total_probs = array_ops.expand_dims(beam_state.log_probs, 2) + step_log_probs\n    543 \n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _mask_probs(probs, eos_token, finished)\n    723       dtype=probs.dtype,\n    724       on_value=0.,\n--&gt; 725       off_value=probs.dtype.min)\n    726   finished_probs = array_ops.tile(\n    727       array_ops.reshape(finished_row, [1, 1, -1]),\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in one_hot(indices, depth, on_value, off_value, axis, dtype, name)\n   2337         if on_exists and on_dtype != dtype:\n   2338           raise TypeError(\"dtype {0} of on_value does not match \"\n-&gt; 2339                           \"dtype parameter {1}\".format(on_dtype, dtype))\n   2340         if off_exists and off_dtype != dtype:\n   2341           raise TypeError(\"dtype {0} of off_value does not match \"\n\nTypeError: dtype &lt;dtype: 'float32'&gt; of on_value does not match dtype parameter &lt;dtype: 'float16'&gt;\n</code></pre>", "body_text": "I tried to feed float16 values into BeamSearchDecoder. Then Type Error occurred.\nThe cause is that:\n\n_mask_probs in beam_search_decoder calls array_ops.one_hot() and the on_value arg is 0..\none_hot in array_ops infers the dtype of on_value from the value 0.\ndtype of on_value becomes tf.float32\nthen raises TypeError: dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float16'>\n\nThe main cause is that array_ops.one_hot gets value 0. but the dtype is unknown, so I convert the value 0. into tensor that has right dtype before it is fed to one_hot.\nCode that raises error\nimport tensorflow as tf\nfrom tensorflow.python.layers import core as layers_core\n\nFL_TYPE = tf.float16  # error does not occur if FL_TYPE is tf.float32\nhidden_dim = 16\nvocab_size = 100\nbeam_width = 2\n\nwith tf.Graph().as_default():\n    cell = tf.nn.rnn_cell.GRUCell(hidden_dim)\n    embeddings = tf.Variable(tf.random_uniform(shape=[vocab_size, hidden_dim], dtype=FL_TYPE))\n    output_layer = layers_core.Dense(vocab_size, use_bias=False)\n\n    decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n        cell=cell,\n        embedding=embeddings,\n        start_tokens=tf.ones([1], dtype=tf.int32),\n        end_token=99,\n        initial_state=tf.random_uniform(shape=[beam_width, hidden_dim], dtype=FL_TYPE),\n        beam_width=beam_width,\n        output_layer=output_layer,\n    )\n    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n        decoder=decoder,\n        maximum_iterations=20,\n         scope='generator_decode'\n    )\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(decoder_outputs)\noutput is bellow\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-14-321fa872acec> in <module>()\n     24         decoder=decoder,\n     25         maximum_iterations=20,\n---> 26          scope='generator_decode'\n     27     )\n     28 \n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\n    307         ],\n    308         parallel_iterations=parallel_iterations,\n--> 309         swap_memory=swap_memory)\n    310 \n    311     final_outputs_ta = res[1]\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\n   2932         swap_memory=swap_memory)\n   2933     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\n-> 2934     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n   2935     if maximum_iterations is not None:\n   2936       return result[1]\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\n   2718       self.Enter()\n   2719       original_body_result, exit_vars = self._BuildLoop(\n-> 2720           pred, body, original_loop_vars, loop_vars, shape_invariants)\n   2721     finally:\n   2722       self.Exit()\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\n   2660         flat_sequence=vars_for_body_with_tensor_arrays)\n   2661     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n-> 2662     body_result = body(*packed_vars_for_body)\n   2663     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n   2664     if not nest.is_sequence(body_result):\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\n    252       \"\"\"\n    253       (next_outputs, decoder_state, next_inputs,\n--> 254        decoder_finished) = decoder.step(time, inputs, state)\n    255       if decoder.tracks_own_finished:\n    256         next_finished = decoder_finished\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)\n    497           beam_width=beam_width,\n    498           end_token=end_token,\n--> 499           length_penalty_weight=length_penalty_weight)\n    500 \n    501       finished = beam_search_state.finished\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _beam_search_step(time, logits, next_cell_state, beam_state, batch_size, beam_width, end_token, length_penalty_weight)\n    539   # Final Shape: [batch_size, beam_width, vocab_size]\n    540   step_log_probs = nn_ops.log_softmax(logits)\n--> 541   step_log_probs = _mask_probs(step_log_probs, end_token, previously_finished)\n    542   total_probs = array_ops.expand_dims(beam_state.log_probs, 2) + step_log_probs\n    543 \n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _mask_probs(probs, eos_token, finished)\n    723       dtype=probs.dtype,\n    724       on_value=0.,\n--> 725       off_value=probs.dtype.min)\n    726   finished_probs = array_ops.tile(\n    727       array_ops.reshape(finished_row, [1, 1, -1]),\n\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in one_hot(indices, depth, on_value, off_value, axis, dtype, name)\n   2337         if on_exists and on_dtype != dtype:\n   2338           raise TypeError(\"dtype {0} of on_value does not match \"\n-> 2339                           \"dtype parameter {1}\".format(on_dtype, dtype))\n   2340         if off_exists and off_dtype != dtype:\n   2341           raise TypeError(\"dtype {0} of off_value does not match \"\n\nTypeError: dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float16'>", "body": "I tried to feed float16 values into BeamSearchDecoder. Then `Type Error` occurred.\r\n\r\nThe cause is that:\r\n\r\n1. `_mask_probs` in beam_search_decoder calls `array_ops.one_hot()` and the `on_value` arg is `0.`.\r\n2. `one_hot` in array_ops infers the `dtype` of `on_value` from the value `0.`\r\n3.  `dtype` of `on_value` becomes `tf.float32`\r\n4. then raises `TypeError: dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float16'>`\r\n\r\nThe main cause is that `array_ops.one_hot` gets value `0.` but the `dtype` is unknown, so I convert the value `0.` into tensor that has right `dtype` before it is fed to `one_hot`.\r\n\r\n# Code that raises error\r\n\r\n```py3\r\nimport tensorflow as tf\r\nfrom tensorflow.python.layers import core as layers_core\r\n\r\nFL_TYPE = tf.float16  # error does not occur if FL_TYPE is tf.float32\r\nhidden_dim = 16\r\nvocab_size = 100\r\nbeam_width = 2\r\n\r\nwith tf.Graph().as_default():\r\n    cell = tf.nn.rnn_cell.GRUCell(hidden_dim)\r\n    embeddings = tf.Variable(tf.random_uniform(shape=[vocab_size, hidden_dim], dtype=FL_TYPE))\r\n    output_layer = layers_core.Dense(vocab_size, use_bias=False)\r\n\r\n    decoder = tf.contrib.seq2seq.BeamSearchDecoder(\r\n        cell=cell,\r\n        embedding=embeddings,\r\n        start_tokens=tf.ones([1], dtype=tf.int32),\r\n        end_token=99,\r\n        initial_state=tf.random_uniform(shape=[beam_width, hidden_dim], dtype=FL_TYPE),\r\n        beam_width=beam_width,\r\n        output_layer=output_layer,\r\n    )\r\n    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\r\n        decoder=decoder,\r\n        maximum_iterations=20,\r\n         scope='generator_decode'\r\n    )\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(decoder_outputs)\r\n```\r\n\r\noutput is bellow\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-14-321fa872acec> in <module>()\r\n     24         decoder=decoder,\r\n     25         maximum_iterations=20,\r\n---> 26          scope='generator_decode'\r\n     27     )\r\n     28 \r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\r\n    307         ],\r\n    308         parallel_iterations=parallel_iterations,\r\n--> 309         swap_memory=swap_memory)\r\n    310 \r\n    311     final_outputs_ta = res[1]\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\r\n   2932         swap_memory=swap_memory)\r\n   2933     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\r\n-> 2934     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n   2935     if maximum_iterations is not None:\r\n   2936       return result[1]\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\r\n   2718       self.Enter()\r\n   2719       original_body_result, exit_vars = self._BuildLoop(\r\n-> 2720           pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2721     finally:\r\n   2722       self.Exit()\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2660         flat_sequence=vars_for_body_with_tensor_arrays)\r\n   2661     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n-> 2662     body_result = body(*packed_vars_for_body)\r\n   2663     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n   2664     if not nest.is_sequence(body_result):\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\r\n    252       \"\"\"\r\n    253       (next_outputs, decoder_state, next_inputs,\r\n--> 254        decoder_finished) = decoder.step(time, inputs, state)\r\n    255       if decoder.tracks_own_finished:\r\n    256         next_finished = decoder_finished\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in step(self, time, inputs, state, name)\r\n    497           beam_width=beam_width,\r\n    498           end_token=end_token,\r\n--> 499           length_penalty_weight=length_penalty_weight)\r\n    500 \r\n    501       finished = beam_search_state.finished\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _beam_search_step(time, logits, next_cell_state, beam_state, batch_size, beam_width, end_token, length_penalty_weight)\r\n    539   # Final Shape: [batch_size, beam_width, vocab_size]\r\n    540   step_log_probs = nn_ops.log_softmax(logits)\r\n--> 541   step_log_probs = _mask_probs(step_log_probs, end_token, previously_finished)\r\n    542   total_probs = array_ops.expand_dims(beam_state.log_probs, 2) + step_log_probs\r\n    543 \r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py in _mask_probs(probs, eos_token, finished)\r\n    723       dtype=probs.dtype,\r\n    724       on_value=0.,\r\n--> 725       off_value=probs.dtype.min)\r\n    726   finished_probs = array_ops.tile(\r\n    727       array_ops.reshape(finished_row, [1, 1, -1]),\r\n\r\n~/.pyenv/versions/3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py in one_hot(indices, depth, on_value, off_value, axis, dtype, name)\r\n   2337         if on_exists and on_dtype != dtype:\r\n   2338           raise TypeError(\"dtype {0} of on_value does not match \"\r\n-> 2339                           \"dtype parameter {1}\".format(on_dtype, dtype))\r\n   2340         if off_exists and off_dtype != dtype:\r\n   2341           raise TypeError(\"dtype {0} of off_value does not match \"\r\n\r\nTypeError: dtype <dtype: 'float32'> of on_value does not match dtype parameter <dtype: 'float16'>\r\n```"}