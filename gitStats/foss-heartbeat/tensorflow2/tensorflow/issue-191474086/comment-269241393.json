{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269241393", "html_url": "https://github.com/tensorflow/tensorflow/issues/5827#issuecomment-269241393", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5827", "id": 269241393, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTI0MTM5Mw==", "user": {"login": "edouardoyallon", "id": 4263222, "node_id": "MDQ6VXNlcjQyNjMyMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4263222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edouardoyallon", "html_url": "https://github.com/edouardoyallon", "followers_url": "https://api.github.com/users/edouardoyallon/followers", "following_url": "https://api.github.com/users/edouardoyallon/following{/other_user}", "gists_url": "https://api.github.com/users/edouardoyallon/gists{/gist_id}", "starred_url": "https://api.github.com/users/edouardoyallon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edouardoyallon/subscriptions", "organizations_url": "https://api.github.com/users/edouardoyallon/orgs", "repos_url": "https://api.github.com/users/edouardoyallon/repos", "events_url": "https://api.github.com/users/edouardoyallon/events{/privacy}", "received_events_url": "https://api.github.com/users/edouardoyallon/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-26T20:57:51Z", "updated_at": "2016-12-26T20:57:51Z", "author_association": "NONE", "body_html": "<p>Hi!<br>\nI'm also having this issue when reusing batch normalization layer, and in particular ema:</p>\n<pre><code>ValueError: Variable deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n</code></pre>\n<p>My objective is to duplicate some variables of a model, to insert them in another model, and then to load them from a check point. Everything works fine except the ema. When I use the trick explained by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1381301\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ppwwyyxx\">@ppwwyyxx</a> , by imposing not to reuse variables, I have an issue when I load a model from a checkpoint:</p>\n<pre><code>NotFoundError (see above for traceback): Key deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased not found in checkpoint\n\t [[Node: save_1/RestoreV2_57 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_57/tensor_names, save_1/RestoreV2_57/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_32/_137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_349_save_1/RestoreV2_32\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n</code></pre>\n<p>Here is the code I use for the BN:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-c1\">None</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span>with tf.variable_scope():# FIX?</span>\n    beta <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[n_out])\n    gamma <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[n_out])\n    batch_mean, batch_var <span class=\"pl-k\">=</span> tf.nn.moments(x, [<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>moments<span class=\"pl-pds\">'</span></span>)\n    ema<span class=\"pl-k\">=</span>[]\n    <span class=\"pl-k\">with</span> tf.variable_scope(tf.get_variable_scope(), <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n      ema <span class=\"pl-k\">=</span> tf.train.ExponentialMovingAverage(<span class=\"pl-v\">decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.99</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">mean_var_with_update</span>():\n      ema_apply_op <span class=\"pl-k\">=</span> ema.apply([batch_mean, batch_var])\n      <span class=\"pl-k\">with</span> tf.control_dependencies([ema_apply_op]):\n        <span class=\"pl-k\">return</span> tf.identity(batch_mean), tf.identity(batch_var)\n    mean, var <span class=\"pl-k\">=</span> tf.cond(phase_train,\n      mean_var_with_update,\n      <span class=\"pl-k\">lambda</span>: (ema.average(batch_mean), ema.average(batch_var)))\n\n    normed <span class=\"pl-k\">=</span> tf.nn.batch_norm_with_global_normalization(x, mean, var, \n      beta, gamma, <span class=\"pl-c1\">1e-3</span>, affine)\n    <span class=\"pl-k\">return</span> normed</pre></div>\n<p>I guess I'm doing a very newbie error and I would really appreciate any help to fix this!</p>\n<p>Thank you very much in advance.</p>", "body_text": "Hi!\nI'm also having this issue when reusing batch normalization layer, and in particular ema:\nValueError: Variable deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\n\nMy objective is to duplicate some variables of a model, to insert them in another model, and then to load them from a check point. Everything works fine except the ema. When I use the trick explained by @ppwwyyxx , by imposing not to reuse variables, I have an issue when I load a model from a checkpoint:\nNotFoundError (see above for traceback): Key deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased not found in checkpoint\n\t [[Node: save_1/RestoreV2_57 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_57/tensor_names, save_1/RestoreV2_57/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_32/_137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_349_save_1/RestoreV2_32\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nHere is the code I use for the BN:\nwith tf.name_scope(None):\n  #with tf.variable_scope():# FIX?\n    beta = tf.constant(0.0, shape=[n_out])\n    gamma = tf.constant(1.0, shape=[n_out])\n    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n    ema=[]\n    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n      ema = tf.train.ExponentialMovingAverage(decay=0.99)\n\n    def mean_var_with_update():\n      ema_apply_op = ema.apply([batch_mean, batch_var])\n      with tf.control_dependencies([ema_apply_op]):\n        return tf.identity(batch_mean), tf.identity(batch_var)\n    mean, var = tf.cond(phase_train,\n      mean_var_with_update,\n      lambda: (ema.average(batch_mean), ema.average(batch_var)))\n\n    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \n      beta, gamma, 1e-3, affine)\n    return normed\nI guess I'm doing a very newbie error and I would really appreciate any help to fix this!\nThank you very much in advance.", "body": "Hi!\r\nI'm also having this issue when reusing batch normalization layer, and in particular ema:\r\n```\r\nValueError: Variable deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n```\r\n\r\nMy objective is to duplicate some variables of a model, to insert them in another model, and then to load them from a check point. Everything works fine except the ema. When I use the trick explained by @ppwwyyxx , by imposing not to reuse variables, I have an issue when I load a model from a checkpoint:\r\n\r\n```\r\nNotFoundError (see above for traceback): Key deep_net/blabla/moments_6/moments_1/mean/ExponentialMovingAverage/biased not found in checkpoint\r\n\t [[Node: save_1/RestoreV2_57 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_57/tensor_names, save_1/RestoreV2_57/shape_and_slices)]]\r\n\t [[Node: save_1/RestoreV2_32/_137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_349_save_1/RestoreV2_32\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n```\r\n\r\nHere is the code I use for the BN:\r\n\r\n```python\r\nwith tf.name_scope(None):\r\n  #with tf.variable_scope():# FIX?\r\n    beta = tf.constant(0.0, shape=[n_out])\r\n    gamma = tf.constant(1.0, shape=[n_out])\r\n    batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\r\n    ema=[]\r\n    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\r\n      ema = tf.train.ExponentialMovingAverage(decay=0.99)\r\n\r\n    def mean_var_with_update():\r\n      ema_apply_op = ema.apply([batch_mean, batch_var])\r\n      with tf.control_dependencies([ema_apply_op]):\r\n        return tf.identity(batch_mean), tf.identity(batch_var)\r\n    mean, var = tf.cond(phase_train,\r\n      mean_var_with_update,\r\n      lambda: (ema.average(batch_mean), ema.average(batch_var)))\r\n\r\n    normed = tf.nn.batch_norm_with_global_normalization(x, mean, var, \r\n      beta, gamma, 1e-3, affine)\r\n    return normed\r\n```\r\nI guess I'm doing a very newbie error and I would really appreciate any help to fix this!\r\n\r\nThank you very much in advance."}