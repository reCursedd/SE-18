{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2106", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2106/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2106/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2106/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2106", "id": 151062059, "node_id": "MDU6SXNzdWUxNTEwNjIwNTk=", "number": 2106, "title": "[ distribution ] How to use multiple GPU on each replica ?", "user": {"login": "ZhuFengdaaa", "id": 9649227, "node_id": "MDQ6VXNlcjk2NDkyMjc=", "avatar_url": "https://avatars0.githubusercontent.com/u/9649227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhuFengdaaa", "html_url": "https://github.com/ZhuFengdaaa", "followers_url": "https://api.github.com/users/ZhuFengdaaa/followers", "following_url": "https://api.github.com/users/ZhuFengdaaa/following{/other_user}", "gists_url": "https://api.github.com/users/ZhuFengdaaa/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhuFengdaaa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhuFengdaaa/subscriptions", "organizations_url": "https://api.github.com/users/ZhuFengdaaa/orgs", "repos_url": "https://api.github.com/users/ZhuFengdaaa/repos", "events_url": "https://api.github.com/users/ZhuFengdaaa/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhuFengdaaa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-04-26T07:22:53Z", "updated_at": "2016-04-26T14:58:49Z", "closed_at": "2016-04-26T14:58:49Z", "author_association": "NONE", "body_html": "<p>The <a href=\"https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py\">Code Here</a> shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like <a href=\"https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py\">that example</a>.</p>\n<p>The way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU.</p>", "body_text": "The Code Here shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like that example.\nThe way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU.", "body": "The [Code Here](https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py) shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like [that example](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py). \n\nThe way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU. \n"}