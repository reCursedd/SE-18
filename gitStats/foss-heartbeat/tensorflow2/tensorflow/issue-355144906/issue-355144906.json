{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21946", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21946/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21946/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21946/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21946", "id": 355144906, "node_id": "MDU6SXNzdWUzNTUxNDQ5MDY=", "number": 21946, "title": "[feature request] specify subgraphs to route to TensorRT in tf.contrib.tensorrt", "user": {"login": "fferroni", "id": 16327442, "node_id": "MDQ6VXNlcjE2MzI3NDQy", "avatar_url": "https://avatars1.githubusercontent.com/u/16327442?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fferroni", "html_url": "https://github.com/fferroni", "followers_url": "https://api.github.com/users/fferroni/followers", "following_url": "https://api.github.com/users/fferroni/following{/other_user}", "gists_url": "https://api.github.com/users/fferroni/gists{/gist_id}", "starred_url": "https://api.github.com/users/fferroni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fferroni/subscriptions", "organizations_url": "https://api.github.com/users/fferroni/orgs", "repos_url": "https://api.github.com/users/fferroni/repos", "events_url": "https://api.github.com/users/fferroni/events{/privacy}", "received_events_url": "https://api.github.com/users/fferroni/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-29T12:50:01Z", "updated_at": "2018-11-12T18:51:50Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.15.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0, 7.0</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Based on the examples provided in tf.contrib.tensorrt as well as on the internet, it seems that the following:</p>\n<pre><code>import tensorflow.contrib.tensorrt as trt\nwith gfile.FastGFile(protobuf_file, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    trt_graph = trt.create_inference_graph(graph_def, trt_nodes,\n                                           max_batch_size=batch_size,\n                                           max_workspace_size_bytes=memory_allocation,\n                                           minimum_segment_size=minimum_segment_size,\n                                           precision_mode=\"FP32\")  # Get optimized graph\n</code></pre>\n<p>is enough to make the parts that are recognized by TensorRT into trt_ops. The only control you have of what to send to TensorRT within the graph is \"minimum_segment_size\" which excludes sections of the graph below this number of compatible ops.<br>\nHowever, it would be helpful to be able to define sections (either explicit ops, or input/output pairs in the subgraph).<br>\nFor example, at the moment, I am struggling to convert into a hybrid TF/TRT graph a Fast-RCNN architecture. TensorRT will convert for example all convolution operations, however the encoder part will have convolutions with a batch size equal to the number of images provided, while the proposal classification part of the network will have convolutions with batch size equal to the number of proposals. I have everything as a single Tensorflow graph with dynamic batch for the 2nd stage, however TensorRT expects a max batch size. If I set the max batch size to the max number of proposals, I run out of memory since it will also assign this max batch to the encoder part.<br>\nAt the moment I've set the minimum_segment_size high enough for TensorRT to ignore the proposal part of the network and convert only the encoder. However, it would be helpful to be convert both sections, and leave the unsupported operations (like <code>tf.image.crop_and_resize</code>, or <code>tf.image.non_max_suppression</code> in Tensorflow).<br>\nAny advice? Thanks</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.10.1\nPython version: 3.5\nBazel version (if compiling from source): 0.15.1\nGCC/Compiler version (if compiling from source): 5\nCUDA/cuDNN version: 9.0, 7.0\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nBased on the examples provided in tf.contrib.tensorrt as well as on the internet, it seems that the following:\nimport tensorflow.contrib.tensorrt as trt\nwith gfile.FastGFile(protobuf_file, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    trt_graph = trt.create_inference_graph(graph_def, trt_nodes,\n                                           max_batch_size=batch_size,\n                                           max_workspace_size_bytes=memory_allocation,\n                                           minimum_segment_size=minimum_segment_size,\n                                           precision_mode=\"FP32\")  # Get optimized graph\n\nis enough to make the parts that are recognized by TensorRT into trt_ops. The only control you have of what to send to TensorRT within the graph is \"minimum_segment_size\" which excludes sections of the graph below this number of compatible ops.\nHowever, it would be helpful to be able to define sections (either explicit ops, or input/output pairs in the subgraph).\nFor example, at the moment, I am struggling to convert into a hybrid TF/TRT graph a Fast-RCNN architecture. TensorRT will convert for example all convolution operations, however the encoder part will have convolutions with a batch size equal to the number of images provided, while the proposal classification part of the network will have convolutions with batch size equal to the number of proposals. I have everything as a single Tensorflow graph with dynamic batch for the 2nd stage, however TensorRT expects a max batch size. If I set the max batch size to the max number of proposals, I run out of memory since it will also assign this max batch to the encoder part.\nAt the moment I've set the minimum_segment_size high enough for TensorRT to ignore the proposal part of the network and convert only the encoder. However, it would be helpful to be convert both sections, and leave the unsupported operations (like tf.image.crop_and_resize, or tf.image.non_max_suppression in Tensorflow).\nAny advice? Thanks", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.15.1\r\n- **GCC/Compiler version (if compiling from source)**: 5\r\n- **CUDA/cuDNN version**: 9.0, 7.0\r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nBased on the examples provided in tf.contrib.tensorrt as well as on the internet, it seems that the following:\r\n```\r\nimport tensorflow.contrib.tensorrt as trt\r\nwith gfile.FastGFile(protobuf_file, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    trt_graph = trt.create_inference_graph(graph_def, trt_nodes,\r\n                                           max_batch_size=batch_size,\r\n                                           max_workspace_size_bytes=memory_allocation,\r\n                                           minimum_segment_size=minimum_segment_size,\r\n                                           precision_mode=\"FP32\")  # Get optimized graph\r\n```\r\nis enough to make the parts that are recognized by TensorRT into trt_ops. The only control you have of what to send to TensorRT within the graph is \"minimum_segment_size\" which excludes sections of the graph below this number of compatible ops.\r\nHowever, it would be helpful to be able to define sections (either explicit ops, or input/output pairs in the subgraph).\r\nFor example, at the moment, I am struggling to convert into a hybrid TF/TRT graph a Fast-RCNN architecture. TensorRT will convert for example all convolution operations, however the encoder part will have convolutions with a batch size equal to the number of images provided, while the proposal classification part of the network will have convolutions with batch size equal to the number of proposals. I have everything as a single Tensorflow graph with dynamic batch for the 2nd stage, however TensorRT expects a max batch size. If I set the max batch size to the max number of proposals, I run out of memory since it will also assign this max batch to the encoder part.\r\nAt the moment I've set the minimum_segment_size high enough for TensorRT to ignore the proposal part of the network and convert only the encoder. However, it would be helpful to be convert both sections, and leave the unsupported operations (like `tf.image.crop_and_resize`, or `tf.image.non_max_suppression` in Tensorflow).\r\nAny advice? Thanks\r\n"}