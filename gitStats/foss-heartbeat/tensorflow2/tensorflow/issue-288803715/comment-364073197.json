{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364073197", "html_url": "https://github.com/tensorflow/tensorflow/issues/16147#issuecomment-364073197", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147", "id": 364073197, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDA3MzE5Nw==", "user": {"login": "Rov67777", "id": 7711526, "node_id": "MDQ6VXNlcjc3MTE1MjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/7711526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rov67777", "html_url": "https://github.com/Rov67777", "followers_url": "https://api.github.com/users/Rov67777/followers", "following_url": "https://api.github.com/users/Rov67777/following{/other_user}", "gists_url": "https://api.github.com/users/Rov67777/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rov67777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rov67777/subscriptions", "organizations_url": "https://api.github.com/users/Rov67777/orgs", "repos_url": "https://api.github.com/users/Rov67777/repos", "events_url": "https://api.github.com/users/Rov67777/events{/privacy}", "received_events_url": "https://api.github.com/users/Rov67777/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-08T10:44:17Z", "updated_at": "2018-02-08T10:45:22Z", "author_association": "NONE", "body_html": "<p>Any update on this issue ? I have also tried to use the V100 on my own code (tensorflow 1.5.0 cuda 9.0 cudnn 7) and did not see any speed improvement with respect to GTX 1080 Ti. I tried either float32 and float 16 without any difference. (but I am not sure exactly if the underlying operations were done in float16 since it seems that operations might still be running float32 even though the graphs/input are defined as float16)</p>\n<p>I would be really interested to see any example of code that manages to use the Volta tensor cores power showing significant speed improvement with respect to previous generation of GPU (Pascal / Maxwell architecture)</p>", "body_text": "Any update on this issue ? I have also tried to use the V100 on my own code (tensorflow 1.5.0 cuda 9.0 cudnn 7) and did not see any speed improvement with respect to GTX 1080 Ti. I tried either float32 and float 16 without any difference. (but I am not sure exactly if the underlying operations were done in float16 since it seems that operations might still be running float32 even though the graphs/input are defined as float16)\nI would be really interested to see any example of code that manages to use the Volta tensor cores power showing significant speed improvement with respect to previous generation of GPU (Pascal / Maxwell architecture)", "body": "Any update on this issue ? I have also tried to use the V100 on my own code (tensorflow 1.5.0 cuda 9.0 cudnn 7) and did not see any speed improvement with respect to GTX 1080 Ti. I tried either float32 and float 16 without any difference. (but I am not sure exactly if the underlying operations were done in float16 since it seems that operations might still be running float32 even though the graphs/input are defined as float16)\r\n\r\nI would be really interested to see any example of code that manages to use the Volta tensor cores power showing significant speed improvement with respect to previous generation of GPU (Pascal / Maxwell architecture)"}