{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16147", "id": 288803715, "node_id": "MDU6SXNzdWUyODg4MDM3MTU=", "number": 16147, "title": "Inference on V100 with TF1.5 is extremely slow. ", "user": {"login": "louisquinn", "id": 5274490, "node_id": "MDQ6VXNlcjUyNzQ0OTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/5274490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/louisquinn", "html_url": "https://github.com/louisquinn", "followers_url": "https://api.github.com/users/louisquinn/followers", "following_url": "https://api.github.com/users/louisquinn/following{/other_user}", "gists_url": "https://api.github.com/users/louisquinn/gists{/gist_id}", "starred_url": "https://api.github.com/users/louisquinn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/louisquinn/subscriptions", "organizations_url": "https://api.github.com/users/louisquinn/orgs", "repos_url": "https://api.github.com/users/louisquinn/repos", "events_url": "https://api.github.com/users/louisquinn/events{/privacy}", "received_events_url": "https://api.github.com/users/louisquinn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 27, "created_at": "2018-01-16T06:56:15Z", "updated_at": "2018-07-11T02:35:12Z", "closed_at": "2018-07-11T02:35:12Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source and Virtual Env, problem doesn't change</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0-rc1 (Makes no difference on 1.4)</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.9.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9/7.0.5</li>\n<li><strong>GPU model and memory</strong>: V100 - 16GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<ul>\n<li>Inference using the V100 is very slow. For example performing object detection with SSD Mobilenet is achieving a max frame rate of ~8, compared to ~45 on a GTX1080</li>\n<li>Initialization with a warm up image is extremely slow - up to 2 mins for the first image.</li>\n<li>I have tried model quantization using graph_transforms/transform_graph (in an attempt to use the FP16 mode) and various combinations of CUDA, cuDNN and Tensorflow versions with no difference.</li>\n</ul>\n<p>Is there some recommended environment setup for the V100?<br>\nI am successfully running Darknet (<a href=\"https://pjreddie.com/darknet/\" rel=\"nofollow\">https://pjreddie.com/darknet/</a>) with a massive increase of speed.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Source and Virtual Env, problem doesn't change\nTensorFlow version (use command below): 1.5.0-rc1 (Makes no difference on 1.4)\nPython version: 3.5\nBazel version (if compiling from source): 0.9.0\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: CUDA 9/7.0.5\nGPU model and memory: V100 - 16GB\nExact command to reproduce:\n\nDescribe the problem\n\nInference using the V100 is very slow. For example performing object detection with SSD Mobilenet is achieving a max frame rate of ~8, compared to ~45 on a GTX1080\nInitialization with a warm up image is extremely slow - up to 2 mins for the first image.\nI have tried model quantization using graph_transforms/transform_graph (in an attempt to use the FP16 mode) and various combinations of CUDA, cuDNN and Tensorflow versions with no difference.\n\nIs there some recommended environment setup for the V100?\nI am successfully running Darknet (https://pjreddie.com/darknet/) with a massive increase of speed.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source and Virtual Env, problem doesn't change\r\n- **TensorFlow version (use command below)**: 1.5.0-rc1 (Makes no difference on 1.4)\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: CUDA 9/7.0.5\r\n- **GPU model and memory**: V100 - 16GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\n- Inference using the V100 is very slow. For example performing object detection with SSD Mobilenet is achieving a max frame rate of ~8, compared to ~45 on a GTX1080\r\n- Initialization with a warm up image is extremely slow - up to 2 mins for the first image. \r\n- I have tried model quantization using graph_transforms/transform_graph (in an attempt to use the FP16 mode) and various combinations of CUDA, cuDNN and Tensorflow versions with no difference. \r\n\r\nIs there some recommended environment setup for the V100?\r\nI am successfully running Darknet (https://pjreddie.com/darknet/) with a massive increase of speed. "}