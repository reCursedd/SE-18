{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364164673", "html_url": "https://github.com/tensorflow/tensorflow/issues/16147#issuecomment-364164673", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16147", "id": 364164673, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDE2NDY3Mw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-08T16:21:17Z", "updated_at": "2018-02-08T16:21:17Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7711526\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Rov67777\">@Rov67777</a>   ResNet50 FP32 on V100 is ~344 image/sec.  FP16 665 images/sec.  A GTX 1080 ti is likely similar to the original Titan X (Pascal) and I would guess ~200-210 images/sec  because a P100 is ~230 images/sec.  I do not believe the GTX 1080 has strong FP16 support even for inference and no mixed-mode so training would not so well at all based on my understanding.</p>\n<p>I do not know your use case but if you are looking for an FP16 example in the short term I have a link below.  For forward-pass only the results would be as dramatic but it would depend on how you are need to do inference. The benchmark script assumes a batch of images not data streaming in, which is a scenario I hope to have a better example for in the near future as I think it is common.  Meaning using tf.data where you provide some type of buffer to tf.data or something like that, sorry the idea is not complete, if you have a scenario please share and explain why it is interesting.</p>\n<p><a href=\"https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks\">https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks</a></p>\n<pre><code># Real data\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --data_dir=/data/imagenet --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10\n\n# Synthetic Data\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10\n</code></pre>", "body_text": "@Rov67777   ResNet50 FP32 on V100 is ~344 image/sec.  FP16 665 images/sec.  A GTX 1080 ti is likely similar to the original Titan X (Pascal) and I would guess ~200-210 images/sec  because a P100 is ~230 images/sec.  I do not believe the GTX 1080 has strong FP16 support even for inference and no mixed-mode so training would not so well at all based on my understanding.\nI do not know your use case but if you are looking for an FP16 example in the short term I have a link below.  For forward-pass only the results would be as dramatic but it would depend on how you are need to do inference. The benchmark script assumes a batch of images not data streaming in, which is a scenario I hope to have a better example for in the near future as I think it is common.  Meaning using tf.data where you provide some type of buffer to tf.data or something like that, sorry the idea is not complete, if you have a scenario please share and explain why it is interesting.\nhttps://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks\n# Real data\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --data_dir=/data/imagenet --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10\n\n# Synthetic Data\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10", "body": "@Rov67777   ResNet50 FP32 on V100 is ~344 image/sec.  FP16 665 images/sec.  A GTX 1080 ti is likely similar to the original Titan X (Pascal) and I would guess ~200-210 images/sec  because a P100 is ~230 images/sec.  I do not believe the GTX 1080 has strong FP16 support even for inference and no mixed-mode so training would not so well at all based on my understanding.\r\n\r\nI do not know your use case but if you are looking for an FP16 example in the short term I have a link below.  For forward-pass only the results would be as dramatic but it would depend on how you are need to do inference. The benchmark script assumes a batch of images not data streaming in, which is a scenario I hope to have a better example for in the near future as I think it is common.  Meaning using tf.data where you provide some type of buffer to tf.data or something like that, sorry the idea is not complete, if you have a scenario please share and explain why it is interesting.  \r\n\r\nhttps://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks\r\n```\r\n# Real data\r\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --data_dir=/data/imagenet --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10\r\n\r\n# Synthetic Data\r\npython tf_cnn_benchmarks.py --data_format=NCHW --batch_size=128 --num_batches=100 --model=resnet50 --optimizer=sgd --variable_update=parameter_server --all_reduce_spec='' --use_fp16=True --nodistortions --local_parameter_device=cpu --num_gpus=1 --display_every=10\r\n```\r\n\r\n\r\n"}