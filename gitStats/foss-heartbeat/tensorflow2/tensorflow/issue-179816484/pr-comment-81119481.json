{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/81119481", "pull_request_review_id": 2122172, "id": 81119481, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgxMTE5NDgx", "diff_hunk": "@@ -132,74 +171,118 @@ def __call__(self, inputs, state, scope=None):\n       - A 2D, batch x state_size, Tensor representing the new state of the cell\n         after reading \"inputs\" when previous state was \"state\".\n     \"\"\"\n-    state_sz = state.get_shape().as_list()[1]\n-    if self.state_size != state_sz:\n-      raise ValueError(\n-          'Actual state size not same as specified: {} vs {}.'.format(\n-              state_sz, self.state_size))\n-\n     conf = self._config\n-    dtype = inputs.dtype if inputs is not None else state.dtype\n+    dtype = inputs.dtype\n \n-    # c_prev is `m`, and m_prev is `h` in the paper.\n-    # Keep c and m here for consistency with the codebase\n-    c_prev = [None] * self._config.num_dims\n-    m_prev = [None] * self._config.num_dims\n-    cell_output_size = self._cell.state_size - conf.num_units\n-\n-    # for LSTM   : state = memory cell + output, hence cell_output_size > 0\n-    # for GRU/RNN: state = output (whose size is equal to _num_units),\n-    #              hence cell_output_size = 0\n-    for recurrent_dim, start_idx in zip(self._config.recurrents, range(\n-        0, self.state_size, self._cell.state_size)):\n-      if cell_output_size > 0:\n-        c_prev[recurrent_dim] = array_ops.slice(state, [0, start_idx],\n-                                                [-1, conf.num_units])\n-        m_prev[recurrent_dim] = array_ops.slice(\n-            state, [0, start_idx + conf.num_units], [-1, cell_output_size])\n-      else:\n-        m_prev[recurrent_dim] = array_ops.slice(state, [0, start_idx],\n-                                                [-1, conf.num_units])\n+    c_prev, m_prev, cell_output_size = self._extract_states(state)\n \n     new_output = [None] * conf.num_dims\n     new_state = [None] * conf.num_dims\n \n     with vs.variable_scope(scope or type(self).__name__):  # GridRNNCell\n+      # project input, populate c_prev and m_prev\n+      self._project_input(inputs, c_prev, m_prev, cell_output_size > 0)\n \n-      # project input\n-      if inputs is not None and sum(inputs.get_shape().as_list()) > 0 and len(\n-          conf.inputs) > 0:\n-        input_splits = array_ops.split(1, len(conf.inputs), inputs)\n-        input_sz = input_splits[0].get_shape().as_list()[1]\n-\n-        for i, j in enumerate(conf.inputs):\n-          input_project_m = vs.get_variable(\n-              'project_m_{}'.format(j), [input_sz, conf.num_units], dtype=dtype)\n-          m_prev[j] = math_ops.matmul(input_splits[i], input_project_m)\n-\n-          if cell_output_size > 0:\n-            input_project_c = vs.get_variable(\n-                'project_c_{}'.format(j), [input_sz, conf.num_units],\n-                dtype=dtype)\n-            c_prev[j] = math_ops.matmul(input_splits[i], input_project_c)\n-\n+      # propagate along dimensions, first for non-priority dimensions\n+      # then priority dimensions\n       _propagate(conf.non_priority, conf, self._cell, c_prev, m_prev,\n                  new_output, new_state, True)\n       _propagate(conf.priority, conf, self._cell, c_prev, m_prev, new_output,\n                  new_state, False)\n \n+      # collect outputs and states\n       output_tensors = [new_output[i] for i in self._config.outputs]\n-      output = array_ops.zeros(\n-          [0, 0], dtype) if len(output_tensors) == 0 else array_ops.concat(\n-              1, output_tensors)\n+      if self._output_is_tuple:\n+        output = tuple(output_tensors)\n+      else:\n+        output = array_ops.zeros([0, 0], dtype) if len(output_tensors) == 0 \\\n+          else array_ops.concat(1, output_tensors)\n \n-      state_tensors = [new_state[i] for i in self._config.recurrents]\n-      states = array_ops.zeros(\n-          [0, 0], dtype) if len(state_tensors) == 0 else array_ops.concat(\n-              1, state_tensors)\n+      if self._state_is_tuple:\n+        states = tuple(new_state[i] for i in self._config.recurrents)\n+      else:\n+        # concat each state first, then flatten the whole thing\n+        state_tensors = [x for i in self._config.recurrents\n+                         for x in new_state[i]]\n+        states = array_ops.zeros([0, 0], dtype) if len(state_tensors) == 0 \\\n+          else array_ops.concat(1, state_tensors)\n \n     return output, states\n \n+  def _extract_states(self, state):\n+    \"\"\"Extract the cell and previous output tensors from the given state\n+    \"\"\"\n+    conf = self._config\n+\n+    # c_prev is `m` (cell value), and\n+    # m_prev is `h` (previous output) in the paper.\n+    # Keeping c and m here for consistency with the codebase\n+    c_prev = [None] * conf.num_dims\n+    m_prev = [None] * conf.num_dims\n+\n+    # for LSTM   : state = memory cell + output, hence cell_output_size > 0\n+    # for GRU/RNN: state = output (whose size is equal to _num_units),\n+    #              hence cell_output_size = 0\n+    total_cell_state_size = self._cell_state_size()\n+    cell_output_size = total_cell_state_size - conf.num_units\n+\n+    if self._state_is_tuple:\n+      if len(conf.recurrents) != len(state):\n+        raise ValueError(\"Expected state as a tuple of {} \"\n+                         \"element\".format(len(conf.recurrents)))\n+\n+      for recurrent_dim, recurrent_state in zip(conf.recurrents, state):\n+        if cell_output_size > 0:\n+          c_prev[recurrent_dim], m_prev[recurrent_dim] = recurrent_state\n+        else:\n+          m_prev[recurrent_dim] = recurrent_state\n+    else:\n+      for recurrent_dim, start_idx in zip(conf.recurrents, range(\n+          0, self.state_size, total_cell_state_size)):\n+        if cell_output_size > 0:\n+          c_prev[recurrent_dim] = array_ops.slice(state, [0, start_idx],\n+                                                  [-1, conf.num_units])\n+          m_prev[recurrent_dim] = array_ops.slice(\n+            state, [0, start_idx + conf.num_units], [-1, cell_output_size])\n+        else:\n+          m_prev[recurrent_dim] = array_ops.slice(state, [0, start_idx],\n+                                                  [-1, conf.num_units])\n+    return c_prev, m_prev, cell_output_size\n+\n+  def _project_input(self, inputs, c_prev, m_prev, with_c):\n+    \"\"\"Fills in c_prev and m_prev with projected input, for input dimensions\n+    \"\"\"\n+    conf = self._config\n+\n+    if inputs is not None and inputs.get_shape().with_rank(2)[1].value > 0 \\", "path": "tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py", "position": null, "original_position": 265, "commit_id": "94528e6a688598a74f538926ab68f1efce321352", "original_commit_id": "bcd4be237d637ab2db4564fe72c98625350ca1ac", "user": {"login": "StefOe", "id": 22097918, "node_id": "MDQ6VXNlcjIyMDk3OTE4", "avatar_url": "https://avatars3.githubusercontent.com/u/22097918?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StefOe", "html_url": "https://github.com/StefOe", "followers_url": "https://api.github.com/users/StefOe/followers", "following_url": "https://api.github.com/users/StefOe/following{/other_user}", "gists_url": "https://api.github.com/users/StefOe/gists{/gist_id}", "starred_url": "https://api.github.com/users/StefOe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StefOe/subscriptions", "organizations_url": "https://api.github.com/users/StefOe/orgs", "repos_url": "https://api.github.com/users/StefOe/repos", "events_url": "https://api.github.com/users/StefOe/events{/privacy}", "received_events_url": "https://api.github.com/users/StefOe/received_events", "type": "User", "site_admin": false}, "body": "This indeed fixes #4296\n", "created_at": "2016-09-29T11:53:20Z", "updated_at": "2016-11-07T09:53:53Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4631#discussion_r81119481", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4631", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/81119481"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4631#discussion_r81119481"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4631"}}, "body_html": "<p>This indeed fixes <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175994966\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4296\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4296/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4296\">#4296</a></p>", "body_text": "This indeed fixes #4296"}