{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/407298717", "html_url": "https://github.com/tensorflow/tensorflow/issues/15805#issuecomment-407298717", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15805", "id": 407298717, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzI5ODcxNw==", "user": {"login": "jyoungyun", "id": 7223627, "node_id": "MDQ6VXNlcjcyMjM2Mjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7223627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jyoungyun", "html_url": "https://github.com/jyoungyun", "followers_url": "https://api.github.com/users/jyoungyun/followers", "following_url": "https://api.github.com/users/jyoungyun/following{/other_user}", "gists_url": "https://api.github.com/users/jyoungyun/gists{/gist_id}", "starred_url": "https://api.github.com/users/jyoungyun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jyoungyun/subscriptions", "organizations_url": "https://api.github.com/users/jyoungyun/orgs", "repos_url": "https://api.github.com/users/jyoungyun/repos", "events_url": "https://api.github.com/users/jyoungyun/events{/privacy}", "received_events_url": "https://api.github.com/users/jyoungyun/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-24T06:42:41Z", "updated_at": "2018-07-24T06:42:41Z", "author_association": "NONE", "body_html": "<p>I modified some code and I successed to generate tflite file for this model.</p>\n<pre><code>#weights and biases of appropriate shape to accomplish above task\nout_weights=tf.Variable(tf.random_normal([num_units,n_classes]),name=\"weights\")\nout_bias=tf.Variable(tf.random_normal([n_classes]),name=\"bias\")\n\n#defining placeholders\n#input image placeholder\nx=tf.placeholder(\"float\",[None,time_steps,n_input])\n#input label placeholder\ny=tf.placeholder(\"float\",[None,n_classes])\n\n#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\ninput=tf.unstack(x ,time_steps,1,name=\"input_tensor\")\n\n#defining the network\n#lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n#lstm_layer=rnn.MultiRNNCell([rnn.BasicLSTMCell(num_units) for _ in range(3)])\n#lstm_layer=rnn.LSTMBlockCell(num_units,forget_bias=1)\nlstm_layer=tf.nn.rnn_cell.BasicLSTMCell(num_units)\n#lstm_layer=tf.nn.rnn_cell.GRUCell(num_units)\n#lstm_layer=tf.nn.rnn_cell.LSTMCell(num_units,forget_bias=1)\noutputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\n\n#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\nprediction=tf.add(tf.matmul(outputs[-1],out_weights), out_bias, name=\"output\")\n\n#loss_function\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n#optimization\nopt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n#model evaluation\ncorrect_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n#initialize variables\ninit=tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n\n    iter=1\n    while iter&lt;800:\n        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)\n\n        batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n\n        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n\n        if iter %10==0:\n            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n            print(\"For iter \",iter)\n            print(\"Accuracy \",acc)\n            print(\"Loss \",los)\n            print(\"__________________\")\n\n        # added\n        saver = tf.train.Saver()\n        filename = saver.save(sess, output_dir + '/model.ckpt')\n\n        iter=iter+1\n</code></pre>\n<p>Train the model:</p>\n<pre><code>$ python rnn.py --output_dir=save\n</code></pre>\n<p>Freeze the model by using generated checkpoint and meta file.</p>\n<pre><code>    output_node_name = \"output\"\n    restore_op_name = \"save/restore_all\"\n    filename_tensor_name = \"save/Const:0\"\n    clear_devices = True\n\n    (directory, fn, ext) = splitDirFilenameExt(input_graph_path)\n    output_frozen_graph_path = os.path.join(directory, fn + '_frozen.pb')\n\n    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path, input_binary,\n                              checkpoint_path, output_node_name, restore_op_name,\n                              filename_tensor_name, output_frozen_graph_path,\n                              clear_devices, \"\")\n</code></pre>\n<pre><code>tensorflow$ bazel run tensorflow/contrib/lite/toco:toco -- \\\n--input_file=[...]/save/rnn_frozen.pb \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--output_file=[...]/save/rnn_frozen.tflite \\\n--input_arrays=\"Placeholder\" \\\n--input_shapes=1,28,28 \\\n--output_arrays=\"output\" \\\n--allow_custom_ops\n</code></pre>\n<p>Finally, I get the tflite and the summarize like below:</p>\n<pre><code># summarize frozen pb\nInputs\n\tname=Placeholder\n\ttype=float(1)\n\tshape=[?,28,28]\nOutputs\n\tname=output, op=Add\nOp Types\n\t99 Const\n\t84 Mul\n\t84 Sigmoid\n\t57 Add\n\t56 Tanh\n\t30 ConcatV2\n\t29 MatMul\n\t28 BiasAdd\n\t28 Split\n\t2 ExpandDims\n\t2 Fill\n\t1 Placeholder\n\t1 Shape\n\t1 StridedSlice\n\t1 Unpack\n</code></pre>\n<pre><code># summarize tflite\nNumber of operator types: 12\n\tCUSTOM(Unpack)[32]                    :    1 \t (total_ops: ???)\n\tCUSTOM(TensorFlowShape)[32]           :    1 \t (total_ops: ???)\n\tSTRIDED_SLICE[45]                     :    1 \t (total_ops: ???)\n\tCUSTOM(ExpandDims)[32]                :    2 \t (total_ops: ???)\n\tCONCATENATION[2]                      :   30 \t (total_ops: ???)\n\tCUSTOM(Fill)[32]                      :    2 \t (total_ops: ???)\n\tFULLY_CONNECTED[9]                    :   29 \t (total_ops: ???)\n\tSPLIT[49]                             :   28 \t (total_ops: ???)\n\tADD[0]                                :   56 \t (total_ops: ???)\n\tLOGISTIC[14]                          :   84 \t (total_ops: ???)\n\tMUL[18]                               :   84 \t (total_ops: ???)\n\tTANH[28]                              :   56 \t (total_ops: ???)\nTotal Number of operators                     :  374 \t (total_ops: 0)\n</code></pre>", "body_text": "I modified some code and I successed to generate tflite file for this model.\n#weights and biases of appropriate shape to accomplish above task\nout_weights=tf.Variable(tf.random_normal([num_units,n_classes]),name=\"weights\")\nout_bias=tf.Variable(tf.random_normal([n_classes]),name=\"bias\")\n\n#defining placeholders\n#input image placeholder\nx=tf.placeholder(\"float\",[None,time_steps,n_input])\n#input label placeholder\ny=tf.placeholder(\"float\",[None,n_classes])\n\n#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\ninput=tf.unstack(x ,time_steps,1,name=\"input_tensor\")\n\n#defining the network\n#lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n#lstm_layer=rnn.MultiRNNCell([rnn.BasicLSTMCell(num_units) for _ in range(3)])\n#lstm_layer=rnn.LSTMBlockCell(num_units,forget_bias=1)\nlstm_layer=tf.nn.rnn_cell.BasicLSTMCell(num_units)\n#lstm_layer=tf.nn.rnn_cell.GRUCell(num_units)\n#lstm_layer=tf.nn.rnn_cell.LSTMCell(num_units,forget_bias=1)\noutputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\n\n#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\nprediction=tf.add(tf.matmul(outputs[-1],out_weights), out_bias, name=\"output\")\n\n#loss_function\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n#optimization\nopt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n#model evaluation\ncorrect_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n#initialize variables\ninit=tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n\n    iter=1\n    while iter<800:\n        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)\n\n        batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n\n        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n\n        if iter %10==0:\n            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n            print(\"For iter \",iter)\n            print(\"Accuracy \",acc)\n            print(\"Loss \",los)\n            print(\"__________________\")\n\n        # added\n        saver = tf.train.Saver()\n        filename = saver.save(sess, output_dir + '/model.ckpt')\n\n        iter=iter+1\n\nTrain the model:\n$ python rnn.py --output_dir=save\n\nFreeze the model by using generated checkpoint and meta file.\n    output_node_name = \"output\"\n    restore_op_name = \"save/restore_all\"\n    filename_tensor_name = \"save/Const:0\"\n    clear_devices = True\n\n    (directory, fn, ext) = splitDirFilenameExt(input_graph_path)\n    output_frozen_graph_path = os.path.join(directory, fn + '_frozen.pb')\n\n    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path, input_binary,\n                              checkpoint_path, output_node_name, restore_op_name,\n                              filename_tensor_name, output_frozen_graph_path,\n                              clear_devices, \"\")\n\ntensorflow$ bazel run tensorflow/contrib/lite/toco:toco -- \\\n--input_file=[...]/save/rnn_frozen.pb \\\n--input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE \\\n--output_file=[...]/save/rnn_frozen.tflite \\\n--input_arrays=\"Placeholder\" \\\n--input_shapes=1,28,28 \\\n--output_arrays=\"output\" \\\n--allow_custom_ops\n\nFinally, I get the tflite and the summarize like below:\n# summarize frozen pb\nInputs\n\tname=Placeholder\n\ttype=float(1)\n\tshape=[?,28,28]\nOutputs\n\tname=output, op=Add\nOp Types\n\t99 Const\n\t84 Mul\n\t84 Sigmoid\n\t57 Add\n\t56 Tanh\n\t30 ConcatV2\n\t29 MatMul\n\t28 BiasAdd\n\t28 Split\n\t2 ExpandDims\n\t2 Fill\n\t1 Placeholder\n\t1 Shape\n\t1 StridedSlice\n\t1 Unpack\n\n# summarize tflite\nNumber of operator types: 12\n\tCUSTOM(Unpack)[32]                    :    1 \t (total_ops: ???)\n\tCUSTOM(TensorFlowShape)[32]           :    1 \t (total_ops: ???)\n\tSTRIDED_SLICE[45]                     :    1 \t (total_ops: ???)\n\tCUSTOM(ExpandDims)[32]                :    2 \t (total_ops: ???)\n\tCONCATENATION[2]                      :   30 \t (total_ops: ???)\n\tCUSTOM(Fill)[32]                      :    2 \t (total_ops: ???)\n\tFULLY_CONNECTED[9]                    :   29 \t (total_ops: ???)\n\tSPLIT[49]                             :   28 \t (total_ops: ???)\n\tADD[0]                                :   56 \t (total_ops: ???)\n\tLOGISTIC[14]                          :   84 \t (total_ops: ???)\n\tMUL[18]                               :   84 \t (total_ops: ???)\n\tTANH[28]                              :   56 \t (total_ops: ???)\nTotal Number of operators                     :  374 \t (total_ops: 0)", "body": "I modified some code and I successed to generate tflite file for this model.\r\n```\r\n#weights and biases of appropriate shape to accomplish above task\r\nout_weights=tf.Variable(tf.random_normal([num_units,n_classes]),name=\"weights\")\r\nout_bias=tf.Variable(tf.random_normal([n_classes]),name=\"bias\")\r\n\r\n#defining placeholders\r\n#input image placeholder\r\nx=tf.placeholder(\"float\",[None,time_steps,n_input])\r\n#input label placeholder\r\ny=tf.placeholder(\"float\",[None,n_classes])\r\n\r\n#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\r\ninput=tf.unstack(x ,time_steps,1,name=\"input_tensor\")\r\n\r\n#defining the network\r\n#lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\r\n#lstm_layer=rnn.MultiRNNCell([rnn.BasicLSTMCell(num_units) for _ in range(3)])\r\n#lstm_layer=rnn.LSTMBlockCell(num_units,forget_bias=1)\r\nlstm_layer=tf.nn.rnn_cell.BasicLSTMCell(num_units)\r\n#lstm_layer=tf.nn.rnn_cell.GRUCell(num_units)\r\n#lstm_layer=tf.nn.rnn_cell.LSTMCell(num_units,forget_bias=1)\r\noutputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\r\n\r\n#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\r\nprediction=tf.add(tf.matmul(outputs[-1],out_weights), out_bias, name=\"output\")\r\n\r\n#loss_function\r\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\r\n#optimization\r\nopt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\r\n\r\n#model evaluation\r\ncorrect_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\r\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\n\r\n#initialize variables\r\ninit=tf.global_variables_initializer()\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n\r\n    iter=1\r\n    while iter<800:\r\n        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)\r\n\r\n        batch_x=batch_x.reshape((batch_size,time_steps,n_input))\r\n\r\n        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\r\n\r\n        if iter %10==0:\r\n            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\r\n            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\r\n            print(\"For iter \",iter)\r\n            print(\"Accuracy \",acc)\r\n            print(\"Loss \",los)\r\n            print(\"__________________\")\r\n\r\n        # added\r\n        saver = tf.train.Saver()\r\n        filename = saver.save(sess, output_dir + '/model.ckpt')\r\n\r\n        iter=iter+1\r\n```\r\n\r\nTrain the model:\r\n```\r\n$ python rnn.py --output_dir=save\r\n```\r\n\r\nFreeze the model by using generated checkpoint and meta file.\r\n```\r\n    output_node_name = \"output\"\r\n    restore_op_name = \"save/restore_all\"\r\n    filename_tensor_name = \"save/Const:0\"\r\n    clear_devices = True\r\n\r\n    (directory, fn, ext) = splitDirFilenameExt(input_graph_path)\r\n    output_frozen_graph_path = os.path.join(directory, fn + '_frozen.pb')\r\n\r\n    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path, input_binary,\r\n                              checkpoint_path, output_node_name, restore_op_name,\r\n                              filename_tensor_name, output_frozen_graph_path,\r\n                              clear_devices, \"\")\r\n```\r\n\r\n```\r\ntensorflow$ bazel run tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=[...]/save/rnn_frozen.pb \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--output_file=[...]/save/rnn_frozen.tflite \\\r\n--input_arrays=\"Placeholder\" \\\r\n--input_shapes=1,28,28 \\\r\n--output_arrays=\"output\" \\\r\n--allow_custom_ops\r\n```\r\n\r\nFinally, I get the tflite and the summarize like below:\r\n```\r\n# summarize frozen pb\r\nInputs\r\n\tname=Placeholder\r\n\ttype=float(1)\r\n\tshape=[?,28,28]\r\nOutputs\r\n\tname=output, op=Add\r\nOp Types\r\n\t99 Const\r\n\t84 Mul\r\n\t84 Sigmoid\r\n\t57 Add\r\n\t56 Tanh\r\n\t30 ConcatV2\r\n\t29 MatMul\r\n\t28 BiasAdd\r\n\t28 Split\r\n\t2 ExpandDims\r\n\t2 Fill\r\n\t1 Placeholder\r\n\t1 Shape\r\n\t1 StridedSlice\r\n\t1 Unpack\r\n```\r\n```\r\n# summarize tflite\r\nNumber of operator types: 12\r\n\tCUSTOM(Unpack)[32]                    :    1 \t (total_ops: ???)\r\n\tCUSTOM(TensorFlowShape)[32]           :    1 \t (total_ops: ???)\r\n\tSTRIDED_SLICE[45]                     :    1 \t (total_ops: ???)\r\n\tCUSTOM(ExpandDims)[32]                :    2 \t (total_ops: ???)\r\n\tCONCATENATION[2]                      :   30 \t (total_ops: ???)\r\n\tCUSTOM(Fill)[32]                      :    2 \t (total_ops: ???)\r\n\tFULLY_CONNECTED[9]                    :   29 \t (total_ops: ???)\r\n\tSPLIT[49]                             :   28 \t (total_ops: ???)\r\n\tADD[0]                                :   56 \t (total_ops: ???)\r\n\tLOGISTIC[14]                          :   84 \t (total_ops: ???)\r\n\tMUL[18]                               :   84 \t (total_ops: ???)\r\n\tTANH[28]                              :   56 \t (total_ops: ???)\r\nTotal Number of operators                     :  374 \t (total_ops: 0)\r\n```"}