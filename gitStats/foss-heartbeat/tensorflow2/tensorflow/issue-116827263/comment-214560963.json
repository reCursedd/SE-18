{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/214560963", "html_url": "https://github.com/tensorflow/tensorflow/issues/206#issuecomment-214560963", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/206", "id": 214560963, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNDU2MDk2Mw==", "user": {"login": "danijar", "id": 2111293, "node_id": "MDQ6VXNlcjIxMTEyOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2111293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danijar", "html_url": "https://github.com/danijar", "followers_url": "https://api.github.com/users/danijar/followers", "following_url": "https://api.github.com/users/danijar/following{/other_user}", "gists_url": "https://api.github.com/users/danijar/gists{/gist_id}", "starred_url": "https://api.github.com/users/danijar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danijar/subscriptions", "organizations_url": "https://api.github.com/users/danijar/orgs", "repos_url": "https://api.github.com/users/danijar/repos", "events_url": "https://api.github.com/users/danijar/events{/privacy}", "received_events_url": "https://api.github.com/users/danijar/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-25T23:20:43Z", "updated_at": "2016-04-26T13:02:09Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=106472\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/waleedka\">@waleedka</a> I adapted <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a>'s example to work with an additional dimension for the output neurons of an RNN. This should yield the last relevant output activations while preserving the shape information.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">extract_last_relevant</span>(<span class=\"pl-smi\">outputs</span>, <span class=\"pl-smi\">length</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">        outputs: [Tensor(batch_size, output_neurons)]: A list containing the output</span>\n<span class=\"pl-s\">            activations of each in the batch for each time step as returned by</span>\n<span class=\"pl-s\">            tensorflow.models.rnn.rnn.</span>\n<span class=\"pl-s\">        length: Tensor(batch_size): The used sequence length of each example in the</span>\n<span class=\"pl-s\">            batch with all later time steps being zeros. Should be of type tf.int32.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Returns:</span>\n<span class=\"pl-s\">        Tensor(batch_size, output_neurons): The last relevant output activation for</span>\n<span class=\"pl-s\">            each example in the batch.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    output <span class=\"pl-k\">=</span> tf.transpose(tf.pack(outputs), <span class=\"pl-v\">perm</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Query shape.</span>\n    batch_size <span class=\"pl-k\">=</span> tf.shape(output)[<span class=\"pl-c1\">0</span>]\n    max_length <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(output.get_shape()[<span class=\"pl-c1\">1</span>])\n    num_neurons <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(output.get_shape()[<span class=\"pl-c1\">2</span>])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Index into flattened array as a workaround.</span>\n    index <span class=\"pl-k\">=</span> tf.range(<span class=\"pl-c1\">0</span>, batch_size) <span class=\"pl-k\">*</span> max_length <span class=\"pl-k\">+</span> (length <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)\n    flat <span class=\"pl-k\">=</span> tf.reshape(output, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, num_neurons])\n    relevant <span class=\"pl-k\">=</span> tf.gather(flat, index)\n    <span class=\"pl-k\">return</span> relevant</pre></div>", "body_text": "@waleedka I adapted @ebrevdo's example to work with an additional dimension for the output neurons of an RNN. This should yield the last relevant output activations while preserving the shape information.\ndef extract_last_relevant(outputs, length):\n    \"\"\"\n    Args:\n        outputs: [Tensor(batch_size, output_neurons)]: A list containing the output\n            activations of each in the batch for each time step as returned by\n            tensorflow.models.rnn.rnn.\n        length: Tensor(batch_size): The used sequence length of each example in the\n            batch with all later time steps being zeros. Should be of type tf.int32.\n\n    Returns:\n        Tensor(batch_size, output_neurons): The last relevant output activation for\n            each example in the batch.\n    \"\"\"\n    output = tf.transpose(tf.pack(outputs), perm=[1, 0, 2])\n    # Query shape.\n    batch_size = tf.shape(output)[0]\n    max_length = int(output.get_shape()[1])\n    num_neurons = int(output.get_shape()[2])\n    # Index into flattened array as a workaround.\n    index = tf.range(0, batch_size) * max_length + (length - 1)\n    flat = tf.reshape(output, [-1, num_neurons])\n    relevant = tf.gather(flat, index)\n    return relevant", "body": "@waleedka I adapted @ebrevdo's example to work with an additional dimension for the output neurons of an RNN. This should yield the last relevant output activations while preserving the shape information.\n\n``` python\ndef extract_last_relevant(outputs, length):\n    \"\"\"\n    Args:\n        outputs: [Tensor(batch_size, output_neurons)]: A list containing the output\n            activations of each in the batch for each time step as returned by\n            tensorflow.models.rnn.rnn.\n        length: Tensor(batch_size): The used sequence length of each example in the\n            batch with all later time steps being zeros. Should be of type tf.int32.\n\n    Returns:\n        Tensor(batch_size, output_neurons): The last relevant output activation for\n            each example in the batch.\n    \"\"\"\n    output = tf.transpose(tf.pack(outputs), perm=[1, 0, 2])\n    # Query shape.\n    batch_size = tf.shape(output)[0]\n    max_length = int(output.get_shape()[1])\n    num_neurons = int(output.get_shape()[2])\n    # Index into flattened array as a workaround.\n    index = tf.range(0, batch_size) * max_length + (length - 1)\n    flat = tf.reshape(output, [-1, num_neurons])\n    relevant = tf.gather(flat, index)\n    return relevant\n```\n"}