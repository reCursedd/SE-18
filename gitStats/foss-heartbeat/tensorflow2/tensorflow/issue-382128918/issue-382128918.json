{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23847", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23847/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23847/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23847/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23847", "id": 382128918, "node_id": "MDU6SXNzdWUzODIxMjg5MTg=", "number": 23847, "title": "~40% performance decrease since Tensorflow 1.9 when training large models", "user": {"login": "DavidWiesner", "id": 243115, "node_id": "MDQ6VXNlcjI0MzExNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/243115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidWiesner", "html_url": "https://github.com/DavidWiesner", "followers_url": "https://api.github.com/users/DavidWiesner/followers", "following_url": "https://api.github.com/users/DavidWiesner/following{/other_user}", "gists_url": "https://api.github.com/users/DavidWiesner/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidWiesner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidWiesner/subscriptions", "organizations_url": "https://api.github.com/users/DavidWiesner/orgs", "repos_url": "https://api.github.com/users/DavidWiesner/repos", "events_url": "https://api.github.com/users/DavidWiesner/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidWiesner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-19T09:38:43Z", "updated_at": "2018-11-19T09:43:37Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): v1.9.0-0-g25c197e 1.9.0</li>\n<li>Python version: 3</li>\n<li>Bazel version (if compiling from source): -</li>\n<li>GCC/Compiler version (if compiling from source): -</li>\n<li>CUDA/cuDNN version: 9.0.176/7.1.4.18</li>\n<li>GPU model and memory: 8 x Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI train a model using slim in tensorflow models with the flowers dataset and the large nasnet. This were run on the official tensorflow docker images.<br>\nOn my Tesla V100 for tensorflow 1.8.0-devel-gpu-py3 I got around<br>\n<code>INFO:tensorflow:global_step/sec: 1.33334</code><br>\nWith tensorflow 1.9.0-devel-gpu-py3 a maximum at<br>\n<code>INFO:tensorflow:global_step/sec: 0.89946</code><br>\nWith the current tensorflow 1.12.0-devel-gpu-py3 a maximum at<br>\n<code>INFO:tensorflow:global_step/sec: 0.900003</code></p>\n<p><strong>Describe the expected behavior</strong><br>\nThere should not be an performance decrease in this drastic</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#!</span>/usr/bin/env bash</span>\n[ <span class=\"pl-k\">!</span> <span class=\"pl-k\">-d</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>models<span class=\"pl-pds\">\"</span></span> ] <span class=\"pl-k\">&amp;&amp;</span> git clone https://github.com/tensorflow/models.git\n<span class=\"pl-c1\">cd</span> models/research/slim/\nMODEL_NAME=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nasnet_large<span class=\"pl-pds\">\"</span></span>\nTRAIN_DIR=/tmp/flowers-models/<span class=\"pl-smi\">${MODEL_NAME}</span>\nDATASET_DIR=/tmp/flowers\nrm -rf <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">$TRAIN_DIR</span><span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">export</span> CUDA_DEVICE_ORDER=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>PCI_BUS_ID<span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">export</span> CUDA_VISIBLE_DEVICES=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>0,1<span class=\"pl-pds\">\"</span></span>\n\npython download_and_convert_data.py \\\n    --dataset_name=flowers \\\n    --dataset_dir=<span class=\"pl-smi\">${DATASET_DIR}</span>\n\npython train_image_classifier.py \\\n    --train_dir=<span class=\"pl-smi\">${TRAIN_DIR}</span>/all \\\n    --dataset_name=flowers \\\n    --dataset_split_name=train \\\n    --dataset_dir=<span class=\"pl-smi\">${DATASET_DIR}</span> \\\n    --model_name=<span class=\"pl-smi\">${MODEL_NAME}</span> \\\n    --max_number_of_steps=500 \\\n    --batch_size=16 \\\n    --learning_rate=0.015 \\\n    --save_interval_secs=60000 \\\n    --save_summaries_secs=60 \\\n    --log_every_n_steps=10 \\\n    --optimizer=rmsprop \\\n    --num_preprocessing_threads 4 \\\n    --num_readers 8 \\\n    --moving_average_decay=0.9999 \\\n    --weight_decay=0.00005 \\\n    --learning_rate_decay_type=exponential \\\n    --learning_rate_decay_factor=0.97 \\\n    --label_smoothing=0.1</pre></div>\n<p><strong>Other info / logs</strong><br>\nI thought this issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"341575533\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/20843\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/20843/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/20843\">#20843</a> is related to the problem but I have done a git bisect between the <code>v1.8.0</code> and the <code>v1.9.0</code> tag and running the script above for every commit and found the one that introduce the largest drop in performance: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29\"><tt>d4976f7</tt></a>. This commit enabled the layout optimizer by default for all gpu cluster. As a workaround and a proof I disabled the layout optimizer with the following config:</p>\n<div class=\"highlight highlight-source-python\"><pre>rewrite_options <span class=\"pl-k\">=</span> rewriter_config_pb2.RewriterConfig(<span class=\"pl-v\">layout_optimizer</span><span class=\"pl-k\">=</span>rewriter_config_pb2.RewriterConfig.<span class=\"pl-c1\">OFF</span>)\ngraph_options <span class=\"pl-k\">=</span> tf.GraphOptions(<span class=\"pl-v\">rewrite_options</span><span class=\"pl-k\">=</span>rewrite_options)\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">graph_options</span><span class=\"pl-k\">=</span>graph_options) </pre></div>\n<p>And most of the performance were back again in <code>tensorflow 1.9.0-devel-gpu-py3</code>:<br>\n<code>INFO:tensorflow:global_step/sec: 1.18333</code><br>\nAnd in the latest release <code>tensorflow 1.12.0-devel-gpu-py3</code>:<br>\n<code>INFO:tensorflow:global_step/sec: 1.23337</code><br>\n<a href=\"https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-log\">Here</a> is a full log of my bisect script. <a href=\"https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-layout_optimizer-on-off-log\">One another log</a> shows the influence of disabling the layout-optimizer in commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29\"><tt>d4976f7</tt></a> (that introducing the drop in performance) and some release versions of tensorflow.<br>\nMaybe <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=841638\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaozhang\">@yaozhang</a> can answer why the layout optimizer was disabled for some architectures until 1.8.0 in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/f0d1abbf2389aa2a29fe6fd090ba68ab6b8fd76f/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/f0d1abbf2389aa2a29fe6fd090ba68ab6b8fd76f\"><tt>f0d1abb</tt></a> and why <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1034716\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhangyaobit\">@zhangyaobit</a> enabled for all architectures since 1.9.0 in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/d4976f754009d084514f4308d3bfc7dc3a106e29\"><tt>d4976f7</tt></a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.9.0-0-g25c197e 1.9.0\nPython version: 3\nBazel version (if compiling from source): -\nGCC/Compiler version (if compiling from source): -\nCUDA/cuDNN version: 9.0.176/7.1.4.18\nGPU model and memory: 8 x Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n\nDescribe the current behavior\nI train a model using slim in tensorflow models with the flowers dataset and the large nasnet. This were run on the official tensorflow docker images.\nOn my Tesla V100 for tensorflow 1.8.0-devel-gpu-py3 I got around\nINFO:tensorflow:global_step/sec: 1.33334\nWith tensorflow 1.9.0-devel-gpu-py3 a maximum at\nINFO:tensorflow:global_step/sec: 0.89946\nWith the current tensorflow 1.12.0-devel-gpu-py3 a maximum at\nINFO:tensorflow:global_step/sec: 0.900003\nDescribe the expected behavior\nThere should not be an performance decrease in this drastic\nCode to reproduce the issue\n#!/usr/bin/env bash\n[ ! -d \"models\" ] && git clone https://github.com/tensorflow/models.git\ncd models/research/slim/\nMODEL_NAME=\"nasnet_large\"\nTRAIN_DIR=/tmp/flowers-models/${MODEL_NAME}\nDATASET_DIR=/tmp/flowers\nrm -rf \"$TRAIN_DIR\"\nexport CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\nexport CUDA_VISIBLE_DEVICES=\"0,1\"\n\npython download_and_convert_data.py \\\n    --dataset_name=flowers \\\n    --dataset_dir=${DATASET_DIR}\n\npython train_image_classifier.py \\\n    --train_dir=${TRAIN_DIR}/all \\\n    --dataset_name=flowers \\\n    --dataset_split_name=train \\\n    --dataset_dir=${DATASET_DIR} \\\n    --model_name=${MODEL_NAME} \\\n    --max_number_of_steps=500 \\\n    --batch_size=16 \\\n    --learning_rate=0.015 \\\n    --save_interval_secs=60000 \\\n    --save_summaries_secs=60 \\\n    --log_every_n_steps=10 \\\n    --optimizer=rmsprop \\\n    --num_preprocessing_threads 4 \\\n    --num_readers 8 \\\n    --moving_average_decay=0.9999 \\\n    --weight_decay=0.00005 \\\n    --learning_rate_decay_type=exponential \\\n    --learning_rate_decay_factor=0.97 \\\n    --label_smoothing=0.1\nOther info / logs\nI thought this issue #20843 is related to the problem but I have done a git bisect between the v1.8.0 and the v1.9.0 tag and running the script above for every commit and found the one that introduce the largest drop in performance: d4976f7. This commit enabled the layout optimizer by default for all gpu cluster. As a workaround and a proof I disabled the layout optimizer with the following config:\nrewrite_options = rewriter_config_pb2.RewriterConfig(layout_optimizer=rewriter_config_pb2.RewriterConfig.OFF)\ngraph_options = tf.GraphOptions(rewrite_options=rewrite_options)\nconfig = tf.ConfigProto(graph_options=graph_options) \nAnd most of the performance were back again in tensorflow 1.9.0-devel-gpu-py3:\nINFO:tensorflow:global_step/sec: 1.18333\nAnd in the latest release tensorflow 1.12.0-devel-gpu-py3:\nINFO:tensorflow:global_step/sec: 1.23337\nHere is a full log of my bisect script. One another log shows the influence of disabling the layout-optimizer in commit d4976f7 (that introducing the drop in performance) and some release versions of tensorflow.\nMaybe @yaozhang can answer why the layout optimizer was disabled for some architectures until 1.8.0 in f0d1abb and why @zhangyaobit enabled for all architectures since 1.9.0 in d4976f7", "body": "**System information**\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.9.0-0-g25c197e 1.9.0\r\n- Python version: 3\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 9.0.176/7.1.4.18\r\n- GPU model and memory: 8 x Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n\r\n**Describe the current behavior**\r\nI train a model using slim in tensorflow models with the flowers dataset and the large nasnet. This were run on the official tensorflow docker images.\r\nOn my Tesla V100 for tensorflow 1.8.0-devel-gpu-py3 I got around \r\n`INFO:tensorflow:global_step/sec: 1.33334`\r\nWith tensorflow 1.9.0-devel-gpu-py3 a maximum at\r\n`INFO:tensorflow:global_step/sec: 0.89946`\r\nWith the current tensorflow 1.12.0-devel-gpu-py3 a maximum at\r\n`INFO:tensorflow:global_step/sec: 0.900003`\r\n\r\n**Describe the expected behavior**\r\nThere should not be an performance decrease in this drastic \r\n\r\n**Code to reproduce the issue**\r\n```shell\r\n#!/usr/bin/env bash\r\n[ ! -d \"models\" ] && git clone https://github.com/tensorflow/models.git\r\ncd models/research/slim/\r\nMODEL_NAME=\"nasnet_large\"\r\nTRAIN_DIR=/tmp/flowers-models/${MODEL_NAME}\r\nDATASET_DIR=/tmp/flowers\r\nrm -rf \"$TRAIN_DIR\"\r\nexport CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\r\nexport CUDA_VISIBLE_DEVICES=\"0,1\"\r\n\r\npython download_and_convert_data.py \\\r\n    --dataset_name=flowers \\\r\n    --dataset_dir=${DATASET_DIR}\r\n\r\npython train_image_classifier.py \\\r\n    --train_dir=${TRAIN_DIR}/all \\\r\n    --dataset_name=flowers \\\r\n    --dataset_split_name=train \\\r\n    --dataset_dir=${DATASET_DIR} \\\r\n    --model_name=${MODEL_NAME} \\\r\n    --max_number_of_steps=500 \\\r\n    --batch_size=16 \\\r\n    --learning_rate=0.015 \\\r\n    --save_interval_secs=60000 \\\r\n    --save_summaries_secs=60 \\\r\n    --log_every_n_steps=10 \\\r\n    --optimizer=rmsprop \\\r\n    --num_preprocessing_threads 4 \\\r\n    --num_readers 8 \\\r\n    --moving_average_decay=0.9999 \\\r\n    --weight_decay=0.00005 \\\r\n    --learning_rate_decay_type=exponential \\\r\n    --learning_rate_decay_factor=0.97 \\\r\n    --label_smoothing=0.1\r\n```\r\n\r\n**Other info / logs**\r\nI thought this issue #20843 is related to the problem but I have done a git bisect between the `v1.8.0` and the `v1.9.0` tag and running the script above for every commit and found the one that introduce the largest drop in performance: d4976f7. This commit enabled the layout optimizer by default for all gpu cluster. As a workaround and a proof I disabled the layout optimizer with the following config:\r\n```python\r\nrewrite_options = rewriter_config_pb2.RewriterConfig(layout_optimizer=rewriter_config_pb2.RewriterConfig.OFF)\r\ngraph_options = tf.GraphOptions(rewrite_options=rewrite_options)\r\nconfig = tf.ConfigProto(graph_options=graph_options) \r\n```  \r\nAnd most of the performance were back again in `tensorflow 1.9.0-devel-gpu-py3`:\r\n`INFO:tensorflow:global_step/sec: 1.18333`\r\nAnd in the latest release `tensorflow 1.12.0-devel-gpu-py3`:\r\n`INFO:tensorflow:global_step/sec: 1.23337`\r\n[Here](https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-log) is a full log of my bisect script. [One another log](https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-layout_optimizer-on-off-log) shows the influence of disabling the layout-optimizer in commit d4976f7 (that introducing the drop in performance) and some release versions of tensorflow. \r\nMaybe @yaozhang can answer why the layout optimizer was disabled for some architectures until 1.8.0 in f0d1abbf2 and why @zhangyaobit enabled for all architectures since 1.9.0 in d4976f7\r\n"}