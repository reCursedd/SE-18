{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269558171", "html_url": "https://github.com/tensorflow/tensorflow/issues/6541#issuecomment-269558171", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6541", "id": 269558171, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTU1ODE3MQ==", "user": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-28T23:30:05Z", "updated_at": "2016-12-28T23:30:05Z", "author_association": "MEMBER", "body_html": "<p>Good catch <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a>, forgot the run() call. When putting in a run() call (see below code), I get</p>\n<pre><code>tensorflow:1.78562903404s\nnumpy:0.0487790107727s\n</code></pre>\n<p>which I suppose is comparible to your results (yours was numpy 66x faster, and mine was like numpy 33x faster). One explanation is that the GPU FFT implementation is really not tuned to smalls sizes, so that it can't achieve the same performance of the CPU FFT on a relatively small 513 element array. That's only 2 KBytes of data, which is not much for throughput optimized devices. As such I ran another one where I set <code>N=16384</code> which will basically use <code>8193</code> element array. Then I got</p>\n<pre><code>tensorflow:5.21\nnumpy:41.5\n</code></pre>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> time\n\nniterations<span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>\nN<span class=\"pl-k\">=</span><span class=\"pl-c1\">16384</span>\nwav <span class=\"pl-k\">=</span> np.random.random_sample((N,))\nspec <span class=\"pl-k\">=</span> np.fft.fft(wav)[:N<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span><span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>]\n\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create and initialize variables</span>\n  cnt <span class=\"pl-k\">=</span> tf.Variable(tf.constant(niterations))\n  specVar <span class=\"pl-k\">=</span> tf.Variable(spec, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.complex64)\n  sess.run(tf.variables_initializer([specVar,cnt]))\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> While loop that counts down to zero and computes reverse and forward fft's</span>\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">condition</span>(<span class=\"pl-smi\">x</span>,<span class=\"pl-smi\">cnt</span>):\n    <span class=\"pl-k\">return</span> cnt <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">x</span>,<span class=\"pl-smi\">cnt</span>):\n    xrev<span class=\"pl-k\">=</span>tf.ifft(x)\n    xnew<span class=\"pl-k\">=</span>tf.fft(xrev)\n    cntnew<span class=\"pl-k\">=</span>cnt<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>\n    <span class=\"pl-k\">return</span> xnew, cntnew\n\n  start <span class=\"pl-k\">=</span> time.time()\n\n  final, cnt<span class=\"pl-k\">=</span> tf.while_loop(condition, body, [specVar,cnt], <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n  final, cnt <span class=\"pl-k\">=</span>  sess.run([final,cnt])\n\n  <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>tensorflow:<span class=\"pl-c1\">{}</span>s<span class=\"pl-pds\">'</span></span>.format(time.time()<span class=\"pl-k\">-</span>start)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Equivalent numpy loop</span>\nstart <span class=\"pl-k\">=</span> time.time()\nx <span class=\"pl-k\">=</span> spec\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(niterations):\n   xrev <span class=\"pl-k\">=</span> np.fft.ifft(x)\n   x<span class=\"pl-k\">=</span> np.fft.fft(xrev)\n   \n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>numpy:<span class=\"pl-c1\">{}</span>s<span class=\"pl-pds\">'</span></span>.format(time.time() <span class=\"pl-k\">-</span> start)\n</pre></div>", "body_text": "Good catch @vrv, forgot the run() call. When putting in a run() call (see below code), I get\ntensorflow:1.78562903404s\nnumpy:0.0487790107727s\n\nwhich I suppose is comparible to your results (yours was numpy 66x faster, and mine was like numpy 33x faster). One explanation is that the GPU FFT implementation is really not tuned to smalls sizes, so that it can't achieve the same performance of the CPU FFT on a relatively small 513 element array. That's only 2 KBytes of data, which is not much for throughput optimized devices. As such I ran another one where I set N=16384 which will basically use 8193 element array. Then I got\ntensorflow:5.21\nnumpy:41.5\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nniterations=1000\nN=16384\nwav = np.random.random_sample((N,))\nspec = np.fft.fft(wav)[:N/2+1]\n\n\nwith tf.Session() as sess:\n  # Create and initialize variables\n  cnt = tf.Variable(tf.constant(niterations))\n  specVar = tf.Variable(spec, dtype=tf.complex64)\n  sess.run(tf.variables_initializer([specVar,cnt]))\n\n  # While loop that counts down to zero and computes reverse and forward fft's\n  def condition(x,cnt):\n    return cnt > 0\n\n  def body(x,cnt):\n    xrev=tf.ifft(x)\n    xnew=tf.fft(xrev)\n    cntnew=cnt-1\n    return xnew, cntnew\n\n  start = time.time()\n\n  final, cnt= tf.while_loop(condition, body, [specVar,cnt], parallel_iterations=1)\n  final, cnt =  sess.run([final,cnt])\n\n  print 'tensorflow:{}s'.format(time.time()-start)\n\n# Equivalent numpy loop\nstart = time.time()\nx = spec\nfor i in range(niterations):\n   xrev = np.fft.ifft(x)\n   x= np.fft.fft(xrev)\n   \nprint 'numpy:{}s'.format(time.time() - start)", "body": "Good catch @vrv, forgot the run() call. When putting in a run() call (see below code), I get \r\n```\r\ntensorflow:1.78562903404s\r\nnumpy:0.0487790107727s\r\n```\r\nwhich I suppose is comparible to your results (yours was numpy 66x faster, and mine was like numpy 33x faster). One explanation is that the GPU FFT implementation is really not tuned to smalls sizes, so that it can't achieve the same performance of the CPU FFT on a relatively small 513 element array. That's only 2 KBytes of data, which is not much for throughput optimized devices. As such I ran another one where I set `N=16384` which will basically use `8193` element array. Then I got\r\n```\r\ntensorflow:5.21\r\nnumpy:41.5\r\n```\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport time\r\n\r\nniterations=1000\r\nN=16384\r\nwav = np.random.random_sample((N,))\r\nspec = np.fft.fft(wav)[:N/2+1]\r\n\r\n\r\nwith tf.Session() as sess:\r\n  # Create and initialize variables\r\n  cnt = tf.Variable(tf.constant(niterations))\r\n  specVar = tf.Variable(spec, dtype=tf.complex64)\r\n  sess.run(tf.variables_initializer([specVar,cnt]))\r\n\r\n  # While loop that counts down to zero and computes reverse and forward fft's\r\n  def condition(x,cnt):\r\n    return cnt > 0\r\n\r\n  def body(x,cnt):\r\n    xrev=tf.ifft(x)\r\n    xnew=tf.fft(xrev)\r\n    cntnew=cnt-1\r\n    return xnew, cntnew\r\n\r\n  start = time.time()\r\n\r\n  final, cnt= tf.while_loop(condition, body, [specVar,cnt], parallel_iterations=1)\r\n  final, cnt =  sess.run([final,cnt])\r\n\r\n  print 'tensorflow:{}s'.format(time.time()-start)\r\n\r\n# Equivalent numpy loop\r\nstart = time.time()\r\nx = spec\r\nfor i in range(niterations):\r\n   xrev = np.fft.ifft(x)\r\n   x= np.fft.fft(xrev)\r\n   \r\nprint 'numpy:{}s'.format(time.time() - start)\r\n\r\n```"}