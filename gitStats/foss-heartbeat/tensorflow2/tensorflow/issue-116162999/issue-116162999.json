{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/101", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/101/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/101/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/101/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/101", "id": 116162999, "node_id": "MDU6SXNzdWUxMTYxNjI5OTk=", "number": 101, "title": "Neural Translation Model example fails due to missing EN tokens ", "user": {"login": "rameshdom", "id": 15787354, "node_id": "MDQ6VXNlcjE1Nzg3MzU0", "avatar_url": "https://avatars3.githubusercontent.com/u/15787354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rameshdom", "html_url": "https://github.com/rameshdom", "followers_url": "https://api.github.com/users/rameshdom/followers", "following_url": "https://api.github.com/users/rameshdom/following{/other_user}", "gists_url": "https://api.github.com/users/rameshdom/gists{/gist_id}", "starred_url": "https://api.github.com/users/rameshdom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rameshdom/subscriptions", "organizations_url": "https://api.github.com/users/rameshdom/orgs", "repos_url": "https://api.github.com/users/rameshdom/repos", "events_url": "https://api.github.com/users/rameshdom/events{/privacy}", "received_events_url": "https://api.github.com/users/rameshdom/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-11-10T17:45:27Z", "updated_at": "2015-12-02T01:59:57Z", "closed_at": "2015-11-12T21:57:00Z", "author_association": "NONE", "body_html": "<p>The S2S Neural Translation example (tensorflow/models/rnn/translate)  runs into this error:</p>\n<blockquote>\n<p>tensorflow.python.platform.default._gfile.FileError: [Errno 2] No such file or directory: 'data/giga-fren.release2.ids40000.en'</p>\n</blockquote>\n<p>The issue seems to be in prepare_wmt_data of data_utils.py. Here, instead of creating a new file for the EN tokens, the FR tokens are overwritten by EN tokens:</p>\n<blockquote>\n<p>data_to_token_ids(train_path + \".en\", fr_train_ids_path, fr_vocab_path)</p>\n</blockquote>\n<p>The fix seems to be as simple as changing that line to:</p>\n<blockquote>\n<p>data_to_token_ids(train_path + \".en\", en_train_ids_path, en_vocab_path)</p>\n</blockquote>", "body_text": "The S2S Neural Translation example (tensorflow/models/rnn/translate)  runs into this error:\n\ntensorflow.python.platform.default._gfile.FileError: [Errno 2] No such file or directory: 'data/giga-fren.release2.ids40000.en'\n\nThe issue seems to be in prepare_wmt_data of data_utils.py. Here, instead of creating a new file for the EN tokens, the FR tokens are overwritten by EN tokens:\n\ndata_to_token_ids(train_path + \".en\", fr_train_ids_path, fr_vocab_path)\n\nThe fix seems to be as simple as changing that line to:\n\ndata_to_token_ids(train_path + \".en\", en_train_ids_path, en_vocab_path)", "body": "The S2S Neural Translation example (tensorflow/models/rnn/translate)  runs into this error:\n\n> tensorflow.python.platform.default._gfile.FileError: [Errno 2] No such file or directory: 'data/giga-fren.release2.ids40000.en'\n\nThe issue seems to be in prepare_wmt_data of data_utils.py. Here, instead of creating a new file for the EN tokens, the FR tokens are overwritten by EN tokens:\n\n> data_to_token_ids(train_path + \".en\", fr_train_ids_path, fr_vocab_path)\n\nThe fix seems to be as simple as changing that line to:\n\n> data_to_token_ids(train_path + \".en\", en_train_ids_path, en_vocab_path)\n"}