{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20747", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20747/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20747/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20747/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20747", "id": 340728994, "node_id": "MDU6SXNzdWUzNDA3Mjg5OTQ=", "number": 20747, "title": "TPU code running locally but not on TPU", "user": {"login": "jplu", "id": 959590, "node_id": "MDQ6VXNlcjk1OTU5MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/959590?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jplu", "html_url": "https://github.com/jplu", "followers_url": "https://api.github.com/users/jplu/followers", "following_url": "https://api.github.com/users/jplu/following{/other_user}", "gists_url": "https://api.github.com/users/jplu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jplu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jplu/subscriptions", "organizations_url": "https://api.github.com/users/jplu/orgs", "repos_url": "https://api.github.com/users/jplu/repos", "events_url": "https://api.github.com/users/jplu/events{/privacy}", "received_events_url": "https://api.github.com/users/jplu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-07-12T17:26:00Z", "updated_at": "2018-07-14T14:24:49Z", "closed_at": "2018-07-13T16:58:58Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes, I did put the code below</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Debian 9</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: already installed while creating the VM</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0-rc2</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>: Not compiled</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Not compiled</li>\n<li><strong>CUDA/cuDNN version</strong>: not installed</li>\n<li><strong>GPU model and memory</strong>: no GPU</li>\n<li><strong>Exact command to reproduce</strong>: <code>python3 test.py --tpu=$TPU_NAME --model_dir=output -use-tpu=True --batch_size=24</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When I run the following code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow.python.keras.applications.vgg16 <span class=\"pl-k\">import</span> <span class=\"pl-c1\">VGG16</span>\n<span class=\"pl-k\">from</span> tensorflow.python.keras <span class=\"pl-k\">import</span> models\n<span class=\"pl-k\">from</span> tensorflow.python.keras <span class=\"pl-k\">import</span> layers\n<span class=\"pl-k\">from</span> tensorflow.python.keras.preprocessing <span class=\"pl-k\">import</span> image\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python <span class=\"pl-k\">import</span> keras\n<span class=\"pl-k\">from</span> absl <span class=\"pl-k\">import</span> flags\n<span class=\"pl-k\">import</span> absl.logging <span class=\"pl-k\">as</span> _logging\n<span class=\"pl-k\">from</span> tensorflow.contrib.tpu.python.tpu <span class=\"pl-k\">import</span> tpu_config\n<span class=\"pl-k\">from</span> tensorflow.contrib.tpu.python.tpu <span class=\"pl-k\">import</span> tpu_estimator\n<span class=\"pl-k\">from</span> tensorflow.contrib.tpu.python.tpu <span class=\"pl-k\">import</span> tpu_optimizer\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> random\n<span class=\"pl-k\">import</span> math\n<span class=\"pl-k\">import</span> os\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>  Cloud TPU Cluster Resolver flags</span>\ntf.flags.DEFINE_string(\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tpu<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>The Cloud TPU to use for training. This should be either the name <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>url.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_string(\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tpu_zone<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[Optional] GCE zone where the Cloud TPU is located in. If not <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>specified, we will attempt to automatically detect the GCE project from <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>metadata.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_string(\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gcp_project<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>[Optional] Project name for the Cloud TPU-enabled project. If not <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>specified, we will attempt to automatically detect the GCE project from <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>metadata.<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Model specific parameters</span>\ntf.flags.DEFINE_string(\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>master<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You <span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>must specify either this flag or --tpu.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data_dir<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n                       <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Path to directory containing the dataset<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_string(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>model_dir<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Estimator model_dir<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch_size<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">3</span>,\n                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Mini-batch size for the training. Note that this <span class=\"pl-pds\">\"</span></span>\n                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>is the global batch size and not the per-shard batch.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>train_steps<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Total number of training steps.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_float(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>learning_rate<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">0.001</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Learning rate.<span class=\"pl-pds\">\"</span></span>)\n\ntf.flags.DEFINE_bool(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>use_tpu<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">True</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use TPUs rather than plain CPUs<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>iterations<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">1</span>,\n                        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Number of iterations per TPU training loop.<span class=\"pl-pds\">\"</span></span>)\ntf.flags.DEFINE_integer(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num_shards<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Number of shards (TPU chips).<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> tf.flags.<span class=\"pl-c1\">FLAGS</span>\n\nfeature_names <span class=\"pl-k\">=</span> [\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">load_triplets</span>():\n    triplets <span class=\"pl-k\">=</span> []\n    triplet_file <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.data_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>triplets.txt<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">with</span> tf.gfile.GFile(triplet_file) <span class=\"pl-k\">as</span> f:\n        count <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n        <span class=\"pl-k\">for</span> line <span class=\"pl-k\">in</span> f:\n            triplets.append(line.strip().split(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>,<span class=\"pl-pds\">'</span></span>))\n            count <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n            <span class=\"pl-k\">if</span> count <span class=\"pl-k\">%</span> <span class=\"pl-c1\">1000</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n                tf.logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Loading <span class=\"pl-c1\">{}</span> triplets<span class=\"pl-pds\">\"</span></span>.format(count))\n\n    tf.logging.info(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Loading <span class=\"pl-c1\">{}</span> triplets<span class=\"pl-pds\">\"</span></span>.format(count))\n    <span class=\"pl-k\">return</span> triplets\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">my_input_fn</span>(<span class=\"pl-smi\">triplet</span>, <span class=\"pl-smi\">label</span>):\n    query_img <span class=\"pl-k\">=</span> tf.image.decode_jpeg(triplet[<span class=\"pl-c1\">0</span>], <span class=\"pl-v\">channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\n    query_img.set_shape([<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>])\n    query_img <span class=\"pl-k\">=</span> tf.image.resize_images(query_img, [<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>])\n    query_img.set_shape([<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">3</span>])\n    positive_img <span class=\"pl-k\">=</span> tf.image.decode_jpeg(tf.read_file(triplet[<span class=\"pl-c1\">1</span>]), <span class=\"pl-v\">channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\n    positive_img.set_shape([<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>])\n    positive_img <span class=\"pl-k\">=</span> tf.image.resize_images(positive_img, [<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>])\n    positive_img.set_shape([<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">3</span>])\n    negative_img <span class=\"pl-k\">=</span> tf.image.decode_jpeg(tf.read_file(triplet[<span class=\"pl-c1\">2</span>]), <span class=\"pl-v\">channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\n    negative_img.set_shape([<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>])\n    negative_img <span class=\"pl-k\">=</span> tf.image.resize_images(negative_img, [<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>])\n    negative_img.set_shape([<span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">3</span>])\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [query_img, positive_img, negative_img])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_flip_left_right</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_flip_left_right(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_flip_left_right(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_flip_left_right(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_flip_up_down</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_flip_up_down(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_flip_up_down(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_flip_up_down(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_brightness</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_brightness(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">1.0</span>))\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_brightness(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">1.0</span>))\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_brightness(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">1.0</span>))\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_contrast</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_contrast(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.3</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_contrast(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.3</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_contrast(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.3</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_hue</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_hue(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.5</span>))\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_hue(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.5</span>))\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_hue(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">max_delta</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.5</span>))\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_saturation</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.image.random_saturation(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2.0</span>)\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.image.random_saturation(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2.0</span>)\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.image.random_saturation(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">lower</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>, <span class=\"pl-v\">upper</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2.0</span>)\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">random_rotate</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">label</span>):\n    augmented_query <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>])\n    augmented_query <span class=\"pl-k\">=</span> tf.contrib.image.rotate(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">angles</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">360</span>) <span class=\"pl-k\">*</span> math.pi <span class=\"pl-k\">/</span> <span class=\"pl-c1\">180</span>)\n    augmented_query <span class=\"pl-k\">=</span> tf.cast(augmented_query, np.uint8)\n    augmented_positive <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>])\n    augmented_positive <span class=\"pl-k\">=</span> tf.contrib.image.rotate(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">angles</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">360</span>) <span class=\"pl-k\">*</span> math.pi <span class=\"pl-k\">/</span> <span class=\"pl-c1\">180</span>)\n    augmented_positive <span class=\"pl-k\">=</span> tf.cast(augmented_positive, np.uint8)\n    augmented_negative <span class=\"pl-k\">=</span> tf.to_float(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>])\n    augmented_negative <span class=\"pl-k\">=</span> tf.contrib.image.rotate(image[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">angles</span><span class=\"pl-k\">=</span>random.uniform(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">360</span>) <span class=\"pl-k\">*</span> math.pi <span class=\"pl-k\">/</span> <span class=\"pl-c1\">180</span>)\n    augmented_negative <span class=\"pl-k\">=</span> tf.cast(augmented_negative, np.uint8)\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-c1\">zip</span>(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train_input_fn</span>(<span class=\"pl-smi\">params</span>):\n    batch_size <span class=\"pl-k\">=</span> params[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch_size<span class=\"pl-pds\">\"</span></span>]\n    triplets <span class=\"pl-k\">=</span> load_triplets()\n    triplets_const <span class=\"pl-k\">=</span> tf.constant(triplets)\n    labels_const <span class=\"pl-k\">=</span>tf.zeros([<span class=\"pl-c1\">len</span>(triplets)], tf.int32)\n    dataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices((triplets_const, labels_const))\n    dataset <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">len</span>(triplets))\n    triplets.clear()\n    dataset <span class=\"pl-k\">=</span> dataset.map(my_input_fn)\n\n    augmented_flip_left_right <span class=\"pl-k\">=</span> dataset.map(random_flip_left_right)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_flip_left_right)\n    augmented_flip_up_down <span class=\"pl-k\">=</span> dataset.map(random_flip_up_down)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_flip_up_down)\n    augmented_brightness <span class=\"pl-k\">=</span> dataset.map(random_brightness)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_brightness)\n    augmented_contrast <span class=\"pl-k\">=</span> dataset.map(random_contrast)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_contrast)\n    augmented_hue <span class=\"pl-k\">=</span> dataset.map(random_hue)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_hue)\n    augmented_saturation <span class=\"pl-k\">=</span> dataset.map(random_saturation)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_saturation)\n    augmented_rotate <span class=\"pl-k\">=</span> dataset.map(random_rotate)\n    dataset <span class=\"pl-k\">=</span> dataset.concatenate(augmented_rotate)\n\n    ds <span class=\"pl-k\">=</span> dataset.cache().repeat().apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n    triplets, labels <span class=\"pl-k\">=</span> ds.make_one_shot_iterator().get_next()\n\n    <span class=\"pl-k\">return</span> triplets, labels\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">convnet_model_</span>():\n    vgg_model <span class=\"pl-k\">=</span> VGG16(<span class=\"pl-v\">weights</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">include_top</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    x <span class=\"pl-k\">=</span> vgg_model.output\n    x <span class=\"pl-k\">=</span> layers.GlobalAveragePooling2D()(x)\n    x <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">4096</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(x)\n    x <span class=\"pl-k\">=</span> layers.Dropout(<span class=\"pl-c1\">0.6</span>)(x)\n    x <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">4096</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>relu<span class=\"pl-pds\">'</span></span>)(x)\n    x <span class=\"pl-k\">=</span> layers.Dropout(<span class=\"pl-c1\">0.6</span>)(x)\n    x <span class=\"pl-k\">=</span> layers.Lambda(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x_</span>: keras.backend.l2_normalize(x_, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>))(x)\n    convnet_model <span class=\"pl-k\">=</span> models.Model(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>vgg_model.input, <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>x)\n\n    <span class=\"pl-k\">return</span> convnet_model\n\n<span class=\"pl-c1\">_EPSILON</span> <span class=\"pl-k\">=</span> keras.backend.epsilon()\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_loss_tensor</span>(<span class=\"pl-smi\">y_true</span>, <span class=\"pl-smi\">y_pred</span>):\n    y_pred <span class=\"pl-k\">=</span> keras.backend.clip(y_pred, <span class=\"pl-c1\">_EPSILON</span>, <span class=\"pl-c1\">1.0</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">_EPSILON</span>)\n    loss <span class=\"pl-k\">=</span> tf.convert_to_tensor(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    g <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">FLAGS</span>.batch_size, <span class=\"pl-c1\">3</span>):\n        <span class=\"pl-k\">try</span>:\n            q_embedding <span class=\"pl-k\">=</span> y_pred[i<span class=\"pl-k\">+</span><span class=\"pl-c1\">0</span>]\n            p_embedding <span class=\"pl-k\">=</span> y_pred[i<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>]\n            n_embedding <span class=\"pl-k\">=</span> y_pred[i<span class=\"pl-k\">+</span><span class=\"pl-c1\">2</span>]\n            D_q_p <span class=\"pl-k\">=</span> keras.backend.sqrt(keras.backend.sum((q_embedding <span class=\"pl-k\">-</span> p_embedding)<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>))\n            D_q_n <span class=\"pl-k\">=</span> keras.backend.sqrt(keras.backend.sum((q_embedding <span class=\"pl-k\">-</span> n_embedding)<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>))\n            loss <span class=\"pl-k\">=</span> (loss <span class=\"pl-k\">+</span> g <span class=\"pl-k\">+</span> D_q_p <span class=\"pl-k\">-</span> D_q_n)\n        <span class=\"pl-k\">except</span>:\n            <span class=\"pl-k\">continue</span>\n    loss <span class=\"pl-k\">=</span> loss <span class=\"pl-k\">/</span> <span class=\"pl-c1\">FLAGS</span>.batch_size\n    zero <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0.0</span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n    <span class=\"pl-k\">return</span> tf.maximum(loss, zero)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>, <span class=\"pl-smi\">params</span>):\n    <span class=\"pl-k\">del</span> params\n\n    convnet_model <span class=\"pl-k\">=</span> convnet_model_()\n    first_input <span class=\"pl-k\">=</span> layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">225</span>,<span class=\"pl-c1\">225</span>,<span class=\"pl-c1\">3</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual1_input<span class=\"pl-pds\">'</span></span>)\n    first_subsample <span class=\"pl-k\">=</span> layers.Conv2D(<span class=\"pl-c1\">3</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual1_subsampling<span class=\"pl-pds\">'</span></span>)(first_input)\n    first_conv <span class=\"pl-k\">=</span> layers.Conv2D(<span class=\"pl-c1\">96</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>,<span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual1_conv<span class=\"pl-pds\">'</span></span>)(first_subsample)\n    first_max <span class=\"pl-k\">=</span> layers.MaxPool2D(<span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>,<span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>,<span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual1_max<span class=\"pl-pds\">'</span></span>)(first_conv)\n    first_max <span class=\"pl-k\">=</span> layers.Flatten(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual1_flatten<span class=\"pl-pds\">'</span></span>)(first_max)\n    second_input <span class=\"pl-k\">=</span> layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">225</span>,<span class=\"pl-c1\">225</span>,<span class=\"pl-c1\">3</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual2_input<span class=\"pl-pds\">'</span></span>)\n    second_subsample <span class=\"pl-k\">=</span> layers.Conv2D(<span class=\"pl-c1\">3</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual2_subsampling<span class=\"pl-pds\">'</span></span>)(second_input)\n    second_conv <span class=\"pl-k\">=</span> layers.Conv2D(<span class=\"pl-c1\">96</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>,<span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual2_conv<span class=\"pl-pds\">'</span></span>)(second_subsample)\n    second_max <span class=\"pl-k\">=</span> layers.MaxPool2D(<span class=\"pl-v\">pool_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">7</span>,<span class=\"pl-v\">strides</span> <span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,<span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>same<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual2_max<span class=\"pl-pds\">'</span></span>)(second_conv)\n    second_max <span class=\"pl-k\">=</span> layers.Flatten(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual2_flatten<span class=\"pl-pds\">'</span></span>)(second_max)\n    merge_low_visual <span class=\"pl-k\">=</span> layers.concatenate([first_max, second_max])\n    l2_norm_low_visual <span class=\"pl-k\">=</span> layers.Lambda(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: K.l2_normalize(x, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>low_visual_l2_normalization<span class=\"pl-pds\">'</span></span>)(merge_low_visual)\n    merge_two <span class=\"pl-k\">=</span> layers.concatenate([l2_norm_low_visual, convnet_model.output])\n    emb <span class=\"pl-k\">=</span> layers.Dense(<span class=\"pl-c1\">4096</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>linear_embedding<span class=\"pl-pds\">'</span></span>)(merge_two)\n    l2_norm_final <span class=\"pl-k\">=</span> layers.Lambda(<span class=\"pl-k\">lambda</span>  <span class=\"pl-smi\">x</span>: K.l2_normalize(x,<span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>final_l2_normalization<span class=\"pl-pds\">'</span></span>)(emb)\n    final_model <span class=\"pl-k\">=</span> models.Model(<span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>[convnet_model.input, first_input, second_input], <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>l2_norm_final)\n    final_model.summary()\n    <span class=\"pl-k\">if</span> mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>:\n        logits <span class=\"pl-k\">=</span> final_model([features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>]], <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        predictions <span class=\"pl-k\">=</span> {\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>embedding<span class=\"pl-pds\">'</span></span>: logits[<span class=\"pl-c1\">0</span>]\n        }\n        <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(\n            <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>tf.estimator.ModeKeys.<span class=\"pl-c1\">PREDICT</span>,\n            <span class=\"pl-v\">predictions</span><span class=\"pl-k\">=</span>predictions,\n            <span class=\"pl-v\">export_outputs</span><span class=\"pl-k\">=</span>{\n                <span class=\"pl-s\"><span class=\"pl-pds\">'</span>classify<span class=\"pl-pds\">'</span></span>: tf.estimator.export.PredictOutput(predictions)\n            })\n    logits_1 <span class=\"pl-k\">=</span> final_model([features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>]], <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>(mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>))\n    logits_2 <span class=\"pl-k\">=</span> final_model([features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>]], <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>(mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>))\n    logits_3 <span class=\"pl-k\">=</span> final_model([features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>], features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>]], <span class=\"pl-v\">training</span><span class=\"pl-k\">=</span>(mode <span class=\"pl-k\">==</span> tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>))\n    logits <span class=\"pl-k\">=</span> tf.concat([logits_1, logits_2, logits_3], <span class=\"pl-c1\">0</span>)\n    loss <span class=\"pl-k\">=</span> _loss_tensor(<span class=\"pl-c1\">None</span>, logits)\n    optimizer <span class=\"pl-k\">=</span> tf.train.MomentumOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.learning_rate, <span class=\"pl-v\">momentum</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.9</span>, <span class=\"pl-v\">use_nesterov</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.use_tpu:\n        optimizer <span class=\"pl-k\">=</span> tf.contrib.tpu.CrossShardOptimizer(optimizer)\n    <span class=\"pl-k\">return</span> tf.contrib.tpu.TPUEstimatorSpec(<span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>tf.estimator.ModeKeys.<span class=\"pl-c1\">TRAIN</span>, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>optimizer.minimize(loss, tf.train.get_global_step()))\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">argv</span>):\n    <span class=\"pl-k\">del</span> argv\n    tf.logging.set_verbosity(tf.logging.<span class=\"pl-c1\">INFO</span>)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.master <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span> <span class=\"pl-k\">and</span> <span class=\"pl-c1\">FLAGS</span>.tpu <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">RuntimeError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>You must specify either --master or --tpu.<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.master <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.tpu <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n            tf.logging.warn(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Both --master and --tpu are set. Ignoring <span class=\"pl-pds\">'</span></span>\n                      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--tpu and using --master.<span class=\"pl-pds\">'</span></span>)\n        tpu_grpc_url <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.master\n    <span class=\"pl-k\">else</span>:\n        tpu_cluster_resolver <span class=\"pl-k\">=</span> (tf.contrib.cluster_resolver.TPUClusterResolver(<span class=\"pl-c1\">FLAGS</span>.tpu, <span class=\"pl-v\">zone</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.tpu_zone, <span class=\"pl-v\">project</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.gcp_project))\n        tpu_grpc_url <span class=\"pl-k\">=</span> tpu_cluster_resolver.get_master()\n\n    run_config <span class=\"pl-k\">=</span> tpu_config.RunConfig(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span>tpu_grpc_url, <span class=\"pl-v\">model_dir</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.model_dir, <span class=\"pl-v\">save_checkpoints_secs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3600</span>, <span class=\"pl-v\">session_config</span><span class=\"pl-k\">=</span>tf.ConfigProto(<span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">log_device_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>), <span class=\"pl-v\">tpu_config</span><span class=\"pl-k\">=</span>tpu_config.TPUConfig(<span class=\"pl-v\">iterations_per_loop</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.iterations, <span class=\"pl-v\">num_shards</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.num_shards),)\n    estimator <span class=\"pl-k\">=</span> tpu_estimator.TPUEstimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_fn, <span class=\"pl-v\">use_tpu</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.use_tpu, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>run_config, <span class=\"pl-v\">train_batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.batch_size)\n    estimator.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>train_input_fn, <span class=\"pl-v\">max_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.train_steps)\n    img_input <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">225</span>, <span class=\"pl-c1\">3</span>])\n    input_fn <span class=\"pl-k\">=</span>tf.estimator.export.build_raw_serving_input_receiver_fn({\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>query<span class=\"pl-pds\">'</span></span>: img_input,\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>positive<span class=\"pl-pds\">'</span></span>: img_input,\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>negative<span class=\"pl-pds\">'</span></span>: img_input,\n    })\n    estimator.export_savedmodel(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output<span class=\"pl-pds\">'</span></span>, input_fn)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    tf.app.run()</pre></div>\n<p>I get the following error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"test.py\", line 370, in &lt;module&gt;\n    tf.app.run()\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"test.py\", line 359, in main\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1168, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2162, in _call_model_fn\n    features, labels, mode, config)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1131, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2414, in _model_fn\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2724, in _train_on_tpu_system\n    device_assignment=ctx.device_assignment)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 829, in shard\n    name=name)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 475, in replicate\n    device_assignment, name)[1]\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 635, in split_compile_and_replicate\n    outputs = computation(*computation_inputs)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2717, in multi_tpu_train_steps_on_single_shard\n    single_tpu_train_step, [_INITIAL_LOSS])\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\n    name=\"\")\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2924, in _BuildLoop\n    next_vars.append(_AddNextAndBackEdge(m, v))\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 666, in _AddNextAndBackEdge\n    _EnforceShapeInvariant(m, v)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 610, in _EnforceShapeInvariant\n    (input_t.name, input_t.shape, n_shape))\nValueError: Input tensor 'Const_1:0' enters the loop with shape (), but has shape (1,) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\n</code></pre>\n<p>While if I run the exact same code with <code>--use_tpu=False --master=''</code> it works like a charm.</p>\n<p>Is it somehow related to a bug or is it me who is doing something wrong with dedicated TPU code?</p>\n<p>Thanks in advance.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I did put the code below\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\nTensorFlow installed from (source or binary): already installed while creating the VM\nTensorFlow version (use command below): 1.9.0-rc2\nPython version: 3.5\nBazel version (if compiling from source): Not compiled\nGCC/Compiler version (if compiling from source): Not compiled\nCUDA/cuDNN version: not installed\nGPU model and memory: no GPU\nExact command to reproduce: python3 test.py --tpu=$TPU_NAME --model_dir=output -use-tpu=True --batch_size=24\n\nDescribe the problem\nWhen I run the following code:\nfrom tensorflow.python.keras.applications.vgg16 import VGG16\nfrom tensorflow.python.keras import models\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras.preprocessing import image\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom absl import flags\nimport absl.logging as _logging\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\nimport numpy as np\nimport random\nimport math\nimport os\n\n\n#  Cloud TPU Cluster Resolver flags\ntf.flags.DEFINE_string(\n    \"tpu\", default=None,\n    help=\"The Cloud TPU to use for training. This should be either the name \"\n    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n    \"url.\")\ntf.flags.DEFINE_string(\n    \"tpu_zone\", default=None,\n    help=\"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n    \"specified, we will attempt to automatically detect the GCE project from \"\n    \"metadata.\")\ntf.flags.DEFINE_string(\n    \"gcp_project\", default=None,\n    help=\"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n    \"specified, we will attempt to automatically detect the GCE project from \"\n    \"metadata.\")\n\n# Model specific parameters\ntf.flags.DEFINE_string(\n    \"master\", default=None,\n    help=\"GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You \"\n    \"must specify either this flag or --tpu.\")\ntf.flags.DEFINE_string(\"data_dir\", \"\",\n                       \"Path to directory containing the dataset\")\ntf.flags.DEFINE_string(\"model_dir\", 'output', \"Estimator model_dir\")\ntf.flags.DEFINE_integer(\"batch_size\", 3,\n                        \"Mini-batch size for the training. Note that this \"\n                        \"is the global batch size and not the per-shard batch.\")\ntf.flags.DEFINE_integer(\"train_steps\", 1, \"Total number of training steps.\")\ntf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate.\")\n\ntf.flags.DEFINE_bool(\"use_tpu\", True, \"Use TPUs rather than plain CPUs\")\ntf.flags.DEFINE_integer(\"iterations\", 1,\n                        \"Number of iterations per TPU training loop.\")\ntf.flags.DEFINE_integer(\"num_shards\", 8, \"Number of shards (TPU chips).\")\n\nFLAGS = tf.flags.FLAGS\n\nfeature_names = [\n    'query',\n    'positive',\n    'negative']\n\ndef load_triplets():\n    triplets = []\n    triplet_file = os.path.join(FLAGS.data_dir, 'triplets.txt')\n    with tf.gfile.GFile(triplet_file) as f:\n        count = 0\n        for line in f:\n            triplets.append(line.strip().split(','))\n            count += 1\n            if count % 1000 == 0:\n                tf.logging.info(\"Loading {} triplets\".format(count))\n\n    tf.logging.info(\"Loading {} triplets\".format(count))\n    return triplets\n\ndef my_input_fn(triplet, label):\n    query_img = tf.image.decode_jpeg(triplet[0], channels=3)\n    query_img.set_shape([None, None, None])\n    query_img = tf.image.resize_images(query_img, [225, 225])\n    query_img.set_shape([225, 225, 3])\n    positive_img = tf.image.decode_jpeg(tf.read_file(triplet[1]), channels=3)\n    positive_img.set_shape([None, None, None])\n    positive_img = tf.image.resize_images(positive_img, [225, 225])\n    positive_img.set_shape([225, 225, 3])\n    negative_img = tf.image.decode_jpeg(tf.read_file(triplet[2]), channels=3)\n    negative_img.set_shape([None, None, None])\n    negative_img = tf.image.resize_images(negative_img, [225, 225])\n    negative_img.set_shape([225, 225, 3])\n\n    return dict(zip(feature_names, [query_img, positive_img, negative_img])), label\n\ndef random_flip_left_right(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_flip_left_right(image['query'])\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_flip_left_right(image['positive'])\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_flip_left_right(image['negative'])\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef random_flip_up_down(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_flip_up_down(image['query'])\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_flip_up_down(image['positive'])\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_flip_up_down(image['negative'])\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\n\ndef random_brightness(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_brightness(image['query'], max_delta=random.uniform(0.0, 1.0))\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_brightness(image['positive'], max_delta=random.uniform(0.0, 1.0))\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_brightness(image['negative'], max_delta=random.uniform(0.0, 1.0))\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef random_contrast(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_contrast(image['query'], lower=0.3, upper=1.0)\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_contrast(image['positive'], lower=0.3, upper=1.0)\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_contrast(image['negative'], lower=0.3, upper=1.0)\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef random_hue(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_hue(image['query'], max_delta=random.uniform(0.0, 0.5))\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_hue(image['positive'], max_delta=random.uniform(0.0, 0.5))\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_hue(image['negative'], max_delta=random.uniform(0.0, 0.5))\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef random_saturation(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.image.random_saturation(image['query'], lower=0.0, upper=2.0)\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.image.random_saturation(image['positive'], lower=0.0, upper=2.0)\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.image.random_saturation(image['negative'], lower=0.0, upper=2.0)\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef random_rotate(image, label):\n    augmented_query = tf.to_float(image['query'])\n    augmented_query = tf.contrib.image.rotate(image['query'], angles=random.uniform(0, 360) * math.pi / 180)\n    augmented_query = tf.cast(augmented_query, np.uint8)\n    augmented_positive = tf.to_float(image['positive'])\n    augmented_positive = tf.contrib.image.rotate(image['positive'], angles=random.uniform(0, 360) * math.pi / 180)\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\n    augmented_negative = tf.to_float(image['negative'])\n    augmented_negative = tf.contrib.image.rotate(image['negative'], angles=random.uniform(0, 360) * math.pi / 180)\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\n\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\n\ndef train_input_fn(params):\n    batch_size = params[\"batch_size\"]\n    triplets = load_triplets()\n    triplets_const = tf.constant(triplets)\n    labels_const =tf.zeros([len(triplets)], tf.int32)\n    dataset = tf.data.Dataset.from_tensor_slices((triplets_const, labels_const))\n    dataset = dataset.shuffle(buffer_size=len(triplets))\n    triplets.clear()\n    dataset = dataset.map(my_input_fn)\n\n    augmented_flip_left_right = dataset.map(random_flip_left_right)\n    dataset = dataset.concatenate(augmented_flip_left_right)\n    augmented_flip_up_down = dataset.map(random_flip_up_down)\n    dataset = dataset.concatenate(augmented_flip_up_down)\n    augmented_brightness = dataset.map(random_brightness)\n    dataset = dataset.concatenate(augmented_brightness)\n    augmented_contrast = dataset.map(random_contrast)\n    dataset = dataset.concatenate(augmented_contrast)\n    augmented_hue = dataset.map(random_hue)\n    dataset = dataset.concatenate(augmented_hue)\n    augmented_saturation = dataset.map(random_saturation)\n    dataset = dataset.concatenate(augmented_saturation)\n    augmented_rotate = dataset.map(random_rotate)\n    dataset = dataset.concatenate(augmented_rotate)\n\n    ds = dataset.cache().repeat().apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n    triplets, labels = ds.make_one_shot_iterator().get_next()\n\n    return triplets, labels\n\n\ndef convnet_model_():\n    vgg_model = VGG16(weights=None, include_top=False)\n    x = vgg_model.output\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(4096, activation='relu')(x)\n    x = layers.Dropout(0.6)(x)\n    x = layers.Dense(4096, activation='relu')(x)\n    x = layers.Dropout(0.6)(x)\n    x = layers.Lambda(lambda x_: keras.backend.l2_normalize(x_, axis=1))(x)\n    convnet_model = models.Model(inputs=vgg_model.input, outputs=x)\n\n    return convnet_model\n\n_EPSILON = keras.backend.epsilon()\ndef _loss_tensor(y_true, y_pred):\n    y_pred = keras.backend.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n    loss = tf.convert_to_tensor(0, dtype=tf.float32)\n    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\n    for i in range(0, FLAGS.batch_size, 3):\n        try:\n            q_embedding = y_pred[i+0]\n            p_embedding = y_pred[i+1]\n            n_embedding = y_pred[i+2]\n            D_q_p = keras.backend.sqrt(keras.backend.sum((q_embedding - p_embedding)**2))\n            D_q_n = keras.backend.sqrt(keras.backend.sum((q_embedding - n_embedding)**2))\n            loss = (loss + g + D_q_p - D_q_n)\n        except:\n            continue\n    loss = loss / FLAGS.batch_size\n    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\n\n    return tf.maximum(loss, zero)\n\n\ndef model_fn(features, labels, mode, params):\n    del params\n\n    convnet_model = convnet_model_()\n    first_input = layers.Input(shape=(225,225,3), name='low_visual1_input')\n    first_subsample = layers.Conv2D(3, kernel_size=1, strides=4, padding='same', name='low_visual1_subsampling')(first_input)\n    first_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual1_conv')(first_subsample)\n    first_max = layers.MaxPool2D(pool_size=3,strides=4,padding='same', name='low_visual1_max')(first_conv)\n    first_max = layers.Flatten(name='low_visual1_flatten')(first_max)\n    second_input = layers.Input(shape=(225,225,3), name='low_visual2_input')\n    second_subsample = layers.Conv2D(3, kernel_size=1, strides=8, padding='same', name='low_visual2_subsampling')(second_input)\n    second_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual2_conv')(second_subsample)\n    second_max = layers.MaxPool2D(pool_size=7,strides =2,padding='same', name='low_visual2_max')(second_conv)\n    second_max = layers.Flatten(name='low_visual2_flatten')(second_max)\n    merge_low_visual = layers.concatenate([first_max, second_max])\n    l2_norm_low_visual = layers.Lambda(lambda x: K.l2_normalize(x, axis=1), name='low_visual_l2_normalization')(merge_low_visual)\n    merge_two = layers.concatenate([l2_norm_low_visual, convnet_model.output])\n    emb = layers.Dense(4096, name='linear_embedding')(merge_two)\n    l2_norm_final = layers.Lambda(lambda  x: K.l2_normalize(x,axis=1), name='final_l2_normalization')(emb)\n    final_model = models.Model(inputs=[convnet_model.input, first_input, second_input], outputs=l2_norm_final)\n    final_model.summary()\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        logits = final_model([features['query'], features['positive'], features['negative']], training=False)\n        predictions = {\n            'embedding': logits[0]\n        }\n        return tf.estimator.EstimatorSpec(\n            mode=tf.estimator.ModeKeys.PREDICT,\n            predictions=predictions,\n            export_outputs={\n                'classify': tf.estimator.export.PredictOutput(predictions)\n            })\n    logits_1 = final_model([features['query'], features['query'], features['query']], training=(mode == tf.estimator.ModeKeys.TRAIN))\n    logits_2 = final_model([features['positive'], features['positive'], features['positive']], training=(mode == tf.estimator.ModeKeys.TRAIN))\n    logits_3 = final_model([features['negative'], features['negative'], features['negative']], training=(mode == tf.estimator.ModeKeys.TRAIN))\n    logits = tf.concat([logits_1, logits_2, logits_3], 0)\n    loss = _loss_tensor(None, logits)\n    optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.learning_rate, momentum=0.9, use_nesterov=True)\n\n    if FLAGS.use_tpu:\n        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n    return tf.contrib.tpu.TPUEstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=optimizer.minimize(loss, tf.train.get_global_step()))\n\n\ndef main(argv):\n    del argv\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n    if FLAGS.master is None and FLAGS.tpu is None:\n        raise RuntimeError('You must specify either --master or --tpu.')\n    if FLAGS.master is not None:\n        if FLAGS.tpu is not None:\n            tf.logging.warn('Both --master and --tpu are set. Ignoring '\n                      '--tpu and using --master.')\n        tpu_grpc_url = FLAGS.master\n    else:\n        tpu_cluster_resolver = (tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project))\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\n\n    run_config = tpu_config.RunConfig(master=tpu_grpc_url, model_dir=FLAGS.model_dir, save_checkpoints_secs=3600, session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True), tpu_config=tpu_config.TPUConfig(iterations_per_loop=FLAGS.iterations, num_shards=FLAGS.num_shards),)\n    estimator = tpu_estimator.TPUEstimator(model_fn=model_fn, use_tpu=FLAGS.use_tpu, config=run_config, train_batch_size=FLAGS.batch_size)\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\n    img_input = tf.placeholder(tf.float32, [None, 225, 225, 3])\n    input_fn =tf.estimator.export.build_raw_serving_input_receiver_fn({\n        'query': img_input,\n        'positive': img_input,\n        'negative': img_input,\n    })\n    estimator.export_savedmodel('output', input_fn)\n\n\nif __name__ == \"__main__\":\n    tf.app.run()\nI get the following error:\nTraceback (most recent call last):\n  File \"test.py\", line 370, in <module>\n    tf.app.run()\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"test.py\", line 359, in main\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1168, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2162, in _call_model_fn\n    features, labels, mode, config)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1131, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2414, in _model_fn\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2724, in _train_on_tpu_system\n    device_assignment=ctx.device_assignment)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 829, in shard\n    name=name)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 475, in replicate\n    device_assignment, name)[1]\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 635, in split_compile_and_replicate\n    outputs = computation(*computation_inputs)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2717, in multi_tpu_train_steps_on_single_shard\n    single_tpu_train_step, [_INITIAL_LOSS])\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\n    name=\"\")\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2924, in _BuildLoop\n    next_vars.append(_AddNextAndBackEdge(m, v))\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 666, in _AddNextAndBackEdge\n    _EnforceShapeInvariant(m, v)\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 610, in _EnforceShapeInvariant\n    (input_t.name, input_t.shape, n_shape))\nValueError: Input tensor 'Const_1:0' enters the loop with shape (), but has shape (1,) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\n\nWhile if I run the exact same code with --use_tpu=False --master='' it works like a charm.\nIs it somehow related to a bug or is it me who is doing something wrong with dedicated TPU code?\nThanks in advance.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, I did put the code below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9\r\n- **TensorFlow installed from (source or binary)**: already installed while creating the VM\r\n- **TensorFlow version (use command below)**: 1.9.0-rc2\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: Not compiled\r\n- **GCC/Compiler version (if compiling from source)**: Not compiled\r\n- **CUDA/cuDNN version**: not installed\r\n- **GPU model and memory**: no GPU\r\n- **Exact command to reproduce**: ```python3 test.py --tpu=$TPU_NAME --model_dir=output -use-tpu=True --batch_size=24```\r\n\r\n### Describe the problem\r\nWhen I run the following code:\r\n\r\n```python\r\nfrom tensorflow.python.keras.applications.vgg16 import VGG16\r\nfrom tensorflow.python.keras import models\r\nfrom tensorflow.python.keras import layers\r\nfrom tensorflow.python.keras.preprocessing import image\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom absl import flags\r\nimport absl.logging as _logging\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\nimport numpy as np\r\nimport random\r\nimport math\r\nimport os\r\n\r\n\r\n#  Cloud TPU Cluster Resolver flags\r\ntf.flags.DEFINE_string(\r\n    \"tpu\", default=None,\r\n    help=\"The Cloud TPU to use for training. This should be either the name \"\r\n    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\r\n    \"url.\")\r\ntf.flags.DEFINE_string(\r\n    \"tpu_zone\", default=None,\r\n    help=\"[Optional] GCE zone where the Cloud TPU is located in. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\ntf.flags.DEFINE_string(\r\n    \"gcp_project\", default=None,\r\n    help=\"[Optional] Project name for the Cloud TPU-enabled project. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\n\r\n# Model specific parameters\r\ntf.flags.DEFINE_string(\r\n    \"master\", default=None,\r\n    help=\"GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You \"\r\n    \"must specify either this flag or --tpu.\")\r\ntf.flags.DEFINE_string(\"data_dir\", \"\",\r\n                       \"Path to directory containing the dataset\")\r\ntf.flags.DEFINE_string(\"model_dir\", 'output', \"Estimator model_dir\")\r\ntf.flags.DEFINE_integer(\"batch_size\", 3,\r\n                        \"Mini-batch size for the training. Note that this \"\r\n                        \"is the global batch size and not the per-shard batch.\")\r\ntf.flags.DEFINE_integer(\"train_steps\", 1, \"Total number of training steps.\")\r\ntf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate.\")\r\n\r\ntf.flags.DEFINE_bool(\"use_tpu\", True, \"Use TPUs rather than plain CPUs\")\r\ntf.flags.DEFINE_integer(\"iterations\", 1,\r\n                        \"Number of iterations per TPU training loop.\")\r\ntf.flags.DEFINE_integer(\"num_shards\", 8, \"Number of shards (TPU chips).\")\r\n\r\nFLAGS = tf.flags.FLAGS\r\n\r\nfeature_names = [\r\n    'query',\r\n    'positive',\r\n    'negative']\r\n\r\ndef load_triplets():\r\n    triplets = []\r\n    triplet_file = os.path.join(FLAGS.data_dir, 'triplets.txt')\r\n    with tf.gfile.GFile(triplet_file) as f:\r\n        count = 0\r\n        for line in f:\r\n            triplets.append(line.strip().split(','))\r\n            count += 1\r\n            if count % 1000 == 0:\r\n                tf.logging.info(\"Loading {} triplets\".format(count))\r\n\r\n    tf.logging.info(\"Loading {} triplets\".format(count))\r\n    return triplets\r\n\r\ndef my_input_fn(triplet, label):\r\n    query_img = tf.image.decode_jpeg(triplet[0], channels=3)\r\n    query_img.set_shape([None, None, None])\r\n    query_img = tf.image.resize_images(query_img, [225, 225])\r\n    query_img.set_shape([225, 225, 3])\r\n    positive_img = tf.image.decode_jpeg(tf.read_file(triplet[1]), channels=3)\r\n    positive_img.set_shape([None, None, None])\r\n    positive_img = tf.image.resize_images(positive_img, [225, 225])\r\n    positive_img.set_shape([225, 225, 3])\r\n    negative_img = tf.image.decode_jpeg(tf.read_file(triplet[2]), channels=3)\r\n    negative_img.set_shape([None, None, None])\r\n    negative_img = tf.image.resize_images(negative_img, [225, 225])\r\n    negative_img.set_shape([225, 225, 3])\r\n\r\n    return dict(zip(feature_names, [query_img, positive_img, negative_img])), label\r\n\r\ndef random_flip_left_right(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_left_right(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_left_right(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_left_right(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_flip_up_down(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_up_down(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_up_down(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_up_down(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\n\r\ndef random_brightness(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_brightness(image['query'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_brightness(image['positive'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_brightness(image['negative'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_contrast(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_contrast(image['query'], lower=0.3, upper=1.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_contrast(image['positive'], lower=0.3, upper=1.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_contrast(image['negative'], lower=0.3, upper=1.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_hue(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_hue(image['query'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_hue(image['positive'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_hue(image['negative'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_saturation(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_saturation(image['query'], lower=0.0, upper=2.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_saturation(image['positive'], lower=0.0, upper=2.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_saturation(image['negative'], lower=0.0, upper=2.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_rotate(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.contrib.image.rotate(image['query'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.contrib.image.rotate(image['positive'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.contrib.image.rotate(image['negative'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef train_input_fn(params):\r\n    batch_size = params[\"batch_size\"]\r\n    triplets = load_triplets()\r\n    triplets_const = tf.constant(triplets)\r\n    labels_const =tf.zeros([len(triplets)], tf.int32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((triplets_const, labels_const))\r\n    dataset = dataset.shuffle(buffer_size=len(triplets))\r\n    triplets.clear()\r\n    dataset = dataset.map(my_input_fn)\r\n\r\n    augmented_flip_left_right = dataset.map(random_flip_left_right)\r\n    dataset = dataset.concatenate(augmented_flip_left_right)\r\n    augmented_flip_up_down = dataset.map(random_flip_up_down)\r\n    dataset = dataset.concatenate(augmented_flip_up_down)\r\n    augmented_brightness = dataset.map(random_brightness)\r\n    dataset = dataset.concatenate(augmented_brightness)\r\n    augmented_contrast = dataset.map(random_contrast)\r\n    dataset = dataset.concatenate(augmented_contrast)\r\n    augmented_hue = dataset.map(random_hue)\r\n    dataset = dataset.concatenate(augmented_hue)\r\n    augmented_saturation = dataset.map(random_saturation)\r\n    dataset = dataset.concatenate(augmented_saturation)\r\n    augmented_rotate = dataset.map(random_rotate)\r\n    dataset = dataset.concatenate(augmented_rotate)\r\n\r\n    ds = dataset.cache().repeat().apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    triplets, labels = ds.make_one_shot_iterator().get_next()\r\n\r\n    return triplets, labels\r\n\r\n\r\ndef convnet_model_():\r\n    vgg_model = VGG16(weights=None, include_top=False)\r\n    x = vgg_model.output\r\n    x = layers.GlobalAveragePooling2D()(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Lambda(lambda x_: keras.backend.l2_normalize(x_, axis=1))(x)\r\n    convnet_model = models.Model(inputs=vgg_model.input, outputs=x)\r\n\r\n    return convnet_model\r\n\r\n_EPSILON = keras.backend.epsilon()\r\ndef _loss_tensor(y_true, y_pred):\r\n    y_pred = keras.backend.clip(y_pred, _EPSILON, 1.0-_EPSILON)\r\n    loss = tf.convert_to_tensor(0, dtype=tf.float32)\r\n    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\r\n    for i in range(0, FLAGS.batch_size, 3):\r\n        try:\r\n            q_embedding = y_pred[i+0]\r\n            p_embedding = y_pred[i+1]\r\n            n_embedding = y_pred[i+2]\r\n            D_q_p = keras.backend.sqrt(keras.backend.sum((q_embedding - p_embedding)**2))\r\n            D_q_n = keras.backend.sqrt(keras.backend.sum((q_embedding - n_embedding)**2))\r\n            loss = (loss + g + D_q_p - D_q_n)\r\n        except:\r\n            continue\r\n    loss = loss / FLAGS.batch_size\r\n    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\r\n\r\n    return tf.maximum(loss, zero)\r\n\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    del params\r\n\r\n    convnet_model = convnet_model_()\r\n    first_input = layers.Input(shape=(225,225,3), name='low_visual1_input')\r\n    first_subsample = layers.Conv2D(3, kernel_size=1, strides=4, padding='same', name='low_visual1_subsampling')(first_input)\r\n    first_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual1_conv')(first_subsample)\r\n    first_max = layers.MaxPool2D(pool_size=3,strides=4,padding='same', name='low_visual1_max')(first_conv)\r\n    first_max = layers.Flatten(name='low_visual1_flatten')(first_max)\r\n    second_input = layers.Input(shape=(225,225,3), name='low_visual2_input')\r\n    second_subsample = layers.Conv2D(3, kernel_size=1, strides=8, padding='same', name='low_visual2_subsampling')(second_input)\r\n    second_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual2_conv')(second_subsample)\r\n    second_max = layers.MaxPool2D(pool_size=7,strides =2,padding='same', name='low_visual2_max')(second_conv)\r\n    second_max = layers.Flatten(name='low_visual2_flatten')(second_max)\r\n    merge_low_visual = layers.concatenate([first_max, second_max])\r\n    l2_norm_low_visual = layers.Lambda(lambda x: K.l2_normalize(x, axis=1), name='low_visual_l2_normalization')(merge_low_visual)\r\n    merge_two = layers.concatenate([l2_norm_low_visual, convnet_model.output])\r\n    emb = layers.Dense(4096, name='linear_embedding')(merge_two)\r\n    l2_norm_final = layers.Lambda(lambda  x: K.l2_normalize(x,axis=1), name='final_l2_normalization')(emb)\r\n    final_model = models.Model(inputs=[convnet_model.input, first_input, second_input], outputs=l2_norm_final)\r\n    final_model.summary()\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        logits = final_model([features['query'], features['positive'], features['negative']], training=False)\r\n        predictions = {\r\n            'embedding': logits[0]\r\n        }\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.PREDICT,\r\n            predictions=predictions,\r\n            export_outputs={\r\n                'classify': tf.estimator.export.PredictOutput(predictions)\r\n            })\r\n    logits_1 = final_model([features['query'], features['query'], features['query']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits_2 = final_model([features['positive'], features['positive'], features['positive']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits_3 = final_model([features['negative'], features['negative'], features['negative']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits = tf.concat([logits_1, logits_2, logits_3], 0)\r\n    loss = _loss_tensor(None, logits)\r\n    optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.learning_rate, momentum=0.9, use_nesterov=True)\r\n\r\n    if FLAGS.use_tpu:\r\n        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\r\n    return tf.contrib.tpu.TPUEstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=optimizer.minimize(loss, tf.train.get_global_step()))\r\n\r\n\r\ndef main(argv):\r\n    del argv\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n    if FLAGS.master is None and FLAGS.tpu is None:\r\n        raise RuntimeError('You must specify either --master or --tpu.')\r\n    if FLAGS.master is not None:\r\n        if FLAGS.tpu is not None:\r\n            tf.logging.warn('Both --master and --tpu are set. Ignoring '\r\n                      '--tpu and using --master.')\r\n        tpu_grpc_url = FLAGS.master\r\n    else:\r\n        tpu_cluster_resolver = (tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project))\r\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\r\n\r\n    run_config = tpu_config.RunConfig(master=tpu_grpc_url, model_dir=FLAGS.model_dir, save_checkpoints_secs=3600, session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True), tpu_config=tpu_config.TPUConfig(iterations_per_loop=FLAGS.iterations, num_shards=FLAGS.num_shards),)\r\n    estimator = tpu_estimator.TPUEstimator(model_fn=model_fn, use_tpu=FLAGS.use_tpu, config=run_config, train_batch_size=FLAGS.batch_size)\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n    img_input = tf.placeholder(tf.float32, [None, 225, 225, 3])\r\n    input_fn =tf.estimator.export.build_raw_serving_input_receiver_fn({\r\n        'query': img_input,\r\n        'positive': img_input,\r\n        'negative': img_input,\r\n    })\r\n    estimator.export_savedmodel('output', input_fn)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```\r\nI get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 370, in <module>\r\n    tf.app.run()\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"test.py\", line 359, in main\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1168, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2162, in _call_model_fn\r\n    features, labels, mode, config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1131, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2414, in _model_fn\r\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2724, in _train_on_tpu_system\r\n    device_assignment=ctx.device_assignment)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 829, in shard\r\n    name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 475, in replicate\r\n    device_assignment, name)[1]\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 635, in split_compile_and_replicate\r\n    outputs = computation(*computation_inputs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2717, in multi_tpu_train_steps_on_single_shard\r\n    single_tpu_train_step, [_INITIAL_LOSS])\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\r\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\r\n    name=\"\")\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\r\n    return_same_structure)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2924, in _BuildLoop\r\n    next_vars.append(_AddNextAndBackEdge(m, v))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 666, in _AddNextAndBackEdge\r\n    _EnforceShapeInvariant(m, v)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 610, in _EnforceShapeInvariant\r\n    (input_t.name, input_t.shape, n_shape))\r\nValueError: Input tensor 'Const_1:0' enters the loop with shape (), but has shape (1,) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\r\n```\r\nWhile if I run the exact same code with ```--use_tpu=False --master=''``` it works like a charm.\r\n\r\nIs it somehow related to a bug or is it me who is doing something wrong with dedicated TPU code?\r\n\r\nThanks in advance."}