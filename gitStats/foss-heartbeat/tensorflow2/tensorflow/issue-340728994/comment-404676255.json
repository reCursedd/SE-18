{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404676255", "html_url": "https://github.com/tensorflow/tensorflow/issues/20747#issuecomment-404676255", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20747", "id": 404676255, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDY3NjI1NQ==", "user": {"login": "rjpower", "id": 607207, "node_id": "MDQ6VXNlcjYwNzIwNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/607207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjpower", "html_url": "https://github.com/rjpower", "followers_url": "https://api.github.com/users/rjpower/followers", "following_url": "https://api.github.com/users/rjpower/following{/other_user}", "gists_url": "https://api.github.com/users/rjpower/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjpower/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjpower/subscriptions", "organizations_url": "https://api.github.com/users/rjpower/orgs", "repos_url": "https://api.github.com/users/rjpower/repos", "events_url": "https://api.github.com/users/rjpower/events{/privacy}", "received_events_url": "https://api.github.com/users/rjpower/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-12T22:57:23Z", "updated_at": "2018-07-12T22:57:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for the report Julien.</p>\n<p>I was able to reproduce this.  It appears the issue is that your loss is a vector but we are expecting the returned loss to be a scalar value.  The TPUEstimator machinery wraps your model in a training loop which returns the loss as the final result.  The \"dummy\" initial loss is a scalar value which means your model function must also return a scalar value to be retain the same shape.  Apply <code>tf.reduce_sum(loss)</code> fixes the issue.</p>\n<p>I ended up summing the logits instead of the loss, as I was seeing a gradient error with the loss function you pasted in.  Hopefully this works for you -- please close the issue if this resolves your problem.</p>\n<p>I've filed a bug internally to track improving the error message.</p>", "body_text": "Thanks for the report Julien.\nI was able to reproduce this.  It appears the issue is that your loss is a vector but we are expecting the returned loss to be a scalar value.  The TPUEstimator machinery wraps your model in a training loop which returns the loss as the final result.  The \"dummy\" initial loss is a scalar value which means your model function must also return a scalar value to be retain the same shape.  Apply tf.reduce_sum(loss) fixes the issue.\nI ended up summing the logits instead of the loss, as I was seeing a gradient error with the loss function you pasted in.  Hopefully this works for you -- please close the issue if this resolves your problem.\nI've filed a bug internally to track improving the error message.", "body": "Thanks for the report Julien. \r\n\r\nI was able to reproduce this.  It appears the issue is that your loss is a vector but we are expecting the returned loss to be a scalar value.  The TPUEstimator machinery wraps your model in a training loop which returns the loss as the final result.  The \"dummy\" initial loss is a scalar value which means your model function must also return a scalar value to be retain the same shape.  Apply `tf.reduce_sum(loss)` fixes the issue.  \r\n\r\nI ended up summing the logits instead of the loss, as I was seeing a gradient error with the loss function you pasted in.  Hopefully this works for you -- please close the issue if this resolves your problem.\r\n\r\nI've filed a bug internally to track improving the error message. "}