{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253808985", "html_url": "https://github.com/tensorflow/tensorflow/issues/4877#issuecomment-253808985", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4877", "id": 253808985, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MzgwODk4NQ==", "user": {"login": "ohadle", "id": 2196196, "node_id": "MDQ6VXNlcjIxOTYxOTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/2196196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ohadle", "html_url": "https://github.com/ohadle", "followers_url": "https://api.github.com/users/ohadle/followers", "following_url": "https://api.github.com/users/ohadle/following{/other_user}", "gists_url": "https://api.github.com/users/ohadle/gists{/gist_id}", "starred_url": "https://api.github.com/users/ohadle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ohadle/subscriptions", "organizations_url": "https://api.github.com/users/ohadle/orgs", "repos_url": "https://api.github.com/users/ohadle/repos", "events_url": "https://api.github.com/users/ohadle/events{/privacy}", "received_events_url": "https://api.github.com/users/ohadle/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-14T14:04:33Z", "updated_at": "2016-10-14T14:04:33Z", "author_association": "NONE", "body_html": "<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    x_iter = np.random.rand(2, 3, 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n\n## -- End pasted text --\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-1-8929993d27e5&gt; in &lt;module&gt;()\n      8\n      9 out = layers.fully_connected(inputs=x, num_outputs=1)\n---&gt; 10 loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\n     11 optimizer = tf.train.AdamOptimizer().minimize(loss)\n     12\n\n/Users/olevinkr/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn.pyc in sigmoid_cross_entropy_with_logits(logits, targets, name)\n    432     except ValueError:\n    433       raise ValueError(\"logits and targets must have the same shape (%s vs %s)\"\n--&gt; 434                        % (logits.get_shape(), targets.get_shape()))\n    435\n    436     # The logistic loss formula from above is\n\nValueError: logits and targets must have the same shape ((?, 3, 1) vs (?, 1))\n</code></pre>\n<p>Flattening <code>x</code> works:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3*4))\n# x = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # x_iter = np.random.rand(2, 3, 4)\n    x_iter = np.random.rand(2, 3 * 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n</code></pre>\n<p>Am I misunderstanding the docs?</p>", "body_text": "import tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    x_iter = np.random.rand(2, 3, 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n\n## -- End pasted text --\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-1-8929993d27e5> in <module>()\n      8\n      9 out = layers.fully_connected(inputs=x, num_outputs=1)\n---> 10 loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\n     11 optimizer = tf.train.AdamOptimizer().minimize(loss)\n     12\n\n/Users/olevinkr/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn.pyc in sigmoid_cross_entropy_with_logits(logits, targets, name)\n    432     except ValueError:\n    433       raise ValueError(\"logits and targets must have the same shape (%s vs %s)\"\n--> 434                        % (logits.get_shape(), targets.get_shape()))\n    435\n    436     # The logistic loss formula from above is\n\nValueError: logits and targets must have the same shape ((?, 3, 1) vs (?, 1))\n\nFlattening x works:\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3*4))\n# x = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # x_iter = np.random.rand(2, 3, 4)\n    x_iter = np.random.rand(2, 3 * 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n\nAm I misunderstanding the docs?", "body": "```\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    x_iter = np.random.rand(2, 3, 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n\n## -- End pasted text --\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-1-8929993d27e5> in <module>()\n      8\n      9 out = layers.fully_connected(inputs=x, num_outputs=1)\n---> 10 loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\n     11 optimizer = tf.train.AdamOptimizer().minimize(loss)\n     12\n\n/Users/olevinkr/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn.pyc in sigmoid_cross_entropy_with_logits(logits, targets, name)\n    432     except ValueError:\n    433       raise ValueError(\"logits and targets must have the same shape (%s vs %s)\"\n--> 434                        % (logits.get_shape(), targets.get_shape()))\n    435\n    436     # The logistic loss formula from above is\n\nValueError: logits and targets must have the same shape ((?, 3, 1) vs (?, 1))\n```\n\nFlattening `x` works:\n\n```\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nimport numpy as np\n\n\nx = tf.placeholder(tf.float32, shape=(None,3*4))\n# x = tf.placeholder(tf.float32, shape=(None,3,4))\ny = tf.placeholder(tf.float32, shape=(None, 1))\n\nout = layers.fully_connected(inputs=x, num_outputs=1)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(out, y))\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # x_iter = np.random.rand(2, 3, 4)\n    x_iter = np.random.rand(2, 3 * 4)\n    y_iter = np.random.rand(2, 1)\n    _ = sess.run(optimizer, feed_dict={x: x_iter, y: y_iter})\n```\n\nAm I misunderstanding the docs?\n"}