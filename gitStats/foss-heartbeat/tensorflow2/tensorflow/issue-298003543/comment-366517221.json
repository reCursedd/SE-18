{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366517221", "html_url": "https://github.com/tensorflow/tensorflow/issues/17092#issuecomment-366517221", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17092", "id": 366517221, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjUxNzIyMQ==", "user": {"login": "georgh", "id": 1831252, "node_id": "MDQ6VXNlcjE4MzEyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1831252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgh", "html_url": "https://github.com/georgh", "followers_url": "https://api.github.com/users/georgh/followers", "following_url": "https://api.github.com/users/georgh/following{/other_user}", "gists_url": "https://api.github.com/users/georgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgh/subscriptions", "organizations_url": "https://api.github.com/users/georgh/orgs", "repos_url": "https://api.github.com/users/georgh/repos", "events_url": "https://api.github.com/users/georgh/events{/privacy}", "received_events_url": "https://api.github.com/users/georgh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-18T13:45:39Z", "updated_at": "2018-02-18T13:49:45Z", "author_association": "NONE", "body_html": "<p>I extended the mem_util script to display the timeline name of state_stats and the operations of the partitions_graph. As far as I understand is the partitions_graph the optimized operations graph and should include all executed (?). Unfortunately it does not contain any timestamps or memory information.<br>\nHere is the output for the not OOM-execution with -size 70000:</p>\n<pre><code>doubleExecution finished!\nPrinting timeline for /gpu:0\n-------------------------------------------------------\ntime[ms] |  total[MB] |   diff[MB] |          kernel | timeline_label\n       0 |       0.00 |       0.00 | _SOURCE         | _SOURCE = NoOp()\n      82 |       0.00 |       0.00 | strided_slice/stack | strided_slice/stack = Const()\n     101 |       0.00 |       0.00 | strided_slice/stack_1 | strided_slice/stack_1 = Const()\n     110 |       0.00 |       0.00 | strided_slice/stack_2 | strided_slice/stack_2 = Const()\n 1061612 |     101.47 |     101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1061643 |     101.47 |       0.00 | strided_slice   | strided_slice = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)\n 1072556 |     102.01 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072560 |     102.54 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072561 |     103.07 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072887 |     102.54 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073494 |     102.01 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073495 |     101.47 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073522 |     101.47 |       0.00 | ExpandDims/dim  | ExpandDims/dim = Const(^first_0)\n 1073530 |     101.47 |       0.00 | xdt_0/multiples | xdt_0/multiples = Const(^first_0)\n 1073533 |     101.47 |       0.00 | Const           | Const = Const(^first_0)\n 1073536 |     101.47 |       0.00 | ExpandDims      | ExpandDims = ExpandDims(strided_slice, ExpandDims/dim)\n 1073548 |    6189.73 |    6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\n 1073600 |    6221.77 |      32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077343 |    6222.31 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077346 |    6222.84 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077347 |    6223.37 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112893 |    6222.84 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112895 |    6222.31 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112895 |    6221.77 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112903 |     133.51 |   -6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\n 1112904 |      32.04 |    -101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1112920 |      32.04 |       0.00 | total_0         | total_0 = Sum(third_0, Const)\n 1112940 |      32.07 |       0.02 | total_0         | total_0 = Sum(third_0, Const)\n 1112985 |      32.04 |      -0.02 | total_0         | total_0 = Sum(third_0, Const)\n 1112992 |       0.00 |     -32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112996 |       0.00 |       0.00 | strided_slice_1/stack | strided_slice_1/stack = Const(^total_0)\n 1113001 |       0.00 |       0.00 | strided_slice_1/stack_1 | strided_slice_1/stack_1 = Const(^total_0)\n 1113004 |       0.00 |       0.00 | strided_slice_1/stack_2 | strided_slice_1/stack_2 = Const(^total_0)\n 1113011 |     101.47 |     101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116695 |     102.01 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116698 |     102.54 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116698 |     103.07 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134374 |     102.54 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134375 |     102.01 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134376 |     101.47 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134395 |     101.47 |       0.00 | strided_slice_1 | strided_slice_1 = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)\n 1134407 |     101.47 |       0.00 | ExpandDims_1/dim | ExpandDims_1/dim = Const(^first_1)\n 1134411 |     101.47 |       0.00 | xdt_1/multiples | xdt_1/multiples = Const(^first_1)\n 1134414 |     101.47 |       0.00 | Const_1         | Const_1 = Const(^first_1)\n 1134416 |     101.47 |       0.00 | ExpandDims_1    | ExpandDims_1 = ExpandDims(strided_slice_1, ExpandDims_1/dim)\n 1134425 |    6189.73 |    6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\n 1134458 |    6221.77 |      32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138132 |    6222.31 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138134 |    6222.84 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138135 |    6223.37 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174411 |    6222.84 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174412 |    6222.31 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174413 |    6221.77 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174422 |    6120.30 |    -101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1174422 |      32.04 |   -6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\n 1174436 |      32.04 |       0.00 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174447 |      32.07 |       0.02 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174479 |      32.04 |      -0.02 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174485 |       0.00 |     -32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174488 |       0.00 |       0.00 | add             | add = Add(total_0, total_1)\n 1174536 |       0.00 |      -0.00 | total_1         | total_1 = Sum(third_1, Const_1)\n 1195860 |       0.00 |      -0.00 | total_0         | total_0 = Sum(third_0, Const)\nPeak: \n6525680640\npartition_graphs:\nop: _arg_XDerivation2_0_0/_13      name: _Recv                on /gpu:0 input: [] \nop: strided_slice/stack            name: Const                on /gpu:0 input: [] \nop: strided_slice/stack_1          name: Const                on /gpu:0 input: [] \nop: strided_slice/stack_2          name: Const                on /gpu:0 input: [] \nop: strided_slice                  name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice/stack', 'strided_slice/stack_1', 'strided_slice/stack_2'] \nop: _arg_alpha_0_2/_11             name: _Recv                on /gpu:0 input: [] \nop: _arg_XDerivation_0_1/_9        name: _Recv                on /gpu:0 input: [] \nop: first_0                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11'] \nop: ExpandDims/dim                 name: Const                on /gpu:0 input: ['^first_0'] \nop: ExpandDims                     name: ExpandDims           on /gpu:0 input: ['strided_slice', 'ExpandDims/dim'] \nop: xdt_0/multiples                name: Const                on /gpu:0 input: ['^first_0'] \nop: xdt_0                          name: Tile                 on /gpu:0 input: ['ExpandDims', 'xdt_0/multiples'] \nop: third_0                        name: BatchMatMul          on /gpu:0 input: ['xdt_0', 'first_0'] \nop: Const                          name: Const                on /gpu:0 input: ['^first_0'] \nop: total_0                        name: Sum                  on /gpu:0 input: ['third_0', 'Const'] \nop: strided_slice_1/stack          name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1/stack_1        name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1/stack_2        name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1                name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice_1/stack', 'strided_slice_1/stack_1', 'strided_slice_1/stack_2'] \nop: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0'] \nop: ExpandDims_1/dim               name: Const                on /gpu:0 input: ['^first_1'] \nop: ExpandDims_1                   name: ExpandDims           on /gpu:0 input: ['strided_slice_1', 'ExpandDims_1/dim'] \nop: xdt_1/multiples                name: Const                on /gpu:0 input: ['^first_1'] \nop: xdt_1                          name: Tile                 on /gpu:0 input: ['ExpandDims_1', 'xdt_1/multiples'] \nop: third_1                        name: BatchMatMul          on /gpu:0 input: ['xdt_1', 'first_1'] \nop: Const_1                        name: Const                on /gpu:0 input: ['^first_1'] \nop: total_1                        name: Sum                  on /gpu:0 input: ['third_1', 'Const_1'] \nop: add                            name: Add                  on /gpu:0 input: ['total_0', 'total_1'] \nop: add/_14                        name: _Send                on /gpu:0 input: ['add'] \n</code></pre>\n<p>I dont really get new information from it. Optimization seems not to change much in this case.<br>\nThe partitions graphs includes the Placeholder input, so thats good, but not sure how memory is allocated for it?<br>\nThe only strange thing is<br>\n<code>op: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0']</code><br>\nwhy has the second \"first\"-op total_0 as an input? But I dont have any clue what the ^ represents :/</p>", "body_text": "I extended the mem_util script to display the timeline name of state_stats and the operations of the partitions_graph. As far as I understand is the partitions_graph the optimized operations graph and should include all executed (?). Unfortunately it does not contain any timestamps or memory information.\nHere is the output for the not OOM-execution with -size 70000:\ndoubleExecution finished!\nPrinting timeline for /gpu:0\n-------------------------------------------------------\ntime[ms] |  total[MB] |   diff[MB] |          kernel | timeline_label\n       0 |       0.00 |       0.00 | _SOURCE         | _SOURCE = NoOp()\n      82 |       0.00 |       0.00 | strided_slice/stack | strided_slice/stack = Const()\n     101 |       0.00 |       0.00 | strided_slice/stack_1 | strided_slice/stack_1 = Const()\n     110 |       0.00 |       0.00 | strided_slice/stack_2 | strided_slice/stack_2 = Const()\n 1061612 |     101.47 |     101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1061643 |     101.47 |       0.00 | strided_slice   | strided_slice = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)\n 1072556 |     102.01 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072560 |     102.54 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072561 |     103.07 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1072887 |     102.54 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073494 |     102.01 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073495 |     101.47 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1073522 |     101.47 |       0.00 | ExpandDims/dim  | ExpandDims/dim = Const(^first_0)\n 1073530 |     101.47 |       0.00 | xdt_0/multiples | xdt_0/multiples = Const(^first_0)\n 1073533 |     101.47 |       0.00 | Const           | Const = Const(^first_0)\n 1073536 |     101.47 |       0.00 | ExpandDims      | ExpandDims = ExpandDims(strided_slice, ExpandDims/dim)\n 1073548 |    6189.73 |    6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\n 1073600 |    6221.77 |      32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077343 |    6222.31 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077346 |    6222.84 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1077347 |    6223.37 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112893 |    6222.84 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112895 |    6222.31 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112895 |    6221.77 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112903 |     133.51 |   -6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\n 1112904 |      32.04 |    -101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\n 1112920 |      32.04 |       0.00 | total_0         | total_0 = Sum(third_0, Const)\n 1112940 |      32.07 |       0.02 | total_0         | total_0 = Sum(third_0, Const)\n 1112985 |      32.04 |      -0.02 | total_0         | total_0 = Sum(third_0, Const)\n 1112992 |       0.00 |     -32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\n 1112996 |       0.00 |       0.00 | strided_slice_1/stack | strided_slice_1/stack = Const(^total_0)\n 1113001 |       0.00 |       0.00 | strided_slice_1/stack_1 | strided_slice_1/stack_1 = Const(^total_0)\n 1113004 |       0.00 |       0.00 | strided_slice_1/stack_2 | strided_slice_1/stack_2 = Const(^total_0)\n 1113011 |     101.47 |     101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116695 |     102.01 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116698 |     102.54 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1116698 |     103.07 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134374 |     102.54 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134375 |     102.01 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134376 |     101.47 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1134395 |     101.47 |       0.00 | strided_slice_1 | strided_slice_1 = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)\n 1134407 |     101.47 |       0.00 | ExpandDims_1/dim | ExpandDims_1/dim = Const(^first_1)\n 1134411 |     101.47 |       0.00 | xdt_1/multiples | xdt_1/multiples = Const(^first_1)\n 1134414 |     101.47 |       0.00 | Const_1         | Const_1 = Const(^first_1)\n 1134416 |     101.47 |       0.00 | ExpandDims_1    | ExpandDims_1 = ExpandDims(strided_slice_1, ExpandDims_1/dim)\n 1134425 |    6189.73 |    6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\n 1134458 |    6221.77 |      32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138132 |    6222.31 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138134 |    6222.84 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1138135 |    6223.37 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174411 |    6222.84 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174412 |    6222.31 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174413 |    6221.77 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174422 |    6120.30 |    -101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\n 1174422 |      32.04 |   -6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\n 1174436 |      32.04 |       0.00 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174447 |      32.07 |       0.02 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174479 |      32.04 |      -0.02 | total_1         | total_1 = Sum(third_1, Const_1)\n 1174485 |       0.00 |     -32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\n 1174488 |       0.00 |       0.00 | add             | add = Add(total_0, total_1)\n 1174536 |       0.00 |      -0.00 | total_1         | total_1 = Sum(third_1, Const_1)\n 1195860 |       0.00 |      -0.00 | total_0         | total_0 = Sum(third_0, Const)\nPeak: \n6525680640\npartition_graphs:\nop: _arg_XDerivation2_0_0/_13      name: _Recv                on /gpu:0 input: [] \nop: strided_slice/stack            name: Const                on /gpu:0 input: [] \nop: strided_slice/stack_1          name: Const                on /gpu:0 input: [] \nop: strided_slice/stack_2          name: Const                on /gpu:0 input: [] \nop: strided_slice                  name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice/stack', 'strided_slice/stack_1', 'strided_slice/stack_2'] \nop: _arg_alpha_0_2/_11             name: _Recv                on /gpu:0 input: [] \nop: _arg_XDerivation_0_1/_9        name: _Recv                on /gpu:0 input: [] \nop: first_0                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11'] \nop: ExpandDims/dim                 name: Const                on /gpu:0 input: ['^first_0'] \nop: ExpandDims                     name: ExpandDims           on /gpu:0 input: ['strided_slice', 'ExpandDims/dim'] \nop: xdt_0/multiples                name: Const                on /gpu:0 input: ['^first_0'] \nop: xdt_0                          name: Tile                 on /gpu:0 input: ['ExpandDims', 'xdt_0/multiples'] \nop: third_0                        name: BatchMatMul          on /gpu:0 input: ['xdt_0', 'first_0'] \nop: Const                          name: Const                on /gpu:0 input: ['^first_0'] \nop: total_0                        name: Sum                  on /gpu:0 input: ['third_0', 'Const'] \nop: strided_slice_1/stack          name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1/stack_1        name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1/stack_2        name: Const                on /gpu:0 input: ['^total_0'] \nop: strided_slice_1                name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice_1/stack', 'strided_slice_1/stack_1', 'strided_slice_1/stack_2'] \nop: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0'] \nop: ExpandDims_1/dim               name: Const                on /gpu:0 input: ['^first_1'] \nop: ExpandDims_1                   name: ExpandDims           on /gpu:0 input: ['strided_slice_1', 'ExpandDims_1/dim'] \nop: xdt_1/multiples                name: Const                on /gpu:0 input: ['^first_1'] \nop: xdt_1                          name: Tile                 on /gpu:0 input: ['ExpandDims_1', 'xdt_1/multiples'] \nop: third_1                        name: BatchMatMul          on /gpu:0 input: ['xdt_1', 'first_1'] \nop: Const_1                        name: Const                on /gpu:0 input: ['^first_1'] \nop: total_1                        name: Sum                  on /gpu:0 input: ['third_1', 'Const_1'] \nop: add                            name: Add                  on /gpu:0 input: ['total_0', 'total_1'] \nop: add/_14                        name: _Send                on /gpu:0 input: ['add'] \n\nI dont really get new information from it. Optimization seems not to change much in this case.\nThe partitions graphs includes the Placeholder input, so thats good, but not sure how memory is allocated for it?\nThe only strange thing is\nop: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0']\nwhy has the second \"first\"-op total_0 as an input? But I dont have any clue what the ^ represents :/", "body": "I extended the mem_util script to display the timeline name of state_stats and the operations of the partitions_graph. As far as I understand is the partitions_graph the optimized operations graph and should include all executed (?). Unfortunately it does not contain any timestamps or memory information.\r\nHere is the output for the not OOM-execution with -size 70000:\r\n\r\n```\r\ndoubleExecution finished!\r\nPrinting timeline for /gpu:0\r\n-------------------------------------------------------\r\ntime[ms] |  total[MB] |   diff[MB] |          kernel | timeline_label\r\n       0 |       0.00 |       0.00 | _SOURCE         | _SOURCE = NoOp()\r\n      82 |       0.00 |       0.00 | strided_slice/stack | strided_slice/stack = Const()\r\n     101 |       0.00 |       0.00 | strided_slice/stack_1 | strided_slice/stack_1 = Const()\r\n     110 |       0.00 |       0.00 | strided_slice/stack_2 | strided_slice/stack_2 = Const()\r\n 1061612 |     101.47 |     101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1061643 |     101.47 |       0.00 | strided_slice   | strided_slice = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)\r\n 1072556 |     102.01 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1072560 |     102.54 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1072561 |     103.07 |       0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1072887 |     102.54 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1073494 |     102.01 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1073495 |     101.47 |      -0.53 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1073522 |     101.47 |       0.00 | ExpandDims/dim  | ExpandDims/dim = Const(^first_0)\r\n 1073530 |     101.47 |       0.00 | xdt_0/multiples | xdt_0/multiples = Const(^first_0)\r\n 1073533 |     101.47 |       0.00 | Const           | Const = Const(^first_0)\r\n 1073536 |     101.47 |       0.00 | ExpandDims      | ExpandDims = ExpandDims(strided_slice, ExpandDims/dim)\r\n 1073548 |    6189.73 |    6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\r\n 1073600 |    6221.77 |      32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1077343 |    6222.31 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1077346 |    6222.84 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1077347 |    6223.37 |       0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1112893 |    6222.84 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1112895 |    6222.31 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1112895 |    6221.77 |      -0.53 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1112903 |     133.51 |   -6088.26 | xdt_0           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_0 = Tile(ExpandDims, xdt_0/multiples)\r\n 1112904 |      32.04 |    -101.47 | first_0         | [GPU_0_bfc 103.1MB 103.1MB] first_0 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11)\r\n 1112920 |      32.04 |       0.00 | total_0         | total_0 = Sum(third_0, Const)\r\n 1112940 |      32.07 |       0.02 | total_0         | total_0 = Sum(third_0, Const)\r\n 1112985 |      32.04 |      -0.02 | total_0         | total_0 = Sum(third_0, Const)\r\n 1112992 |       0.00 |     -32.04 | third_0         | [GPU_0_bfc 33.6MB 33.6MB] third_0 = BatchMatMul(xdt_0, first_0)\r\n 1112996 |       0.00 |       0.00 | strided_slice_1/stack | strided_slice_1/stack = Const(^total_0)\r\n 1113001 |       0.00 |       0.00 | strided_slice_1/stack_1 | strided_slice_1/stack_1 = Const(^total_0)\r\n 1113004 |       0.00 |       0.00 | strided_slice_1/stack_2 | strided_slice_1/stack_2 = Const(^total_0)\r\n 1113011 |     101.47 |     101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1116695 |     102.01 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1116698 |     102.54 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1116698 |     103.07 |       0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1134374 |     102.54 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1134375 |     102.01 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1134376 |     101.47 |      -0.53 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1134395 |     101.47 |       0.00 | strided_slice_1 | strided_slice_1 = StridedSlice(_arg_XDerivation2_0_0/_13, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)\r\n 1134407 |     101.47 |       0.00 | ExpandDims_1/dim | ExpandDims_1/dim = Const(^first_1)\r\n 1134411 |     101.47 |       0.00 | xdt_1/multiples | xdt_1/multiples = Const(^first_1)\r\n 1134414 |     101.47 |       0.00 | Const_1         | Const_1 = Const(^first_1)\r\n 1134416 |     101.47 |       0.00 | ExpandDims_1    | ExpandDims_1 = ExpandDims(strided_slice_1, ExpandDims_1/dim)\r\n 1134425 |    6189.73 |    6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\r\n 1134458 |    6221.77 |      32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1138132 |    6222.31 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1138134 |    6222.84 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1138135 |    6223.37 |       0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1174411 |    6222.84 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1174412 |    6222.31 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1174413 |    6221.77 |      -0.53 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1174422 |    6120.30 |    -101.47 | first_1         | [GPU_0_bfc 103.1MB 103.1MB] first_1 = BatchMatMul(_arg_XDerivation_0_1/_9, _arg_alpha_0_2/_11, ^total_0)\r\n 1174422 |      32.04 |   -6088.26 | xdt_1           | [GPU_0_bfc 6088.3MB 6088.3MB] xdt_1 = Tile(ExpandDims_1, xdt_1/multiples)\r\n 1174436 |      32.04 |       0.00 | total_1         | total_1 = Sum(third_1, Const_1)\r\n 1174447 |      32.07 |       0.02 | total_1         | total_1 = Sum(third_1, Const_1)\r\n 1174479 |      32.04 |      -0.02 | total_1         | total_1 = Sum(third_1, Const_1)\r\n 1174485 |       0.00 |     -32.04 | third_1         | [GPU_0_bfc 33.6MB 33.6MB] third_1 = BatchMatMul(xdt_1, first_1)\r\n 1174488 |       0.00 |       0.00 | add             | add = Add(total_0, total_1)\r\n 1174536 |       0.00 |      -0.00 | total_1         | total_1 = Sum(third_1, Const_1)\r\n 1195860 |       0.00 |      -0.00 | total_0         | total_0 = Sum(third_0, Const)\r\nPeak: \r\n6525680640\r\npartition_graphs:\r\nop: _arg_XDerivation2_0_0/_13      name: _Recv                on /gpu:0 input: [] \r\nop: strided_slice/stack            name: Const                on /gpu:0 input: [] \r\nop: strided_slice/stack_1          name: Const                on /gpu:0 input: [] \r\nop: strided_slice/stack_2          name: Const                on /gpu:0 input: [] \r\nop: strided_slice                  name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice/stack', 'strided_slice/stack_1', 'strided_slice/stack_2'] \r\nop: _arg_alpha_0_2/_11             name: _Recv                on /gpu:0 input: [] \r\nop: _arg_XDerivation_0_1/_9        name: _Recv                on /gpu:0 input: [] \r\nop: first_0                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11'] \r\nop: ExpandDims/dim                 name: Const                on /gpu:0 input: ['^first_0'] \r\nop: ExpandDims                     name: ExpandDims           on /gpu:0 input: ['strided_slice', 'ExpandDims/dim'] \r\nop: xdt_0/multiples                name: Const                on /gpu:0 input: ['^first_0'] \r\nop: xdt_0                          name: Tile                 on /gpu:0 input: ['ExpandDims', 'xdt_0/multiples'] \r\nop: third_0                        name: BatchMatMul          on /gpu:0 input: ['xdt_0', 'first_0'] \r\nop: Const                          name: Const                on /gpu:0 input: ['^first_0'] \r\nop: total_0                        name: Sum                  on /gpu:0 input: ['third_0', 'Const'] \r\nop: strided_slice_1/stack          name: Const                on /gpu:0 input: ['^total_0'] \r\nop: strided_slice_1/stack_1        name: Const                on /gpu:0 input: ['^total_0'] \r\nop: strided_slice_1/stack_2        name: Const                on /gpu:0 input: ['^total_0'] \r\nop: strided_slice_1                name: StridedSlice         on /gpu:0 input: ['_arg_XDerivation2_0_0/_13', 'strided_slice_1/stack', 'strided_slice_1/stack_1', 'strided_slice_1/stack_2'] \r\nop: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0'] \r\nop: ExpandDims_1/dim               name: Const                on /gpu:0 input: ['^first_1'] \r\nop: ExpandDims_1                   name: ExpandDims           on /gpu:0 input: ['strided_slice_1', 'ExpandDims_1/dim'] \r\nop: xdt_1/multiples                name: Const                on /gpu:0 input: ['^first_1'] \r\nop: xdt_1                          name: Tile                 on /gpu:0 input: ['ExpandDims_1', 'xdt_1/multiples'] \r\nop: third_1                        name: BatchMatMul          on /gpu:0 input: ['xdt_1', 'first_1'] \r\nop: Const_1                        name: Const                on /gpu:0 input: ['^first_1'] \r\nop: total_1                        name: Sum                  on /gpu:0 input: ['third_1', 'Const_1'] \r\nop: add                            name: Add                  on /gpu:0 input: ['total_0', 'total_1'] \r\nop: add/_14                        name: _Send                on /gpu:0 input: ['add'] \r\n```\r\nI dont really get new information from it. Optimization seems not to change much in this case.\r\nThe partitions graphs includes the Placeholder input, so thats good, but not sure how memory is allocated for it?\r\nThe only strange thing is\r\n`op: first_1                        name: BatchMatMul          on /gpu:0 input: ['_arg_XDerivation_0_1/_9', '_arg_alpha_0_2/_11', '^total_0']`  \r\nwhy has the second \"first\"-op total_0 as an input? But I dont have any clue what the ^ represents :/"}