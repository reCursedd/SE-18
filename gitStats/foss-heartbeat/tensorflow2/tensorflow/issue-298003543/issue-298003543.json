{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17092", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17092/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17092/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17092/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17092", "id": 298003543, "node_id": "MDU6SXNzdWUyOTgwMDM1NDM=", "number": 17092, "title": "[BUG] GPU memory is not freed before execution of following operation + report_tensor_allocations_upon_oom is wrong", "user": {"login": "georgh", "id": 1831252, "node_id": "MDQ6VXNlcjE4MzEyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1831252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgh", "html_url": "https://github.com/georgh", "followers_url": "https://api.github.com/users/georgh/followers", "following_url": "https://api.github.com/users/georgh/following{/other_user}", "gists_url": "https://api.github.com/users/georgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgh/subscriptions", "organizations_url": "https://api.github.com/users/georgh/orgs", "repos_url": "https://api.github.com/users/georgh/repos", "events_url": "https://api.github.com/users/georgh/events{/privacy}", "received_events_url": "https://api.github.com/users/georgh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatianashp", "id": 986732, "node_id": "MDQ6VXNlcjk4NjczMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/986732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatianashp", "html_url": "https://github.com/tatianashp", "followers_url": "https://api.github.com/users/tatianashp/followers", "following_url": "https://api.github.com/users/tatianashp/following{/other_user}", "gists_url": "https://api.github.com/users/tatianashp/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatianashp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatianashp/subscriptions", "organizations_url": "https://api.github.com/users/tatianashp/orgs", "repos_url": "https://api.github.com/users/tatianashp/repos", "events_url": "https://api.github.com/users/tatianashp/events{/privacy}", "received_events_url": "https://api.github.com/users/tatianashp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-02-17T13:06:14Z", "updated_at": "2018-05-31T22:39:13Z", "closed_at": "2018-05-31T22:39:12Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: both</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4 and 1.6</li>\n<li><strong>Python version</strong>: 3.5.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>: ?</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 9 / 6</li>\n<li><strong>GPU model and memory</strong>: Tesla P100-PCIE-16GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>The following code defines an operation that performs two big multiplications and a sum reduction on the GPU:</p>\n<pre><code>def op(alpha, Xder, Xdertest, i):\n      cols = size #tf.shape(X)[0]\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \n      with tf.control_dependencies([first]):\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\n      return total \n</code></pre>\n<p>This will run fine if performed once, but if you repeat it with:</p>\n<pre><code>singleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\nwith tf.control_dependencies([singleExecution]):\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\n      doubleExecution = singleExecution + secodExecution # this should only add two doubles!\n</code></pre>\n<p>it will produce an OOM-Execption. The expected behavior would be the calculation of the first result, clearing the GPU of all used memory and then calculating the second result.</p>\n<p>Complete Code to reproduce:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.client import timeline\nimport numpy as np\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('-size', type=int, default=100000)\nparser.add_argument('-displayPlacement',action='store_true', default=False)\nargs = parser.parse_args()\n\nrows = 2\nsize = args.size\nnum_des = 190\nnum_dim = 60\n\ndef op(alpha, Xder, Xdertest, i):\n      cols = size #tf.shape(X)[0]\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \n      with tf.control_dependencies([first]):\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\n      return total  \n\n\nXder = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation\")\nXdertest = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation2\")\nalpha = tf.placeholder(tf.float64, [None, num_dim, 1], name=\"alpha\")\n\n\nsingleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\nwith tf.control_dependencies([singleExecution]):\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\n      doubleExecution = singleExecution + secodExecution\n\nfdict = {\n      alpha: np.random.rand(size, num_dim, 1),\n      Xder: np.random.rand(size, num_dim, num_des),\n      Xdertest: np.random.rand(rows, num_dim, num_des),\n}\nprint(\"Memory of input:\")\nprint(\"alpha: {:.2f} MB\".format(size*num_dim * 8. / 1024**2))\nprint(\"Xder: {:.2f} MB\".format(size*num_dim*num_des * 8. / 1024**2))\nprint(\"Xdertest: {:.2f} MB\".format(rows*num_dim*num_dim * 8. / 1024**2))\n\nprint(\"first operation should need Xder + alpha + result: {:.2f} MB\".format(( size*num_dim*num_des + size*num_dim  + size*num_des )* 8. / 1024**2))\nprint(\"result of first operation alone needs: {:.2f} MB\".format(( size*num_des )* 8. / 1024**2))\nprint(\"xdt operation should need : {:.2f} MB\".format(( size*num_dim*num_des )* 8. / 1024**2))\nprint(\"third operation should need xdt + first + result: {:.2f} MB\".format((size*num_dim + size*num_des + size*num_dim*num_des )* 8. / 1024**2))\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = False\nconfig.log_device_placement = args.displayPlacement\nsess = tf.Session(config=config) \nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE, report_tensor_allocations_upon_oom = True)\nrun_metadata = tf.RunMetadata()\nprint(sess.run(singleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\nprint(\"singleExecution finished!\")\n\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\nwith open('timeline_single.json', 'w') as f:\n      f.write(chrome_trace)\n\nrun_metadata = tf.RunMetadata()\nprint(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\nprint(\"doubleExecution finished!\")\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\nwith open('timeline_double.json', 'w') as f:\n      f.write(chrome_trace)\n</code></pre>\n<p>You may have to change the size of the tensor to trigger the OOM if you use a different GPU.<br>\nThe test-Code will also produce timelines, one for the single execution and a second for the second execution (only if you choose a size small enough - for example 70000 on the P100)</p>\n<p>The print created by the report_tensor_allocations_upon_oom is not helpful, because it indicates a nearly complete free GPU. Total Log of the execution:</p>\n<pre><code> $$  CUDA_VISIBLE_DEVICES=1 python gpuMem.py \nMemory of input:\nalpha: 45.78 MB\nXder: 8697.51 MB\nXdertest: 0.05 MB\nfirst operation should need Xder + alpha + result: 8888.24 MB\nresult of first operation alone needs: 144.96 MB\nxdt operation should need : 8697.51 MB\nthird operation should need xdt + first + result: 8888.24 MB\n2018-02-17 14:02:30.712016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:0b:00.0\ntotalMemory: 15.89GiB freeMemory: 15.60GiB\n2018-02-17 14:02:30.712072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-02-17 14:02:31.024207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15128 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)\n2018-02-17 14:02:36.312709: I tensorflow/stream_executor/dso_loader.cc:151] successfully opened CUDA library libcupti.so.9.0 locally\n8563879389.460578\nsingleExecution finished!\n2018-02-17 14:02:53.755140: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.49GiB.  Current allocation summary follows.\n2018-02-17 14:02:53.755215: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755233: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755256: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n2018-02-17 14:02:53.755271: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755285: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755358: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755375: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755390: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755406: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755427: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 1, Chunks in use: 1. 178.2KiB allocated for chunks. 178.2KiB in use in bin. 178.1KiB client-requested in use in bin.\n2018-02-17 14:02:53.755445: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755459: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755473: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755487: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755502: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755517: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755532: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755555: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 1, Chunks in use: 1. 45.78MiB allocated for chunks. 45.78MiB in use in bin. 45.78MiB client-requested in use in bin.\n2018-02-17 14:02:53.755570: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755589: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 1, Chunks in use: 1. 144.96MiB allocated for chunks. 144.96MiB in use in bin. 144.96MiB client-requested in use in bin.\n2018-02-17 14:02:53.755606: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 14.59GiB allocated for chunks. 8.49GiB in use in bin. 8.49GiB client-requested in use in bin.\n2018-02-17 14:02:53.755622: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 8.49GiB was 256.00MiB, Chunk State: \n2018-02-17 14:02:53.755645: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 6.09GiB | Requested Size: 781.2KiB | in_use: 0, prev:   Size: 144.96MiB | Requested Size: 144.96MiB | in_use: 1\n2018-02-17 14:02:53.755662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400000 of size 1280\n2018-02-17 14:02:53.755676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400500 of size 9120000000\n2018-02-17 14:02:53.755688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10435d82d00 of size 48000000\n2018-02-17 14:02:53.755699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b49900 of size 182528\n2018-02-17 14:02:53.755711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b76200 of size 152000000\n2018-02-17 14:02:53.755723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x10441c6b800 of size 6543709184\n2018-02-17 14:02:53.755731: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \n2018-02-17 14:02:53.755746: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\n2018-02-17 14:02:53.755759: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 182528 totalling 178.2KiB\n2018-02-17 14:02:53.755772: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 48000000 totalling 45.78MiB\n2018-02-17 14:02:53.755786: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 152000000 totalling 144.96MiB\n2018-02-17 14:02:53.755799: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 9120000000 totalling 8.49GiB\n2018-02-17 14:02:53.755812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 8.68GiB\n2018-02-17 14:02:53.755827: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \nLimit:                 15863893197\nInUse:                  9320183808\nMaxInUse:               9322583808\nNumAllocs:                      22\nMaxAllocSize:           9120000000\n\n2018-02-17 14:02:53.755846: W tensorflow/core/common_runtime/bfc_allocator.cc:279] ***********************************************************_________________________________________\n2018-02-17 14:02:53.755879: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at tile_ops.cc:123 : Resource exhausted: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\nTraceback (most recent call last):\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n    return fn(*args)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n    target_list, status, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"gpuMem.py\", line 65, in &lt;module&gt;\n    print(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 905, in run\n    run_metadata_ptr)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n    options, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0\n\n\nCaused by op 'xdt_0', defined at:\n  File \"gpuMem.py\", line 30, in &lt;module&gt;\n    singleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\n  File \"gpuMem.py\", line 19, in op\n    xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5587, in tile\n    \"Tile\", input=input, multiples=multiples, name=name)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0\n \n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\nTensorFlow installed from (source or binary): both\nTensorFlow version (use command below): 1.4 and 1.6\nPython version: 3.5.4\nBazel version (if compiling from source): ?\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: 9 / 6\nGPU model and memory: Tesla P100-PCIE-16GB\nExact command to reproduce:\n\nThe following code defines an operation that performs two big multiplications and a sum reduction on the GPU:\ndef op(alpha, Xder, Xdertest, i):\n      cols = size #tf.shape(X)[0]\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \n      with tf.control_dependencies([first]):\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\n      return total \n\nThis will run fine if performed once, but if you repeat it with:\nsingleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\nwith tf.control_dependencies([singleExecution]):\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\n      doubleExecution = singleExecution + secodExecution # this should only add two doubles!\n\nit will produce an OOM-Execption. The expected behavior would be the calculation of the first result, clearing the GPU of all used memory and then calculating the second result.\nComplete Code to reproduce:\nimport tensorflow as tf\nfrom tensorflow.python.client import timeline\nimport numpy as np\nimport argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('-size', type=int, default=100000)\nparser.add_argument('-displayPlacement',action='store_true', default=False)\nargs = parser.parse_args()\n\nrows = 2\nsize = args.size\nnum_des = 190\nnum_dim = 60\n\ndef op(alpha, Xder, Xdertest, i):\n      cols = size #tf.shape(X)[0]\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \n      with tf.control_dependencies([first]):\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\n      return total  \n\n\nXder = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation\")\nXdertest = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation2\")\nalpha = tf.placeholder(tf.float64, [None, num_dim, 1], name=\"alpha\")\n\n\nsingleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\nwith tf.control_dependencies([singleExecution]):\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\n      doubleExecution = singleExecution + secodExecution\n\nfdict = {\n      alpha: np.random.rand(size, num_dim, 1),\n      Xder: np.random.rand(size, num_dim, num_des),\n      Xdertest: np.random.rand(rows, num_dim, num_des),\n}\nprint(\"Memory of input:\")\nprint(\"alpha: {:.2f} MB\".format(size*num_dim * 8. / 1024**2))\nprint(\"Xder: {:.2f} MB\".format(size*num_dim*num_des * 8. / 1024**2))\nprint(\"Xdertest: {:.2f} MB\".format(rows*num_dim*num_dim * 8. / 1024**2))\n\nprint(\"first operation should need Xder + alpha + result: {:.2f} MB\".format(( size*num_dim*num_des + size*num_dim  + size*num_des )* 8. / 1024**2))\nprint(\"result of first operation alone needs: {:.2f} MB\".format(( size*num_des )* 8. / 1024**2))\nprint(\"xdt operation should need : {:.2f} MB\".format(( size*num_dim*num_des )* 8. / 1024**2))\nprint(\"third operation should need xdt + first + result: {:.2f} MB\".format((size*num_dim + size*num_des + size*num_dim*num_des )* 8. / 1024**2))\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = False\nconfig.log_device_placement = args.displayPlacement\nsess = tf.Session(config=config) \nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE, report_tensor_allocations_upon_oom = True)\nrun_metadata = tf.RunMetadata()\nprint(sess.run(singleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\nprint(\"singleExecution finished!\")\n\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\nwith open('timeline_single.json', 'w') as f:\n      f.write(chrome_trace)\n\nrun_metadata = tf.RunMetadata()\nprint(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\nprint(\"doubleExecution finished!\")\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\nwith open('timeline_double.json', 'w') as f:\n      f.write(chrome_trace)\n\nYou may have to change the size of the tensor to trigger the OOM if you use a different GPU.\nThe test-Code will also produce timelines, one for the single execution and a second for the second execution (only if you choose a size small enough - for example 70000 on the P100)\nThe print created by the report_tensor_allocations_upon_oom is not helpful, because it indicates a nearly complete free GPU. Total Log of the execution:\n $$  CUDA_VISIBLE_DEVICES=1 python gpuMem.py \nMemory of input:\nalpha: 45.78 MB\nXder: 8697.51 MB\nXdertest: 0.05 MB\nfirst operation should need Xder + alpha + result: 8888.24 MB\nresult of first operation alone needs: 144.96 MB\nxdt operation should need : 8697.51 MB\nthird operation should need xdt + first + result: 8888.24 MB\n2018-02-17 14:02:30.712016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:0b:00.0\ntotalMemory: 15.89GiB freeMemory: 15.60GiB\n2018-02-17 14:02:30.712072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n2018-02-17 14:02:31.024207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15128 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)\n2018-02-17 14:02:36.312709: I tensorflow/stream_executor/dso_loader.cc:151] successfully opened CUDA library libcupti.so.9.0 locally\n8563879389.460578\nsingleExecution finished!\n2018-02-17 14:02:53.755140: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.49GiB.  Current allocation summary follows.\n2018-02-17 14:02:53.755215: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755233: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755256: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n2018-02-17 14:02:53.755271: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755285: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755358: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755375: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755390: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755406: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755427: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 1, Chunks in use: 1. 178.2KiB allocated for chunks. 178.2KiB in use in bin. 178.1KiB client-requested in use in bin.\n2018-02-17 14:02:53.755445: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755459: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755473: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755487: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755502: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755517: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755532: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755555: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 1, Chunks in use: 1. 45.78MiB allocated for chunks. 45.78MiB in use in bin. 45.78MiB client-requested in use in bin.\n2018-02-17 14:02:53.755570: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-02-17 14:02:53.755589: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 1, Chunks in use: 1. 144.96MiB allocated for chunks. 144.96MiB in use in bin. 144.96MiB client-requested in use in bin.\n2018-02-17 14:02:53.755606: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 14.59GiB allocated for chunks. 8.49GiB in use in bin. 8.49GiB client-requested in use in bin.\n2018-02-17 14:02:53.755622: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 8.49GiB was 256.00MiB, Chunk State: \n2018-02-17 14:02:53.755645: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 6.09GiB | Requested Size: 781.2KiB | in_use: 0, prev:   Size: 144.96MiB | Requested Size: 144.96MiB | in_use: 1\n2018-02-17 14:02:53.755662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400000 of size 1280\n2018-02-17 14:02:53.755676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400500 of size 9120000000\n2018-02-17 14:02:53.755688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10435d82d00 of size 48000000\n2018-02-17 14:02:53.755699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b49900 of size 182528\n2018-02-17 14:02:53.755711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b76200 of size 152000000\n2018-02-17 14:02:53.755723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x10441c6b800 of size 6543709184\n2018-02-17 14:02:53.755731: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \n2018-02-17 14:02:53.755746: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\n2018-02-17 14:02:53.755759: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 182528 totalling 178.2KiB\n2018-02-17 14:02:53.755772: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 48000000 totalling 45.78MiB\n2018-02-17 14:02:53.755786: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 152000000 totalling 144.96MiB\n2018-02-17 14:02:53.755799: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 9120000000 totalling 8.49GiB\n2018-02-17 14:02:53.755812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 8.68GiB\n2018-02-17 14:02:53.755827: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \nLimit:                 15863893197\nInUse:                  9320183808\nMaxInUse:               9322583808\nNumAllocs:                      22\nMaxAllocSize:           9120000000\n\n2018-02-17 14:02:53.755846: W tensorflow/core/common_runtime/bfc_allocator.cc:279] ***********************************************************_________________________________________\n2018-02-17 14:02:53.755879: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at tile_ops.cc:123 : Resource exhausted: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\nTraceback (most recent call last):\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n    return fn(*args)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n    target_list, status, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"gpuMem.py\", line 65, in <module>\n    print(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 905, in run\n    run_metadata_ptr)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n    options, run_metadata)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0\n\n\nCaused by op 'xdt_0', defined at:\n  File \"gpuMem.py\", line 30, in <module>\n    singleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\n  File \"gpuMem.py\", line 19, in op\n    xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5587, in tile\n    \"Tile\", input=input, multiples=multiples, name=name)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from first_0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: both\r\n- **TensorFlow version (use command below)**: 1.4 and 1.6\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**: ?\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9 / 6\r\n- **GPU model and memory**: Tesla P100-PCIE-16GB\r\n- **Exact command to reproduce**:\r\n\r\nThe following code defines an operation that performs two big multiplications and a sum reduction on the GPU:\r\n```\r\ndef op(alpha, Xder, Xdertest, i):\r\n      cols = size #tf.shape(X)[0]\r\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \r\n      with tf.control_dependencies([first]):\r\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\r\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\r\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\r\n      return total \r\n```\r\nThis will run fine if performed once, but if you repeat it with:\r\n```\r\nsingleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\r\nwith tf.control_dependencies([singleExecution]):\r\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\r\n      doubleExecution = singleExecution + secodExecution # this should only add two doubles!\r\n```\r\n it will produce an OOM-Execption. The expected behavior would be the calculation of the first result, clearing the GPU of all used memory and then calculating the second result.\r\n\r\nComplete Code to reproduce:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\nimport numpy as np\r\nimport argparse\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('-size', type=int, default=100000)\r\nparser.add_argument('-displayPlacement',action='store_true', default=False)\r\nargs = parser.parse_args()\r\n\r\nrows = 2\r\nsize = args.size\r\nnum_des = 190\r\nnum_dim = 60\r\n\r\ndef op(alpha, Xder, Xdertest, i):\r\n      cols = size #tf.shape(X)[0]\r\n      first = tf.matmul(Xder, alpha, transpose_a=True, name=\"first_{}\".format(i))            # cols x num_des x 1  \r\n      with tf.control_dependencies([first]):\r\n            xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\r\n            third = tf.matmul(xdt, first, name=\"third_{}\".format(i))                         # cols x num_dim x 1\r\n            total = tf.reduce_sum(third, name=\"total_{}\".format(i))                          # single number\r\n      return total  \r\n\r\n\r\nXder = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation\")\r\nXdertest = tf.placeholder(tf.float64, [None, num_dim, num_des], name=\"XDerivation2\")\r\nalpha = tf.placeholder(tf.float64, [None, num_dim, 1], name=\"alpha\")\r\n\r\n\r\nsingleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\r\nwith tf.control_dependencies([singleExecution]):\r\n      secodExecution = op(alpha, Xder, Xdertest[1,:,:], 1)\r\n      doubleExecution = singleExecution + secodExecution\r\n\r\nfdict = {\r\n      alpha: np.random.rand(size, num_dim, 1),\r\n      Xder: np.random.rand(size, num_dim, num_des),\r\n      Xdertest: np.random.rand(rows, num_dim, num_des),\r\n}\r\nprint(\"Memory of input:\")\r\nprint(\"alpha: {:.2f} MB\".format(size*num_dim * 8. / 1024**2))\r\nprint(\"Xder: {:.2f} MB\".format(size*num_dim*num_des * 8. / 1024**2))\r\nprint(\"Xdertest: {:.2f} MB\".format(rows*num_dim*num_dim * 8. / 1024**2))\r\n\r\nprint(\"first operation should need Xder + alpha + result: {:.2f} MB\".format(( size*num_dim*num_des + size*num_dim  + size*num_des )* 8. / 1024**2))\r\nprint(\"result of first operation alone needs: {:.2f} MB\".format(( size*num_des )* 8. / 1024**2))\r\nprint(\"xdt operation should need : {:.2f} MB\".format(( size*num_dim*num_des )* 8. / 1024**2))\r\nprint(\"third operation should need xdt + first + result: {:.2f} MB\".format((size*num_dim + size*num_des + size*num_dim*num_des )* 8. / 1024**2))\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = False\r\nconfig.log_device_placement = args.displayPlacement\r\nsess = tf.Session(config=config) \r\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE, report_tensor_allocations_upon_oom = True)\r\nrun_metadata = tf.RunMetadata()\r\nprint(sess.run(singleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\r\nprint(\"singleExecution finished!\")\r\n\r\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\r\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\r\nwith open('timeline_single.json', 'w') as f:\r\n      f.write(chrome_trace)\r\n\r\nrun_metadata = tf.RunMetadata()\r\nprint(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\r\nprint(\"doubleExecution finished!\")\r\nfetched_timeline = timeline.Timeline(run_metadata.step_stats)\r\nchrome_trace = fetched_timeline.generate_chrome_trace_format(show_memory=True)\r\nwith open('timeline_double.json', 'w') as f:\r\n      f.write(chrome_trace)\r\n```\r\nYou may have to change the size of the tensor to trigger the OOM if you use a different GPU. \r\nThe test-Code will also produce timelines, one for the single execution and a second for the second execution (only if you choose a size small enough - for example 70000 on the P100)\r\n\r\nThe print created by the report_tensor_allocations_upon_oom is not helpful, because it indicates a nearly complete free GPU. Total Log of the execution:\r\n\r\n```\r\n $$  CUDA_VISIBLE_DEVICES=1 python gpuMem.py \r\nMemory of input:\r\nalpha: 45.78 MB\r\nXder: 8697.51 MB\r\nXdertest: 0.05 MB\r\nfirst operation should need Xder + alpha + result: 8888.24 MB\r\nresult of first operation alone needs: 144.96 MB\r\nxdt operation should need : 8697.51 MB\r\nthird operation should need xdt + first + result: 8888.24 MB\r\n2018-02-17 14:02:30.712016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:0b:00.0\r\ntotalMemory: 15.89GiB freeMemory: 15.60GiB\r\n2018-02-17 14:02:30.712072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-02-17 14:02:31.024207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15128 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)\r\n2018-02-17 14:02:36.312709: I tensorflow/stream_executor/dso_loader.cc:151] successfully opened CUDA library libcupti.so.9.0 locally\r\n8563879389.460578\r\nsingleExecution finished!\r\n2018-02-17 14:02:53.755140: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.49GiB.  Current allocation summary follows.\r\n2018-02-17 14:02:53.755215: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755233: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755256: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\r\n2018-02-17 14:02:53.755271: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755285: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755358: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755375: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755390: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755406: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755427: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 1, Chunks in use: 1. 178.2KiB allocated for chunks. 178.2KiB in use in bin. 178.1KiB client-requested in use in bin.\r\n2018-02-17 14:02:53.755445: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755459: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755473: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755487: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755502: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755517: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755532: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755555: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 1, Chunks in use: 1. 45.78MiB allocated for chunks. 45.78MiB in use in bin. 45.78MiB client-requested in use in bin.\r\n2018-02-17 14:02:53.755570: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-17 14:02:53.755589: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 1, Chunks in use: 1. 144.96MiB allocated for chunks. 144.96MiB in use in bin. 144.96MiB client-requested in use in bin.\r\n2018-02-17 14:02:53.755606: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 14.59GiB allocated for chunks. 8.49GiB in use in bin. 8.49GiB client-requested in use in bin.\r\n2018-02-17 14:02:53.755622: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 8.49GiB was 256.00MiB, Chunk State: \r\n2018-02-17 14:02:53.755645: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 6.09GiB | Requested Size: 781.2KiB | in_use: 0, prev:   Size: 144.96MiB | Requested Size: 144.96MiB | in_use: 1\r\n2018-02-17 14:02:53.755662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400000 of size 1280\r\n2018-02-17 14:02:53.755676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10216400500 of size 9120000000\r\n2018-02-17 14:02:53.755688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10435d82d00 of size 48000000\r\n2018-02-17 14:02:53.755699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b49900 of size 182528\r\n2018-02-17 14:02:53.755711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x10438b76200 of size 152000000\r\n2018-02-17 14:02:53.755723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x10441c6b800 of size 6543709184\r\n2018-02-17 14:02:53.755731: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \r\n2018-02-17 14:02:53.755746: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\r\n2018-02-17 14:02:53.755759: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 182528 totalling 178.2KiB\r\n2018-02-17 14:02:53.755772: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 48000000 totalling 45.78MiB\r\n2018-02-17 14:02:53.755786: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 152000000 totalling 144.96MiB\r\n2018-02-17 14:02:53.755799: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 9120000000 totalling 8.49GiB\r\n2018-02-17 14:02:53.755812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 8.68GiB\r\n2018-02-17 14:02:53.755827: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \r\nLimit:                 15863893197\r\nInUse:                  9320183808\r\nMaxInUse:               9322583808\r\nNumAllocs:                      22\r\nMaxAllocSize:           9120000000\r\n\r\n2018-02-17 14:02:53.755846: W tensorflow/core/common_runtime/bfc_allocator.cc:279] ***********************************************************_________________________________________\r\n2018-02-17 14:02:53.755879: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at tile_ops.cc:123 : Resource exhausted: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\r\n    return fn(*args)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\r\n    target_list, status, run_metadata)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from first_0\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"gpuMem.py\", line 65, in <module>\r\n    print(sess.run(doubleExecution, feed_dict=fdict, options=run_options, run_metadata=run_metadata))\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from first_0\r\n\r\n\r\nCaused by op 'xdt_0', defined at:\r\n  File \"gpuMem.py\", line 30, in <module>\r\n    singleExecution = op(alpha, Xder, Xdertest[0,:,:], 0)\r\n  File \"gpuMem.py\", line 19, in op\r\n    xdt = tf.tile(tf.expand_dims(Xdertest,0), [cols,1,1], name=\"xdt_{}\".format(i))   # cols x num_dim x num_des\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5587, in tile\r\n    \"Tile\", input=input, multiples=multiples, name=name)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ghiero/anaconda3/envs/tftest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[Node: xdt_0 = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, xdt_0/multiples)]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from first_0\r\n \r\n```\r\n\r\n\r\n"}