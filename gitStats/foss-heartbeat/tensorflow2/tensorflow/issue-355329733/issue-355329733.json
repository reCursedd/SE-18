{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21959", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21959/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21959/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21959/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21959", "id": 355329733, "node_id": "MDU6SXNzdWUzNTUzMjk3MzM=", "number": 21959, "title": "tf.contrib.training.batch_sequences_with_states treats batching as duplicating", "user": {"login": "htcai", "id": 10578185, "node_id": "MDQ6VXNlcjEwNTc4MTg1", "avatar_url": "https://avatars2.githubusercontent.com/u/10578185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/htcai", "html_url": "https://github.com/htcai", "followers_url": "https://api.github.com/users/htcai/followers", "following_url": "https://api.github.com/users/htcai/following{/other_user}", "gists_url": "https://api.github.com/users/htcai/gists{/gist_id}", "starred_url": "https://api.github.com/users/htcai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/htcai/subscriptions", "organizations_url": "https://api.github.com/users/htcai/orgs", "repos_url": "https://api.github.com/users/htcai/repos", "events_url": "https://api.github.com/users/htcai/events{/privacy}", "received_events_url": "https://api.github.com/users/htcai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-08-29T20:55:57Z", "updated_at": "2018-11-14T19:26:18Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Google Colab</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: N/A</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.0</li>\n<li><strong>Python version</strong>: 3.6.3</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When <code>train.batch_sequences_with_states</code> extracts batches from a sequence of samples, what it actually does is duplicating the same segment for <code>batch_size</code> times.</p>\n<h3>Source code / logs</h3>\n<p>The code is revised based on <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/training/python/training/batch_sequences_with_states_test.py\">batch_sequences_with_states_test.py</a></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> pprint <span class=\"pl-k\">import</span> pprint\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.contrib.training.python.training <span class=\"pl-k\">import</span> sequence_queueing_state_saver <span class=\"pl-k\">as</span> sqss\n\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\nnum_unroll <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\nlstm_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\nvalue_length <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span>\ninput_key <span class=\"pl-k\">=</span> tf.as_string(tf.cast(<span class=\"pl-c1\">10000</span> <span class=\"pl-k\">*</span> tf.random_uniform(()), tf.int32))\ninput_sequences <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>: np.random.rand(value_length, <span class=\"pl-c1\">3</span>)}\ninput_context <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>context_key<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-c1\">1</span>]}\ninitial_states <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>lstm_state<span class=\"pl-pds\">\"</span></span>: np.random.rand(<span class=\"pl-c1\">10</span>, lstm_size)}\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    batch <span class=\"pl-k\">=</span> sqss.batch_sequences_with_states(\n        <span class=\"pl-v\">input_key</span><span class=\"pl-k\">=</span>input_key,\n        <span class=\"pl-v\">input_sequences</span><span class=\"pl-k\">=</span>input_sequences,\n        <span class=\"pl-v\">input_context</span><span class=\"pl-k\">=</span>input_context,\n        <span class=\"pl-v\">input_length</span><span class=\"pl-k\">=</span>value_length,\n        <span class=\"pl-v\">initial_states</span><span class=\"pl-k\">=</span>initial_states,\n        <span class=\"pl-v\">num_unroll</span><span class=\"pl-k\">=</span>num_unroll,\n        <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size)\n    state <span class=\"pl-k\">=</span> batch.state(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lstm_state<span class=\"pl-pds\">'</span></span>)\n    update_state <span class=\"pl-k\">=</span> batch.save_state(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lstm_state<span class=\"pl-pds\">'</span></span>, state <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)\n    coord <span class=\"pl-k\">=</span> tf.train.Coordinator()\n    tf.train.start_queue_runners(<span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess, <span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord)\n    input_batch_val <span class=\"pl-k\">=</span> sess.run([\n        batch.key, batch.next_key, batch.sequences[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>],\n        batch.context[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>context_key<span class=\"pl-pds\">'</span></span>], state, batch.length, update_state][<span class=\"pl-c1\">2</span>])\n    pprint(input_batch_val)</pre></div>\n<p>Output:</p>\n<pre><code>array([[[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]],\n\n       [[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]],\n\n       [[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]]])\n</code></pre>\n<p>What further justifies my suspect is the expected values of sequences in unit tests <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/training/python/training/batch_sequences_with_states_test.py\">batch_sequences_with_states_test.py</a>, which is duplicating the first segment of <code>\"seq1\"</code>.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">_testBasicPadding</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">pad</span>, <span class=\"pl-smi\">key</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">make_keys_unique</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    num_unroll <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Divisor of value_length - so no padding necessary.</span>\n    expected_seq1_batch1 <span class=\"pl-k\">=</span> np.tile(\n        <span class=\"pl-c1\">self</span>.sequences[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>seq1<span class=\"pl-pds\">\"</span></span>][np.newaxis, <span class=\"pl-c1\">0</span>:num_unroll, :],\n(<span class=\"pl-c1\">self</span>.batch_size, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>))</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): N/A\nTensorFlow version (use command below): 1.10.0\nPython version: 3.6.3\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nDescribe the problem\nWhen train.batch_sequences_with_states extracts batches from a sequence of samples, what it actually does is duplicating the same segment for batch_size times.\nSource code / logs\nThe code is revised based on batch_sequences_with_states_test.py\nfrom pprint import pprint\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.training.python.training import sequence_queueing_state_saver as sqss\n\nbatch_size = 3\nnum_unroll = 2\nlstm_size = 4\nvalue_length = 8\ninput_key = tf.as_string(tf.cast(10000 * tf.random_uniform(()), tf.int32))\ninput_sequences = {'input': np.random.rand(value_length, 3)}\ninput_context = {'context_key': [1]}\ninitial_states = {\"lstm_state\": np.random.rand(10, lstm_size)}\n\nwith tf.Session() as sess:\n    batch = sqss.batch_sequences_with_states(\n        input_key=input_key,\n        input_sequences=input_sequences,\n        input_context=input_context,\n        input_length=value_length,\n        initial_states=initial_states,\n        num_unroll=num_unroll,\n        batch_size=batch_size)\n    state = batch.state('lstm_state')\n    update_state = batch.save_state('lstm_state', state + 1)\n    coord = tf.train.Coordinator()\n    tf.train.start_queue_runners(sess=sess, coord=coord)\n    input_batch_val = sess.run([\n        batch.key, batch.next_key, batch.sequences['input'],\n        batch.context['context_key'], state, batch.length, update_state][2])\n    pprint(input_batch_val)\nOutput:\narray([[[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]],\n\n       [[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]],\n\n       [[0.33537843, 0.76504494, 0.368679  ],\n        [0.47943187, 0.58871135, 0.06263617]]])\n\nWhat further justifies my suspect is the expected values of sequences in unit tests batch_sequences_with_states_test.py, which is duplicating the first segment of \"seq1\".\ndef _testBasicPadding(self, pad, key=None, make_keys_unique=False):\n    num_unroll = 2  # Divisor of value_length - so no padding necessary.\n    expected_seq1_batch1 = np.tile(\n        self.sequences[\"seq1\"][np.newaxis, 0:num_unroll, :],\n(self.batch_size, 1, 1))", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nWhen `train.batch_sequences_with_states` extracts batches from a sequence of samples, what it actually does is duplicating the same segment for `batch_size` times.\r\n\r\n### Source code / logs\r\nThe code is revised based on [batch_sequences_with_states_test.py](https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/training/python/training/batch_sequences_with_states_test.py)\r\n\r\n```python\r\nfrom pprint import pprint\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.training.python.training import sequence_queueing_state_saver as sqss\r\n\r\nbatch_size = 3\r\nnum_unroll = 2\r\nlstm_size = 4\r\nvalue_length = 8\r\ninput_key = tf.as_string(tf.cast(10000 * tf.random_uniform(()), tf.int32))\r\ninput_sequences = {'input': np.random.rand(value_length, 3)}\r\ninput_context = {'context_key': [1]}\r\ninitial_states = {\"lstm_state\": np.random.rand(10, lstm_size)}\r\n\r\nwith tf.Session() as sess:\r\n    batch = sqss.batch_sequences_with_states(\r\n        input_key=input_key,\r\n        input_sequences=input_sequences,\r\n        input_context=input_context,\r\n        input_length=value_length,\r\n        initial_states=initial_states,\r\n        num_unroll=num_unroll,\r\n        batch_size=batch_size)\r\n    state = batch.state('lstm_state')\r\n    update_state = batch.save_state('lstm_state', state + 1)\r\n    coord = tf.train.Coordinator()\r\n    tf.train.start_queue_runners(sess=sess, coord=coord)\r\n    input_batch_val = sess.run([\r\n        batch.key, batch.next_key, batch.sequences['input'],\r\n        batch.context['context_key'], state, batch.length, update_state][2])\r\n    pprint(input_batch_val)\r\n```\r\nOutput:\r\n```\r\narray([[[0.33537843, 0.76504494, 0.368679  ],\r\n        [0.47943187, 0.58871135, 0.06263617]],\r\n\r\n       [[0.33537843, 0.76504494, 0.368679  ],\r\n        [0.47943187, 0.58871135, 0.06263617]],\r\n\r\n       [[0.33537843, 0.76504494, 0.368679  ],\r\n        [0.47943187, 0.58871135, 0.06263617]]])\r\n```\r\nWhat further justifies my suspect is the expected values of sequences in unit tests [batch_sequences_with_states_test.py](https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/training/python/training/batch_sequences_with_states_test.py), which is duplicating the first segment of `\"seq1\"`.\r\n```python\r\ndef _testBasicPadding(self, pad, key=None, make_keys_unique=False):\r\n    num_unroll = 2  # Divisor of value_length - so no padding necessary.\r\n    expected_seq1_batch1 = np.tile(\r\n        self.sequences[\"seq1\"][np.newaxis, 0:num_unroll, :],\r\n(self.batch_size, 1, 1))\r\n```"}