{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421087355", "html_url": "https://github.com/tensorflow/tensorflow/issues/19491#issuecomment-421087355", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19491", "id": 421087355, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTA4NzM1NQ==", "user": {"login": "ezhulenev", "id": 1174378, "node_id": "MDQ6VXNlcjExNzQzNzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1174378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezhulenev", "html_url": "https://github.com/ezhulenev", "followers_url": "https://api.github.com/users/ezhulenev/followers", "following_url": "https://api.github.com/users/ezhulenev/following{/other_user}", "gists_url": "https://api.github.com/users/ezhulenev/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezhulenev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezhulenev/subscriptions", "organizations_url": "https://api.github.com/users/ezhulenev/orgs", "repos_url": "https://api.github.com/users/ezhulenev/repos", "events_url": "https://api.github.com/users/ezhulenev/events{/privacy}", "received_events_url": "https://api.github.com/users/ezhulenev/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-13T17:27:48Z", "updated_at": "2018-09-13T17:27:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4223137\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fcacarminati\">@fcacarminati</a> I've submitted couple of changes that should make Conv3D performance much better (I'd expecte something like ~5x). One of them is custom kernels for backprop input and filter: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/e183b8d0328d7398cb6ffc530d1ae8fdbd2111c0/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/e183b8d0328d7398cb6ffc530d1ae8fdbd2111c0\"><tt>e183b8d</tt></a></p>\n<p>These kernels make less smaller allocations, instead they allocate quite large temporary buffers, so you might see increased peak memory usage. It's possible to fallback on original Eigen kernels using <code>kernel_label_map</code> (see <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/tensorflow/tensorflow/blob/8cb0558da924e891aa1bb5d79a6c0c846301e4eb/tensorflow/python/framework/ops.py#L3311\">tensorflow/tensorflow/python/framework/ops.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 3311\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/tensorflow/tensorflow/commit/8cb0558da924e891aa1bb5d79a6c0c846301e4eb\">8cb0558</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L3311\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"3311\"></td>\n          <td id=\"LC3311\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">def</span> <span class=\"pl-en\">_kernel_label_map</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">op_to_kernel_label_map</span>): </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n), old kernels registered with a \"eigen_tensor\" label.</p>\n<p>I'd be super interested to know how much this helps in your specific case.</p>", "body_text": "@fcacarminati I've submitted couple of changes that should make Conv3D performance much better (I'd expecte something like ~5x). One of them is custom kernels for backprop input and filter: e183b8d\nThese kernels make less smaller allocations, instead they allocate quite large temporary buffers, so you might see increased peak memory usage. It's possible to fallback on original Eigen kernels using kernel_label_map (see \n  \n    \n      tensorflow/tensorflow/python/framework/ops.py\n    \n    \n         Line 3311\n      in\n      8cb0558\n    \n    \n    \n    \n\n        \n          \n           def _kernel_label_map(self, op_to_kernel_label_map): \n        \n    \n  \n\n), old kernels registered with a \"eigen_tensor\" label.\nI'd be super interested to know how much this helps in your specific case.", "body": "@fcacarminati I've submitted couple of changes that should make Conv3D performance much better (I'd expecte something like ~5x). One of them is custom kernels for backprop input and filter: https://github.com/tensorflow/tensorflow/commit/e183b8d0328d7398cb6ffc530d1ae8fdbd2111c0\r\n\r\nThese kernels make less smaller allocations, instead they allocate quite large temporary buffers, so you might see increased peak memory usage. It's possible to fallback on original Eigen kernels using `kernel_label_map` (see https://github.com/tensorflow/tensorflow/blob/8cb0558da924e891aa1bb5d79a6c0c846301e4eb/tensorflow/python/framework/ops.py#L3311), old kernels registered with a \"eigen_tensor\" label.\r\n\r\nI'd be super interested to know how much this helps in your specific case."}