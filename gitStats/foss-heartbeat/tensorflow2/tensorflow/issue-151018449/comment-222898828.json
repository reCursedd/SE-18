{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/222898828", "html_url": "https://github.com/tensorflow/tensorflow/pull/2104#issuecomment-222898828", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2104", "id": 222898828, "node_id": "MDEyOklzc3VlQ29tbWVudDIyMjg5ODgyOA==", "user": {"login": "mikowals", "id": 1331470, "node_id": "MDQ6VXNlcjEzMzE0NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1331470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mikowals", "html_url": "https://github.com/mikowals", "followers_url": "https://api.github.com/users/mikowals/followers", "following_url": "https://api.github.com/users/mikowals/following{/other_user}", "gists_url": "https://api.github.com/users/mikowals/gists{/gist_id}", "starred_url": "https://api.github.com/users/mikowals/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mikowals/subscriptions", "organizations_url": "https://api.github.com/users/mikowals/orgs", "repos_url": "https://api.github.com/users/mikowals/repos", "events_url": "https://api.github.com/users/mikowals/events{/privacy}", "received_events_url": "https://api.github.com/users/mikowals/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-01T05:47:52Z", "updated_at": "2016-06-01T05:47:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Since this has yet to be merged I wonder if I should amend to it use the newly added  <code>tf.contrib.layers.batch_norm</code> to avoid duplication.</p>\n<p>I think this could become:</p>\n<pre><code>def batch_normalize(tensor_in,\n       epsilon=1e-5,\n       convnet=False, # this becomes redundant with tensor_in shape\n       decay=0.9,\n       scale_after_normalization=True):\n\n    with vs.variable_scope(\"batch_norm\"):\n        batch_norm = functools.partial(layers.batch_norm, tensor_in,\n              decay=decay,\n              center=True,\n              scale=scale_after_normalization,\n              epsilon=epsilon,\n              updates_collections=None, \n              scope='learn_bn')\n\n        batch_norm_from_moving_averages = functools.partial(batch_norm, \n              is_training=False, reuse=True)\n\n        is_training = array_ops_.squeeze(ops.get_collection(\"IS_TRAINING\"))\n        return control_flow_ops.cond(is_training, batch_norm, batch_norm_from_moving_averages)\n</code></pre>", "body_text": "Since this has yet to be merged I wonder if I should amend to it use the newly added  tf.contrib.layers.batch_norm to avoid duplication.\nI think this could become:\ndef batch_normalize(tensor_in,\n       epsilon=1e-5,\n       convnet=False, # this becomes redundant with tensor_in shape\n       decay=0.9,\n       scale_after_normalization=True):\n\n    with vs.variable_scope(\"batch_norm\"):\n        batch_norm = functools.partial(layers.batch_norm, tensor_in,\n              decay=decay,\n              center=True,\n              scale=scale_after_normalization,\n              epsilon=epsilon,\n              updates_collections=None, \n              scope='learn_bn')\n\n        batch_norm_from_moving_averages = functools.partial(batch_norm, \n              is_training=False, reuse=True)\n\n        is_training = array_ops_.squeeze(ops.get_collection(\"IS_TRAINING\"))\n        return control_flow_ops.cond(is_training, batch_norm, batch_norm_from_moving_averages)", "body": "Since this has yet to be merged I wonder if I should amend to it use the newly added  `tf.contrib.layers.batch_norm` to avoid duplication.\n\nI think this could become:\n\n```\ndef batch_normalize(tensor_in,\n       epsilon=1e-5,\n       convnet=False, # this becomes redundant with tensor_in shape\n       decay=0.9,\n       scale_after_normalization=True):\n\n    with vs.variable_scope(\"batch_norm\"):\n        batch_norm = functools.partial(layers.batch_norm, tensor_in,\n              decay=decay,\n              center=True,\n              scale=scale_after_normalization,\n              epsilon=epsilon,\n              updates_collections=None, \n              scope='learn_bn')\n\n        batch_norm_from_moving_averages = functools.partial(batch_norm, \n              is_training=False, reuse=True)\n\n        is_training = array_ops_.squeeze(ops.get_collection(\"IS_TRAINING\"))\n        return control_flow_ops.cond(is_training, batch_norm, batch_norm_from_moving_averages)\n```\n"}