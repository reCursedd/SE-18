{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12293", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12293/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12293/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12293/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12293", "id": 250279606, "node_id": "MDU6SXNzdWUyNTAyNzk2MDY=", "number": 12293, "title": "tf.nn.avg_pool NaN bug with pool size 7 and stride 1", "user": {"login": "basveeling", "id": 536975, "node_id": "MDQ6VXNlcjUzNjk3NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/536975?v=4", "gravatar_id": "", "url": "https://api.github.com/users/basveeling", "html_url": "https://github.com/basveeling", "followers_url": "https://api.github.com/users/basveeling/followers", "following_url": "https://api.github.com/users/basveeling/following{/other_user}", "gists_url": "https://api.github.com/users/basveeling/gists{/gist_id}", "starred_url": "https://api.github.com/users/basveeling/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/basveeling/subscriptions", "organizations_url": "https://api.github.com/users/basveeling/orgs", "repos_url": "https://api.github.com/users/basveeling/repos", "events_url": "https://api.github.com/users/basveeling/events{/privacy}", "received_events_url": "https://api.github.com/users/basveeling/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mjanusz", "id": 328443, "node_id": "MDQ6VXNlcjMyODQ0Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/328443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjanusz", "html_url": "https://github.com/mjanusz", "followers_url": "https://api.github.com/users/mjanusz/followers", "following_url": "https://api.github.com/users/mjanusz/following{/other_user}", "gists_url": "https://api.github.com/users/mjanusz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjanusz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjanusz/subscriptions", "organizations_url": "https://api.github.com/users/mjanusz/orgs", "repos_url": "https://api.github.com/users/mjanusz/repos", "events_url": "https://api.github.com/users/mjanusz/events{/privacy}", "received_events_url": "https://api.github.com/users/mjanusz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mjanusz", "id": 328443, "node_id": "MDQ6VXNlcjMyODQ0Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/328443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjanusz", "html_url": "https://github.com/mjanusz", "followers_url": "https://api.github.com/users/mjanusz/followers", "following_url": "https://api.github.com/users/mjanusz/following{/other_user}", "gists_url": "https://api.github.com/users/mjanusz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjanusz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjanusz/subscriptions", "organizations_url": "https://api.github.com/users/mjanusz/orgs", "repos_url": "https://api.github.com/users/mjanusz/repos", "events_url": "https://api.github.com/users/mjanusz/events{/privacy}", "received_events_url": "https://api.github.com/users/mjanusz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2017-08-15T10:36:34Z", "updated_at": "2018-11-18T02:16:52Z", "closed_at": "2018-11-18T02:16:52Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip install tensorflow-gpu</li>\n<li><strong>TensorFlow version (use command below)</strong>:  1.2.1</li>\n<li><strong>Python version</strong>: Python 3.6.1 :: Anaconda custom (64-bit)</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0 / libcudnn.so.5.1.10</li>\n<li><strong>GPU model and memory</strong>: titan x (pascal) 12gb</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When performing tf.nn.avg_pool over a large binary image, containing a few small blobs (diameter ~ 100px), I get NaN errors and all-zero outputs depending on stride and poolsize option. I've added a test script below, which results in the following output on my setup. The results for strides 1 and pool &gt;= 7 are incorrect:</p>\n<pre><code>strides (1, 1, 1, 1)\nPool: 5 len where: 7955\nmin: 0.0 max: 1.0\nPool: 6 len where: 7997\nmin: 0.0 max: 1.0\nPool: 7 len where: 0\nmin: 0.0 max: 0.0\nPool: 8 len where: 0\nmin: 0.0 max: 0.0\nPool: 9 len where: 49939008\nmin: nan max: nan\nPool: 10 len where: 33141389\nmin: nan max: nan\n\nstrides (1, 2, 2, 1)\nPool: 5 len where: 12045\nmin: 0.0 max: 1.0\nPool: 6 len where: 12584\nmin: 0.0 max: 1.0\nPool: 7 len where: 13093\nmin: 0.0 max: 1.0\nPool: 8 len where: 13608\nmin: 0.0 max: 1.0\nPool: 9 len where: 10588\nmin: 0.0 max: 1.0\nPool: 10 len where: 2707\nmin: 0.0 max: 1.0\n</code></pre>\n<h3>Source code / logs</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nmaps <span class=\"pl-k\">=</span> np.load(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/test.npy<span class=\"pl-pds\">'</span></span>)\nin_shape <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">4096</span>, <span class=\"pl-c1\">4096</span>, <span class=\"pl-c1\">2</span>)\npadding <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>\nsess <span class=\"pl-k\">=</span> tf.Session()\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>, in_shape)\n\n<span class=\"pl-k\">for</span> strides <span class=\"pl-k\">in</span> [(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>)]:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>strides<span class=\"pl-pds\">'</span></span>, strides)\n    <span class=\"pl-k\">for</span> pool <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">11</span>):\n        pool_size <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">1</span>, pool, pool, <span class=\"pl-c1\">1</span>)\n        x <span class=\"pl-k\">=</span> tf.nn.avg_pool(<span class=\"pl-c1\">input</span>, pool_size, strides, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span>padding)\n        pooled_maps <span class=\"pl-k\">=</span> sess.run(x, {<span class=\"pl-c1\">input</span>: maps.astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)})\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Pool:<span class=\"pl-pds\">'</span></span>, pool, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>len where:<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">len</span>(np.where(pooled_maps[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">0</span>)[<span class=\"pl-c1\">0</span>]))\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>min:<span class=\"pl-pds\">'</span></span>, pooled_maps[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">1</span>].min(), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>max:<span class=\"pl-pds\">'</span></span>, pooled_maps[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">1</span>].max())</pre></div>\n<p>maps is too large to upload for me, but can be replaced with <code>maps = np.random.binomial(1, 0.0000001, in_shape)</code> to reproduce the NaNs for pool &gt;= 8</p>\n<pre><code>\n== cat /etc/issue ===============================================\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nnumpydoc (0.6.0)\nprotobuf (3.3.0)\ntensorflow-gpu (1.2.1)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /home/basv/.local/lib/cuda:/usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nTue Aug 15 11:50:59 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\n|  0%   44C    P0    58W / 250W |      0MiB / 12189MiB |      2%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): pip install tensorflow-gpu\nTensorFlow version (use command below):  1.2.1\nPython version: Python 3.6.1 :: Anaconda custom (64-bit)\nBazel version (if compiling from source):\nCUDA/cuDNN version: 8.0 / libcudnn.so.5.1.10\nGPU model and memory: titan x (pascal) 12gb\nExact command to reproduce:\n\nDescribe the problem\nWhen performing tf.nn.avg_pool over a large binary image, containing a few small blobs (diameter ~ 100px), I get NaN errors and all-zero outputs depending on stride and poolsize option. I've added a test script below, which results in the following output on my setup. The results for strides 1 and pool >= 7 are incorrect:\nstrides (1, 1, 1, 1)\nPool: 5 len where: 7955\nmin: 0.0 max: 1.0\nPool: 6 len where: 7997\nmin: 0.0 max: 1.0\nPool: 7 len where: 0\nmin: 0.0 max: 0.0\nPool: 8 len where: 0\nmin: 0.0 max: 0.0\nPool: 9 len where: 49939008\nmin: nan max: nan\nPool: 10 len where: 33141389\nmin: nan max: nan\n\nstrides (1, 2, 2, 1)\nPool: 5 len where: 12045\nmin: 0.0 max: 1.0\nPool: 6 len where: 12584\nmin: 0.0 max: 1.0\nPool: 7 len where: 13093\nmin: 0.0 max: 1.0\nPool: 8 len where: 13608\nmin: 0.0 max: 1.0\nPool: 9 len where: 10588\nmin: 0.0 max: 1.0\nPool: 10 len where: 2707\nmin: 0.0 max: 1.0\n\nSource code / logs\nimport numpy as np\nimport tensorflow as tf\n\nmaps = np.load('/tmp/test.npy')\nin_shape = (9, 4096, 4096, 2)\npadding = 'VALID'\nsess = tf.Session()\ninput = tf.placeholder('float32', in_shape)\n\nfor strides in [(1, 1, 1, 1), (1, 2, 2, 1)]:\n    print('strides', strides)\n    for pool in range(5, 11):\n        pool_size = (1, pool, pool, 1)\n        x = tf.nn.avg_pool(input, pool_size, strides, padding=padding)\n        pooled_maps = sess.run(x, {input: maps.astype('float32')})\n        print('Pool:', pool, 'len where:', len(np.where(pooled_maps[..., 1] != 0)[0]))\n        print('min:', pooled_maps[..., 1].min(), 'max:', pooled_maps[..., 1].max())\nmaps is too large to upload for me, but can be replaced with maps = np.random.binomial(1, 0.0000001, in_shape) to reproduce the NaNs for pool >= 8\n\n== cat /etc/issue ===============================================\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.1)\nnumpydoc (0.6.0)\nprotobuf (3.3.0)\ntensorflow-gpu (1.2.1)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH /home/basv/.local/lib/cuda:/usr/local/cuda-8.0/lib64:\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nTue Aug 15 11:50:59 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\n|  0%   44C    P0    58W / 250W |      0MiB / 12189MiB |      2%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**:  1.2.1\r\n- **Python version**: Python 3.6.1 :: Anaconda custom (64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0 / libcudnn.so.5.1.10\r\n- **GPU model and memory**: titan x (pascal) 12gb\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\nWhen performing tf.nn.avg_pool over a large binary image, containing a few small blobs (diameter ~ 100px), I get NaN errors and all-zero outputs depending on stride and poolsize option. I've added a test script below, which results in the following output on my setup. The results for strides 1 and pool >= 7 are incorrect:\r\n\r\n```\r\nstrides (1, 1, 1, 1)\r\nPool: 5 len where: 7955\r\nmin: 0.0 max: 1.0\r\nPool: 6 len where: 7997\r\nmin: 0.0 max: 1.0\r\nPool: 7 len where: 0\r\nmin: 0.0 max: 0.0\r\nPool: 8 len where: 0\r\nmin: 0.0 max: 0.0\r\nPool: 9 len where: 49939008\r\nmin: nan max: nan\r\nPool: 10 len where: 33141389\r\nmin: nan max: nan\r\n\r\nstrides (1, 2, 2, 1)\r\nPool: 5 len where: 12045\r\nmin: 0.0 max: 1.0\r\nPool: 6 len where: 12584\r\nmin: 0.0 max: 1.0\r\nPool: 7 len where: 13093\r\nmin: 0.0 max: 1.0\r\nPool: 8 len where: 13608\r\nmin: 0.0 max: 1.0\r\nPool: 9 len where: 10588\r\nmin: 0.0 max: 1.0\r\nPool: 10 len where: 2707\r\nmin: 0.0 max: 1.0\r\n```\r\n\r\n### Source code / logs\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nmaps = np.load('/tmp/test.npy')\r\nin_shape = (9, 4096, 4096, 2)\r\npadding = 'VALID'\r\nsess = tf.Session()\r\ninput = tf.placeholder('float32', in_shape)\r\n\r\nfor strides in [(1, 1, 1, 1), (1, 2, 2, 1)]:\r\n    print('strides', strides)\r\n    for pool in range(5, 11):\r\n        pool_size = (1, pool, pool, 1)\r\n        x = tf.nn.avg_pool(input, pool_size, strides, padding=padding)\r\n        pooled_maps = sess.run(x, {input: maps.astype('float32')})\r\n        print('Pool:', pool, 'len where:', len(np.where(pooled_maps[..., 1] != 0)[0]))\r\n        print('min:', pooled_maps[..., 1].min(), 'max:', pooled_maps[..., 1].max())\r\n```\r\n\r\nmaps is too large to upload for me, but can be replaced with `maps = np.random.binomial(1, 0.0000001, in_shape)` to reproduce the NaNs for pool >= 8 \r\n\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.3.0)\r\ntensorflow-gpu (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /home/basv/.local/lib/cuda:/usr/local/cuda-8.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Aug 15 11:50:59 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\r\n|  0%   44C    P0    58W / 250W |      0MiB / 12189MiB |      2%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n```"}