{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/338420379", "html_url": "https://github.com/tensorflow/tensorflow/issues/7669#issuecomment-338420379", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7669", "id": 338420379, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODQyMDM3OQ==", "user": {"login": "lelugom", "id": 20136420, "node_id": "MDQ6VXNlcjIwMTM2NDIw", "avatar_url": "https://avatars3.githubusercontent.com/u/20136420?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lelugom", "html_url": "https://github.com/lelugom", "followers_url": "https://api.github.com/users/lelugom/followers", "following_url": "https://api.github.com/users/lelugom/following{/other_user}", "gists_url": "https://api.github.com/users/lelugom/gists{/gist_id}", "starred_url": "https://api.github.com/users/lelugom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lelugom/subscriptions", "organizations_url": "https://api.github.com/users/lelugom/orgs", "repos_url": "https://api.github.com/users/lelugom/repos", "events_url": "https://api.github.com/users/lelugom/events{/privacy}", "received_events_url": "https://api.github.com/users/lelugom/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-21T17:50:54Z", "updated_at": "2017-10-22T16:45:38Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17916698\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Moymix\">@Moymix</a> you can implement early stopping by using the <code>continuous_eval_predicate_fn</code>, available in <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment\" rel=\"nofollow\">tf.contrib.learn.Experiment.continuous_eval_on_train_data</a>. For instance, let's take a batch size of 10 and early stop count of 15.  Modifying the example at <a href=\"https://www.tensorflow.org/tutorials/layers\" rel=\"nofollow\">TF Layers tutorial</a> for a bigger dataset, the code would look like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">BATCH_SIZE</span>  <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n<span class=\"pl-c1\">EARLY_STOP_COUNT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">15</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Model function</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span>\n  eval_metric_ops <span class=\"pl-k\">=</span> { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>accuracy<span class=\"pl-pds\">\"</span></span>  : accuracy}\n  <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(\n      <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span>mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">eval_metric_ops</span><span class=\"pl-k\">=</span>eval_metric_ops)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Early stopping function</span>\naccuracy_reg <span class=\"pl-k\">=</span> np.zeros(<span class=\"pl-c1\">EARLY_STOP_COUNT</span>)\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">early_stopping</span>(<span class=\"pl-smi\">eval_results</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> None argument for the first evaluation</span>\n  <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> eval_results: \n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">True</span>\n  \n  accuracy_reg[<span class=\"pl-c1\">0</span> : <span class=\"pl-c1\">EARLY_STOP_COUNT</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> accuracy_reg[<span class=\"pl-c1\">1</span> : <span class=\"pl-c1\">EARLY_STOP_COUNT</span>]\n  accuracy_reg[<span class=\"pl-c1\">EARLY_STOP_COUNT</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> eval_results[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>accuracy<span class=\"pl-pds\">\"</span></span>]\n  counts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n  <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">EARLY_STOP_COUNT</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>):\n    <span class=\"pl-k\">if</span> accuracy_reg[i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">&lt;=</span> accuracy_reg[i]:\n      counts <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n  <span class=\"pl-k\">if</span> counts <span class=\"pl-k\">==</span> <span class=\"pl-c1\">EARLY_STOP_COUNT</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\n</span>Early stopping: <span class=\"pl-c1\">%s</span> <span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> accuracy_reg)\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">False</span>\n    \n  <span class=\"pl-k\">return</span> <span class=\"pl-c1\">True</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Main function</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">unused_argv</span>):\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span>...</span>\n  estimator <span class=\"pl-k\">=</span> tf.estimator.Estimator(\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span>...</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Train the model </span>\n  <span class=\"pl-v\">train_input_fn</span> <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n    <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data<span class=\"pl-pds\">\"</span></span>: train_data},\n    <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>train_labels,\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">BATCH_SIZE</span>,\n    <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-c\"><span class=\"pl-c\">#</span> Continue until training steps are finished</span>\n    <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n    )\n  <span class=\"pl-v\">eval_input_fn</span> <span class=\"pl-k\">=</span> tf.estimator.inputs.numpy_input_fn(\n    <span class=\"pl-v\">x</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>data<span class=\"pl-pds\">\"</span></span>: validate_data},\n    <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>validate_labels,\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">BATCH_SIZE</span>,\n    <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, \n    <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>\n    )\n  <span class=\"pl-v\">experiment</span> <span class=\"pl-k\">=</span> tf.contrib.learn.Experiment(\n    <span class=\"pl-v\">estimator</span><span class=\"pl-k\">=</span>estimator,\n    <span class=\"pl-v\">train_input_fn</span><span class=\"pl-k\">=</span>train_input_fn,\n    <span class=\"pl-v\">eval_input_fn</span><span class=\"pl-k\">=</span>eval_input_fn,\n    <span class=\"pl-v\">train_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">80000</span>,\n    <span class=\"pl-v\">eval_steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-c\"><span class=\"pl-c\">#</span> evaluate runs until input is exhausted</span>\n    <span class=\"pl-v\">eval_delay_secs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">180</span>, \n    <span class=\"pl-v\">train_steps_per_iteration</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>\n    )\n  experiment.continuous_train_and_eval(\n    <span class=\"pl-v\">continuous_eval_predicate_fn</span><span class=\"pl-k\">=</span>early_stopping)  \n  \n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>However, have in mind that <code>continuous_eval_predicate_fn</code> is an experimental function, so it could change at any moment.</p>", "body_text": "@Moymix you can implement early stopping by using the continuous_eval_predicate_fn, available in tf.contrib.learn.Experiment.continuous_eval_on_train_data. For instance, let's take a batch size of 10 and early stop count of 15.  Modifying the example at TF Layers tutorial for a bigger dataset, the code would look like this:\nBATCH_SIZE  = 10\nEARLY_STOP_COUNT = 15\n\n# Model function\ndef model_fn(features, labels, mode):\n  # ...\n  eval_metric_ops = { \"accuracy\"  : accuracy}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n# Early stopping function\naccuracy_reg = np.zeros(EARLY_STOP_COUNT)\ndef early_stopping(eval_results):\n  # None argument for the first evaluation\n  if not eval_results: \n    return True\n  \n  accuracy_reg[0 : EARLY_STOP_COUNT - 1] = accuracy_reg[1 : EARLY_STOP_COUNT]\n  accuracy_reg[EARLY_STOP_COUNT - 1] = eval_results[\"accuracy\"]\n  counts = 0\n  for i in range(0, EARLY_STOP_COUNT - 1):\n    if accuracy_reg[i + 1] <= accuracy_reg[i]:\n      counts += 1\n  if counts == EARLY_STOP_COUNT - 1:\n    print(\"\\nEarly stopping: %s \\n\" % accuracy_reg)\n    return False\n    \n  return True\n\n# Main function\ndef main(unused_argv):\n  #...\n  estimator = tf.estimator.Estimator(\n  #...\n  # Train the model \n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"data\": train_data},\n    y=train_labels,\n    batch_size=BATCH_SIZE,\n    num_epochs=None, # Continue until training steps are finished\n    shuffle=True\n    )\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"data\": validate_data},\n    y=validate_labels,\n    batch_size=BATCH_SIZE,\n    num_epochs=1, \n    shuffle=False\n    )\n  experiment = tf.contrib.learn.Experiment(\n    estimator=estimator,\n    train_input_fn=train_input_fn,\n    eval_input_fn=eval_input_fn,\n    train_steps=80000,\n    eval_steps=None, # evaluate runs until input is exhausted\n    eval_delay_secs=180, \n    train_steps_per_iteration=1000\n    )\n  experiment.continuous_train_and_eval(\n    continuous_eval_predicate_fn=early_stopping)  \n  \n  # ...\nHowever, have in mind that continuous_eval_predicate_fn is an experimental function, so it could change at any moment.", "body": "@Moymix you can implement early stopping by using the `continuous_eval_predicate_fn`, available in [tf.contrib.learn.Experiment.continuous_eval_on_train_data](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment). For instance, let's take a batch size of 10 and early stop count of 15.  Modifying the example at [TF Layers tutorial](https://www.tensorflow.org/tutorials/layers) for a bigger dataset, the code would look like this:\r\n\r\n```python\r\nBATCH_SIZE  = 10\r\nEARLY_STOP_COUNT = 15\r\n\r\n# Model function\r\ndef model_fn(features, labels, mode):\r\n  # ...\r\n  eval_metric_ops = { \"accuracy\"  : accuracy}\r\n  return tf.estimator.EstimatorSpec(\r\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n# Early stopping function\r\naccuracy_reg = np.zeros(EARLY_STOP_COUNT)\r\ndef early_stopping(eval_results):\r\n  # None argument for the first evaluation\r\n  if not eval_results: \r\n    return True\r\n  \r\n  accuracy_reg[0 : EARLY_STOP_COUNT - 1] = accuracy_reg[1 : EARLY_STOP_COUNT]\r\n  accuracy_reg[EARLY_STOP_COUNT - 1] = eval_results[\"accuracy\"]\r\n  counts = 0\r\n  for i in range(0, EARLY_STOP_COUNT - 1):\r\n    if accuracy_reg[i + 1] <= accuracy_reg[i]:\r\n      counts += 1\r\n  if counts == EARLY_STOP_COUNT - 1:\r\n    print(\"\\nEarly stopping: %s \\n\" % accuracy_reg)\r\n    return False\r\n    \r\n  return True\r\n\r\n# Main function\r\ndef main(unused_argv):\r\n  #...\r\n  estimator = tf.estimator.Estimator(\r\n  #...\r\n  # Train the model \r\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"data\": train_data},\r\n    y=train_labels,\r\n    batch_size=BATCH_SIZE,\r\n    num_epochs=None, # Continue until training steps are finished\r\n    shuffle=True\r\n    )\r\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"data\": validate_data},\r\n    y=validate_labels,\r\n    batch_size=BATCH_SIZE,\r\n    num_epochs=1, \r\n    shuffle=False\r\n    )\r\n  experiment = tf.contrib.learn.Experiment(\r\n    estimator=estimator,\r\n    train_input_fn=train_input_fn,\r\n    eval_input_fn=eval_input_fn,\r\n    train_steps=80000,\r\n    eval_steps=None, # evaluate runs until input is exhausted\r\n    eval_delay_secs=180, \r\n    train_steps_per_iteration=1000\r\n    )\r\n  experiment.continuous_train_and_eval(\r\n    continuous_eval_predicate_fn=early_stopping)  \r\n  \r\n  # ...\r\n```\r\nHowever, have in mind that `continuous_eval_predicate_fn` is an experimental function, so it could change at any moment."}