{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/398925542", "html_url": "https://github.com/tensorflow/tensorflow/issues/2431#issuecomment-398925542", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2431", "id": 398925542, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODkyNTU0Mg==", "user": {"login": "Hoeze", "id": 1200058, "node_id": "MDQ6VXNlcjEyMDAwNTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1200058?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hoeze", "html_url": "https://github.com/Hoeze", "followers_url": "https://api.github.com/users/Hoeze/followers", "following_url": "https://api.github.com/users/Hoeze/following{/other_user}", "gists_url": "https://api.github.com/users/Hoeze/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hoeze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hoeze/subscriptions", "organizations_url": "https://api.github.com/users/Hoeze/orgs", "repos_url": "https://api.github.com/users/Hoeze/repos", "events_url": "https://api.github.com/users/Hoeze/events{/privacy}", "received_events_url": "https://api.github.com/users/Hoeze/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-20T23:08:52Z", "updated_at": "2018-06-20T23:10:54Z", "author_association": "NONE", "body_html": "<p>Hey, I'd like to calculate a matrix multiplication with one sample tensor which does not fit into memory.<br>\nNow I thought about batching the samples and summing up the results.</p>\n<p>In OpenMP this would be a simple omp parallel reduction.<br>\nIn Tensorflow, it is a rather big bunch of code to write a dedicated input pipeline, create a while loop, assign-adding the values, ...<br>\nAlso, the user has to decide how big the batches are allowed to be.</p>\n<p>Have there been any updates on simplifying this?<br>\nI'd love something like a map-reduce option which would automatically decide which batch size it can use.</p>", "body_text": "Hey, I'd like to calculate a matrix multiplication with one sample tensor which does not fit into memory.\nNow I thought about batching the samples and summing up the results.\nIn OpenMP this would be a simple omp parallel reduction.\nIn Tensorflow, it is a rather big bunch of code to write a dedicated input pipeline, create a while loop, assign-adding the values, ...\nAlso, the user has to decide how big the batches are allowed to be.\nHave there been any updates on simplifying this?\nI'd love something like a map-reduce option which would automatically decide which batch size it can use.", "body": "Hey, I'd like to calculate a matrix multiplication with one sample tensor which does not fit into memory.\r\nNow I thought about batching the samples and summing up the results.\r\n\r\nIn OpenMP this would be a simple omp parallel reduction.\r\nIn Tensorflow, it is a rather big bunch of code to write a dedicated input pipeline, create a while loop, assign-adding the values, ...\r\nAlso, the user has to decide how big the batches are allowed to be.\r\n\r\nHave there been any updates on simplifying this?\r\nI'd love something like a map-reduce option which would automatically decide which batch size it can use."}