{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345497294", "html_url": "https://github.com/tensorflow/tensorflow/issues/14641#issuecomment-345497294", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14641", "id": 345497294, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTQ5NzI5NA==", "user": {"login": "qmick", "id": 6958746, "node_id": "MDQ6VXNlcjY5NTg3NDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6958746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qmick", "html_url": "https://github.com/qmick", "followers_url": "https://api.github.com/users/qmick/followers", "following_url": "https://api.github.com/users/qmick/following{/other_user}", "gists_url": "https://api.github.com/users/qmick/gists{/gist_id}", "starred_url": "https://api.github.com/users/qmick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qmick/subscriptions", "organizations_url": "https://api.github.com/users/qmick/orgs", "repos_url": "https://api.github.com/users/qmick/repos", "events_url": "https://api.github.com/users/qmick/events{/privacy}", "received_events_url": "https://api.github.com/users/qmick/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-19T07:17:34Z", "updated_at": "2017-11-19T07:17:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You can try this. It computes the hessian matrix for softmax cross entropy. Though it may be not efficient enough.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ntfe.enable_eager_execution()\n\nlogits <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">0.5</span>]\ny <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>]\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">loss_function</span>(<span class=\"pl-k\">*</span><span class=\"pl-smi\">x</span>):\n    loss2 <span class=\"pl-k\">=</span> tf.nn.softmax_cross_entropy_with_logits_v2(<span class=\"pl-v\">labels</span><span class=\"pl-k\">=</span>y, <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>x)\n    <span class=\"pl-k\">return</span> loss2\n\ngrad_loss <span class=\"pl-k\">=</span> tfe.gradients_function(loss_function)\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(logits)):\n    <span class=\"pl-c1\">print</span>(tfe.gradients_function(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: grad_loss(<span class=\"pl-k\">*</span>x)[i])(logits))</pre></div>", "body_text": "You can try this. It computes the hessian matrix for softmax cross entropy. Though it may be not efficient enough.\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport numpy as np\n\ntfe.enable_eager_execution()\n\nlogits = [0.5, 0.5]\ny = [1, 0]\n\ndef loss_function(*x):\n    loss2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=x)\n    return loss2\n\ngrad_loss = tfe.gradients_function(loss_function)\nfor i in range(len(logits)):\n    print(tfe.gradients_function(lambda x: grad_loss(*x)[i])(logits))", "body": "You can try this. It computes the hessian matrix for softmax cross entropy. Though it may be not efficient enough.\r\n```Python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport numpy as np\r\n\r\ntfe.enable_eager_execution()\r\n\r\nlogits = [0.5, 0.5]\r\ny = [1, 0]\r\n\r\ndef loss_function(*x):\r\n    loss2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=x)\r\n    return loss2\r\n\r\ngrad_loss = tfe.gradients_function(loss_function)\r\nfor i in range(len(logits)):\r\n    print(tfe.gradients_function(lambda x: grad_loss(*x)[i])(logits))\r\n```"}