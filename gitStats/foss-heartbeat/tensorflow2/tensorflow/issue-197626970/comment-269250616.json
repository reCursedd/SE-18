{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/269250616", "html_url": "https://github.com/tensorflow/tensorflow/issues/6508#issuecomment-269250616", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6508", "id": 269250616, "node_id": "MDEyOklzc3VlQ29tbWVudDI2OTI1MDYxNg==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-27T00:08:37Z", "updated_at": "2016-12-27T00:13:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>How many PS tasks do you have? I would first check CPU utilization/network utilization of PS to make sure you have enough capacity to keep up with the workers. IE, suppose each worker can do a single batch in 2 seconds. With 25M parameters that's 50MB per second per worker both receive and send, so on a shared cloud one might use 10 PS tasks for 32 workers and 20 PS tasks for 64 workers to keep each PS task communication load around 2.5Gbps</p>\n<p>More generally, you can use Heap Checker from google profiling tools to get a break-down of what is taking up all the memory</p>", "body_text": "How many PS tasks do you have? I would first check CPU utilization/network utilization of PS to make sure you have enough capacity to keep up with the workers. IE, suppose each worker can do a single batch in 2 seconds. With 25M parameters that's 50MB per second per worker both receive and send, so on a shared cloud one might use 10 PS tasks for 32 workers and 20 PS tasks for 64 workers to keep each PS task communication load around 2.5Gbps\nMore generally, you can use Heap Checker from google profiling tools to get a break-down of what is taking up all the memory", "body": "How many PS tasks do you have? I would first check CPU utilization/network utilization of PS to make sure you have enough capacity to keep up with the workers. IE, suppose each worker can do a single batch in 2 seconds. With 25M parameters that's 50MB per second per worker both receive and send, so on a shared cloud one might use 10 PS tasks for 32 workers and 20 PS tasks for 64 workers to keep each PS task communication load around 2.5Gbps\r\n\r\nMore generally, you can use Heap Checker from google profiling tools to get a break-down of what is taking up all the memory"}