{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14509", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14509/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14509/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14509/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14509", "id": 273315585, "node_id": "MDU6SXNzdWUyNzMzMTU1ODU=", "number": 14509, "title": "Function for explicit broadcasting", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-11-13T05:36:12Z", "updated_at": "2018-04-16T02:22:39Z", "closed_at": "2018-04-16T02:22:39Z", "author_association": "MEMBER", "body_html": "<p>It would be convenient to have an explicit function for broadcasting in TensorFlow's Python API, like to <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.broadcast_to.html\" rel=\"nofollow\"><code>numpy.broadcast_to</code></a> or XLA's <a href=\"https://www.tensorflow.org/performance/xla/operation_semantics#broadcast\" rel=\"nofollow\">Broadcast</a>, and as <a href=\"https://stackoverflow.com/questions/34362193/how-to-explicitly-broadcast-a-tensor-to-match-anothers-shape-in-tensorflow\" rel=\"nofollow\">requested on StackOverFlow</a>. This would facilitate adding broadcasting-like behavior to the many TensorFlow operations that don't support it out of the box.</p>\n<p>I understand that in general TensorFlow does not implement NumPy's the strided N-dimensional array data model, so unlike the case for NumPy, broadcasting (e.g., with Eigen tensors) can require a copy. This is a good reason to not necessarily build such a version of broadcasting into ops. However, explicit broadcasting rather than using tile/expand_dims can still be very convenient.</p>", "body_text": "It would be convenient to have an explicit function for broadcasting in TensorFlow's Python API, like to numpy.broadcast_to or XLA's Broadcast, and as requested on StackOverFlow. This would facilitate adding broadcasting-like behavior to the many TensorFlow operations that don't support it out of the box.\nI understand that in general TensorFlow does not implement NumPy's the strided N-dimensional array data model, so unlike the case for NumPy, broadcasting (e.g., with Eigen tensors) can require a copy. This is a good reason to not necessarily build such a version of broadcasting into ops. However, explicit broadcasting rather than using tile/expand_dims can still be very convenient.", "body": "It would be convenient to have an explicit function for broadcasting in TensorFlow's Python API, like to [`numpy.broadcast_to`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.broadcast_to.html) or XLA's [Broadcast](https://www.tensorflow.org/performance/xla/operation_semantics#broadcast), and as [requested on StackOverFlow](https://stackoverflow.com/questions/34362193/how-to-explicitly-broadcast-a-tensor-to-match-anothers-shape-in-tensorflow). This would facilitate adding broadcasting-like behavior to the many TensorFlow operations that don't support it out of the box.\r\n\r\nI understand that in general TensorFlow does not implement NumPy's the strided N-dimensional array data model, so unlike the case for NumPy, broadcasting (e.g., with Eigen tensors) can require a copy. This is a good reason to not necessarily build such a version of broadcasting into ops. However, explicit broadcasting rather than using tile/expand_dims can still be very convenient.\r\n"}