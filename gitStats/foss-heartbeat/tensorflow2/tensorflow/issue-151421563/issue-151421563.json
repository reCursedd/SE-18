{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2131", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2131/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2131/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2131/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2131", "id": 151421563, "node_id": "MDU6SXNzdWUxNTE0MjE1NjM=", "number": 2131, "title": "control_dependencies of ExponentialMovingAverage in cifar10_multi_gpu_train.py", "user": {"login": "c149028", "id": 18388769, "node_id": "MDQ6VXNlcjE4Mzg4NzY5", "avatar_url": "https://avatars2.githubusercontent.com/u/18388769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c149028", "html_url": "https://github.com/c149028", "followers_url": "https://api.github.com/users/c149028/followers", "following_url": "https://api.github.com/users/c149028/following{/other_user}", "gists_url": "https://api.github.com/users/c149028/gists{/gist_id}", "starred_url": "https://api.github.com/users/c149028/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c149028/subscriptions", "organizations_url": "https://api.github.com/users/c149028/orgs", "repos_url": "https://api.github.com/users/c149028/repos", "events_url": "https://api.github.com/users/c149028/events{/privacy}", "received_events_url": "https://api.github.com/users/c149028/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sherrym", "id": 12770037, "node_id": "MDQ6VXNlcjEyNzcwMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/12770037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sherrym", "html_url": "https://github.com/sherrym", "followers_url": "https://api.github.com/users/sherrym/followers", "following_url": "https://api.github.com/users/sherrym/following{/other_user}", "gists_url": "https://api.github.com/users/sherrym/gists{/gist_id}", "starred_url": "https://api.github.com/users/sherrym/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sherrym/subscriptions", "organizations_url": "https://api.github.com/users/sherrym/orgs", "repos_url": "https://api.github.com/users/sherrym/repos", "events_url": "https://api.github.com/users/sherrym/events{/privacy}", "received_events_url": "https://api.github.com/users/sherrym/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2016-04-27T15:53:11Z", "updated_at": "2016-06-08T16:43:41Z", "closed_at": "2016-06-08T16:43:41Z", "author_association": "NONE", "body_html": "<p>There are two ExponentialMovingAverage in cifar10_multi_gpu_train.py.</p>\n<ul>\n<li>For model parameters <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L220\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L220</a><br>\nShould the <code>apply</code> operation of ExponentialMovingAverage be called after the update of parameters?</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> tf.control_dependencies([apply_gradient_op]):\n    train_op <span class=\"pl-k\">=</span> variable_averages.apply(tf.trainable_variables())</pre></div>\n<ul>\n<li>For loss<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L105-L106\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L105-L106</a><br>\nAre these two lines redundant? Loss value won't change within a single run.</li>\n</ul>\n<p>P.S. The document of ExponentialMovingAverage (<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py#L172-L177\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py#L172-L177</a>) says</p>\n<blockquote>\n<div class=\"highlight highlight-source-python\"><pre>maintain_averages_op <span class=\"pl-k\">=</span> ema.apply([var0, var1])\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create an op that will update the moving averages after each training</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> step.  This is what we will use in place of the usual training op.</span>\n<span class=\"pl-k\">with</span> tf.control_dependencies([opt_op]):\n    training_op <span class=\"pl-k\">=</span> tf.group(maintain_averages_op)<span class=\"pl-bu\">```</span></pre></div>\n</blockquote>\n<p>If we want to update the moving averages after the training step, should we call <code>ema.apply</code> within the context of tf.control_dependencies([opt_op])?</p>", "body_text": "There are two ExponentialMovingAverage in cifar10_multi_gpu_train.py.\n\nFor model parameters https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L220\nShould the apply operation of ExponentialMovingAverage be called after the update of parameters?\n\nwith tf.control_dependencies([apply_gradient_op]):\n    train_op = variable_averages.apply(tf.trainable_variables())\n\nFor loss\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L105-L106\nAre these two lines redundant? Loss value won't change within a single run.\n\nP.S. The document of ExponentialMovingAverage (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py#L172-L177) says\n\nmaintain_averages_op = ema.apply([var0, var1])\n  # Create an op that will update the moving averages after each training\n  # step.  This is what we will use in place of the usual training op.\nwith tf.control_dependencies([opt_op]):\n    training_op = tf.group(maintain_averages_op)```\n\nIf we want to update the moving averages after the training step, should we call ema.apply within the context of tf.control_dependencies([opt_op])?", "body": "There are two ExponentialMovingAverage in cifar10_multi_gpu_train.py.  \n- For model parameters https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L220  \n  Should the `apply` operation of ExponentialMovingAverage be called after the update of parameters? \n\n``` python\nwith tf.control_dependencies([apply_gradient_op]):\n    train_op = variable_averages.apply(tf.trainable_variables())\n```\n- For loss\n  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L105-L106  \n  Are these two lines redundant? Loss value won't change within a single run.\n\nP.S. The document of ExponentialMovingAverage (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py#L172-L177) says\n\n> `````` python\n> maintain_averages_op = ema.apply([var0, var1])\n>   # Create an op that will update the moving averages after each training\n>   # step.  This is what we will use in place of the usual training op.\n> with tf.control_dependencies([opt_op]):\n>     training_op = tf.group(maintain_averages_op)```\n> ``````\n\nIf we want to update the moving averages after the training step, should we call `ema.apply` within the context of tf.control_dependencies([opt_op])?\n"}