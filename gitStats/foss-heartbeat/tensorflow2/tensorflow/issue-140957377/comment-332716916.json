{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/332716916", "html_url": "https://github.com/tensorflow/tensorflow/issues/1511#issuecomment-332716916", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1511", "id": 332716916, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjcxNjkxNg==", "user": {"login": "LaiPiXiong", "id": 15033269, "node_id": "MDQ6VXNlcjE1MDMzMjY5", "avatar_url": "https://avatars2.githubusercontent.com/u/15033269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LaiPiXiong", "html_url": "https://github.com/LaiPiXiong", "followers_url": "https://api.github.com/users/LaiPiXiong/followers", "following_url": "https://api.github.com/users/LaiPiXiong/following{/other_user}", "gists_url": "https://api.github.com/users/LaiPiXiong/gists{/gist_id}", "starred_url": "https://api.github.com/users/LaiPiXiong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LaiPiXiong/subscriptions", "organizations_url": "https://api.github.com/users/LaiPiXiong/orgs", "repos_url": "https://api.github.com/users/LaiPiXiong/repos", "events_url": "https://api.github.com/users/LaiPiXiong/events{/privacy}", "received_events_url": "https://api.github.com/users/LaiPiXiong/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-28T03:23:12Z", "updated_at": "2017-09-28T03:23:12Z", "author_association": "NONE", "body_html": "<p>I have the same problem, however, I could not find the reason. How to solve it? Thanks very much!<br>\nThe code contains two parts, first is read data:<br>\n`import tensorflow as tf<br>\nimport matplotlib.pyplot as plt<br>\nfrom PIL import Image</p>\n<h1>import tensorflow.examples.tutorials.mnist.input_data as input_data</h1>\n<p>def read_and_decode(file_name):<br>\nfilename_queue = tf.train.string_input_producer([file_name])</p>\n<pre><code>reader = tf.TFRecordReader() \n_, serialized_example = reader.read(filename_queue)\n   \nfeatures = tf.parse_single_example(\n    serialized_example,\n    features = {\n        'height': tf.FixedLenFeature([], tf.int64),  \n        'width': tf.FixedLenFeature([], tf.int64),  \n        'depth': tf.FixedLenFeature([], tf.int64),   \n        'label': tf.FixedLenFeature([], tf.int64),   \n        'image_raw': tf.FixedLenFeature([], tf.string)\n    }\n)\n\nimg = tf.decode_raw(features['image_raw'], tf.uint8)\nimg = tf.reshape(img, [32, 32, 3])\nimg = tf.cast(img, tf.float32) * (1./ 255) - 0.5\n# img = tf.cast(img, tf.float32)\nlabel = tf.cast(features['label'], tf.float32)\nreturn img, label\n</code></pre>\n<p>def fetch_data(file_name, batch_size):<br>\nimage, label = read_and_decode(file_name)<br>\nimage_batch, label_batch = tf.train.shuffle_batch(<br>\n[image, label],<br>\nbatch_size = batch_size,<br>\ncapacity = 2000,<br>\nmin_after_dequeue = 1000<br>\n)<br>\ninit_op = tf.global_variables_initializer()</p>\n<pre><code>with tf.Session() as sess: \n    coord   = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess = sess, coord=coord)\n    sess.run(init_op)\n    #image = Image.fromarray(image, 'RGB')    \n    coord.request_stop()\n    coord.join(threads) \nreturn image_batch, tf.convert_to_tensor([label_batch])\n</code></pre>\n<p>`</p>\n<p>and second is classification:<br>\n`# -<em>- coding: UTF-8 -</em>-<br>\nimport tensorflow as tf<br>\nimport read_data<br>\nimport numpy as np<br>\ndef conv_op(input_op, name, kh, kw, n_out, dh, dw, p):<br>\nn_in = input_op.get_shape()[-1].value # \u83b7\u53d6input_op\u7684\u901a\u9053\u6570</p>\n<pre><code>with tf.name_scope(name) as scope: # \u8bbe\u7f6escope\uff0c\u751f\u6210\u7684Variable\u4f7f\u7528\u9ed8\u8ba4\u7684\u547d\u540d\n    kernel = tf.get_variable(scope+\"w\",  # kernel\uff08\u5373\u5377\u79ef\u6838\u53c2\u6570\uff09\u4f7f\u7528tf.get_variable\u521b\u5efa\n                             shape=[kh, kw, n_in, n_out], # \u3010\u5377\u79ef\u6838\u7684\u9ad8\uff0c\u5377\u79ef\u6838\u7684\u5bbd\u3001\u8f93\u5165\u901a\u9053\u6570\uff0c\u8f93\u51fa\u901a\u9053\u6570\u3011\n                             dtype=tf.float32, \n                             initializer=tf.contrib.layers.xavier_initializer_conv2d()) # \u53c2\u6570\u521d\u59cb\u5316\n    # \u4f7f\u7528tf.nn.conv2d\u5bf9input_op\u8fdb\u884c\u5377\u79ef\u5904\u7406\uff0c\u5377\u79ef\u6838kernel\uff0c\u6b65\u957fdh*dw\uff0cpadding\u6a21\u5f0f\u4e3aSAME\n    conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME') \n    bias_init_val = tf.constant(0.0, shape=[n_out], dtype=tf.float32) # biases\u4f7f\u7528tf.constant\u8d4b\u503c\u4e3a0\n    biases = tf.Variable(bias_init_val, trainable=True, name='b') # \u5c06bias_init_val\u8f6c\u6210\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\n    z = tf.nn.bias_add(conv, biases) # \u5c06\u5377\u79ef\u7ed3\u679cconv\u548cbias\u76f8\u52a0\n    activation = tf.nn.relu(z, name=scope) # \u5bf9z\u8fdb\u884c\u975e\u7ebf\u6027\u5904\u7406\u5f97\u5230activation\n    p += [kernel, biases]  # \u521b\u5efa\u5377\u79ef\u5c42\u65f6\u7528\u5230\u7684\u53c2\u6570kernel\u548cbias\u6dfb\u52a0\u8fdb\u53c2\u6570\u5217\u8868\n    return activation # \u5c06\u5377\u79ef\u5c42\u7684\u8f93\u51faactivation\u4f5c\u4e3a\u51fd\u6570\u7ed3\u679c\u8fd4\u56de\n</code></pre>\n<p>def fc_op(input_op, name, n_out, p):<br>\nn_in = input_op.get_shape()[-1].value # \u83b7\u53d6tensor\u7684\u901a\u9053\u6570<br>\nwith tf.name_scope(name) as scope:<br>\nkernel = tf.get_variable(scope+\"w\", # \u4f7f\u7528tf.get_variable\u521b\u5efa\u5168\u8fde\u63a5\u5c42\u7684\u53c2\u6570<br>\nshape=[n_in, n_out], # \u53c2\u6570\u7684\u7ef4\u5ea6\u6709\u4e24\u4e2a\uff0c\u8f93\u5165\u901a\u9053\u6570\u548c\u8f93\u51fa\u901a\u9053\u6570<br>\ndtype=tf.float32,<br>\ninitializer=tf.contrib.layers.xavier_initializer())<br>\n# biases\u8d4b\u503c0.1\u4ee5\u907f\u514ddead neuron<br>\nbiases = tf.Variable(tf.constant(0.1, shape=[n_out], dtype=tf.float32), name='b')<br>\n# \u5bf9\u8f93\u5165\u53d8\u91cfinput_op\u548ckernel\u505a\u77e9\u9635\u4e58\u6cd5\u5e76\u52a0\u4e0abiases\u3002\u518d\u505a\u975e\u7ebf\u6027\u53d8\u6362activation<br>\nactivation = tf.nn.relu_layer(input_op, kernel, biases, name=scope)<br>\np += [kernel, biases]<br>\nreturn activation</p>\n<p>def mpool_op(input_op, name, kh, kw, dh, dw):<br>\nreturn tf.nn.max_pool(input_op,<br>\nksize=[1, kh, kw, 1], # \u6c60\u5316\u5c42\u5c3a\u5bf8kh<em>kw<br>\nstrides=[1, dh, dw, 1], # \u6b65\u957fdh</em>dw<br>\npadding='SAME',<br>\nname=name)</p>\n<p>def inference_op(input_op, keep_prob):<br>\n# \u521d\u59cb\u5316\u53c2\u6570\u5217\u8868p<br>\np = []<br>\n# assume input_op shape is 224x224x3\uff08\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u8f93\u5165input_op\uff09</p>\n<pre><code># \u521b\u5efa\u7b2c\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 112x112x64\n# \u4e24\u4e2a\u5377\u79ef\u5c42\u7684\u5377\u79ef\u6838\u90fd\u662f3*3\uff0c\u5377\u79ef\u6838\u6570\u91cf\uff08\u8f93\u51fa\u901a\u9053\u6570\uff09\u5747\u4e3a64\uff0c\u6b65\u957f1*1\uff0c\u5168\u50cf\u7d20\u626b\u63cf\u3002\nconv1_1 = conv_op(input_op, name=\"conv1_1\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\nconv1_2 = conv_op(conv1_1,  name=\"conv1_2\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\npool1  = mpool_op(conv1_2,  name=\"pool1\",   kh=2, kw=2, dw=2, dh=2) # \u6807\u51c6\u76842*2\u7684\u6700\u5927\u6c60\u5316-outputs 112x112x64\n\n# \u521b\u5efa\u7b2c\u4e8c\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 56x56x128\nconv2_1 = conv_op(pool1,    name=\"conv2_1\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\nconv2_2 = conv_op(conv2_1,  name=\"conv2_2\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\npool2 = mpool_op(conv2_2,   name=\"pool2\",   kh=2, kw=2, dh=2, dw=2)\n\n# \u521b\u5efa\u7b2c\u4e09\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 28x28x256\n# conv3_1 = conv_op(pool2,    name=\"conv3_1\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\n# conv3_2 = conv_op(conv3_1,  name=\"conv3_2\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\n# conv3_3 = conv_op(conv3_2,  name=\"conv3_3\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)    \n# pool3 = mpool_op(conv3_3,   name=\"pool3\",   kh=2, kw=2, dh=2, dw=2)\n\n# # \u521b\u5efa\u7b2c\u56db\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 14x14x512\n# conv4_1 = conv_op(pool3,    name=\"conv4_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv4_2 = conv_op(conv4_1,  name=\"conv4_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv4_3 = conv_op(conv4_2,  name=\"conv4_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# pool4 = mpool_op(conv4_3,   name=\"pool4\",   kh=2, kw=2, dh=2, dw=2)\n\n# # \u521b\u5efa\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 7x7x512\n# conv5_1 = conv_op(pool4,    name=\"conv5_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv5_2 = conv_op(conv5_1,  name=\"conv5_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv5_3 = conv_op(conv5_2,  name=\"conv5_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# pool5 = mpool_op(conv5_3,   name=\"pool5\",   kh=2, kw=2, dw=2, dh=2)\n\n# \u5907\u6ce8\uff1aVGGNet-16\u7684\u6bcf\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc\u90fd\u4f1a\u5c06\u56fe\u50cf\u7684\u8fb9\u957f\u7f29\u5c0f\u4e00\u534a\uff0c\u4f46\u662f\u5c06\u5377\u79ef\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\u3002\n# \u7b2c\u4e94\u6bb5\u5377\u79ef\u8f93\u51fa\u7684\u901a\u9053\u6570\u4e0d\u518d\u589e\u52a0\u3002\n\n# flatten \u5c06\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8fdb\u884c\u6241\u5e73\u5316\nshp = pool2.get_shape()\nflattened_shape = shp[1].value * shp[2].value * shp[3].value\n\n# tf.reshape\u51fd\u6570\u5c06\u6bcf\u4e2a\u6837\u672c\u5316\u4e3a\u957f\u5ea67*7*512 = 25088\u7684\u5411\u91cf\nresh1 = tf.reshape(pool2, [-1, flattened_shape], name=\"resh1\") \n\n# fully connected \u9690\u542b\u8282\u70b94096\u7684\u5168\u8fde\u63a5\u5c42\nfc6 = fc_op(resh1, name=\"fc6\", n_out=4096, p=p)\nfc6_drop = tf.nn.dropout(fc6, keep_prob, name=\"fc6_drop\")\n\nfc7 = fc_op(fc6_drop, name=\"fc7\", n_out=4096, p=p)\nfc7_drop = tf.nn.dropout(fc7, keep_prob, name=\"fc7_drop\")\n\nfc8 = fc_op(fc7_drop, name=\"fc8\", n_out=10, p=p)\nsoftmax = tf.nn.softmax(fc8) # \u5f97\u5230\u5206\u7c7b\u8f93\u51fa\u6982\u7387\npredictions = tf.argmax(softmax, 1) # tf.argmax\u6c42\u8f93\u51fa\u6982\u7387\u6700\u5927\u7c7b\u522b\nreturn tf.convert_to_tensor([predictions]), softmax, fc8, p\n</code></pre>\n<p>def main(file_name, batch_size, iter_times):<br>\nx = tf.placeholder('float', shape = [batch_size, 32, 32, 3])<br>\ny = tf.placeholder('float', shape = [1, batch_size])<br>\npredictions, _, _, _ = inference_op(x, keep_prob = 0.5)<br>\npredictions = tf.cast(predictions, tf.float32)</p>\n<pre><code>##### tf.equal \u8fd4\u56de\u7684\u662fbool tensor  ######\n##### tf.reduce_mean() \u4e0d\u80fd\u662fbool\u503c ######\ncross_entropy = -tf.reduce_sum(y * tf.log(predictions))\ntrain = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\nsess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in xrange(iter_times):\n    train_x, train_y = read_data.fetch_data(file_name, batch_size) \n    # train_x, train_y = sess.run([train_x, train_y])\n    train.eval(feedict = {x: train_x, y: train_y})\n    \n    if i % 100 == 0 :\n        print \"%d step accuarcy is %f\" % (i, sess.run(cross_entropy))\n</code></pre>\n<p>main('train.tfrecords', 30, 2000)`</p>", "body_text": "I have the same problem, however, I could not find the reason. How to solve it? Thanks very much!\nThe code contains two parts, first is read data:\n`import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tensorflow.examples.tutorials.mnist.input_data as input_data\ndef read_and_decode(file_name):\nfilename_queue = tf.train.string_input_producer([file_name])\nreader = tf.TFRecordReader() \n_, serialized_example = reader.read(filename_queue)\n   \nfeatures = tf.parse_single_example(\n    serialized_example,\n    features = {\n        'height': tf.FixedLenFeature([], tf.int64),  \n        'width': tf.FixedLenFeature([], tf.int64),  \n        'depth': tf.FixedLenFeature([], tf.int64),   \n        'label': tf.FixedLenFeature([], tf.int64),   \n        'image_raw': tf.FixedLenFeature([], tf.string)\n    }\n)\n\nimg = tf.decode_raw(features['image_raw'], tf.uint8)\nimg = tf.reshape(img, [32, 32, 3])\nimg = tf.cast(img, tf.float32) * (1./ 255) - 0.5\n# img = tf.cast(img, tf.float32)\nlabel = tf.cast(features['label'], tf.float32)\nreturn img, label\n\ndef fetch_data(file_name, batch_size):\nimage, label = read_and_decode(file_name)\nimage_batch, label_batch = tf.train.shuffle_batch(\n[image, label],\nbatch_size = batch_size,\ncapacity = 2000,\nmin_after_dequeue = 1000\n)\ninit_op = tf.global_variables_initializer()\nwith tf.Session() as sess: \n    coord   = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess = sess, coord=coord)\n    sess.run(init_op)\n    #image = Image.fromarray(image, 'RGB')    \n    coord.request_stop()\n    coord.join(threads) \nreturn image_batch, tf.convert_to_tensor([label_batch])\n\n`\nand second is classification:\n`# -- coding: UTF-8 --\nimport tensorflow as tf\nimport read_data\nimport numpy as np\ndef conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\nn_in = input_op.get_shape()[-1].value # \u83b7\u53d6input_op\u7684\u901a\u9053\u6570\nwith tf.name_scope(name) as scope: # \u8bbe\u7f6escope\uff0c\u751f\u6210\u7684Variable\u4f7f\u7528\u9ed8\u8ba4\u7684\u547d\u540d\n    kernel = tf.get_variable(scope+\"w\",  # kernel\uff08\u5373\u5377\u79ef\u6838\u53c2\u6570\uff09\u4f7f\u7528tf.get_variable\u521b\u5efa\n                             shape=[kh, kw, n_in, n_out], # \u3010\u5377\u79ef\u6838\u7684\u9ad8\uff0c\u5377\u79ef\u6838\u7684\u5bbd\u3001\u8f93\u5165\u901a\u9053\u6570\uff0c\u8f93\u51fa\u901a\u9053\u6570\u3011\n                             dtype=tf.float32, \n                             initializer=tf.contrib.layers.xavier_initializer_conv2d()) # \u53c2\u6570\u521d\u59cb\u5316\n    # \u4f7f\u7528tf.nn.conv2d\u5bf9input_op\u8fdb\u884c\u5377\u79ef\u5904\u7406\uff0c\u5377\u79ef\u6838kernel\uff0c\u6b65\u957fdh*dw\uff0cpadding\u6a21\u5f0f\u4e3aSAME\n    conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME') \n    bias_init_val = tf.constant(0.0, shape=[n_out], dtype=tf.float32) # biases\u4f7f\u7528tf.constant\u8d4b\u503c\u4e3a0\n    biases = tf.Variable(bias_init_val, trainable=True, name='b') # \u5c06bias_init_val\u8f6c\u6210\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\n    z = tf.nn.bias_add(conv, biases) # \u5c06\u5377\u79ef\u7ed3\u679cconv\u548cbias\u76f8\u52a0\n    activation = tf.nn.relu(z, name=scope) # \u5bf9z\u8fdb\u884c\u975e\u7ebf\u6027\u5904\u7406\u5f97\u5230activation\n    p += [kernel, biases]  # \u521b\u5efa\u5377\u79ef\u5c42\u65f6\u7528\u5230\u7684\u53c2\u6570kernel\u548cbias\u6dfb\u52a0\u8fdb\u53c2\u6570\u5217\u8868\n    return activation # \u5c06\u5377\u79ef\u5c42\u7684\u8f93\u51faactivation\u4f5c\u4e3a\u51fd\u6570\u7ed3\u679c\u8fd4\u56de\n\ndef fc_op(input_op, name, n_out, p):\nn_in = input_op.get_shape()[-1].value # \u83b7\u53d6tensor\u7684\u901a\u9053\u6570\nwith tf.name_scope(name) as scope:\nkernel = tf.get_variable(scope+\"w\", # \u4f7f\u7528tf.get_variable\u521b\u5efa\u5168\u8fde\u63a5\u5c42\u7684\u53c2\u6570\nshape=[n_in, n_out], # \u53c2\u6570\u7684\u7ef4\u5ea6\u6709\u4e24\u4e2a\uff0c\u8f93\u5165\u901a\u9053\u6570\u548c\u8f93\u51fa\u901a\u9053\u6570\ndtype=tf.float32,\ninitializer=tf.contrib.layers.xavier_initializer())\n# biases\u8d4b\u503c0.1\u4ee5\u907f\u514ddead neuron\nbiases = tf.Variable(tf.constant(0.1, shape=[n_out], dtype=tf.float32), name='b')\n# \u5bf9\u8f93\u5165\u53d8\u91cfinput_op\u548ckernel\u505a\u77e9\u9635\u4e58\u6cd5\u5e76\u52a0\u4e0abiases\u3002\u518d\u505a\u975e\u7ebf\u6027\u53d8\u6362activation\nactivation = tf.nn.relu_layer(input_op, kernel, biases, name=scope)\np += [kernel, biases]\nreturn activation\ndef mpool_op(input_op, name, kh, kw, dh, dw):\nreturn tf.nn.max_pool(input_op,\nksize=[1, kh, kw, 1], # \u6c60\u5316\u5c42\u5c3a\u5bf8khkw\nstrides=[1, dh, dw, 1], # \u6b65\u957fdhdw\npadding='SAME',\nname=name)\ndef inference_op(input_op, keep_prob):\n# \u521d\u59cb\u5316\u53c2\u6570\u5217\u8868p\np = []\n# assume input_op shape is 224x224x3\uff08\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u8f93\u5165input_op\uff09\n# \u521b\u5efa\u7b2c\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 112x112x64\n# \u4e24\u4e2a\u5377\u79ef\u5c42\u7684\u5377\u79ef\u6838\u90fd\u662f3*3\uff0c\u5377\u79ef\u6838\u6570\u91cf\uff08\u8f93\u51fa\u901a\u9053\u6570\uff09\u5747\u4e3a64\uff0c\u6b65\u957f1*1\uff0c\u5168\u50cf\u7d20\u626b\u63cf\u3002\nconv1_1 = conv_op(input_op, name=\"conv1_1\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\nconv1_2 = conv_op(conv1_1,  name=\"conv1_2\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\npool1  = mpool_op(conv1_2,  name=\"pool1\",   kh=2, kw=2, dw=2, dh=2) # \u6807\u51c6\u76842*2\u7684\u6700\u5927\u6c60\u5316-outputs 112x112x64\n\n# \u521b\u5efa\u7b2c\u4e8c\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 56x56x128\nconv2_1 = conv_op(pool1,    name=\"conv2_1\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\nconv2_2 = conv_op(conv2_1,  name=\"conv2_2\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\npool2 = mpool_op(conv2_2,   name=\"pool2\",   kh=2, kw=2, dh=2, dw=2)\n\n# \u521b\u5efa\u7b2c\u4e09\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 28x28x256\n# conv3_1 = conv_op(pool2,    name=\"conv3_1\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\n# conv3_2 = conv_op(conv3_1,  name=\"conv3_2\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\n# conv3_3 = conv_op(conv3_2,  name=\"conv3_3\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)    \n# pool3 = mpool_op(conv3_3,   name=\"pool3\",   kh=2, kw=2, dh=2, dw=2)\n\n# # \u521b\u5efa\u7b2c\u56db\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 14x14x512\n# conv4_1 = conv_op(pool3,    name=\"conv4_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv4_2 = conv_op(conv4_1,  name=\"conv4_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv4_3 = conv_op(conv4_2,  name=\"conv4_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# pool4 = mpool_op(conv4_3,   name=\"pool4\",   kh=2, kw=2, dh=2, dw=2)\n\n# # \u521b\u5efa\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 7x7x512\n# conv5_1 = conv_op(pool4,    name=\"conv5_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv5_2 = conv_op(conv5_1,  name=\"conv5_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# conv5_3 = conv_op(conv5_2,  name=\"conv5_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\n# pool5 = mpool_op(conv5_3,   name=\"pool5\",   kh=2, kw=2, dw=2, dh=2)\n\n# \u5907\u6ce8\uff1aVGGNet-16\u7684\u6bcf\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc\u90fd\u4f1a\u5c06\u56fe\u50cf\u7684\u8fb9\u957f\u7f29\u5c0f\u4e00\u534a\uff0c\u4f46\u662f\u5c06\u5377\u79ef\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\u3002\n# \u7b2c\u4e94\u6bb5\u5377\u79ef\u8f93\u51fa\u7684\u901a\u9053\u6570\u4e0d\u518d\u589e\u52a0\u3002\n\n# flatten \u5c06\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8fdb\u884c\u6241\u5e73\u5316\nshp = pool2.get_shape()\nflattened_shape = shp[1].value * shp[2].value * shp[3].value\n\n# tf.reshape\u51fd\u6570\u5c06\u6bcf\u4e2a\u6837\u672c\u5316\u4e3a\u957f\u5ea67*7*512 = 25088\u7684\u5411\u91cf\nresh1 = tf.reshape(pool2, [-1, flattened_shape], name=\"resh1\") \n\n# fully connected \u9690\u542b\u8282\u70b94096\u7684\u5168\u8fde\u63a5\u5c42\nfc6 = fc_op(resh1, name=\"fc6\", n_out=4096, p=p)\nfc6_drop = tf.nn.dropout(fc6, keep_prob, name=\"fc6_drop\")\n\nfc7 = fc_op(fc6_drop, name=\"fc7\", n_out=4096, p=p)\nfc7_drop = tf.nn.dropout(fc7, keep_prob, name=\"fc7_drop\")\n\nfc8 = fc_op(fc7_drop, name=\"fc8\", n_out=10, p=p)\nsoftmax = tf.nn.softmax(fc8) # \u5f97\u5230\u5206\u7c7b\u8f93\u51fa\u6982\u7387\npredictions = tf.argmax(softmax, 1) # tf.argmax\u6c42\u8f93\u51fa\u6982\u7387\u6700\u5927\u7c7b\u522b\nreturn tf.convert_to_tensor([predictions]), softmax, fc8, p\n\ndef main(file_name, batch_size, iter_times):\nx = tf.placeholder('float', shape = [batch_size, 32, 32, 3])\ny = tf.placeholder('float', shape = [1, batch_size])\npredictions, _, _, _ = inference_op(x, keep_prob = 0.5)\npredictions = tf.cast(predictions, tf.float32)\n##### tf.equal \u8fd4\u56de\u7684\u662fbool tensor  ######\n##### tf.reduce_mean() \u4e0d\u80fd\u662fbool\u503c ######\ncross_entropy = -tf.reduce_sum(y * tf.log(predictions))\ntrain = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\nsess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in xrange(iter_times):\n    train_x, train_y = read_data.fetch_data(file_name, batch_size) \n    # train_x, train_y = sess.run([train_x, train_y])\n    train.eval(feedict = {x: train_x, y: train_y})\n    \n    if i % 100 == 0 :\n        print \"%d step accuarcy is %f\" % (i, sess.run(cross_entropy))\n\nmain('train.tfrecords', 30, 2000)`", "body": "I have the same problem, however, I could not find the reason. How to solve it? Thanks very much!\r\nThe code contains two parts, first is read data:\r\n`import tensorflow as tf\r\nimport matplotlib.pyplot as plt \r\nfrom PIL import Image\r\n# import tensorflow.examples.tutorials.mnist.input_data as input_data\r\n\r\ndef read_and_decode(file_name):\r\n    filename_queue = tf.train.string_input_producer([file_name])\r\n\r\n    reader = tf.TFRecordReader() \r\n    _, serialized_example = reader.read(filename_queue)\r\n       \r\n    features = tf.parse_single_example(\r\n        serialized_example,\r\n        features = {\r\n            'height': tf.FixedLenFeature([], tf.int64),  \r\n            'width': tf.FixedLenFeature([], tf.int64),  \r\n            'depth': tf.FixedLenFeature([], tf.int64),   \r\n            'label': tf.FixedLenFeature([], tf.int64),   \r\n            'image_raw': tf.FixedLenFeature([], tf.string)\r\n        }\r\n    )\r\n\r\n    img = tf.decode_raw(features['image_raw'], tf.uint8)\r\n    img = tf.reshape(img, [32, 32, 3])\r\n    img = tf.cast(img, tf.float32) * (1./ 255) - 0.5\r\n    # img = tf.cast(img, tf.float32)\r\n    label = tf.cast(features['label'], tf.float32)\r\n    return img, label\r\n\r\ndef fetch_data(file_name, batch_size): \r\n    image, label = read_and_decode(file_name)\r\n    image_batch, label_batch = tf.train.shuffle_batch(\r\n                                            [image, label], \r\n                                            batch_size = batch_size, \r\n                                            capacity = 2000, \r\n                                            min_after_dequeue = 1000\r\n                                            )\r\n    init_op = tf.global_variables_initializer()\r\n\r\n    with tf.Session() as sess: \r\n        coord   = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess = sess, coord=coord)\r\n        sess.run(init_op)\r\n        #image = Image.fromarray(image, 'RGB')    \r\n        coord.request_stop()\r\n        coord.join(threads) \r\n    return image_batch, tf.convert_to_tensor([label_batch])\r\n`\r\n\r\nand second is classification:\r\n`# -*- coding: UTF-8 -*-\r\nimport tensorflow as tf\r\nimport read_data\r\nimport numpy as np\r\ndef conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\r\n    n_in = input_op.get_shape()[-1].value # \u83b7\u53d6input_op\u7684\u901a\u9053\u6570\r\n\r\n    with tf.name_scope(name) as scope: # \u8bbe\u7f6escope\uff0c\u751f\u6210\u7684Variable\u4f7f\u7528\u9ed8\u8ba4\u7684\u547d\u540d\r\n        kernel = tf.get_variable(scope+\"w\",  # kernel\uff08\u5373\u5377\u79ef\u6838\u53c2\u6570\uff09\u4f7f\u7528tf.get_variable\u521b\u5efa\r\n                                 shape=[kh, kw, n_in, n_out], # \u3010\u5377\u79ef\u6838\u7684\u9ad8\uff0c\u5377\u79ef\u6838\u7684\u5bbd\u3001\u8f93\u5165\u901a\u9053\u6570\uff0c\u8f93\u51fa\u901a\u9053\u6570\u3011\r\n                                 dtype=tf.float32, \r\n                                 initializer=tf.contrib.layers.xavier_initializer_conv2d()) # \u53c2\u6570\u521d\u59cb\u5316\r\n        # \u4f7f\u7528tf.nn.conv2d\u5bf9input_op\u8fdb\u884c\u5377\u79ef\u5904\u7406\uff0c\u5377\u79ef\u6838kernel\uff0c\u6b65\u957fdh*dw\uff0cpadding\u6a21\u5f0f\u4e3aSAME\r\n        conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding='SAME') \r\n        bias_init_val = tf.constant(0.0, shape=[n_out], dtype=tf.float32) # biases\u4f7f\u7528tf.constant\u8d4b\u503c\u4e3a0\r\n        biases = tf.Variable(bias_init_val, trainable=True, name='b') # \u5c06bias_init_val\u8f6c\u6210\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\r\n        z = tf.nn.bias_add(conv, biases) # \u5c06\u5377\u79ef\u7ed3\u679cconv\u548cbias\u76f8\u52a0\r\n        activation = tf.nn.relu(z, name=scope) # \u5bf9z\u8fdb\u884c\u975e\u7ebf\u6027\u5904\u7406\u5f97\u5230activation\r\n        p += [kernel, biases]  # \u521b\u5efa\u5377\u79ef\u5c42\u65f6\u7528\u5230\u7684\u53c2\u6570kernel\u548cbias\u6dfb\u52a0\u8fdb\u53c2\u6570\u5217\u8868\r\n        return activation # \u5c06\u5377\u79ef\u5c42\u7684\u8f93\u51faactivation\u4f5c\u4e3a\u51fd\u6570\u7ed3\u679c\u8fd4\u56de\r\n\r\ndef fc_op(input_op, name, n_out, p):  \r\n    n_in = input_op.get_shape()[-1].value # \u83b7\u53d6tensor\u7684\u901a\u9053\u6570 \r\n    with tf.name_scope(name) as scope:\r\n        kernel = tf.get_variable(scope+\"w\", # \u4f7f\u7528tf.get_variable\u521b\u5efa\u5168\u8fde\u63a5\u5c42\u7684\u53c2\u6570\r\n                                 shape=[n_in, n_out], # \u53c2\u6570\u7684\u7ef4\u5ea6\u6709\u4e24\u4e2a\uff0c\u8f93\u5165\u901a\u9053\u6570\u548c\u8f93\u51fa\u901a\u9053\u6570\r\n                                 dtype=tf.float32, \r\n                                 initializer=tf.contrib.layers.xavier_initializer())\r\n        # biases\u8d4b\u503c0.1\u4ee5\u907f\u514ddead neuron\r\n        biases = tf.Variable(tf.constant(0.1, shape=[n_out], dtype=tf.float32), name='b') \r\n        # \u5bf9\u8f93\u5165\u53d8\u91cfinput_op\u548ckernel\u505a\u77e9\u9635\u4e58\u6cd5\u5e76\u52a0\u4e0abiases\u3002\u518d\u505a\u975e\u7ebf\u6027\u53d8\u6362activation\r\n        activation = tf.nn.relu_layer(input_op, kernel, biases, name=scope) \r\n        p += [kernel, biases]\r\n        return activation\r\n\r\ndef mpool_op(input_op, name, kh, kw, dh, dw): \r\n    return tf.nn.max_pool(input_op,\r\n                          ksize=[1, kh, kw, 1], # \u6c60\u5316\u5c42\u5c3a\u5bf8kh*kw\r\n                          strides=[1, dh, dw, 1], # \u6b65\u957fdh*dw\r\n                          padding='SAME',\r\n                          name=name)\r\n\r\ndef inference_op(input_op, keep_prob):\r\n    # \u521d\u59cb\u5316\u53c2\u6570\u5217\u8868p\r\n    p = []\r\n    # assume input_op shape is 224x224x3\uff08\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u8f93\u5165input_op\uff09\r\n\r\n    # \u521b\u5efa\u7b2c\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 112x112x64\r\n    # \u4e24\u4e2a\u5377\u79ef\u5c42\u7684\u5377\u79ef\u6838\u90fd\u662f3*3\uff0c\u5377\u79ef\u6838\u6570\u91cf\uff08\u8f93\u51fa\u901a\u9053\u6570\uff09\u5747\u4e3a64\uff0c\u6b65\u957f1*1\uff0c\u5168\u50cf\u7d20\u626b\u63cf\u3002\r\n    conv1_1 = conv_op(input_op, name=\"conv1_1\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\r\n    conv1_2 = conv_op(conv1_1,  name=\"conv1_2\", kh=3, kw=3, n_out=64, dh=1, dw=1, p=p) # outputs 224x224x64\r\n    pool1  = mpool_op(conv1_2,  name=\"pool1\",   kh=2, kw=2, dw=2, dh=2) # \u6807\u51c6\u76842*2\u7684\u6700\u5927\u6c60\u5316-outputs 112x112x64\r\n\r\n    # \u521b\u5efa\u7b2c\u4e8c\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 56x56x128\r\n    conv2_1 = conv_op(pool1,    name=\"conv2_1\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\r\n    conv2_2 = conv_op(conv2_1,  name=\"conv2_2\", kh=3, kw=3, n_out=128, dh=1, dw=1, p=p)\r\n    pool2 = mpool_op(conv2_2,   name=\"pool2\",   kh=2, kw=2, dh=2, dw=2)\r\n\r\n    # \u521b\u5efa\u7b2c\u4e09\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 28x28x256\r\n    # conv3_1 = conv_op(pool2,    name=\"conv3_1\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\r\n    # conv3_2 = conv_op(conv3_1,  name=\"conv3_2\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)\r\n    # conv3_3 = conv_op(conv3_2,  name=\"conv3_3\", kh=3, kw=3, n_out=256, dh=1, dw=1, p=p)    \r\n    # pool3 = mpool_op(conv3_3,   name=\"pool3\",   kh=2, kw=2, dh=2, dw=2)\r\n\r\n    # # \u521b\u5efa\u7b2c\u56db\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 14x14x512\r\n    # conv4_1 = conv_op(pool3,    name=\"conv4_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # conv4_2 = conv_op(conv4_1,  name=\"conv4_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # conv4_3 = conv_op(conv4_2,  name=\"conv4_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # pool4 = mpool_op(conv4_3,   name=\"pool4\",   kh=2, kw=2, dh=2, dw=2)\r\n\r\n    # # \u521b\u5efa\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc -- outputs 7x7x512\r\n    # conv5_1 = conv_op(pool4,    name=\"conv5_1\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # conv5_2 = conv_op(conv5_1,  name=\"conv5_2\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # conv5_3 = conv_op(conv5_2,  name=\"conv5_3\", kh=3, kw=3, n_out=512, dh=1, dw=1, p=p)\r\n    # pool5 = mpool_op(conv5_3,   name=\"pool5\",   kh=2, kw=2, dw=2, dh=2)\r\n\r\n    # \u5907\u6ce8\uff1aVGGNet-16\u7684\u6bcf\u4e00\u6bb5\u5377\u79ef\u7f51\u7edc\u90fd\u4f1a\u5c06\u56fe\u50cf\u7684\u8fb9\u957f\u7f29\u5c0f\u4e00\u534a\uff0c\u4f46\u662f\u5c06\u5377\u79ef\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\u3002\r\n    # \u7b2c\u4e94\u6bb5\u5377\u79ef\u8f93\u51fa\u7684\u901a\u9053\u6570\u4e0d\u518d\u589e\u52a0\u3002\r\n\r\n    # flatten \u5c06\u7b2c\u4e94\u6bb5\u5377\u79ef\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8fdb\u884c\u6241\u5e73\u5316\r\n    shp = pool2.get_shape()\r\n    flattened_shape = shp[1].value * shp[2].value * shp[3].value\r\n\r\n    # tf.reshape\u51fd\u6570\u5c06\u6bcf\u4e2a\u6837\u672c\u5316\u4e3a\u957f\u5ea67*7*512 = 25088\u7684\u5411\u91cf\r\n    resh1 = tf.reshape(pool2, [-1, flattened_shape], name=\"resh1\") \r\n\r\n    # fully connected \u9690\u542b\u8282\u70b94096\u7684\u5168\u8fde\u63a5\u5c42\r\n    fc6 = fc_op(resh1, name=\"fc6\", n_out=4096, p=p)\r\n    fc6_drop = tf.nn.dropout(fc6, keep_prob, name=\"fc6_drop\")\r\n\r\n    fc7 = fc_op(fc6_drop, name=\"fc7\", n_out=4096, p=p)\r\n    fc7_drop = tf.nn.dropout(fc7, keep_prob, name=\"fc7_drop\")\r\n\r\n    fc8 = fc_op(fc7_drop, name=\"fc8\", n_out=10, p=p)\r\n    softmax = tf.nn.softmax(fc8) # \u5f97\u5230\u5206\u7c7b\u8f93\u51fa\u6982\u7387\r\n    predictions = tf.argmax(softmax, 1) # tf.argmax\u6c42\u8f93\u51fa\u6982\u7387\u6700\u5927\u7c7b\u522b\r\n    return tf.convert_to_tensor([predictions]), softmax, fc8, p\r\n\r\ndef main(file_name, batch_size, iter_times):\r\n    x = tf.placeholder('float', shape = [batch_size, 32, 32, 3])\r\n    y = tf.placeholder('float', shape = [1, batch_size])\r\n    predictions, _, _, _ = inference_op(x, keep_prob = 0.5)\r\n    predictions = tf.cast(predictions, tf.float32)\r\n\r\n    ##### tf.equal \u8fd4\u56de\u7684\u662fbool tensor  ######\r\n    ##### tf.reduce_mean() \u4e0d\u80fd\u662fbool\u503c ######\r\n    cross_entropy = -tf.reduce_sum(y * tf.log(predictions))\r\n    train = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n    sess = tf.Session()\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    \r\n    for i in xrange(iter_times):\r\n        train_x, train_y = read_data.fetch_data(file_name, batch_size) \r\n        # train_x, train_y = sess.run([train_x, train_y])\r\n        train.eval(feedict = {x: train_x, y: train_y})\r\n        \r\n        if i % 100 == 0 :\r\n            print \"%d step accuarcy is %f\" % (i, sess.run(cross_entropy))\r\n\r\nmain('train.tfrecords', 30, 2000)`"}