{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264290264", "html_url": "https://github.com/tensorflow/tensorflow/issues/781#issuecomment-264290264", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/781", "id": 264290264, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDI5MDI2NA==", "user": {"login": "kofd", "id": 5904259, "node_id": "MDQ6VXNlcjU5MDQyNTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/5904259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kofd", "html_url": "https://github.com/kofd", "followers_url": "https://api.github.com/users/kofd/followers", "following_url": "https://api.github.com/users/kofd/following{/other_user}", "gists_url": "https://api.github.com/users/kofd/gists{/gist_id}", "starred_url": "https://api.github.com/users/kofd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kofd/subscriptions", "organizations_url": "https://api.github.com/users/kofd/orgs", "repos_url": "https://api.github.com/users/kofd/repos", "events_url": "https://api.github.com/users/kofd/events{/privacy}", "received_events_url": "https://api.github.com/users/kofd/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-01T20:48:25Z", "updated_at": "2016-12-01T21:23:42Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">rotate</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">angle</span>):\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>rotate<span class=\"pl-pds\">'</span></span>):\n        image <span class=\"pl-k\">=</span> tf.cast(image, tf.float32)\n        angle <span class=\"pl-k\">=</span> angle <span class=\"pl-k\">/</span> <span class=\"pl-c1\">180</span> <span class=\"pl-k\">*</span> math.pi\n        shape <span class=\"pl-k\">=</span> image.get_shape().as_list()\n        <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(shape) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">3</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Input needs to be 3D.<span class=\"pl-pds\">\"</span></span>\n        image_center <span class=\"pl-k\">=</span> np.array([x<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span> <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> shape][:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])\n\n        coord1 <span class=\"pl-k\">=</span> tf.cast(tf.range(shape[<span class=\"pl-c1\">0</span>]), tf.float32)\n        coord2 <span class=\"pl-k\">=</span> tf.cast(tf.range(shape[<span class=\"pl-c1\">1</span>]), tf.float32)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create vectors of those coordinates in order to vectorize the image</span>\n        coord1_vec <span class=\"pl-k\">=</span> tf.tile(coord1, [shape[<span class=\"pl-c1\">1</span>]])\n\n        coord2_vec_unordered <span class=\"pl-k\">=</span> tf.tile(coord2, [shape[<span class=\"pl-c1\">0</span>]])\n        coord2_vec_unordered <span class=\"pl-k\">=</span> tf.reshape(coord2_vec_unordered, [shape[<span class=\"pl-c1\">0</span>], shape[<span class=\"pl-c1\">1</span>]])\n        coord2_vec <span class=\"pl-k\">=</span> tf.reshape(tf.transpose(coord2_vec_unordered, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>]), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> center coordinates since rotation center is supposed to be in the image center</span>\n        coord1_vec_centered <span class=\"pl-k\">=</span> coord1_vec <span class=\"pl-k\">-</span> image_center[<span class=\"pl-c1\">0</span>]\n        coord2_vec_centered <span class=\"pl-k\">=</span> coord2_vec <span class=\"pl-k\">-</span> image_center[<span class=\"pl-c1\">1</span>]\n\n        coord_new_centered <span class=\"pl-k\">=</span> tf.cast(tf.pack([coord1_vec_centered, coord2_vec_centered]), tf.float32)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Perform backward transformation of the image coordinates</span>\n        rot_mat_inv <span class=\"pl-k\">=</span> tf.expand_dims(tf.pack([tf.cos(angle), tf.sin(angle), <span class=\"pl-k\">-</span>tf.sin(angle), tf.cos(angle)]), <span class=\"pl-c1\">0</span>)\n        rot_mat_inv <span class=\"pl-k\">=</span> tf.cast(tf.reshape(rot_mat_inv, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>]), tf.float32)\n        coord_old_centered <span class=\"pl-k\">=</span> tf.matmul(rot_mat_inv, coord_new_centered)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Find neighbors in old image</span>\n        coord1_old_nn <span class=\"pl-k\">=</span> coord_old_centered[<span class=\"pl-c1\">0</span>, :] <span class=\"pl-k\">+</span> image_center[<span class=\"pl-c1\">0</span>]\n        coord2_old_nn <span class=\"pl-k\">=</span> coord_old_centered[<span class=\"pl-c1\">1</span>, :] <span class=\"pl-k\">+</span> image_center[<span class=\"pl-c1\">1</span>]\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Clip values to stay inside image coordinates</span>\n        outside_ind1 <span class=\"pl-k\">=</span> tf.logical_or(tf.greater(coord1_old_nn, shape[<span class=\"pl-c1\">0</span>]<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>), tf.less(coord1_old_nn, <span class=\"pl-c1\">0</span>))\n        outside_ind2 <span class=\"pl-k\">=</span> tf.logical_or(tf.greater(coord2_old_nn, shape[<span class=\"pl-c1\">1</span>]<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>), tf.less(coord2_old_nn, <span class=\"pl-c1\">0</span>))\n        outside_ind <span class=\"pl-k\">=</span> tf.logical_or(outside_ind1, outside_ind2)\n\n        coord1_vec <span class=\"pl-k\">=</span> tf.boolean_mask(coord1_vec, tf.logical_not(outside_ind))\n        coord2_vec <span class=\"pl-k\">=</span> tf.boolean_mask(coord2_vec, tf.logical_not(outside_ind))\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Coordinates of the new image</span>\n        coord_new <span class=\"pl-k\">=</span> tf.transpose(tf.cast(tf.pack([coord1_vec, coord2_vec]), tf.int32), [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>])\n\n        coord1_old_nn0 <span class=\"pl-k\">=</span> tf.floor(coord1_old_nn)\n        coord2_old_nn0 <span class=\"pl-k\">=</span> tf.floor(coord2_old_nn)\n        sx <span class=\"pl-k\">=</span> coord1_old_nn <span class=\"pl-k\">-</span> coord1_old_nn0\n        sy <span class=\"pl-k\">=</span> coord2_old_nn <span class=\"pl-k\">-</span> coord2_old_nn0\n        coord1_old_nn0 <span class=\"pl-k\">=</span> tf.cast(coord1_old_nn0, tf.int32)\n        coord2_old_nn0 <span class=\"pl-k\">=</span> tf.cast(coord2_old_nn0, tf.int32)\n        coord1_old_nn0 <span class=\"pl-k\">=</span> tf.boolean_mask(coord1_old_nn0, tf.logical_not(outside_ind))\n        coord2_old_nn0 <span class=\"pl-k\">=</span> tf.boolean_mask(coord2_old_nn0, tf.logical_not(outside_ind))\n        coord1_old_nn1 <span class=\"pl-k\">=</span> coord1_old_nn0 <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n        coord2_old_nn1 <span class=\"pl-k\">=</span> coord2_old_nn0 <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n        interp_coords <span class=\"pl-k\">=</span> [\n            ((<span class=\"pl-c1\">1</span>.<span class=\"pl-k\">-</span>sx) <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">1</span>.<span class=\"pl-k\">-</span>sy), coord1_old_nn0, coord2_old_nn0),\n            (    sx  <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">1</span>.<span class=\"pl-k\">-</span>sy), coord1_old_nn1, coord2_old_nn0),\n            ((<span class=\"pl-c1\">1</span>.<span class=\"pl-k\">-</span>sx) <span class=\"pl-k\">*</span>     sy,  coord1_old_nn0, coord2_old_nn1),\n            (    sx  <span class=\"pl-k\">*</span>     sy,  coord1_old_nn1, coord2_old_nn1)\n        ]\n\n        interp_old <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> intensity, coord1, coord2 <span class=\"pl-k\">in</span> interp_coords:\n            intensity <span class=\"pl-k\">=</span> tf.transpose(tf.reshape(intensity, [shape[<span class=\"pl-c1\">1</span>], shape[<span class=\"pl-c1\">0</span>]]))\n            coord_old_clipped <span class=\"pl-k\">=</span> tf.transpose(tf.pack([coord1, coord2]), [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>])\n            interp_old.append((intensity, coord_old_clipped))\n\n        channels <span class=\"pl-k\">=</span> tf.split(<span class=\"pl-c1\">2</span>, shape[<span class=\"pl-c1\">2</span>], image)\n        image_rotated_channel_list <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>()\n        <span class=\"pl-k\">for</span> channel <span class=\"pl-k\">in</span> channels:\n            channel <span class=\"pl-k\">=</span> tf.squeeze(channel)\n            interp_intensities <span class=\"pl-k\">=</span> []\n            <span class=\"pl-k\">for</span> intensity, coord_old_clipped <span class=\"pl-k\">in</span> interp_old:\n                image_chan_new_values <span class=\"pl-k\">=</span> tf.gather_nd(channel, coord_old_clipped)\n\n                channel_values <span class=\"pl-k\">=</span> tf.sparse_to_dense(coord_new, [shape[<span class=\"pl-c1\">0</span>], shape[<span class=\"pl-c1\">1</span>]], image_chan_new_values,\n                                                    <span class=\"pl-c1\">0</span>, <span class=\"pl-v\">validate_indices</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n                interp_intensities.append(channel_values <span class=\"pl-k\">*</span> intensity)\n            image_rotated_channel_list.append(tf.add_n(interp_intensities))\n\n        image_rotated <span class=\"pl-k\">=</span> tf.transpose(tf.pack(image_rotated_channel_list), [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>])\n\n        <span class=\"pl-k\">return</span> image_rotated</pre></div>", "body_text": "def rotate(image, angle):\n    with tf.name_scope('rotate'):\n        image = tf.cast(image, tf.float32)\n        angle = angle / 180 * math.pi\n        shape = image.get_shape().as_list()\n        assert len(shape) == 3, \"Input needs to be 3D.\"\n        image_center = np.array([x/2 for x in shape][:-1])\n\n        coord1 = tf.cast(tf.range(shape[0]), tf.float32)\n        coord2 = tf.cast(tf.range(shape[1]), tf.float32)\n\n        # Create vectors of those coordinates in order to vectorize the image\n        coord1_vec = tf.tile(coord1, [shape[1]])\n\n        coord2_vec_unordered = tf.tile(coord2, [shape[0]])\n        coord2_vec_unordered = tf.reshape(coord2_vec_unordered, [shape[0], shape[1]])\n        coord2_vec = tf.reshape(tf.transpose(coord2_vec_unordered, [1, 0]), [-1])\n\n        # center coordinates since rotation center is supposed to be in the image center\n        coord1_vec_centered = coord1_vec - image_center[0]\n        coord2_vec_centered = coord2_vec - image_center[1]\n\n        coord_new_centered = tf.cast(tf.pack([coord1_vec_centered, coord2_vec_centered]), tf.float32)\n\n        # Perform backward transformation of the image coordinates\n        rot_mat_inv = tf.expand_dims(tf.pack([tf.cos(angle), tf.sin(angle), -tf.sin(angle), tf.cos(angle)]), 0)\n        rot_mat_inv = tf.cast(tf.reshape(rot_mat_inv, shape=[2, 2]), tf.float32)\n        coord_old_centered = tf.matmul(rot_mat_inv, coord_new_centered)\n\n        # Find neighbors in old image\n        coord1_old_nn = coord_old_centered[0, :] + image_center[0]\n        coord2_old_nn = coord_old_centered[1, :] + image_center[1]\n\n        # Clip values to stay inside image coordinates\n        outside_ind1 = tf.logical_or(tf.greater(coord1_old_nn, shape[0]-1), tf.less(coord1_old_nn, 0))\n        outside_ind2 = tf.logical_or(tf.greater(coord2_old_nn, shape[1]-1), tf.less(coord2_old_nn, 0))\n        outside_ind = tf.logical_or(outside_ind1, outside_ind2)\n\n        coord1_vec = tf.boolean_mask(coord1_vec, tf.logical_not(outside_ind))\n        coord2_vec = tf.boolean_mask(coord2_vec, tf.logical_not(outside_ind))\n\n        # Coordinates of the new image\n        coord_new = tf.transpose(tf.cast(tf.pack([coord1_vec, coord2_vec]), tf.int32), [1, 0])\n\n        coord1_old_nn0 = tf.floor(coord1_old_nn)\n        coord2_old_nn0 = tf.floor(coord2_old_nn)\n        sx = coord1_old_nn - coord1_old_nn0\n        sy = coord2_old_nn - coord2_old_nn0\n        coord1_old_nn0 = tf.cast(coord1_old_nn0, tf.int32)\n        coord2_old_nn0 = tf.cast(coord2_old_nn0, tf.int32)\n        coord1_old_nn0 = tf.boolean_mask(coord1_old_nn0, tf.logical_not(outside_ind))\n        coord2_old_nn0 = tf.boolean_mask(coord2_old_nn0, tf.logical_not(outside_ind))\n        coord1_old_nn1 = coord1_old_nn0 + 1\n        coord2_old_nn1 = coord2_old_nn0 + 1\n        interp_coords = [\n            ((1.-sx) * (1.-sy), coord1_old_nn0, coord2_old_nn0),\n            (    sx  * (1.-sy), coord1_old_nn1, coord2_old_nn0),\n            ((1.-sx) *     sy,  coord1_old_nn0, coord2_old_nn1),\n            (    sx  *     sy,  coord1_old_nn1, coord2_old_nn1)\n        ]\n\n        interp_old = []\n        for intensity, coord1, coord2 in interp_coords:\n            intensity = tf.transpose(tf.reshape(intensity, [shape[1], shape[0]]))\n            coord_old_clipped = tf.transpose(tf.pack([coord1, coord2]), [1, 0])\n            interp_old.append((intensity, coord_old_clipped))\n\n        channels = tf.split(2, shape[2], image)\n        image_rotated_channel_list = list()\n        for channel in channels:\n            channel = tf.squeeze(channel)\n            interp_intensities = []\n            for intensity, coord_old_clipped in interp_old:\n                image_chan_new_values = tf.gather_nd(channel, coord_old_clipped)\n\n                channel_values = tf.sparse_to_dense(coord_new, [shape[0], shape[1]], image_chan_new_values,\n                                                    0, validate_indices=False)\n\n                interp_intensities.append(channel_values * intensity)\n            image_rotated_channel_list.append(tf.add_n(interp_intensities))\n\n        image_rotated = tf.transpose(tf.pack(image_rotated_channel_list), [1, 2, 0])\n\n        return image_rotated", "body": "```python\r\ndef rotate(image, angle):\r\n    with tf.name_scope('rotate'):\r\n        image = tf.cast(image, tf.float32)\r\n        angle = angle / 180 * math.pi\r\n        shape = image.get_shape().as_list()\r\n        assert len(shape) == 3, \"Input needs to be 3D.\"\r\n        image_center = np.array([x/2 for x in shape][:-1])\r\n\r\n        coord1 = tf.cast(tf.range(shape[0]), tf.float32)\r\n        coord2 = tf.cast(tf.range(shape[1]), tf.float32)\r\n\r\n        # Create vectors of those coordinates in order to vectorize the image\r\n        coord1_vec = tf.tile(coord1, [shape[1]])\r\n\r\n        coord2_vec_unordered = tf.tile(coord2, [shape[0]])\r\n        coord2_vec_unordered = tf.reshape(coord2_vec_unordered, [shape[0], shape[1]])\r\n        coord2_vec = tf.reshape(tf.transpose(coord2_vec_unordered, [1, 0]), [-1])\r\n\r\n        # center coordinates since rotation center is supposed to be in the image center\r\n        coord1_vec_centered = coord1_vec - image_center[0]\r\n        coord2_vec_centered = coord2_vec - image_center[1]\r\n\r\n        coord_new_centered = tf.cast(tf.pack([coord1_vec_centered, coord2_vec_centered]), tf.float32)\r\n\r\n        # Perform backward transformation of the image coordinates\r\n        rot_mat_inv = tf.expand_dims(tf.pack([tf.cos(angle), tf.sin(angle), -tf.sin(angle), tf.cos(angle)]), 0)\r\n        rot_mat_inv = tf.cast(tf.reshape(rot_mat_inv, shape=[2, 2]), tf.float32)\r\n        coord_old_centered = tf.matmul(rot_mat_inv, coord_new_centered)\r\n\r\n        # Find neighbors in old image\r\n        coord1_old_nn = coord_old_centered[0, :] + image_center[0]\r\n        coord2_old_nn = coord_old_centered[1, :] + image_center[1]\r\n\r\n        # Clip values to stay inside image coordinates\r\n        outside_ind1 = tf.logical_or(tf.greater(coord1_old_nn, shape[0]-1), tf.less(coord1_old_nn, 0))\r\n        outside_ind2 = tf.logical_or(tf.greater(coord2_old_nn, shape[1]-1), tf.less(coord2_old_nn, 0))\r\n        outside_ind = tf.logical_or(outside_ind1, outside_ind2)\r\n\r\n        coord1_vec = tf.boolean_mask(coord1_vec, tf.logical_not(outside_ind))\r\n        coord2_vec = tf.boolean_mask(coord2_vec, tf.logical_not(outside_ind))\r\n\r\n        # Coordinates of the new image\r\n        coord_new = tf.transpose(tf.cast(tf.pack([coord1_vec, coord2_vec]), tf.int32), [1, 0])\r\n\r\n        coord1_old_nn0 = tf.floor(coord1_old_nn)\r\n        coord2_old_nn0 = tf.floor(coord2_old_nn)\r\n        sx = coord1_old_nn - coord1_old_nn0\r\n        sy = coord2_old_nn - coord2_old_nn0\r\n        coord1_old_nn0 = tf.cast(coord1_old_nn0, tf.int32)\r\n        coord2_old_nn0 = tf.cast(coord2_old_nn0, tf.int32)\r\n        coord1_old_nn0 = tf.boolean_mask(coord1_old_nn0, tf.logical_not(outside_ind))\r\n        coord2_old_nn0 = tf.boolean_mask(coord2_old_nn0, tf.logical_not(outside_ind))\r\n        coord1_old_nn1 = coord1_old_nn0 + 1\r\n        coord2_old_nn1 = coord2_old_nn0 + 1\r\n        interp_coords = [\r\n            ((1.-sx) * (1.-sy), coord1_old_nn0, coord2_old_nn0),\r\n            (    sx  * (1.-sy), coord1_old_nn1, coord2_old_nn0),\r\n            ((1.-sx) *     sy,  coord1_old_nn0, coord2_old_nn1),\r\n            (    sx  *     sy,  coord1_old_nn1, coord2_old_nn1)\r\n        ]\r\n\r\n        interp_old = []\r\n        for intensity, coord1, coord2 in interp_coords:\r\n            intensity = tf.transpose(tf.reshape(intensity, [shape[1], shape[0]]))\r\n            coord_old_clipped = tf.transpose(tf.pack([coord1, coord2]), [1, 0])\r\n            interp_old.append((intensity, coord_old_clipped))\r\n\r\n        channels = tf.split(2, shape[2], image)\r\n        image_rotated_channel_list = list()\r\n        for channel in channels:\r\n            channel = tf.squeeze(channel)\r\n            interp_intensities = []\r\n            for intensity, coord_old_clipped in interp_old:\r\n                image_chan_new_values = tf.gather_nd(channel, coord_old_clipped)\r\n\r\n                channel_values = tf.sparse_to_dense(coord_new, [shape[0], shape[1]], image_chan_new_values,\r\n                                                    0, validate_indices=False)\r\n\r\n                interp_intensities.append(channel_values * intensity)\r\n            image_rotated_channel_list.append(tf.add_n(interp_intensities))\r\n\r\n        image_rotated = tf.transpose(tf.pack(image_rotated_channel_list), [1, 2, 0])\r\n\r\n        return image_rotated\r\n```"}