{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290885971", "html_url": "https://github.com/tensorflow/tensorflow/issues/8870#issuecomment-290885971", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8870", "id": 290885971, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDg4NTk3MQ==", "user": {"login": "zzw922cn", "id": 11649939, "node_id": "MDQ6VXNlcjExNjQ5OTM5", "avatar_url": "https://avatars3.githubusercontent.com/u/11649939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zzw922cn", "html_url": "https://github.com/zzw922cn", "followers_url": "https://api.github.com/users/zzw922cn/followers", "following_url": "https://api.github.com/users/zzw922cn/following{/other_user}", "gists_url": "https://api.github.com/users/zzw922cn/gists{/gist_id}", "starred_url": "https://api.github.com/users/zzw922cn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zzw922cn/subscriptions", "organizations_url": "https://api.github.com/users/zzw922cn/orgs", "repos_url": "https://api.github.com/users/zzw922cn/repos", "events_url": "https://api.github.com/users/zzw922cn/events{/privacy}", "received_events_url": "https://api.github.com/users/zzw922cn/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-01T02:00:10Z", "updated_at": "2017-04-01T02:02:13Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> Ok, my code is as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>q <span class=\"pl-k\">=</span> tf.FIFOQueue(<span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">dtypes</span><span class=\"pl-k\">=</span>tf.float32) \nenqueue_op <span class=\"pl-k\">=</span> q.enqueue(x)\nnum_threads <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> \nqr <span class=\"pl-k\">=</span> tf.train.QueueRunner(q, [enqueue_op] <span class=\"pl-k\">*</span> num_threads)\ntf.train.add_queue_runner(qr)\ninputs <span class=\"pl-k\">=</span> q.dequeue() \n<span class=\"pl-c\"><span class=\"pl-c\">#</span>inputs.set_shape(x.get_shape())</span>\ny <span class=\"pl-k\">=</span> tf.reduce_mean(tf.reduce_sum(inputs, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">keep_dims</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nlabels <span class=\"pl-k\">=</span> tf.cast(tf.greater(y, <span class=\"pl-c1\">0</span>), tf.int32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span># build model</span>\nsequence_length <span class=\"pl-k\">=</span> tf.Variable([time_length]<span class=\"pl-k\">*</span>batch_size, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\ncell_fw <span class=\"pl-k\">=</span> LSTMCell(<span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span>hidden_size)\ncell_bw <span class=\"pl-k\">=</span> LSTMCell(<span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span>hidden_size)\noutputs, state <span class=\"pl-k\">=</span> tf.nn.bidirectional_dynamic_rnn(\n      <span class=\"pl-v\">cell_fw</span><span class=\"pl-k\">=</span>cell_fw,\n      <span class=\"pl-v\">cell_bw</span><span class=\"pl-k\">=</span>cell_bw,\n      <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>inputs, \n      <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>sequence_length,\n      <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n      <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>error is</p>\n<div class=\"highlight highlight-source-python\"><pre>Traceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test1.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">32</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    time_major<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">350</span>, <span class=\"pl-k\">in</span> bidirectional_dynamic_rnn\n    time_major<span class=\"pl-k\">=</span>time_major, scope<span class=\"pl-k\">=</span>fw_scope)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">546</span>, <span class=\"pl-k\">in</span> dynamic_rnn\n    dtype<span class=\"pl-k\">=</span>dtype)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">615</span>, <span class=\"pl-k\">in</span> _dynamic_rnn_loop\n    const_time_steps, const_batch_size <span class=\"pl-k\">=</span> inputs_got_shape[<span class=\"pl-c1\">0</span>].as_list()[:<span class=\"pl-c1\">2</span>]\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">761</span>, <span class=\"pl-k\">in</span> as_list\n    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>as_list() is not defined on an unknown TensorShape.<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">ValueError</span>: as_list() <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> defined on an unknown TensorShape.</pre></div>\n<p>and I think the error is caused by BLSTM, maybe the set_shape bug should be fixed.</p>", "body_text": "@mrry Ok, my code is as follows:\nq = tf.FIFOQueue(capacity=4, dtypes=tf.float32) \nenqueue_op = q.enqueue(x)\nnum_threads = 1 \nqr = tf.train.QueueRunner(q, [enqueue_op] * num_threads)\ntf.train.add_queue_runner(qr)\ninputs = q.dequeue() \n#inputs.set_shape(x.get_shape())\ny = tf.reduce_mean(tf.reduce_sum(inputs, axis=0), axis=1, keep_dims=True)\nlabels = tf.cast(tf.greater(y, 0), tf.int32)\n\n## build model\nsequence_length = tf.Variable([time_length]*batch_size, dtype=tf.int32)\ncell_fw = LSTMCell(num_units=hidden_size)\ncell_bw = LSTMCell(num_units=hidden_size)\noutputs, state = tf.nn.bidirectional_dynamic_rnn(\n      cell_fw=cell_fw,\n      cell_bw=cell_bw,\n      inputs=inputs, \n      sequence_length=sequence_length,\n      dtype=tf.float32,\n      time_major=True)\nerror is\nTraceback (most recent call last):\n  File \"test1.py\", line 32, in <module>\n    time_major=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 350, in bidirectional_dynamic_rnn\n    time_major=time_major, scope=fw_scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 546, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 615, in _dynamic_rnn_loop\n    const_time_steps, const_batch_size = inputs_got_shape[0].as_list()[:2]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 761, in as_list\n    raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\nValueError: as_list() is not defined on an unknown TensorShape.\nand I think the error is caused by BLSTM, maybe the set_shape bug should be fixed.", "body": "@mrry Ok, my code is as follows:\r\n```python\r\nq = tf.FIFOQueue(capacity=4, dtypes=tf.float32) \r\nenqueue_op = q.enqueue(x)\r\nnum_threads = 1 \r\nqr = tf.train.QueueRunner(q, [enqueue_op] * num_threads)\r\ntf.train.add_queue_runner(qr)\r\ninputs = q.dequeue() \r\n#inputs.set_shape(x.get_shape())\r\ny = tf.reduce_mean(tf.reduce_sum(inputs, axis=0), axis=1, keep_dims=True)\r\nlabels = tf.cast(tf.greater(y, 0), tf.int32)\r\n\r\n## build model\r\nsequence_length = tf.Variable([time_length]*batch_size, dtype=tf.int32)\r\ncell_fw = LSTMCell(num_units=hidden_size)\r\ncell_bw = LSTMCell(num_units=hidden_size)\r\noutputs, state = tf.nn.bidirectional_dynamic_rnn(\r\n      cell_fw=cell_fw,\r\n      cell_bw=cell_bw,\r\n      inputs=inputs, \r\n      sequence_length=sequence_length,\r\n      dtype=tf.float32,\r\n      time_major=True)\r\n```\r\n\r\nerror is\r\n```python\r\nTraceback (most recent call last):\r\n  File \"test1.py\", line 32, in <module>\r\n    time_major=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 350, in bidirectional_dynamic_rnn\r\n    time_major=time_major, scope=fw_scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 546, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 615, in _dynamic_rnn_loop\r\n    const_time_steps, const_batch_size = inputs_got_shape[0].as_list()[:2]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 761, in as_list\r\n    raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\nValueError: as_list() is not defined on an unknown TensorShape.\r\n```\r\n and I think the error is caused by BLSTM, maybe the set_shape bug should be fixed."}