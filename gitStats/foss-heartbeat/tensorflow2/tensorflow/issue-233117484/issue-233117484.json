{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10390", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10390/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10390/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10390/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10390", "id": 233117484, "node_id": "MDU6SXNzdWUyMzMxMTc0ODQ=", "number": 10390, "title": "error \uff0ca configure error! help!", "user": {"login": "lulinyuan", "id": 24367032, "node_id": "MDQ6VXNlcjI0MzY3MDMy", "avatar_url": "https://avatars3.githubusercontent.com/u/24367032?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lulinyuan", "html_url": "https://github.com/lulinyuan", "followers_url": "https://api.github.com/users/lulinyuan/followers", "following_url": "https://api.github.com/users/lulinyuan/following{/other_user}", "gists_url": "https://api.github.com/users/lulinyuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/lulinyuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lulinyuan/subscriptions", "organizations_url": "https://api.github.com/users/lulinyuan/orgs", "repos_url": "https://api.github.com/users/lulinyuan/repos", "events_url": "https://api.github.com/users/lulinyuan/events{/privacy}", "received_events_url": "https://api.github.com/users/lulinyuan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-02T08:52:38Z", "updated_at": "2017-06-03T17:52:07Z", "closed_at": "2017-06-02T19:09:40Z", "author_association": "NONE", "body_html": "<p>\u279c  tensorflow git:(master) \u2717 ./configure<br>\nPlease specify the location of python. [Default is /usr/bin/python]:<br>\nFound possible Python library paths:<br>\n/opt/ros/kinetic/lib/python2.7/dist-packages<br>\n/usr/local/lib/python2.7/dist-packages<br>\n/usr/lib/python2.7/dist-packages<br>\nPlease input the desired Python library path to use.  Default is [/opt/ros/kinetic/lib/python2.7/dist-packages]</p>\n<p>Using python library path: /opt/ros/kinetic/lib/python2.7/dist-packages<br>\nDo you wish to build TensorFlow with MKL support? [y/N]<br>\nNo MKL support will be enabled for TensorFlow<br>\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:<br>\nDo you wish to use jemalloc as the malloc implementation? [Y/n]<br>\njemalloc enabled<br>\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]<br>\nNo Google Cloud Platform support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]<br>\nNo Hadoop File System support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]<br>\nNo XLA support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with VERBS support? [y/N]<br>\nNo VERBS support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with OpenCL support? [y/N]<br>\nNo OpenCL support will be enabled for TensorFlow<br>\nDo you wish to build TensorFlow with CUDA support? [y/N] u<br>\nInvalid selection:  u<br>\nDo you wish to build TensorFlow with CUDA support? [y/N] y<br>\nCUDA support will be enabled for TensorFlow<br>\nDo you want to use clang as CUDA compiler? [y/N] n<br>\nnvcc will be used as CUDA compiler<br>\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0<br>\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:<br>\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:<br>\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]:<br>\nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:<br>\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.<br>\nYou can find the compute capability of your device at: <a href=\"https://developer.nvidia.com/cuda-gpus\" rel=\"nofollow\">https://developer.nvidia.com/cuda-gpus</a>.<br>\nPlease note that each additional compute capability significantly increases your build time and binary size.<br>\n[Default is: \"3.5,5.2\"]:<br>\nDo you wish to build TensorFlow with MPI support? [y/N] n<br>\nMPI support will not be enabled for TensorFlow<br>\nINFO: Options provided by the client:<br>\nInherited 'common' options: --isatty=1 --terminal_columns=80<br>\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/tools/bazel.rc:<br>\nInherited 'build' options: --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --genrule_strategy=standalone -c opt<br>\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/.tf_configure.bazelrc:<br>\nInherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --define PYTHON_BIN_PATH=/usr/bin/python --define PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --force_python=py2 --host_force_python=py2 --python2_path=/usr/bin/python --define with_jemalloc=true --action_env TF_NEED_CUDA=1 --action_env TF_NEED_OPENCL=0 --action_env TF_CUDA_CLANG=0 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_VERSION=8.0 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc --action_env TF_CUDNN_VERSION= --action_env CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2<br>\nUnrecognized option: --action_env</p>\n<p>bazel is 0.3.0;cuda8.0;cudnn5.0.</p>", "body_text": "\u279c  tensorflow git:(master) \u2717 ./configure\nPlease specify the location of python. [Default is /usr/bin/python]:\nFound possible Python library paths:\n/opt/ros/kinetic/lib/python2.7/dist-packages\n/usr/local/lib/python2.7/dist-packages\n/usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/opt/ros/kinetic/lib/python2.7/dist-packages]\nUsing python library path: /opt/ros/kinetic/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with MKL support? [y/N]\nNo MKL support will be enabled for TensorFlow\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]\nNo XLA support will be enabled for TensorFlow\nDo you wish to build TensorFlow with VERBS support? [y/N]\nNo VERBS support will be enabled for TensorFlow\nDo you wish to build TensorFlow with OpenCL support? [y/N]\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] u\nInvalid selection:  u\nDo you wish to build TensorFlow with CUDA support? [y/N] y\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N] n\nnvcc will be used as CUDA compiler\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]:\nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]:\nDo you wish to build TensorFlow with MPI support? [y/N] n\nMPI support will not be enabled for TensorFlow\nINFO: Options provided by the client:\nInherited 'common' options: --isatty=1 --terminal_columns=80\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/tools/bazel.rc:\nInherited 'build' options: --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --genrule_strategy=standalone -c opt\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/.tf_configure.bazelrc:\nInherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --define PYTHON_BIN_PATH=/usr/bin/python --define PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --force_python=py2 --host_force_python=py2 --python2_path=/usr/bin/python --define with_jemalloc=true --action_env TF_NEED_CUDA=1 --action_env TF_NEED_OPENCL=0 --action_env TF_CUDA_CLANG=0 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_VERSION=8.0 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc --action_env TF_CUDNN_VERSION= --action_env CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2\nUnrecognized option: --action_env\nbazel is 0.3.0;cuda8.0;cudnn5.0.", "body": "\r\n\u279c  tensorflow git:(master) \u2717 ./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nFound possible Python library paths:\r\n  /opt/ros/kinetic/lib/python2.7/dist-packages\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/opt/ros/kinetic/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /opt/ros/kinetic/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N] \r\nNo MKL support will be enabled for TensorFlow\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nDo you wish to use jemalloc as the malloc implementation? [Y/n] \r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N] \r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] u\r\nInvalid selection:  u\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N] n\r\nnvcc will be used as CUDA compiler\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]: \r\nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: \r\nDo you wish to build TensorFlow with MPI support? [y/N] n\r\nMPI support will not be enabled for TensorFlow\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=80\r\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/tools/bazel.rc:\r\n  Inherited 'build' options: --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --genrule_strategy=standalone -c opt\r\nINFO: Reading options for 'clean' from /home/lulin/tensorflow/.tf_configure.bazelrc:\r\n  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --define PYTHON_BIN_PATH=/usr/bin/python --define PYTHON_LIB_PATH=/opt/ros/kinetic/lib/python2.7/dist-packages --force_python=py2 --host_force_python=py2 --python2_path=/usr/bin/python --define with_jemalloc=true --action_env TF_NEED_CUDA=1 --action_env TF_NEED_OPENCL=0 --action_env TF_CUDA_CLANG=0 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_VERSION=8.0 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc --action_env TF_CUDNN_VERSION= --action_env CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2\r\nUnrecognized option: --action_env\r\n\r\n\r\nbazel is 0.3.0;cuda8.0;cudnn5.0.\r\n\r\n"}