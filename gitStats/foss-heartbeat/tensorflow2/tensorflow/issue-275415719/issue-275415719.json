{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14729", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14729/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14729/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14729/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14729", "id": 275415719, "node_id": "MDU6SXNzdWUyNzU0MTU3MTk=", "number": 14729, "title": "Unhelpful error for dynamic_rnn in version 1.4.0", "user": {"login": "parsa-saadatpanah", "id": 5870935, "node_id": "MDQ6VXNlcjU4NzA5MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5870935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parsa-saadatpanah", "html_url": "https://github.com/parsa-saadatpanah", "followers_url": "https://api.github.com/users/parsa-saadatpanah/followers", "following_url": "https://api.github.com/users/parsa-saadatpanah/following{/other_user}", "gists_url": "https://api.github.com/users/parsa-saadatpanah/gists{/gist_id}", "starred_url": "https://api.github.com/users/parsa-saadatpanah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parsa-saadatpanah/subscriptions", "organizations_url": "https://api.github.com/users/parsa-saadatpanah/orgs", "repos_url": "https://api.github.com/users/parsa-saadatpanah/repos", "events_url": "https://api.github.com/users/parsa-saadatpanah/events{/privacy}", "received_events_url": "https://api.github.com/users/parsa-saadatpanah/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-11-20T16:26:40Z", "updated_at": "2018-10-01T13:07:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>This code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nx <span class=\"pl-k\">=</span> tf.constant([\n\t\t[[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>],[<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">0</span>]],\n\t\t[[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>],[<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>]]\n\t], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32) <span class=\"pl-c\"><span class=\"pl-c\">#</span>changing this to tf.float32 solves the problem</span>\n\n\ncell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.LSTMCell(<span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">15</span>) \ninitial_state <span class=\"pl-k\">=</span> cell.zero_state(tf.shape(x)[<span class=\"pl-c1\">0</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\noutputs, state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(cell, x, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>initial_state, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\ninit_op <span class=\"pl-k\">=</span> tf.group(tf.global_variables_initializer(),\n\t\ttf.local_variables_initializer())\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n\tsess.run(init_op)\n\t<span class=\"pl-c1\">print</span>(sess.run([outputs, state]))</pre></div>\n<p>Does not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:</p>\n<pre><code>ValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.\n</code></pre>\n<p>Which has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:</p>\n<pre><code>TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.\n</code></pre>", "body_text": "This code:\nimport tensorflow as tf\n\nx = tf.constant([\n\t\t[[0,0],[5,0],[1,0],[1,0],[2,3],[4,0]],\n\t\t[[0,0],[0,0],[1,3],[2,0],[0,0],[0,0]]\n\t], dtype=tf.int32) #changing this to tf.float32 solves the problem\n\n\ncell = tf.nn.rnn_cell.LSTMCell(num_units=15) \ninitial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)\noutputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)\n\ninit_op = tf.group(tf.global_variables_initializer(),\n\t\ttf.local_variables_initializer())\n\nwith tf.Session() as sess:\n\tsess.run(init_op)\n\tprint(sess.run([outputs, state]))\nDoes not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:\nValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.\n\nWhich has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.", "body": "This code:\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.constant([\r\n\t\t[[0,0],[5,0],[1,0],[1,0],[2,3],[4,0]],\r\n\t\t[[0,0],[0,0],[1,3],[2,0],[0,0],[0,0]]\r\n\t], dtype=tf.int32) #changing this to tf.float32 solves the problem\r\n\r\n\r\ncell = tf.nn.rnn_cell.LSTMCell(num_units=15) \r\ninitial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)\r\noutputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)\r\n\r\ninit_op = tf.group(tf.global_variables_initializer(),\r\n\t\ttf.local_variables_initializer())\r\n\r\nwith tf.Session() as sess:\r\n\tsess.run(init_op)\r\n\tprint(sess.run([outputs, state]))\r\n```\r\nDoes not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:\r\n```\r\nValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.\r\n```\r\nWhich has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:\r\n```\r\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.\r\n```\r\n"}