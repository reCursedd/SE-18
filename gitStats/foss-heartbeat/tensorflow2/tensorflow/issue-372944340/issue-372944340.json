{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23187", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23187/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23187/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23187/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23187", "id": 372944340, "node_id": "MDU6SXNzdWUzNzI5NDQzNDA=", "number": 23187, "title": "Error : Check failed: IsConstantParameterArray", "user": {"login": "Jeong-Heon", "id": 44399317, "node_id": "MDQ6VXNlcjQ0Mzk5MzE3", "avatar_url": "https://avatars2.githubusercontent.com/u/44399317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jeong-Heon", "html_url": "https://github.com/Jeong-Heon", "followers_url": "https://api.github.com/users/Jeong-Heon/followers", "following_url": "https://api.github.com/users/Jeong-Heon/following{/other_user}", "gists_url": "https://api.github.com/users/Jeong-Heon/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jeong-Heon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jeong-Heon/subscriptions", "organizations_url": "https://api.github.com/users/Jeong-Heon/orgs", "repos_url": "https://api.github.com/users/Jeong-Heon/repos", "events_url": "https://api.github.com/users/Jeong-Heon/events{/privacy}", "received_events_url": "https://api.github.com/users/Jeong-Heon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "liyunlu0618", "id": 9705880, "node_id": "MDQ6VXNlcjk3MDU4ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9705880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liyunlu0618", "html_url": "https://github.com/liyunlu0618", "followers_url": "https://api.github.com/users/liyunlu0618/followers", "following_url": "https://api.github.com/users/liyunlu0618/following{/other_user}", "gists_url": "https://api.github.com/users/liyunlu0618/gists{/gist_id}", "starred_url": "https://api.github.com/users/liyunlu0618/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liyunlu0618/subscriptions", "organizations_url": "https://api.github.com/users/liyunlu0618/orgs", "repos_url": "https://api.github.com/users/liyunlu0618/repos", "events_url": "https://api.github.com/users/liyunlu0618/events{/privacy}", "received_events_url": "https://api.github.com/users/liyunlu0618/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-10-23T11:13:07Z", "updated_at": "2018-11-13T18:55:18Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No<br>\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.5 LTS<br>\nTensorFlow installed from (source or binary): binary<br>\nTensorFlow version (use command below): 1.13.0-dev20181023<br>\nPython version:<br>\nBazel version (if compiling from source):<br>\nGCC/Compiler version (if compiling from source):<br>\nCUDA/cuDNN version: 9.0.176 / 9<br>\nGPU model and memory: GeForce GTX 1080ti / 11175MiB</p>\n<p><strong>Describe the current behavior</strong></p>\n<p>I want to convert a custom graph from TF to TFLite using 'TFLiteconverter'<br>\nbut I faced below error:</p>\n<blockquote>\n<p>tensorflow.contrib.lite.python.convert.ConverterError: TOCO failed. See console for info.<br>\n2018-10-23 10:13:26.786330: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 784 operators, 1332 arrays (0 quantized)<br>\n2018-10-23 10:13:26.797260: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 511 operators, 912 arrays (0 quantized)<br>\n2018-10-23 10:13:26.806327: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 511 operators, 912 arrays (0 quantized)<br>\n2018-10-23 10:13:26.806920: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op-&gt;inputs[1]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[2]) &amp;&amp; IsConstantParameterArray(*model, bn_op-&gt;inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.<br>\nAborted (core dumped)</p>\n</blockquote>\n<p>How can I fix it?</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<pre><code>import tensorflow as tf\n\ngraph_def_file = \"/path/graph.pb\"\ninput_arrays = [\"Placeholder\"]\noutput_arrays = [\"final\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\n  graph_def_file, input_arrays, output_arrays)\nconverter.inference_type = tf.contrib.lite.constants.FLOAT\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>", "body_text": "System information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.5 LTS\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.13.0-dev20181023\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0.176 / 9\nGPU model and memory: GeForce GTX 1080ti / 11175MiB\nDescribe the current behavior\nI want to convert a custom graph from TF to TFLite using 'TFLiteconverter'\nbut I faced below error:\n\ntensorflow.contrib.lite.python.convert.ConverterError: TOCO failed. See console for info.\n2018-10-23 10:13:26.786330: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 784 operators, 1332 arrays (0 quantized)\n2018-10-23 10:13:26.797260: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 511 operators, 912 arrays (0 quantized)\n2018-10-23 10:13:26.806327: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 511 operators, 912 arrays (0 quantized)\n2018-10-23 10:13:26.806920: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\nAborted (core dumped)\n\nHow can I fix it?\nCode to reproduce the issue\nimport tensorflow as tf\n\ngraph_def_file = \"/path/graph.pb\"\ninput_arrays = [\"Placeholder\"]\noutput_arrays = [\"final\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\n  graph_def_file, input_arrays, output_arrays)\nconverter.inference_type = tf.contrib.lite.constants.FLOAT\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)", "body": "**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.5 LTS \r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.13.0-dev20181023\r\nPython version: \r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 9.0.176 / 9\r\nGPU model and memory: GeForce GTX 1080ti / 11175MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI want to convert a custom graph from TF to TFLite using 'TFLiteconverter'\r\nbut I faced below error:\r\n\r\n> tensorflow.contrib.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n> 2018-10-23 10:13:26.786330: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 784 operators, 1332 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.797260: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 511 operators, 912 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.806327: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 511 operators, 912 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.806920: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\n> Aborted (core dumped)\r\n> \r\n\r\nHow can I fix it?\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"/path/graph.pb\"\r\ninput_arrays = [\"Placeholder\"]\r\noutput_arrays = [\"final\"]\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\r\n  graph_def_file, input_arrays, output_arrays)\r\nconverter.inference_type = tf.contrib.lite.constants.FLOAT\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n"}