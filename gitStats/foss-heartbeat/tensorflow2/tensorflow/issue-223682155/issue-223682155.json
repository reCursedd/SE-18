{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9398", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9398/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9398/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9398/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9398", "id": 223682155, "node_id": "MDU6SXNzdWUyMjM2ODIxNTU=", "number": 9398, "title": "Tf.gradients returning all zeroes when called on result of a tf.gradient call", "user": {"login": "rkjones4", "id": 10440535, "node_id": "MDQ6VXNlcjEwNDQwNTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/10440535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rkjones4", "html_url": "https://github.com/rkjones4", "followers_url": "https://api.github.com/users/rkjones4/followers", "following_url": "https://api.github.com/users/rkjones4/following{/other_user}", "gists_url": "https://api.github.com/users/rkjones4/gists{/gist_id}", "starred_url": "https://api.github.com/users/rkjones4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rkjones4/subscriptions", "organizations_url": "https://api.github.com/users/rkjones4/orgs", "repos_url": "https://api.github.com/users/rkjones4/repos", "events_url": "https://api.github.com/users/rkjones4/events{/privacy}", "received_events_url": "https://api.github.com/users/rkjones4/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-04-24T01:09:31Z", "updated_at": "2017-04-24T16:26:44Z", "closed_at": "2017-04-24T16:26:40Z", "author_association": "NONE", "body_html": "<p>I have the following code snippet:</p>\n<p>interpolates = alpha*real_data + ((1-alpha)*fake_data)<br>\ndisc_interpolates = Discriminator(interpolates)<br>\ngradients = tf.gradients(disc_interpolates, [interpolates])[0]<br>\nsecond_grad = tf.gradients(gradients[0], [interpolates])[0]</p>\n<p>Where Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes.</p>\n<p>Is this expected behavior or should I be able to find the second derivatives of my neural net?</p>", "body_text": "I have the following code snippet:\ninterpolates = alpha*real_data + ((1-alpha)*fake_data)\ndisc_interpolates = Discriminator(interpolates)\ngradients = tf.gradients(disc_interpolates, [interpolates])[0]\nsecond_grad = tf.gradients(gradients[0], [interpolates])[0]\nWhere Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes.\nIs this expected behavior or should I be able to find the second derivatives of my neural net?", "body": "I have the following code snippet:\r\n\r\ninterpolates = alpha*real_data + ((1-alpha)*fake_data)\r\ndisc_interpolates = Discriminator(interpolates)\r\ngradients = tf.gradients(disc_interpolates, [interpolates])[0]\r\nsecond_grad = tf.gradients(gradients[0], [interpolates])[0]\r\n\r\nWhere Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes. \r\n\r\nIs this expected behavior or should I be able to find the second derivatives of my neural net? "}