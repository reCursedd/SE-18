{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/418008118", "html_url": "https://github.com/tensorflow/tensorflow/issues/21725#issuecomment-418008118", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21725", "id": 418008118, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODAwODExOA==", "user": {"login": "sepulm01", "id": 33760447, "node_id": "MDQ6VXNlcjMzNzYwNDQ3", "avatar_url": "https://avatars3.githubusercontent.com/u/33760447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sepulm01", "html_url": "https://github.com/sepulm01", "followers_url": "https://api.github.com/users/sepulm01/followers", "following_url": "https://api.github.com/users/sepulm01/following{/other_user}", "gists_url": "https://api.github.com/users/sepulm01/gists{/gist_id}", "starred_url": "https://api.github.com/users/sepulm01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sepulm01/subscriptions", "organizations_url": "https://api.github.com/users/sepulm01/orgs", "repos_url": "https://api.github.com/users/sepulm01/repos", "events_url": "https://api.github.com/users/sepulm01/events{/privacy}", "received_events_url": "https://api.github.com/users/sepulm01/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-03T05:58:31Z", "updated_at": "2018-09-03T05:58:31Z", "author_association": "NONE", "body_html": "<p>Hi, I have the same issue \"Array TFLite_Detection_PostProcess does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\"<br>\nMy tensorflow version is 1.10.1 with GPU. I've training my data with ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config in Google Machine Learning (TPU).<br>\nThe exported method that I use is object_detection/export_tflite_ssd_graph.py, I did TOCO with  \"pet breeds dataset\" example and TOCO works well. My problem is when I try to use TOCO with my own data set. I did the very same process for both data set (my own and TF example). The frozen graph with my own data set woks well in my computer (object_detection/export_inference_graph.py).</p>\n<p>TOCO command:<br>\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- <br>\n--input_file=$OUTPUT_DIR/tflite_graph.pb <br>\n--output_file=$OUTPUT_DIR/detect.tflite <br>\n--input_shapes=1,300,300,3 <br>\n--input_arrays=normalized_input_image_tensor <br>\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--mean_values=128 <br>\n--std_values=128 <br>\n--change_concat_input_ranges=false <br>\n--allow_custom_ops</p>\n<p>best regards.</p>", "body_text": "Hi, I have the same issue \"Array TFLite_Detection_PostProcess does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\"\nMy tensorflow version is 1.10.1 with GPU. I've training my data with ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config in Google Machine Learning (TPU).\nThe exported method that I use is object_detection/export_tflite_ssd_graph.py, I did TOCO with  \"pet breeds dataset\" example and TOCO works well. My problem is when I try to use TOCO with my own data set. I did the very same process for both data set (my own and TF example). The frozen graph with my own data set woks well in my computer (object_detection/export_inference_graph.py).\nTOCO command:\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \n--input_file=$OUTPUT_DIR/tflite_graph.pb \n--output_file=$OUTPUT_DIR/detect.tflite \n--input_shapes=1,300,300,3 \n--input_arrays=normalized_input_image_tensor \n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \n--inference_type=QUANTIZED_UINT8 \n--mean_values=128 \n--std_values=128 \n--change_concat_input_ranges=false \n--allow_custom_ops\nbest regards.", "body": "Hi, I have the same issue \"Array TFLite_Detection_PostProcess does not have MinMax information, and is not a constant array. Cannot proceed with quantization.\"\r\nMy tensorflow version is 1.10.1 with GPU. I've training my data with ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config in Google Machine Learning (TPU). \r\n The exported method that I use is object_detection/export_tflite_ssd_graph.py, I did TOCO with  \"pet breeds dataset\" example and TOCO works well. My problem is when I try to use TOCO with my own data set. I did the very same process for both data set (my own and TF example). The frozen graph with my own data set woks well in my computer (object_detection/export_inference_graph.py). \r\n\r\nTOCO command:\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_values=128 \\\r\n--change_concat_input_ranges=false \\\r\n--allow_custom_ops\r\n\r\nbest regards."}