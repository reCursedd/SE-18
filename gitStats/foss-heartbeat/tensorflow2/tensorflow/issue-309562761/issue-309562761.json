{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18066", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18066/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18066/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18066/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18066", "id": 309562761, "node_id": "MDU6SXNzdWUzMDk1NjI3NjE=", "number": 18066, "title": "Lite label_image with Quantized MobileNet reporting varying, incorrect labels for test image", "user": {"login": "andrew-anki", "id": 5142143, "node_id": "MDQ6VXNlcjUxNDIxNDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5142143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrew-anki", "html_url": "https://github.com/andrew-anki", "followers_url": "https://api.github.com/users/andrew-anki/followers", "following_url": "https://api.github.com/users/andrew-anki/following{/other_user}", "gists_url": "https://api.github.com/users/andrew-anki/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrew-anki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrew-anki/subscriptions", "organizations_url": "https://api.github.com/users/andrew-anki/orgs", "repos_url": "https://api.github.com/users/andrew-anki/repos", "events_url": "https://api.github.com/users/andrew-anki/events{/privacy}", "received_events_url": "https://api.github.com/users/andrew-anki/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}, {"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-03-28T23:01:45Z", "updated_at": "2018-05-01T02:47:54Z", "closed_at": "2018-05-01T02:47:54Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: OSX</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.6.0-0-gd2e24b6039 1.6.0</li>\n<li><strong>Python version</strong>: 3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>: [bazel release 0.8.1-homebrew]</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: Apple LLVM version 9.0.0 (clang-900.0.39.2)</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: See below, running Lite's <code>label_image</code> example</li>\n</ul>\n<p>I've set the Android SDK/NDK paths in my WORKSPACE file and I'm cross compiling the Lite <code>label_image</code> binary for my armv7a device as described in the README, without errors:</p>\n<pre><code>bazel build --config android_arm --config monolithic --cxxopt=-std=c++11   //tensorflow/contrib/lite/examples/label_image:label_image\n</code></pre>\n<p>When I run the resulting binary on my device with the stock <code>mobilenet_quant_v1_224.tflite</code> model and Grace Hopper image, I do not get the expected results, with \"military uniform\" at the top of the list. Instead I get:</p>\n<pre><code> # ./label_image\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2153.24 ms \n0.862745: 188 Yorkshire terrier\n0.0862745: 194 Australian terrier\n0.0313726: 187 Norwich terrier\n0.0117647: 202 silky terrier\n0.00784314: 152 Chihuahua\n</code></pre>\n<p>I see the <code>nnapi</code> error about the lack of the <code>libneuralnetworks.so</code>, so is that the culprit here? I had hoped that if the library was missing, it would still run correctly, albeit more slowly, but perhaps that is not the case and the library is 100% required for Lite to work. (If it is truly <em>required</em>, it does seem odd/confusing that the error isn't \"more fatal\" instead of continuing to do forward inference and producing garbage output!)</p>\n<p>Furthermore, when I run with more iterations (via the <code>-c</code> flag), I continue to get the wrong labels, but a <em>different</em> set of incorrect labels depending on the number of iterations. For example, with two iterations:</p>\n<pre><code># ./label_image2 -c 2\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2214.83 ms \n0.345098: 795 shower curtain\n0.109804: 906 window shade\n0.0470588: 563 fountain\n0.0470588: 534 dishrag\n0.0392157: 912 wool\n</code></pre>\n<p>And with three iterations:</p>\n<pre><code># ./label_image2 -c 3\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2407.64 ms \n0.0705882: 906 window shade\n0.0509804: 829 strainer\n0.0509804: 734 pole\n0.0431373: 795 shower curtain\n0.0431373: 620 lampshade\n</code></pre>\n<p>And so on.</p>\n<p>Why does the number of iterations performed affect the output? (Perhaps this is just the same issue as above, due to missing nnapi lib?)</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): v1.6.0-0-gd2e24b6039 1.6.0\nPython version: 3.6.4\nBazel version (if compiling from source): [bazel release 0.8.1-homebrew]\nGCC/Compiler version (if compiling from source): Apple LLVM version 9.0.0 (clang-900.0.39.2)\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: See below, running Lite's label_image example\n\nI've set the Android SDK/NDK paths in my WORKSPACE file and I'm cross compiling the Lite label_image binary for my armv7a device as described in the README, without errors:\nbazel build --config android_arm --config monolithic --cxxopt=-std=c++11   //tensorflow/contrib/lite/examples/label_image:label_image\n\nWhen I run the resulting binary on my device with the stock mobilenet_quant_v1_224.tflite model and Grace Hopper image, I do not get the expected results, with \"military uniform\" at the top of the list. Instead I get:\n # ./label_image\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2153.24 ms \n0.862745: 188 Yorkshire terrier\n0.0862745: 194 Australian terrier\n0.0313726: 187 Norwich terrier\n0.0117647: 202 silky terrier\n0.00784314: 152 Chihuahua\n\nI see the nnapi error about the lack of the libneuralnetworks.so, so is that the culprit here? I had hoped that if the library was missing, it would still run correctly, albeit more slowly, but perhaps that is not the case and the library is 100% required for Lite to work. (If it is truly required, it does seem odd/confusing that the error isn't \"more fatal\" instead of continuing to do forward inference and producing garbage output!)\nFurthermore, when I run with more iterations (via the -c flag), I continue to get the wrong labels, but a different set of incorrect labels depending on the number of iterations. For example, with two iterations:\n# ./label_image2 -c 2\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2214.83 ms \n0.345098: 795 shower curtain\n0.109804: 906 window shade\n0.0470588: 563 fountain\n0.0470588: 534 dishrag\n0.0392157: 912 wool\n\nAnd with three iterations:\n# ./label_image2 -c 3\nnnapi error: unable to open library libneuralnetworks.so\nLoaded model ./mobilenet_quant_v1_224.tflite\nresolved reporter\ninvoked \naverage time: 2407.64 ms \n0.0705882: 906 window shade\n0.0509804: 829 strainer\n0.0509804: 734 pole\n0.0431373: 795 shower curtain\n0.0431373: 620 lampshade\n\nAnd so on.\nWhy does the number of iterations performed affect the output? (Perhaps this is just the same issue as above, due to missing nnapi lib?)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: [bazel release 0.8.1-homebrew]\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: See below, running Lite's `label_image` example\r\n\r\nI've set the Android SDK/NDK paths in my WORKSPACE file and I'm cross compiling the Lite `label_image` binary for my armv7a device as described in the README, without errors:\r\n```\r\nbazel build --config android_arm --config monolithic --cxxopt=-std=c++11   //tensorflow/contrib/lite/examples/label_image:label_image\r\n```\r\n\r\nWhen I run the resulting binary on my device with the stock `mobilenet_quant_v1_224.tflite` model and Grace Hopper image, I do not get the expected results, with \"military uniform\" at the top of the list. Instead I get:\r\n```\r\n # ./label_image\r\nnnapi error: unable to open library libneuralnetworks.so\r\nLoaded model ./mobilenet_quant_v1_224.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 2153.24 ms \r\n0.862745: 188 Yorkshire terrier\r\n0.0862745: 194 Australian terrier\r\n0.0313726: 187 Norwich terrier\r\n0.0117647: 202 silky terrier\r\n0.00784314: 152 Chihuahua\r\n```\r\n\r\nI see the `nnapi` error about the lack of the `libneuralnetworks.so`, so is that the culprit here? I had hoped that if the library was missing, it would still run correctly, albeit more slowly, but perhaps that is not the case and the library is 100% required for Lite to work. (If it is truly _required_, it does seem odd/confusing that the error isn't \"more fatal\" instead of continuing to do forward inference and producing garbage output!)\r\n\r\nFurthermore, when I run with more iterations (via the `-c` flag), I continue to get the wrong labels, but a _different_ set of incorrect labels depending on the number of iterations. For example, with two iterations:\r\n```\r\n# ./label_image2 -c 2\r\nnnapi error: unable to open library libneuralnetworks.so\r\nLoaded model ./mobilenet_quant_v1_224.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 2214.83 ms \r\n0.345098: 795 shower curtain\r\n0.109804: 906 window shade\r\n0.0470588: 563 fountain\r\n0.0470588: 534 dishrag\r\n0.0392157: 912 wool\r\n```\r\nAnd with three iterations:\r\n```\r\n# ./label_image2 -c 3\r\nnnapi error: unable to open library libneuralnetworks.so\r\nLoaded model ./mobilenet_quant_v1_224.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 2407.64 ms \r\n0.0705882: 906 window shade\r\n0.0509804: 829 strainer\r\n0.0509804: 734 pole\r\n0.0431373: 795 shower curtain\r\n0.0431373: 620 lampshade\r\n```\r\nAnd so on.\r\n\r\nWhy does the number of iterations performed affect the output? (Perhaps this is just the same issue as above, due to missing nnapi lib?)\r\n"}