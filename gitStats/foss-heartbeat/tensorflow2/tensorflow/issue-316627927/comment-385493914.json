{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385493914", "html_url": "https://github.com/tensorflow/tensorflow/issues/18784#issuecomment-385493914", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18784", "id": 385493914, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTQ5MzkxNA==", "user": {"login": "rachellim", "id": 9589037, "node_id": "MDQ6VXNlcjk1ODkwMzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/9589037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rachellim", "html_url": "https://github.com/rachellim", "followers_url": "https://api.github.com/users/rachellim/followers", "following_url": "https://api.github.com/users/rachellim/following{/other_user}", "gists_url": "https://api.github.com/users/rachellim/gists{/gist_id}", "starred_url": "https://api.github.com/users/rachellim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rachellim/subscriptions", "organizations_url": "https://api.github.com/users/rachellim/orgs", "repos_url": "https://api.github.com/users/rachellim/repos", "events_url": "https://api.github.com/users/rachellim/events{/privacy}", "received_events_url": "https://api.github.com/users/rachellim/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-30T18:52:55Z", "updated_at": "2018-04-30T18:55:57Z", "author_association": "MEMBER", "body_html": "<p>Oh, one more thing, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11020984\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/recolgan\">@recolgan</a> -- can you try applying <code>batch</code> before <code>map</code>? So the code should look like:</p>\n<pre><code>def make_tld(csv_filename, header_lines, delim, batch_size):\n    dataset = tf.data.TextLineDataset(filenames=csv_filename).skip(header_lines)\n\n    def parse_csv(line):\n        cols_types = [[]] * num_cols_  # all required\n        columns = tf.decode_csv(line, record_defaults=cols_types, field_delim=delim)\n        return tf.stack(columns)\n\n    dataset = dataset.batch(batch_size).map(parse_csv).\n    return dataset\n</code></pre>\n<p>I expect this to speed things up significantly, because the <code>map</code> function has significant overhead compared to the actual work of calling <code>decode_csv</code> on a small line. In your original example, the map function is applied to each line of the input file. When the data batched first, the map function is applied to a whole batch at a time, i.e. there are 100x fewer <code>map</code> operations being run. Let me know how this affects things.</p>\n<p>You can read more about this optimization in the <a href=\"https://www.tensorflow.org/versions/master/performance/datasets_performance\" rel=\"nofollow\">tensorflow input pipeline performance guide </a> (Look for \"Map and Batch\")</p>", "body_text": "Oh, one more thing, @recolgan -- can you try applying batch before map? So the code should look like:\ndef make_tld(csv_filename, header_lines, delim, batch_size):\n    dataset = tf.data.TextLineDataset(filenames=csv_filename).skip(header_lines)\n\n    def parse_csv(line):\n        cols_types = [[]] * num_cols_  # all required\n        columns = tf.decode_csv(line, record_defaults=cols_types, field_delim=delim)\n        return tf.stack(columns)\n\n    dataset = dataset.batch(batch_size).map(parse_csv).\n    return dataset\n\nI expect this to speed things up significantly, because the map function has significant overhead compared to the actual work of calling decode_csv on a small line. In your original example, the map function is applied to each line of the input file. When the data batched first, the map function is applied to a whole batch at a time, i.e. there are 100x fewer map operations being run. Let me know how this affects things.\nYou can read more about this optimization in the tensorflow input pipeline performance guide  (Look for \"Map and Batch\")", "body": "Oh, one more thing, @recolgan -- can you try applying `batch` before `map`? So the code should look like:\r\n\r\n```\r\ndef make_tld(csv_filename, header_lines, delim, batch_size):\r\n    dataset = tf.data.TextLineDataset(filenames=csv_filename).skip(header_lines)\r\n\r\n    def parse_csv(line):\r\n        cols_types = [[]] * num_cols_  # all required\r\n        columns = tf.decode_csv(line, record_defaults=cols_types, field_delim=delim)\r\n        return tf.stack(columns)\r\n\r\n    dataset = dataset.batch(batch_size).map(parse_csv).\r\n    return dataset\r\n```\r\n\r\nI expect this to speed things up significantly, because the `map` function has significant overhead compared to the actual work of calling `decode_csv` on a small line. In your original example, the map function is applied to each line of the input file. When the data batched first, the map function is applied to a whole batch at a time, i.e. there are 100x fewer `map` operations being run. Let me know how this affects things. \r\n\r\nYou can read more about this optimization in the [tensorflow input pipeline performance guide ](https://www.tensorflow.org/versions/master/performance/datasets_performance) (Look for \"Map and Batch\")\r\n"}