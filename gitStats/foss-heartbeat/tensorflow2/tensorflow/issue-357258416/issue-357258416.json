{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22094", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22094/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22094/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22094/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22094", "id": 357258416, "node_id": "MDU6SXNzdWUzNTcyNTg0MTY=", "number": 22094, "title": "Possible bug with map_fn in Graph mode during training, works fine with Eager execution", "user": {"login": "dmus", "id": 464378, "node_id": "MDQ6VXNlcjQ2NDM3OA==", "avatar_url": "https://avatars1.githubusercontent.com/u/464378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dmus", "html_url": "https://github.com/dmus", "followers_url": "https://api.github.com/users/dmus/followers", "following_url": "https://api.github.com/users/dmus/following{/other_user}", "gists_url": "https://api.github.com/users/dmus/gists{/gist_id}", "starred_url": "https://api.github.com/users/dmus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dmus/subscriptions", "organizations_url": "https://api.github.com/users/dmus/orgs", "repos_url": "https://api.github.com/users/dmus/repos", "events_url": "https://api.github.com/users/dmus/events{/privacy}", "received_events_url": "https://api.github.com/users/dmus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736653459, "node_id": "MDU6TGFiZWw3MzY2NTM0NTk=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:eager", "name": "comp:eager", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-05T14:32:37Z", "updated_at": "2018-09-27T19:00:06Z", "closed_at": "2018-09-27T19:00:06Z", "author_association": "NONE", "body_html": "<p>Tensorflow 1.10 on Ubuntu 16.04</p>\n<p>A simplified code example, see also stackoverflow: <a href=\"https://stackoverflow.com/questions/52187269/tensorflow-map-fn-does-not-work-in-graph-mode-during-training-in-eager-mode-it\" rel=\"nofollow\">https://stackoverflow.com/questions/52187269/tensorflow-map-fn-does-not-work-in-graph-mode-during-training-in-eager-mode-it</a></p>\n<p>This loss function works:</p>\n<pre><code>def discriminative_loss_working(y_true, y_pred):\n    # Compute the loss for only the first image in the batch\n    \n    prediction = y_pred[0]\n    label = y_true[0]\n\n    # Number of clusters in ground truth\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n    # Compute cluster means and variances for each cluster\n    def compute_mean(c):\n        mask = tf.equal(label[:,:,0], c)\n        masked_pixels = tf.boolean_mask(prediction, mask)\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n        return cluster_mean\n\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n    return tf.reduce_mean(cluster_means)\n</code></pre>\n<p>However, when inserting an extra map_fn to work with batch sizes &gt; 1 it doesnot work:</p>\n<pre><code>def discriminative_loss(y_true, y_pred):\n    \"\"\"Computes loss for a batch of images\n    Args:\n        y_true: (n, h, w) where each elements contains the ground truth instance id\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\n    Returns:\n        loss\n    \"\"\"\n    # Compute the loss for each image in the batch\n    def compute_loss(input):\n        prediction = input[1]\n        label = input[0]\n\n        # Number of clusters in ground truth\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n        # Compute cluster means and variances for each cluster\n        def compute_mean(c):\n            mask = tf.equal(label[:,:,0], c)\n            masked_pixels = tf.boolean_mask(prediction, mask)\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n            return cluster_mean\n\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n        return tf.reduce_mean(cluster_means)\n        \n    # We want to know the loss for each image in the batch\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\n    return losses\n</code></pre>\n<p>The error is:</p>\n<blockquote>\n<p>018-09-05 16:07:24.740128: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at tensor_array_ops.cc:121 : Not found: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.<br>\nTraceback (most recent call last):<br>\nFile \"instancesegmenter/test.py\", line 90, in <br>\nmodel.fit(train_dataset, epochs=5, steps_per_epoch=2)<br>\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1363, in fit<br>\nvalidation_steps=validation_steps)<br>\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 205, in fit_loop<br>\nouts = f(ins)<br>\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\", line 2914, in <strong>call</strong><br>\nfetched = self._callable_fn(*array_vals)<br>\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1382, in <strong>call</strong><br>\nrun_metadata_ptr)<br>\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in <strong>exit</strong><br>\nc_api.TF_GetCode(self.status.status))<br>\ntensorflow.python.framework.errors_impl.NotFoundError: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.<br>\n[[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3 = TensorArrayGradV3[_class=[\"loc:@train...ad/truediv\"], source=\"training/SGD/gradients\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2, training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2_1)]]<br>\n[[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/while/Mean_grad/truediv/_161 = _Recv<a href=\"%5E_clooptraining/SGD/gradients/loss/output_1_loss/map/while/map/while/boolean_mask/Reshape/Enter_grad/Switch/_36\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_608_t...ad/truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"</a>]]</p>\n</blockquote>\n<p>Note that this works fine in Eager mode and also when only doing a forward pass. However the backward pass when in graph mode gives the error.</p>\n<p>The full code example to reproduce the issue:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef discriminative_loss(y_true, y_pred):\n    \"\"\"Computes loss for a batch of images\n    Args:\n        y_true: (n, h, w) where each elements contains the ground truth instance id\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\n    Returns:\n        loss\n    \"\"\"\n    # Compute the loss for each image in the batch\n    def compute_loss(input):\n        prediction = input[1]\n        label = input[0]\n\n        # Number of clusters in ground truth\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n        # Compute cluster means and variances for each cluster\n        def compute_mean(c):\n            mask = tf.equal(label[:,:,0], c)\n            masked_pixels = tf.boolean_mask(prediction, mask)\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n            return cluster_mean\n\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n        return tf.reduce_mean(cluster_means)\n        \n    # We want to know the loss for each image in the batch\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\n    return losses\n\ndef discriminative_loss_working(y_true, y_pred):\n    # Compute the loss for only the first image in the batch\n    \n    prediction = y_pred[0]\n    label = y_true[0]\n\n    # Number of clusters in ground truth\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n    # Compute cluster means and variances for each cluster\n    def compute_mean(c):\n        mask = tf.equal(label[:,:,0], c)\n        masked_pixels = tf.boolean_mask(prediction, mask)\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n        return cluster_mean\n\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n    return tf.reduce_mean(cluster_means)\n\nclass MyModel(tf.keras.Model):\n    def __init__(self, input_shape):\n        super(MyModel, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=4, kernel_size=(1,1))\n\n    def call(self, input):\n        return self.conv(input)\n\ninput_shape = (1,128,128,3)\ndef my_gen():\n    while True:\n        x = np.random.rand(1,input_shape[1], input_shape[2],3)\n        y = np.random.randint(11000, 11015, (input_shape[1], input_shape[2],1))\n        yield x,y\n\ntrain_dataset = tf.data.Dataset.from_generator(my_gen, (tf.float32, tf.float32))\ntrain_dataset = train_dataset.batch(1)\ntrain_dataset = train_dataset.repeat()\n\nmodel = MyModel(input_shape=input_shape)\n\n# This is a fix to make loading weights possible\n# x = tf.zeros((1,) + input_shape)\nx = tf.zeros(input_shape)\ny = model(x)\n\noptimizer = tf.keras.optimizers.SGD(lr=0.0001)\nmodel.compile(loss=discriminative_loss,optimizer=optimizer)\nmodel.fit(train_dataset, epochs=5, steps_per_epoch=2)\n</code></pre>", "body_text": "Tensorflow 1.10 on Ubuntu 16.04\nA simplified code example, see also stackoverflow: https://stackoverflow.com/questions/52187269/tensorflow-map-fn-does-not-work-in-graph-mode-during-training-in-eager-mode-it\nThis loss function works:\ndef discriminative_loss_working(y_true, y_pred):\n    # Compute the loss for only the first image in the batch\n    \n    prediction = y_pred[0]\n    label = y_true[0]\n\n    # Number of clusters in ground truth\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n    # Compute cluster means and variances for each cluster\n    def compute_mean(c):\n        mask = tf.equal(label[:,:,0], c)\n        masked_pixels = tf.boolean_mask(prediction, mask)\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n        return cluster_mean\n\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n    return tf.reduce_mean(cluster_means)\n\nHowever, when inserting an extra map_fn to work with batch sizes > 1 it doesnot work:\ndef discriminative_loss(y_true, y_pred):\n    \"\"\"Computes loss for a batch of images\n    Args:\n        y_true: (n, h, w) where each elements contains the ground truth instance id\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\n    Returns:\n        loss\n    \"\"\"\n    # Compute the loss for each image in the batch\n    def compute_loss(input):\n        prediction = input[1]\n        label = input[0]\n\n        # Number of clusters in ground truth\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n        # Compute cluster means and variances for each cluster\n        def compute_mean(c):\n            mask = tf.equal(label[:,:,0], c)\n            masked_pixels = tf.boolean_mask(prediction, mask)\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n            return cluster_mean\n\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n        return tf.reduce_mean(cluster_means)\n        \n    # We want to know the loss for each image in the batch\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\n    return losses\n\nThe error is:\n\n018-09-05 16:07:24.740128: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at tensor_array_ops.cc:121 : Not found: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.\nTraceback (most recent call last):\nFile \"instancesegmenter/test.py\", line 90, in \nmodel.fit(train_dataset, epochs=5, steps_per_epoch=2)\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1363, in fit\nvalidation_steps=validation_steps)\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 205, in fit_loop\nouts = f(ins)\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\", line 2914, in call\nfetched = self._callable_fn(*array_vals)\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1382, in call\nrun_metadata_ptr)\nFile \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in exit\nc_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.NotFoundError: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.\n[[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3 = TensorArrayGradV3[_class=[\"loc:@train...ad/truediv\"], source=\"training/SGD/gradients\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2, training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2_1)]]\n[[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/while/Mean_grad/truediv/_161 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_608_t...ad/truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\n\nNote that this works fine in Eager mode and also when only doing a forward pass. However the backward pass when in graph mode gives the error.\nThe full code example to reproduce the issue:\nimport tensorflow as tf\nimport numpy as np\n\ndef discriminative_loss(y_true, y_pred):\n    \"\"\"Computes loss for a batch of images\n    Args:\n        y_true: (n, h, w) where each elements contains the ground truth instance id\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\n    Returns:\n        loss\n    \"\"\"\n    # Compute the loss for each image in the batch\n    def compute_loss(input):\n        prediction = input[1]\n        label = input[0]\n\n        # Number of clusters in ground truth\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n        # Compute cluster means and variances for each cluster\n        def compute_mean(c):\n            mask = tf.equal(label[:,:,0], c)\n            masked_pixels = tf.boolean_mask(prediction, mask)\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n            return cluster_mean\n\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n        return tf.reduce_mean(cluster_means)\n        \n    # We want to know the loss for each image in the batch\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\n    return losses\n\ndef discriminative_loss_working(y_true, y_pred):\n    # Compute the loss for only the first image in the batch\n    \n    prediction = y_pred[0]\n    label = y_true[0]\n\n    # Number of clusters in ground truth\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\n\n    # Compute cluster means and variances for each cluster\n    def compute_mean(c):\n        mask = tf.equal(label[:,:,0], c)\n        masked_pixels = tf.boolean_mask(prediction, mask)\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\n\n        return cluster_mean\n\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\n    return tf.reduce_mean(cluster_means)\n\nclass MyModel(tf.keras.Model):\n    def __init__(self, input_shape):\n        super(MyModel, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=4, kernel_size=(1,1))\n\n    def call(self, input):\n        return self.conv(input)\n\ninput_shape = (1,128,128,3)\ndef my_gen():\n    while True:\n        x = np.random.rand(1,input_shape[1], input_shape[2],3)\n        y = np.random.randint(11000, 11015, (input_shape[1], input_shape[2],1))\n        yield x,y\n\ntrain_dataset = tf.data.Dataset.from_generator(my_gen, (tf.float32, tf.float32))\ntrain_dataset = train_dataset.batch(1)\ntrain_dataset = train_dataset.repeat()\n\nmodel = MyModel(input_shape=input_shape)\n\n# This is a fix to make loading weights possible\n# x = tf.zeros((1,) + input_shape)\nx = tf.zeros(input_shape)\ny = model(x)\n\noptimizer = tf.keras.optimizers.SGD(lr=0.0001)\nmodel.compile(loss=discriminative_loss,optimizer=optimizer)\nmodel.fit(train_dataset, epochs=5, steps_per_epoch=2)", "body": "Tensorflow 1.10 on Ubuntu 16.04\r\n\r\nA simplified code example, see also stackoverflow: https://stackoverflow.com/questions/52187269/tensorflow-map-fn-does-not-work-in-graph-mode-during-training-in-eager-mode-it\r\n\r\nThis loss function works:\r\n```\r\ndef discriminative_loss_working(y_true, y_pred):\r\n    # Compute the loss for only the first image in the batch\r\n    \r\n    prediction = y_pred[0]\r\n    label = y_true[0]\r\n\r\n    # Number of clusters in ground truth\r\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\r\n\r\n    # Compute cluster means and variances for each cluster\r\n    def compute_mean(c):\r\n        mask = tf.equal(label[:,:,0], c)\r\n        masked_pixels = tf.boolean_mask(prediction, mask)\r\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\r\n\r\n        return cluster_mean\r\n\r\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\r\n    return tf.reduce_mean(cluster_means)\r\n```\r\n\r\nHowever, when inserting an extra map_fn to work with batch sizes > 1 it doesnot work:\r\n```\r\ndef discriminative_loss(y_true, y_pred):\r\n    \"\"\"Computes loss for a batch of images\r\n    Args:\r\n        y_true: (n, h, w) where each elements contains the ground truth instance id\r\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\r\n    Returns:\r\n        loss\r\n    \"\"\"\r\n    # Compute the loss for each image in the batch\r\n    def compute_loss(input):\r\n        prediction = input[1]\r\n        label = input[0]\r\n\r\n        # Number of clusters in ground truth\r\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\r\n\r\n        # Compute cluster means and variances for each cluster\r\n        def compute_mean(c):\r\n            mask = tf.equal(label[:,:,0], c)\r\n            masked_pixels = tf.boolean_mask(prediction, mask)\r\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\r\n\r\n            return cluster_mean\r\n\r\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\r\n        return tf.reduce_mean(cluster_means)\r\n        \r\n    # We want to know the loss for each image in the batch\r\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\r\n    return losses\r\n```\r\n\r\nThe error is:\r\n\r\n> 018-09-05 16:07:24.740128: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at tensor_array_ops.cc:121 : Not found: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.\r\n> Traceback (most recent call last):\r\n>   File \"instancesegmenter/test.py\", line 90, in <module>\r\n>     model.fit(train_dataset, epochs=5, steps_per_epoch=2)\r\n>   File \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1363, in fit\r\n>     validation_steps=validation_steps)\r\n>   File \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 205, in fit_loop\r\n>     outs = f(ins)\r\n>   File \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\", line 2914, in __call__\r\n>     fetched = self._callable_fn(*array_vals)\r\n>   File \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1382, in __call__\r\n>     run_metadata_ptr)\r\n>   File \"/home/derk/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in __exit__\r\n>     c_api.TF_GetCode(self.status.status))\r\n> tensorflow.python.framework.errors_impl.NotFoundError: Resource __per_step_6/_tensor_arraysloss/output_1_loss/map/while/map/TensorArray_1_3/N10tensorflow11TensorArrayE does not exist.\r\n> \t [[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3 = TensorArrayGradV3[_class=[\"loc:@train...ad/truediv\"], source=\"training/SGD/gradients\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2, training/SGD/gradients/loss/output_1_loss/map/while/map/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3/StackPopV2_1)]]\r\n> \t [[Node: training/SGD/gradients/loss/output_1_loss/map/while/map/while/Mean_grad/truediv/_161 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_608_t...ad/truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](^_clooptraining/SGD/gradients/loss/output_1_loss/map/while/map/while/boolean_mask/Reshape/Enter_grad/Switch/_36)]]\r\n\r\nNote that this works fine in Eager mode and also when only doing a forward pass. However the backward pass when in graph mode gives the error.\r\n\r\nThe full code example to reproduce the issue:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef discriminative_loss(y_true, y_pred):\r\n    \"\"\"Computes loss for a batch of images\r\n    Args:\r\n        y_true: (n, h, w) where each elements contains the ground truth instance id\r\n        y_pred: (n, h, w, d) d-dimensional vector for each pixel for each image in the batch\r\n    Returns:\r\n        loss\r\n    \"\"\"\r\n    # Compute the loss for each image in the batch\r\n    def compute_loss(input):\r\n        prediction = input[1]\r\n        label = input[0]\r\n\r\n        # Number of clusters in ground truth\r\n        clusters,_ = tf.unique(tf.reshape(label, [-1]))\r\n\r\n        # Compute cluster means and variances for each cluster\r\n        def compute_mean(c):\r\n            mask = tf.equal(label[:,:,0], c)\r\n            masked_pixels = tf.boolean_mask(prediction, mask)\r\n            cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\r\n\r\n            return cluster_mean\r\n\r\n        cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\r\n        return tf.reduce_mean(cluster_means)\r\n        \r\n    # We want to know the loss for each image in the batch\r\n    losses = tf.map_fn(compute_loss, (y_true,y_pred), dtype=(tf.float32))\r\n    return losses\r\n\r\ndef discriminative_loss_working(y_true, y_pred):\r\n    # Compute the loss for only the first image in the batch\r\n    \r\n    prediction = y_pred[0]\r\n    label = y_true[0]\r\n\r\n    # Number of clusters in ground truth\r\n    clusters,_ = tf.unique(tf.reshape(label, [-1]))\r\n\r\n    # Compute cluster means and variances for each cluster\r\n    def compute_mean(c):\r\n        mask = tf.equal(label[:,:,0], c)\r\n        masked_pixels = tf.boolean_mask(prediction, mask)\r\n        cluster_mean = tf.reduce_mean(masked_pixels, axis=0)\r\n\r\n        return cluster_mean\r\n\r\n    cluster_means = tf.map_fn(compute_mean, clusters, dtype=(tf.float32))\r\n    return tf.reduce_mean(cluster_means)\r\n\r\nclass MyModel(tf.keras.Model):\r\n    def __init__(self, input_shape):\r\n        super(MyModel, self).__init__()\r\n        self.conv = tf.keras.layers.Conv2D(filters=4, kernel_size=(1,1))\r\n\r\n    def call(self, input):\r\n        return self.conv(input)\r\n\r\ninput_shape = (1,128,128,3)\r\ndef my_gen():\r\n    while True:\r\n        x = np.random.rand(1,input_shape[1], input_shape[2],3)\r\n        y = np.random.randint(11000, 11015, (input_shape[1], input_shape[2],1))\r\n        yield x,y\r\n\r\ntrain_dataset = tf.data.Dataset.from_generator(my_gen, (tf.float32, tf.float32))\r\ntrain_dataset = train_dataset.batch(1)\r\ntrain_dataset = train_dataset.repeat()\r\n\r\nmodel = MyModel(input_shape=input_shape)\r\n\r\n# This is a fix to make loading weights possible\r\n# x = tf.zeros((1,) + input_shape)\r\nx = tf.zeros(input_shape)\r\ny = model(x)\r\n\r\noptimizer = tf.keras.optimizers.SGD(lr=0.0001)\r\nmodel.compile(loss=discriminative_loss,optimizer=optimizer)\r\nmodel.fit(train_dataset, epochs=5, steps_per_epoch=2)\r\n```\r\n"}