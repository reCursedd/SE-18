{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302860685", "html_url": "https://github.com/tensorflow/tensorflow/issues/10040#issuecomment-302860685", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10040", "id": 302860685, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjg2MDY4NQ==", "user": {"login": "Cospel", "id": 615554, "node_id": "MDQ6VXNlcjYxNTU1NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/615554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Cospel", "html_url": "https://github.com/Cospel", "followers_url": "https://api.github.com/users/Cospel/followers", "following_url": "https://api.github.com/users/Cospel/following{/other_user}", "gists_url": "https://api.github.com/users/Cospel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Cospel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Cospel/subscriptions", "organizations_url": "https://api.github.com/users/Cospel/orgs", "repos_url": "https://api.github.com/users/Cospel/repos", "events_url": "https://api.github.com/users/Cospel/events{/privacy}", "received_events_url": "https://api.github.com/users/Cospel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-20T08:57:59Z", "updated_at": "2017-05-20T08:57:59Z", "author_association": "NONE", "body_html": "<p>I found this on stackoverflow:</p>\n<p>Nothing to do with scratch space, it is the result of the addressing system that allows unified andressing and peer to peer access between host and multiple GPUs. The CUDA driver registers all the GPU(s) memory + host memory in a single virtual address space using the kernel's virtual memory system. It isn't actually memory consumption, per se, it is just a \"trick\" to map all the available address spaces into a linear virtual space for unified addressing.</p>\n<p>So probably it is just the behaviour of cuda....</p>", "body_text": "I found this on stackoverflow:\nNothing to do with scratch space, it is the result of the addressing system that allows unified andressing and peer to peer access between host and multiple GPUs. The CUDA driver registers all the GPU(s) memory + host memory in a single virtual address space using the kernel's virtual memory system. It isn't actually memory consumption, per se, it is just a \"trick\" to map all the available address spaces into a linear virtual space for unified addressing.\nSo probably it is just the behaviour of cuda....", "body": "I found this on stackoverflow:\r\n\r\nNothing to do with scratch space, it is the result of the addressing system that allows unified andressing and peer to peer access between host and multiple GPUs. The CUDA driver registers all the GPU(s) memory + host memory in a single virtual address space using the kernel's virtual memory system. It isn't actually memory consumption, per se, it is just a \"trick\" to map all the available address spaces into a linear virtual space for unified addressing.\r\n\r\nSo probably it is just the behaviour of cuda...."}