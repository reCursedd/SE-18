{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313699566", "html_url": "https://github.com/tensorflow/tensorflow/issues/11171#issuecomment-313699566", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11171", "id": 313699566, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzY5OTU2Ng==", "user": {"login": "MarvinTeichmann", "id": 2729159, "node_id": "MDQ6VXNlcjI3MjkxNTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/2729159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarvinTeichmann", "html_url": "https://github.com/MarvinTeichmann", "followers_url": "https://api.github.com/users/MarvinTeichmann/followers", "following_url": "https://api.github.com/users/MarvinTeichmann/following{/other_user}", "gists_url": "https://api.github.com/users/MarvinTeichmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarvinTeichmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarvinTeichmann/subscriptions", "organizations_url": "https://api.github.com/users/MarvinTeichmann/orgs", "repos_url": "https://api.github.com/users/MarvinTeichmann/repos", "events_url": "https://api.github.com/users/MarvinTeichmann/events{/privacy}", "received_events_url": "https://api.github.com/users/MarvinTeichmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-07T14:34:33Z", "updated_at": "2017-07-07T15:01:23Z", "author_association": "NONE", "body_html": "<p>Thanks for the answers. I had a short look through the gradient computation code in tensorflow. By now I am quite confident that node-mirroring can be be (fully) implemented in python. The whole think bowls done to manipulating the code which produces the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_impl.py#L488-L516\">gradient computation subgraph</a>.</p>\n<p>At the moment the intermediate results of each tensor are saved in GPU memory (if gradients are computed). This is an <em>incredible</em> wasteful behavior. I think this is the main reason why tensorflow is so extremly hungry for GPU memory.</p>\n<p>As an example, I have recently implemented a (gaussian) crf model in tensorflow. When performing back-propagation through the CRF the memory requirement went up from <code>320MB</code> to <code>10.45GB</code>, compared to plain inference. The issue in this case is, that the different computation along the line of  <code>tf.exp ( tf.reduce_sum(   -0.5 * tf.square( f_i - f_j ) * M ) )</code> are done very often. For each minor step in those kind of computations (i.e. <code>-0.5 * sqr_diff</code> ) the intermediate output is kept in memory.  The time it take to run the entire core of the CRF is only <code>347 \u03bcs</code>. This is negligible, compared to the rest of the model.</p>\n<p>So the bottom line of this example is: Recomputation during backward pass could save 10GB for a negligible amount of extra computation time. In all models the majority of memory is used for storing tensors for back-prop. Allowing recomputation will reduce the memory requirement of all deep models (i.e. &gt;= 12 layers) by an order of magnitude.</p>", "body_text": "Thanks for the answers. I had a short look through the gradient computation code in tensorflow. By now I am quite confident that node-mirroring can be be (fully) implemented in python. The whole think bowls done to manipulating the code which produces the gradient computation subgraph.\nAt the moment the intermediate results of each tensor are saved in GPU memory (if gradients are computed). This is an incredible wasteful behavior. I think this is the main reason why tensorflow is so extremly hungry for GPU memory.\nAs an example, I have recently implemented a (gaussian) crf model in tensorflow. When performing back-propagation through the CRF the memory requirement went up from 320MB to 10.45GB, compared to plain inference. The issue in this case is, that the different computation along the line of  tf.exp ( tf.reduce_sum(   -0.5 * tf.square( f_i - f_j ) * M ) ) are done very often. For each minor step in those kind of computations (i.e. -0.5 * sqr_diff ) the intermediate output is kept in memory.  The time it take to run the entire core of the CRF is only 347 \u03bcs. This is negligible, compared to the rest of the model.\nSo the bottom line of this example is: Recomputation during backward pass could save 10GB for a negligible amount of extra computation time. In all models the majority of memory is used for storing tensors for back-prop. Allowing recomputation will reduce the memory requirement of all deep models (i.e. >= 12 layers) by an order of magnitude.", "body": "Thanks for the answers. I had a short look through the gradient computation code in tensorflow. By now I am quite confident that node-mirroring can be be (fully) implemented in python. The whole think bowls done to manipulating the code which produces the [gradient computation subgraph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_impl.py#L488-L516).\r\n\r\nAt the moment the intermediate results of each tensor are saved in GPU memory (if gradients are computed). This is an *incredible* wasteful behavior. I think this is the main reason why tensorflow is so extremly hungry for GPU memory. \r\n\r\nAs an example, I have recently implemented a (gaussian) crf model in tensorflow. When performing back-propagation through the CRF the memory requirement went up from `320MB` to `10.45GB`, compared to plain inference. The issue in this case is, that the different computation along the line of  `tf.exp ( tf.reduce_sum(   -0.5 * tf.square( f_i - f_j ) * M ) )` are done very often. For each minor step in those kind of computations (i.e. `-0.5 * sqr_diff` ) the intermediate output is kept in memory.  The time it take to run the entire core of the CRF is only `347 \u03bcs`. This is negligible, compared to the rest of the model. \r\n\r\nSo the bottom line of this example is: Recomputation during backward pass could save 10GB for a negligible amount of extra computation time. In all models the majority of memory is used for storing tensors for back-prop. Allowing recomputation will reduce the memory requirement of all deep models (i.e. >= 12 layers) by an order of magnitude."}