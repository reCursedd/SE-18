{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/217784418", "html_url": "https://github.com/tensorflow/tensorflow/issues/2280#issuecomment-217784418", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2280", "id": 217784418, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNzc4NDQxOA==", "user": {"login": "myme5261314", "id": 1814831, "node_id": "MDQ6VXNlcjE4MTQ4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1814831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myme5261314", "html_url": "https://github.com/myme5261314", "followers_url": "https://api.github.com/users/myme5261314/followers", "following_url": "https://api.github.com/users/myme5261314/following{/other_user}", "gists_url": "https://api.github.com/users/myme5261314/gists{/gist_id}", "starred_url": "https://api.github.com/users/myme5261314/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myme5261314/subscriptions", "organizations_url": "https://api.github.com/users/myme5261314/orgs", "repos_url": "https://api.github.com/users/myme5261314/repos", "events_url": "https://api.github.com/users/myme5261314/events{/privacy}", "received_events_url": "https://api.github.com/users/myme5261314/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-09T06:20:28Z", "updated_at": "2016-05-09T06:20:28Z", "author_association": "NONE", "body_html": "<p>Seems tensorflow has optimized when the previous <code>a</code> is a placeholder. Here's another version of toy snippet.</p>\n<pre><code>Timer unit: 1e-06 s\n\nTotal time: 28.7196 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6                                               # a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7         1         2280   2280.0      0.0      a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8         1        54021  54021.0      0.2      mat = np.random.randn(1000, 1000)\n     9         1         2338   2338.0      0.0      b = a * 2\n    10         1         1809   1809.0      0.0      c = b * 3\n    11         1       359919 359919.0      1.3      sess = tf.Session()\n    12         1         9476   9476.0      0.0      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         3013      3.0      0.0      for _ in xrange(1000):\n    15      1000       462844    462.8      1.6          h = sess.partial_run_setup([b, c], [a])\n    16      1000      7600600   7600.6     26.5          res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    17      1001         3028      3.0      0.0      for _ in xrange(1000):\n    18      1000      5680910   5680.9     19.8          d = sess.run(b, feed_dict={a: mat})\n    19      1001         2960      3.0      0.0      for _ in xrange(1000):\n    20      1000      6443068   6443.1     22.4          e = sess.run(c, feed_dict={a: mat})\n    21      1001         2853      2.9      0.0      for _ in xrange(1000):\n    22      1000      8090507   8090.5     28.2          f = sess.run([b, c], feed_dict={a: mat})\n</code></pre>\n<p>But using <code>partial_run</code> while <code>a</code> is a Variable is useless.</p>\n<pre><code>Timer unit: 1e-06 s\n\nTotal time: 10.8776 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1         9836   9836.0      0.1      a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7                                               # a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8                                               # mat = np.random.randn(1000, 1000)\n     9         1         1608   1608.0      0.0      b = a * 2\n    10         1         1525   1525.0      0.0      c = b * 3\n    11         1       427775 427775.0      3.9      sess = tf.Session()\n    12         1       181565 181565.0      1.7      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         2385      2.4      0.0      for _ in xrange(1000):\n    15      1000       196307    196.3      1.8          h = sess.partial_run_setup([b, c], [])\n    16      1000      3327579   3327.6     30.6          res = sess.partial_run(h, [b, c])\n    17                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    18      1001         2048      2.0      0.0      for _ in xrange(1000):\n    19                                                   # d = sess.run(b, feed_dict={a: mat})\n    20      1000      1428858   1428.9     13.1          d = sess.run(b)\n    21      1001         2058      2.1      0.0      for _ in xrange(1000):\n    22                                                   # e = sess.run(c, feed_dict={a: mat})\n    23      1000      1449288   1449.3     13.3          e = sess.run(c)\n    24      1001         2769      2.8      0.0      for _ in xrange(1000):\n    25                                                   # f = sess.run([b, c], feed_dict={a: mat})\n    26      1000      3843996   3844.0     35.3          f = sess.run([b, c])\n</code></pre>\n<p>I know transfer content from RAM to gpu memory is very time consuming, is this fact related?<br>\nI mean, when <code>a</code> is a placeholder, since the time of placeholder transfer dominates, so getting <code>[b, c]</code> with or without <code>partial_run</code> is time comparable to getting <code>b</code> or <code>c</code>?</p>", "body_text": "Seems tensorflow has optimized when the previous a is a placeholder. Here's another version of toy snippet.\nTimer unit: 1e-06 s\n\nTotal time: 28.7196 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6                                               # a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7         1         2280   2280.0      0.0      a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8         1        54021  54021.0      0.2      mat = np.random.randn(1000, 1000)\n     9         1         2338   2338.0      0.0      b = a * 2\n    10         1         1809   1809.0      0.0      c = b * 3\n    11         1       359919 359919.0      1.3      sess = tf.Session()\n    12         1         9476   9476.0      0.0      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         3013      3.0      0.0      for _ in xrange(1000):\n    15      1000       462844    462.8      1.6          h = sess.partial_run_setup([b, c], [a])\n    16      1000      7600600   7600.6     26.5          res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    17      1001         3028      3.0      0.0      for _ in xrange(1000):\n    18      1000      5680910   5680.9     19.8          d = sess.run(b, feed_dict={a: mat})\n    19      1001         2960      3.0      0.0      for _ in xrange(1000):\n    20      1000      6443068   6443.1     22.4          e = sess.run(c, feed_dict={a: mat})\n    21      1001         2853      2.9      0.0      for _ in xrange(1000):\n    22      1000      8090507   8090.5     28.2          f = sess.run([b, c], feed_dict={a: mat})\n\nBut using partial_run while a is a Variable is useless.\nTimer unit: 1e-06 s\n\nTotal time: 10.8776 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1         9836   9836.0      0.1      a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7                                               # a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8                                               # mat = np.random.randn(1000, 1000)\n     9         1         1608   1608.0      0.0      b = a * 2\n    10         1         1525   1525.0      0.0      c = b * 3\n    11         1       427775 427775.0      3.9      sess = tf.Session()\n    12         1       181565 181565.0      1.7      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         2385      2.4      0.0      for _ in xrange(1000):\n    15      1000       196307    196.3      1.8          h = sess.partial_run_setup([b, c], [])\n    16      1000      3327579   3327.6     30.6          res = sess.partial_run(h, [b, c])\n    17                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    18      1001         2048      2.0      0.0      for _ in xrange(1000):\n    19                                                   # d = sess.run(b, feed_dict={a: mat})\n    20      1000      1428858   1428.9     13.1          d = sess.run(b)\n    21      1001         2058      2.1      0.0      for _ in xrange(1000):\n    22                                                   # e = sess.run(c, feed_dict={a: mat})\n    23      1000      1449288   1449.3     13.3          e = sess.run(c)\n    24      1001         2769      2.8      0.0      for _ in xrange(1000):\n    25                                                   # f = sess.run([b, c], feed_dict={a: mat})\n    26      1000      3843996   3844.0     35.3          f = sess.run([b, c])\n\nI know transfer content from RAM to gpu memory is very time consuming, is this fact related?\nI mean, when a is a placeholder, since the time of placeholder transfer dominates, so getting [b, c] with or without partial_run is time comparable to getting b or c?", "body": "Seems tensorflow has optimized when the previous `a` is a placeholder. Here's another version of toy snippet.\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 28.7196 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6                                               # a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7         1         2280   2280.0      0.0      a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8         1        54021  54021.0      0.2      mat = np.random.randn(1000, 1000)\n     9         1         2338   2338.0      0.0      b = a * 2\n    10         1         1809   1809.0      0.0      c = b * 3\n    11         1       359919 359919.0      1.3      sess = tf.Session()\n    12         1         9476   9476.0      0.0      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         3013      3.0      0.0      for _ in xrange(1000):\n    15      1000       462844    462.8      1.6          h = sess.partial_run_setup([b, c], [a])\n    16      1000      7600600   7600.6     26.5          res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    17      1001         3028      3.0      0.0      for _ in xrange(1000):\n    18      1000      5680910   5680.9     19.8          d = sess.run(b, feed_dict={a: mat})\n    19      1001         2960      3.0      0.0      for _ in xrange(1000):\n    20      1000      6443068   6443.1     22.4          e = sess.run(c, feed_dict={a: mat})\n    21      1001         2853      2.9      0.0      for _ in xrange(1000):\n    22      1000      8090507   8090.5     28.2          f = sess.run([b, c], feed_dict={a: mat})\n```\n\nBut using `partial_run` while `a` is a Variable is useless.\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 10.8776 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1         9836   9836.0      0.1      a = tf.Variable(tf.random_normal(shape=[1000, 1000]))\n     7                                               # a = tf.placeholder(\"float\", shape=[1000, 1000])\n     8                                               # mat = np.random.randn(1000, 1000)\n     9         1         1608   1608.0      0.0      b = a * 2\n    10         1         1525   1525.0      0.0      c = b * 3\n    11         1       427775 427775.0      3.9      sess = tf.Session()\n    12         1       181565 181565.0      1.7      sess.run(tf.initialize_all_variables())\n    13                                           \n    14      1001         2385      2.4      0.0      for _ in xrange(1000):\n    15      1000       196307    196.3      1.8          h = sess.partial_run_setup([b, c], [])\n    16      1000      3327579   3327.6     30.6          res = sess.partial_run(h, [b, c])\n    17                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: mat})\n    18      1001         2048      2.0      0.0      for _ in xrange(1000):\n    19                                                   # d = sess.run(b, feed_dict={a: mat})\n    20      1000      1428858   1428.9     13.1          d = sess.run(b)\n    21      1001         2058      2.1      0.0      for _ in xrange(1000):\n    22                                                   # e = sess.run(c, feed_dict={a: mat})\n    23      1000      1449288   1449.3     13.3          e = sess.run(c)\n    24      1001         2769      2.8      0.0      for _ in xrange(1000):\n    25                                                   # f = sess.run([b, c], feed_dict={a: mat})\n    26      1000      3843996   3844.0     35.3          f = sess.run([b, c])\n```\n\nI know transfer content from RAM to gpu memory is very time consuming, is this fact related?\nI mean, when `a` is a placeholder, since the time of placeholder transfer dominates, so getting `[b, c]` with or without `partial_run` is time comparable to getting `b` or `c`?\n"}