{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/218128111", "html_url": "https://github.com/tensorflow/tensorflow/issues/2280#issuecomment-218128111", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2280", "id": 218128111, "node_id": "MDEyOklzc3VlQ29tbWVudDIxODEyODExMQ==", "user": {"login": "myme5261314", "id": 1814831, "node_id": "MDQ6VXNlcjE4MTQ4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1814831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myme5261314", "html_url": "https://github.com/myme5261314", "followers_url": "https://api.github.com/users/myme5261314/followers", "following_url": "https://api.github.com/users/myme5261314/following{/other_user}", "gists_url": "https://api.github.com/users/myme5261314/gists{/gist_id}", "starred_url": "https://api.github.com/users/myme5261314/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myme5261314/subscriptions", "organizations_url": "https://api.github.com/users/myme5261314/orgs", "repos_url": "https://api.github.com/users/myme5261314/repos", "events_url": "https://api.github.com/users/myme5261314/events{/privacy}", "received_events_url": "https://api.github.com/users/myme5261314/received_events", "type": "User", "site_admin": false}, "created_at": "2016-05-10T11:14:06Z", "updated_at": "2016-05-10T11:14:06Z", "author_association": "NONE", "body_html": "<p>Here are some more investigation.</p>\n<pre><code>Timer unit: 1e-06 s\n\nTotal time: 12.3761 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          515    515.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            3      3.0      0.0          s = 500\n     8                                                   # a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9         1         2327   2327.0      0.0          a = tf.placeholder(\"float\", shape=[s, s])\n    10         1        15789  15789.0      0.1          np_a = np.random.randn(s, s)\n    11         1         2305   2305.0      0.0          b = tf.matmul(a, a)\n    12         1         1878   1878.0      0.0          c = tf.matmul(b, b)\n    13         1          567    567.0      0.0          init = tf.initialize_all_variables()\n    14         1       264673 264673.0      2.1      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1         9307   9307.0      0.1      sess.run(init)\n    16                                           \n    17                                           \n    18         1       140504 140504.0      1.1      sess.run(c, feed_dict={a: np_a})\n    19                                           \n    20      1001         1911      1.9      0.0      for _ in xrange(1000):\n    21      1000       240162    240.2      1.9          h = sess.partial_run_setup([b, c], [a])\n    22      1000      2517772   2517.8     20.3          res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    23                                           \n    24      1001         2108      2.1      0.0      for _ in xrange(1000):\n    25      1000      1971059   1971.1     15.9          d = sess.run(b, feed_dict={a: np_a})\n    26      1001         1938      1.9      0.0      for _ in xrange(1000):\n    27      1000      2251912   2251.9     18.2          e = sess.run(c, feed_dict={a: np_a})\n    28      1001         2102      2.1      0.0      for _ in xrange(1000):\n    29      1000      2627560   2627.6     21.2          f = sess.run([b, c], feed_dict={a: np_a})\n    30      1001         2021      2.0      0.0      for _ in xrange(1000):\n    31      1000      2319638   2319.6     18.7          f = sess.run([c, c], feed_dict={a: np_a})\n</code></pre>\n<p>change <code>a</code> from <strong>placeholder</strong> to <strong>Variable</strong>. Then total running time decrease to <strong>half</strong> of above.</p>\n<pre><code>Timer unit: 1e-06 s\n\nTotal time: 5.92345 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          539    539.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            1      1.0      0.0          s = 500\n     8         1        16648  16648.0      0.3          a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9                                                   # a = tf.placeholder(\"float\", shape=[s, s])\n    10                                                   # np_a = np.random.randn(s, s)\n    11         1         1856   1856.0      0.0          b = tf.matmul(a, a)\n    12         1         1801   1801.0      0.0          c = tf.matmul(b, b)\n    13         1          823    823.0      0.0          init = tf.initialize_all_variables()\n    14         1       315201 315201.0      5.3      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1       161516 161516.0      2.7      sess.run(init)\n    16                                           \n    17                                           \n    18                                               # sess.run(c, feed_dict={a: np_a})\n    19         1       126629 126629.0      2.1      sess.run(c)\n    20                                           \n    21      1001         1401      1.4      0.0      for _ in xrange(1000):\n    22                                                   # h = sess.partial_run_setup([b, c], [a])\n    23                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    24      1000       194673    194.7      3.3          h = sess.partial_run_setup([b, c], [])\n    25      1000      1121128   1121.1     18.9          res = sess.partial_run(h, [b, c])\n    26                                           \n    27      1001         1130      1.1      0.0      for _ in xrange(1000):\n    28                                                   # d = sess.run(b, feed_dict={a: np_a})\n    29      1000       733446    733.4     12.4          d = sess.run(b)\n    30      1001         1003      1.0      0.0      for _ in xrange(1000):\n    31                                                   # e = sess.run(c, feed_dict={a: np_a})\n    32      1000       854119    854.1     14.4          e = sess.run(c)\n    33      1001         1283      1.3      0.0      for _ in xrange(1000):\n    34                                                   # f = sess.run([b, c], feed_dict={a: np_a})\n    35      1000      1240861   1240.9     20.9          f = sess.run([b, c])\n    36      1001         1387      1.4      0.0      for _ in xrange(1000):\n    37                                                   # f = sess.run([c, c], feed_dict={a: np_a})\n    38      1000      1148003   1148.0     19.4          f = sess.run([c, c])\n</code></pre>\n<p>Using these toy snippets isn't my intension. I intended to find out where is the slow component of tensorflow framework.<br>\nActually, I can confirm that current <code>tensorflow</code> runs kind of very slow compared to <code>Torch</code> based on my practical experiments running.</p>\n<p>I propose this issue because I'm facing practical performance problem with tensorflow. I'm using tensorflow to re-implement a project which is implemented with <code>Torch</code>.<br>\nFor now the result and code seems run properly, and the experiments result are similar to that project, the issue is the computation time.<br>\nWith <strong>same</strong> network architecture, <strong>same</strong> batchsize, \"Torch\" project's single mini-batch forward and backward plus some extra computation takes only, say around <strong>1</strong> second, while my tensorflow version implementation takes around <strong>3</strong> seconds to finish a min-batch (actually, in torch they just backward with gradient Input, while I compute gradients with gradient Input, then apply gradients via tensorflow since it has no backward API), and almost 80+% time is consuming by tensorflow <strong>API</strong> according to <code>line_profiler</code>.<br>\nSo, there seems no place of code to diagnose except \"tensorflow API\" (the key component I use is feedforward, compute gradients and apply gradients).</p>\n<p>It's really hard for me to wait 3 days experiments with tensorflow compared to one day with <code>Torch</code>.</p>", "body_text": "Here are some more investigation.\nTimer unit: 1e-06 s\n\nTotal time: 12.3761 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          515    515.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            3      3.0      0.0          s = 500\n     8                                                   # a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9         1         2327   2327.0      0.0          a = tf.placeholder(\"float\", shape=[s, s])\n    10         1        15789  15789.0      0.1          np_a = np.random.randn(s, s)\n    11         1         2305   2305.0      0.0          b = tf.matmul(a, a)\n    12         1         1878   1878.0      0.0          c = tf.matmul(b, b)\n    13         1          567    567.0      0.0          init = tf.initialize_all_variables()\n    14         1       264673 264673.0      2.1      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1         9307   9307.0      0.1      sess.run(init)\n    16                                           \n    17                                           \n    18         1       140504 140504.0      1.1      sess.run(c, feed_dict={a: np_a})\n    19                                           \n    20      1001         1911      1.9      0.0      for _ in xrange(1000):\n    21      1000       240162    240.2      1.9          h = sess.partial_run_setup([b, c], [a])\n    22      1000      2517772   2517.8     20.3          res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    23                                           \n    24      1001         2108      2.1      0.0      for _ in xrange(1000):\n    25      1000      1971059   1971.1     15.9          d = sess.run(b, feed_dict={a: np_a})\n    26      1001         1938      1.9      0.0      for _ in xrange(1000):\n    27      1000      2251912   2251.9     18.2          e = sess.run(c, feed_dict={a: np_a})\n    28      1001         2102      2.1      0.0      for _ in xrange(1000):\n    29      1000      2627560   2627.6     21.2          f = sess.run([b, c], feed_dict={a: np_a})\n    30      1001         2021      2.0      0.0      for _ in xrange(1000):\n    31      1000      2319638   2319.6     18.7          f = sess.run([c, c], feed_dict={a: np_a})\n\nchange a from placeholder to Variable. Then total running time decrease to half of above.\nTimer unit: 1e-06 s\n\nTotal time: 5.92345 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          539    539.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            1      1.0      0.0          s = 500\n     8         1        16648  16648.0      0.3          a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9                                                   # a = tf.placeholder(\"float\", shape=[s, s])\n    10                                                   # np_a = np.random.randn(s, s)\n    11         1         1856   1856.0      0.0          b = tf.matmul(a, a)\n    12         1         1801   1801.0      0.0          c = tf.matmul(b, b)\n    13         1          823    823.0      0.0          init = tf.initialize_all_variables()\n    14         1       315201 315201.0      5.3      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1       161516 161516.0      2.7      sess.run(init)\n    16                                           \n    17                                           \n    18                                               # sess.run(c, feed_dict={a: np_a})\n    19         1       126629 126629.0      2.1      sess.run(c)\n    20                                           \n    21      1001         1401      1.4      0.0      for _ in xrange(1000):\n    22                                                   # h = sess.partial_run_setup([b, c], [a])\n    23                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    24      1000       194673    194.7      3.3          h = sess.partial_run_setup([b, c], [])\n    25      1000      1121128   1121.1     18.9          res = sess.partial_run(h, [b, c])\n    26                                           \n    27      1001         1130      1.1      0.0      for _ in xrange(1000):\n    28                                                   # d = sess.run(b, feed_dict={a: np_a})\n    29      1000       733446    733.4     12.4          d = sess.run(b)\n    30      1001         1003      1.0      0.0      for _ in xrange(1000):\n    31                                                   # e = sess.run(c, feed_dict={a: np_a})\n    32      1000       854119    854.1     14.4          e = sess.run(c)\n    33      1001         1283      1.3      0.0      for _ in xrange(1000):\n    34                                                   # f = sess.run([b, c], feed_dict={a: np_a})\n    35      1000      1240861   1240.9     20.9          f = sess.run([b, c])\n    36      1001         1387      1.4      0.0      for _ in xrange(1000):\n    37                                                   # f = sess.run([c, c], feed_dict={a: np_a})\n    38      1000      1148003   1148.0     19.4          f = sess.run([c, c])\n\nUsing these toy snippets isn't my intension. I intended to find out where is the slow component of tensorflow framework.\nActually, I can confirm that current tensorflow runs kind of very slow compared to Torch based on my practical experiments running.\nI propose this issue because I'm facing practical performance problem with tensorflow. I'm using tensorflow to re-implement a project which is implemented with Torch.\nFor now the result and code seems run properly, and the experiments result are similar to that project, the issue is the computation time.\nWith same network architecture, same batchsize, \"Torch\" project's single mini-batch forward and backward plus some extra computation takes only, say around 1 second, while my tensorflow version implementation takes around 3 seconds to finish a min-batch (actually, in torch they just backward with gradient Input, while I compute gradients with gradient Input, then apply gradients via tensorflow since it has no backward API), and almost 80+% time is consuming by tensorflow API according to line_profiler.\nSo, there seems no place of code to diagnose except \"tensorflow API\" (the key component I use is feedforward, compute gradients and apply gradients).\nIt's really hard for me to wait 3 days experiments with tensorflow compared to one day with Torch.", "body": "Here are some more investigation.\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 12.3761 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          515    515.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            3      3.0      0.0          s = 500\n     8                                                   # a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9         1         2327   2327.0      0.0          a = tf.placeholder(\"float\", shape=[s, s])\n    10         1        15789  15789.0      0.1          np_a = np.random.randn(s, s)\n    11         1         2305   2305.0      0.0          b = tf.matmul(a, a)\n    12         1         1878   1878.0      0.0          c = tf.matmul(b, b)\n    13         1          567    567.0      0.0          init = tf.initialize_all_variables()\n    14         1       264673 264673.0      2.1      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1         9307   9307.0      0.1      sess.run(init)\n    16                                           \n    17                                           \n    18         1       140504 140504.0      1.1      sess.run(c, feed_dict={a: np_a})\n    19                                           \n    20      1001         1911      1.9      0.0      for _ in xrange(1000):\n    21      1000       240162    240.2      1.9          h = sess.partial_run_setup([b, c], [a])\n    22      1000      2517772   2517.8     20.3          res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    23                                           \n    24      1001         2108      2.1      0.0      for _ in xrange(1000):\n    25      1000      1971059   1971.1     15.9          d = sess.run(b, feed_dict={a: np_a})\n    26      1001         1938      1.9      0.0      for _ in xrange(1000):\n    27      1000      2251912   2251.9     18.2          e = sess.run(c, feed_dict={a: np_a})\n    28      1001         2102      2.1      0.0      for _ in xrange(1000):\n    29      1000      2627560   2627.6     21.2          f = sess.run([b, c], feed_dict={a: np_a})\n    30      1001         2021      2.0      0.0      for _ in xrange(1000):\n    31      1000      2319638   2319.6     18.7          f = sess.run([c, c], feed_dict={a: np_a})\n```\n\nchange `a` from **placeholder** to **Variable**. Then total running time decrease to **half** of above.\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 5.92345 s\nFile: test_tf_time.py\nFunction: main at line 4\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     4                                           @profile\n     5                                           def main():\n     6         1          539    539.0      0.0      with tf.device(\"/gpu:1\"):\n     7         1            1      1.0      0.0          s = 500\n     8         1        16648  16648.0      0.3          a = tf.Variable(tf.random_normal(shape=[s, s]))\n     9                                                   # a = tf.placeholder(\"float\", shape=[s, s])\n    10                                                   # np_a = np.random.randn(s, s)\n    11         1         1856   1856.0      0.0          b = tf.matmul(a, a)\n    12         1         1801   1801.0      0.0          c = tf.matmul(b, b)\n    13         1          823    823.0      0.0          init = tf.initialize_all_variables()\n    14         1       315201 315201.0      5.3      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    15         1       161516 161516.0      2.7      sess.run(init)\n    16                                           \n    17                                           \n    18                                               # sess.run(c, feed_dict={a: np_a})\n    19         1       126629 126629.0      2.1      sess.run(c)\n    20                                           \n    21      1001         1401      1.4      0.0      for _ in xrange(1000):\n    22                                                   # h = sess.partial_run_setup([b, c], [a])\n    23                                                   # res = sess.partial_run(h, [b, c], feed_dict={a: np_a})\n    24      1000       194673    194.7      3.3          h = sess.partial_run_setup([b, c], [])\n    25      1000      1121128   1121.1     18.9          res = sess.partial_run(h, [b, c])\n    26                                           \n    27      1001         1130      1.1      0.0      for _ in xrange(1000):\n    28                                                   # d = sess.run(b, feed_dict={a: np_a})\n    29      1000       733446    733.4     12.4          d = sess.run(b)\n    30      1001         1003      1.0      0.0      for _ in xrange(1000):\n    31                                                   # e = sess.run(c, feed_dict={a: np_a})\n    32      1000       854119    854.1     14.4          e = sess.run(c)\n    33      1001         1283      1.3      0.0      for _ in xrange(1000):\n    34                                                   # f = sess.run([b, c], feed_dict={a: np_a})\n    35      1000      1240861   1240.9     20.9          f = sess.run([b, c])\n    36      1001         1387      1.4      0.0      for _ in xrange(1000):\n    37                                                   # f = sess.run([c, c], feed_dict={a: np_a})\n    38      1000      1148003   1148.0     19.4          f = sess.run([c, c])\n```\n\nUsing these toy snippets isn't my intension. I intended to find out where is the slow component of tensorflow framework.\nActually, I can confirm that current `tensorflow` runs kind of very slow compared to `Torch` based on my practical experiments running.\n\nI propose this issue because I'm facing practical performance problem with tensorflow. I'm using tensorflow to re-implement a project which is implemented with `Torch`.\nFor now the result and code seems run properly, and the experiments result are similar to that project, the issue is the computation time.\nWith **same** network architecture, **same** batchsize, \"Torch\" project's single mini-batch forward and backward plus some extra computation takes only, say around **1** second, while my tensorflow version implementation takes around **3** seconds to finish a min-batch (actually, in torch they just backward with gradient Input, while I compute gradients with gradient Input, then apply gradients via tensorflow since it has no backward API), and almost 80+% time is consuming by tensorflow **API** according to `line_profiler`.\nSo, there seems no place of code to diagnose except \"tensorflow API\" (the key component I use is feedforward, compute gradients and apply gradients).\n\nIt's really hard for me to wait 3 days experiments with tensorflow compared to one day with `Torch`.\n"}