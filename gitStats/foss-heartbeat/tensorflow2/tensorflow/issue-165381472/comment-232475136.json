{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232475136", "html_url": "https://github.com/tensorflow/tensorflow/issues/3299#issuecomment-232475136", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3299", "id": 232475136, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjQ3NTEzNg==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-13T20:22:42Z", "updated_at": "2016-07-13T20:22:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes. All tensors in TensorFlow are refcounted, dynamically allocated and freed. On GPU, this goes through its own non-blocking BFC memory allocator. All the tensors are freed when their refcount goes to zero. For temporary tensors, that is often when \"Compute\" finishes. For output tensors, that is when they finish being used as input tensors.</p>", "body_text": "Yes. All tensors in TensorFlow are refcounted, dynamically allocated and freed. On GPU, this goes through its own non-blocking BFC memory allocator. All the tensors are freed when their refcount goes to zero. For temporary tensors, that is often when \"Compute\" finishes. For output tensors, that is when they finish being used as input tensors.", "body": "Yes. All tensors in TensorFlow are refcounted, dynamically allocated and freed. On GPU, this goes through its own non-blocking BFC memory allocator. All the tensors are freed when their refcount goes to zero. For temporary tensors, that is often when \"Compute\" finishes. For output tensors, that is when they finish being used as input tensors. \n"}