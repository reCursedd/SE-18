{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/415905822", "html_url": "https://github.com/tensorflow/tensorflow/issues/21326#issuecomment-415905822", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21326", "id": 415905822, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTkwNTgyMg==", "user": {"login": "gaarangoa", "id": 13142027, "node_id": "MDQ6VXNlcjEzMTQyMDI3", "avatar_url": "https://avatars2.githubusercontent.com/u/13142027?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaarangoa", "html_url": "https://github.com/gaarangoa", "followers_url": "https://api.github.com/users/gaarangoa/followers", "following_url": "https://api.github.com/users/gaarangoa/following{/other_user}", "gists_url": "https://api.github.com/users/gaarangoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaarangoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaarangoa/subscriptions", "organizations_url": "https://api.github.com/users/gaarangoa/orgs", "repos_url": "https://api.github.com/users/gaarangoa/repos", "events_url": "https://api.github.com/users/gaarangoa/events{/privacy}", "received_events_url": "https://api.github.com/users/gaarangoa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T23:14:17Z", "updated_at": "2018-08-24T23:14:17Z", "author_association": "NONE", "body_html": "<p>Hey there,</p>\n<p>Local environment: '1.10.0'<br>\ncolab only CPU: '1.10.0'<br>\ncolab GPU: '1.10.0'</p>\n<p>Only works in colab when using GPU. I also suspect is because of CuDNNGRU, in the provided example, there is a function that takes care of it (see below) depending on the environment it uses either GRU or CuDNNGRU.</p>\n<p>Based on the tf documentation, I found that GRU should have enabled: <strong>reset_after=True,</strong>,  <strong>recurrent_activation='sigmoid',</strong> But, I got the same inconsistent results.</p>\n<p>def gru(units):<br>\n# If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)<br>\n# the code automatically does that.<br>\nif tf.test.is_gpu_available():<br>\nreturn tf.keras.layers.CuDNNGRU(units,<br>\nreturn_sequences=True,<br>\nreturn_state=True,<br>\nrecurrent_initializer='glorot_uniform')<br>\nelse:<br>\nreturn tf.keras.layers.GRU(units,<br>\nreturn_sequences=True,<br>\nreturn_state=True,<br>\n<strong>reset_after=True,</strong><br>\n<strong>recurrent_activation='sigmoid',</strong><br>\nrecurrent_initializer='glorot_uniform',<br>\n)</p>\n<p>I'm a little confused about what version is using the GRU implementation, in the documentation says the CPU compatible is v1 see <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU</a></p>\n<p>Many thanks!!</p>", "body_text": "Hey there,\nLocal environment: '1.10.0'\ncolab only CPU: '1.10.0'\ncolab GPU: '1.10.0'\nOnly works in colab when using GPU. I also suspect is because of CuDNNGRU, in the provided example, there is a function that takes care of it (see below) depending on the environment it uses either GRU or CuDNNGRU.\nBased on the tf documentation, I found that GRU should have enabled: reset_after=True,,  recurrent_activation='sigmoid', But, I got the same inconsistent results.\ndef gru(units):\n# If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n# the code automatically does that.\nif tf.test.is_gpu_available():\nreturn tf.keras.layers.CuDNNGRU(units,\nreturn_sequences=True,\nreturn_state=True,\nrecurrent_initializer='glorot_uniform')\nelse:\nreturn tf.keras.layers.GRU(units,\nreturn_sequences=True,\nreturn_state=True,\nreset_after=True,\nrecurrent_activation='sigmoid',\nrecurrent_initializer='glorot_uniform',\n)\nI'm a little confused about what version is using the GRU implementation, in the documentation says the CPU compatible is v1 see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\nMany thanks!!", "body": "Hey there, \r\n\r\nLocal environment: '1.10.0'\r\ncolab only CPU: '1.10.0'\r\ncolab GPU: '1.10.0'\r\n\r\nOnly works in colab when using GPU. I also suspect is because of CuDNNGRU, in the provided example, there is a function that takes care of it (see below) depending on the environment it uses either GRU or CuDNNGRU. \r\n\r\nBased on the tf documentation, I found that GRU should have enabled: **reset_after=True,**,  **recurrent_activation='sigmoid',** But, I got the same inconsistent results. \r\n\r\ndef gru(units):\r\n    # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\r\n    # the code automatically does that.\r\n    if tf.test.is_gpu_available():\r\n        return tf.keras.layers.CuDNNGRU(units,\r\n                                    return_sequences=True,\r\n                                    return_state=True,\r\n                                    recurrent_initializer='glorot_uniform')\r\n    else:\r\n        return tf.keras.layers.GRU(units,\r\n                                return_sequences=True,\r\n                                return_state=True,\r\n                                **reset_after=True,**\r\n                                **recurrent_activation='sigmoid',**\r\n                                recurrent_initializer='glorot_uniform',\r\n                                )\r\n\r\nI'm a little confused about what version is using the GRU implementation, in the documentation says the CPU compatible is v1 see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\r\n\r\nMany thanks!!"}