{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5952", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5952/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5952/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5952/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5952", "id": 192404334, "node_id": "MDU6SXNzdWUxOTI0MDQzMzQ=", "number": 5952, "title": "pthread cond_wait deadlock on assignment via tf.while_loop", "user": {"login": "jramapuram", "id": 8204807, "node_id": "MDQ6VXNlcjgyMDQ4MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/8204807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jramapuram", "html_url": "https://github.com/jramapuram", "followers_url": "https://api.github.com/users/jramapuram/followers", "following_url": "https://api.github.com/users/jramapuram/following{/other_user}", "gists_url": "https://api.github.com/users/jramapuram/gists{/gist_id}", "starred_url": "https://api.github.com/users/jramapuram/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jramapuram/subscriptions", "organizations_url": "https://api.github.com/users/jramapuram/orgs", "repos_url": "https://api.github.com/users/jramapuram/repos", "events_url": "https://api.github.com/users/jramapuram/events{/privacy}", "received_events_url": "https://api.github.com/users/jramapuram/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-29T21:27:11Z", "updated_at": "2017-06-19T15:10:28Z", "closed_at": "2017-06-16T16:01:40Z", "author_association": "NONE", "body_html": "<p>State:</p>\n<ul>\n<li>tf 0.12RC0 (installed via pip URL)</li>\n<li>Ubuntu 16.04</li>\n<li>cuda 8.0 w/cudnn 5.1</li>\n</ul>\n<p>Ran python through gdb and it looks like there is a deadlock?</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    index <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>)\n    values_0 <span class=\"pl-k\">=</span> [tf.constant(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32), tf.zeros([<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">100</span>])]\n    cond <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">val</span>: tf.less(i, <span class=\"pl-c1\">10</span>)\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_update</span>(<span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">val</span>):\n        row <span class=\"pl-k\">=</span> tf.random_normal([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>])\n        update <span class=\"pl-k\">=</span> val <span class=\"pl-k\">+</span> tf.concat(<span class=\"pl-c1\">0</span>, [tf.zeros([i, <span class=\"pl-c1\">100</span>]),\n                                     row,\n                                     tf.zeros([<span class=\"pl-c1\">10</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span><span class=\"pl-k\">-</span>i, <span class=\"pl-c1\">100</span>])])\n       <span class=\"pl-c\"><span class=\"pl-c\">#</span> Just to verify sizing</span>\n        <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>update = <span class=\"pl-pds\">'</span></span>, update.get_shape().as_list(), \\\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span> | values_0 = <span class=\"pl-pds\">'</span></span>, values_0[<span class=\"pl-c1\">1</span>].get_shape().as_list()\n\n        <span class=\"pl-k\">return</span> [i<span class=\"pl-k\">+</span>i, update]\n\n    _, values_t <span class=\"pl-k\">=</span> tf.while_loop(cond, _update, values_0,\n                                <span class=\"pl-v\">parallel_iterations</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\n\n    <span class=\"pl-c1\">print</span> sess.run(values_t)</pre></div>\n<p>Is this expected behavior? I want to update different rows of the matrix in parallel and this seemed somewhat logical to me. Since each row is independent it \"shouldn't\" really collide even if it is in parallel.</p>", "body_text": "State:\n\ntf 0.12RC0 (installed via pip URL)\nUbuntu 16.04\ncuda 8.0 w/cudnn 5.1\n\nRan python through gdb and it looks like there is a deadlock?\nimport tensorflow as tf\n\nwith tf.Session() as sess:\n    index = tf.constant(0)\n    values_0 = [tf.constant(0, dtype=tf.int32), tf.zeros([10, 100])]\n    cond = lambda i, val: tf.less(i, 10)\n    def _update(i, val):\n        row = tf.random_normal([1, 100])\n        update = val + tf.concat(0, [tf.zeros([i, 100]),\n                                     row,\n                                     tf.zeros([10-1-i, 100])])\n       # Just to verify sizing\n        print 'update = ', update.get_shape().as_list(), \\\n            ' | values_0 = ', values_0[1].get_shape().as_list()\n\n        return [i+i, update]\n\n    _, values_t = tf.while_loop(cond, _update, values_0,\n                                parallel_iterations=10)\n\n    print sess.run(values_t)\nIs this expected behavior? I want to update different rows of the matrix in parallel and this seemed somewhat logical to me. Since each row is independent it \"shouldn't\" really collide even if it is in parallel.", "body": "State:\r\n- tf 0.12RC0 (installed via pip URL)\r\n- Ubuntu 16.04\r\n- cuda 8.0 w/cudnn 5.1\r\n\r\nRan python through gdb and it looks like there is a deadlock?\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.Session() as sess:\r\n    index = tf.constant(0)\r\n    values_0 = [tf.constant(0, dtype=tf.int32), tf.zeros([10, 100])]\r\n    cond = lambda i, val: tf.less(i, 10)\r\n    def _update(i, val):\r\n        row = tf.random_normal([1, 100])\r\n        update = val + tf.concat(0, [tf.zeros([i, 100]),\r\n                                     row,\r\n                                     tf.zeros([10-1-i, 100])])\r\n       # Just to verify sizing\r\n        print 'update = ', update.get_shape().as_list(), \\\r\n            ' | values_0 = ', values_0[1].get_shape().as_list()\r\n\r\n        return [i+i, update]\r\n\r\n    _, values_t = tf.while_loop(cond, _update, values_0,\r\n                                parallel_iterations=10)\r\n\r\n    print sess.run(values_t)\r\n```\r\n\r\nIs this expected behavior? I want to update different rows of the matrix in parallel and this seemed somewhat logical to me. Since each row is independent it \"shouldn't\" really collide even if it is in parallel."}