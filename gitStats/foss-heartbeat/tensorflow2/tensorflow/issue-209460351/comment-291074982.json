{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291074982", "html_url": "https://github.com/tensorflow/tensorflow/issues/7778#issuecomment-291074982", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7778", "id": 291074982, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTA3NDk4Mg==", "user": {"login": "hughsando", "id": 1665494, "node_id": "MDQ6VXNlcjE2NjU0OTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1665494?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughsando", "html_url": "https://github.com/hughsando", "followers_url": "https://api.github.com/users/hughsando/followers", "following_url": "https://api.github.com/users/hughsando/following{/other_user}", "gists_url": "https://api.github.com/users/hughsando/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughsando/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughsando/subscriptions", "organizations_url": "https://api.github.com/users/hughsando/orgs", "repos_url": "https://api.github.com/users/hughsando/repos", "events_url": "https://api.github.com/users/hughsando/events{/privacy}", "received_events_url": "https://api.github.com/users/hughsando/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T08:06:38Z", "updated_at": "2017-04-03T08:06:38Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">I wonder if a solution to this problem might to to treat the cpu\narchitectures as different processors, like \"cpu\", \"gpu\", \"cpu-avx\".  Then\nthe kernels can register multiple versions, and the runtime can choose\nwhere to run depending on the client machine.\nThis could be done for the main \"hot\" inference functions (eg, Conv2D), and\nthe deployment problem would largely go away.\nCustom builds for training is not so difficult to manage - the community\nwheels look like a good idea.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sun, Apr 2, 2017 at 10:43 PM, Yaroslav Bulatov ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/hughsando\">@hughsando</a> &lt;<a href=\"https://github.com/hughsando\">https://github.com/hughsando</a>&gt; PS people have been uploading\n wheels built for their favorite configuration to\n <a href=\"https://github.com/yaroslavvb/tensorflow-community-wheels\">https://github.com/yaroslavvb/tensorflow-community-wheels</a>\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"209460351\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7778\" href=\"https://github.com/tensorflow/tensorflow/issues/7778#issuecomment-290990644\">#7778 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABlp1q-aGPy-lna8-2DLAo7xGrl04_3Wks5rr7P9gaJpZM4MIq5A\">https://github.com/notifications/unsubscribe-auth/ABlp1q-aGPy-lna8-2DLAo7xGrl04_3Wks5rr7P9gaJpZM4MIq5A</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "I wonder if a solution to this problem might to to treat the cpu\narchitectures as different processors, like \"cpu\", \"gpu\", \"cpu-avx\".  Then\nthe kernels can register multiple versions, and the runtime can choose\nwhere to run depending on the client machine.\nThis could be done for the main \"hot\" inference functions (eg, Conv2D), and\nthe deployment problem would largely go away.\nCustom builds for training is not so difficult to manage - the community\nwheels look like a good idea.\n\u2026\nOn Sun, Apr 2, 2017 at 10:43 PM, Yaroslav Bulatov ***@***.***> wrote:\n @hughsando <https://github.com/hughsando> PS people have been uploading\n wheels built for their favorite configuration to\n https://github.com/yaroslavvb/tensorflow-community-wheels\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#7778 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABlp1q-aGPy-lna8-2DLAo7xGrl04_3Wks5rr7P9gaJpZM4MIq5A>\n .", "body": "I wonder if a solution to this problem might to to treat the cpu\narchitectures as different processors, like \"cpu\", \"gpu\", \"cpu-avx\".  Then\nthe kernels can register multiple versions, and the runtime can choose\nwhere to run depending on the client machine.\nThis could be done for the main \"hot\" inference functions (eg, Conv2D), and\nthe deployment problem would largely go away.\nCustom builds for training is not so difficult to manage - the community\nwheels look like a good idea.\n\n\nOn Sun, Apr 2, 2017 at 10:43 PM, Yaroslav Bulatov <notifications@github.com>\nwrote:\n\n> @hughsando <https://github.com/hughsando> PS people have been uploading\n> wheels built for their favorite configuration to\n> https://github.com/yaroslavvb/tensorflow-community-wheels\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7778#issuecomment-290990644>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABlp1q-aGPy-lna8-2DLAo7xGrl04_3Wks5rr7P9gaJpZM4MIq5A>\n> .\n>\n"}