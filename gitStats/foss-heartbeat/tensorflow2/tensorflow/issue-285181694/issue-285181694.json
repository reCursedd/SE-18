{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15725", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15725/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15725/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15725/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15725", "id": 285181694, "node_id": "MDU6SXNzdWUyODUxODE2OTQ=", "number": 15725, "title": "Source Built r1.4 on GPUs with CPU optimized is always slower than 'no cpu optimization'", "user": {"login": "inscite", "id": 20734988, "node_id": "MDQ6VXNlcjIwNzM0OTg4", "avatar_url": "https://avatars2.githubusercontent.com/u/20734988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/inscite", "html_url": "https://github.com/inscite", "followers_url": "https://api.github.com/users/inscite/followers", "following_url": "https://api.github.com/users/inscite/following{/other_user}", "gists_url": "https://api.github.com/users/inscite/gists{/gist_id}", "starred_url": "https://api.github.com/users/inscite/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/inscite/subscriptions", "organizations_url": "https://api.github.com/users/inscite/orgs", "repos_url": "https://api.github.com/users/inscite/repos", "events_url": "https://api.github.com/users/inscite/events{/privacy}", "received_events_url": "https://api.github.com/users/inscite/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-12-30T03:46:20Z", "updated_at": "2018-01-30T02:00:04Z", "closed_at": "2018-01-30T02:00:04Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: Yes, the model named PSIque <a href=\"https://arxiv.org/abs/1711.10644\" rel=\"nofollow\">arXiv:1711.10644</a></li>\n<li><strong>OS Platform and Distribution</strong>: CentOS 7.1/CentOS 7.3</li>\n<li><strong>TensorFlow installed from</strong>: source build w/ Bazel</li>\n<li><strong>TensorFlow version</strong>: 1.4</li>\n<li><strong>Python version</strong>: Anaconda 3.6.2</li>\n<li><strong>Bazel version</strong>: 0.8.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 8.0/r375.26/cuDNN 6.0.0 &amp; CUDA 9.0/r384.81/cuDNN 7.0.5</li>\n<li><strong>GPU model and memory</strong>: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB</li>\n<li><strong>Exact command to reproduce</strong>: python model.py</li>\n</ul>\n<h3>Describe the problem</h3>\n<ul>\n<li>\n<p>I built tensorflow from source for boosting operation performance.</p>\n</li>\n<li>\n<p>6 different distributions were built;</p>\n<ul>\n<li>CPU only &amp; No CPU optimization (NO EXTRA flags)</li>\n<li>CPU only &amp; CPU optimization (--config=opt)</li>\n<li>GPU support &amp; CUDA 8/9 &amp; No CPU optimization (--config=cuda)</li>\n<li>GPU support &amp; CUDA 8/9 &amp; CPU optimization (--config=opt --config=cuda)</li>\n</ul>\n</li>\n<li>\n<p>Experiments were basically done by 5 phases; experiments on CPU only are still going on,<br>\nso please focus on GPU version results.</p>\n</li>\n<li>\n<p>Results are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/20734988/34451067-1d8c1cf0-ed5e-11e7-9a4f-3ff21a5c9aea.png\"><img src=\"https://user-images.githubusercontent.com/20734988/34451067-1d8c1cf0-ed5e-11e7-9a4f-3ff21a5c9aea.png\" alt=\"results\" style=\"max-width:100%;\"></a></p>\n</li>\n<li>\n<p>Test were made on multiple machine with random order.</p>\n<ul>\n<li>P100: 2 nodes</li>\n<li>K40m: 7 nodes</li>\n<li>CPU only: 8 nodes</li>\n</ul>\n</li>\n<li>\n<p>I am curious why CPU optimized version is slow</p>\n<ul>\n<li>on every experiment combinations</li>\n<li>even different GPU environments</li>\n<li>even Dual CPU socket (E5-2660v3)</li>\n</ul>\n</li>\n<li>\n<p>(Extra) I believe my current model does not require high throughputs</p>\n</li>\n</ul>\n<h3>tf_env_collect.sh</h3>\n<p>== cat /etc/issue ===============================================<br>\nLinux  3.10.0-229.el7.x86_64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"7 (Core)\"<br>\nVERSION_ID=\"7\"<br>\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"<br>\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)<br>\nCopyright (C) 2013 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux vis5 3.10.0-229.el7.x86_64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.3)<br>\nprotobuf (3.4.0)<br>\ntensorflow (1.4.0)<br>\ntensorflow-tensorboard (0.4.0rc3)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.4.0<br>\ntf.GIT_VERSION = b'unknown'<br>\ntf.COMPILER_VERSION = b'unknown'<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nSat Dec 30 12:39:08 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |<br>\n| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |<br>\n| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    1     68169      C   python                                     15643MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176<br>\n/usr/local/cuda-9.0/lib64/libcudart_static.a</p>", "body_text": "System information\n\nHave I written custom code: Yes, the model named PSIque arXiv:1711.10644\nOS Platform and Distribution: CentOS 7.1/CentOS 7.3\nTensorFlow installed from: source build w/ Bazel\nTensorFlow version: 1.4\nPython version: Anaconda 3.6.2\nBazel version: 0.8.1\nGCC/Compiler version (if compiling from source): gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)\nCUDA/cuDNN version: CUDA 8.0/r375.26/cuDNN 6.0.0 & CUDA 9.0/r384.81/cuDNN 7.0.5\nGPU model and memory: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB\nExact command to reproduce: python model.py\n\nDescribe the problem\n\n\nI built tensorflow from source for boosting operation performance.\n\n\n6 different distributions were built;\n\nCPU only & No CPU optimization (NO EXTRA flags)\nCPU only & CPU optimization (--config=opt)\nGPU support & CUDA 8/9 & No CPU optimization (--config=cuda)\nGPU support & CUDA 8/9 & CPU optimization (--config=opt --config=cuda)\n\n\n\nExperiments were basically done by 5 phases; experiments on CPU only are still going on,\nso please focus on GPU version results.\n\n\nResults are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.\n\n\n\nTest were made on multiple machine with random order.\n\nP100: 2 nodes\nK40m: 7 nodes\nCPU only: 8 nodes\n\n\n\nI am curious why CPU optimized version is slow\n\non every experiment combinations\neven different GPU environments\neven Dual CPU socket (E5-2660v3)\n\n\n\n(Extra) I believe my current model does not require high throughputs\n\n\ntf_env_collect.sh\n== cat /etc/issue ===============================================\nLinux  3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"7 (Core)\"\nVERSION_ID=\"7\"\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux vis5 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.4.0)\ntensorflow (1.4.0)\ntensorflow-tensorboard (0.4.0rc3)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.4.0\ntf.GIT_VERSION = b'unknown'\ntf.COMPILER_VERSION = b'unknown'\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nSat Dec 30 12:39:08 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |\n| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    1     68169      C   python                                     15643MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\n/usr/local/cuda-9.0/lib64/libcudart_static.a", "body": "### System information\r\n- **Have I written custom code**: Yes, the model named PSIque [arXiv:1711.10644](https://arxiv.org/abs/1711.10644)\r\n- **OS Platform and Distribution**: CentOS 7.1/CentOS 7.3\r\n- **TensorFlow installed from**: source build w/ Bazel\r\n- **TensorFlow version**: 1.4\r\n- **Python version**: Anaconda 3.6.2\r\n- **Bazel version**: 0.8.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)\r\n- **CUDA/cuDNN version**: CUDA 8.0/r375.26/cuDNN 6.0.0 & CUDA 9.0/r384.81/cuDNN 7.0.5 \r\n- **GPU model and memory**: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB\r\n- **Exact command to reproduce**: python model.py\r\n\r\n### Describe the problem\r\n* I built tensorflow from source for boosting operation performance.\r\n\r\n* 6 different distributions were built;\r\n  * CPU only & No CPU optimization (NO EXTRA flags)\r\n  * CPU only & CPU optimization (--config=opt)\r\n  * GPU support & CUDA 8/9 & No CPU optimization (--config=cuda)\r\n  * GPU support & CUDA 8/9 & CPU optimization (--config=opt --config=cuda)\r\n\r\n* Experiments were basically done by 5 phases; experiments on CPU only are still going on,\r\nso please focus on GPU version results.\r\n\r\n* Results are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.\r\n![results](https://user-images.githubusercontent.com/20734988/34451067-1d8c1cf0-ed5e-11e7-9a4f-3ff21a5c9aea.png)\r\n\r\n* Test were made on multiple machine with random order.\r\n  * P100: 2 nodes\r\n  * K40m: 7 nodes\r\n  * CPU only: 8 nodes\r\n\r\n* I am curious why CPU optimized version is slow\r\n  * on every experiment combinations\r\n  * even different GPU environments\r\n  * even Dual CPU socket (E5-2660v3)\r\n\r\n* (Extra) I believe my current model does not require high throughputs\r\n\r\n### tf_env_collect.sh\r\n== cat /etc/issue ===============================================\r\nLinux <hostname> 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7 (Core)\"\r\nVERSION_ID=\"7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux vis5 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.4.0)\r\ntensorflow (1.4.0)\r\ntensorflow-tensorboard (0.4.0rc3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.0\r\ntf.GIT_VERSION = b'unknown'\r\ntf.COMPILER_VERSION = b'unknown'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nSat Dec 30 12:39:08 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\r\n| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |\r\n| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    1     68169      C   python                                     15643MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n"}