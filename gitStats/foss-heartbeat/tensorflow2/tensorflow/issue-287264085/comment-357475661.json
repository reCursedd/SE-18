{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357475661", "html_url": "https://github.com/tensorflow/tensorflow/issues/15985#issuecomment-357475661", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15985", "id": 357475661, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzQ3NTY2MQ==", "user": {"login": "selcouthlyBlue", "id": 13268675, "node_id": "MDQ6VXNlcjEzMjY4Njc1", "avatar_url": "https://avatars2.githubusercontent.com/u/13268675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/selcouthlyBlue", "html_url": "https://github.com/selcouthlyBlue", "followers_url": "https://api.github.com/users/selcouthlyBlue/followers", "following_url": "https://api.github.com/users/selcouthlyBlue/following{/other_user}", "gists_url": "https://api.github.com/users/selcouthlyBlue/gists{/gist_id}", "starred_url": "https://api.github.com/users/selcouthlyBlue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/selcouthlyBlue/subscriptions", "organizations_url": "https://api.github.com/users/selcouthlyBlue/orgs", "repos_url": "https://api.github.com/users/selcouthlyBlue/repos", "events_url": "https://api.github.com/users/selcouthlyBlue/events{/privacy}", "received_events_url": "https://api.github.com/users/selcouthlyBlue/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-13T23:26:20Z", "updated_at": "2018-01-14T00:28:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I already got it working! Turns out, the <code>sequence_length</code> parameter I was passing is a scalar but it should be a 1-d vector according to the <a href=\"https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/connectionist_temporal_classification__ctc_#ctc_loss\" rel=\"nofollow\">documentation</a>:</p>\n<blockquote>\n<p>sequence_length: 1-D int32 vector, size [batch_size]. The sequence lengths.</p>\n</blockquote>\n<p>The code for converting a dense tensor into a sparse one is as follows:</p>\n<pre><code>def dense_to_sparse(dense_tensor, out_type):\n    indices = tf.where(tf.not_equal(dense_tensor, tf.constant(0, dense_tensor.dtype)\n    values = tf.gather_nd(dense_tensor, indices)\n    shape = tf.shape(dense_tensor, out_type=out_type)\n    return tf.SparseTensor(indices, values, shape)\n</code></pre>\n<p>Now the questions is whether to have this op exist or just put it inside <code>tf.nn.ctc_loss</code>.,, or maybe both. Thoughts, anyone?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21050803\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Holded\">@Holded</a></p>", "body_text": "I already got it working! Turns out, the sequence_length parameter I was passing is a scalar but it should be a 1-d vector according to the documentation:\n\nsequence_length: 1-D int32 vector, size [batch_size]. The sequence lengths.\n\nThe code for converting a dense tensor into a sparse one is as follows:\ndef dense_to_sparse(dense_tensor, out_type):\n    indices = tf.where(tf.not_equal(dense_tensor, tf.constant(0, dense_tensor.dtype)\n    values = tf.gather_nd(dense_tensor, indices)\n    shape = tf.shape(dense_tensor, out_type=out_type)\n    return tf.SparseTensor(indices, values, shape)\n\nNow the questions is whether to have this op exist or just put it inside tf.nn.ctc_loss.,, or maybe both. Thoughts, anyone?\n@Holded", "body": "I already got it working! Turns out, the `sequence_length` parameter I was passing is a scalar but it should be a 1-d vector according to the [documentation](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/connectionist_temporal_classification__ctc_#ctc_loss):\r\n\r\n> sequence_length: 1-D int32 vector, size [batch_size]. The sequence lengths. \r\n\r\nThe code for converting a dense tensor into a sparse one is as follows:\r\n\r\n```\r\ndef dense_to_sparse(dense_tensor, out_type):\r\n    indices = tf.where(tf.not_equal(dense_tensor, tf.constant(0, dense_tensor.dtype)\r\n    values = tf.gather_nd(dense_tensor, indices)\r\n    shape = tf.shape(dense_tensor, out_type=out_type)\r\n    return tf.SparseTensor(indices, values, shape)\r\n```\r\n\r\nNow the questions is whether to have this op exist or just put it inside `tf.nn.ctc_loss`.,, or maybe both. Thoughts, anyone?\r\n\r\n@Holded "}