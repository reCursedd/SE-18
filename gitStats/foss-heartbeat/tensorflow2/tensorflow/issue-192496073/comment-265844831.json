{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/265844831", "html_url": "https://github.com/tensorflow/tensorflow/issues/5972#issuecomment-265844831", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5972", "id": 265844831, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NTg0NDgzMQ==", "user": {"login": "keveman", "id": 229914, "node_id": "MDQ6VXNlcjIyOTkxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/229914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keveman", "html_url": "https://github.com/keveman", "followers_url": "https://api.github.com/users/keveman/followers", "following_url": "https://api.github.com/users/keveman/following{/other_user}", "gists_url": "https://api.github.com/users/keveman/gists{/gist_id}", "starred_url": "https://api.github.com/users/keveman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keveman/subscriptions", "organizations_url": "https://api.github.com/users/keveman/orgs", "repos_url": "https://api.github.com/users/keveman/repos", "events_url": "https://api.github.com/users/keveman/events{/privacy}", "received_events_url": "https://api.github.com/users/keveman/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-08T20:22:11Z", "updated_at": "2016-12-08T20:22:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=59132\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/albertz\">@albertz</a> Sorry, I was too quick to pull the trigger on this one. What you are trying to do is morally equivalent to the following code, which is supported by TensorFlow :</p>\n<pre><code>import tensorflow as tf\nsess = tf.InteractiveSession()\n\ninit = tf.placeholder(tf.float32)\na = tf.Variable(init,validate_shape=False)\n\nb = a+1\nc = tf.gradients(b, a)[0]\n\n# run the graph with [1] as the shape for the variable a\nsess.run(a.initializer, feed_dict={init: [1.0]})\nc_val = c.eval()\nprint(c_val)\n\n# run the graph with [2] as the shape for the variable a\nsess.run(a.initializer, feed_dict={init: [1.0, 2.0]})\nc_val = c.eval()\nprint(c_val)\n</code></pre>\n<p>Although I have to say, this use case is pretty esoteric. It looks like we can support this in the <code>AdamOptimizer</code>. Feel free to send PR. I am reopening this and marking as 'contributions welcome'.</p>", "body_text": "@albertz Sorry, I was too quick to pull the trigger on this one. What you are trying to do is morally equivalent to the following code, which is supported by TensorFlow :\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\ninit = tf.placeholder(tf.float32)\na = tf.Variable(init,validate_shape=False)\n\nb = a+1\nc = tf.gradients(b, a)[0]\n\n# run the graph with [1] as the shape for the variable a\nsess.run(a.initializer, feed_dict={init: [1.0]})\nc_val = c.eval()\nprint(c_val)\n\n# run the graph with [2] as the shape for the variable a\nsess.run(a.initializer, feed_dict={init: [1.0, 2.0]})\nc_val = c.eval()\nprint(c_val)\n\nAlthough I have to say, this use case is pretty esoteric. It looks like we can support this in the AdamOptimizer. Feel free to send PR. I am reopening this and marking as 'contributions welcome'.", "body": "@albertz Sorry, I was too quick to pull the trigger on this one. What you are trying to do is morally equivalent to the following code, which is supported by TensorFlow :\r\n\r\n    import tensorflow as tf\r\n    sess = tf.InteractiveSession()\r\n\r\n    init = tf.placeholder(tf.float32)\r\n    a = tf.Variable(init,validate_shape=False)\r\n\r\n    b = a+1\r\n    c = tf.gradients(b, a)[0]\r\n\r\n    # run the graph with [1] as the shape for the variable a\r\n    sess.run(a.initializer, feed_dict={init: [1.0]})\r\n    c_val = c.eval()\r\n    print(c_val)\r\n\r\n    # run the graph with [2] as the shape for the variable a\r\n    sess.run(a.initializer, feed_dict={init: [1.0, 2.0]})\r\n    c_val = c.eval()\r\n    print(c_val)\r\n\r\nAlthough I have to say, this use case is pretty esoteric. It looks like we can support this in the `AdamOptimizer`. Feel free to send PR. I am reopening this and marking as 'contributions welcome'."}