{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19186", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19186/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19186/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19186/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19186", "id": 321661110, "node_id": "MDU6SXNzdWUzMjE2NjExMTA=", "number": 19186, "title": "[tf.keras] Bug with Stateful Metrics & Fit Generator", "user": {"login": "brge17", "id": 33430930, "node_id": "MDQ6VXNlcjMzNDMwOTMw", "avatar_url": "https://avatars3.githubusercontent.com/u/33430930?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brge17", "html_url": "https://github.com/brge17", "followers_url": "https://api.github.com/users/brge17/followers", "following_url": "https://api.github.com/users/brge17/following{/other_user}", "gists_url": "https://api.github.com/users/brge17/gists{/gist_id}", "starred_url": "https://api.github.com/users/brge17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brge17/subscriptions", "organizations_url": "https://api.github.com/users/brge17/orgs", "repos_url": "https://api.github.com/users/brge17/repos", "events_url": "https://api.github.com/users/brge17/events{/privacy}", "received_events_url": "https://api.github.com/users/brge17/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-05-09T17:36:48Z", "updated_at": "2018-05-14T19:38:20Z", "closed_at": "2018-05-14T19:38:19Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.8.0</li>\n<li><strong>Python version</strong>:  2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: n/a</li>\n<li><strong>GPU model and memory</strong>: n/a</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<p>The stateful metrics integration with fit generator is not working. This can be demonstrated by taking the Keras metrics tests from the latest release and changing the imports to TensorFlow.keras (see <a href=\"https://github.com/keras-team/keras/blob/master/tests/keras/metrics_test.py\">https://github.com/keras-team/keras/blob/master/tests/keras/metrics_test.py</a>):</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\nimport numpy as np\n\nclass BinaryTruePositives(tf.keras.layers.Layer):\n    \"\"\"Stateful Metric to count the total true positives over all batches.\n    Assumes predictions and targets of shape `(samples, 1)`.\n    # Arguments\n        name: String, name for the metric.\n    \"\"\"\n\n    def __init__(self, name='true_positives', **kwargs):\n        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n        self.stateful = True\n        self.true_positives = K.variable(value=0, dtype='int32')\n\n    def reset_states(self):\n        K.set_value(self.true_positives, 0)\n\n    def __call__(self, y_true, y_pred):\n        \"\"\"Computes the number of true positives in a batch.\n        # Arguments\n            y_true: Tensor, batch_wise labels\n            y_pred: Tensor, batch_wise predictions\n        # Returns\n            The total number of true positives seen this epoch at the\n                completion of the batch.\n        \"\"\"\n        y_true = K.cast(y_true, 'int32')\n        y_pred = K.cast(K.round(y_pred), 'int32')\n        correct_preds = K.cast(K.equal(y_pred, y_true), 'int32')\n        true_pos = K.cast(K.sum(correct_preds * y_true), 'int32')\n        current_true_pos = self.true_positives * 1\n        self.add_update(K.update_add(self.true_positives,\n                                     true_pos),\n                        inputs=[y_true, y_pred])\n        return current_true_pos + true_pos\n\n# Test on simple model\ninputs = tf.keras.Input(shape=(2,))\noutputs = tf.keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(optimizer='sgd',\n              loss='binary_crossentropy',\n              metrics=['acc', BinaryTruePositives()])\n\nsamples = 1000\nx = np.random.random((samples, 2))\ny = np.random.randint(2, size=(samples, 1))\n\nval_samples = 10\nval_x = np.random.random((val_samples, 2))\nval_y = np.random.randint(2, size=(val_samples, 1))\n\n# Test fit and evaluate\nhistory = model.fit(x, y, validation_data=(val_x, val_y), epochs=2, batch_size=10)\nouts = model.evaluate(x, y, batch_size=10)\npreds = model.predict(x)\n\ndef ref_true_pos(y_true, y_pred):\n    return np.sum(np.logical_and(y_pred &gt; 0.5, y_true == 1))\n\n# Test correctness (e.g. updates should have been run)\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n\n# Test correctness of the validation metric computation\nval_preds = model.predict(val_x)\nval_outs = model.evaluate(val_x, val_y, batch_size=10)\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n\n# Test with generators\ngen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\nval_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\nhistory = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n                              validation_data=iter(val_gen), validation_steps=val_samples)\nouts = model.evaluate_generator(iter(gen), steps=samples)\npreds = model.predict_generator(iter(gen), steps=samples)\n\n# Test correctness of the metric re ref_true_pos()\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n\n# Test correctness of the validation metric computation\nval_preds = model.predict_generator(iter(val_gen), steps=val_samples)\nval_outs = model.evaluate_generator(iter(val_gen), steps=val_samples)\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n</code></pre>\n<p>In addition the progress bar is not working with fit generator. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below): 1.8.0\nPython version:  2.7\nBazel version (if compiling from source): n/a\nGCC/Compiler version (if compiling from source): n/a\nCUDA/cuDNN version: n/a\nGPU model and memory: n/a\nExact command to reproduce: n/a\n\nThe stateful metrics integration with fit generator is not working. This can be demonstrated by taking the Keras metrics tests from the latest release and changing the imports to TensorFlow.keras (see https://github.com/keras-team/keras/blob/master/tests/keras/metrics_test.py):\nimport tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\nimport numpy as np\n\nclass BinaryTruePositives(tf.keras.layers.Layer):\n    \"\"\"Stateful Metric to count the total true positives over all batches.\n    Assumes predictions and targets of shape `(samples, 1)`.\n    # Arguments\n        name: String, name for the metric.\n    \"\"\"\n\n    def __init__(self, name='true_positives', **kwargs):\n        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n        self.stateful = True\n        self.true_positives = K.variable(value=0, dtype='int32')\n\n    def reset_states(self):\n        K.set_value(self.true_positives, 0)\n\n    def __call__(self, y_true, y_pred):\n        \"\"\"Computes the number of true positives in a batch.\n        # Arguments\n            y_true: Tensor, batch_wise labels\n            y_pred: Tensor, batch_wise predictions\n        # Returns\n            The total number of true positives seen this epoch at the\n                completion of the batch.\n        \"\"\"\n        y_true = K.cast(y_true, 'int32')\n        y_pred = K.cast(K.round(y_pred), 'int32')\n        correct_preds = K.cast(K.equal(y_pred, y_true), 'int32')\n        true_pos = K.cast(K.sum(correct_preds * y_true), 'int32')\n        current_true_pos = self.true_positives * 1\n        self.add_update(K.update_add(self.true_positives,\n                                     true_pos),\n                        inputs=[y_true, y_pred])\n        return current_true_pos + true_pos\n\n# Test on simple model\ninputs = tf.keras.Input(shape=(2,))\noutputs = tf.keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(optimizer='sgd',\n              loss='binary_crossentropy',\n              metrics=['acc', BinaryTruePositives()])\n\nsamples = 1000\nx = np.random.random((samples, 2))\ny = np.random.randint(2, size=(samples, 1))\n\nval_samples = 10\nval_x = np.random.random((val_samples, 2))\nval_y = np.random.randint(2, size=(val_samples, 1))\n\n# Test fit and evaluate\nhistory = model.fit(x, y, validation_data=(val_x, val_y), epochs=2, batch_size=10)\nouts = model.evaluate(x, y, batch_size=10)\npreds = model.predict(x)\n\ndef ref_true_pos(y_true, y_pred):\n    return np.sum(np.logical_and(y_pred > 0.5, y_true == 1))\n\n# Test correctness (e.g. updates should have been run)\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n\n# Test correctness of the validation metric computation\nval_preds = model.predict(val_x)\nval_outs = model.evaluate(val_x, val_y, batch_size=10)\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n\n# Test with generators\ngen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\nval_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\nhistory = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n                              validation_data=iter(val_gen), validation_steps=val_samples)\nouts = model.evaluate_generator(iter(gen), steps=samples)\npreds = model.predict_generator(iter(gen), steps=samples)\n\n# Test correctness of the metric re ref_true_pos()\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n\n# Test correctness of the validation metric computation\nval_preds = model.predict_generator(iter(val_gen), steps=val_samples)\nval_outs = model.evaluate_generator(iter(val_gen), steps=val_samples)\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n\nIn addition the progress bar is not working with fit generator. @fchollet", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\nThe stateful metrics integration with fit generator is not working. This can be demonstrated by taking the Keras metrics tests from the latest release and changing the imports to TensorFlow.keras (see https://github.com/keras-team/keras/blob/master/tests/keras/metrics_test.py):\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras import backend as K\r\n\r\nimport numpy as np\r\n\r\nclass BinaryTruePositives(tf.keras.layers.Layer):\r\n    \"\"\"Stateful Metric to count the total true positives over all batches.\r\n    Assumes predictions and targets of shape `(samples, 1)`.\r\n    # Arguments\r\n        name: String, name for the metric.\r\n    \"\"\"\r\n\r\n    def __init__(self, name='true_positives', **kwargs):\r\n        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\r\n        self.stateful = True\r\n        self.true_positives = K.variable(value=0, dtype='int32')\r\n\r\n    def reset_states(self):\r\n        K.set_value(self.true_positives, 0)\r\n\r\n    def __call__(self, y_true, y_pred):\r\n        \"\"\"Computes the number of true positives in a batch.\r\n        # Arguments\r\n            y_true: Tensor, batch_wise labels\r\n            y_pred: Tensor, batch_wise predictions\r\n        # Returns\r\n            The total number of true positives seen this epoch at the\r\n                completion of the batch.\r\n        \"\"\"\r\n        y_true = K.cast(y_true, 'int32')\r\n        y_pred = K.cast(K.round(y_pred), 'int32')\r\n        correct_preds = K.cast(K.equal(y_pred, y_true), 'int32')\r\n        true_pos = K.cast(K.sum(correct_preds * y_true), 'int32')\r\n        current_true_pos = self.true_positives * 1\r\n        self.add_update(K.update_add(self.true_positives,\r\n                                     true_pos),\r\n                        inputs=[y_true, y_pred])\r\n        return current_true_pos + true_pos\r\n\r\n# Test on simple model\r\ninputs = tf.keras.Input(shape=(2,))\r\noutputs = tf.keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)\r\nmodel = tf.keras.Model(inputs, outputs)\r\n\r\nmodel.compile(optimizer='sgd',\r\n              loss='binary_crossentropy',\r\n              metrics=['acc', BinaryTruePositives()])\r\n\r\nsamples = 1000\r\nx = np.random.random((samples, 2))\r\ny = np.random.randint(2, size=(samples, 1))\r\n\r\nval_samples = 10\r\nval_x = np.random.random((val_samples, 2))\r\nval_y = np.random.randint(2, size=(val_samples, 1))\r\n\r\n# Test fit and evaluate\r\nhistory = model.fit(x, y, validation_data=(val_x, val_y), epochs=2, batch_size=10)\r\nouts = model.evaluate(x, y, batch_size=10)\r\npreds = model.predict(x)\r\n\r\ndef ref_true_pos(y_true, y_pred):\r\n    return np.sum(np.logical_and(y_pred > 0.5, y_true == 1))\r\n\r\n# Test correctness (e.g. updates should have been run)\r\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\r\n\r\n# Test correctness of the validation metric computation\r\nval_preds = model.predict(val_x)\r\nval_outs = model.evaluate(val_x, val_y, batch_size=10)\r\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\r\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\r\n\r\n# Test with generators\r\ngen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\r\nval_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\r\nhistory = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\r\n                              validation_data=iter(val_gen), validation_steps=val_samples)\r\nouts = model.evaluate_generator(iter(gen), steps=samples)\r\npreds = model.predict_generator(iter(gen), steps=samples)\r\n\r\n# Test correctness of the metric re ref_true_pos()\r\nnp.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\r\n\r\n# Test correctness of the validation metric computation\r\nval_preds = model.predict_generator(iter(val_gen), steps=val_samples)\r\nval_outs = model.evaluate_generator(iter(val_gen), steps=val_samples)\r\nnp.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\r\nnp.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\r\n```\r\n\r\nIn addition the progress bar is not working with fit generator. @fchollet \r\n\r\n"}