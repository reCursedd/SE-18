{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/402329215", "html_url": "https://github.com/tensorflow/tensorflow/issues/17150#issuecomment-402329215", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17150", "id": 402329215, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjMyOTIxNQ==", "user": {"login": "johntrimble", "id": 156620, "node_id": "MDQ6VXNlcjE1NjYyMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/156620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johntrimble", "html_url": "https://github.com/johntrimble", "followers_url": "https://api.github.com/users/johntrimble/followers", "following_url": "https://api.github.com/users/johntrimble/following{/other_user}", "gists_url": "https://api.github.com/users/johntrimble/gists{/gist_id}", "starred_url": "https://api.github.com/users/johntrimble/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johntrimble/subscriptions", "organizations_url": "https://api.github.com/users/johntrimble/orgs", "repos_url": "https://api.github.com/users/johntrimble/repos", "events_url": "https://api.github.com/users/johntrimble/events{/privacy}", "received_events_url": "https://api.github.com/users/johntrimble/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-04T00:35:45Z", "updated_at": "2018-07-04T00:35:45Z", "author_association": "NONE", "body_html": "<p>I am convinced this is working. I did a little test to make sure masking is handled correctly, and all looks well:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow <span class=\"pl-k\">import</span> keras\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ndense_layer <span class=\"pl-k\">=</span> keras.layers.Dense(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>)\n\nmodel <span class=\"pl-k\">=</span> keras.Sequential()\nmodel.add(keras.layers.Embedding(<span class=\"pl-c1\">11</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-v\">mask_zero</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">embeddings_initializer</span><span class=\"pl-k\">=</span>keras.initializers.Constant(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>)))\nmodel.add(dense_layer)\nmodel.compile(<span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>adam<span class=\"pl-pds\">'</span></span>,\n              <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sparse_categorical_crossentropy<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Set the weights for our dense layer such that each category has the same</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> probability except for 1, which will have a lower probability</span>\nnew_weights <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> weight <span class=\"pl-k\">in</span> dense_layer.get_weights():\n    <span class=\"pl-k\">if</span> weight.shape <span class=\"pl-k\">==</span> (<span class=\"pl-c1\">6</span>,<span class=\"pl-c1\">10</span>):\n        weight <span class=\"pl-k\">=</span> np.full_like(weight, <span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n        weight[:,<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>.\n    new_weights.append(weight)\ndense_layer.set_weights(new_weights)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Create random dataset where each sample has a different length with 0 padding</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> and none of the labels use category 1</span>\nx_data <span class=\"pl-k\">=</span> np.zeros((<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">20</span>))\ny_data <span class=\"pl-k\">=</span> np.zeros((<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">20</span>, <span class=\"pl-c1\">1</span>))\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">32</span>):\n    length <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">20</span>)\n    x_data[i, <span class=\"pl-c1\">0</span>:length] <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>length)\n    y_data[i, <span class=\"pl-c1\">0</span>:length] <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(length, <span class=\"pl-c1\">1</span>))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Evaluate to get the cost</span>\ncost1 <span class=\"pl-k\">=</span> model.evaluate(x_data, <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>y_data)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Change the 0s to 1s in the labels. If masking is handled correctly, this</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> shouldn't matter as these labels will be ignored anyway. If masking is not</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> handled correctly, then the cost should go up as the probability of 1 being</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> the correct category is lower than any other category</span>\ny_data[y_data <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\ncost2 <span class=\"pl-k\">=</span> model.evaluate(x_data, <span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>y_data)\n\n<span class=\"pl-k\">assert</span> cost1 <span class=\"pl-k\">==</span> cost2</pre></div>\n<p>It is possible that there needs to be an update to the documentation to make it clearer as to what the shape of the labels should be. It is perhaps a bit counter intuitive that an extra dimension of size 1 needs to be tacked on. Code-wise though, this appears to be working.</p>", "body_text": "I am convinced this is working. I did a little test to make sure masking is handled correctly, and all looks well:\nfrom tensorflow import keras\nimport numpy as np\n\ndense_layer = keras.layers.Dense(10, activation='softmax')\n\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(11, 6, mask_zero=True, embeddings_initializer=keras.initializers.Constant(value=0.1)))\nmodel.add(dense_layer)\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy')\n\n# Set the weights for our dense layer such that each category has the same\n# probability except for 1, which will have a lower probability\nnew_weights = []\nfor weight in dense_layer.get_weights():\n    if weight.shape == (6,10):\n        weight = np.full_like(weight, 0.1, dtype='float32')\n        weight[:,1] = -2.\n    new_weights.append(weight)\ndense_layer.set_weights(new_weights)\n\n# Create random dataset where each sample has a different length with 0 padding\n# and none of the labels use category 1\nx_data = np.zeros((32, 20))\ny_data = np.zeros((32, 20, 1))\nfor i in range(32):\n    length = np.random.randint(1, 20)\n    x_data[i, 0:length] = np.random.randint(2, 10, size=length)\n    y_data[i, 0:length] = np.random.randint(2, 10, size=(length, 1))\n\n# Evaluate to get the cost\ncost1 = model.evaluate(x_data, y=y_data)\n\n# Change the 0s to 1s in the labels. If masking is handled correctly, this\n# shouldn't matter as these labels will be ignored anyway. If masking is not\n# handled correctly, then the cost should go up as the probability of 1 being\n# the correct category is lower than any other category\ny_data[y_data == 0] = 1\n\ncost2 = model.evaluate(x_data, y=y_data)\n\nassert cost1 == cost2\nIt is possible that there needs to be an update to the documentation to make it clearer as to what the shape of the labels should be. It is perhaps a bit counter intuitive that an extra dimension of size 1 needs to be tacked on. Code-wise though, this appears to be working.", "body": "I am convinced this is working. I did a little test to make sure masking is handled correctly, and all looks well:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\ndense_layer = keras.layers.Dense(10, activation='softmax')\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Embedding(11, 6, mask_zero=True, embeddings_initializer=keras.initializers.Constant(value=0.1)))\r\nmodel.add(dense_layer)\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy')\r\n\r\n# Set the weights for our dense layer such that each category has the same\r\n# probability except for 1, which will have a lower probability\r\nnew_weights = []\r\nfor weight in dense_layer.get_weights():\r\n    if weight.shape == (6,10):\r\n        weight = np.full_like(weight, 0.1, dtype='float32')\r\n        weight[:,1] = -2.\r\n    new_weights.append(weight)\r\ndense_layer.set_weights(new_weights)\r\n\r\n# Create random dataset where each sample has a different length with 0 padding\r\n# and none of the labels use category 1\r\nx_data = np.zeros((32, 20))\r\ny_data = np.zeros((32, 20, 1))\r\nfor i in range(32):\r\n    length = np.random.randint(1, 20)\r\n    x_data[i, 0:length] = np.random.randint(2, 10, size=length)\r\n    y_data[i, 0:length] = np.random.randint(2, 10, size=(length, 1))\r\n\r\n# Evaluate to get the cost\r\ncost1 = model.evaluate(x_data, y=y_data)\r\n\r\n# Change the 0s to 1s in the labels. If masking is handled correctly, this\r\n# shouldn't matter as these labels will be ignored anyway. If masking is not\r\n# handled correctly, then the cost should go up as the probability of 1 being\r\n# the correct category is lower than any other category\r\ny_data[y_data == 0] = 1\r\n\r\ncost2 = model.evaluate(x_data, y=y_data)\r\n\r\nassert cost1 == cost2\r\n```\r\n\r\nIt is possible that there needs to be an update to the documentation to make it clearer as to what the shape of the labels should be. It is perhaps a bit counter intuitive that an extra dimension of size 1 needs to be tacked on. Code-wise though, this appears to be working."}