{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/390437207", "html_url": "https://github.com/tensorflow/tensorflow/issues/17150#issuecomment-390437207", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17150", "id": 390437207, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MDQzNzIwNw==", "user": {"login": "johntrimble", "id": 156620, "node_id": "MDQ6VXNlcjE1NjYyMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/156620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johntrimble", "html_url": "https://github.com/johntrimble", "followers_url": "https://api.github.com/users/johntrimble/followers", "following_url": "https://api.github.com/users/johntrimble/following{/other_user}", "gists_url": "https://api.github.com/users/johntrimble/gists{/gist_id}", "starred_url": "https://api.github.com/users/johntrimble/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johntrimble/subscriptions", "organizations_url": "https://api.github.com/users/johntrimble/orgs", "repos_url": "https://api.github.com/users/johntrimble/repos", "events_url": "https://api.github.com/users/johntrimble/events{/privacy}", "received_events_url": "https://api.github.com/users/johntrimble/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-19T22:37:21Z", "updated_at": "2018-05-19T22:37:21Z", "author_association": "NONE", "body_html": "<p>For seq2seq at least, I think the suggested workaround with a custom <code>sparse_loss</code> function should not return a scalar (i.e. don't use <code>reduce_mean</code>). The <code>weighted_masked_objective</code> decorator will take care of that. If the loss function returns a scalar, then masking will not work appropriately. I also don't think using <code>tf.reduce_mean(foo, axis=-1)</code> will work either as it will change the shape from (samples, time-steps) to (samples) also breaking masking.</p>", "body_text": "For seq2seq at least, I think the suggested workaround with a custom sparse_loss function should not return a scalar (i.e. don't use reduce_mean). The weighted_masked_objective decorator will take care of that. If the loss function returns a scalar, then masking will not work appropriately. I also don't think using tf.reduce_mean(foo, axis=-1) will work either as it will change the shape from (samples, time-steps) to (samples) also breaking masking.", "body": "For seq2seq at least, I think the suggested workaround with a custom `sparse_loss` function should not return a scalar (i.e. don't use `reduce_mean`). The `weighted_masked_objective` decorator will take care of that. If the loss function returns a scalar, then masking will not work appropriately. I also don't think using `tf.reduce_mean(foo, axis=-1)` will work either as it will change the shape from (samples, time-steps) to (samples) also breaking masking."}