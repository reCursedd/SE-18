{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/332676523", "html_url": "https://github.com/tensorflow/tensorflow/pull/11922#issuecomment-332676523", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11922", "id": 332676523, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjY3NjUyMw==", "user": {"login": "liuzjmike", "id": 15717157, "node_id": "MDQ6VXNlcjE1NzE3MTU3", "avatar_url": "https://avatars1.githubusercontent.com/u/15717157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzjmike", "html_url": "https://github.com/liuzjmike", "followers_url": "https://api.github.com/users/liuzjmike/followers", "following_url": "https://api.github.com/users/liuzjmike/following{/other_user}", "gists_url": "https://api.github.com/users/liuzjmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzjmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzjmike/subscriptions", "organizations_url": "https://api.github.com/users/liuzjmike/orgs", "repos_url": "https://api.github.com/users/liuzjmike/repos", "events_url": "https://api.github.com/users/liuzjmike/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzjmike/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-27T22:43:09Z", "updated_at": "2017-09-27T22:43:09Z", "author_association": "NONE", "body_html": "<pre><code>bazel run //tensorflow/python:batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\n</code></pre>\n<p>gives <code>Unrecognized option: --benchmarks=BatchNormBenchmark.benchmark_batch_norm</code>.</p>\n<pre><code>bazel-bin/tensorflow/python/batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\n</code></pre>\n<p>gives the following output:</p>\n<p>On original impl:</p>\n<pre><code>Forward convolution (lower layers).\n2017-09-27 18:27:39.204075: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.049103 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.0491034030914\n}\n\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.109263 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.109263372421\n}\n\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.182931 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.182931375504\n}\n\n=== op vs py: 122.5% ===\n=== py vs slow: 67.4% ===\n2017-09-27 18:27:42.277512: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\nAbort (core dumped)\n</code></pre>\n<p>On proposed impl:</p>\n<pre><code>Forward convolution (lower layers).\n2017-09-27 18:30:13.324701: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.047454 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.0474540233612\n}\n\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.191871 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.191870594025\n}\n\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.180249 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.180248832703\n}\n\n=== op vs py: 304.3% ===\n=== py vs slow: -6.1% ===\n2017-09-27 18:30:33.873145: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\nAbort (core dumped)\n</code></pre>", "body_text": "bazel run //tensorflow/python:batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\n\ngives Unrecognized option: --benchmarks=BatchNormBenchmark.benchmark_batch_norm.\nbazel-bin/tensorflow/python/batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\n\ngives the following output:\nOn original impl:\nForward convolution (lower layers).\n2017-09-27 18:27:39.204075: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.049103 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.0491034030914\n}\n\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.109263 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.109263372421\n}\n\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.182931 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.182931375504\n}\n\n=== op vs py: 122.5% ===\n=== py vs slow: 67.4% ===\n2017-09-27 18:27:42.277512: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\nAbort (core dumped)\n\nOn proposed impl:\nForward convolution (lower layers).\n2017-09-27 18:30:13.324701: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.047454 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.0474540233612\n}\n\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.191871 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.191870594025\n}\n\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.180249 secs\nentry {\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\n  iters: 5\n  wall_time: 0.180248832703\n}\n\n=== op vs py: 304.3% ===\n=== py vs slow: -6.1% ===\n2017-09-27 18:30:33.873145: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\nAbort (core dumped)", "body": "```\r\nbazel run //tensorflow/python:batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\r\n```\r\ngives `Unrecognized option: --benchmarks=BatchNormBenchmark.benchmark_batch_norm`.\r\n```\r\nbazel-bin/tensorflow/python/batch_norm_benchmark --benchmarks=BatchNormBenchmark.benchmark_batch_norm\r\n```\r\ngives the following output:\r\n\r\nOn original impl:\r\n```\r\nForward convolution (lower layers).\r\n2017-09-27 18:27:39.204075: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.049103 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.0491034030914\r\n}\r\n\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.109263 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.109263372421\r\n}\r\n\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.182931 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.182931375504\r\n}\r\n\r\n=== op vs py: 122.5% ===\r\n=== py vs slow: 67.4% ===\r\n2017-09-27 18:27:42.277512: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\r\nAbort (core dumped)\r\n```\r\n\r\nOn proposed impl:\r\n```\r\nForward convolution (lower layers).\r\n2017-09-27 18:30:13.324701: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\ncpu shape:4/3 #layers:10 mode:op scale:True train:False - 0.047454 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_op_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.0474540233612\r\n}\r\n\r\ncpu shape:4/3 #layers:10 mode:py scale:True train:False - 0.191871 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_py_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.191870594025\r\n}\r\n\r\ncpu shape:4/3 #layers:10 mode:slow scale:True train:False - 0.180249 secs\r\nentry {\r\n  name: \"BatchNormBenchmark.batch_norm_cpu_input_shape_[8,128,128,32]_axes_[0,1,2]_mode_slow_layers_10_scale_True_train_False\"\r\n  iters: 5\r\n  wall_time: 0.180248832703\r\n}\r\n\r\n=== op vs py: 304.3% ===\r\n=== py vs slow: -6.1% ===\r\n2017-09-27 18:30:33.873145: F tensorflow/core/common_runtime/gpu/gpu_device.cc:131] Check failed: err == cudaSuccess (2 vs. 0)\r\nAbort (core dumped)"}