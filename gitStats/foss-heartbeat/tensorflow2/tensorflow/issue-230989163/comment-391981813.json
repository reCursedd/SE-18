{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/391981813", "html_url": "https://github.com/tensorflow/tensorflow/issues/10155#issuecomment-391981813", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10155", "id": 391981813, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTk4MTgxMw==", "user": {"login": "mixuala", "id": 31947245, "node_id": "MDQ6VXNlcjMxOTQ3MjQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/31947245?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mixuala", "html_url": "https://github.com/mixuala", "followers_url": "https://api.github.com/users/mixuala/followers", "following_url": "https://api.github.com/users/mixuala/following{/other_user}", "gists_url": "https://api.github.com/users/mixuala/gists{/gist_id}", "starred_url": "https://api.github.com/users/mixuala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mixuala/subscriptions", "organizations_url": "https://api.github.com/users/mixuala/orgs", "repos_url": "https://api.github.com/users/mixuala/repos", "events_url": "https://api.github.com/users/mixuala/events{/privacy}", "received_events_url": "https://api.github.com/users/mixuala/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T08:31:25Z", "updated_at": "2018-05-25T08:31:25Z", "author_association": "NONE", "body_html": "<p>I'm using the following <code>SessionRunHook</code> to warm_start with an <code>exclude=[\"Logits\"]</code> filter\u2013\u2013useful for excluding the last FC layer of a pre-trained model. but shouldn't it be easier?</p>\n<pre><code>class RestoreHook(tf.train.SessionRunHook):\n  \"\"\"restores model from a checkpoint_path with include/exclude variable filtering from\n  see:\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/assign_from_checkpoint_fn\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore\n  \n  args:\n    checkpoint_path: full path to checkpoint\n    include: an optional list/tuple of scope strings for filtering which\n      variables from the VARIABLES collection to include. None would include all\n      the variables.\n    exclude: an optional list/tuple of scope strings for filtering which\n      variables from the VARIABLES collection to exclude. None it would not\n      exclude any.\n  \n  use in combination with tf.Estimator `training_hooks`\n\n  \n  usage:\n    def main():\n      checkpoint_path = \"/path/to/checkpoint/file.ckpt\"\n      restore_hook = RestoreHook(checkpoint_path, exclude=['Logits'])\n      estimator = tf.estimator.Estimator( model_fn=model_fn, \n                                          warm_start_from=None\n                                         )\n      estimator.train(, hooks=[restore_hook,])\n\n  \"\"\"\n  def __init__(self, checkpoint_path, include=None, exclude=None ):\n      self.checkpoint_path = checkpoint_path\n      self.include = include\n      self.exclude = exclude\n\n  def after_create_session(self, session, coord=None):\n      # delay until AFTER graph is created\n      var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)\n      self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(\n              checkpoint_path,\n              var_list=var_list,\n              ignore_missing_vars=True\n              )      \n      if session.run(tf.train.get_or_create_global_step()) == 0:\n          # suppress WARN\n          log_level = tf.logging.get_verbosity()\n          tf.logging.set_verbosity(tf.logging.ERROR)\n          self.init_fn(session)\n          tf.logging.set_verbosity(log_level)\n          \n</code></pre>", "body_text": "I'm using the following SessionRunHook to warm_start with an exclude=[\"Logits\"] filter\u2013\u2013useful for excluding the last FC layer of a pre-trained model. but shouldn't it be easier?\nclass RestoreHook(tf.train.SessionRunHook):\n  \"\"\"restores model from a checkpoint_path with include/exclude variable filtering from\n  see:\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/assign_from_checkpoint_fn\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore\n  \n  args:\n    checkpoint_path: full path to checkpoint\n    include: an optional list/tuple of scope strings for filtering which\n      variables from the VARIABLES collection to include. None would include all\n      the variables.\n    exclude: an optional list/tuple of scope strings for filtering which\n      variables from the VARIABLES collection to exclude. None it would not\n      exclude any.\n  \n  use in combination with tf.Estimator `training_hooks`\n\n  \n  usage:\n    def main():\n      checkpoint_path = \"/path/to/checkpoint/file.ckpt\"\n      restore_hook = RestoreHook(checkpoint_path, exclude=['Logits'])\n      estimator = tf.estimator.Estimator( model_fn=model_fn, \n                                          warm_start_from=None\n                                         )\n      estimator.train(, hooks=[restore_hook,])\n\n  \"\"\"\n  def __init__(self, checkpoint_path, include=None, exclude=None ):\n      self.checkpoint_path = checkpoint_path\n      self.include = include\n      self.exclude = exclude\n\n  def after_create_session(self, session, coord=None):\n      # delay until AFTER graph is created\n      var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)\n      self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(\n              checkpoint_path,\n              var_list=var_list,\n              ignore_missing_vars=True\n              )      \n      if session.run(tf.train.get_or_create_global_step()) == 0:\n          # suppress WARN\n          log_level = tf.logging.get_verbosity()\n          tf.logging.set_verbosity(tf.logging.ERROR)\n          self.init_fn(session)\n          tf.logging.set_verbosity(log_level)", "body": "I'm using the following `SessionRunHook` to warm_start with an `exclude=[\"Logits\"]` filter\u2013\u2013useful for excluding the last FC layer of a pre-trained model. but shouldn't it be easier?\r\n\r\n```\r\nclass RestoreHook(tf.train.SessionRunHook):\r\n  \"\"\"restores model from a checkpoint_path with include/exclude variable filtering from\r\n  see:\r\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/assign_from_checkpoint_fn\r\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore\r\n  \r\n  args:\r\n    checkpoint_path: full path to checkpoint\r\n    include: an optional list/tuple of scope strings for filtering which\r\n      variables from the VARIABLES collection to include. None would include all\r\n      the variables.\r\n    exclude: an optional list/tuple of scope strings for filtering which\r\n      variables from the VARIABLES collection to exclude. None it would not\r\n      exclude any.\r\n  \r\n  use in combination with tf.Estimator `training_hooks`\r\n\r\n  \r\n  usage:\r\n    def main():\r\n      checkpoint_path = \"/path/to/checkpoint/file.ckpt\"\r\n      restore_hook = RestoreHook(checkpoint_path, exclude=['Logits'])\r\n      estimator = tf.estimator.Estimator( model_fn=model_fn, \r\n                                          warm_start_from=None\r\n                                         )\r\n      estimator.train(, hooks=[restore_hook,])\r\n\r\n  \"\"\"\r\n  def __init__(self, checkpoint_path, include=None, exclude=None ):\r\n      self.checkpoint_path = checkpoint_path\r\n      self.include = include\r\n      self.exclude = exclude\r\n\r\n  def after_create_session(self, session, coord=None):\r\n      # delay until AFTER graph is created\r\n      var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)\r\n      self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(\r\n              checkpoint_path,\r\n              var_list=var_list,\r\n              ignore_missing_vars=True\r\n              )      \r\n      if session.run(tf.train.get_or_create_global_step()) == 0:\r\n          # suppress WARN\r\n          log_level = tf.logging.get_verbosity()\r\n          tf.logging.set_verbosity(tf.logging.ERROR)\r\n          self.init_fn(session)\r\n          tf.logging.set_verbosity(log_level)\r\n          \r\n```"}