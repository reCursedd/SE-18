{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/437430085", "html_url": "https://github.com/tensorflow/tensorflow/issues/10155#issuecomment-437430085", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10155", "id": 437430085, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzQzMDA4NQ==", "user": {"login": "eddie-zhou", "id": 35045937, "node_id": "MDQ6VXNlcjM1MDQ1OTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/35045937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddie-zhou", "html_url": "https://github.com/eddie-zhou", "followers_url": "https://api.github.com/users/eddie-zhou/followers", "following_url": "https://api.github.com/users/eddie-zhou/following{/other_user}", "gists_url": "https://api.github.com/users/eddie-zhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddie-zhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddie-zhou/subscriptions", "organizations_url": "https://api.github.com/users/eddie-zhou/orgs", "repos_url": "https://api.github.com/users/eddie-zhou/repos", "events_url": "https://api.github.com/users/eddie-zhou/events{/privacy}", "received_events_url": "https://api.github.com/users/eddie-zhou/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-09T17:17:33Z", "updated_at": "2018-11-09T17:17:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I apologize for the convoluted (no pun intended) API here -- there are users who want to warm-start variables from the GLOBAL_VARIABLES collection (such as batch norm or optimizer accumulator vars, which aren't added to TRAINABLE_VARIABLES), and we also needed to ensure backwards compatibility.  So tangibly, we have the following options for vars_to_warm_start:</p>\n<ul>\n<li>regexp, which applies tf.get_collection to TRAINABLE_VARIABLES</li>\n<li>list of tf.Variable, which is explicit</li>\n<li>list of strings, each a regex scope to provide to tf.get_collection on GLOBAL_VARIABLES</li>\n<li><code>None</code></li>\n</ul>\n<p>An upcoming release's documentation should make this more clear.</p>", "body_text": "I apologize for the convoluted (no pun intended) API here -- there are users who want to warm-start variables from the GLOBAL_VARIABLES collection (such as batch norm or optimizer accumulator vars, which aren't added to TRAINABLE_VARIABLES), and we also needed to ensure backwards compatibility.  So tangibly, we have the following options for vars_to_warm_start:\n\nregexp, which applies tf.get_collection to TRAINABLE_VARIABLES\nlist of tf.Variable, which is explicit\nlist of strings, each a regex scope to provide to tf.get_collection on GLOBAL_VARIABLES\nNone\n\nAn upcoming release's documentation should make this more clear.", "body": "I apologize for the convoluted (no pun intended) API here -- there are users who want to warm-start variables from the GLOBAL_VARIABLES collection (such as batch norm or optimizer accumulator vars, which aren't added to TRAINABLE_VARIABLES), and we also needed to ensure backwards compatibility.  So tangibly, we have the following options for vars_to_warm_start:\r\n\r\n- regexp, which applies tf.get_collection to TRAINABLE_VARIABLES\r\n- list of tf.Variable, which is explicit\r\n- list of strings, each a regex scope to provide to tf.get_collection on GLOBAL_VARIABLES\r\n- `None`\r\n\r\nAn upcoming release's documentation should make this more clear."}