{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3351", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3351/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3351/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3351/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/3351", "id": 165985459, "node_id": "MDExOlB1bGxSZXF1ZXN0Nzc3NDAzOTA=", "number": 3351, "title": "Fix gradient of prod op using cumprod", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2016-07-17T17:03:44Z", "updated_at": "2016-08-22T23:32:37Z", "closed_at": "2016-07-18T17:47:40Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/3351", "html_url": "https://github.com/tensorflow/tensorflow/pull/3351", "diff_url": "https://github.com/tensorflow/tensorflow/pull/3351.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/3351.patch"}, "body_html": "<p>This is an initial shot at fixing <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"158408706\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2641\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2641/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2641\">#2641</a> (NaNs in the gradient of <code>tf.reduce_prod</code> when the input is <code>0</code>).<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=70511\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/girving\">@girving</a> suggested to use two calls to <code>cumprod</code> and to multiply the outputs to produce an array containing the products of all values without the current one, like this:</p>\n<pre><code>input: [0, 1, 2, 3, 4]\ncumprod1: [1, 0, 0, 0, 0]\ncumprod2 (reverse): [24, 24, 12, 4, 1]\ngradient: [24, 0, 0, 0, 0]\n</code></pre>\n<p>The difficulty with this is handling the fact that <code>tf.reduce_prod</code> can calculate the product over a subset of the tensor dimensions.<br>\nWhen solving this in Python, quite a bit of transposing and reshaping is required.<br>\nThe idea is to reshape the input into a tensor with shape <code>[N, M]</code>, where the first dimension contains all the entries that we reduced over, and the second dimension contains the remaining ones.<br>\nI've pushed a Python solution using the approach that makes the reduction op tests pass.<br>\nAs you can see, the gradient code is a bit complicated.<br>\nMaybe someone knows a shortcut that makes this simpler?</p>\n<p>There might be other solutions that could be better here:<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6969686\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benoitsteiner\">@benoitsteiner</a> suggested that <code>tf.cumprod</code> could be changed to take a list of dimensions to scan over instead of a single axis. This would bring it more in line with the reduction ops.<br>\nI think this could be implemented without modifying Eigen, by using various Eigen methods to reshape and transpose the input.</p>", "body_text": "This is an initial shot at fixing #2641 (NaNs in the gradient of tf.reduce_prod when the input is 0).\n@girving suggested to use two calls to cumprod and to multiply the outputs to produce an array containing the products of all values without the current one, like this:\ninput: [0, 1, 2, 3, 4]\ncumprod1: [1, 0, 0, 0, 0]\ncumprod2 (reverse): [24, 24, 12, 4, 1]\ngradient: [24, 0, 0, 0, 0]\n\nThe difficulty with this is handling the fact that tf.reduce_prod can calculate the product over a subset of the tensor dimensions.\nWhen solving this in Python, quite a bit of transposing and reshaping is required.\nThe idea is to reshape the input into a tensor with shape [N, M], where the first dimension contains all the entries that we reduced over, and the second dimension contains the remaining ones.\nI've pushed a Python solution using the approach that makes the reduction op tests pass.\nAs you can see, the gradient code is a bit complicated.\nMaybe someone knows a shortcut that makes this simpler?\nThere might be other solutions that could be better here:\n@benoitsteiner suggested that tf.cumprod could be changed to take a list of dimensions to scan over instead of a single axis. This would bring it more in line with the reduction ops.\nI think this could be implemented without modifying Eigen, by using various Eigen methods to reshape and transpose the input.", "body": "This is an initial shot at fixing #2641 (NaNs in the gradient of `tf.reduce_prod` when the input is `0`).\n@girving suggested to use two calls to `cumprod` and to multiply the outputs to produce an array containing the products of all values without the current one, like this:\n\n```\ninput: [0, 1, 2, 3, 4]\ncumprod1: [1, 0, 0, 0, 0]\ncumprod2 (reverse): [24, 24, 12, 4, 1]\ngradient: [24, 0, 0, 0, 0]\n```\n\nThe difficulty with this is handling the fact that `tf.reduce_prod` can calculate the product over a subset of the tensor dimensions.\nWhen solving this in Python, quite a bit of transposing and reshaping is required.\nThe idea is to reshape the input into a tensor with shape `[N, M]`, where the first dimension contains all the entries that we reduced over, and the second dimension contains the remaining ones.\nI've pushed a Python solution using the approach that makes the reduction op tests pass.\nAs you can see, the gradient code is a bit complicated.\nMaybe someone knows a shortcut that makes this simpler?\n\nThere might be other solutions that could be better here:\n@benoitsteiner suggested that `tf.cumprod` could be changed to take a list of dimensions to scan over instead of a single axis. This would bring it more in line with the reduction ops.\nI think this could be implemented without modifying Eigen, by using various Eigen methods to reshape and transpose the input.\n"}