{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1517", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1517/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1517/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1517/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1517", "id": 141058520, "node_id": "MDU6SXNzdWUxNDEwNTg1MjA=", "number": 1517, "title": "Extend existing ops to complex128", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2016-03-15T18:20:48Z", "updated_at": "2016-05-29T20:56:22Z", "closed_at": "2016-05-29T20:56:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a follow-up to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"139042460\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1420\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1420/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1420\">#1420</a>.<br>\nNow that <code>complex128</code> is supported in tensorflow, we should extend existing ops like <code>complex</code>, <code>real</code>, <code>imag</code>, \u2026 to support <code>complex128</code> as well.<br>\nI've already done some work on this, but I'm currently stuck on expressing dependencies between input and output types.<br>\nFor example, the spec for the <code>Real</code> op is currently</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Real<span class=\"pl-pds\">\"</span></span>)\n    .Input(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>in: complex64<span class=\"pl-pds\">\"</span></span>)\n    .Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>out: float<span class=\"pl-pds\">\"</span></span>);</pre></div>\n<p>I've extended this to</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Real<span class=\"pl-pds\">\"</span></span>)\n    .Input(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>in: T<span class=\"pl-pds\">\"</span></span>)\n    .Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>out: Tout<span class=\"pl-pds\">\"</span></span>)\n    .Attr(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>T: {complex64, complex128} = DT_COMPLEX64<span class=\"pl-pds\">\"</span></span>)\n    .Attr(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tout: {float, double} = DT_FLOAT<span class=\"pl-pds\">\"</span></span>);</pre></div>\n<p>and specified corresponding <code>Tout</code> constraints when registering the kernels.</p>\n<p>The problem is that the auto-generated Python op will default to <code>float32</code> for the output.<br>\n(It also turns <code>Tout</code> into an optional argument).<br>\nI'd like to express \"If <code>T==complex128</code>, then <code>Tout==float64</code>\" somehow.</p>\n<p>The only way of doing it that I could come up with is by writing a Python wrapper that essentially does</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">real</span>(<span class=\"pl-k\">in</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">in</span>.dtype <span class=\"pl-k\">==</span> tf.complex64:\n        Tout <span class=\"pl-k\">=</span> tf.float32\n    <span class=\"pl-k\">elif</span> <span class=\"pl-k\">in</span>.dtype <span class=\"pl-k\">==</span> tf.complex128:\n        Tout <span class=\"pl-k\">=</span> tf.float64\n    <span class=\"pl-k\">return</span> generated_real(<span class=\"pl-k\">in</span>, <span class=\"pl-v\">Tout</span><span class=\"pl-k\">=</span>Tout)</pre></div>\n<p>Would that be an acceptable solution, or is there a better one?</p>", "body_text": "This is a follow-up to #1420.\nNow that complex128 is supported in tensorflow, we should extend existing ops like complex, real, imag, \u2026 to support complex128 as well.\nI've already done some work on this, but I'm currently stuck on expressing dependencies between input and output types.\nFor example, the spec for the Real op is currently\nREGISTER_OP(\"Real\")\n    .Input(\"in: complex64\")\n    .Output(\"out: float\");\nI've extended this to\nREGISTER_OP(\"Real\")\n    .Input(\"in: T\")\n    .Output(\"out: Tout\")\n    .Attr(\"T: {complex64, complex128} = DT_COMPLEX64\")\n    .Attr(\"Tout: {float, double} = DT_FLOAT\");\nand specified corresponding Tout constraints when registering the kernels.\nThe problem is that the auto-generated Python op will default to float32 for the output.\n(It also turns Tout into an optional argument).\nI'd like to express \"If T==complex128, then Tout==float64\" somehow.\nThe only way of doing it that I could come up with is by writing a Python wrapper that essentially does\ndef real(in):\n    if in.dtype == tf.complex64:\n        Tout = tf.float32\n    elif in.dtype == tf.complex128:\n        Tout = tf.float64\n    return generated_real(in, Tout=Tout)\nWould that be an acceptable solution, or is there a better one?", "body": "This is a follow-up to #1420.\nNow that `complex128` is supported in tensorflow, we should extend existing ops like `complex`, `real`, `imag`, \u2026 to support `complex128` as well.\nI've already done some work on this, but I'm currently stuck on expressing dependencies between input and output types.\nFor example, the spec for the `Real` op is currently\n\n``` c++\nREGISTER_OP(\"Real\")\n    .Input(\"in: complex64\")\n    .Output(\"out: float\");\n```\n\nI've extended this to\n\n``` c++\nREGISTER_OP(\"Real\")\n    .Input(\"in: T\")\n    .Output(\"out: Tout\")\n    .Attr(\"T: {complex64, complex128} = DT_COMPLEX64\")\n    .Attr(\"Tout: {float, double} = DT_FLOAT\");\n```\n\nand specified corresponding `Tout` constraints when registering the kernels.\n\nThe problem is that the auto-generated Python op will default to `float32` for the output.\n(It also turns `Tout` into an optional argument).\nI'd like to express \"If `T==complex128`, then `Tout==float64`\" somehow.\n\nThe only way of doing it that I could come up with is by writing a Python wrapper that essentially does\n\n``` python\ndef real(in):\n    if in.dtype == tf.complex64:\n        Tout = tf.float32\n    elif in.dtype == tf.complex128:\n        Tout = tf.float64\n    return generated_real(in, Tout=Tout)\n```\n\nWould that be an acceptable solution, or is there a better one?\n"}