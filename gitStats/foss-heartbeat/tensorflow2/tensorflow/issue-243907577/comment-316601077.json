{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316601077", "html_url": "https://github.com/tensorflow/tensorflow/issues/11598#issuecomment-316601077", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11598", "id": 316601077, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjYwMTA3Nw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-20T05:31:33Z", "updated_at": "2017-07-20T05:31:33Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">If you don't use attention then you can directly pass the tiled encoder\nstate as the initial state (assuming your encoder and decoder cells are the\nsame architecture).</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Jul 19, 2017 10:02 PM, \"zhedongzheng\" ***@***.***&gt; wrote:\n initial_state = decoder_cell.zero_state(128, tf.float32).clone(\n         cell_state=tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=10)),\n\n @ ebrevdo\n if I don't use attention, the error says:\n 'LSTMStateTuple' object has no attribute 'clone'\n is beam search forced to be used with attention?\n\n \u2014\n You are receiving this because you modified the open/close state.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"243907577\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11598\" href=\"https://github.com/tensorflow/tensorflow/issues/11598#issuecomment-316597391\">#11598 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim_2vyHpyWMx2Zjp9TUufg4g9EbZkks5sPt9-gaJpZM4OcKdG\">https://github.com/notifications/unsubscribe-auth/ABtim_2vyHpyWMx2Zjp9TUufg4g9EbZkks5sPt9-gaJpZM4OcKdG</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "If you don't use attention then you can directly pass the tiled encoder\nstate as the initial state (assuming your encoder and decoder cells are the\nsame architecture).\n\u2026\nOn Jul 19, 2017 10:02 PM, \"zhedongzheng\" ***@***.***> wrote:\n initial_state = decoder_cell.zero_state(128, tf.float32).clone(\n         cell_state=tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=10)),\n\n @ ebrevdo\n if I don't use attention, the error says:\n 'LSTMStateTuple' object has no attribute 'clone'\n is beam search forced to be used with attention?\n\n \u2014\n You are receiving this because you modified the open/close state.\n Reply to this email directly, view it on GitHub\n <#11598 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim_2vyHpyWMx2Zjp9TUufg4g9EbZkks5sPt9-gaJpZM4OcKdG>\n .", "body": "If you don't use attention then you can directly pass the tiled encoder\nstate as the initial state (assuming your encoder and decoder cells are the\nsame architecture).\n\nOn Jul 19, 2017 10:02 PM, \"zhedongzheng\" <notifications@github.com> wrote:\n\n> initial_state = decoder_cell.zero_state(128, tf.float32).clone(\n>         cell_state=tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=10)),\n>\n> @ ebrevdo\n> if I don't use attention, the error says:\n> 'LSTMStateTuple' object has no attribute 'clone'\n> is beam search forced to be used with attention?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11598#issuecomment-316597391>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim_2vyHpyWMx2Zjp9TUufg4g9EbZkks5sPt9-gaJpZM4OcKdG>\n> .\n>\n"}