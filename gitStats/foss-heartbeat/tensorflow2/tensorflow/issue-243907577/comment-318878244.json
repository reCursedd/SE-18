{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318878244", "html_url": "https://github.com/tensorflow/tensorflow/issues/11598#issuecomment-318878244", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11598", "id": 318878244, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODg3ODI0NA==", "user": {"login": "zhedongzheng", "id": 16261331, "node_id": "MDQ6VXNlcjE2MjYxMzMx", "avatar_url": "https://avatars2.githubusercontent.com/u/16261331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhedongzheng", "html_url": "https://github.com/zhedongzheng", "followers_url": "https://api.github.com/users/zhedongzheng/followers", "following_url": "https://api.github.com/users/zhedongzheng/following{/other_user}", "gists_url": "https://api.github.com/users/zhedongzheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhedongzheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhedongzheng/subscriptions", "organizations_url": "https://api.github.com/users/zhedongzheng/orgs", "repos_url": "https://api.github.com/users/zhedongzheng/repos", "events_url": "https://api.github.com/users/zhedongzheng/events{/privacy}", "received_events_url": "https://api.github.com/users/zhedongzheng/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-30T04:48:54Z", "updated_at": "2017-07-30T04:56:11Z", "author_association": "NONE", "body_html": "<p>okay, the key is to:</p>\n<ul>\n<li>tile the encoder state separately for LSTMStateTuple</li>\n<li>make sure impute_finished is False<br>\nthe complete code is:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.layers.core <span class=\"pl-k\">import</span> Dense\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> INPUTS</span>\nX <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>])\nY <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>])\nX_seq_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>])\nY_seq_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">None</span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ENCODER         </span>\nencoder_out, encoder_state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n    <span class=\"pl-v\">cell</span> <span class=\"pl-k\">=</span> tf.nn.rnn_cell.BasicLSTMCell(<span class=\"pl-c1\">128</span>), \n    <span class=\"pl-v\">inputs</span> <span class=\"pl-k\">=</span> tf.contrib.layers.embed_sequence(X, <span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">128</span>),\n    <span class=\"pl-v\">sequence_length</span> <span class=\"pl-k\">=</span> X_seq_len,\n    <span class=\"pl-v\">dtype</span> <span class=\"pl-k\">=</span> tf.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> DECODER COMPONENTS</span>\nY_vocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10000</span>\ndecoder_embedding <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([Y_vocab_size, <span class=\"pl-c1\">128</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>))\nprojection_layer <span class=\"pl-k\">=</span> Dense(Y_vocab_size)\ndecoder_cell <span class=\"pl-k\">=</span> tf.nn.rnn_cell.BasicLSTMCell(<span class=\"pl-c1\">128</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> TRAINING DECODER</span>\ntraining_helper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n    <span class=\"pl-v\">inputs</span> <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(decoder_embedding, Y),\n    <span class=\"pl-v\">sequence_length</span> <span class=\"pl-k\">=</span> Y_seq_len,\n    <span class=\"pl-v\">time_major</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>)\ntraining_decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n    <span class=\"pl-v\">cell</span> <span class=\"pl-k\">=</span> decoder_cell,\n    <span class=\"pl-v\">helper</span> <span class=\"pl-k\">=</span> training_helper,\n    <span class=\"pl-v\">initial_state</span> <span class=\"pl-k\">=</span> encoder_state,\n    <span class=\"pl-v\">output_layer</span> <span class=\"pl-k\">=</span> projection_layer)\ntraining_decoder_output, _, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n    <span class=\"pl-v\">decoder</span> <span class=\"pl-k\">=</span> training_decoder,\n    <span class=\"pl-v\">impute_finished</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>,\n    <span class=\"pl-v\">maximum_iterations</span> <span class=\"pl-k\">=</span> tf.reduce_max(Y_seq_len))\ntraining_logits <span class=\"pl-k\">=</span> training_decoder_output.rnn_output\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> PREDICTING_DECODER</span>\npredicting_decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BeamSearchDecoder(\n    <span class=\"pl-v\">cell</span> <span class=\"pl-k\">=</span> decoder_cell,\n    <span class=\"pl-v\">embedding</span> <span class=\"pl-k\">=</span> decoder_embedding,\n    <span class=\"pl-v\">start_tokens</span> <span class=\"pl-k\">=</span> tf.tile(tf.constant([<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32), [<span class=\"pl-c1\">128</span>]),\n    <span class=\"pl-v\">end_token</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>,\n    <span class=\"pl-v\">initial_state</span> <span class=\"pl-k\">=</span> tf.nn.rnn_cell.LSTMStateTuple(\n        tf.contrib.seq2seq.tile_batch(encoder_state[<span class=\"pl-c1\">0</span>], <span class=\"pl-v\">multiplier</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>),\n        tf.contrib.seq2seq.tile_batch(encoder_state[<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">multiplier</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)),,\n    <span class=\"pl-v\">beam_width</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>,\n    <span class=\"pl-v\">output_layer</span> <span class=\"pl-k\">=</span> projection_layer,\n    <span class=\"pl-v\">length_penalty_weight</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>)\npredicting_decoder_output, _, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n    <span class=\"pl-v\">decoder</span> <span class=\"pl-k\">=</span> predicting_decoder,\n    <span class=\"pl-v\">impute_finished</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>,\n    <span class=\"pl-v\">maximum_iterations</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">*</span> tf.reduce_max(Y_seq_len))\npredicting_logits <span class=\"pl-k\">=</span> predicting_decoder_output.sample_id\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> LOSS</span>\nmasks <span class=\"pl-k\">=</span> tf.sequence_mask(Y_seq_len, tf.reduce_max(Y_seq_len), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nloss <span class=\"pl-k\">=</span> tf.contrib.seq2seq.sequence_loss(<span class=\"pl-v\">logits</span> <span class=\"pl-k\">=</span> training_logits, <span class=\"pl-v\">targets</span> <span class=\"pl-k\">=</span> Y, <span class=\"pl-v\">weights</span> <span class=\"pl-k\">=</span> masks)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> BACKWARD</span>\nparams <span class=\"pl-k\">=</span> tf.trainable_variables()\ngradients <span class=\"pl-k\">=</span> tf.gradients(loss, params)\nclipped_gradients, _ <span class=\"pl-k\">=</span> tf.clip_by_global_norm(gradients, <span class=\"pl-c1\">5.0</span>)\ntrain_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().apply_gradients(<span class=\"pl-c1\">zip</span>(clipped_gradients, params))</pre></div>", "body_text": "okay, the key is to:\n\ntile the encoder state separately for LSTMStateTuple\nmake sure impute_finished is False\nthe complete code is:\n\nimport tensorflow as tf\nfrom tensorflow.python.layers.core import Dense\n\n# INPUTS\nX = tf.placeholder(tf.int32, [None, None])\nY = tf.placeholder(tf.int32, [None, None])\nX_seq_len = tf.placeholder(tf.int32, [None])\nY_seq_len = tf.placeholder(tf.int32, [None])\n\n# ENCODER         \nencoder_out, encoder_state = tf.nn.dynamic_rnn(\n    cell = tf.nn.rnn_cell.BasicLSTMCell(128), \n    inputs = tf.contrib.layers.embed_sequence(X, 10000, 128),\n    sequence_length = X_seq_len,\n    dtype = tf.float32)\n\n# DECODER COMPONENTS\nY_vocab_size = 10000\ndecoder_embedding = tf.Variable(tf.random_uniform([Y_vocab_size, 128], -1.0, 1.0))\nprojection_layer = Dense(Y_vocab_size)\ndecoder_cell = tf.nn.rnn_cell.BasicLSTMCell(128)\n\n# TRAINING DECODER\ntraining_helper = tf.contrib.seq2seq.TrainingHelper(\n    inputs = tf.nn.embedding_lookup(decoder_embedding, Y),\n    sequence_length = Y_seq_len,\n    time_major = False)\ntraining_decoder = tf.contrib.seq2seq.BasicDecoder(\n    cell = decoder_cell,\n    helper = training_helper,\n    initial_state = encoder_state,\n    output_layer = projection_layer)\ntraining_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n    decoder = training_decoder,\n    impute_finished = True,\n    maximum_iterations = tf.reduce_max(Y_seq_len))\ntraining_logits = training_decoder_output.rnn_output\n\n# PREDICTING_DECODER\npredicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n    cell = decoder_cell,\n    embedding = decoder_embedding,\n    start_tokens = tf.tile(tf.constant([1], dtype=tf.int32), [128]),\n    end_token = 2,\n    initial_state = tf.nn.rnn_cell.LSTMStateTuple(\n        tf.contrib.seq2seq.tile_batch(encoder_state[0], multiplier=10),\n        tf.contrib.seq2seq.tile_batch(encoder_state[1], multiplier=10)),,\n    beam_width = 10,\n    output_layer = projection_layer,\n    length_penalty_weight = 0.0)\npredicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n    decoder = predicting_decoder,\n    impute_finished = False,\n    maximum_iterations = 2 * tf.reduce_max(Y_seq_len))\npredicting_logits = predicting_decoder_output.sample_id\n\n# LOSS\nmasks = tf.sequence_mask(Y_seq_len, tf.reduce_max(Y_seq_len), dtype=tf.float32)\nloss = tf.contrib.seq2seq.sequence_loss(logits = training_logits, targets = Y, weights = masks)\n\n# BACKWARD\nparams = tf.trainable_variables()\ngradients = tf.gradients(loss, params)\nclipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\ntrain_op = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params))", "body": "okay, the key is to:\r\n* tile the encoder state separately for LSTMStateTuple\r\n* make sure impute_finished is False\r\nthe complete code is:\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.layers.core import Dense\r\n\r\n# INPUTS\r\nX = tf.placeholder(tf.int32, [None, None])\r\nY = tf.placeholder(tf.int32, [None, None])\r\nX_seq_len = tf.placeholder(tf.int32, [None])\r\nY_seq_len = tf.placeholder(tf.int32, [None])\r\n\r\n# ENCODER         \r\nencoder_out, encoder_state = tf.nn.dynamic_rnn(\r\n    cell = tf.nn.rnn_cell.BasicLSTMCell(128), \r\n    inputs = tf.contrib.layers.embed_sequence(X, 10000, 128),\r\n    sequence_length = X_seq_len,\r\n    dtype = tf.float32)\r\n\r\n# DECODER COMPONENTS\r\nY_vocab_size = 10000\r\ndecoder_embedding = tf.Variable(tf.random_uniform([Y_vocab_size, 128], -1.0, 1.0))\r\nprojection_layer = Dense(Y_vocab_size)\r\ndecoder_cell = tf.nn.rnn_cell.BasicLSTMCell(128)\r\n\r\n# TRAINING DECODER\r\ntraining_helper = tf.contrib.seq2seq.TrainingHelper(\r\n    inputs = tf.nn.embedding_lookup(decoder_embedding, Y),\r\n    sequence_length = Y_seq_len,\r\n    time_major = False)\r\ntraining_decoder = tf.contrib.seq2seq.BasicDecoder(\r\n    cell = decoder_cell,\r\n    helper = training_helper,\r\n    initial_state = encoder_state,\r\n    output_layer = projection_layer)\r\ntraining_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\r\n    decoder = training_decoder,\r\n    impute_finished = True,\r\n    maximum_iterations = tf.reduce_max(Y_seq_len))\r\ntraining_logits = training_decoder_output.rnn_output\r\n\r\n# PREDICTING_DECODER\r\npredicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\r\n    cell = decoder_cell,\r\n    embedding = decoder_embedding,\r\n    start_tokens = tf.tile(tf.constant([1], dtype=tf.int32), [128]),\r\n    end_token = 2,\r\n    initial_state = tf.nn.rnn_cell.LSTMStateTuple(\r\n        tf.contrib.seq2seq.tile_batch(encoder_state[0], multiplier=10),\r\n        tf.contrib.seq2seq.tile_batch(encoder_state[1], multiplier=10)),,\r\n    beam_width = 10,\r\n    output_layer = projection_layer,\r\n    length_penalty_weight = 0.0)\r\npredicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\r\n    decoder = predicting_decoder,\r\n    impute_finished = False,\r\n    maximum_iterations = 2 * tf.reduce_max(Y_seq_len))\r\npredicting_logits = predicting_decoder_output.sample_id\r\n\r\n# LOSS\r\nmasks = tf.sequence_mask(Y_seq_len, tf.reduce_max(Y_seq_len), dtype=tf.float32)\r\nloss = tf.contrib.seq2seq.sequence_loss(logits = training_logits, targets = Y, weights = masks)\r\n\r\n# BACKWARD\r\nparams = tf.trainable_variables()\r\ngradients = tf.gradients(loss, params)\r\nclipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\r\ntrain_op = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params))\r\n```"}