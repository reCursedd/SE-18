{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/294178569", "html_url": "https://github.com/tensorflow/tensorflow/issues/9171#issuecomment-294178569", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9171", "id": 294178569, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDE3ODU2OQ==", "user": {"login": "msmsajjadi", "id": 23297830, "node_id": "MDQ6VXNlcjIzMjk3ODMw", "avatar_url": "https://avatars0.githubusercontent.com/u/23297830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msmsajjadi", "html_url": "https://github.com/msmsajjadi", "followers_url": "https://api.github.com/users/msmsajjadi/followers", "following_url": "https://api.github.com/users/msmsajjadi/following{/other_user}", "gists_url": "https://api.github.com/users/msmsajjadi/gists{/gist_id}", "starred_url": "https://api.github.com/users/msmsajjadi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msmsajjadi/subscriptions", "organizations_url": "https://api.github.com/users/msmsajjadi/orgs", "repos_url": "https://api.github.com/users/msmsajjadi/repos", "events_url": "https://api.github.com/users/msmsajjadi/events{/privacy}", "received_events_url": "https://api.github.com/users/msmsajjadi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-14T15:52:25Z", "updated_at": "2017-04-14T15:55:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Alright!</p>\n<p>Simpler, more low-level code example:</p>\n<pre><code>for i in range(2):\n    tf.set_random_seed(1)\n    print(tf.random_uniform([1], seed=None).eval())\n</code></pre>\n<p>Output:</p>\n<pre><code>[ 0.77878559]\n[ 0.54316521]\n</code></pre>\n<p>Judging from the current implementation, this seems to be intended behavior. In <code>random_seed.py</code>, <code>op_seed</code> is set to <code>ops.get_default_graph()._last_id</code> if the passed parameter for <code>op_seed</code> is <code>None</code>. This value depends on the execution and can change (as it does in the example above). <code>graph_seed</code> is constant as long as it is not set again via <code>set_graph_seed</code>.</p>\n<p>The wording in the documentation could be understood either way:</p>\n<blockquote>\n<ol start=\"3\">\n<li>If the graph-level seed is not set, but the operation seed is set:<br>\nA default graph-level seed and the specified operation seed are used to<br>\ndetermine the random sequence.</li>\n</ol>\n</blockquote>\n<p>I think the following behavior would be more natural:</p>\n<ul>\n<li><code>graph_seed</code> is changed randomly upon each creation of a random variable (current implementation: <code>graph_seed</code> is fixed!)</li>\n<li>if <code>op_seed</code> is <code>None</code>, use only <code>graph_seed</code> for the creation of the random values</li>\n<li>if <code>op_seed</code> is given, use only <code>op_seed</code> (and ignore <code>graph_seed</code>)</li>\n</ul>\n<p>Motivation:<br>\nThere doesn't seem to be an elegant way to have, say, 2 neural network models<br>\ninitialized to the same random values in the same execution graph. Current<br>\nworkarounds include the usage of <code>update_ops</code> to copy values from one network to<br>\nthe other, or to set the <code>op_seeds</code> for all operations which leads to<br>\nhard-to-maintain code (because the <code>op_seeds</code> would need to be deterministic but<br>\ndifferent for each layer to ensure that we don't get the same values for all<br>\nvariables).</p>", "body_text": "Alright!\nSimpler, more low-level code example:\nfor i in range(2):\n    tf.set_random_seed(1)\n    print(tf.random_uniform([1], seed=None).eval())\n\nOutput:\n[ 0.77878559]\n[ 0.54316521]\n\nJudging from the current implementation, this seems to be intended behavior. In random_seed.py, op_seed is set to ops.get_default_graph()._last_id if the passed parameter for op_seed is None. This value depends on the execution and can change (as it does in the example above). graph_seed is constant as long as it is not set again via set_graph_seed.\nThe wording in the documentation could be understood either way:\n\n\nIf the graph-level seed is not set, but the operation seed is set:\nA default graph-level seed and the specified operation seed are used to\ndetermine the random sequence.\n\n\nI think the following behavior would be more natural:\n\ngraph_seed is changed randomly upon each creation of a random variable (current implementation: graph_seed is fixed!)\nif op_seed is None, use only graph_seed for the creation of the random values\nif op_seed is given, use only op_seed (and ignore graph_seed)\n\nMotivation:\nThere doesn't seem to be an elegant way to have, say, 2 neural network models\ninitialized to the same random values in the same execution graph. Current\nworkarounds include the usage of update_ops to copy values from one network to\nthe other, or to set the op_seeds for all operations which leads to\nhard-to-maintain code (because the op_seeds would need to be deterministic but\ndifferent for each layer to ensure that we don't get the same values for all\nvariables).", "body": "Alright!\r\n\r\nSimpler, more low-level code example:\r\n```\r\nfor i in range(2):\r\n    tf.set_random_seed(1)\r\n    print(tf.random_uniform([1], seed=None).eval())\r\n```\r\nOutput:\r\n```\r\n[ 0.77878559]\r\n[ 0.54316521]\r\n```\r\nJudging from the current implementation, this seems to be intended behavior. In `random_seed.py`, `op_seed` is set to `ops.get_default_graph()._last_id` if the passed parameter for `op_seed` is `None`. This value depends on the execution and can change (as it does in the example above). `graph_seed` is constant as long as it is not set again via `set_graph_seed`.\r\n\r\nThe wording in the documentation could be understood either way:\r\n\r\n>   3. If the graph-level seed is not set, but the operation seed is set:\r\n>     A default graph-level seed and the specified operation seed are used to\r\n>     determine the random sequence.\r\n\r\nI think the following behavior would be more natural:\r\n- `graph_seed` is changed randomly upon each creation of a random variable (current implementation: `graph_seed` is fixed!)\r\n- if `op_seed` is `None`, use only `graph_seed` for the creation of the random values\r\n- if `op_seed` is given, use only `op_seed` (and ignore `graph_seed`)\r\n\r\nMotivation:\r\nThere doesn't seem to be an elegant way to have, say, 2 neural network models\r\ninitialized to the same random values in the same execution graph. Current\r\nworkarounds include the usage of `update_ops` to copy values from one network to\r\nthe other, or to set the `op_seeds` for all operations which leads to\r\nhard-to-maintain code (because the `op_seeds` would need to be deterministic but\r\ndifferent for each layer to ensure that we don't get the same values for all\r\nvariables).\r\n"}