{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9201", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9201/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9201/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9201/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9201", "id": 221681884, "node_id": "MDU6SXNzdWUyMjE2ODE4ODQ=", "number": 9201, "title": "Tensorflow Still Trying to use CUDA even when Session Created with device_count={'GPU': 0}", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-04-13T21:04:36Z", "updated_at": "2017-12-20T13:14:30Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System Information</h3>\n<p>Using the <code>tensorflow/tensorflow:1.0.1-devel-gpu</code> Docker image.<br>\n<code>('v1.0.0-65-g4763edf-dirty', '1.0.1')</code><br>\nHost: <code>Driver Version: 367.57</code>, <code>3.13.0-57-generic</code></p>\n<h3>Issue</h3>\n<p>If I <code>Set compute mode to EXCLUSIVE_PROCESS</code> on the Nvidia device (<code>sudo nvidia-smi -c 1</code>), then even though I tell the <code>Session</code> not to use GPUs (<code>config=tf.ConfigProto(device_count={'GPU': 0})</code>), Tensorflow attempts to use the GPU resulting in an inability to create session:</p>\n<pre><code>InternalErrorTraceback (most recent call last)\n&lt;ipython-input-1-cabf26c1451a&gt; in &lt;module&gt;()\n      1 import tensorflow as tf\n      2 from tensorflow.python.framework import ops\n----&gt; 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n      4     pass\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\n   1174 \n   1175     \"\"\"\n-&gt; 1176     super(Session, self).__init__(target, graph, config=config)\n   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1178     self._default_graph_context_manager = None\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\n    550     try:\n    551       with errors.raise_exception_on_not_ok_status() as status:\n--&gt; 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n    553     finally:\n    554       tf_session.TF_DeleteSessionOptions(opts)\n\n/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)\n     22         if type is None:\n     23             try:\n---&gt; 24                 self.gen.next()\n     25             except StopIteration:\n     26                 return\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--&gt; 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n\nInternalError: Failed to create session.\n</code></pre>\n<p>This can be demonstrated by running:</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.framework import ops\nwith tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n    pass\n</code></pre>\n<p>when another process is using CUDA and the exclusive process mode is set.</p>\n<p>If exclusive process mode is <em>not</em> set, then the session is created but using <code>nvidia-smi</code>, I see that the process is using GPU ram (and CUDA):</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      2237    C   /usr/bin/python                                 61MiB |\n</code></pre>\n<p>The issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU.</p>", "body_text": "System Information\nUsing the tensorflow/tensorflow:1.0.1-devel-gpu Docker image.\n('v1.0.0-65-g4763edf-dirty', '1.0.1')\nHost: Driver Version: 367.57, 3.13.0-57-generic\nIssue\nIf I Set compute mode to EXCLUSIVE_PROCESS on the Nvidia device (sudo nvidia-smi -c 1), then even though I tell the Session not to use GPUs (config=tf.ConfigProto(device_count={'GPU': 0})), Tensorflow attempts to use the GPU resulting in an inability to create session:\nInternalErrorTraceback (most recent call last)\n<ipython-input-1-cabf26c1451a> in <module>()\n      1 import tensorflow as tf\n      2 from tensorflow.python.framework import ops\n----> 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n      4     pass\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\n   1174 \n   1175     \"\"\"\n-> 1176     super(Session, self).__init__(target, graph, config=config)\n   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\n   1178     self._default_graph_context_manager = None\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\n    550     try:\n    551       with errors.raise_exception_on_not_ok_status() as status:\n--> 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n    553     finally:\n    554       tf_session.TF_DeleteSessionOptions(opts)\n\n/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)\n     22         if type is None:\n     23             try:\n---> 24                 self.gen.next()\n     25             except StopIteration:\n     26                 return\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()\n    464           None, None,\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\n\nInternalError: Failed to create session.\n\nThis can be demonstrated by running:\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nwith tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n    pass\n\nwhen another process is using CUDA and the exclusive process mode is set.\nIf exclusive process mode is not set, then the session is created but using nvidia-smi, I see that the process is using GPU ram (and CUDA):\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      2237    C   /usr/bin/python                                 61MiB |\n\nThe issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU.", "body": "### System Information\r\nUsing the `tensorflow/tensorflow:1.0.1-devel-gpu` Docker image.\r\n`('v1.0.0-65-g4763edf-dirty', '1.0.1')`\r\nHost: `Driver Version: 367.57`, `3.13.0-57-generic`\r\n\r\n### Issue\r\nIf I `Set compute mode to EXCLUSIVE_PROCESS` on the Nvidia device (`sudo nvidia-smi -c 1`), then even though I tell the `Session` not to use GPUs (`config=tf.ConfigProto(device_count={'GPU': 0})`), Tensorflow attempts to use the GPU resulting in an inability to create session:\r\n```\r\nInternalErrorTraceback (most recent call last)\r\n<ipython-input-1-cabf26c1451a> in <module>()\r\n      1 import tensorflow as tf\r\n      2 from tensorflow.python.framework import ops\r\n----> 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\r\n      4     pass\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\r\n   1174 \r\n   1175     \"\"\"\r\n-> 1176     super(Session, self).__init__(target, graph, config=config)\r\n   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\r\n   1178     self._default_graph_context_manager = None\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)\r\n    550     try:\r\n    551       with errors.raise_exception_on_not_ok_status() as status:\r\n--> 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n    553     finally:\r\n    554       tf_session.TF_DeleteSessionOptions(opts)\r\n\r\n/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)\r\n     22         if type is None:\r\n     23             try:\r\n---> 24                 self.gen.next()\r\n     25             except StopIteration:\r\n     26                 return\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()\r\n    464           None, None,\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n    468     pywrap_tensorflow.TF_DeleteStatus(status)\r\n\r\nInternalError: Failed to create session.\r\n```\r\nThis can be demonstrated by running:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import ops\r\nwith tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\r\n    pass\r\n```\r\nwhen another process is using CUDA and the exclusive process mode is set.\r\n\r\nIf exclusive process mode is _not_ set, then the session is created but using `nvidia-smi`, I see that the process is using GPU ram (and CUDA):\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      2237    C   /usr/bin/python                                 61MiB |\r\n```\r\n\r\nThe issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU."}