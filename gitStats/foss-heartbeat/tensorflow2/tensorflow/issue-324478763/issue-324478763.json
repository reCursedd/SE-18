{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19390", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19390/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19390/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19390/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19390", "id": 324478763, "node_id": "MDU6SXNzdWUzMjQ0Nzg3NjM=", "number": 19390, "title": "depthwise_conv2d_native too slow", "user": {"login": "lubomir1", "id": 21107748, "node_id": "MDQ6VXNlcjIxMTA3NzQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/21107748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lubomir1", "html_url": "https://github.com/lubomir1", "followers_url": "https://api.github.com/users/lubomir1/followers", "following_url": "https://api.github.com/users/lubomir1/following{/other_user}", "gists_url": "https://api.github.com/users/lubomir1/gists{/gist_id}", "starred_url": "https://api.github.com/users/lubomir1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lubomir1/subscriptions", "organizations_url": "https://api.github.com/users/lubomir1/orgs", "repos_url": "https://api.github.com/users/lubomir1/repos", "events_url": "https://api.github.com/users/lubomir1/events{/privacy}", "received_events_url": "https://api.github.com/users/lubomir1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-05-18T16:40:37Z", "updated_at": "2018-11-23T18:38:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em><strong>edit</strong></em>: Simplified the example, added system info</p>\n<p>According to this <a href=\"https://github.com/tensorflow/tensorflow/pull/17961\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/17961/hovercard\">thread</a> Tensorflow now uses the CuDNN accelerations of group convolutions for depthwise_conv2d_native. Thank you for working on this! However, I am having a hard time reproducing any gains from the accelerated version. Both the native and accelerated versions of depthwise_conv2d_native is about 3-4 times slower than doing a full (dense) convolution.</p>\n<p>In the example below, a dense 3x3 convolution with 64-in and 64-out channels should do about 16 times more multiplications compared to a group convolution with the same dimensions and 16 groups (64x3x3x64 vs 16x4x3x3x4). The latter can be implemented with depthwise_conv2d_native with channel_multiplier of 4 followed by a sum. So I expect a fully amortized depthwise_conv2d_native to be 16 times faster than a dense convolution, and yet, it is about 4 times slower. It is also substantially slower than naive slice/convolve/concat implementation of group convolution</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: no</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source)</strong>: from May 15, 2018 commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/1521eeb676383417b33ad55ad73b152bd5b046ca/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/1521eeb676383417b33ad55ad73b152bd5b046ca\"><tt>1521eeb</tt></a></li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.1, 7.1.3</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 1080ti (tf compiled for compute capability 6.1) and Volta (V100, tf compiled for compute capability 7.0)</li>\n<li><strong>Exact command to reproduce</strong>: see code below</li>\n</ul>\n<p>Here are my results on GTX 1080ti:</p>\n<pre><code>           depthwise : 2.72s\n     depthwise_cudnn : 2.59s\n   manual_group_conv : 0.84s\n          dense_conv : 0.72s\n</code></pre>\n<p>Here is the code I used to test performance:</p>\n<pre><code>import numpy as np, time, os\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\ndef conv3x3(bottom, filters):\n    return tf.layers.conv2d(bottom, filters, kernel_size = 3, padding='same', use_bias = False, data_format = 'channels_first')\n\n# this is not even group convolution, just the depthwise part without the sum\ndef depthwise(bottom, num_groups):\n    input_chans = bottom.shape[1]\n    group_size = input_chans / num_groups\n    w0 = tf.get_variable(name='var', shape=[3, 3, input_chans, group_size])\n    return tf.nn.depthwise_conv2d_native(bottom, w0, strides = [1,1,1,1], padding = 'SAME', data_format = 'NCHW')\n\ndef depthwise_cudnn(bottom, num_groups):\n    with tf.get_default_graph()._kernel_label_map({\"DepthwiseConv2dNative\": \"cudnn_grouped_convolution\"}):\n        return depthwise(bottom, num_groups)\n\ndef manual_group_conv(bottom, num_groups):\n    input_chans = bottom.shape[1]\n    group_size = input_chans / num_groups\n    slices = [bottom[:,i:(i+group_size)] for i in range(0, input_chans, group_size)]\n    convs = [conv3x3(sl, group_size) for sl in slices]\n    return tf.concat(convs, axis = 1)\n\ndef dense_conv(bottom, num_groups):\n    return conv3x3(bottom, bottom.shape[1])\n\ninput_shape = [16, 64, 128, 128]\ngroups = 16\ndtype = tf.float32\n\nfor cnv_type in [depthwise, depthwise_cudnn, manual_group_conv, dense_conv]:\n    tf.reset_default_graph()\n\n    cnv = cnv_type(tf.constant(np.zeros(input_shape), dtype), groups)\n\n    N = 100\n    with tf.Session('') as sess:\n        sess.run(tf.global_variables_initializer())\n\n        sess.run(cnv) # initialization run\n\n        start = time.time()\n        for i in range(N):\n            sess.run(cnv)\n\n        print \"%20s : %4.2fs\" % (cnv_type.func_name, time.time() - start)\n\n</code></pre>\n<p>I also tested with NHWC with similar results. Let me know if I am doing something wrong or whether you can replicate my perf results. Thanks!</p>", "body_text": "edit: Simplified the example, added system info\nAccording to this thread Tensorflow now uses the CuDNN accelerations of group convolutions for depthwise_conv2d_native. Thank you for working on this! However, I am having a hard time reproducing any gains from the accelerated version. Both the native and accelerated versions of depthwise_conv2d_native is about 3-4 times slower than doing a full (dense) convolution.\nIn the example below, a dense 3x3 convolution with 64-in and 64-out channels should do about 16 times more multiplications compared to a group convolution with the same dimensions and 16 groups (64x3x3x64 vs 16x4x3x3x4). The latter can be implemented with depthwise_conv2d_native with channel_multiplier of 4 followed by a sum. So I expect a fully amortized depthwise_conv2d_native to be 16 times faster than a dense convolution, and yet, it is about 4 times slower. It is also substantially slower than naive slice/convolve/concat implementation of group convolution\nSystem information\n\nHave I written custom code: no\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from (source): from May 15, 2018 commit 1521eeb\nPython version: 2.7\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source): 5.4\nCUDA/cuDNN version: 9.1, 7.1.3\nGPU model and memory: GeForce GTX 1080ti (tf compiled for compute capability 6.1) and Volta (V100, tf compiled for compute capability 7.0)\nExact command to reproduce: see code below\n\nHere are my results on GTX 1080ti:\n           depthwise : 2.72s\n     depthwise_cudnn : 2.59s\n   manual_group_conv : 0.84s\n          dense_conv : 0.72s\n\nHere is the code I used to test performance:\nimport numpy as np, time, os\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\ndef conv3x3(bottom, filters):\n    return tf.layers.conv2d(bottom, filters, kernel_size = 3, padding='same', use_bias = False, data_format = 'channels_first')\n\n# this is not even group convolution, just the depthwise part without the sum\ndef depthwise(bottom, num_groups):\n    input_chans = bottom.shape[1]\n    group_size = input_chans / num_groups\n    w0 = tf.get_variable(name='var', shape=[3, 3, input_chans, group_size])\n    return tf.nn.depthwise_conv2d_native(bottom, w0, strides = [1,1,1,1], padding = 'SAME', data_format = 'NCHW')\n\ndef depthwise_cudnn(bottom, num_groups):\n    with tf.get_default_graph()._kernel_label_map({\"DepthwiseConv2dNative\": \"cudnn_grouped_convolution\"}):\n        return depthwise(bottom, num_groups)\n\ndef manual_group_conv(bottom, num_groups):\n    input_chans = bottom.shape[1]\n    group_size = input_chans / num_groups\n    slices = [bottom[:,i:(i+group_size)] for i in range(0, input_chans, group_size)]\n    convs = [conv3x3(sl, group_size) for sl in slices]\n    return tf.concat(convs, axis = 1)\n\ndef dense_conv(bottom, num_groups):\n    return conv3x3(bottom, bottom.shape[1])\n\ninput_shape = [16, 64, 128, 128]\ngroups = 16\ndtype = tf.float32\n\nfor cnv_type in [depthwise, depthwise_cudnn, manual_group_conv, dense_conv]:\n    tf.reset_default_graph()\n\n    cnv = cnv_type(tf.constant(np.zeros(input_shape), dtype), groups)\n\n    N = 100\n    with tf.Session('') as sess:\n        sess.run(tf.global_variables_initializer())\n\n        sess.run(cnv) # initialization run\n\n        start = time.time()\n        for i in range(N):\n            sess.run(cnv)\n\n        print \"%20s : %4.2fs\" % (cnv_type.func_name, time.time() - start)\n\n\nI also tested with NHWC with similar results. Let me know if I am doing something wrong or whether you can replicate my perf results. Thanks!", "body": "***edit***: Simplified the example, added system info\r\n\r\nAccording to this [thread](https://github.com/tensorflow/tensorflow/pull/17961) Tensorflow now uses the CuDNN accelerations of group convolutions for depthwise_conv2d_native. Thank you for working on this! However, I am having a hard time reproducing any gains from the accelerated version. Both the native and accelerated versions of depthwise_conv2d_native is about 3-4 times slower than doing a full (dense) convolution.\r\n\r\nIn the example below, a dense 3x3 convolution with 64-in and 64-out channels should do about 16 times more multiplications compared to a group convolution with the same dimensions and 16 groups (64x3x3x64 vs 16x4x3x3x4). The latter can be implemented with depthwise_conv2d_native with channel_multiplier of 4 followed by a sum. So I expect a fully amortized depthwise_conv2d_native to be 16 times faster than a dense convolution, and yet, it is about 4 times slower. It is also substantially slower than naive slice/convolve/concat implementation of group convolution\r\n\r\n\r\n### System information\r\n- **Have I written custom code**: no\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source)**: from May 15, 2018 commit 1521eeb676383417b33ad55ad73b152bd5b046ca\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: 9.1, 7.1.3\r\n- **GPU model and memory**: GeForce GTX 1080ti (tf compiled for compute capability 6.1) and Volta (V100, tf compiled for compute capability 7.0)\r\n- **Exact command to reproduce**: see code below\r\n\r\n\r\nHere are my results on GTX 1080ti:\r\n```\r\n           depthwise : 2.72s\r\n     depthwise_cudnn : 2.59s\r\n   manual_group_conv : 0.84s\r\n          dense_conv : 0.72s\r\n```\r\nHere is the code I used to test performance:\r\n```\r\nimport numpy as np, time, os\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n\r\ndef conv3x3(bottom, filters):\r\n    return tf.layers.conv2d(bottom, filters, kernel_size = 3, padding='same', use_bias = False, data_format = 'channels_first')\r\n\r\n# this is not even group convolution, just the depthwise part without the sum\r\ndef depthwise(bottom, num_groups):\r\n    input_chans = bottom.shape[1]\r\n    group_size = input_chans / num_groups\r\n    w0 = tf.get_variable(name='var', shape=[3, 3, input_chans, group_size])\r\n    return tf.nn.depthwise_conv2d_native(bottom, w0, strides = [1,1,1,1], padding = 'SAME', data_format = 'NCHW')\r\n\r\ndef depthwise_cudnn(bottom, num_groups):\r\n    with tf.get_default_graph()._kernel_label_map({\"DepthwiseConv2dNative\": \"cudnn_grouped_convolution\"}):\r\n        return depthwise(bottom, num_groups)\r\n\r\ndef manual_group_conv(bottom, num_groups):\r\n    input_chans = bottom.shape[1]\r\n    group_size = input_chans / num_groups\r\n    slices = [bottom[:,i:(i+group_size)] for i in range(0, input_chans, group_size)]\r\n    convs = [conv3x3(sl, group_size) for sl in slices]\r\n    return tf.concat(convs, axis = 1)\r\n\r\ndef dense_conv(bottom, num_groups):\r\n    return conv3x3(bottom, bottom.shape[1])\r\n\r\ninput_shape = [16, 64, 128, 128]\r\ngroups = 16\r\ndtype = tf.float32\r\n\r\nfor cnv_type in [depthwise, depthwise_cudnn, manual_group_conv, dense_conv]:\r\n    tf.reset_default_graph()\r\n\r\n    cnv = cnv_type(tf.constant(np.zeros(input_shape), dtype), groups)\r\n\r\n    N = 100\r\n    with tf.Session('') as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        sess.run(cnv) # initialization run\r\n\r\n        start = time.time()\r\n        for i in range(N):\r\n            sess.run(cnv)\r\n\r\n        print \"%20s : %4.2fs\" % (cnv_type.func_name, time.time() - start)\r\n\r\n```\r\n\r\nI also tested with NHWC with similar results. Let me know if I am doing something wrong or whether you can replicate my perf results. Thanks!\r\n"}