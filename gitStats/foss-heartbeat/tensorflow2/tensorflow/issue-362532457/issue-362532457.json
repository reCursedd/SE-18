{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22444", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22444/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22444/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22444/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22444", "id": 362532457, "node_id": "MDU6SXNzdWUzNjI1MzI0NTc=", "number": 22444, "title": "tflite interpreter get different output for same input", "user": {"login": "lcxywfe", "id": 11569055, "node_id": "MDQ6VXNlcjExNTY5MDU1", "avatar_url": "https://avatars1.githubusercontent.com/u/11569055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lcxywfe", "html_url": "https://github.com/lcxywfe", "followers_url": "https://api.github.com/users/lcxywfe/followers", "following_url": "https://api.github.com/users/lcxywfe/following{/other_user}", "gists_url": "https://api.github.com/users/lcxywfe/gists{/gist_id}", "starred_url": "https://api.github.com/users/lcxywfe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lcxywfe/subscriptions", "organizations_url": "https://api.github.com/users/lcxywfe/orgs", "repos_url": "https://api.github.com/users/lcxywfe/repos", "events_url": "https://api.github.com/users/lcxywfe/events{/privacy}", "received_events_url": "https://api.github.com/users/lcxywfe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-09-21T09:35:22Z", "updated_at": "2018-10-13T02:38:08Z", "closed_at": "2018-10-13T02:38:08Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Debian 4.5.5</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:  v1.10.1</li>\n<li><strong>Python version</strong>: 3.5.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>give data to a tflite model<br>\ndata shape = (2, 28, 28, 1) and data[0] == data[1]<br>\nuse tf.contrib.lite.Interpreter to run the model<br>\nget the output, but output[0] != output[1]</p>\n<h3>Source code / <a href=\"url\">logs</a></h3>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef test_same():\n    data = np.random.random((1,28,28,1)).astype(np.float32)\n    data = np.concatenate([data, data])\n    print('input[0] == input[1]: ', equal(data[0], data[1]))\n    model = tf.contrib.lite.Interpreter(\n        model_path='resnet18_finetuned_batch2.tflite')\n    model.allocate_tensors()\n    model.set_tensor(0, data)\n    model.invoke()\n    output = model.get_tensor(model.get_output_details()[0]['index'])\n    print('output[0] == output[1]: ', equal(output[0], output[1]))\n\ndef equal(tensor1, tensor2):\n    for i, j in zip(tensor1.reshape(-1), tensor2.reshape(-1)):\n        if abs(i - j) &gt; 0.001:\n            return False\n    return True\n\nif __name__ == \"__main__\":\n    test_same()\n</code></pre>\n<p>OUTPUT:</p>\n<pre><code>input[0] == input[1]:  True\noutput[0] == output[1]:  False\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 4.5.5\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below):  v1.10.1\nPython version: 3.5.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\ngive data to a tflite model\ndata shape = (2, 28, 28, 1) and data[0] == data[1]\nuse tf.contrib.lite.Interpreter to run the model\nget the output, but output[0] != output[1]\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\n\ndef test_same():\n    data = np.random.random((1,28,28,1)).astype(np.float32)\n    data = np.concatenate([data, data])\n    print('input[0] == input[1]: ', equal(data[0], data[1]))\n    model = tf.contrib.lite.Interpreter(\n        model_path='resnet18_finetuned_batch2.tflite')\n    model.allocate_tensors()\n    model.set_tensor(0, data)\n    model.invoke()\n    output = model.get_tensor(model.get_output_details()[0]['index'])\n    print('output[0] == output[1]: ', equal(output[0], output[1]))\n\ndef equal(tensor1, tensor2):\n    for i, j in zip(tensor1.reshape(-1), tensor2.reshape(-1)):\n        if abs(i - j) > 0.001:\n            return False\n    return True\n\nif __name__ == \"__main__\":\n    test_same()\n\nOUTPUT:\ninput[0] == input[1]:  True\noutput[0] == output[1]:  False", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 4.5.5\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  v1.10.1\r\n- **Python version**: 3.5.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\ngive data to a tflite model\r\ndata shape = (2, 28, 28, 1) and data[0] == data[1]\r\nuse tf.contrib.lite.Interpreter to run the model\r\nget the output, but output[0] != output[1]\r\n\r\n### Source code / [logs](url)\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef test_same():\r\n    data = np.random.random((1,28,28,1)).astype(np.float32)\r\n    data = np.concatenate([data, data])\r\n    print('input[0] == input[1]: ', equal(data[0], data[1]))\r\n    model = tf.contrib.lite.Interpreter(\r\n        model_path='resnet18_finetuned_batch2.tflite')\r\n    model.allocate_tensors()\r\n    model.set_tensor(0, data)\r\n    model.invoke()\r\n    output = model.get_tensor(model.get_output_details()[0]['index'])\r\n    print('output[0] == output[1]: ', equal(output[0], output[1]))\r\n\r\ndef equal(tensor1, tensor2):\r\n    for i, j in zip(tensor1.reshape(-1), tensor2.reshape(-1)):\r\n        if abs(i - j) > 0.001:\r\n            return False\r\n    return True\r\n\r\nif __name__ == \"__main__\":\r\n    test_same()\r\n```\r\nOUTPUT:\r\n```\r\ninput[0] == input[1]:  True\r\noutput[0] == output[1]:  False\r\n```"}