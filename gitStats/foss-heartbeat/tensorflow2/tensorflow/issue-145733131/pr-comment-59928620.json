{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59928620", "pull_request_review_id": null, "id": 59928620, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTI4NjIw", "diff_hunk": "@@ -0,0 +1,763 @@\n+package tensorflow\n+\n+import (\n+\t\"encoding/binary\"\n+\t\"fmt\"\n+\t\"math\"\n+\t\"reflect\"\n+\t\"runtime\"\n+\t\"unsafe\"\n+\n+\t\"github.com/golang/protobuf/proto\"\n+\n+\tpb \"github.com/tensorflow/tensorflow/tensorflow/contrib/go/proto\"\n+)\n+\n+import \"C\"\n+\n+const (\n+\tcAckByte  = 6\n+\tcBellByte = 7\n+\tcDc1      = 17\n+\n+\tcBytesComplex64 = 8\n+\tcBytesFloat32   = 4\n+\tcBytesFloat64   = 8\n+\tcBytesInt16     = 2\n+\tcBytesInt32     = 4\n+\tcBytesInt64     = 8\n+\tcBytesUint16    = 2\n+)\n+\n+// DataType Type of the data contained by a Tensor\n+type DataType pb.DataType\n+\n+// TensorInt Interface to be implemented by the tensors.\n+type TensorInt interface {\n+\tData() []byte\n+\tDataSize() int64\n+\tDataType() DataType\n+\tGetVal(d ...int) (val interface{}, err error)\n+\n+\tDim(n int) int\n+\tNumDims() int\n+\n+\tAsBool() (res []bool, err error)\n+\tAsFloat32() (res []float32, err error)\n+\tAsFloat64() (res []float64, err error)\n+\tAsInt32() (res []int32, err error)\n+\tAsInt64() (res []int64, err error)\n+\tAsStr() (res [][]byte, err error)\n+\n+\tString() string\n+}\n+\n+// Tensor Holds a multi-dimensional array of elements of a single data type.\n+type Tensor struct {\n+\tpb.TensorProto\n+\n+\ttensor      TF_Tensor\n+\tdimWeights  []int\n+\tmemReleased bool\n+}\n+\n+// TensorShape represents the shapre of a Tensor.\n+type TensorShape [][]int64\n+\n+var (\n+\t// DtInvalid Invalid tensor DataType.\n+\tDtInvalid = DataType(0)\n+\t// DtBfloat corresponds to TF_BFLOAT16.\n+\tDtBfloat = DataType(TF_BFLOAT16)\n+\t// DtBool corresponds to TF_BOOL.\n+\tDtBool = DataType(TF_BOOL)\n+\t// DtComplex corresponds to TF_COMPLEX.\n+\tDtComplex = DataType(TF_COMPLEX)\n+\t// DtFloat corresponds to TF_FLOAT.\n+\tDtFloat = DataType(TF_FLOAT)\n+\t// DtDouble corresponds to TF_DOUBLE.\n+\tDtDouble = DataType(TF_DOUBLE)\n+\t// DtInt8 corresponds to TF_INT8.\n+\tDtInt8 = DataType(TF_INT8)\n+\t// DtInt16 corresponds to TF_INT16.\n+\tDtInt16 = DataType(TF_INT16)\n+\t// DtInt32 corresponds to TF_INT32.\n+\tDtInt32 = DataType(TF_INT32)\n+\t// DtInt64 corresponds to TF_INT64.\n+\tDtInt64 = DataType(TF_INT64)\n+\t// DtQint16 corresponds to TF_QINT16.\n+\tDtQint16 = DataType(TF_QINT16)\n+\t// DtQuint16 corresponds to TF_QUINT16.\n+\tDtQuint16 = DataType(TF_QUINT16)\n+\t// DtQuint32 corresponds to TF_QINT32.\n+\tDtQuint32 = DataType(TF_QINT32)\n+\t// DtQint8 corresponds to TF_QINT8.\n+\tDtQint8 = DataType(TF_QINT8)\n+\t// DtQuint8 corresponds to TF_QUINT8.\n+\tDtQuint8 = DataType(TF_QUINT8)\n+\t// DtString corresponds to TF_STRING.\n+\tDtString = DataType(TF_STRING)\n+\t// DtUint8 corresponds to TF_UINT8.\n+\tDtUint8 = DataType(TF_UINT8)\n+\t// DtUint16 corresponds to TF_UINT16.\n+\tDtUint16 = DataType(TF_UINT16)\n+)\n+\n+// NewTensorWithShape returns a new tensor with teh specified type, shape and data.\n+// The supported  data types are:\n+//  - DtInt8\n+//  - DtInt16\n+//  - DtInt32\n+//  - DtInt64\n+//  - DtUint8\n+//  - DtUint16\n+//  - DtFloat\n+//  - DtDouble\n+func NewTensorWithShape(shape TensorShape, data interface{}) (*Tensor, error) {\n+\tv := reflect.ValueOf(data)\n+\tif v.Kind() != reflect.Slice {\n+\t\treturn nil, &ErrSliceExpected{\n+\t\t\tdataType: v.Kind().String(),\n+\t\t}\n+\t}\n+\n+\tdataType, err := getDataTypeFromReflect(v.Type().Elem().Kind(), int64(v.Type().Elem().Size()))\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tdataSize := int64(v.Len()) * int64(v.Type().Elem().Size())\n+\tdataPtr := v.Pointer()\n+\n+\treturn newTensor(dataType, shape, unsafe.Pointer(dataPtr), dataSize)\n+}\n+\n+// NewTensor Initializes a tensor based on the slice passed by parameter, the\n+// data type and shape is deducted from the data parameter.\n+func NewTensor(data interface{}) (tensor *Tensor, err error) {\n+\tvar dataPtr uintptr\n+\tvar dataSer []interface{}\n+\tvar dims [][]int64\n+\tvar dataType DataType\n+\tvar dataSize int64\n+\n+\tv := reflect.ValueOf(data)\n+\tif v.Kind() == reflect.Slice {\n+\t\tdataType, _ = getDataTypeFromReflect(v.Type().Elem().Kind(), 1)\n+\t\tif dataType == DtString {\n+\t\t\tstrings := make([]string, v.Len())\n+\t\t\tfor i := 0; i < v.Len(); i++ {\n+\t\t\t\tstrings[i] = v.Index(i).String()\n+\t\t\t}\n+\t\t\tbuf := encodeStrings(strings)\n+\t\t\treturn newTensor(DtString, TensorShape{{int64(len(strings))}}, unsafe.Pointer(&(buf[0])), int64(len(buf)))\n+\t\t}\n+\n+\t\tdataSer, dims, dataType, dataSize, err = serialize(data, 0, [][]int64{})\n+\t\tif err != nil {\n+\t\t\treturn\n+\t\t}\n+\t} else {\n+\t\t// Scalar tensor\n+\t\tdataSer = []interface{}{data}\n+\t\tdims = [][]int64{}\n+\t\tdataSize = int64(v.Type().Size())\n+\t\tif dataType, err = getDataTypeFromReflect(v.Kind(), dataSize); err != nil {\n+\t\t\treturn\n+\t\t}\n+\t}\n+\tts := TensorShape(dims)\n+\n+\tauxTensor := new(Tensor)\n+\tswitch dataType {\n+\tcase DtFloat:\n+\t\tauxTensor.FloatVal = make([]float32, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.FloatVal[i] = v.(float32)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.FloatVal).Pointer()\n+\tcase DtDouble:\n+\t\tauxTensor.DoubleVal = make([]float64, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.DoubleVal[i] = v.(float64)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.DoubleVal).Pointer()\n+\tcase DtInt8, DtInt16, DtInt32, DtUint8:\n+\t\tauxTensor.IntVal = make([]int32, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.IntVal[i] = int32(reflect.ValueOf(v).Int())\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.IntVal).Pointer()\n+\tcase DtInt64:\n+\t\tauxTensor.Int64Val = make([]int64, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.Int64Val[i] = reflect.ValueOf(v).Int()\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.Int64Val).Pointer()\n+\tcase DtBool:\n+\t\tauxTensor.BoolVal = make([]bool, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.BoolVal[i] = v.(bool)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.BoolVal).Pointer()\n+\tcase DtString:\n+\t\tauxTensor.StringVal = make([][]byte, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.StringVal[i] = []byte(v.(string))\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.StringVal).Pointer()\n+\tdefault:\n+\t\treturn nil, &ErrTensorTypeNotSupported{\n+\t\t\ttensotType: dataType,\n+\t\t}\n+\t}\n+\n+\ttensor, err = newTensor(dataType, ts, unsafe.Pointer(dataPtr), int64(len(dataSer))*dataSize)\n+\n+\ttensor.FloatVal = auxTensor.FloatVal\n+\ttensor.DoubleVal = auxTensor.DoubleVal\n+\ttensor.IntVal = auxTensor.IntVal\n+\ttensor.StringVal = auxTensor.StringVal\n+\ttensor.ScomplexVal = auxTensor.ScomplexVal\n+\ttensor.Int64Val = auxTensor.Int64Val\n+\ttensor.BoolVal = auxTensor.BoolVal\n+\n+\treturn\n+}\n+\n+// DataType returns the data type of the elements contained by the tensor.\n+func (t *Tensor) DataType() DataType {\n+\treturn DataType(TF_TensorType(t.tensor))\n+}\n+\n+// NumDims returns the number of dimensions that this tensor in a tensor.\n+func (t *Tensor) NumDims() int {\n+\treturn TF_NumDims(t.tensor)\n+}\n+\n+// Shape returns the shape of the tensor.\n+func (t *Tensor) Shape() (shape TensorShape) {\n+\tif t.NumDims() == 0 {\n+\t\t// This is a scalar tensor\n+\t\tshape = [][]int64{}\n+\t} else {\n+\t\tshape = make([][]int64, t.NumDims())\n+\t\tfor i := 0; i < t.NumDims(); i++ {\n+\t\t\tshape[i] = []int64{int64(t.Dim(i))}\n+\t\t}\n+\t}\n+\n+\treturn shape\n+}\n+\n+// Dim returns the size of the specified dimension.\n+func (t *Tensor) Dim(n int) int {\n+\treturn int(TF_Dim(t.tensor, n))\n+}\n+\n+// DataSize returns the size of the data in bytes contained in a tensor.\n+func (t *Tensor) DataSize() int64 {\n+\treturn TF_TensorByteSize(t.tensor)\n+}\n+\n+// Data returns the data contained in a tensor as a slice of bytes.\n+func (t *Tensor) Data() []byte {\n+\tlength := t.DataSize()\n+\treturn (*[1 << 40]byte)(unsafe.Pointer(TF_TensorData(t.tensor)))[:length:length]\n+}\n+\n+// String string representation of a tensor.\n+func (t *Tensor) String() string {\n+\treturn fmt.Sprintf(\"%v: dims:%v size:%v\", t.DataType(), t.NumDims(), t.DataSize())\n+}\n+\n+// AsStr returns the content of the tensor as slice of strings if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtString\n+func (t *Tensor) AsStr() (res [][]byte, err error) {\n+\tif DtString != t.DataType() {\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtString,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tif t.StringVal != nil {\n+\t\treturn t.StringVal, nil\n+\t}\n+\n+\tresultBytes := []byte{}\n+\tinStr := false\n+\tfor _, b := range t.Data() {\n+\t\tif inStr {\n+\t\t\tif b == cBellByte {\n+\t\t\t\tres = append(res, resultBytes)\n+\t\t\t\tresultBytes = []byte{}\n+\t\t\t} else {\n+\t\t\t\tresultBytes = append(resultBytes, byte(b))\n+\t\t\t}\n+\t\t} else {\n+\t\t\t// TODO: Must be any better way to parse the strings...\n+\t\t\tif b == cAckByte || b == cBellByte || b == cDc1 {\n+\t\t\t\tinStr = true\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif len(resultBytes) > 0 {\n+\t\tres = append(res, resultBytes)\n+\t}\n+\tt.StringVal = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// AsFloat32 returns the content of the tensor as a slice of float32 if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtFloat\n+func (t *Tensor) AsFloat32() (res []float32, err error) {\n+\tif DtFloat != t.DataType() {\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtFloat,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tif t.FloatVal != nil {\n+\t\treturn t.FloatVal, nil\n+\t}\n+\n+\tdata := t.Data()\n+\tres = make([]float32, len(data)/cBytesFloat32)\n+\tfor i := range res {\n+\t\tres[i] = math.Float32frombits(binary.LittleEndian.Uint32(data[i*cBytesFloat32 : (i+1)*cBytesFloat32]))\n+\t}\n+\tt.FloatVal = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// AsFloat64 returns the content of the tensor as a slice of float64 if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtDouble\n+func (t *Tensor) AsFloat64() (res []float64, err error) {\n+\tif DtDouble != t.DataType() {\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtDouble,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tif t.DoubleVal != nil {\n+\t\treturn t.DoubleVal, nil\n+\t}\n+\n+\tdata := t.Data()\n+\tres = make([]float64, len(data)/cBytesFloat64)\n+\tfor i := range res {\n+\t\tres[i] = math.Float64frombits(binary.LittleEndian.Uint64(data[i*cBytesFloat64 : (i+1)*cBytesFloat64]))\n+\t}\n+\tt.DoubleVal = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// AsInt32 returns the content of the tensor as a slice of int32 if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtUint8\n+//  - DtInt8\n+//  - DtInt16\n+//  - DtInt32\n+func (t *Tensor) AsInt32() (res []int32, err error) {\n+\tif t.IntVal != nil {\n+\t\treturn t.IntVal, nil\n+\t}\n+\n+\tdata := t.Data()\n+\tswitch t.DataType() {\n+\tcase DtInt8, DtUint8:\n+\t\tres = make([]int32, len(data))\n+\t\tfor i, v := range data {\n+\t\t\tres[i] = int32(v)\n+\t\t}\n+\tcase DtInt16:\n+\t\tres = make([]int32, len(data)/cBytesUint16)\n+\t\tfor i := range res {\n+\t\t\tres[i] = int32(binary.LittleEndian.Uint16(data[i*cBytesUint16 : (i+1)*cBytesUint16]))\n+\t\t}\n+\tcase DtInt32:\n+\t\tres = make([]int32, len(data)/cBytesInt32)\n+\t\tfor i := range res {\n+\t\t\tres[i] = int32(binary.LittleEndian.Uint32(data[i*cBytesInt32 : (i+1)*cBytesInt32]))\n+\t\t}\n+\tdefault:\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtInt32,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tt.IntVal = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// AsInt64 returns the content of the tensor as a slice of int64 if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtInt64\n+func (t *Tensor) AsInt64() (res []int64, err error) {\n+\tif DtInt64 != t.DataType() {\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtInt64,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tif t.Int64Val != nil {\n+\t\treturn t.Int64Val, nil\n+\t}\n+\n+\tdata := t.Data()\n+\tres = make([]int64, len(data)/cBytesInt64)\n+\tfor i := range res {\n+\t\tres[i] = int64(binary.LittleEndian.Uint64(data[i*cBytesInt64 : (i+1)*cBytesInt64]))\n+\t}\n+\tt.Int64Val = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// AsBool returns the content of the tensor as a slice of bool if the tensor\n+// type matches, if not returns a ErrInvalidTensorType error.\n+// The datatypes are:\n+//  - DtBool\n+func (t *Tensor) AsBool() (res []bool, err error) {\n+\tif DtBool != t.DataType() {\n+\t\terr = &ErrInvalidTensorType{\n+\t\t\ttensorType:   t.DataType(),\n+\t\t\texpectedType: DtBool,\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tif t.BoolVal != nil {\n+\t\treturn t.BoolVal, nil\n+\t}\n+\n+\tdata := t.Data()\n+\tres = make([]bool, len(data))\n+\tfor i, v := range data {\n+\t\tres[i] = v == 1\n+\t}\n+\tt.BoolVal = res\n+\tt.Dtype = pb.DataType(TF_TensorType(t.tensor))\n+\n+\treturn\n+}\n+\n+// GetVal resturns the value of the element contained in the specified position\n+// on the tensor, Ex: GetVal(1, 2, 3) is equivalent to data[1][2][3] on a\n+// multidimensional array.\n+// This method could return an error in case of a wrong specified number of\n+// dimensions or a dimesions out of range.\n+func (t *Tensor) GetVal(d ...int) (val interface{}, err error) {\n+\tif len(d) != t.NumDims() {\n+\t\terr = &ErrDimsOutOfTensorRange{\n+\t\t\ttensorDim: t.NumDims(),\n+\t\t\tspecDims:  len(d),\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\tpos := 0\n+\tif t.dimWeights != nil {\n+\t\tfor i, w := range t.dimWeights {\n+\t\t\tpos += d[i] * w\n+\t\t}\n+\t} else {\n+\t\tt.dimWeights = make([]int, len(d))\n+\t\tpos = d[len(d)-1]\n+\t\tif pos >= t.Dim(len(d)-1) {\n+\t\t\terr = &ErrIndexOutOfRange{\n+\t\t\t\tdim:       len(d) - 1,\n+\t\t\t\tindex:     pos,\n+\t\t\t\tdimsRange: t.Dim(len(d) - 1),\n+\t\t\t}\n+\t\t\treturn\n+\t\t}\n+\t\tt.dimWeights[len(d)-1] = 1\n+\n+\t\tlastWeight := 0\n+\t\tfor i := len(d) - 2; i >= 0; i-- {\n+\t\t\tlastWeight += t.Dim(i + 1)\n+\t\t\tt.dimWeights[i] = lastWeight\n+\t\t\tpos += d[i] * lastWeight\n+\n+\t\t\tif d[i] >= t.Dim(i) {\n+\t\t\t\terr = &ErrIndexOutOfRange{\n+\t\t\t\t\tdim:       i,\n+\t\t\t\t\tindex:     pos,\n+\t\t\t\t\tdimsRange: t.Dim(i),\n+\t\t\t\t}\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tswitch t.DataType() {\n+\tcase DtFloat:\n+\t\tvals, _ := t.AsFloat32()\n+\t\tval = vals[pos]\n+\tcase DtDouble:\n+\t\tvals, _ := t.AsFloat64()\n+\t\tval = vals[pos]\n+\tcase DtInt8, DtInt16, DtInt32, DtUint8:\n+\t\tvals, _ := t.AsInt32()\n+\t\tval = vals[pos]\n+\tcase DtInt64:\n+\t\tvals, _ := t.AsInt64()\n+\t\tval = vals[pos]\n+\tcase DtBool:\n+\t\tvals, _ := t.AsBool()\n+\t\tval = vals[pos]\n+\tcase DtString:\n+\t\tvals, _ := t.AsStr()\n+\t\tval = vals[pos]\n+\tdefault:\n+\t\terr = &ErrTensorTypeNotSupported{\n+\t\t\ttensotType: t.DataType(),\n+\t\t}\n+\t\treturn\n+\t}\n+\n+\treturn\n+}\n+\n+// setCMemAsAlreadyRelease The C allocated memory was already released from C.\n+func (t *Tensor) setCMemAsAlreadyRelease() {\n+\tt.memReleased = true\n+}\n+\n+// FreeAllocMem Method used telease the C allocated memory for this tensor.\n+func (t *Tensor) FreeAllocMem() {\n+\t// We can't clean the tensor here in case of it had been  used as in\n+\t// input parameter since on tensorflow/core/client/tensor_c_api.cc the\n+\t// function TF_Run_Helper is cleaning the input tensors after every\n+\t// execution what can cause a a double free or corruption error in C++\n+\t// since there is no way to determine if a tensor had been previously\n+\t// cleaned.\n+\tif !t.memReleased {\n+\t\tTF_DeleteTensor(t.tensor)\n+\t}", "path": "tensorflow/contrib/go/tensor.go", "position": 646, "original_position": 565, "commit_id": "942760424141d0f5a930982d5e78aaeb05869488", "original_commit_id": "210180befbd05694aa3285fef7d498bbd1be2dcc", "user": {"login": "dave-andersen", "id": 827870, "node_id": "MDQ6VXNlcjgyNzg3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/827870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-andersen", "html_url": "https://github.com/dave-andersen", "followers_url": "https://api.github.com/users/dave-andersen/followers", "following_url": "https://api.github.com/users/dave-andersen/following{/other_user}", "gists_url": "https://api.github.com/users/dave-andersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-andersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-andersen/subscriptions", "organizations_url": "https://api.github.com/users/dave-andersen/orgs", "repos_url": "https://api.github.com/users/dave-andersen/repos", "events_url": "https://api.github.com/users/dave-andersen/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-andersen/received_events", "type": "User", "site_admin": false}, "body": "typo 'telease'\nsuggest:  FreeAllocMem releases the C allocated memory for this tensor.\n", "created_at": "2016-04-15T19:29:59Z", "updated_at": "2016-05-05T08:12:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59928620", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59928620"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59928620"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771"}}, "body_html": "<p>typo 'telease'<br>\nsuggest:  FreeAllocMem releases the C allocated memory for this tensor.</p>", "body_text": "typo 'telease'\nsuggest:  FreeAllocMem releases the C allocated memory for this tensor."}