{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59936683", "pull_request_review_id": null, "id": 59936683, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTM2Njgz", "diff_hunk": "@@ -0,0 +1,570 @@\n+package tensorflow\n+\n+import (\n+\t\"bytes\"\n+\t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"strings\"\n+\n+\t\"github.com/golang/protobuf/proto\"\n+\n+\tpb \"github.com/tensorflow/tensorflow/tensorflow/contrib/go/proto\"\n+)\n+\n+const (\n+\tcOpsProtobufDefsPath = \"/usr/local/tensorlow/ops.pbtxt\"\n+)\n+\n+// Graph Representation of the computation graph.\n+type Graph struct {\n+\tdef *pb.GraphDef\n+\n+\tavailableOps map[string]*pb.OpDef\n+\tconstants    map[string]*Tensor\n+\tvariables    map[string]*Tensor\n+}\n+\n+// GraphNode Representation of one of the nodes of the TensorFlow Graph.\n+// A node takes zero or more Tensors, performs some computation, and\n+// produces zero or more Tensors.\n+type GraphNode struct {\n+\tref          *pb.NodeDef\n+\tdef          *pb.NodeDef\n+\toutDataTypes map[string]DataType\n+}\n+\n+// NewGraph Returns an initialized instance of the Graph struct.\n+func NewGraph() *Graph {\n+\treturn &Graph{\n+\t\tdef:          new(pb.GraphDef),\n+\t\tavailableOps: make(map[string]*pb.OpDef),\n+\t\tconstants:    make(map[string]*Tensor),\n+\t\tvariables:    make(map[string]*Tensor),\n+\t}\n+}\n+\n+// NewGraphFromText Returns a new graph populated with the deserialization of\n+// the provided graph string.\n+func NewGraphFromText(graphStr string) (gr *Graph, err error) {\n+\tgr = NewGraph()\n+\terr = proto.UnmarshalText(graphStr, gr.def)\n+\n+\treturn\n+}\n+\n+// LoadGraphFromFile Loads a Graph from the file on the specified path.\n+func LoadGraphFromFile(path string) (gr *Graph, err error) {\n+\tgraphStr, err := ioutil.ReadFile(path)\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\n+\tgr = NewGraph()\n+\terr = proto.Unmarshal(graphStr, gr.def)\n+\n+\treturn\n+}\n+\n+// LoadGraphFromTextFile Loads a Graph as plain text from the file on the specified\n+// path.\n+func LoadGraphFromTextFile(path string) (gr *Graph, err error) {\n+\tgraphStr, err := ioutil.ReadFile(path)\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\n+\treturn NewGraphFromText(string(graphStr))\n+}\n+\n+// Op Adds a new Node to the Graph with the specified operation, this function\n+// could return an error if any of the mandatory attributes is not be present\n+// or the value is not the expected for this attribute.\n+func (gr *Graph) Op(opName string, name string, input []*GraphNode, device string, attrs map[string]interface{}) (node *GraphNode, err error) {\n+\tif err = gr.loadAvailableOps(); err != nil {\n+\t\treturn\n+\t}\n+\n+\top, opFound := gr.availableOps[strings.ToLower(opName)]\n+\tif !opFound {\n+\t\treturn nil, &ErrOperationNotFound{\n+\t\t\top: opName,\n+\t\t}\n+\t}\n+\n+\tif len(op.InputArg) != len(input) {\n+\t\treturn nil, &ErrInvalidAmounthOfInputs{\n+\t\t\toperation:  opName,\n+\t\t\topInputs:   len(op.InputArg),\n+\t\t\tspecInputs: len(input),\n+\t\t}\n+\t}\n+\tinputs := make([]string, len(input))\n+\tfor i, inNode := range input {\n+\t\tif op.InputArg[i].IsRef {\n+\t\t\tif inNode.ref == nil {\n+\t\t\t\treturn nil, &ErrExpectedVarAsinput{\n+\t\t\t\t\toperation: opName,\n+\t\t\t\t\tinputPos:  i,\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tinputs[i] = inNode.ref.Name\n+\t\t} else {\n+\t\t\tinputs[i] = inNode.def.Name\n+\t\t}\n+\t}\n+\tnode = &GraphNode{\n+\t\tdef: &pb.NodeDef{\n+\t\t\tName:   name,\n+\t\t\tOp:     opName,\n+\t\t\tInput:  inputs,\n+\t\t\tDevice: device,\n+\t\t\tAttr:   make(map[string]*pb.AttrValue),\n+\t\t},\n+\t\toutDataTypes: make(map[string]DataType),\n+\t}\n+\n+\tif attrs == nil {\n+\t\tattrs = make(map[string]interface{})\n+\t}\n+\tgr.matchTypes(input, node, attrs, op)\n+\n+\tfor _, attr := range op.Attr {\n+\t\t// Check if the attribute is specified, if it is not\n+\t\t// and doesn't have a default value, return an error since it\n+\t\t// is mandatory\n+\t\tif v, ok := attrs[attr.Name]; ok {\n+\t\t\tnode.def.Attr[attr.Name] = gr.castAttrValue(attr.Type, v)\n+\t\t\tif node.def.Attr[attr.Name] == nil {\n+\t\t\t\treturn nil, &ErrInvalidAttrValue{\n+\t\t\t\t\toperation:  opName,\n+\t\t\t\t\tattribName: attr.Name,\n+\t\t\t\t}\n+\t\t\t}\n+\t\t} else {\n+\t\t\tif attr.DefaultValue != nil {\n+\t\t\t\tnode.def.Attr[attr.Name] = attr.DefaultValue\n+\t\t\t} else {\n+\t\t\t\treturn nil, &ErrMandatoryAttributeNotSpecified{\n+\t\t\t\t\toperation:  opName,\n+\t\t\t\t\tattribName: attr.Name,\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tgr.def.Node = append(gr.def.Node, node.def)\n+\n+\treturn node, nil\n+}\n+\n+// Variable Creates a variable operation and adds it to the graph. A variable\n+// is a type of tensor that holds state in the form of a tensor that persists\n+// across steps.\n+func (gr *Graph) Variable(name string, initialData interface{}) (op *GraphNode, err error) {\n+\tvar dims [][]int64\n+\n+\tts, err := NewTensor(initialData)\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\tgr.variables[name] = ts\n+\n+\tshape := new(pb.TensorShapeProto)\n+\tif ts.NumDims() == 0 {\n+\t\tdims = [][]int64{{1}}\n+\t} else {\n+\t\tdims = ts.Shape()\n+\t}\n+\n+\tshape.Dim = make([]*pb.TensorShapeProto_Dim, len(dims))\n+\tfor i, dim := range dims {\n+\t\tshape.Dim[i] = &pb.TensorShapeProto_Dim{\n+\t\t\tSize: dim[i],\n+\t\t}\n+\t}\n+\n+\tinitVal, err := gr.Op(\"Const\", name+\"/initial_value\", nil, \"\", map[string]interface{}{\n+\t\t\"dtype\": ts.DataType(),\n+\t\t\"value\": ts,\n+\t\t\"shape\": shape,\n+\t})\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\n+\tvariable, err := gr.Op(\"Variable\", name, nil, \"\", map[string]interface{}{\n+\t\t\"dtype\":       ts.DataType(),\n+\t\t\"shape\":       shape,\n+\t\t\"container\":   \"\",\n+\t\t\"shared_name\": \"\",\n+\t})\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\n+\tvariable.ref = variable.def\n+\n+\t_, err = gr.Op(\"Assign\", name+\"/Assign\", []*GraphNode{variable, initVal}, \"\", map[string]interface{}{\n+\t\t\"use_locking\":    true,\n+\t\t\"validate_shape\": true,\n+\t})\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\n+\top, err = gr.Op(\"Identity\", name+\"/read\", []*GraphNode{variable}, \"\", nil)\n+\n+\t// For reference this variable, use the variable as it.\n+\top.ref = variable.def\n+\n+\treturn\n+}\n+\n+// String Returns a string representation of this graph, used for debugging\n+// proposals.\n+func (gr *Graph) String() string {\n+\tvar bufStr bytes.Buffer\n+\tproto.MarshalText(&bufStr, gr.def)\n+\n+\treturn bufStr.String()\n+}\n+\n+// addInitializationGraphOp Add the initialization operation to the graph to\n+// cover all the added variables\n+func (gr *Graph) addInitializationGraphOp() {\n+\tinputs := make([]string, len(gr.variables))\n+\ti := 0\n+\tfor input := range gr.variables {\n+\t\tinputs[i] = \"^\" + input + \"/Assign\"\n+\t\ti++\n+\t}\n+\n+\tgr.def.Node = append(gr.def.Node, &pb.NodeDef{\n+\t\tName:  \"init\",\n+\t\tOp:    \"NoOp\",\n+\t\tInput: inputs,\n+\t})\n+}\n+\n+// Placeholder Adds a placeholder to the Graph, a placeholder is an\n+// operation that must be fed with data on execution.\n+func (gr *Graph) Placeholder(name string, dataType DataType, dims []int64, dimNames []string) (op *GraphNode) {\n+\top = &GraphNode{\n+\t\toutDataTypes: map[string]DataType{\n+\t\t\tname: dataType,\n+\t\t},\n+\t\tdef: &pb.NodeDef{\n+\t\t\tName: name,\n+\t\t\tOp:   \"Placeholder\",\n+\t\t\tAttr: make(map[string]*pb.AttrValue),\n+\t\t},\n+\t}\n+\top.def.Attr[\"dtype\"] = &pb.AttrValue{\n+\t\tValue: &pb.AttrValue_Type{\n+\t\t\tType: pb.DataType(dataType),\n+\t\t},\n+\t}\n+\n+\tshape := &pb.TensorShapeProto{\n+\t\tDim: make([]*pb.TensorShapeProto_Dim, len(dims)),\n+\t}\n+\n+\tfor i, dim := range dims {\n+\t\tshape.Dim[i] = &pb.TensorShapeProto_Dim{\n+\t\t\tSize: dim,\n+\t\t}\n+\n+\t\tif len(dimNames) == len(dims) {\n+\t\t\tshape.Dim[i].Name = dimNames[i]\n+\t\t}\n+\t}\n+\n+\top.def.Attr[\"shape\"] = &pb.AttrValue{\n+\t\tValue: &pb.AttrValue_Shape{\n+\t\t\tShape: shape,\n+\t\t},\n+\t}\n+\n+\tgr.def.Node = append(gr.def.Node, op.def)\n+\n+\treturn\n+}\n+\n+// AsStr Returns the current graph serialized so it can be exported.\n+func (gr *Graph) AsStr() []byte {\n+\tresult, _ := proto.Marshal(gr.def)\n+\n+\treturn result\n+}\n+\n+// ErrExpectedVarAsinput The specified operation is not defined.\n+type ErrExpectedVarAsinput struct {\n+\toperation string\n+\tinputPos  int\n+}\n+\n+func (e *ErrExpectedVarAsinput) Error() string {\n+\treturn fmt.Sprintf(\n+\t\t\"The expected input value at pos %d for the operation '%s' must be of type Variable\",\n+\t\te.inputPos, e.operation)\n+}\n+\n+// ErrOperationNotFound The specified operation is not defined.\n+type ErrOperationNotFound struct {\n+\top string\n+}\n+\n+func (e *ErrOperationNotFound) Error() string {\n+\treturn fmt.Sprintf(\"Operation '%s' not defined\", e.op)\n+}\n+\n+// ErrInvalidAmounthOfInputs The number of inputs doesn't corresponds with the\n+// expected for this operation.\n+type ErrInvalidAmounthOfInputs struct {\n+\toperation  string\n+\topInputs   int\n+\tspecInputs int\n+}\n+\n+func (e *ErrInvalidAmounthOfInputs) Error() string {\n+\treturn fmt.Sprintf(\"Inputs required for operation '%s': %d, but %d provided\",\n+\t\te.operation, e.opInputs, e.specInputs)\n+}\n+\n+// ErrMandatoryAttributeNotSpecified A mandatory attribute for this operation\n+// was not specified.\n+type ErrMandatoryAttributeNotSpecified struct {\n+\toperation  string\n+\tattribName string\n+}\n+\n+func (e *ErrMandatoryAttributeNotSpecified) Error() string {\n+\treturn fmt.Sprintf(\"The attribute '%s' is mandatory for the operation: '%s'\",\n+\t\te.attribName, e.operation)\n+}\n+\n+// ErrInvalidAttrValue The data type of the value for this attribute is not valid.\n+type ErrInvalidAttrValue struct {\n+\toperation  string\n+\tattribName string\n+}\n+\n+func (e *ErrInvalidAttrValue) Error() string {\n+\treturn fmt.Sprintf(\"The attribute '%s' value provided for operation: '%s' is not valid\",\n+\t\te.attribName, e.operation)\n+}\n+\n+// ErrInputOutputDataTypeMismatch The output data type doesn't match with the input one.\n+type ErrInputOutputDataTypeMismatch struct {\n+\toutDt DataType\n+\tinDt  DataType\n+}\n+\n+func (e *ErrInputOutputDataTypeMismatch) Error() string {\n+\treturn fmt.Sprintf(\"The output datatype '%s' doesn't correspond with the input data type '%s'\",\n+\t\te.outDt, e.inDt)\n+}\n+\n+// castAttrValue Returns an pb.AttrValue that contains the corresponding\n+// pb.AttrValue_* according to the type specified. Returns nil if the data type\n+// of the provided value can't be allocated on the AttrValue type\n+func (gr *Graph) castAttrValue(attrType string, v interface{}) (attrVal *pb.AttrValue) {\n+\tswitch attrType {\n+\tcase \"type\":\n+\t\tif dt, ok := v.(DataType); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_Type{\n+\t\t\t\t\tType: pb.DataType(dt),\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"string\":\n+\t\tif st, ok := v.(string); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_S{\n+\t\t\t\t\tS: []byte(st),\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"tensor\":\n+\t\tif t, ok := v.(*Tensor); ok {\n+\t\t\ttp := &pb.TensorProto{\n+\t\t\t\tDtype:         t.Dtype,\n+\t\t\t\tTensorShape:   t.TensorShape,\n+\t\t\t\tTensorContent: t.TensorContent,\n+\t\t\t}\n+\t\t\tswitch t.DataType() {\n+\t\t\tcase DtFloat:\n+\t\t\t\ttp.FloatVal, _ = t.AsFloat32()\n+\t\t\tcase DtDouble:\n+\t\t\t\ttp.DoubleVal, _ = t.AsFloat64()\n+\t\t\tcase DtInt8, DtInt16, DtInt32, DtUint8:\n+\t\t\t\ttp.IntVal, _ = t.AsInt32()\n+\t\t\tcase DtInt64:\n+\t\t\t\ttp.Int64Val, _ = t.AsInt64()\n+\t\t\tcase DtBool:\n+\t\t\t\ttp.BoolVal, _ = t.AsBool()\n+\t\t\tcase DtString:\n+\t\t\t\ttp.StringVal, _ = t.AsStr()\n+\t\t\tdefault:\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_Tensor{\n+\t\t\t\t\tTensor: tp,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"func\":\n+\t\tif f, ok := v.(*pb.NameAttrList); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_Func{\n+\t\t\t\t\tFunc: f,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"int\":\n+\t\tif i, ok := v.(int64); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_I{\n+\t\t\t\t\tI: i,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"bool\":\n+\t\tif b, ok := v.(bool); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_B{\n+\t\t\t\t\tB: b,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"float\":\n+\t\tif f, ok := v.(float32); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_F{\n+\t\t\t\t\tF: f,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"shape\":\n+\t\tif s, ok := v.(*pb.TensorShapeProto); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_Shape{\n+\t\t\t\t\tShape: s,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\tcase \"list(type)\", \"list(int)\", \"list(shape)\", \"list(float)\":\n+\t\tif lv, ok := v.(*pb.AttrValue_ListValue); ok {\n+\t\t\treturn &pb.AttrValue{\n+\t\t\t\tValue: &pb.AttrValue_List{\n+\t\t\t\t\tList: lv,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+// Constant Creates a tensor that is added as a constant to the Graph with the\n+// specified name.\n+func (gr *Graph) Constant(name string, data interface{}) (op *GraphNode, err error) {\n+\tts, err := NewTensor(data)\n+\tif err != nil {\n+\t\treturn\n+\t}\n+\tgr.constants[name] = ts\n+\n+\treturn gr.Op(\"Const\", name, nil, \"\", map[string]interface{}{\n+\t\t\"dtype\": ts.DataType(),\n+\t\t\"value\": ts,\n+\t})\n+}\n+\n+// matchTypes Matches all the input/output parameters with their corresponding\n+// data types specified on the attribues or deducting the data type from other\n+// parameters, this method can return an error in case of the matching is not\n+// possible, for instance if two input paramters mas have the same data type\n+// but one is int and the other float.\n+func (gr *Graph) matchTypes(input []*GraphNode, outNode *GraphNode, attrs map[string]interface{}, op *pb.OpDef) (err error) {\n+\t// Associate the data type tags with the input data types\n+\tfor i, arg := range op.InputArg {\n+\t\tinType, inTypeDefined := input[i].outDataTypes[input[i].def.Name]\n+\t\tif inTypeDefined && inType != DtInvalid && arg.TypeAttr != \"\" {\n+\t\t\tattrs[arg.TypeAttr] = inType\n+\t\t}\n+\t}\n+\tfor _, arg := range op.OutputArg {\n+\t\targType := DataType(arg.Type)\n+\t\tif arg.TypeAttr != \"\" && argType != DtInvalid {\n+\t\t\tif inType, defined := attrs[arg.TypeAttr]; defined && inType.(DataType) != argType {\n+\t\t\t\treturn &ErrInputOutputDataTypeMismatch{\n+\t\t\t\t\toutDt: argType,\n+\t\t\t\t\tinDt:  inType.(DataType),\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tattrs[arg.TypeAttr] = arg.Type\n+\t\t}\n+\t}\n+\n+\t// Now assign all the types we got from the inputs/ouputs to their\n+\t// binded attributes\n+\tfor _, attr := range op.Attr {\n+\t\tif attr.Type == \"type\" {\n+\t\t\tif _, isTypeProvided := attrs[attr.Name]; !isTypeProvided {\n+\t\t\t\tif inOutDt, inOutDef := attrs[attr.Name]; inOutDef {\n+\t\t\t\t\tattrs[attr.Name] = inOutDt\n+\t\t\t\t} else {\n+\t\t\t\t\tif attr.DefaultValue != nil {\n+\t\t\t\t\t\tattrs[attr.Name] = attr.DefaultValue.GetType()\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Assign the corresonding data types from the attributes to the output\n+\t// params\n+\tfor i, arg := range op.OutputArg {\n+\t\tvar outDt DataType\n+\n+\t\targType := DataType(arg.Type)\n+\t\tif argType != DtInvalid {\n+\t\t\toutDt = argType\n+\t\t} else {\n+\t\t\tif arg.TypeAttr != \"\" {\n+\t\t\t\tif dT, definedDt := attrs[arg.TypeAttr]; definedDt {\n+\t\t\t\t\toutDt = dT.(DataType)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\tif len(op.OutputArg) == 1 {\n+\t\t\toutNode.outDataTypes[outNode.def.Name] = outDt\n+\t\t} else {\n+\t\t\t// This is a node with more than one output, in this\n+\t\t\t// case the name format is: <name:incremental_id>\n+\t\t\toutNode.outDataTypes[fmt.Sprintf(\"%s:%d\", outNode.def.Name, i)] = outDt\n+\t\t}\n+\t}\n+\n+\treturn\n+}\n+\n+// loadAvailableOps Loads all the available operation definitions from local", "path": "tensorflow/contrib/go/graph.go", "position": null, "original_position": 556, "commit_id": "942760424141d0f5a930982d5e78aaeb05869488", "original_commit_id": "210180befbd05694aa3285fef7d498bbd1be2dcc", "user": {"login": "alonsovidales", "id": 1468785, "node_id": "MDQ6VXNlcjE0Njg3ODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1468785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alonsovidales", "html_url": "https://github.com/alonsovidales", "followers_url": "https://api.github.com/users/alonsovidales/followers", "following_url": "https://api.github.com/users/alonsovidales/following{/other_user}", "gists_url": "https://api.github.com/users/alonsovidales/gists{/gist_id}", "starred_url": "https://api.github.com/users/alonsovidales/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alonsovidales/subscriptions", "organizations_url": "https://api.github.com/users/alonsovidales/orgs", "repos_url": "https://api.github.com/users/alonsovidales/repos", "events_url": "https://api.github.com/users/alonsovidales/events{/privacy}", "received_events_url": "https://api.github.com/users/alonsovidales/received_events", "type": "User", "site_admin": false}, "body": "I forgot to update this comment, now the definitions are loaded from a .go file that contains the definitions marshalled as string, this file is generated by go generate. The new comment is:\n\n``` go\n// loadAvailableOps loads all the available operation definitions from a\n// constant stored in: proto/tf_ops_def.go that contains a string with all the\n// operation definitions\n```\n", "created_at": "2016-04-15T20:32:52Z", "updated_at": "2016-05-05T08:12:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59936683", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59936683"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59936683"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771"}}, "body_html": "<p>I forgot to update this comment, now the definitions are loaded from a .go file that contains the definitions marshalled as string, this file is generated by go generate. The new comment is:</p>\n<div class=\"highlight highlight-source-go\"><pre><span class=\"pl-c\"><span class=\"pl-c\">//</span> loadAvailableOps loads all the available operation definitions from a</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> constant stored in: proto/tf_ops_def.go that contains a string with all the</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> operation definitions</span></pre></div>", "body_text": "I forgot to update this comment, now the definitions are loaded from a .go file that contains the definitions marshalled as string, this file is generated by go generate. The new comment is:\n// loadAvailableOps loads all the available operation definitions from a\n// constant stored in: proto/tf_ops_def.go that contains a string with all the\n// operation definitions"}