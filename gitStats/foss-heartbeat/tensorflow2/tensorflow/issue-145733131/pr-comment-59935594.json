{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59935594", "pull_request_review_id": null, "id": 59935594, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTM1NTk0", "diff_hunk": "@@ -0,0 +1,214 @@\n+package main\n+\n+/* Copyright 2015 Google Inc. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// A minimal but useful Go example showing how to load an Imagenet-style object\n+// recognition TensorFlow model, prepare input images for it, run them through\n+// the graph, and interpret the results.\n+//\n+// It's designed to have as few dependencies and be as clear as possible, so\n+// it's more verbose than it could be in production code. The errors maagement\n+// while building the Graph had been ommited in order to make the code less\n+// verbose, but for production code is recomended to check the returned errors\n+// on each step.\n+//\n+// To use it, run in a working directory with the\n+// learning/brain/tutorials/label_image_go/data/ folder below it: go run\n+// main.go <image_file>, you can use data/ceres_paris.jpg as image file which\n+// contains the image of a Labrador and you should see the top five labels for\n+// the example image output.\n+//\n+// The tensorflow_inception_graph.pb file included by default is created from\n+// Inception.\n+\n+import (\n+\t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"log\"\n+\t\"os\"\n+\t\"strings\"\n+\n+\ttf \"github.com/tensorflow/tensorflow/tensorflow/contrib/go\"\n+)\n+\n+const (\n+\tcInputWidth  = 299\n+\tcInputHeight = 299\n+\tcInputMean   = 128\n+\tcInputStd    = 128\n+\n+\t// cInceptionGraphFile This is the path of the graph who contains the\n+\t// model.\n+\tcInceptionGraphFile = \"tensorflow/examples/label_image_go/data/tensorflow_inception_graph.pb\"\n+\t// cLabelsFile File path that contains a label per line.\n+\tcLabelsFile = \"tensorflow/examples/label_image_go/data/imagenet_comp_graph_label_strings.txt\"\n+\n+\t// cLabelsToShow Amounth of best match labels to be returned per image.\n+\tcLabelsToShow = 5\n+)\n+\n+// readTensorFromImageFile Given an image file name, read in the data, try to\n+// decode it as an image, resize it to the requested size, and then scale the\n+// values as desired.\n+func readTensorFromImageFile(filePath string) *tf.Tensor {\n+\tvar imageReader *tf.GraphNode\n+\n+\tgraph := tf.NewGraph()\n+\n+\t// Load the image file path into the graph as a constant, and read its\n+\t// content.\n+\tfileNameNode, _ := graph.Constant(\"file_name\", filePath)\n+\tfileReader, _ := graph.Op(\"ReadFile\", \"file_reader\", []*tf.GraphNode{fileNameNode}, \"\", nil)\n+\n+\t// Now try to figure out what kind of file it is and decode it.\n+\tif filePath[len(filePath)-4:] == \".png\" {\n+\t\timageReader, _ = graph.Op(\"DecodePng\", \"png_reader\", []*tf.GraphNode{fileReader}, \"\", map[string]interface{}{\n+\t\t\t\"channels\": int64(3),\n+\t\t})\n+\t} else {\n+\t\t// Assume if it's not a PNG then it must be a JPEG.\n+\t\timageReader, _ = graph.Op(\"DecodeJpeg\", \"jpeg_reader\", []*tf.GraphNode{fileReader}, \"\", map[string]interface{}{\n+\t\t\t\"channels\": int64(3),\n+\t\t})\n+\t}\n+\n+\t// Now cast the image data to float so we can do normal math on it. In\n+\t// the attributes we have to specify the output datatype that we want.\n+\tfloatCaster, _ := graph.Op(\"Cast\", \"float_caster\", []*tf.GraphNode{imageReader}, \"\", map[string]interface{}{\n+\t\t\"DstT\": tf.DtFloat,\n+\t})\n+\n+\t// The convention for image ops in TensorFlow is that all images are expected\n+\t// to be in batches, so that they're four-dimensional arrays with indices of\n+\t// [batch, height, width, channel]. Because we only have a single image, we\n+\t// have to add a batch dimension of 1 to the start with ExpandDims operation.\n+\tdimIndex, _ := graph.Constant(\"dim_index\", []int32{0})\n+\tdimsExpander, _ := graph.Op(\"ExpandDims\", \"dims_expander\", []*tf.GraphNode{floatCaster, dimIndex}, \"\", map[string]interface{}{\n+\t\t\"T\":   tf.DtFloat,\n+\t\t\"dim\": 0,\n+\t})\n+\n+\t// Bilinearly resize the image to fit the required dimensions.\n+\tsizeDims, _ := graph.Constant(\"size_dims\", []int32{cInputWidth, cInputHeight})\n+\tsize, _ := graph.Op(\"ResizeBilinear\", \"size\", []*tf.GraphNode{dimsExpander, sizeDims}, \"\", map[string]interface{}{\n+\t\t\"T\": tf.DtFloat,\n+\t})\n+\n+\t// Subtract the mean and divide by the scale.\n+\tinputMean, _ := graph.Constant(\"input_mean\", float32(cInputMean))\n+\tsubMean, _ := graph.Op(\"Sub\", \"sub_mean\", []*tf.GraphNode{size, inputMean}, \"\", nil)\n+\tinputStd, _ := graph.Constant(\"input_std\", float32(cInputStd))\n+\t_, _ = graph.Op(\"Div\", \"normalized\", []*tf.GraphNode{subMean, inputStd}, \"\", nil)\n+\n+\t// Create the session and extend the Graph\n+\ts, err := tf.NewSession()\n+\ts.ExtendGraph(graph)\n+\n+\t/// This runs the GraphDef network definition that we've just constructed, and\n+\t// returns the results in the output tensor.\n+\tout, err := s.Run(nil, []string{\"normalized\"}, nil)\n+\tif err != nil {\n+\t\tlog.Fatal(\"Problem trying to run the graph, Error:\", err)\n+\t}\n+\n+\tif len(out) != 1 {\n+\t\tlog.Fatalf(\"The expected number of outputs is 1 but: %d returned\", len(out))\n+\t}\n+\n+\t// The outputs are sorted in the same order than they was specfied on", "path": "tensorflow/examples/label_image_go/main.go", "position": null, "original_position": 131, "commit_id": "942760424141d0f5a930982d5e78aaeb05869488", "original_commit_id": "210180befbd05694aa3285fef7d498bbd1be2dcc", "user": {"login": "dave-andersen", "id": 827870, "node_id": "MDQ6VXNlcjgyNzg3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/827870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-andersen", "html_url": "https://github.com/dave-andersen", "followers_url": "https://api.github.com/users/dave-andersen/followers", "following_url": "https://api.github.com/users/dave-andersen/following{/other_user}", "gists_url": "https://api.github.com/users/dave-andersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-andersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-andersen/subscriptions", "organizations_url": "https://api.github.com/users/dave-andersen/orgs", "repos_url": "https://api.github.com/users/dave-andersen/repos", "events_url": "https://api.github.com/users/dave-andersen/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-andersen/received_events", "type": "User", "site_admin": false}, "body": "typo:  \"than they was ...\" -> that they were specified in\n", "created_at": "2016-04-15T20:23:32Z", "updated_at": "2016-05-05T08:12:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59935594", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59935594"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59935594"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771"}}, "body_html": "<p>typo:  \"than they was ...\" -&gt; that they were specified in</p>", "body_text": "typo:  \"than they was ...\" -> that they were specified in"}