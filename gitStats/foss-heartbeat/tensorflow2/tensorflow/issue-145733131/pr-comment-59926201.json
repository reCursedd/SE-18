{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59926201", "pull_request_review_id": null, "id": 59926201, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTI2MjAx", "diff_hunk": "@@ -0,0 +1,763 @@\n+package tensorflow\n+\n+import (\n+\t\"encoding/binary\"\n+\t\"fmt\"\n+\t\"math\"\n+\t\"reflect\"\n+\t\"runtime\"\n+\t\"unsafe\"\n+\n+\t\"github.com/golang/protobuf/proto\"\n+\n+\tpb \"github.com/tensorflow/tensorflow/tensorflow/contrib/go/proto\"\n+)\n+\n+import \"C\"\n+\n+const (\n+\tcAckByte  = 6\n+\tcBellByte = 7\n+\tcDc1      = 17\n+\n+\tcBytesComplex64 = 8\n+\tcBytesFloat32   = 4\n+\tcBytesFloat64   = 8\n+\tcBytesInt16     = 2\n+\tcBytesInt32     = 4\n+\tcBytesInt64     = 8\n+\tcBytesUint16    = 2\n+)\n+\n+// DataType Type of the data contained by a Tensor\n+type DataType pb.DataType\n+\n+// TensorInt Interface to be implemented by the tensors.\n+type TensorInt interface {\n+\tData() []byte\n+\tDataSize() int64\n+\tDataType() DataType\n+\tGetVal(d ...int) (val interface{}, err error)\n+\n+\tDim(n int) int\n+\tNumDims() int\n+\n+\tAsBool() (res []bool, err error)\n+\tAsFloat32() (res []float32, err error)\n+\tAsFloat64() (res []float64, err error)\n+\tAsInt32() (res []int32, err error)\n+\tAsInt64() (res []int64, err error)\n+\tAsStr() (res [][]byte, err error)\n+\n+\tString() string\n+}\n+\n+// Tensor Holds a multi-dimensional array of elements of a single data type.\n+type Tensor struct {\n+\tpb.TensorProto\n+\n+\ttensor      TF_Tensor\n+\tdimWeights  []int\n+\tmemReleased bool\n+}\n+\n+// TensorShape represents the shapre of a Tensor.\n+type TensorShape [][]int64\n+\n+var (\n+\t// DtInvalid Invalid tensor DataType.\n+\tDtInvalid = DataType(0)\n+\t// DtBfloat corresponds to TF_BFLOAT16.\n+\tDtBfloat = DataType(TF_BFLOAT16)\n+\t// DtBool corresponds to TF_BOOL.\n+\tDtBool = DataType(TF_BOOL)\n+\t// DtComplex corresponds to TF_COMPLEX.\n+\tDtComplex = DataType(TF_COMPLEX)\n+\t// DtFloat corresponds to TF_FLOAT.\n+\tDtFloat = DataType(TF_FLOAT)\n+\t// DtDouble corresponds to TF_DOUBLE.\n+\tDtDouble = DataType(TF_DOUBLE)\n+\t// DtInt8 corresponds to TF_INT8.\n+\tDtInt8 = DataType(TF_INT8)\n+\t// DtInt16 corresponds to TF_INT16.\n+\tDtInt16 = DataType(TF_INT16)\n+\t// DtInt32 corresponds to TF_INT32.\n+\tDtInt32 = DataType(TF_INT32)\n+\t// DtInt64 corresponds to TF_INT64.\n+\tDtInt64 = DataType(TF_INT64)\n+\t// DtQint16 corresponds to TF_QINT16.\n+\tDtQint16 = DataType(TF_QINT16)\n+\t// DtQuint16 corresponds to TF_QUINT16.\n+\tDtQuint16 = DataType(TF_QUINT16)\n+\t// DtQuint32 corresponds to TF_QINT32.\n+\tDtQuint32 = DataType(TF_QINT32)\n+\t// DtQint8 corresponds to TF_QINT8.\n+\tDtQint8 = DataType(TF_QINT8)\n+\t// DtQuint8 corresponds to TF_QUINT8.\n+\tDtQuint8 = DataType(TF_QUINT8)\n+\t// DtString corresponds to TF_STRING.\n+\tDtString = DataType(TF_STRING)\n+\t// DtUint8 corresponds to TF_UINT8.\n+\tDtUint8 = DataType(TF_UINT8)\n+\t// DtUint16 corresponds to TF_UINT16.\n+\tDtUint16 = DataType(TF_UINT16)\n+)\n+\n+// NewTensorWithShape returns a new tensor with teh specified type, shape and data.\n+// The supported  data types are:\n+//  - DtInt8\n+//  - DtInt16\n+//  - DtInt32\n+//  - DtInt64\n+//  - DtUint8\n+//  - DtUint16\n+//  - DtFloat\n+//  - DtDouble\n+func NewTensorWithShape(shape TensorShape, data interface{}) (*Tensor, error) {\n+\tv := reflect.ValueOf(data)\n+\tif v.Kind() != reflect.Slice {\n+\t\treturn nil, &ErrSliceExpected{\n+\t\t\tdataType: v.Kind().String(),\n+\t\t}\n+\t}\n+\n+\tdataType, err := getDataTypeFromReflect(v.Type().Elem().Kind(), int64(v.Type().Elem().Size()))\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tdataSize := int64(v.Len()) * int64(v.Type().Elem().Size())\n+\tdataPtr := v.Pointer()\n+\n+\treturn newTensor(dataType, shape, unsafe.Pointer(dataPtr), dataSize)\n+}\n+\n+// NewTensor Initializes a tensor based on the slice passed by parameter, the\n+// data type and shape is deducted from the data parameter.\n+func NewTensor(data interface{}) (tensor *Tensor, err error) {\n+\tvar dataPtr uintptr\n+\tvar dataSer []interface{}\n+\tvar dims [][]int64\n+\tvar dataType DataType\n+\tvar dataSize int64\n+\n+\tv := reflect.ValueOf(data)\n+\tif v.Kind() == reflect.Slice {\n+\t\tdataType, _ = getDataTypeFromReflect(v.Type().Elem().Kind(), 1)\n+\t\tif dataType == DtString {\n+\t\t\tstrings := make([]string, v.Len())\n+\t\t\tfor i := 0; i < v.Len(); i++ {\n+\t\t\t\tstrings[i] = v.Index(i).String()\n+\t\t\t}\n+\t\t\tbuf := encodeStrings(strings)\n+\t\t\treturn newTensor(DtString, TensorShape{{int64(len(strings))}}, unsafe.Pointer(&(buf[0])), int64(len(buf)))\n+\t\t}\n+\n+\t\tdataSer, dims, dataType, dataSize, err = serialize(data, 0, [][]int64{})\n+\t\tif err != nil {\n+\t\t\treturn\n+\t\t}\n+\t} else {\n+\t\t// Scalar tensor\n+\t\tdataSer = []interface{}{data}\n+\t\tdims = [][]int64{}\n+\t\tdataSize = int64(v.Type().Size())\n+\t\tif dataType, err = getDataTypeFromReflect(v.Kind(), dataSize); err != nil {\n+\t\t\treturn\n+\t\t}\n+\t}\n+\tts := TensorShape(dims)\n+\n+\tauxTensor := new(Tensor)\n+\tswitch dataType {\n+\tcase DtFloat:\n+\t\tauxTensor.FloatVal = make([]float32, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.FloatVal[i] = v.(float32)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.FloatVal).Pointer()\n+\tcase DtDouble:\n+\t\tauxTensor.DoubleVal = make([]float64, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.DoubleVal[i] = v.(float64)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.DoubleVal).Pointer()\n+\tcase DtInt8, DtInt16, DtInt32, DtUint8:\n+\t\tauxTensor.IntVal = make([]int32, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.IntVal[i] = int32(reflect.ValueOf(v).Int())\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.IntVal).Pointer()\n+\tcase DtInt64:\n+\t\tauxTensor.Int64Val = make([]int64, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.Int64Val[i] = reflect.ValueOf(v).Int()\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.Int64Val).Pointer()\n+\tcase DtBool:\n+\t\tauxTensor.BoolVal = make([]bool, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.BoolVal[i] = v.(bool)\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.BoolVal).Pointer()\n+\tcase DtString:\n+\t\tauxTensor.StringVal = make([][]byte, len(dataSer))\n+\t\tfor i, v := range dataSer {\n+\t\t\tauxTensor.StringVal[i] = []byte(v.(string))\n+\t\t}\n+\t\tdataPtr = reflect.ValueOf(auxTensor.StringVal).Pointer()\n+\tdefault:\n+\t\treturn nil, &ErrTensorTypeNotSupported{\n+\t\t\ttensotType: dataType,\n+\t\t}\n+\t}\n+\n+\ttensor, err = newTensor(dataType, ts, unsafe.Pointer(dataPtr), int64(len(dataSer))*dataSize)\n+\n+\ttensor.FloatVal = auxTensor.FloatVal\n+\ttensor.DoubleVal = auxTensor.DoubleVal\n+\ttensor.IntVal = auxTensor.IntVal\n+\ttensor.StringVal = auxTensor.StringVal\n+\ttensor.ScomplexVal = auxTensor.ScomplexVal\n+\ttensor.Int64Val = auxTensor.Int64Val\n+\ttensor.BoolVal = auxTensor.BoolVal\n+\n+\treturn\n+}\n+\n+// DataType returns the data type of the elements contained by the tensor.\n+func (t *Tensor) DataType() DataType {\n+\treturn DataType(TF_TensorType(t.tensor))\n+}\n+\n+// NumDims returns the number of dimensions that this tensor in a tensor.\n+func (t *Tensor) NumDims() int {\n+\treturn TF_NumDims(t.tensor)\n+}\n+\n+// Shape returns the shape of the tensor.\n+func (t *Tensor) Shape() (shape TensorShape) {\n+\tif t.NumDims() == 0 {\n+\t\t// This is a scalar tensor\n+\t\tshape = [][]int64{}\n+\t} else {\n+\t\tshape = make([][]int64, t.NumDims())\n+\t\tfor i := 0; i < t.NumDims(); i++ {\n+\t\t\tshape[i] = []int64{int64(t.Dim(i))}\n+\t\t}\n+\t}\n+\n+\treturn shape\n+}\n+\n+// Dim returns the size of the specified dimension.\n+func (t *Tensor) Dim(n int) int {\n+\treturn int(TF_Dim(t.tensor, n))\n+}\n+\n+// DataSize returns the size of the data in bytes contained in a tensor.\n+func (t *Tensor) DataSize() int64 {\n+\treturn TF_TensorByteSize(t.tensor)\n+}\n+\n+// Data returns the data contained in a tensor as a slice of bytes.\n+func (t *Tensor) Data() []byte {\n+\tlength := t.DataSize()\n+\treturn (*[1 << 40]byte)(unsafe.Pointer(TF_TensorData(t.tensor)))[:length:length]\n+}\n+\n+// String string representation of a tensor.", "path": "tensorflow/contrib/go/tensor.go", "position": null, "original_position": 269, "commit_id": "942760424141d0f5a930982d5e78aaeb05869488", "original_commit_id": "210180befbd05694aa3285fef7d498bbd1be2dcc", "user": {"login": "dave-andersen", "id": 827870, "node_id": "MDQ6VXNlcjgyNzg3MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/827870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-andersen", "html_url": "https://github.com/dave-andersen", "followers_url": "https://api.github.com/users/dave-andersen/followers", "following_url": "https://api.github.com/users/dave-andersen/following{/other_user}", "gists_url": "https://api.github.com/users/dave-andersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-andersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-andersen/subscriptions", "organizations_url": "https://api.github.com/users/dave-andersen/orgs", "repos_url": "https://api.github.com/users/dave-andersen/repos", "events_url": "https://api.github.com/users/dave-andersen/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-andersen/received_events", "type": "User", "site_admin": false}, "body": "String returns a human-readable string description of a Tensor.\n", "created_at": "2016-04-15T19:11:43Z", "updated_at": "2016-05-05T08:12:14Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59926201", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/59926201"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/1771#discussion_r59926201"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/1771"}}, "body_html": "<p>String returns a human-readable string description of a Tensor.</p>", "body_text": "String returns a human-readable string description of a Tensor."}