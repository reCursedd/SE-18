{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/437770603", "html_url": "https://github.com/tensorflow/tensorflow/issues/23665#issuecomment-437770603", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23665", "id": 437770603, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzc3MDYwMw==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-12T06:27:02Z", "updated_at": "2018-11-12T06:27:02Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>def f(x): return tf.reduce_mean(x,(0,1,2,),keep_dims=True)<br>\nso the output would be a tensor shape of (1,1,1,32) right?<br>\nBut when we take the derivative respect to the original input x the derivative is 1/(10 * 94 * 94)<br>\nFor all variable in x - so it would be a tensor that has a shape of (10,94,94,32) but every value would be<br>\n0.00001131733</p>\n</blockquote>\n<p>This is correct. And this is <code>dx_hat/dx</code>.<br>\nBut the point is, because it is a tensor (not a real number), and the multiplication is a tensor product: you can only take out the individual element of the tensor after the multiplication. You can not first take one real value out of each tensor and then multiply them together.</p>\n<p>Also, I'm not sure if you are aware, but <a href=\"https://www.tensorflow.org/api_docs/python/tf/gradients\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/gradients</a> has this sentence that's relevant:</p>\n<blockquote>\n<p>grad_ys is a list of tensors of the same length as ys that holds the initial gradients for each y in ys. When grad_ys is None, we fill in a tensor of '1's of the shape of y for each y in ys.</p>\n</blockquote>\n<p>This means that you're actually computing <code>tf.gradients(xs=testing_tensor, ys=tf.reduce_sum(testing_output))</code></p>\n<p>If that's not clear enough, I would be sorry but I do not intend to explain more of it. My intention is mainly to give an initial triage of the issue so the TF developers can focus more on actual bugs.</p>", "body_text": "def f(x): return tf.reduce_mean(x,(0,1,2,),keep_dims=True)\nso the output would be a tensor shape of (1,1,1,32) right?\nBut when we take the derivative respect to the original input x the derivative is 1/(10 * 94 * 94)\nFor all variable in x - so it would be a tensor that has a shape of (10,94,94,32) but every value would be\n0.00001131733\n\nThis is correct. And this is dx_hat/dx.\nBut the point is, because it is a tensor (not a real number), and the multiplication is a tensor product: you can only take out the individual element of the tensor after the multiplication. You can not first take one real value out of each tensor and then multiply them together.\nAlso, I'm not sure if you are aware, but https://www.tensorflow.org/api_docs/python/tf/gradients has this sentence that's relevant:\n\ngrad_ys is a list of tensors of the same length as ys that holds the initial gradients for each y in ys. When grad_ys is None, we fill in a tensor of '1's of the shape of y for each y in ys.\n\nThis means that you're actually computing tf.gradients(xs=testing_tensor, ys=tf.reduce_sum(testing_output))\nIf that's not clear enough, I would be sorry but I do not intend to explain more of it. My intention is mainly to give an initial triage of the issue so the TF developers can focus more on actual bugs.", "body": "> def f(x): return tf.reduce_mean(x,(0,1,2,),keep_dims=True)\r\nso the output would be a tensor shape of (1,1,1,32) right?\r\nBut when we take the derivative respect to the original input x the derivative is 1/(10 * 94 * 94)\r\nFor all variable in x - so it would be a tensor that has a shape of (10,94,94,32) but every value would be\r\n0.00001131733\r\n\r\nThis is correct. And this is `dx_hat/dx`.\r\nBut the point is, because it is a tensor (not a real number), and the multiplication is a tensor product: you can only take out the individual element of the tensor after the multiplication. You can not first take one real value out of each tensor and then multiply them together.\r\n\r\nAlso, I'm not sure if you are aware, but https://www.tensorflow.org/api_docs/python/tf/gradients has this sentence that's relevant: \r\n> grad_ys is a list of tensors of the same length as ys that holds the initial gradients for each y in ys. When grad_ys is None, we fill in a tensor of '1's of the shape of y for each y in ys.\r\n\r\nThis means that you're actually computing `tf.gradients(xs=testing_tensor, ys=tf.reduce_sum(testing_output))`\r\n\r\nIf that's not clear enough, I would be sorry but I do not intend to explain more of it. My intention is mainly to give an initial triage of the issue so the TF developers can focus more on actual bugs."}