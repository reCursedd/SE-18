{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23665", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23665/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23665/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23665/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23665", "id": 379562827, "node_id": "MDU6SXNzdWUzNzk1NjI4Mjc=", "number": 23665, "title": "Possible Error for tf Gradient on mean", "user": {"login": "JaeDukSeo", "id": 22832406, "node_id": "MDQ6VXNlcjIyODMyNDA2", "avatar_url": "https://avatars1.githubusercontent.com/u/22832406?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JaeDukSeo", "html_url": "https://github.com/JaeDukSeo", "followers_url": "https://api.github.com/users/JaeDukSeo/followers", "following_url": "https://api.github.com/users/JaeDukSeo/following{/other_user}", "gists_url": "https://api.github.com/users/JaeDukSeo/gists{/gist_id}", "starred_url": "https://api.github.com/users/JaeDukSeo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JaeDukSeo/subscriptions", "organizations_url": "https://api.github.com/users/JaeDukSeo/orgs", "repos_url": "https://api.github.com/users/JaeDukSeo/repos", "events_url": "https://api.github.com/users/JaeDukSeo/events{/privacy}", "received_events_url": "https://api.github.com/users/JaeDukSeo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-11-11T21:01:13Z", "updated_at": "2018-11-12T06:31:17Z", "closed_at": "2018-11-12T06:31:17Z", "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary):</li>\n<li>TensorFlow version (use command below):</li>\n<li>Python version: python 3</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU model and memory:</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\nb'v1.8.0-0-g93bc2e2072' 1.8.0</p>\n<p><strong>Describe the current behavior</strong><br>\nWhen taking the gradient respect to a variable and reduce mean the outcome should be<br>\n1 - (1/(# of reduced dimension)) however it does not happen.</p>\n<p><strong>Describe the expected behavior</strong><br>\nThere are a different blog post and resources on how to perform backpropagation for batch norm.<br>\nCentering the data is a key part of any norm, and it seems like auto differentiation is getting the value wrong? Or am I just going crazy. I thought the gradient respect to the input variable should be<br>\n1 - 1/(10<em>94</em>94) - since 10 is dim - 94 is dim 1 and 2.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.<br>\nimport tensorflow as tf<br>\ntesting_tensor   = tf.placeholder(shape=[10,94,94,32],dtype=tf.float64)<br>\ntesting_output   = testing_tensor - tf.reduce_mean(testing_tensor,(0,1,2),keep_dims=True)<br>\nwhat_grad_auto   = tf.gradients(xs=testing_tensor,ys=testing_output)</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/22832406/48318218-c9682400-e5ca-11e8-8abd-46e660ada701.png\"><img src=\"https://user-images.githubusercontent.com/22832406/48318218-c9682400-e5ca-11e8-8abd-46e660ada701.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version: python 3\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nb'v1.8.0-0-g93bc2e2072' 1.8.0\nDescribe the current behavior\nWhen taking the gradient respect to a variable and reduce mean the outcome should be\n1 - (1/(# of reduced dimension)) however it does not happen.\nDescribe the expected behavior\nThere are a different blog post and resources on how to perform backpropagation for batch norm.\nCentering the data is a key part of any norm, and it seems like auto differentiation is getting the value wrong? Or am I just going crazy. I thought the gradient respect to the input variable should be\n1 - 1/(109494) - since 10 is dim - 94 is dim 1 and 2.\nCode to reproduce the issue\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\nimport tensorflow as tf\ntesting_tensor   = tf.placeholder(shape=[10,94,94,32],dtype=tf.float64)\ntesting_output   = testing_tensor - tf.reduce_mean(testing_tensor,(0,1,2),keep_dims=True)\nwhat_grad_auto   = tf.gradients(xs=testing_tensor,ys=testing_output)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version: python 3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nb'v1.8.0-0-g93bc2e2072' 1.8.0\r\n\r\n**Describe the current behavior**\r\nWhen taking the gradient respect to a variable and reduce mean the outcome should be \r\n1 - (1/(# of reduced dimension)) however it does not happen. \r\n\r\n\r\n**Describe the expected behavior**\r\nThere are a different blog post and resources on how to perform backpropagation for batch norm. \r\nCentering the data is a key part of any norm, and it seems like auto differentiation is getting the value wrong? Or am I just going crazy. I thought the gradient respect to the input variable should be\r\n1 - 1/(10*94*94) - since 10 is dim - 94 is dim 1 and 2. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nimport tensorflow as tf\r\ntesting_tensor   = tf.placeholder(shape=[10,94,94,32],dtype=tf.float64)\r\ntesting_output   = testing_tensor - tf.reduce_mean(testing_tensor,(0,1,2),keep_dims=True) \r\nwhat_grad_auto   = tf.gradients(xs=testing_tensor,ys=testing_output)\r\n\r\n![image](https://user-images.githubusercontent.com/22832406/48318218-c9682400-e5ca-11e8-8abd-46e660ada701.png)\r\n\r\n"}