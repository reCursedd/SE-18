{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/271486091", "html_url": "https://github.com/tensorflow/tensorflow/issues/6360#issuecomment-271486091", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6360", "id": 271486091, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MTQ4NjA5MQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-10T04:51:56Z", "updated_at": "2017-01-10T06:17:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5376757\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/michaelisard\">@michaelisard</a> so turns out <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2111293\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/danijar\">@danijar</a> and I were both working on an A3C, and have similar use-case -- use-case is for <code>Snapshot</code> type op that lets you obtain a variable between updates. More specifically, our A3C implementation in <a href=\"https://github.com/openai/universe-starter-agent\">https://github.com/openai/universe-starter-agent</a> has agents trying to make prediction using parameters stored on a parameter server, which may be in the process of being updated by other agents, hence inconsistent. We'd like to be able to get a consistent version of parameters. A complication is that network parameters are typically split over several variables.</p>\n<p>So maybe something like this, when updating params stored on parameter server.</p>\n<p><code>ops.apply_gradients(grads_and_vars, snapshot_vars) </code></p>\n<p>Then on workers, when transferring central parameters to a local copy.<br>\n<code>tf.copy_snapshots(snapshot_vars, local_vars)</code></p>\n<p>The last op would be guaranteed to place a consistent version of global parameter variables into local parameter variables.</p>", "body_text": "@michaelisard so turns out @danijar and I were both working on an A3C, and have similar use-case -- use-case is for Snapshot type op that lets you obtain a variable between updates. More specifically, our A3C implementation in https://github.com/openai/universe-starter-agent has agents trying to make prediction using parameters stored on a parameter server, which may be in the process of being updated by other agents, hence inconsistent. We'd like to be able to get a consistent version of parameters. A complication is that network parameters are typically split over several variables.\nSo maybe something like this, when updating params stored on parameter server.\nops.apply_gradients(grads_and_vars, snapshot_vars) \nThen on workers, when transferring central parameters to a local copy.\ntf.copy_snapshots(snapshot_vars, local_vars)\nThe last op would be guaranteed to place a consistent version of global parameter variables into local parameter variables.", "body": "@michaelisard so turns out @danijar and I were both working on an A3C, and have similar use-case -- use-case is for `Snapshot` type op that lets you obtain a variable between updates. More specifically, our A3C implementation in https://github.com/openai/universe-starter-agent has agents trying to make prediction using parameters stored on a parameter server, which may be in the process of being updated by other agents, hence inconsistent. We'd like to be able to get a consistent version of parameters. A complication is that network parameters are typically split over several variables. \r\n\r\nSo maybe something like this, when updating params stored on parameter server.\r\n\r\n`ops.apply_gradients(grads_and_vars, snapshot_vars)\r\n`\r\n\r\nThen on workers, when transferring central parameters to a local copy. \r\n`tf.copy_snapshots(snapshot_vars, local_vars)`\r\n\r\nThe last op would be guaranteed to place a consistent version of global parameter variables into local parameter variables."}