{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299069708", "html_url": "https://github.com/tensorflow/tensorflow/issues/5987#issuecomment-299069708", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5987", "id": 299069708, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTA2OTcwOA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-04T00:11:27Z", "updated_at": "2017-05-04T00:11:27Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=26417094\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ybsave\">@ybsave</a> what <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=756520\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kmalakoff\">@kmalakoff</a> wrote is a way to compute evaluation metrics while training.</p>\n<p>As I mentioned above, that has some problems, like slowing down the training, but could be used for early stopping.</p>\n<p>For examples on how to train and evaluate in two different process see:<br>\n<a href=\"https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py\">https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py</a><br>\n<a href=\"https://github.com/tensorflow/models/blob/master/slim/eval_image_classifier.py\">https://github.com/tensorflow/models/blob/master/slim/eval_image_classifier.py</a></p>\n<p>I typically just run train_image_classifier in one process and eval_image_classifier in another.</p>", "body_text": "@ybsave what @kmalakoff wrote is a way to compute evaluation metrics while training.\nAs I mentioned above, that has some problems, like slowing down the training, but could be used for early stopping.\nFor examples on how to train and evaluate in two different process see:\nhttps://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py\nhttps://github.com/tensorflow/models/blob/master/slim/eval_image_classifier.py\nI typically just run train_image_classifier in one process and eval_image_classifier in another.", "body": "@ybsave what @kmalakoff wrote is a way to compute evaluation metrics while training.\r\n\r\nAs I mentioned above, that has some problems, like slowing down the training, but could be used for early stopping.\r\n\r\nFor examples on how to train and evaluate in two different process see:\r\nhttps://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py\r\nhttps://github.com/tensorflow/models/blob/master/slim/eval_image_classifier.py\r\n\r\nI typically just run train_image_classifier in one process and eval_image_classifier in another."}