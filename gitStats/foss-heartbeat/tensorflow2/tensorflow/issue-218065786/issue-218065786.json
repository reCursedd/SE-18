{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8828", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8828/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8828/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8828/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8828", "id": 218065786, "node_id": "MDU6SXNzdWUyMTgwNjU3ODY=", "number": 8828, "title": "Suport cuDNN v6.0", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gunan", "id": 7946809, "node_id": "MDQ6VXNlcjc5NDY4MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7946809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gunan", "html_url": "https://github.com/gunan", "followers_url": "https://api.github.com/users/gunan/followers", "following_url": "https://api.github.com/users/gunan/following{/other_user}", "gists_url": "https://api.github.com/users/gunan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gunan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gunan/subscriptions", "organizations_url": "https://api.github.com/users/gunan/orgs", "repos_url": "https://api.github.com/users/gunan/repos", "events_url": "https://api.github.com/users/gunan/events{/privacy}", "received_events_url": "https://api.github.com/users/gunan/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 45, "created_at": "2017-03-30T02:48:37Z", "updated_at": "2018-03-11T22:04:15Z", "closed_at": "2017-12-22T18:41:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>cuDNN v6.0 has been released. There are some cool new features:</p>\n<ul>\n<li>Dilated Convolutions: Dilated Convolutions are now supported in cuDNN without a<br>\nchange in API.</li>\n<li><code>cudnnConvolutionBiasActivationForward</code> allows for the execution of a single kernel fusing convolution, bias and activation operations</li>\n</ul>\n<p>Full release notes:</p>\n<blockquote>\n<p>Dilated Convolutions: Dilated Convolutions are now supported in cuDNN without a<br>\nchange in API. Previously unused \u201cupscale\u201d fields in the Convolution Descriptor<br>\nhave been repurposed to allow user specification of dilation factors along each<br>\ndimension. Support for dilation is present in the following code paths :<br>\nForward : CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,<br>\nBackward Data: CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 and<br>\nBackward Filter: CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0<br>\n\uf0b7 The new API cudnnConvolutionBiasActivationForward allows for the execution of<br>\na single kernel fusing convolution, bias and activation operations. At present, only<br>\nper channel bias and RELU activation are supported.<br>\n\uf0b7 Inference on 8 bit integer data is now supported, leveraging the 4 element dot<br>\nproduct instruction (IDP4A) of Pascal GPUs with CUDA capabilities 6.1. Two tensor<br>\nlayouts are supported for this feature: CUDNN_TENSOR_NHWC with INT8 data<br>\ntype and CUDNN_TENSOR_NCHW_VECT with INT8x4 data type.<br>\n\uf0b7 RNN now supports 3 algorithms<br>\no CUDNN_RNN_ALGO_STANDARD :<br>\n\uf0a7 Same functionality as in CUDNN v5.1<br>\no CUDNN_RNN_ALGO_PERSIST_STATIC :<br>\n\uf0a7 This algorithm relies on the usage of persistent CUDA kernels which<br>\nare pre-compiled to fit different GPUs.<br>\n\uf0a7 This algorithm is available only on Pascal GPUs.<br>\no CUDNN_RNN_ALGO_PERSIST_DYNAMIC :<br>\nThis algorithm also relies on the usage of persistent CUDA kernels<br>\nbut these kernels are compiled at runtime using nvrtc. In some cases<br>\nthis results in a significant performance benefit.<br>\n\uf0a7 This algorithm is also available only on Pascal GPUs and is supported<br>\nonly on Linux and Windows.<br>\n\uf0b7 Support for 1D-FFT convolutions has been added<br>\n\uf0b7 New API routine cudnnReduceTensor has been added, supporting 8 reduction<br>\noperations<br>\n\uf0b7 Activation mode CUDNN_ACTIVATION_ELU is now supported.<br>\n\uf0b7 A deterministic max pooling mode CUDNN_POOLING_MAX_DETERMINISTIC<br>\nhas been added.<br>\n\uf0b7 Significant performance improvement for softmax layers for mode<br>\nCUDNN_SOFTMAX_MODE_CHANNEL has been achieved when low batch<br>\nnumber is used.<br>\n\uf0b7 Significant performance improvements have been added for cudnnAddTensor<br>\nwhen spatial dimensions are set to 1.</p>\n</blockquote>", "body_text": "cuDNN v6.0 has been released. There are some cool new features:\n\nDilated Convolutions: Dilated Convolutions are now supported in cuDNN without a\nchange in API.\ncudnnConvolutionBiasActivationForward allows for the execution of a single kernel fusing convolution, bias and activation operations\n\nFull release notes:\n\nDilated Convolutions: Dilated Convolutions are now supported in cuDNN without a\nchange in API. Previously unused \u201cupscale\u201d fields in the Convolution Descriptor\nhave been repurposed to allow user specification of dilation factors along each\ndimension. Support for dilation is present in the following code paths :\nForward : CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\nBackward Data: CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 and\nBackward Filter: CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0\n\uf0b7 The new API cudnnConvolutionBiasActivationForward allows for the execution of\na single kernel fusing convolution, bias and activation operations. At present, only\nper channel bias and RELU activation are supported.\n\uf0b7 Inference on 8 bit integer data is now supported, leveraging the 4 element dot\nproduct instruction (IDP4A) of Pascal GPUs with CUDA capabilities 6.1. Two tensor\nlayouts are supported for this feature: CUDNN_TENSOR_NHWC with INT8 data\ntype and CUDNN_TENSOR_NCHW_VECT with INT8x4 data type.\n\uf0b7 RNN now supports 3 algorithms\no CUDNN_RNN_ALGO_STANDARD :\n\uf0a7 Same functionality as in CUDNN v5.1\no CUDNN_RNN_ALGO_PERSIST_STATIC :\n\uf0a7 This algorithm relies on the usage of persistent CUDA kernels which\nare pre-compiled to fit different GPUs.\n\uf0a7 This algorithm is available only on Pascal GPUs.\no CUDNN_RNN_ALGO_PERSIST_DYNAMIC :\nThis algorithm also relies on the usage of persistent CUDA kernels\nbut these kernels are compiled at runtime using nvrtc. In some cases\nthis results in a significant performance benefit.\n\uf0a7 This algorithm is also available only on Pascal GPUs and is supported\nonly on Linux and Windows.\n\uf0b7 Support for 1D-FFT convolutions has been added\n\uf0b7 New API routine cudnnReduceTensor has been added, supporting 8 reduction\noperations\n\uf0b7 Activation mode CUDNN_ACTIVATION_ELU is now supported.\n\uf0b7 A deterministic max pooling mode CUDNN_POOLING_MAX_DETERMINISTIC\nhas been added.\n\uf0b7 Significant performance improvement for softmax layers for mode\nCUDNN_SOFTMAX_MODE_CHANNEL has been achieved when low batch\nnumber is used.\n\uf0b7 Significant performance improvements have been added for cudnnAddTensor\nwhen spatial dimensions are set to 1.", "body": "cuDNN v6.0 has been released. There are some cool new features:\r\n* Dilated Convolutions: Dilated Convolutions are now supported in cuDNN without a\r\nchange in API.\r\n* `cudnnConvolutionBiasActivationForward` allows for the execution of a single kernel fusing convolution, bias and activation operations\r\n\r\nFull release notes:\r\n>Dilated Convolutions: Dilated Convolutions are now supported in cuDNN without a\r\nchange in API. Previously unused \u201cupscale\u201d fields in the Convolution Descriptor\r\nhave been repurposed to allow user specification of dilation factors along each\r\ndimension. Support for dilation is present in the following code paths :\r\nForward : CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\r\nBackward Data: CUDNN_CONVOLUTION_BWD_DATA_ALGO_0 and\r\nBackward Filter: CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0\r\n\uf0b7 The new API cudnnConvolutionBiasActivationForward allows for the execution of\r\na single kernel fusing convolution, bias and activation operations. At present, only\r\nper channel bias and RELU activation are supported.\r\n\uf0b7 Inference on 8 bit integer data is now supported, leveraging the 4 element dot\r\nproduct instruction (IDP4A) of Pascal GPUs with CUDA capabilities 6.1. Two tensor\r\nlayouts are supported for this feature: CUDNN_TENSOR_NHWC with INT8 data\r\ntype and CUDNN_TENSOR_NCHW_VECT with INT8x4 data type.\r\n\uf0b7 RNN now supports 3 algorithms\r\no CUDNN_RNN_ALGO_STANDARD :\r\n\uf0a7 Same functionality as in CUDNN v5.1\r\no CUDNN_RNN_ALGO_PERSIST_STATIC :\r\n\uf0a7 This algorithm relies on the usage of persistent CUDA kernels which\r\nare pre-compiled to fit different GPUs.\r\n\uf0a7 This algorithm is available only on Pascal GPUs.\r\no CUDNN_RNN_ALGO_PERSIST_DYNAMIC :\r\nThis algorithm also relies on the usage of persistent CUDA kernels\r\nbut these kernels are compiled at runtime using nvrtc. In some cases\r\nthis results in a significant performance benefit.\r\n\uf0a7 This algorithm is also available only on Pascal GPUs and is supported\r\nonly on Linux and Windows.\r\n\uf0b7 Support for 1D-FFT convolutions has been added\r\n\uf0b7 New API routine cudnnReduceTensor has been added, supporting 8 reduction\r\noperations\r\n\uf0b7 Activation mode CUDNN_ACTIVATION_ELU is now supported.\r\n\uf0b7 A deterministic max pooling mode CUDNN_POOLING_MAX_DETERMINISTIC\r\nhas been added.\r\n\uf0b7 Significant performance improvement for softmax layers for mode\r\nCUDNN_SOFTMAX_MODE_CHANNEL has been achieved when low batch\r\nnumber is used.\r\n\uf0b7 Significant performance improvements have been added for cudnnAddTensor\r\nwhen spatial dimensions are set to 1."}