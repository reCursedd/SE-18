{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5642", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5642/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5642/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5642/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5642", "id": 189708673, "node_id": "MDU6SXNzdWUxODk3MDg2NzM=", "number": 5642, "title": "Tensorflow built from sources in Docker doesn't recognize GPUs", "user": {"login": "Hediby", "id": 12557936, "node_id": "MDQ6VXNlcjEyNTU3OTM2", "avatar_url": "https://avatars1.githubusercontent.com/u/12557936?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hediby", "html_url": "https://github.com/Hediby", "followers_url": "https://api.github.com/users/Hediby/followers", "following_url": "https://api.github.com/users/Hediby/following{/other_user}", "gists_url": "https://api.github.com/users/Hediby/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hediby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hediby/subscriptions", "organizations_url": "https://api.github.com/users/Hediby/orgs", "repos_url": "https://api.github.com/users/Hediby/repos", "events_url": "https://api.github.com/users/Hediby/events{/privacy}", "received_events_url": "https://api.github.com/users/Hediby/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-11-16T13:47:44Z", "updated_at": "2016-12-08T07:55:07Z", "closed_at": "2016-12-08T07:55:07Z", "author_association": "NONE", "body_html": "<p>I need to build TensorFlow from sources in a Dockerfile (because of our architecture's constraints). Unfortunately, TensorFlow does not recognize the gpus.<br>\nI use a Tesla K80, with Nvidia driver's version 367.55</p>\n<p>Here is the DockerFile related to Tensorflow:</p>\n<pre><code>#####       BAZEL        #####\nRUN apt-get update \\\n&amp;&amp; apt-get install -y software-properties-common curl\nRUN apt-get update\nRUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections\n\nRUN add-apt-repository ppa:webupd8team/java \nRUN apt-get update \nRUN apt-get install -y oracle-java8-installer\n\nRUN echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\nRUN curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | apt-key add - \nRUN apt-get update\nRUN apt-get install --yes --force-yes bazel\nRUN apt-get upgrade -y --force-yes bazel\nRUN apt-get install -y swig\n\n#####       TENSORFLOW        #####\nWORKDIR /Programs\nRUN git clone https://github.com/tensorflow/tensorflow.git\nWORKDIR /Programs/tensorflow\n\nENV PYTHON_BIN_PATH /usr/bin/python3.5\nENV TF_NEED_GCP 0\nENV TF_NEED_HDFS 1\nENV TF_NEED_CUDA 1\nENV TF_NEED_OPENCL 0\nENV TF_CUDNN_VERSION 5\nENV TF_CUDA_VERSION 8.0\nENV TF_CUDA_COMPUTE_CAPABILITIES 3.7\nENV GCC_HOST_COMPILER_PATH /usr/bin/gcc\nENV CUDA_TOOLKIT_PATH /usr/local/cuda\nENV CUDNN_INSTALL_PATH /usr/local/cuda\n\nRUN echo /usr/local/lib/python3.5/dist-packages | ./configure &amp;&amp; \\\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n\nRUN pip3 install /tmp/tensorflow_pkg/*.whl --upgrade\n</code></pre>\n<p>I run the docker like this :</p>\n<pre><code>docker run -it --device /dev/nvidiactl --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 tensorflow bash\n</code></pre>\n<p>When I am in the Docker, I run this little script to see if it sees gpu's work:</p>\n<pre><code>import tensorflow as tf\nif __name__ == \"__main__\":\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n    print(\"Tf version :\",tf.__version__)\n</code></pre>\n<p>What it prints :</p>\n<pre><code>root@fae4ae4d9fee:/home# CUDA_VISIBLE_DEVICES=0 python3 gpu.py \nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: fae4ae4d9fee\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: fae4ae4d9fee\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.55.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.55  Tue Sep 27 10:17:05 PDT 2016\nGCC version:  gcc version 4.9.2 (Debian 4.9.2-10) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.55.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 367.55.0\nTf version : 0.11.0rc2\n</code></pre>\n<p>Note that I obtain the same output when I run this script without the <code>CUDA_VISIBLE_DEVICES=0</code> flag</p>\n<p>output of <code>ls -l /path/to/cuda/lib/libcud*</code></p>\n<pre><code>root@fae4ae4d9fee:/home# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root    558720 Nov 15 11:29 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rwxr-xr-x 1 root root    415432 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root    775162 Nov 15 11:29 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 users       13 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5\nlrwxrwxrwx 1 1000 users       17 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.5\n-rwxrwxr-x 1 1000 users 79337624 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-rw-r-- 1 1000 users 69756172 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn_static.a\n</code></pre>\n<p>The commit hash (<code>git rev-parse HEAD</code>):<br>\n<code>de6bbda2353b50944bd06d5b04c86f8c0a62792a</code></p>\n<p>The output of <code>bazel version</code>:</p>\n<pre><code>root@fae4ae4d9fee:/Programs/tensorflow# bazel version\n.\nBuild label: 0.4.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Nov 2 17:54:14 2016 (1478109254)\nBuild timestamp: 1478109254\nBuild timestamp as int: 1478109254\n</code></pre>\n<p>Note that the nvidia drivers in the Docker are very aware of the GPU's:</p>\n<pre><code>root@fae4ae4d9fee:~# nvidia-smi\nWed Nov 16 13:33:16 2016       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.55                 Driver Version: 367.55                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:83:00.0     Off |                    0 |\n| N/A   36C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |\n| N/A   27C    P0    74W / 149W |      0MiB / 11439MiB |     98%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>I am not very familiar with Docker, so maybe am I doing something wrong in the Dockerfile. Thank's to anyone who could help me with this !</p>", "body_text": "I need to build TensorFlow from sources in a Dockerfile (because of our architecture's constraints). Unfortunately, TensorFlow does not recognize the gpus.\nI use a Tesla K80, with Nvidia driver's version 367.55\nHere is the DockerFile related to Tensorflow:\n#####       BAZEL        #####\nRUN apt-get update \\\n&& apt-get install -y software-properties-common curl\nRUN apt-get update\nRUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections\n\nRUN add-apt-repository ppa:webupd8team/java \nRUN apt-get update \nRUN apt-get install -y oracle-java8-installer\n\nRUN echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\nRUN curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | apt-key add - \nRUN apt-get update\nRUN apt-get install --yes --force-yes bazel\nRUN apt-get upgrade -y --force-yes bazel\nRUN apt-get install -y swig\n\n#####       TENSORFLOW        #####\nWORKDIR /Programs\nRUN git clone https://github.com/tensorflow/tensorflow.git\nWORKDIR /Programs/tensorflow\n\nENV PYTHON_BIN_PATH /usr/bin/python3.5\nENV TF_NEED_GCP 0\nENV TF_NEED_HDFS 1\nENV TF_NEED_CUDA 1\nENV TF_NEED_OPENCL 0\nENV TF_CUDNN_VERSION 5\nENV TF_CUDA_VERSION 8.0\nENV TF_CUDA_COMPUTE_CAPABILITIES 3.7\nENV GCC_HOST_COMPILER_PATH /usr/bin/gcc\nENV CUDA_TOOLKIT_PATH /usr/local/cuda\nENV CUDNN_INSTALL_PATH /usr/local/cuda\n\nRUN echo /usr/local/lib/python3.5/dist-packages | ./configure && \\\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n\nRUN pip3 install /tmp/tensorflow_pkg/*.whl --upgrade\n\nI run the docker like this :\ndocker run -it --device /dev/nvidiactl --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 tensorflow bash\n\nWhen I am in the Docker, I run this little script to see if it sees gpu's work:\nimport tensorflow as tf\nif __name__ == \"__main__\":\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n    print(\"Tf version :\",tf.__version__)\n\nWhat it prints :\nroot@fae4ae4d9fee:/home# CUDA_VISIBLE_DEVICES=0 python3 gpu.py \nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: fae4ae4d9fee\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: fae4ae4d9fee\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.55.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.55  Tue Sep 27 10:17:05 PDT 2016\nGCC version:  gcc version 4.9.2 (Debian 4.9.2-10) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.55.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 367.55.0\nTf version : 0.11.0rc2\n\nNote that I obtain the same output when I run this script without the CUDA_VISIBLE_DEVICES=0 flag\noutput of ls -l /path/to/cuda/lib/libcud*\nroot@fae4ae4d9fee:/home# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root    558720 Nov 15 11:29 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root    415432 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root    775162 Nov 15 11:29 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 users       13 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 1000 users       17 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxrwxr-x 1 1000 users 79337624 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-rw-r-- 1 1000 users 69756172 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn_static.a\n\nThe commit hash (git rev-parse HEAD):\nde6bbda2353b50944bd06d5b04c86f8c0a62792a\nThe output of bazel version:\nroot@fae4ae4d9fee:/Programs/tensorflow# bazel version\n.\nBuild label: 0.4.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Nov 2 17:54:14 2016 (1478109254)\nBuild timestamp: 1478109254\nBuild timestamp as int: 1478109254\n\nNote that the nvidia drivers in the Docker are very aware of the GPU's:\nroot@fae4ae4d9fee:~# nvidia-smi\nWed Nov 16 13:33:16 2016       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.55                 Driver Version: 367.55                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:83:00.0     Off |                    0 |\n| N/A   36C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |\n| N/A   27C    P0    74W / 149W |      0MiB / 11439MiB |     98%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\nI am not very familiar with Docker, so maybe am I doing something wrong in the Dockerfile. Thank's to anyone who could help me with this !", "body": "I need to build TensorFlow from sources in a Dockerfile (because of our architecture's constraints). Unfortunately, TensorFlow does not recognize the gpus.\r\nI use a Tesla K80, with Nvidia driver's version 367.55\r\n\r\nHere is the DockerFile related to Tensorflow:\r\n```\r\n#####       BAZEL        #####\r\nRUN apt-get update \\\r\n&& apt-get install -y software-properties-common curl\r\nRUN apt-get update\r\nRUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections\r\n\r\nRUN add-apt-repository ppa:webupd8team/java \r\nRUN apt-get update \r\nRUN apt-get install -y oracle-java8-installer\r\n\r\nRUN echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\r\nRUN curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | apt-key add - \r\nRUN apt-get update\r\nRUN apt-get install --yes --force-yes bazel\r\nRUN apt-get upgrade -y --force-yes bazel\r\nRUN apt-get install -y swig\r\n\r\n#####       TENSORFLOW        #####\r\nWORKDIR /Programs\r\nRUN git clone https://github.com/tensorflow/tensorflow.git\r\nWORKDIR /Programs/tensorflow\r\n\r\nENV PYTHON_BIN_PATH /usr/bin/python3.5\r\nENV TF_NEED_GCP 0\r\nENV TF_NEED_HDFS 1\r\nENV TF_NEED_CUDA 1\r\nENV TF_NEED_OPENCL 0\r\nENV TF_CUDNN_VERSION 5\r\nENV TF_CUDA_VERSION 8.0\r\nENV TF_CUDA_COMPUTE_CAPABILITIES 3.7\r\nENV GCC_HOST_COMPILER_PATH /usr/bin/gcc\r\nENV CUDA_TOOLKIT_PATH /usr/local/cuda\r\nENV CUDNN_INSTALL_PATH /usr/local/cuda\r\n\r\nRUN echo /usr/local/lib/python3.5/dist-packages | ./configure && \\\r\n    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package\r\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\nRUN pip3 install /tmp/tensorflow_pkg/*.whl --upgrade\r\n```\r\nI run the docker like this : \r\n```\r\ndocker run -it --device /dev/nvidiactl --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 tensorflow bash\r\n```\r\nWhen I am in the Docker, I run this little script to see if it sees gpu's work:\r\n```\r\nimport tensorflow as tf\r\nif __name__ == \"__main__\":\r\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\r\n    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\r\n    print(\"Tf version :\",tf.__version__)\r\n```\r\nWhat it prints : \r\n```\r\nroot@fae4ae4d9fee:/home# CUDA_VISIBLE_DEVICES=0 python3 gpu.py \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: fae4ae4d9fee\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: fae4ae4d9fee\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.55.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.55  Tue Sep 27 10:17:05 PDT 2016\r\nGCC version:  gcc version 4.9.2 (Debian 4.9.2-10) \r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.55.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 367.55.0\r\nTf version : 0.11.0rc2\r\n```\r\nNote that I obtain the same output when I run this script without the `CUDA_VISIBLE_DEVICES=0` flag\r\n\r\noutput of `ls -l /path/to/cuda/lib/libcud*`\r\n```\r\nroot@fae4ae4d9fee:/home# ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root    558720 Nov 15 11:29 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root        16 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root        19 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root    415432 Nov 15 11:29 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    775162 Nov 15 11:29 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 1000 users       13 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 1000 users       17 Jul 27 05:55 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxrwxr-x 1 1000 users 79337624 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-rw-r-- 1 1000 users 69756172 Jul 27 05:53 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\nThe commit hash (`git rev-parse HEAD`):\r\n`de6bbda2353b50944bd06d5b04c86f8c0a62792a`\r\n\r\nThe output of `bazel version`:\r\n```\r\nroot@fae4ae4d9fee:/Programs/tensorflow# bazel version\r\n.\r\nBuild label: 0.4.0\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Nov 2 17:54:14 2016 (1478109254)\r\nBuild timestamp: 1478109254\r\nBuild timestamp as int: 1478109254\r\n```\r\nNote that the nvidia drivers in the Docker are very aware of the GPU's:\r\n```\r\nroot@fae4ae4d9fee:~# nvidia-smi\r\nWed Nov 16 13:33:16 2016       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.55                 Driver Version: 367.55                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 0000:83:00.0     Off |                    0 |\r\n| N/A   36C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |\r\n| N/A   27C    P0    74W / 149W |      0MiB / 11439MiB |     98%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nI am not very familiar with Docker, so maybe am I doing something wrong in the Dockerfile. Thank's to anyone who could help me with this !"}