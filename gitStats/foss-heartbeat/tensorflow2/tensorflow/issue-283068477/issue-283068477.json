{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15464", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15464/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15464/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15464/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15464", "id": 283068477, "node_id": "MDU6SXNzdWUyODMwNjg0Nzc=", "number": 15464, "title": "[Feature Request] Sparse compute_gradient", "user": {"login": "OscarDPan", "id": 10855426, "node_id": "MDQ6VXNlcjEwODU1NDI2", "avatar_url": "https://avatars0.githubusercontent.com/u/10855426?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OscarDPan", "html_url": "https://github.com/OscarDPan", "followers_url": "https://api.github.com/users/OscarDPan/followers", "following_url": "https://api.github.com/users/OscarDPan/following{/other_user}", "gists_url": "https://api.github.com/users/OscarDPan/gists{/gist_id}", "starred_url": "https://api.github.com/users/OscarDPan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OscarDPan/subscriptions", "organizations_url": "https://api.github.com/users/OscarDPan/orgs", "repos_url": "https://api.github.com/users/OscarDPan/repos", "events_url": "https://api.github.com/users/OscarDPan/events{/privacy}", "received_events_url": "https://api.github.com/users/OscarDPan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-12-19T00:42:07Z", "updated_at": "2018-06-26T08:10:12Z", "closed_at": "2018-01-31T08:10:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.</p>\n<p><strong>Have I written custom code</strong><br>\nVersion I.<br>\nMy feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()<br>\nMy graph is like this:</p>\n<pre><code>cost = fn(w)\nvars_to_update = tf.gather(w, non_zero_indices)\ngrads = tf.gradients(cost, vars_to_update)\nupdate_op = tf.scatter_sub(w, non_zero_indeces, grads)\n</code></pre>\n<p>I found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather().</p>\n<p>I was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?</p>\n<p>Version II.<br>\nIn stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was <strong>horribly slower (15seconds)</strong> than the sparse tensor approach. And idea why?</p>\n<p>Pseudo code:</p>\n<pre><code>active_weights = tf.gather(weights, non_zero_indices)\ntotal = tf.segment_sum(\n                tf.reshape(activated_weights, [-1]),\n                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]\n                )\nupdate_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)\n</code></pre>\n<p><strong>OS Platform and Distribution</strong><br>\nCentos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )</p>\n<p><strong>TensorFlow installed from (source or binary)</strong><br>\npip install tensorflow</p>\n<p><strong>TF version</strong><br>\n1.3.0</p>\n<p><strong>Python version</strong><br>\n2.7.5</p>\n<p><strong>Bazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce</strong><br>\nN/A</p>\n<p><strong>Also there might be a potential bug</strong><br>\nIf in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket.</p>", "body_text": "I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.\nHave I written custom code\nVersion I.\nMy feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()\nMy graph is like this:\ncost = fn(w)\nvars_to_update = tf.gather(w, non_zero_indices)\ngrads = tf.gradients(cost, vars_to_update)\nupdate_op = tf.scatter_sub(w, non_zero_indeces, grads)\n\nI found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather().\nI was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?\nVersion II.\nIn stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was horribly slower (15seconds) than the sparse tensor approach. And idea why?\nPseudo code:\nactive_weights = tf.gather(weights, non_zero_indices)\ntotal = tf.segment_sum(\n                tf.reshape(activated_weights, [-1]),\n                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]\n                )\nupdate_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)\n\nOS Platform and Distribution\nCentos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )\nTensorFlow installed from (source or binary)\npip install tensorflow\nTF version\n1.3.0\nPython version\n2.7.5\nBazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce\nN/A\nAlso there might be a potential bug\nIf in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket.", "body": "I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.\r\n\r\n**Have I written custom code**\r\nVersion I.\r\nMy feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()\r\nMy graph is like this:\r\n```\r\ncost = fn(w)\r\nvars_to_update = tf.gather(w, non_zero_indices)\r\ngrads = tf.gradients(cost, vars_to_update)\r\nupdate_op = tf.scatter_sub(w, non_zero_indeces, grads)\r\n```\r\nI found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather(). \r\n\r\nI was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?\r\n\r\nVersion II.\r\nIn stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was **horribly slower (15seconds)** than the sparse tensor approach. And idea why?\r\n\r\nPseudo code:\r\n```\r\nactive_weights = tf.gather(weights, non_zero_indices)\r\ntotal = tf.segment_sum(\r\n                tf.reshape(activated_weights, [-1]),\r\n                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]\r\n                )\r\nupdate_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)\r\n```\r\n\r\n**OS Platform and Distribution**\r\nCentos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )\r\n\r\n**TensorFlow installed from (source or binary)**\r\npip install tensorflow\r\n\r\n**TF version**\r\n1.3.0\r\n\r\n**Python version**\r\n2.7.5\r\n\r\n**Bazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce**\r\nN/A\r\n\r\n**Also there might be a potential bug**\r\nIf in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket."}