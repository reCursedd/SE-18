{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397824708", "html_url": "https://github.com/tensorflow/tensorflow/issues/20067#issuecomment-397824708", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20067", "id": 397824708, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzgyNDcwOA==", "user": {"login": "hadaev8", "id": 20247085, "node_id": "MDQ6VXNlcjIwMjQ3MDg1", "avatar_url": "https://avatars2.githubusercontent.com/u/20247085?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hadaev8", "html_url": "https://github.com/hadaev8", "followers_url": "https://api.github.com/users/hadaev8/followers", "following_url": "https://api.github.com/users/hadaev8/following{/other_user}", "gists_url": "https://api.github.com/users/hadaev8/gists{/gist_id}", "starred_url": "https://api.github.com/users/hadaev8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hadaev8/subscriptions", "organizations_url": "https://api.github.com/users/hadaev8/orgs", "repos_url": "https://api.github.com/users/hadaev8/repos", "events_url": "https://api.github.com/users/hadaev8/events{/privacy}", "received_events_url": "https://api.github.com/users/hadaev8/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-16T16:45:28Z", "updated_at": "2018-06-16T16:46:16Z", "author_association": "NONE", "body_html": "<p>Windows 10<br>\ntensorflow tf-nightly-gpu<br>\ncuda 9 cudnn 7<br>\nnvidia gtx 760</p>\n<p>import pandas as pd<br>\nimport numpy as np<br>\nimport os<br>\nfrom time import *<br>\nimport matplotlib.pyplot as plt<br>\n%matplotlib inline</p>\n<p>from keras.models import Model<br>\nfrom keras.layers import Input, Dense, Reshape, Dropout, SimpleRNN, CuDNNGRU, CuDNNLSTM, LeakyReLU<br>\nfrom keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau</p>\n<p>from sklearn.preprocessing import MinMaxScaler<br>\nfrom sklearn.utils import shuffle</p>\n<p>work_dir = r'E:\\neuro_projects\\morda'</p>\n<p>data = pd.read_csv(os.path.join(work_dir, 'train.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])<br>\ndata = shuffle(data)<br>\nscaler = MinMaxScaler()<br>\ndata = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)<br>\nx = data[data.columns[:-1]]<br>\ny = data['100']<br>\nx_train = x[:8000]<br>\nx_test = x[8000:]<br>\ny_train = y[:8000]<br>\ny_test = y[8000:]</p>\n<p>lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9,<br>\ncooldown=1,<br>\npatience=10,<br>\nverbose=1,<br>\nmin_lr=1e-8)<br>\nnan = TerminateOnNaN()<br>\nstop = EarlyStopping(monitor='val_loss', min_delta=0, patience=200, verbose=1, mode='auto')<br>\ncallbacks = [lr_reducer, nan, stop]<br>\n#test = pd.read_csv(os.path.join(work_dir, 'test.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])<br>\n#x_test = test[test.columns[:-1]]<br>\n#y_test = test['100']</p>\n<p>def test_model():<br>\ny_pred = model.predict(x_test)<br>\ny_pred = y_pred/scaler.scale_[-1]<br>\nfrom sklearn.metrics import mean_absolute_error<br>\nprint(mean_absolute_error(data['100'][8000:], y_pred))</p>\n<p>inp = Input(shape=(x_test.shape[1],))<br>\ni = inp<br>\ni = Reshape((1, x_test.shape[1]))(i)</p>\n<p>i = CuDNNGRU(256)(i)<br>\ni = LeakyReLU()(i)<br>\n#i = Dropout(0.3)(i)</p>\n<p>i = Dense(1)(i)</p>\n<p>model = Model(inp, i)</p>\n<p>model.compile(loss='mae', optimizer='adam')<br>\n#model.summary()<br>\ntimer = time()<br>\nhistory = model.fit(x_train, y_train,<br>\nepochs=10000,<br>\nbatch_size=64,<br>\nverbose=2,<br>\nvalidation_data=(x_test, y_test),<br>\ncallbacks=callbacks<br>\n)<br>\nplt.plot(history.history['loss'][10:])<br>\nplt.plot(history.history['val_loss'][10:])<br>\nplt.title('model loss')<br>\nplt.ylabel('loss')<br>\nplt.xlabel('epoch')<br>\nplt.legend(['train', 'test'], loc='upper left')<br>\nplt.show()<br>\nprint(history.history['loss'][-1], history.history['val_loss'][-1])<br>\nprint((time()-timer)/60)<br>\ntest_model()</p>", "body_text": "Windows 10\ntensorflow tf-nightly-gpu\ncuda 9 cudnn 7\nnvidia gtx 760\nimport pandas as pd\nimport numpy as np\nimport os\nfrom time import *\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Reshape, Dropout, SimpleRNN, CuDNNGRU, CuDNNLSTM, LeakyReLU\nfrom keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.utils import shuffle\nwork_dir = r'E:\\neuro_projects\\morda'\ndata = pd.read_csv(os.path.join(work_dir, 'train.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])\ndata = shuffle(data)\nscaler = MinMaxScaler()\ndata = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\nx = data[data.columns[:-1]]\ny = data['100']\nx_train = x[:8000]\nx_test = x[8000:]\ny_train = y[:8000]\ny_test = y[8000:]\nlr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\ncooldown=1,\npatience=10,\nverbose=1,\nmin_lr=1e-8)\nnan = TerminateOnNaN()\nstop = EarlyStopping(monitor='val_loss', min_delta=0, patience=200, verbose=1, mode='auto')\ncallbacks = [lr_reducer, nan, stop]\n#test = pd.read_csv(os.path.join(work_dir, 'test.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])\n#x_test = test[test.columns[:-1]]\n#y_test = test['100']\ndef test_model():\ny_pred = model.predict(x_test)\ny_pred = y_pred/scaler.scale_[-1]\nfrom sklearn.metrics import mean_absolute_error\nprint(mean_absolute_error(data['100'][8000:], y_pred))\ninp = Input(shape=(x_test.shape[1],))\ni = inp\ni = Reshape((1, x_test.shape[1]))(i)\ni = CuDNNGRU(256)(i)\ni = LeakyReLU()(i)\n#i = Dropout(0.3)(i)\ni = Dense(1)(i)\nmodel = Model(inp, i)\nmodel.compile(loss='mae', optimizer='adam')\n#model.summary()\ntimer = time()\nhistory = model.fit(x_train, y_train,\nepochs=10000,\nbatch_size=64,\nverbose=2,\nvalidation_data=(x_test, y_test),\ncallbacks=callbacks\n)\nplt.plot(history.history['loss'][10:])\nplt.plot(history.history['val_loss'][10:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nprint(history.history['loss'][-1], history.history['val_loss'][-1])\nprint((time()-timer)/60)\ntest_model()", "body": "Windows 10\r\ntensorflow tf-nightly-gpu\r\ncuda 9 cudnn 7\r\nnvidia gtx 760\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nimport os\r\nfrom time import *\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\nfrom keras.models import Model\r\nfrom keras.layers import Input, Dense, Reshape, Dropout, SimpleRNN, CuDNNGRU, CuDNNLSTM, LeakyReLU\r\nfrom keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau\r\n\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom sklearn.utils import shuffle\r\n\r\nwork_dir = r'E:\\neuro_projects\\morda'\r\n\r\ndata = pd.read_csv(os.path.join(work_dir, 'train.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])\r\ndata = shuffle(data)\r\nscaler = MinMaxScaler()\r\ndata = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\r\nx = data[data.columns[:-1]]\r\ny = data['100']\r\nx_train = x[:8000]\r\nx_test = x[8000:]\r\ny_train = y[:8000]\r\ny_test = y[8000:]\r\n\r\nlr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\r\n                               cooldown=1,\r\n                               patience=10,\r\n                               verbose=1,\r\n                               min_lr=1e-8)\r\nnan = TerminateOnNaN()\r\nstop = EarlyStopping(monitor='val_loss', min_delta=0, patience=200, verbose=1, mode='auto')\r\ncallbacks = [lr_reducer, nan, stop]\r\n#test = pd.read_csv(os.path.join(work_dir, 'test.tsv'), delim_whitespace=True, names=[str(i) for i in range(101)])\r\n#x_test = test[test.columns[:-1]]\r\n#y_test = test['100']\r\n\r\ndef test_model():\r\n    y_pred = model.predict(x_test)\r\n    y_pred = y_pred/scaler.scale_[-1]\r\n    from sklearn.metrics import mean_absolute_error\r\n    print(mean_absolute_error(data['100'][8000:], y_pred))\r\n    \r\n\r\ninp = Input(shape=(x_test.shape[1],))\r\ni = inp\r\ni = Reshape((1, x_test.shape[1]))(i)\r\n\r\ni = CuDNNGRU(256)(i)\r\ni = LeakyReLU()(i)\r\n#i = Dropout(0.3)(i)\r\n\r\ni = Dense(1)(i)\r\n\r\nmodel = Model(inp, i)\r\n\r\nmodel.compile(loss='mae', optimizer='adam')\r\n#model.summary()\r\ntimer = time()\r\nhistory = model.fit(x_train, y_train,\r\n                      epochs=10000,\r\n                      batch_size=64,\r\n                      verbose=2,\r\n                      validation_data=(x_test, y_test),\r\n                      callbacks=callbacks\r\n                   )\r\nplt.plot(history.history['loss'][10:])\r\nplt.plot(history.history['val_loss'][10:])\r\nplt.title('model loss')\r\nplt.ylabel('loss')\r\nplt.xlabel('epoch')\r\nplt.legend(['train', 'test'], loc='upper left')\r\nplt.show()\r\nprint(history.history['loss'][-1], history.history['val_loss'][-1])\r\nprint((time()-timer)/60)\r\ntest_model()"}