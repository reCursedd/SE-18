{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/275500463", "html_url": "https://github.com/tensorflow/tensorflow/issues/7091#issuecomment-275500463", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7091", "id": 275500463, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTUwMDQ2Mw==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-26T20:14:24Z", "updated_at": "2017-01-26T20:14:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>tf.nn.batch_normalization</code> is more low-level. Unlike the <code>layers</code> version it doesn't handle estimation of population statistics as decaying moving averages during training; it doesn't make a distinction between test time and train time statistics on its own; it requires you to manually introduce trainable variables for beta and gamma, and so on. It's rather tricky to setup, in fact, as it's basically just the mathematical operation and nothing more.</p>", "body_text": "tf.nn.batch_normalization is more low-level. Unlike the layers version it doesn't handle estimation of population statistics as decaying moving averages during training; it doesn't make a distinction between test time and train time statistics on its own; it requires you to manually introduce trainable variables for beta and gamma, and so on. It's rather tricky to setup, in fact, as it's basically just the mathematical operation and nothing more.", "body": "`tf.nn.batch_normalization` is more low-level. Unlike the `layers` version it doesn't handle estimation of population statistics as decaying moving averages during training; it doesn't make a distinction between test time and train time statistics on its own; it requires you to manually introduce trainable variables for beta and gamma, and so on. It's rather tricky to setup, in fact, as it's basically just the mathematical operation and nothing more."}