{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16277", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16277/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16277/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16277/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16277", "id": 290362102, "node_id": "MDU6SXNzdWUyOTAzNjIxMDI=", "number": 16277, "title": "Control dependency does not ensure write observed by read", "user": {"login": "gaohuazuo", "id": 10446514, "node_id": "MDQ6VXNlcjEwNDQ2NTE0", "avatar_url": "https://avatars0.githubusercontent.com/u/10446514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaohuazuo", "html_url": "https://github.com/gaohuazuo", "followers_url": "https://api.github.com/users/gaohuazuo/followers", "following_url": "https://api.github.com/users/gaohuazuo/following{/other_user}", "gists_url": "https://api.github.com/users/gaohuazuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaohuazuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaohuazuo/subscriptions", "organizations_url": "https://api.github.com/users/gaohuazuo/orgs", "repos_url": "https://api.github.com/users/gaohuazuo/repos", "events_url": "https://api.github.com/users/gaohuazuo/events{/privacy}", "received_events_url": "https://api.github.com/users/gaohuazuo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-22T06:22:40Z", "updated_at": "2018-01-26T21:40:10Z", "closed_at": "2018-01-26T21:40:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p>TF version 1.3.0</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">sleep</span>(<span class=\"pl-smi\">t</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">'''</span>TF sleep<span class=\"pl-pds\">'''</span></span>\n    <span class=\"pl-k\">import</span> time\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">t</span>):\n        time.sleep(t)\n        <span class=\"pl-k\">return</span> np.array([], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n    <span class=\"pl-k\">return</span> tf.py_func(f, [t], [tf.float32])[<span class=\"pl-c1\">0</span>]\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>gpu<span class=\"pl-pds\">'</span></span>):\n    x <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>.)\n<span class=\"pl-k\">with</span> tf.control_dependencies([tf.identity(sleep(<span class=\"pl-c1\">0.1</span>))]):\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>gpu<span class=\"pl-pds\">'</span></span>):\n        mod <span class=\"pl-k\">=</span> tf.assign(x, <span class=\"pl-c1\">100</span>.)\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cpu<span class=\"pl-pds\">'</span></span>):\n    a <span class=\"pl-k\">=</span> x<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>.\n    <span class=\"pl-k\">with</span> tf.control_dependencies([tf.identity(mod)]):\n        b <span class=\"pl-k\">=</span> x<span class=\"pl-k\">+</span><span class=\"pl-c1\">2</span>.\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>gpu<span class=\"pl-pds\">'</span></span>):\n            c <span class=\"pl-k\">=</span> x<span class=\"pl-k\">+</span><span class=\"pl-c1\">3</span>.\n\nx.initializer.run()\nsess.run([a, b, c])\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> [1.0, 2.0, 103.0]</span></pre></div>\n<p>When a variable is read on another device, TF seems to copy once regardless of dependencies. I understand this is how TF works, but I think it would be nice to have dependencies ensure memory access order.</p>", "body_text": "TF version 1.3.0\ndef sleep(t):\n    '''TF sleep'''\n    import time\n    def f(t):\n        time.sleep(t)\n        return np.array([], dtype=np.float32)\n    return tf.py_func(f, [t], [tf.float32])[0]\n\nwith tf.device('gpu'):\n    x = tf.Variable(0.)\nwith tf.control_dependencies([tf.identity(sleep(0.1))]):\n    with tf.device('gpu'):\n        mod = tf.assign(x, 100.)\nwith tf.device('cpu'):\n    a = x+1.\n    with tf.control_dependencies([tf.identity(mod)]):\n        b = x+2.\n        with tf.device('gpu'):\n            c = x+3.\n\nx.initializer.run()\nsess.run([a, b, c])\n# [1.0, 2.0, 103.0]\nWhen a variable is read on another device, TF seems to copy once regardless of dependencies. I understand this is how TF works, but I think it would be nice to have dependencies ensure memory access order.", "body": "TF version 1.3.0\r\n\r\n```python\r\ndef sleep(t):\r\n    '''TF sleep'''\r\n    import time\r\n    def f(t):\r\n        time.sleep(t)\r\n        return np.array([], dtype=np.float32)\r\n    return tf.py_func(f, [t], [tf.float32])[0]\r\n\r\nwith tf.device('gpu'):\r\n    x = tf.Variable(0.)\r\nwith tf.control_dependencies([tf.identity(sleep(0.1))]):\r\n    with tf.device('gpu'):\r\n        mod = tf.assign(x, 100.)\r\nwith tf.device('cpu'):\r\n    a = x+1.\r\n    with tf.control_dependencies([tf.identity(mod)]):\r\n        b = x+2.\r\n        with tf.device('gpu'):\r\n            c = x+3.\r\n\r\nx.initializer.run()\r\nsess.run([a, b, c])\r\n# [1.0, 2.0, 103.0]\r\n```\r\n\r\nWhen a variable is read on another device, TF seems to copy once regardless of dependencies. I understand this is how TF works, but I think it would be nice to have dependencies ensure memory access order."}