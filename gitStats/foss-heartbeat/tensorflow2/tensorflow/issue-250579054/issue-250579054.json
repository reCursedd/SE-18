{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12323", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12323/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12323/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12323/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12323", "id": 250579054, "node_id": "MDU6SXNzdWUyNTA1NzkwNTQ=", "number": 12323, "title": "tf.device() is allocating all available GPU memory", "user": {"login": "wangqr", "id": 8182182, "node_id": "MDQ6VXNlcjgxODIxODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8182182?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wangqr", "html_url": "https://github.com/wangqr", "followers_url": "https://api.github.com/users/wangqr/followers", "following_url": "https://api.github.com/users/wangqr/following{/other_user}", "gists_url": "https://api.github.com/users/wangqr/gists{/gist_id}", "starred_url": "https://api.github.com/users/wangqr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wangqr/subscriptions", "organizations_url": "https://api.github.com/users/wangqr/orgs", "repos_url": "https://api.github.com/users/wangqr/repos", "events_url": "https://api.github.com/users/wangqr/events{/privacy}", "received_events_url": "https://api.github.com/users/wangqr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "agarwal-ashish", "id": 19335798, "node_id": "MDQ6VXNlcjE5MzM1Nzk4", "avatar_url": "https://avatars3.githubusercontent.com/u/19335798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agarwal-ashish", "html_url": "https://github.com/agarwal-ashish", "followers_url": "https://api.github.com/users/agarwal-ashish/followers", "following_url": "https://api.github.com/users/agarwal-ashish/following{/other_user}", "gists_url": "https://api.github.com/users/agarwal-ashish/gists{/gist_id}", "starred_url": "https://api.github.com/users/agarwal-ashish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agarwal-ashish/subscriptions", "organizations_url": "https://api.github.com/users/agarwal-ashish/orgs", "repos_url": "https://api.github.com/users/agarwal-ashish/repos", "events_url": "https://api.github.com/users/agarwal-ashish/events{/privacy}", "received_events_url": "https://api.github.com/users/agarwal-ashish/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "agarwal-ashish", "id": 19335798, "node_id": "MDQ6VXNlcjE5MzM1Nzk4", "avatar_url": "https://avatars3.githubusercontent.com/u/19335798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agarwal-ashish", "html_url": "https://github.com/agarwal-ashish", "followers_url": "https://api.github.com/users/agarwal-ashish/followers", "following_url": "https://api.github.com/users/agarwal-ashish/following{/other_user}", "gists_url": "https://api.github.com/users/agarwal-ashish/gists{/gist_id}", "starred_url": "https://api.github.com/users/agarwal-ashish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agarwal-ashish/subscriptions", "organizations_url": "https://api.github.com/users/agarwal-ashish/orgs", "repos_url": "https://api.github.com/users/agarwal-ashish/repos", "events_url": "https://api.github.com/users/agarwal-ashish/events{/privacy}", "received_events_url": "https://api.github.com/users/agarwal-ashish/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-08-16T10:23:26Z", "updated_at": "2018-10-01T03:06:56Z", "closed_at": "2017-12-20T01:32:02Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04.1 LTS</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>: source (git repo)</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>: ('unknown', '1.3.0-rc2')<br>\nusing commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3686ef0d51047d2806df3e2ff6c1aac727456c1d/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3686ef0d51047d2806df3e2ff6c1aac727456c1d\"><tt>3686ef0</tt></a></p>\n</li>\n<li>\n<p><strong>Python version</strong>: Python 2.7.12 (default, Nov 19 2016, 06:48:10)</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.5.1<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Tue Jun 6 10:34:11 2017 (1496745251)<br>\nBuild timestamp: 1496745251<br>\nBuild timestamp as int: 1496745251</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>: CUDA 8.0 / cuDNN 5.0.5</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>: GTX 1080 Ti / 11172MiB</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:</p>\n</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">$</span> python\nPython <span class=\"pl-c1\">2.7</span>.12 (default, Nov <span class=\"pl-c1\">19</span> <span class=\"pl-c1\">2016</span>, <span class=\"pl-c1\">0<span class=\"pl-ii\">6</span></span>:<span class=\"pl-c1\">48</span>:<span class=\"pl-c1\">10</span>)\n[<span class=\"pl-c1\">GCC</span> <span class=\"pl-c1\">5.4</span>.0 <span class=\"pl-c1\">20160609</span>] on linux2\nType <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>help<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>copyright<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>credits<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">or</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>license<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">for</span> more information.\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> tensorflow\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> tensorflow.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">2017</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">16</span> <span class=\"pl-c1\">18</span>:<span class=\"pl-c1\">14</span>:<span class=\"pl-c1\">10.490730</span>: I tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device.cc:<span class=\"pl-c1\">962</span>] Found device <span class=\"pl-c1\">0</span> <span class=\"pl-k\">with</span> properties:\nname: Graphics Device major: <span class=\"pl-c1\">6</span> minor: <span class=\"pl-c1\">1</span> memoryClockRate(GHz): <span class=\"pl-c1\">1.582</span>\npciBusID: <span class=\"pl-c1\">0000</span>:<span class=\"pl-c1\">0<span class=\"pl-ii\">2</span></span>:<span class=\"pl-c1\">00.0</span>\ntotalMemory: <span class=\"pl-c1\">10.</span><span class=\"pl-ii\">91GiB</span> freeMemory: <span class=\"pl-c1\">3.</span><span class=\"pl-ii\">02GiB</span>\n<span class=\"pl-c1\">2017</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">0<span class=\"pl-ii\">8</span></span><span class=\"pl-k\">-</span><span class=\"pl-c1\">16</span> <span class=\"pl-c1\">18</span>:<span class=\"pl-c1\">14</span>:<span class=\"pl-c1\">10.490782</span>: I tensorflow<span class=\"pl-k\">/</span>core<span class=\"pl-k\">/</span>common_runtime<span class=\"pl-k\">/</span>gpu<span class=\"pl-k\">/</span>gpu_device.cc:<span class=\"pl-c1\">1052</span>] Creating TensorFlow device (<span class=\"pl-k\">/</span>device:<span class=\"pl-c1\">GPU</span>:<span class=\"pl-c1\">0</span>) <span class=\"pl-ii\">-&gt;</span> (device: <span class=\"pl-c1\">0</span>, name: Graphics Device, pci bus <span class=\"pl-c1\">id</span>: <span class=\"pl-c1\">0000</span>:<span class=\"pl-c1\">0<span class=\"pl-ii\">2</span></span>:<span class=\"pl-c1\">00.0</span>, compute capability: <span class=\"pl-c1\">6.1</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a\n<span class=\"pl-k\">&lt;</span>contextlib.GeneratorContextManager <span class=\"pl-c1\">object</span> at <span class=\"pl-c1\"><span class=\"pl-k\">0x</span>7fdf6f0e8790</span><span class=\"pl-k\">&gt;</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span></pre></div>\n<p>At this point, tensorflow is allocating all of the available GPU memory. This can be checked using <code>nvidia-smi</code>.<br>\nExpected behavior is nothing is done with GPU.</p>\n<p>I have used tensorflow 1.2.1, which will allocate nothing on GPU until a <code>tf.Session</code> is created. <code>tf.Session</code> also allows setting <code>config.gpu_options.per_process_gpu_memory_fraction</code> to limit the usage of GPU memory.</p>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.1 LTS\n\n\nTensorFlow installed from (source or binary): source (git repo)\n\n\nTensorFlow version (use command below): ('unknown', '1.3.0-rc2')\nusing commit 3686ef0\n\n\nPython version: Python 2.7.12 (default, Nov 19 2016, 06:48:10)\n\n\nBazel version (if compiling from source):\nBuild label: 0.5.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue Jun 6 10:34:11 2017 (1496745251)\nBuild timestamp: 1496745251\nBuild timestamp as int: 1496745251\n\n\nCUDA/cuDNN version: CUDA 8.0 / cuDNN 5.0.5\n\n\nGPU model and memory: GTX 1080 Ti / 11172MiB\n\n\nExact command to reproduce:\n\n\n$ python\nPython 2.7.12 (default, Nov 19 2016, 06:48:10)\n[GCC 5.4.0 20160609] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow\n>>> a = tensorflow.device('/cpu:0')\n2017-08-16 18:14:10.490730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:962] Found device 0 with properties:\nname: Graphics Device major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:02:00.0\ntotalMemory: 10.91GiB freeMemory: 3.02GiB\n2017-08-16 18:14:10.490782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1052] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:02:00.0, compute capability: 6.1)\n>>> a\n<contextlib.GeneratorContextManager object at 0x7fdf6f0e8790>\n>>>\nAt this point, tensorflow is allocating all of the available GPU memory. This can be checked using nvidia-smi.\nExpected behavior is nothing is done with GPU.\nI have used tensorflow 1.2.1, which will allocate nothing on GPU until a tf.Session is created. tf.Session also allows setting config.gpu_options.per_process_gpu_memory_fraction to limit the usage of GPU memory.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.1 LTS\r\n- **TensorFlow installed from (source or binary)**: source (git repo)\r\n- **TensorFlow version (use command below)**: ('unknown', '1.3.0-rc2')\r\nusing commit 3686ef0d51047d2806df3e2ff6c1aac727456c1d\r\n\r\n- **Python version**: Python 2.7.12 (default, Nov 19 2016, 06:48:10)\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.1\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Jun 6 10:34:11 2017 (1496745251)\r\nBuild timestamp: 1496745251\r\nBuild timestamp as int: 1496745251\r\n\r\n- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 5.0.5\r\n- **GPU model and memory**: GTX 1080 Ti / 11172MiB\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\n$ python\r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10)\r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n>>> a = tensorflow.device('/cpu:0')\r\n2017-08-16 18:14:10.490730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:962] Found device 0 with properties:\r\nname: Graphics Device major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.91GiB freeMemory: 3.02GiB\r\n2017-08-16 18:14:10.490782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1052] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n>>> a\r\n<contextlib.GeneratorContextManager object at 0x7fdf6f0e8790>\r\n>>>\r\n```\r\nAt this point, tensorflow is allocating all of the available GPU memory. This can be checked using `nvidia-smi`.\r\nExpected behavior is nothing is done with GPU.\r\n\r\nI have used tensorflow 1.2.1, which will allocate nothing on GPU until a `tf.Session` is created. `tf.Session` also allows setting `config.gpu_options.per_process_gpu_memory_fraction` to limit the usage of GPU memory."}