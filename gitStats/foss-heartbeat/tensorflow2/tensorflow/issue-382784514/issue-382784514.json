{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23887", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23887/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23887/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23887/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23887", "id": 382784514, "node_id": "MDU6SXNzdWUzODI3ODQ1MTQ=", "number": 23887, "title": "Hessian diagonal computation", "user": {"login": "MaxHalford", "id": 8095957, "node_id": "MDQ6VXNlcjgwOTU5NTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/8095957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaxHalford", "html_url": "https://github.com/MaxHalford", "followers_url": "https://api.github.com/users/MaxHalford/followers", "following_url": "https://api.github.com/users/MaxHalford/following{/other_user}", "gists_url": "https://api.github.com/users/MaxHalford/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaxHalford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaxHalford/subscriptions", "organizations_url": "https://api.github.com/users/MaxHalford/orgs", "repos_url": "https://api.github.com/users/MaxHalford/repos", "events_url": "https://api.github.com/users/MaxHalford/events{/privacy}", "received_events_url": "https://api.github.com/users/MaxHalford/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-20T18:00:29Z", "updated_at": "2018-11-20T18:00:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): v1.10.0-0-g656e7a2b34 1.10.0</li>\n<li>Python version: 3.6</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU model and memory:</li>\n</ul>\n<p>You can collect some of this information using our environment capture <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">script</a><br>\nYou can also obtain the TensorFlow version with<br>\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<p><strong>Describe the current behavior</strong></p>\n<p>I'm computing the full Hessian before extracting the diagonal.</p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>I want to only compute the diagonal to avoid the overhead of computing the full Hessian.</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ny_true <span class=\"pl-k\">=</span> np.array([\n    [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>]\n], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">float</span>)\n\ny_pred <span class=\"pl-k\">=</span> np.array([\n    [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n    [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>]\n], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">float</span>)\n\nweights <span class=\"pl-k\">=</span> np.array([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">float</span>)\n\n<span class=\"pl-k\">with</span> tf.Session():\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> We first convert the numpy arrays to Tensorflow tensors</span>\n    y_true <span class=\"pl-k\">=</span> tf.convert_to_tensor(y_true)\n    y_pred <span class=\"pl-k\">=</span> tf.convert_to_tensor(y_pred)\n    weights <span class=\"pl-k\">=</span> tf.convert_to_tensor(weights)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> The following code block is a custom loss </span>\n    ys <span class=\"pl-k\">=</span> tf.reduce_sum(y_true, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    y_true <span class=\"pl-k\">=</span> y_true <span class=\"pl-k\">/</span> ys\n    ln_p <span class=\"pl-k\">=</span> tf.nn.log_softmax(y_pred)\n    wll <span class=\"pl-k\">=</span> tf.reduce_sum(y_true <span class=\"pl-k\">*</span> ln_p, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    loss <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span>tf.tensordot(weights, wll, <span class=\"pl-v\">axes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    grad <span class=\"pl-k\">=</span> tf.gradients(loss, y_pred)[<span class=\"pl-c1\">0</span>]\n\n    hess <span class=\"pl-k\">=</span> tf.hessians(loss, y_pred)[<span class=\"pl-c1\">0</span>]\n    hess <span class=\"pl-k\">=</span> tf.diag_part(hess)\n\n    <span class=\"pl-c1\">print</span>(hess.eval())</pre></div>\n<p>This outputs:</p>\n<div class=\"highlight highlight-source-python\"><pre>[[<span class=\"pl-c1\">0.24090069</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span>]\n [<span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.24090069</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span>]\n [<span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.24090069</span> <span class=\"pl-c1\">0.12669198</span>]\n [<span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.24090069</span> <span class=\"pl-c1\">0.12669198</span> <span class=\"pl-c1\">0.12669198</span>]\n [<span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.08030023</span>]\n [<span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.08030023</span>]\n [<span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.04223066</span> <span class=\"pl-c1\">0.08030023</span>]]</pre></div>\n<p>which is exactly what I want. The problem is that the full Hessian is computed before actually <code>tf.diag_part</code>.</p>\n<p><strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): v1.10.0-0-g656e7a2b34 1.10.0\nPython version: 3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\n\nYou can collect some of this information using our environment capture script\nYou can also obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the current behavior\nI'm computing the full Hessian before extracting the diagonal.\nDescribe the expected behavior\nI want to only compute the diagonal to avoid the overhead of computing the full Hessian.\nCode to reproduce the issue\nimport numpy as np\nimport tensorflow as tf\n\ny_true = np.array([\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 1, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1]\n], dtype=float)\n\ny_pred = np.array([\n    [1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0],\n    [0, 0, 0, 1, 0],\n    [0, 0, 1, 0, 0],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1],\n    [0, 0, 0, 0, 1]\n], dtype=float)\n\nweights = np.array([1, 1, 1, 1, 1], dtype=float)\n\nwith tf.Session():\n\n    # We first convert the numpy arrays to Tensorflow tensors\n    y_true = tf.convert_to_tensor(y_true)\n    y_pred = tf.convert_to_tensor(y_pred)\n    weights = tf.convert_to_tensor(weights)\n\n    # The following code block is a custom loss \n    ys = tf.reduce_sum(y_true, axis=0)\n    y_true = y_true / ys\n    ln_p = tf.nn.log_softmax(y_pred)\n    wll = tf.reduce_sum(y_true * ln_p, axis=0)\n    loss = -tf.tensordot(weights, wll, axes=1)\n\n    grad = tf.gradients(loss, y_pred)[0]\n\n    hess = tf.hessians(loss, y_pred)[0]\n    hess = tf.diag_part(hess)\n\n    print(hess.eval())\nThis outputs:\n[[0.24090069 0.12669198 0.12669198 0.12669198 0.12669198]\n [0.12669198 0.24090069 0.12669198 0.12669198 0.12669198]\n [0.12669198 0.12669198 0.12669198 0.24090069 0.12669198]\n [0.12669198 0.12669198 0.24090069 0.12669198 0.12669198]\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]]\nwhich is exactly what I want. The problem is that the full Hessian is computed before actually tf.diag_part.\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.10.0-0-g656e7a2b34 1.10.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nI'm computing the full Hessian before extracting the diagonal.\r\n\r\n**Describe the expected behavior**\r\n\r\nI want to only compute the diagonal to avoid the overhead of computing the full Hessian.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ny_true = np.array([\r\n    [1, 0, 0, 0, 0],\r\n    [0, 1, 0, 0, 0],\r\n    [0, 0, 0, 1, 0],\r\n    [0, 0, 1, 0, 0],\r\n    [0, 0, 0, 0, 1],\r\n    [0, 0, 0, 0, 1],\r\n    [0, 0, 0, 0, 1]\r\n], dtype=float)\r\n\r\ny_pred = np.array([\r\n    [1, 0, 0, 0, 0],\r\n    [0, 1, 0, 0, 0],\r\n    [0, 0, 0, 1, 0],\r\n    [0, 0, 1, 0, 0],\r\n    [0, 0, 0, 0, 1],\r\n    [0, 0, 0, 0, 1],\r\n    [0, 0, 0, 0, 1]\r\n], dtype=float)\r\n\r\nweights = np.array([1, 1, 1, 1, 1], dtype=float)\r\n\r\nwith tf.Session():\r\n\r\n    # We first convert the numpy arrays to Tensorflow tensors\r\n    y_true = tf.convert_to_tensor(y_true)\r\n    y_pred = tf.convert_to_tensor(y_pred)\r\n    weights = tf.convert_to_tensor(weights)\r\n\r\n    # The following code block is a custom loss \r\n    ys = tf.reduce_sum(y_true, axis=0)\r\n    y_true = y_true / ys\r\n    ln_p = tf.nn.log_softmax(y_pred)\r\n    wll = tf.reduce_sum(y_true * ln_p, axis=0)\r\n    loss = -tf.tensordot(weights, wll, axes=1)\r\n\r\n    grad = tf.gradients(loss, y_pred)[0]\r\n\r\n    hess = tf.hessians(loss, y_pred)[0]\r\n    hess = tf.diag_part(hess)\r\n\r\n    print(hess.eval())\r\n```\r\n\r\nThis outputs:\r\n\r\n```python\r\n[[0.24090069 0.12669198 0.12669198 0.12669198 0.12669198]\r\n [0.12669198 0.24090069 0.12669198 0.12669198 0.12669198]\r\n [0.12669198 0.12669198 0.12669198 0.24090069 0.12669198]\r\n [0.12669198 0.12669198 0.24090069 0.12669198 0.12669198]\r\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]\r\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]\r\n [0.04223066 0.04223066 0.04223066 0.04223066 0.08030023]]\r\n```\r\n\r\nwhich is exactly what I want. The problem is that the full Hessian is computed before actually `tf.diag_part`.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"}