{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16723", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16723/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16723/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16723/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16723", "id": 294100631, "node_id": "MDU6SXNzdWUyOTQxMDA2MzE=", "number": 16723, "title": "Bug: Compile Tensorflow 1.5.0 Java from source failed on NVIDIA Jetson TX2 with error \"'@bazel_tools//tools/jdk:singlejar' must produce a single file\"", "user": {"login": "YanzheL", "id": 25402886, "node_id": "MDQ6VXNlcjI1NDAyODg2", "avatar_url": "https://avatars0.githubusercontent.com/u/25402886?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YanzheL", "html_url": "https://github.com/YanzheL", "followers_url": "https://api.github.com/users/YanzheL/followers", "following_url": "https://api.github.com/users/YanzheL/following{/other_user}", "gists_url": "https://api.github.com/users/YanzheL/gists{/gist_id}", "starred_url": "https://api.github.com/users/YanzheL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YanzheL/subscriptions", "organizations_url": "https://api.github.com/users/YanzheL/orgs", "repos_url": "https://api.github.com/users/YanzheL/repos", "events_url": "https://api.github.com/users/YanzheL/events{/privacy}", "received_events_url": "https://api.github.com/users/YanzheL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-02-03T10:22:31Z", "updated_at": "2018-09-05T07:19:39Z", "closed_at": "2018-02-11T22:01:46Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nNO</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04 aarch64</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nsource on branch r1.5</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nv1.5.0-1934-g9e7ce91 1.5.0</li>\n<li><strong>Python version</strong>:<br>\nPython 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\n0.9.0 and 0.10.0 (both tried with clean installation)</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\ngcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\nCUDA 9.0, cuDNN 7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nNVIDIA Tegra X2 major (Pascal\u2122 architecture) 8G</li>\n<li><strong>JDK Version</strong>:</li>\n</ul>\n<pre><code>root@tegra-ubuntu:/usr/src# java -version\nopenjdk version \"1.8.0_151\"\nOpenJDK Runtime Environment (build 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12)\nOpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)\n\nroot@tegra-ubuntu:/usr/src# javac -version\njavac 1.8.0_151\n</code></pre>\n<ul>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>root@tegra-ubuntu:/usr/src/tensorflow# ./configure\nExtracting Bazel installation...\nYou have bazel 0.9.0- (@non-git) installed.\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\n\n\nFound possible Python library paths:\n  /usr/local/lib/python3.5/dist-packages\n  /usr/lib/python3/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\n\nDo you wish to build TensorFlow with jemalloc as malloc support<span class=\"pl-k\">?</span> [Y/n]: \njemalloc as malloc support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support<span class=\"pl-k\">?</span> [Y/n]: n\nNo Google Cloud Platform support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support<span class=\"pl-k\">?</span> [Y/n]: \nHadoop File System support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support<span class=\"pl-k\">?</span> [Y/n]: n\nNo Amazon S3 File System support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support<span class=\"pl-k\">?</span> [y/N]: \nNo Apache Kafka Platform support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support<span class=\"pl-k\">?</span> [y/N]: \nNo XLA JIT support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with GDR support<span class=\"pl-k\">?</span> [y/N]: \nNo GDR support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support<span class=\"pl-k\">?</span> [y/N]: \nNo VERBS support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support<span class=\"pl-k\">?</span> [y/N]: \nNo OpenCL SYCL support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support<span class=\"pl-k\">?</span> [y/N]: y\nCUDA support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: \n\n\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md <span class=\"pl-k\">for</span> more details. [Default is /usr/local/cuda]: \n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md <span class=\"pl-k\">for</span> more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support<span class=\"pl-k\">?</span> [y/N]: \nNo TensorRT support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build <span class=\"pl-k\">time</span> and binary size. [Default is: 3.5,5.2]6.2\n\n\nDo you want to use clang as CUDA compiler<span class=\"pl-k\">?</span> [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \n\n\nDo you wish to build TensorFlow with MPI support<span class=\"pl-k\">?</span> [y/N]: \nNo MPI support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--config=opt<span class=\"pl-pds\">\"</span></span> is specified [Default is -march<span class=\"pl-k\">=</span>native]: \n\n\nWould you like to interactively configure ./WORKSPACE <span class=\"pl-k\">for</span> Android builds<span class=\"pl-k\">?</span> [y/N]: \nNot configuring the WORKSPACE <span class=\"pl-k\">for</span> Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--config=&lt;&gt;<span class=\"pl-pds\">\"</span></span> to your build command. See tools/bazel.rc <span class=\"pl-k\">for</span> more details.\n\t--config=mkl         \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with MKL support.</span>\n\t--config=monolithic  \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Config for mostly static monolithic build.</span>\n\t--config=tensorrt    \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with TensorRT support.</span>\nConfiguration finished</pre></div>\n<p>The output from compile procedure is</p>\n<div class=\"highlight highlight-source-shell\"><pre>root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n.........................\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: <span class=\"pl-k\">in</span> singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>@bazel_tools//tools/jdk:singlejar<span class=\"pl-pds\">'</span></span> must produce a single file\nERROR: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>//tensorflow/java:tensorflow<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>@bazel_tools//tools/jdk:toolchain<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted\nINFO: Elapsed time: 57.138s\nFAILED: Build did NOT <span class=\"pl-c1\">complete</span> successfully (7 packages loaded)\n    currently loading: tensorflow</pre></div>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<pre><code>root@tegra-ubuntu:/usr/src# tensorflow/tools/tf_env_collect.sh\nCollecting system information...\n2018-02-03 09:51:47.561112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] ARM64 does not support NUMA - returning NUMA node zero\n2018-02-03 09:51:47.561338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: \nname: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3005\npciBusID: 0000:00:00.0\ntotalMemory: 7.66GiB freeMemory: 465.56MiB\n2018-02-03 09:51:47.561450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0\n2018-02-03 09:51:48.341988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 52 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n</code></pre>\n<pre><code>root@tegra-ubuntu:/usr/src# cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.14.0)\nprotobuf (3.5.1)\ntensorflow (1.5.0)\ntensorflow-tensorboard (1.5.0)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.5.0\ntf.GIT_VERSION = v1.5.0-1934-g9e7ce91\ntf.COMPILER_VERSION = v1.5.0-1934-g9e7ce91\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart.so.9.0.252\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n</code></pre>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<pre><code>root@tegra-ubuntu:/usr/src# python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.5.0-1934-g9e7ce91 1.5.0\n</code></pre>\n<h3>Describe the problem</h3>\n<p>I have successfully compiled tensorflow python from source using same configure procedure as above with the following command:</p>\n<pre><code>root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<p>There is no error in output and I can install the .whl file with pip.</p>\n<p>After that, I tried to compile the Java native library without the configure step (because I already configured it when compiling python version) using the command:</p>\n<pre><code>root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n</code></pre>\n<p>It failed with errors:</p>\n<div class=\"highlight highlight-source-shell\"><pre>root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n.........................\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: <span class=\"pl-k\">in</span> singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>@bazel_tools//tools/jdk:singlejar<span class=\"pl-pds\">'</span></span> must produce a single file\nERROR: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>//tensorflow/java:tensorflow<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>@bazel_tools//tools/jdk:toolchain<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted\nINFO: Elapsed time: 57.138s\nFAILED: Build did NOT <span class=\"pl-c1\">complete</span> successfully (7 packages loaded)\n    currently loading: tensorflow</pre></div>\n<h3>Here are some ways I tried but faild with same error:</h3>\n<ol>\n<li>Configure again (With same configure settings) and compile</li>\n<li>Remove the directory ~/.cache and do the step 1</li>\n<li>Remove the directory ~/.cache and tensorflow source directory, git clone tensorflow from r1.5 branch then do step 1</li>\n<li>Remove ~/.cache and the bazel binary, compile and install bazel from latest source release (0.10.0) without error. Then I use bazel 0.10.0 to compile tensorflow java. This produced same error.</li>\n</ol>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nNO\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04 aarch64\nTensorFlow installed from (source or binary):\nsource on branch r1.5\nTensorFlow version (use command below):\nv1.5.0-1934-g9e7ce91 1.5.0\nPython version:\nPython 3.5\nBazel version (if compiling from source):\n0.9.0 and 0.10.0 (both tried with clean installation)\nGCC/Compiler version (if compiling from source):\ngcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\nCUDA/cuDNN version:\nCUDA 9.0, cuDNN 7.0\nGPU model and memory:\nNVIDIA Tegra X2 major (Pascal\u2122 architecture) 8G\nJDK Version:\n\nroot@tegra-ubuntu:/usr/src# java -version\nopenjdk version \"1.8.0_151\"\nOpenJDK Runtime Environment (build 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12)\nOpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)\n\nroot@tegra-ubuntu:/usr/src# javac -version\njavac 1.8.0_151\n\n\nExact command to reproduce:\n\nroot@tegra-ubuntu:/usr/src/tensorflow# ./configure\nExtracting Bazel installation...\nYou have bazel 0.9.0- (@non-git) installed.\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\n\n\nFound possible Python library paths:\n  /usr/local/lib/python3.5/dist-packages\n  /usr/lib/python3/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\n\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \njemalloc as malloc support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\nNo Google Cloud Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \nHadoop File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\nNo Amazon S3 File System support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: \nNo Apache Kafka Platform support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \nNo XLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with GDR support? [y/N]: \nNo GDR support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with VERBS support? [y/N]: \nNo VERBS support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: \n\n\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.2\n\n\nDo you want to use clang as CUDA compiler? [y/N]: \nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \n\n\nDo you wish to build TensorFlow with MPI support? [y/N]: \nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \n\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\n\t--config=tensorrt    \t# Build with TensorRT support.\nConfiguration finished\nThe output from compile procedure is\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n.........................\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted\nINFO: Elapsed time: 57.138s\nFAILED: Build did NOT complete successfully (7 packages loaded)\n    currently loading: tensorflow\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nroot@tegra-ubuntu:/usr/src# tensorflow/tools/tf_env_collect.sh\nCollecting system information...\n2018-02-03 09:51:47.561112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] ARM64 does not support NUMA - returning NUMA node zero\n2018-02-03 09:51:47.561338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: \nname: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3005\npciBusID: 0000:00:00.0\ntotalMemory: 7.66GiB freeMemory: 465.56MiB\n2018-02-03 09:51:47.561450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0\n2018-02-03 09:51:48.341988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 52 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\nWrote environment to tf_env.txt. You can review the contents of that file.\nand use it to populate the fields in the github issue template.\n\ncat tf_env.txt\n\nroot@tegra-ubuntu:/usr/src# cat tf_env.txt\n\n== cat /etc/issue ===============================================\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.14.0)\nprotobuf (3.5.1)\ntensorflow (1.5.0)\ntensorflow-tensorboard (1.5.0)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.5.0\ntf.GIT_VERSION = v1.5.0-1934-g9e7ce91\ntf.COMPILER_VERSION = v1.5.0-1934-g9e7ce91\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart.so.9.0.252\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nroot@tegra-ubuntu:/usr/src# python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.5.0-1934-g9e7ce91 1.5.0\n\nDescribe the problem\nI have successfully compiled tensorflow python from source using same configure procedure as above with the following command:\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nThere is no error in output and I can install the .whl file with pip.\nAfter that, I tried to compile the Java native library without the configure step (because I already configured it when compiling python version) using the command:\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n\nIt failed with errors:\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\n.........................\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted\nINFO: Elapsed time: 57.138s\nFAILED: Build did NOT complete successfully (7 packages loaded)\n    currently loading: tensorflow\nHere are some ways I tried but faild with same error:\n\nConfigure again (With same configure settings) and compile\nRemove the directory ~/.cache and do the step 1\nRemove the directory ~/.cache and tensorflow source directory, git clone tensorflow from r1.5 branch then do step 1\nRemove ~/.cache and the bazel binary, compile and install bazel from latest source release (0.10.0) without error. Then I use bazel 0.10.0 to compile tensorflow java. This produced same error.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04 aarch64\r\n- **TensorFlow installed from (source or binary)**:\r\nsource on branch r1.5\r\n- **TensorFlow version (use command below)**:\r\nv1.5.0-1934-g9e7ce91 1.5.0\r\n- **Python version**:\r\nPython 3.5\r\n- **Bazel version (if compiling from source)**:\r\n0.9.0 and 0.10.0 (both tried with clean installation)\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:\r\nCUDA 9.0, cuDNN 7.0\r\n- **GPU model and memory**:\r\nNVIDIA Tegra X2 major (Pascal\u2122 architecture) 8G\r\n- **JDK Version**:\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src# java -version\r\nopenjdk version \"1.8.0_151\"\r\nOpenJDK Runtime Environment (build 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12)\r\nOpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)\r\n\r\nroot@tegra-ubuntu:/usr/src# javac -version\r\njavac 1.8.0_151\r\n```\r\n- **Exact command to reproduce**:\r\n\r\n```shell\r\nroot@tegra-ubuntu:/usr/src/tensorflow# ./configure\r\nExtracting Bazel installation...\r\nYou have bazel 0.9.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.5/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: \r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: \r\n\r\n\r\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.2\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: \r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=tensorrt    \t# Build with TensorRT support.\r\nConfiguration finished\r\n```\r\nThe output from compile procedure is\r\n\r\n```shell\r\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\r\n.........................\r\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file\r\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted\r\nINFO: Elapsed time: 57.138s\r\nFAILED: Build did NOT complete successfully (7 packages loaded)\r\n    currently loading: tensorflow\r\n```\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src# tensorflow/tools/tf_env_collect.sh\r\nCollecting system information...\r\n2018-02-03 09:51:47.561112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] ARM64 does not support NUMA - returning NUMA node zero\r\n2018-02-03 09:51:47.561338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: \r\nname: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3005\r\npciBusID: 0000:00:00.0\r\ntotalMemory: 7.66GiB freeMemory: 465.56MiB\r\n2018-02-03 09:51:47.561450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0\r\n2018-02-03 09:51:48.341988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 52 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n```\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src# cat tf_env.txt\r\n\r\n== cat /etc/issue ===============================================\r\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.14.0)\r\nprotobuf (3.5.1)\r\ntensorflow (1.5.0)\r\ntensorflow-tensorboard (1.5.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.5.0\r\ntf.GIT_VERSION = v1.5.0-1934-g9e7ce91\r\ntf.COMPILER_VERSION = v1.5.0-1934-g9e7ce91\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart.so.9.0.252\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n```\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src# python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nv1.5.0-1934-g9e7ce91 1.5.0\r\n```\r\n\r\n### Describe the problem\r\n\r\nI have successfully compiled tensorflow python from source using same configure procedure as above with the following command:\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n``` \r\nThere is no error in output and I can install the .whl file with pip.\r\n\r\nAfter that, I tried to compile the Java native library without the configure step (because I already configured it when compiling python version) using the command:\r\n\r\n```\r\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\r\n```\r\n\r\nIt failed with errors:\r\n\r\n```shell\r\nroot@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\r\n.........................\r\nERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file\r\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted\r\nINFO: Elapsed time: 57.138s\r\nFAILED: Build did NOT complete successfully (7 packages loaded)\r\n    currently loading: tensorflow\r\n```\r\n\r\n### Here are some ways I tried but faild with same error:\r\n\r\n1. Configure again (With same configure settings) and compile\r\n2. Remove the directory ~/.cache and do the step 1\r\n3. Remove the directory ~/.cache and tensorflow source directory, git clone tensorflow from r1.5 branch then do step 1\r\n4. Remove ~/.cache and the bazel binary, compile and install bazel from latest source release (0.10.0) without error. Then I use bazel 0.10.0 to compile tensorflow java. This produced same error.\r\n"}