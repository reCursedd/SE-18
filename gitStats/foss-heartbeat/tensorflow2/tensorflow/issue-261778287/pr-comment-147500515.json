{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147500515", "pull_request_review_id": 72608842, "id": 147500515, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NzUwMDUxNQ==", "diff_hunk": "@@ -341,16 +341,16 @@ def testInference(self):\n             x_shape, dtype, [1], np.float32, use_gpu=True, data_format='NHWC')\n         self._test_inference(\n             x_shape, dtype, [1], np.float32, use_gpu=True, data_format='NCHW')\n-    self._test_inference(\n-        x_shape, np.float32, [1], np.float32, use_gpu=False, data_format='NHWC')\n+        self._test_inference(", "path": "tensorflow/python/ops/nn_fused_batchnorm_test.py", "position": null, "original_position": 6, "commit_id": "8755a4305af31c18f1a4bc3b0cf4cbb875027156", "original_commit_id": "c51f11bb58bca592759811e9465df479c6b82bc5", "user": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "body": "This test is removed in the case where no GPU is available, and same for the test below. Like you did for the tests below, swap the \"if test.is_gpu_available(cuda_only=True)\" and \"for dtype in [np.float16, np.float32]\" statements", "created_at": "2017-10-27T19:43:30Z", "updated_at": "2017-11-08T17:01:09Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13388#discussion_r147500515", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13388", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/147500515"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13388#discussion_r147500515"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13388"}}, "body_html": "<p>This test is removed in the case where no GPU is available, and same for the test below. Like you did for the tests below, swap the \"if test.is_gpu_available(cuda_only=True)\" and \"for dtype in [np.float16, np.float32]\" statements</p>", "body_text": "This test is removed in the case where no GPU is available, and same for the test below. Like you did for the tests below, swap the \"if test.is_gpu_available(cuda_only=True)\" and \"for dtype in [np.float16, np.float32]\" statements"}