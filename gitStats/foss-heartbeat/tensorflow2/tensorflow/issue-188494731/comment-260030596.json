{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260030596", "html_url": "https://github.com/tensorflow/tensorflow/issues/5516#issuecomment-260030596", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5516", "id": 260030596, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDAzMDU5Ng==", "user": {"login": "wjaskowski", "id": 4952605, "node_id": "MDQ6VXNlcjQ5NTI2MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/4952605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wjaskowski", "html_url": "https://github.com/wjaskowski", "followers_url": "https://api.github.com/users/wjaskowski/followers", "following_url": "https://api.github.com/users/wjaskowski/following{/other_user}", "gists_url": "https://api.github.com/users/wjaskowski/gists{/gist_id}", "starred_url": "https://api.github.com/users/wjaskowski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wjaskowski/subscriptions", "organizations_url": "https://api.github.com/users/wjaskowski/orgs", "repos_url": "https://api.github.com/users/wjaskowski/repos", "events_url": "https://api.github.com/users/wjaskowski/events{/privacy}", "received_events_url": "https://api.github.com/users/wjaskowski/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-11T19:04:27Z", "updated_at": "2016-11-11T19:04:27Z", "author_association": "NONE", "body_html": "<p>I use <code>tf.contrib.layers.convolution2d(input,...)</code>, where input is <code>[batch_size, height, width, channels]</code> according to the documentation. Do you suggest that this is wrong, and I should use [batch_size, channels, height, width]?</p>\n<p>The code for tensorflow is dead simple:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">create_tf</span>(<span class=\"pl-smi\">image_shape</span>, <span class=\"pl-smi\">output_dim</span>, <span class=\"pl-smi\">layers_conf</span>):\n    <span class=\"pl-k\">from</span> tensorflow.contrib <span class=\"pl-k\">import</span> layers\n\n    x <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, image_shape[<span class=\"pl-c1\">0</span>], image_shape[<span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>)\n    t <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, output_dim], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>target<span class=\"pl-pds\">\"</span></span>)\n\n    net <span class=\"pl-k\">=</span> x\n    <span class=\"pl-k\">for</span> num_filters <span class=\"pl-k\">in</span> layers_conf[:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]:\n        net <span class=\"pl-k\">=</span> layers.conv2d(net, <span class=\"pl-v\">num_outputs</span><span class=\"pl-k\">=</span>num_filters, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu,\n                <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>layers.xavier_initializer_conv2d(), <span class=\"pl-v\">biases_initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">0.1</span>))\n    net <span class=\"pl-k\">=</span> layers.flatten(net)\n    net <span class=\"pl-k\">=</span> layers.fully_connected(net, <span class=\"pl-v\">num_outputs</span><span class=\"pl-k\">=</span>layers_conf[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>layers.xavier_initializer(),\n            <span class=\"pl-v\">biases_initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">0.1</span>))\n    y <span class=\"pl-k\">=</span> layers.fully_connected(net, <span class=\"pl-v\">num_outputs</span><span class=\"pl-k\">=</span>output_dim, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>layers.xavier_initializer(),\n            <span class=\"pl-v\">biases_initializer</span><span class=\"pl-k\">=</span>tf.constant_initializer(<span class=\"pl-c1\">0.1</span>))\n    mean_square_error <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.5</span><span class=\"pl-k\">*</span>tf.reduce_mean((y <span class=\"pl-k\">-</span> t)<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>)\n    optimizer <span class=\"pl-k\">=</span> tf.train.RMSPropOptimizer(learning_rate).minimize(<span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>mean_square_error)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">backprop</span>(<span class=\"pl-smi\">x_batch</span>, <span class=\"pl-smi\">y_batch</span>):\n        optimizer.run({x: x_batch, t: y_batch})\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">fwd_pass</span>(<span class=\"pl-smi\">x_batch</span>):\n        <span class=\"pl-k\">return</span> y.eval({x: x_batch})\n\n    <span class=\"pl-k\">return</span> fwd_pass, backprop</pre></div>\n<p>I am willing to profile it I this could help you. I would not spend time on it, however, if you acknowledge that such performance gap is expected. So is this expected or not?</p>", "body_text": "I use tf.contrib.layers.convolution2d(input,...), where input is [batch_size, height, width, channels] according to the documentation. Do you suggest that this is wrong, and I should use [batch_size, channels, height, width]?\nThe code for tensorflow is dead simple:\ndef create_tf(image_shape, output_dim, layers_conf):\n    from tensorflow.contrib import layers\n\n    x = tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], 1], name=\"input\")\n    t = tf.placeholder(tf.float32, shape=[None, output_dim], name=\"target\")\n\n    net = x\n    for num_filters in layers_conf[:-1]:\n        net = layers.conv2d(net, num_outputs=num_filters, kernel_size=3, stride=3, activation_fn=tf.nn.relu,\n                weights_initializer=layers.xavier_initializer_conv2d(), biases_initializer=tf.constant_initializer(0.1))\n    net = layers.flatten(net)\n    net = layers.fully_connected(net, num_outputs=layers_conf[-1], activation_fn=tf.nn.relu, weights_initializer=layers.xavier_initializer(),\n            biases_initializer=tf.constant_initializer(0.1))\n    y = layers.fully_connected(net, num_outputs=output_dim, activation_fn=None, weights_initializer=layers.xavier_initializer(),\n            biases_initializer=tf.constant_initializer(0.1))\n    mean_square_error = 0.5*tf.reduce_mean((y - t)**2)\n    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss=mean_square_error)\n\n    def backprop(x_batch, y_batch):\n        optimizer.run({x: x_batch, t: y_batch})\n\n    def fwd_pass(x_batch):\n        return y.eval({x: x_batch})\n\n    return fwd_pass, backprop\nI am willing to profile it I this could help you. I would not spend time on it, however, if you acknowledge that such performance gap is expected. So is this expected or not?", "body": "I use `tf.contrib.layers.convolution2d(input,...)`, where input is `[batch_size, height, width, channels]` according to the documentation. Do you suggest that this is wrong, and I should use [batch_size, channels, height, width]?\n\nThe code for tensorflow is dead simple:\n\n``` python\ndef create_tf(image_shape, output_dim, layers_conf):\n    from tensorflow.contrib import layers\n\n    x = tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], 1], name=\"input\")\n    t = tf.placeholder(tf.float32, shape=[None, output_dim], name=\"target\")\n\n    net = x\n    for num_filters in layers_conf[:-1]:\n        net = layers.conv2d(net, num_outputs=num_filters, kernel_size=3, stride=3, activation_fn=tf.nn.relu,\n                weights_initializer=layers.xavier_initializer_conv2d(), biases_initializer=tf.constant_initializer(0.1))\n    net = layers.flatten(net)\n    net = layers.fully_connected(net, num_outputs=layers_conf[-1], activation_fn=tf.nn.relu, weights_initializer=layers.xavier_initializer(),\n            biases_initializer=tf.constant_initializer(0.1))\n    y = layers.fully_connected(net, num_outputs=output_dim, activation_fn=None, weights_initializer=layers.xavier_initializer(),\n            biases_initializer=tf.constant_initializer(0.1))\n    mean_square_error = 0.5*tf.reduce_mean((y - t)**2)\n    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss=mean_square_error)\n\n    def backprop(x_batch, y_batch):\n        optimizer.run({x: x_batch, t: y_batch})\n\n    def fwd_pass(x_batch):\n        return y.eval({x: x_batch})\n\n    return fwd_pass, backprop\n```\n\nI am willing to profile it I this could help you. I would not spend time on it, however, if you acknowledge that such performance gap is expected. So is this expected or not?\n"}