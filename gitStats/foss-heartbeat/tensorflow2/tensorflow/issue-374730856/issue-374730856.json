{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23327", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23327/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23327/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23327/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23327", "id": 374730856, "node_id": "MDU6SXNzdWUzNzQ3MzA4NTY=", "number": 23327, "title": "tfp.distributions.TransformedDistribution can't handle input and output events with different ndims", "user": {"login": "breadbread1984", "id": 1930282, "node_id": "MDQ6VXNlcjE5MzAyODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1930282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/breadbread1984", "html_url": "https://github.com/breadbread1984", "followers_url": "https://api.github.com/users/breadbread1984/followers", "following_url": "https://api.github.com/users/breadbread1984/following{/other_user}", "gists_url": "https://api.github.com/users/breadbread1984/gists{/gist_id}", "starred_url": "https://api.github.com/users/breadbread1984/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/breadbread1984/subscriptions", "organizations_url": "https://api.github.com/users/breadbread1984/orgs", "repos_url": "https://api.github.com/users/breadbread1984/repos", "events_url": "https://api.github.com/users/breadbread1984/events{/privacy}", "received_events_url": "https://api.github.com/users/breadbread1984/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-28T08:38:59Z", "updated_at": "2018-11-02T01:26:19Z", "closed_at": "2018-11-02T01:26:19Z", "author_association": "NONE", "body_html": "<p>TransformedDistribution can infer event_ndims from base distribution's event_ndims. When the output event (usually an image) has different ndims from input event (usually a 1-D vector), the training would crash at TransformedDistribution::_log_prob(self,y). It calls underlying bijector's Bijector::inverse_log_det_jacobian(self,y,event_ndims) and pass inferred event_ndims which equals 1 according to base distribution's ndims (MultivariateNormalDiag in my case). but y is an image which has ndims of 3 (height x width x channel). The ndims sanity check would fail in Bijector::_call_inverse_log_det_jacobian(self,y,event_ndims).</p>\n<p>I recommend that TransformedDistribution infer the forward_event_ndims and inverse_event_ndims separately from base distribution and underlying bijector respectively to get proper behavior.</p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a</li>\n<li>TensorFlow installed from (source or binary):pip repo</li>\n<li>TensorFlow version (use command below):1.11</li>\n<li>Python version:3.6</li>\n<li>Bazel version (if compiling from source):n/a</li>\n<li>GCC/Compiler version (if compiling from source):n/a</li>\n<li>CUDA/cuDNN version:n/a</li>\n<li>GPU model and memory:n/a</li>\n</ul>", "body_text": "TransformedDistribution can infer event_ndims from base distribution's event_ndims. When the output event (usually an image) has different ndims from input event (usually a 1-D vector), the training would crash at TransformedDistribution::_log_prob(self,y). It calls underlying bijector's Bijector::inverse_log_det_jacobian(self,y,event_ndims) and pass inferred event_ndims which equals 1 according to base distribution's ndims (MultivariateNormalDiag in my case). but y is an image which has ndims of 3 (height x width x channel). The ndims sanity check would fail in Bijector::_call_inverse_log_det_jacobian(self,y,event_ndims).\nI recommend that TransformedDistribution infer the forward_event_ndims and inverse_event_ndims separately from base distribution and underlying bijector respectively to get proper behavior.\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a\nTensorFlow installed from (source or binary):pip repo\nTensorFlow version (use command below):1.11\nPython version:3.6\nBazel version (if compiling from source):n/a\nGCC/Compiler version (if compiling from source):n/a\nCUDA/cuDNN version:n/a\nGPU model and memory:n/a", "body": "TransformedDistribution can infer event_ndims from base distribution's event_ndims. When the output event (usually an image) has different ndims from input event (usually a 1-D vector), the training would crash at TransformedDistribution::_log_prob(self,y). It calls underlying bijector's Bijector::inverse_log_det_jacobian(self,y,event_ndims) and pass inferred event_ndims which equals 1 according to base distribution's ndims (MultivariateNormalDiag in my case). but y is an image which has ndims of 3 (height x width x channel). The ndims sanity check would fail in Bijector::_call_inverse_log_det_jacobian(self,y,event_ndims).\r\n\r\nI recommend that TransformedDistribution infer the forward_event_ndims and inverse_event_ndims separately from base distribution and underlying bijector respectively to get proper behavior.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a\r\n- TensorFlow installed from (source or binary):pip repo\r\n- TensorFlow version (use command below):1.11\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):n/a\r\n- GCC/Compiler version (if compiling from source):n/a\r\n- CUDA/cuDNN version:n/a\r\n- GPU model and memory:n/a"}