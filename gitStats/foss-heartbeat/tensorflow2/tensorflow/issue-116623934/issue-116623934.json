{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/184", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/184/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/184/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/184/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/184", "id": 116623934, "node_id": "MDU6SXNzdWUxMTY2MjM5MzQ=", "number": 184, "title": "Dropout Loses Shape Inference Information", "user": {"login": "nlintz", "id": 1192661, "node_id": "MDQ6VXNlcjExOTI2NjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/1192661?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nlintz", "html_url": "https://github.com/nlintz", "followers_url": "https://api.github.com/users/nlintz/followers", "following_url": "https://api.github.com/users/nlintz/following{/other_user}", "gists_url": "https://api.github.com/users/nlintz/gists{/gist_id}", "starred_url": "https://api.github.com/users/nlintz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nlintz/subscriptions", "organizations_url": "https://api.github.com/users/nlintz/orgs", "repos_url": "https://api.github.com/users/nlintz/repos", "events_url": "https://api.github.com/users/nlintz/events{/privacy}", "received_events_url": "https://api.github.com/users/nlintz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2015-11-12T19:37:07Z", "updated_at": "2015-11-13T15:32:56Z", "closed_at": "2015-11-13T01:31:11Z", "author_association": "NONE", "body_html": "<p>I was working on a simple conv net architecture (stack of convs followed by fully connected) and I came across the following issue. If you apply dropout to the output of a convolution and use a placeholder for p_keep on the dropout, you lose all of the shape information except for the last axis'. Below is a code snippet demonstrating this behavior</p>\n<pre><code>def conv(input_, h, w, nfilt_in, nfilt_out, layer_number):\n    with tf.name_scope('conv_%d' % layer_number) as scope:\n        kernel = tf.Variable(tf.truncated_normal([h, w, nfilt_in, nfilt_out],\n                                                 dtype=tf.float32,\n                                                 stddev=1e-1), name='conv_kernel')\n        conv = tf.nn.conv2d(input_, kernel, [1, 1, 1, 1], padding='SAME')\n    return conv\n\n\ndef model(X, p_keep):\n\n    c = conv(X, 5, 5, 1, 8, 0)\n    print \"c_shape before dropout:\", c.get_shape()  # prints TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(8)]) as expected\n    c = tf.nn.dropout(c, p_keep)\n    print \"c_shape after dropout:\", c.get_shape()  # prints TensorShape(None) which is strange\n    c2 = conv(c, 5, 5, 8, 16, 1)\n    print \"c2_shape:\", c2.get_shape()  # prints TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(16)]) which is strange\n    return c2\n\nX = tf.placeholder(\"float\", [None, 28, 28, 1])\np_keep = tf.placeholder(\"float\")\ny_model = model(X, p_keep)\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n</code></pre>\n<p>As an aside, if you explicitly pass in a value instead of using a placeholder (e.g. replace p_keep=tf.placeholder('float') with p_keep=0.5) this issue does not occur.</p>", "body_text": "I was working on a simple conv net architecture (stack of convs followed by fully connected) and I came across the following issue. If you apply dropout to the output of a convolution and use a placeholder for p_keep on the dropout, you lose all of the shape information except for the last axis'. Below is a code snippet demonstrating this behavior\ndef conv(input_, h, w, nfilt_in, nfilt_out, layer_number):\n    with tf.name_scope('conv_%d' % layer_number) as scope:\n        kernel = tf.Variable(tf.truncated_normal([h, w, nfilt_in, nfilt_out],\n                                                 dtype=tf.float32,\n                                                 stddev=1e-1), name='conv_kernel')\n        conv = tf.nn.conv2d(input_, kernel, [1, 1, 1, 1], padding='SAME')\n    return conv\n\n\ndef model(X, p_keep):\n\n    c = conv(X, 5, 5, 1, 8, 0)\n    print \"c_shape before dropout:\", c.get_shape()  # prints TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(8)]) as expected\n    c = tf.nn.dropout(c, p_keep)\n    print \"c_shape after dropout:\", c.get_shape()  # prints TensorShape(None) which is strange\n    c2 = conv(c, 5, 5, 8, 16, 1)\n    print \"c2_shape:\", c2.get_shape()  # prints TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(16)]) which is strange\n    return c2\n\nX = tf.placeholder(\"float\", [None, 28, 28, 1])\np_keep = tf.placeholder(\"float\")\ny_model = model(X, p_keep)\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n\nAs an aside, if you explicitly pass in a value instead of using a placeholder (e.g. replace p_keep=tf.placeholder('float') with p_keep=0.5) this issue does not occur.", "body": "I was working on a simple conv net architecture (stack of convs followed by fully connected) and I came across the following issue. If you apply dropout to the output of a convolution and use a placeholder for p_keep on the dropout, you lose all of the shape information except for the last axis'. Below is a code snippet demonstrating this behavior\n\n```\ndef conv(input_, h, w, nfilt_in, nfilt_out, layer_number):\n    with tf.name_scope('conv_%d' % layer_number) as scope:\n        kernel = tf.Variable(tf.truncated_normal([h, w, nfilt_in, nfilt_out],\n                                                 dtype=tf.float32,\n                                                 stddev=1e-1), name='conv_kernel')\n        conv = tf.nn.conv2d(input_, kernel, [1, 1, 1, 1], padding='SAME')\n    return conv\n\n\ndef model(X, p_keep):\n\n    c = conv(X, 5, 5, 1, 8, 0)\n    print \"c_shape before dropout:\", c.get_shape()  # prints TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(8)]) as expected\n    c = tf.nn.dropout(c, p_keep)\n    print \"c_shape after dropout:\", c.get_shape()  # prints TensorShape(None) which is strange\n    c2 = conv(c, 5, 5, 8, 16, 1)\n    print \"c2_shape:\", c2.get_shape()  # prints TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(16)]) which is strange\n    return c2\n\nX = tf.placeholder(\"float\", [None, 28, 28, 1])\np_keep = tf.placeholder(\"float\")\ny_model = model(X, p_keep)\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n```\n\nAs an aside, if you explicitly pass in a value instead of using a placeholder (e.g. replace p_keep=tf.placeholder('float') with p_keep=0.5) this issue does not occur.\n"}