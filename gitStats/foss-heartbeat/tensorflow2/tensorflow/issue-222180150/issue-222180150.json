{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9272", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9272/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9272/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9272/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9272", "id": 222180150, "node_id": "MDU6SXNzdWUyMjIxODAxNTA=", "number": 9272, "title": "[idea] new Op: Conv2DWithBiasActivation for Backends that Support Higher Level Op", "user": {"login": "cancan101", "id": 51059, "node_id": "MDQ6VXNlcjUxMDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/51059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cancan101", "html_url": "https://github.com/cancan101", "followers_url": "https://api.github.com/users/cancan101/followers", "following_url": "https://api.github.com/users/cancan101/following{/other_user}", "gists_url": "https://api.github.com/users/cancan101/gists{/gist_id}", "starred_url": "https://api.github.com/users/cancan101/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cancan101/subscriptions", "organizations_url": "https://api.github.com/users/cancan101/orgs", "repos_url": "https://api.github.com/users/cancan101/repos", "events_url": "https://api.github.com/users/cancan101/events{/privacy}", "received_events_url": "https://api.github.com/users/cancan101/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-04-17T17:31:00Z", "updated_at": "2017-06-16T20:49:35Z", "closed_at": "2017-06-16T20:44:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a <a href=\"https://github.com/tensorflow/tensorflow/pull/8673#issuecomment-290722014\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/8673/hovercard\">repost of the comment here</a>:</p>\n<p>Along the lines of <a href=\"https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645\"><code>MklConv2DWithBias</code></a>, I suggest defining a new primitive Op, <code>Conv2DWithBiasActivation</code> that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.</p>\n<p>As far as the (new) fused <code>Conv2D</code> Op that I am using for my BNNS implementation, I used the <a href=\"https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645\">MKL Conv2D Op</a> as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.</p>\n<p>I understand that the primitive <code>Conv2D</code> op in TF does not currently handle activations or bias addition, but this op may be \"too primitive\". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"218065786\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8828\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8828/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8828\">#8828</a>). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a <code>fused</code> version of the Op to reduce the number of primitive Ops used.</p>\n<p>Addendum<br>\nThere are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:</p>\n<ul>\n<li>Metal Performance Shaders (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"210971437\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7958\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7958/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7958\">#7958</a>). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned <code>MPSTemporary\u200bImage</code> and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.</li>\n<li>MKL (as linked above, perhaps the MKL specific Op (<code>MklConv2DWithBias</code>) can be unified with this new Op.</li>\n<li><a href=\"https://github.com/tensorflow/tensorflow/issues/8828\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8828/hovercard\">cuDNN v6</a></li>\n</ul>\n<p>/CC <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20959853\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/drpngx\">@drpngx</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=161459\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/petewarden\">@petewarden</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3645581\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/flx42\">@flx42</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7946809\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gunan\">@gunan</a></p>", "body_text": "This is a repost of the comment here:\nAlong the lines of MklConv2DWithBias, I suggest defining a new primitive Op, Conv2DWithBiasActivation that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.\nAs far as the (new) fused Conv2D Op that I am using for my BNNS implementation, I used the MKL Conv2D Op as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.\nI understand that the primitive Conv2D op in TF does not currently handle activations or bias addition, but this op may be \"too primitive\". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: #8828). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a fused version of the Op to reduce the number of primitive Ops used.\nAddendum\nThere are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:\n\nMetal Performance Shaders (#7958). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned MPSTemporary\u200bImage and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.\nMKL (as linked above, perhaps the MKL specific Op (MklConv2DWithBias) can be unified with this new Op.\ncuDNN v6\n\n/CC @drpngx @petewarden @flx42 @gunan", "body": "This is a [repost of the comment here](https://github.com/tensorflow/tensorflow/pull/8673#issuecomment-290722014):\r\n\r\nAlong the lines of [`MklConv2DWithBias`](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645), I suggest defining a new primitive Op, `Conv2DWithBiasActivation` that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.\r\n\r\nAs far as the (new) fused `Conv2D` Op that I am using for my BNNS implementation, I used the [MKL Conv2D Op](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645) as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.\r\n\r\nI understand that the primitive `Conv2D` op in TF does not currently handle activations or bias addition, but this op may be \"too primitive\". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: https://github.com/tensorflow/tensorflow/issues/8828). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a `fused` version of the Op to reduce the number of primitive Ops used.\r\n\r\nAddendum\r\nThere are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:\r\n* Metal Performance Shaders (https://github.com/tensorflow/tensorflow/issues/7958). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned `MPSTemporary\u200bImage` and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.\r\n* MKL (as linked above, perhaps the MKL specific Op (`MklConv2DWithBias`) can be unified with this new Op.\r\n* [cuDNN v6](https://github.com/tensorflow/tensorflow/issues/8828)\r\n\r\n/CC @drpngx @petewarden @flx42 @gunan "}