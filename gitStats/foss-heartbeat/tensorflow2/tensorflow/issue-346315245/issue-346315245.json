{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21284", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21284/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21284/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21284/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21284", "id": 346315245, "node_id": "MDU6SXNzdWUzNDYzMTUyNDU=", "number": 21284, "title": "TensorFlow 1.9.0 deadlocks on libc6 2.19?", "user": {"login": "ravwojdyla", "id": 1419010, "node_id": "MDQ6VXNlcjE0MTkwMTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1419010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ravwojdyla", "html_url": "https://github.com/ravwojdyla", "followers_url": "https://api.github.com/users/ravwojdyla/followers", "following_url": "https://api.github.com/users/ravwojdyla/following{/other_user}", "gists_url": "https://api.github.com/users/ravwojdyla/gists{/gist_id}", "starred_url": "https://api.github.com/users/ravwojdyla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ravwojdyla/subscriptions", "organizations_url": "https://api.github.com/users/ravwojdyla/orgs", "repos_url": "https://api.github.com/users/ravwojdyla/repos", "events_url": "https://api.github.com/users/ravwojdyla/events{/privacy}", "received_events_url": "https://api.github.com/users/ravwojdyla/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-07-31T18:54:21Z", "updated_at": "2018-11-16T22:30:48Z", "closed_at": "2018-11-16T22:30:48Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: Yes, reproduction repo: <a href=\"https://github.com/ravwojdyla/tf190bug\">https://github.com/ravwojdyla/tf190bug</a></li>\n<li><strong>OS Platform and Distribution</strong>: Ubuntu 14.04, Container-Optimized OS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:  binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Exact command to reproduce</strong>: see repo <a href=\"https://github.com/ravwojdyla/tf190bug\">https://github.com/ravwojdyla/tf190bug</a></li>\n<li><strong>Mobile device</strong>: N/A</li>\n<li><strong>Python version</strong>: N/A</li>\n<li><strong>Bazel version</strong>: N/A</li>\n<li><strong>GCC/Compiler version</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>It seems like TF 1.9.0 deadlocks when used concurrently and linked to libc 2.19 (libpthread?)  (Ubuntu 14.04 and COS to name a some). See the reproduction repo. This is specifically a problem if TF 1.9.0 is used on Google Dataflow worker which  currently ship with libc 2.19. The libc/libpthread is currently just a theory, that said I validated that the reproduction code works fine with libc 2.24 (Ubuntu 16.04).</p>\n<p>I might continue investigating this issue, but wanted to double check if this is a known problem?</p>\n<h3>Source code / logs</h3>\n<p>Reproduction repo: <a href=\"https://github.com/ravwojdyla/tf190bug\">https://github.com/ravwojdyla/tf190bug</a></p>\n<p>Stack of one of the threads:</p>\n<pre><code>\"Thread-9\" #18 prio=5 os_prio=0 tid=0x00007fa568149800 nid=0x4a runnable [0x00007fa55244e000]\n   java.lang.Thread.State: RUNNABLE\n        at org.tensorflow.Tensor.allocateScalarBytes(Native Method)\n        at org.tensorflow.Tensor.create(Tensor.java:150)\n        at org.tensorflow.Tensor.create(Tensor.java:115)\n        at org.tensorflow.Tensors.create(Tensors.java:257)\n        at sh.rav.TestTF.createTensor(TestTF.java:11)\n        at sh.rav.TestTF$1.run(TestTF.java:18)\n        at java.lang.Thread.run(Thread.java:745)\n</code></pre>\n<p>Those threads are all in runnable state, and in fact they do burn CPU, I checked the native frames as well, it seems like some form of a starvation.</p>", "body_text": "System information\n\nHave I written custom code: Yes, reproduction repo: https://github.com/ravwojdyla/tf190bug\nOS Platform and Distribution: Ubuntu 14.04, Container-Optimized OS\nTensorFlow installed from (source or binary):  binary\nTensorFlow version (use command below): 1.9.0\nExact command to reproduce: see repo https://github.com/ravwojdyla/tf190bug\nMobile device: N/A\nPython version: N/A\nBazel version: N/A\nGCC/Compiler version: N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\n\nDescribe the problem\nIt seems like TF 1.9.0 deadlocks when used concurrently and linked to libc 2.19 (libpthread?)  (Ubuntu 14.04 and COS to name a some). See the reproduction repo. This is specifically a problem if TF 1.9.0 is used on Google Dataflow worker which  currently ship with libc 2.19. The libc/libpthread is currently just a theory, that said I validated that the reproduction code works fine with libc 2.24 (Ubuntu 16.04).\nI might continue investigating this issue, but wanted to double check if this is a known problem?\nSource code / logs\nReproduction repo: https://github.com/ravwojdyla/tf190bug\nStack of one of the threads:\n\"Thread-9\" #18 prio=5 os_prio=0 tid=0x00007fa568149800 nid=0x4a runnable [0x00007fa55244e000]\n   java.lang.Thread.State: RUNNABLE\n        at org.tensorflow.Tensor.allocateScalarBytes(Native Method)\n        at org.tensorflow.Tensor.create(Tensor.java:150)\n        at org.tensorflow.Tensor.create(Tensor.java:115)\n        at org.tensorflow.Tensors.create(Tensors.java:257)\n        at sh.rav.TestTF.createTensor(TestTF.java:11)\n        at sh.rav.TestTF$1.run(TestTF.java:18)\n        at java.lang.Thread.run(Thread.java:745)\n\nThose threads are all in runnable state, and in fact they do burn CPU, I checked the native frames as well, it seems like some form of a starvation.", "body": "### System information\r\n- **Have I written custom code**: Yes, reproduction repo: https://github.com/ravwojdyla/tf190bug\r\n- **OS Platform and Distribution**: Ubuntu 14.04, Container-Optimized OS\r\n- **TensorFlow installed from (source or binary)**:  binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Exact command to reproduce**: see repo https://github.com/ravwojdyla/tf190bug\r\n- **Mobile device**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n\r\n### Describe the problem\r\nIt seems like TF 1.9.0 deadlocks when used concurrently and linked to libc 2.19 (libpthread?)  (Ubuntu 14.04 and COS to name a some). See the reproduction repo. This is specifically a problem if TF 1.9.0 is used on Google Dataflow worker which  currently ship with libc 2.19. The libc/libpthread is currently just a theory, that said I validated that the reproduction code works fine with libc 2.24 (Ubuntu 16.04).\r\n\r\nI might continue investigating this issue, but wanted to double check if this is a known problem?\r\n\r\n### Source code / logs\r\n\r\nReproduction repo: https://github.com/ravwojdyla/tf190bug\r\n\r\nStack of one of the threads:\r\n\r\n```\r\n\"Thread-9\" #18 prio=5 os_prio=0 tid=0x00007fa568149800 nid=0x4a runnable [0x00007fa55244e000]\r\n   java.lang.Thread.State: RUNNABLE\r\n        at org.tensorflow.Tensor.allocateScalarBytes(Native Method)\r\n        at org.tensorflow.Tensor.create(Tensor.java:150)\r\n        at org.tensorflow.Tensor.create(Tensor.java:115)\r\n        at org.tensorflow.Tensors.create(Tensors.java:257)\r\n        at sh.rav.TestTF.createTensor(TestTF.java:11)\r\n        at sh.rav.TestTF$1.run(TestTF.java:18)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nThose threads are all in runnable state, and in fact they do burn CPU, I checked the native frames as well, it seems like some form of a starvation."}