{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/355922049", "html_url": "https://github.com/tensorflow/tensorflow/issues/3636#issuecomment-355922049", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3636", "id": 355922049, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTkyMjA0OQ==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-08T09:51:00Z", "updated_at": "2018-01-08T09:51:00Z", "author_association": "NONE", "body_html": "<p>Thanks for tfboyd.<br>\nCan you please suggest or guide me any link which will support the multi-gpu for Tensorflow for poets retraining.</p>\n<p>Part of my code :</p>\n<p>_<strong>with tf.device('/device:GPU:0'):</strong><br>\n<strong>with tf.Session(graph=graph,config=tf.ConfigProto(log_device_placement=True)) as sess:</strong><br>\njpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(<br>\nmodel_info['input_width'], model_info['input_height'],<br>\nmodel_info['input_depth'], model_info['input_mean'],<br>\nmodel_info['input_std'])</p>\n<pre><code>    if do_distort_images:\n      # We will be applying distortions, so setup the operations we'll need.\n      (distorted_jpeg_data_tensor,\n       distorted_image_tensor) = add_input_distortions(\n           FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n           FLAGS.random_brightness, model_info['input_width'],\n           model_info['input_height'], model_info['input_depth'],\n           model_info['input_mean'], model_info['input_std'])\n    else:\n      # We'll make sure we've calculated the 'bottleneck' image summaries and\n      # cached them on disk.\n      cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n                        FLAGS.bottleneck_dir, jpeg_data_tensor,\n                        decoded_image_tensor, resized_image_tensor,\n                        bottleneck_tensor, FLAGS.architecture)\n\n    # Add the new layer that we'll be training.\n    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n     final_tensor) = add_final_training_ops(\n         len(image_lists.keys()), FLAGS.final_tensor_name, bottleneck_tensor,\n         model_info['bottleneck_tensor_size'])\n\n    # Create the operations we need to evaluate the accuracy of our new layer.\n    evaluation_step, prediction = add_evaluation_step(\n        final_tensor, ground_truth_input)\n\n    # Merge all the summaries and write them out to the summaries_dir\n    merged = tf.summary.merge_all()\n    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n                                         sess.graph)\n\n    validation_writer = tf.summary.FileWriter(\n        FLAGS.summaries_dir + '/validation')\n\n    # Set up all our weights to their initial default values.\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    # Run the training for as many cycles as requested on the command line.\n    **for i in range(FLAGS.how_many_training_steps):**\n         # Get a batch of input bottleneck values, either calculated fresh every\n      # time with distortions applied, or from the cache stored on disk.\n      if do_distort_images:\n        (train_bottlenecks,\n         train_ground_truth) = get_random_distorted_bottlenecks(\n             sess, image_lists, FLAGS.train_batch_size, 'training',\n             FLAGS.image_dir, distorted_jpeg_data_tensor,\n             distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n      else:\n        (train_bottlenecks,\n         train_ground_truth, _) = get_random_cached_bottlenecks(\n             sess, image_lists, FLAGS.train_batch_size, 'training',\n             FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n             FLAGS.architecture)\n      # Feed the bottlenecks and ground truth into the graph, and run a training\n      # step. Capture training summaries for TensorBoard with the `merged` op.\n      train_summary, _ = sess.run(\n          [merged, train_step],\n          feed_dict={bottleneck_input: train_bottlenecks,\n                     ground_truth_input: train_ground_truth})\n      train_writer.add_summary(train_summary, i)\n\n      # Every so often, print out how well the graph is training.\n      is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n      if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n        train_accuracy, cross_entropy_value = sess.run(\n            [evaluation_step, cross_entropy],\n            feed_dict={bottleneck_input: train_bottlenecks,\n                       ground_truth_input: train_ground_truth})\n        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n                        (datetime.now(), i, train_accuracy * 100))\n        tf.logging.info('%s: Step %d: Cross entropy = %f' %\n                        (datetime.now(), i, cross_entropy_value))\n        validation_bottlenecks, validation_ground_truth, _ = (\n            get_random_cached_bottlenecks(\n                sess, image_lists, FLAGS.validation_batch_size, 'validation',\n                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n                FLAGS.architecture))\n        # Run a validation step and capture training summaries for TensorBoard\n        # with the `merged` op.\n        validation_summary, validation_accuracy = sess.run(\n            [merged, evaluation_step],\n            feed_dict={bottleneck_input: validation_bottlenecks,\n                       ground_truth_input: validation_ground_truth})\n        validation_writer.add_summary(validation_summary, i)\n        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n                        (datetime.now(), i, validation_accuracy * 100,\n                         len(validation_bottlenecks)))\n\n      # Store intermediate results\n      intermediate_frequency = FLAGS.intermediate_store_frequency\n\n      if (intermediate_frequency &gt; 0 and (i % intermediate_frequency == 0)\n          and i &gt; 0):\n        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\n                                  'intermediate_' + str(i) + '.pb')\n        tf.logging.info('Save intermediate result to : ' +\n                        intermediate_file_name)\n        save_graph_to_file(sess, graph, intermediate_file_name)\n\n    # We've completed all our training, so run a final test evaluation on\n    # some new images we haven't used before.\n    test_bottlenecks, test_ground_truth, test_filenames = (\n        get_random_cached_bottlenecks(\n            sess, image_lists, FLAGS.test_batch_size, 'testing',\n            FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n            FLAGS.architecture))\n    test_accuracy, predictions = sess.run(\n        [evaluation_step, prediction],\n        feed_dict={bottleneck_input: test_bottlenecks,\n                   ground_truth_input: test_ground_truth})\n    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n                    (test_accuracy * 100, len(test_bottlenecks)))\n\n    if FLAGS.print_misclassified_test_images:\n      tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n      for i, test_filename in enumerate(test_filenames):\n        if predictions[i] != test_ground_truth[i].argmax():\n          tf.logging.info('%70s  %s' %\n                          (test_filename,\n                           list(image_lists.keys())[predictions[i]]))\n\n    # Write out the trained graph and labels with the weights stored as\n    # constants.\n    save_graph_to_file(sess, graph, FLAGS.output_graph)\n    with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n      f.write('\\n'.join(image_lists.keys()) + '\\n')_\n</code></pre>\n<p>Here I am creating sess object with tf.device('/device:GPU:0'),how can i ran my training on multiple GPU's</p>", "body_text": "Thanks for tfboyd.\nCan you please suggest or guide me any link which will support the multi-gpu for Tensorflow for poets retraining.\nPart of my code :\n_with tf.device('/device:GPU:0'):\nwith tf.Session(graph=graph,config=tf.ConfigProto(log_device_placement=True)) as sess:\njpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\nmodel_info['input_width'], model_info['input_height'],\nmodel_info['input_depth'], model_info['input_mean'],\nmodel_info['input_std'])\n    if do_distort_images:\n      # We will be applying distortions, so setup the operations we'll need.\n      (distorted_jpeg_data_tensor,\n       distorted_image_tensor) = add_input_distortions(\n           FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n           FLAGS.random_brightness, model_info['input_width'],\n           model_info['input_height'], model_info['input_depth'],\n           model_info['input_mean'], model_info['input_std'])\n    else:\n      # We'll make sure we've calculated the 'bottleneck' image summaries and\n      # cached them on disk.\n      cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n                        FLAGS.bottleneck_dir, jpeg_data_tensor,\n                        decoded_image_tensor, resized_image_tensor,\n                        bottleneck_tensor, FLAGS.architecture)\n\n    # Add the new layer that we'll be training.\n    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n     final_tensor) = add_final_training_ops(\n         len(image_lists.keys()), FLAGS.final_tensor_name, bottleneck_tensor,\n         model_info['bottleneck_tensor_size'])\n\n    # Create the operations we need to evaluate the accuracy of our new layer.\n    evaluation_step, prediction = add_evaluation_step(\n        final_tensor, ground_truth_input)\n\n    # Merge all the summaries and write them out to the summaries_dir\n    merged = tf.summary.merge_all()\n    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n                                         sess.graph)\n\n    validation_writer = tf.summary.FileWriter(\n        FLAGS.summaries_dir + '/validation')\n\n    # Set up all our weights to their initial default values.\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    # Run the training for as many cycles as requested on the command line.\n    **for i in range(FLAGS.how_many_training_steps):**\n         # Get a batch of input bottleneck values, either calculated fresh every\n      # time with distortions applied, or from the cache stored on disk.\n      if do_distort_images:\n        (train_bottlenecks,\n         train_ground_truth) = get_random_distorted_bottlenecks(\n             sess, image_lists, FLAGS.train_batch_size, 'training',\n             FLAGS.image_dir, distorted_jpeg_data_tensor,\n             distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n      else:\n        (train_bottlenecks,\n         train_ground_truth, _) = get_random_cached_bottlenecks(\n             sess, image_lists, FLAGS.train_batch_size, 'training',\n             FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n             FLAGS.architecture)\n      # Feed the bottlenecks and ground truth into the graph, and run a training\n      # step. Capture training summaries for TensorBoard with the `merged` op.\n      train_summary, _ = sess.run(\n          [merged, train_step],\n          feed_dict={bottleneck_input: train_bottlenecks,\n                     ground_truth_input: train_ground_truth})\n      train_writer.add_summary(train_summary, i)\n\n      # Every so often, print out how well the graph is training.\n      is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n      if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n        train_accuracy, cross_entropy_value = sess.run(\n            [evaluation_step, cross_entropy],\n            feed_dict={bottleneck_input: train_bottlenecks,\n                       ground_truth_input: train_ground_truth})\n        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n                        (datetime.now(), i, train_accuracy * 100))\n        tf.logging.info('%s: Step %d: Cross entropy = %f' %\n                        (datetime.now(), i, cross_entropy_value))\n        validation_bottlenecks, validation_ground_truth, _ = (\n            get_random_cached_bottlenecks(\n                sess, image_lists, FLAGS.validation_batch_size, 'validation',\n                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n                FLAGS.architecture))\n        # Run a validation step and capture training summaries for TensorBoard\n        # with the `merged` op.\n        validation_summary, validation_accuracy = sess.run(\n            [merged, evaluation_step],\n            feed_dict={bottleneck_input: validation_bottlenecks,\n                       ground_truth_input: validation_ground_truth})\n        validation_writer.add_summary(validation_summary, i)\n        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n                        (datetime.now(), i, validation_accuracy * 100,\n                         len(validation_bottlenecks)))\n\n      # Store intermediate results\n      intermediate_frequency = FLAGS.intermediate_store_frequency\n\n      if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n          and i > 0):\n        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\n                                  'intermediate_' + str(i) + '.pb')\n        tf.logging.info('Save intermediate result to : ' +\n                        intermediate_file_name)\n        save_graph_to_file(sess, graph, intermediate_file_name)\n\n    # We've completed all our training, so run a final test evaluation on\n    # some new images we haven't used before.\n    test_bottlenecks, test_ground_truth, test_filenames = (\n        get_random_cached_bottlenecks(\n            sess, image_lists, FLAGS.test_batch_size, 'testing',\n            FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n            FLAGS.architecture))\n    test_accuracy, predictions = sess.run(\n        [evaluation_step, prediction],\n        feed_dict={bottleneck_input: test_bottlenecks,\n                   ground_truth_input: test_ground_truth})\n    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n                    (test_accuracy * 100, len(test_bottlenecks)))\n\n    if FLAGS.print_misclassified_test_images:\n      tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n      for i, test_filename in enumerate(test_filenames):\n        if predictions[i] != test_ground_truth[i].argmax():\n          tf.logging.info('%70s  %s' %\n                          (test_filename,\n                           list(image_lists.keys())[predictions[i]]))\n\n    # Write out the trained graph and labels with the weights stored as\n    # constants.\n    save_graph_to_file(sess, graph, FLAGS.output_graph)\n    with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n      f.write('\\n'.join(image_lists.keys()) + '\\n')_\n\nHere I am creating sess object with tf.device('/device:GPU:0'),how can i ran my training on multiple GPU's", "body": "Thanks for tfboyd.\r\nCan you please suggest or guide me any link which will support the multi-gpu for Tensorflow for poets retraining. \r\n\r\n\r\nPart of my code :\r\n\r\n_**with tf.device('/device:GPU:0'):**\r\n      **with tf.Session(graph=graph,config=tf.ConfigProto(log_device_placement=True)) as sess:**\r\n        jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\r\n            model_info['input_width'], model_info['input_height'],\r\n            model_info['input_depth'], model_info['input_mean'],\r\n            model_info['input_std'])\r\n    \r\n        if do_distort_images:\r\n          # We will be applying distortions, so setup the operations we'll need.\r\n          (distorted_jpeg_data_tensor,\r\n           distorted_image_tensor) = add_input_distortions(\r\n               FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\r\n               FLAGS.random_brightness, model_info['input_width'],\r\n               model_info['input_height'], model_info['input_depth'],\r\n               model_info['input_mean'], model_info['input_std'])\r\n        else:\r\n          # We'll make sure we've calculated the 'bottleneck' image summaries and\r\n          # cached them on disk.\r\n          cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\r\n                            FLAGS.bottleneck_dir, jpeg_data_tensor,\r\n                            decoded_image_tensor, resized_image_tensor,\r\n                            bottleneck_tensor, FLAGS.architecture)\r\n    \r\n        # Add the new layer that we'll be training.\r\n        (train_step, cross_entropy, bottleneck_input, ground_truth_input,\r\n         final_tensor) = add_final_training_ops(\r\n             len(image_lists.keys()), FLAGS.final_tensor_name, bottleneck_tensor,\r\n             model_info['bottleneck_tensor_size'])\r\n    \r\n        # Create the operations we need to evaluate the accuracy of our new layer.\r\n        evaluation_step, prediction = add_evaluation_step(\r\n            final_tensor, ground_truth_input)\r\n    \r\n        # Merge all the summaries and write them out to the summaries_dir\r\n        merged = tf.summary.merge_all()\r\n        train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\r\n                                             sess.graph)\r\n    \r\n        validation_writer = tf.summary.FileWriter(\r\n            FLAGS.summaries_dir + '/validation')\r\n    \r\n        # Set up all our weights to their initial default values.\r\n        init = tf.global_variables_initializer()\r\n        sess.run(init)\r\n    \r\n        # Run the training for as many cycles as requested on the command line.\r\n        **for i in range(FLAGS.how_many_training_steps):**\r\n             # Get a batch of input bottleneck values, either calculated fresh every\r\n          # time with distortions applied, or from the cache stored on disk.\r\n          if do_distort_images:\r\n            (train_bottlenecks,\r\n             train_ground_truth) = get_random_distorted_bottlenecks(\r\n                 sess, image_lists, FLAGS.train_batch_size, 'training',\r\n                 FLAGS.image_dir, distorted_jpeg_data_tensor,\r\n                 distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\r\n          else:\r\n            (train_bottlenecks,\r\n             train_ground_truth, _) = get_random_cached_bottlenecks(\r\n                 sess, image_lists, FLAGS.train_batch_size, 'training',\r\n                 FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\r\n                 decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\r\n                 FLAGS.architecture)\r\n          # Feed the bottlenecks and ground truth into the graph, and run a training\r\n          # step. Capture training summaries for TensorBoard with the `merged` op.\r\n          train_summary, _ = sess.run(\r\n              [merged, train_step],\r\n              feed_dict={bottleneck_input: train_bottlenecks,\r\n                         ground_truth_input: train_ground_truth})\r\n          train_writer.add_summary(train_summary, i)\r\n    \r\n          # Every so often, print out how well the graph is training.\r\n          is_last_step = (i + 1 == FLAGS.how_many_training_steps)\r\n          if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\r\n            train_accuracy, cross_entropy_value = sess.run(\r\n                [evaluation_step, cross_entropy],\r\n                feed_dict={bottleneck_input: train_bottlenecks,\r\n                           ground_truth_input: train_ground_truth})\r\n            tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\r\n                            (datetime.now(), i, train_accuracy * 100))\r\n            tf.logging.info('%s: Step %d: Cross entropy = %f' %\r\n                            (datetime.now(), i, cross_entropy_value))\r\n            validation_bottlenecks, validation_ground_truth, _ = (\r\n                get_random_cached_bottlenecks(\r\n                    sess, image_lists, FLAGS.validation_batch_size, 'validation',\r\n                    FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\r\n                    decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\r\n                    FLAGS.architecture))\r\n            # Run a validation step and capture training summaries for TensorBoard\r\n            # with the `merged` op.\r\n            validation_summary, validation_accuracy = sess.run(\r\n                [merged, evaluation_step],\r\n                feed_dict={bottleneck_input: validation_bottlenecks,\r\n                           ground_truth_input: validation_ground_truth})\r\n            validation_writer.add_summary(validation_summary, i)\r\n            tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\r\n                            (datetime.now(), i, validation_accuracy * 100,\r\n                             len(validation_bottlenecks)))\r\n    \r\n          # Store intermediate results\r\n          intermediate_frequency = FLAGS.intermediate_store_frequency\r\n    \r\n          if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\r\n              and i > 0):\r\n            intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\r\n                                      'intermediate_' + str(i) + '.pb')\r\n            tf.logging.info('Save intermediate result to : ' +\r\n                            intermediate_file_name)\r\n            save_graph_to_file(sess, graph, intermediate_file_name)\r\n    \r\n        # We've completed all our training, so run a final test evaluation on\r\n        # some new images we haven't used before.\r\n        test_bottlenecks, test_ground_truth, test_filenames = (\r\n            get_random_cached_bottlenecks(\r\n                sess, image_lists, FLAGS.test_batch_size, 'testing',\r\n                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\r\n                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\r\n                FLAGS.architecture))\r\n        test_accuracy, predictions = sess.run(\r\n            [evaluation_step, prediction],\r\n            feed_dict={bottleneck_input: test_bottlenecks,\r\n                       ground_truth_input: test_ground_truth})\r\n        tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\r\n                        (test_accuracy * 100, len(test_bottlenecks)))\r\n    \r\n        if FLAGS.print_misclassified_test_images:\r\n          tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\r\n          for i, test_filename in enumerate(test_filenames):\r\n            if predictions[i] != test_ground_truth[i].argmax():\r\n              tf.logging.info('%70s  %s' %\r\n                              (test_filename,\r\n                               list(image_lists.keys())[predictions[i]]))\r\n    \r\n        # Write out the trained graph and labels with the weights stored as\r\n        # constants.\r\n        save_graph_to_file(sess, graph, FLAGS.output_graph)\r\n        with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\r\n          f.write('\\n'.join(image_lists.keys()) + '\\n')_\r\n\r\nHere I am creating sess object with tf.device('/device:GPU:0'),how can i ran my training on multiple GPU's"}