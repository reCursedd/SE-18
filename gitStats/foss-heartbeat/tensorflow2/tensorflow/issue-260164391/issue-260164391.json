{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13286", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13286/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13286/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13286/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13286", "id": 260164391, "node_id": "MDU6SXNzdWUyNjAxNjQzOTE=", "number": 13286, "title": "[bug/docs] tf.Estimator: 'train' method is missing", "user": {"login": "DSLituiev", "id": 8426290, "node_id": "MDQ6VXNlcjg0MjYyOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/8426290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DSLituiev", "html_url": "https://github.com/DSLituiev", "followers_url": "https://api.github.com/users/DSLituiev/followers", "following_url": "https://api.github.com/users/DSLituiev/following{/other_user}", "gists_url": "https://api.github.com/users/DSLituiev/gists{/gist_id}", "starred_url": "https://api.github.com/users/DSLituiev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DSLituiev/subscriptions", "organizations_url": "https://api.github.com/users/DSLituiev/orgs", "repos_url": "https://api.github.com/users/DSLituiev/repos", "events_url": "https://api.github.com/users/DSLituiev/events{/privacy}", "received_events_url": "https://api.github.com/users/DSLituiev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-09-25T06:15:03Z", "updated_at": "2017-10-03T07:17:30Z", "closed_at": "2017-10-03T07:17:30Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Used doc</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution, versions etc</strong>:</p>\n</li>\n</ul>\n<details>\n== cat /etc/issue ===============================================\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64\nMac OS X 10.12.6\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nApple LLVM version 8.1.0 (clang-802.0.42)<br>\nTarget: x86_64-apple-darwin16.7.0<br>\nThread model: posix<br>\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin</p>\n<p>== uname -a =====================================================<br>\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64</p>\n<p>== check pips ===================================================<br>\nnumpy (1.13.1)<br>\nprotobuf (3.3.0)<br>\ntensorflow (1.2.1)</p>\n<p>== check for virtualenv =========================================<br>\nFalse<br>\n== tensorflow import ============================================<br>\ntf.VERSION = 1.2.1<br>\ntf.GIT_VERSION = v1.2.0-5-g435cdfc<br>\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH is unset<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\ntf_env_collect.sh: line 105: nvidia-smi: command not found</p>\n<p>No GPU</p>\n</details>\n<ul>\n<li><strong>Exact command to reproduce</strong>:<br>\nI am modifying this <a href=\"http://localhost:8888/notebooks/keras_tfest/keras-estimator/Integration%20of%20Keras%20with%20Tensorflow.ipynb\" rel=\"nofollow\">script that works</a> + documentation as referenced below. The resulting code is following:</li>\n</ul>\n<details>\n<pre><code># coding: utf-8\nimport sys\nsys.path.append(\"/data/dlituiev/target2/\")\nfrom inception import get_model\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, InputLayer, Reshape, Input\nimport tensorflow as tf\nfrom tensorflow.python.framework.ops import _get_graph_from_inputs\nfrom tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\nimport numpy as np\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')\n\nBATCH_SIZE = 4\nn_classes=10\nfinal_activation='linear'\nlr=1e-4\nopt_name = \"Adadelta\"\nepochs = 20\nHEIGHT, WIDTH = 512, 512\n\ndef get_model():\n    model = Sequential()\n    model.add(InputLayer(input_shape=[512 , 512, 1], batch_size=BATCH_SIZE))\n    #     model.add(Reshape([512*512,]))\n    model.add(Flatten())\n    model.add(Dense(n_classes, activation='relu', ))\n    return model\n\n\ng = tf.Graph()\nwith g.as_default():\n    model = get_model()\n    model.build()\n    funcmodel = model.model\n\n    def model_fn(features, labels, params):\n        optimizer = params[\"optimizer\"]\n        opt_params= params.get(\"opt_params\", {})\n    #     x = tf.placeholder(tf.float32, shape=model.layers[0].input.shape)\n        print(\"features\", features.shape)\n        logyhat = funcmodel(features)\n\n        if (mode == tf.estimator.ModeKeys.TRAIN or\n            mode == tf.estimator.ModeKeys.EVAL):\n    #         loss = tf.contrib.keras.backend.categorical_crossentropy()\n            loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logyhat)\n        else:\n            loss = None\n        if mode == tf.estimator.ModeKeys.TRAIN:\n            optimizer = getattr(tf.train, optimizer)\n            train_op = optimizer(opt_params).minimize(loss)\n        else:\n            train_op = None\n        if mode == tf.estimator.ModeKeys.PREDICT:\n            predictions = tf.nn.softmax(logyhat)\n        else:\n            predictions = None\n\n        \"\"\"\n        return tf.estimator.EstimatorSpec(\n              mode=mode,\n              predictions=predictions,\n              loss=loss,\n              train_op=train_op)\n              \"\"\"\n\n        return model_fn_lib.ModelFnOps(\n              mode=mode,\n              predictions=predictions,\n              loss=loss,\n              train_op=train_op,\n              #eval_metric_ops=eval_metric_ops\n              )\n    ##############################################\n\n    def parser(record):\n        keys_to_features = {\n            'height': tf.FixedLenFeature([], tf.int64),\n            'width': tf.FixedLenFeature([], tf.int64),\n            'image_raw': tf.FixedLenFeature([], tf.string),\n            'label': tf.FixedLenFeature([], tf.int64)\n            }\n        features = tf.parse_single_example(\n          record,\n          features=keys_to_features)\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.float32)\n        #annotation = tf.decode_raw(features['mask_raw'], tf.uint8)\n\n        height = tf.cast(features['height'], tf.int32)\n        width = tf.cast(features['width'], tf.int32)\n\n#         image_shape = tf.stack([height, width, 1])\n        image_shape = tf.stack([HEIGHT, WIDTH,1])\n        #annotation_shape = tf.pack([height, width, 1])\n\n        image = tf.reshape(image, image_shape)\n        label = tf.cast(features[\"label\"], tf.int32)\n        return image, label\n\n    def get_dataset_inp_fn(filenames, epochs=20, batch_size=2,\n                           buffer_size=100):\n        def dataset_input_fn():\n            dataset = tf.contrib.data.TFRecordDataset(filenames)\n\n            # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n            # protocol buffer, and perform any additional per-record preprocessing.\n\n            # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n            # tensor for each example.\n            dataset = dataset.map(parser)\n            dataset = dataset.shuffle(buffer_size=buffer_size)\n            dataset = dataset.batch(batch_size)\n            dataset = dataset.repeat(epochs)\n            iterator = dataset.make_one_shot_iterator()\n\n            # `features` is a dictionary in which each value is a batch of values for\n            # that feature; `labels` is a batch of labels.\n            features, labels = iterator.get_next()\n            return features, labels\n        return dataset_input_fn\n\n##############################################\ndef get_optimizer(opt_name = \"Adadelta\", **kwargs):\n    #lr=kwargs.pop(\"lr\", 1e-4)\n    opt_name = opt_name if opt_name.endswith(\"Optimizer\") else opt_name.title()+\"Optimizer\"\n    optimizer = getattr(tf.train, opt_name)\n    return optimizer#(lr, **kwargs)\n##############################################\n\nfrom tensorflow.contrib.learn.python.learn.estimators import estimator\nLEARNING_RATE = 0.001\n# Set model params\nmodel_params = {\"opt_params\":{\"learning_rate\": LEARNING_RATE}, 'optimizer' : get_optimizer()}\n\ninpfun = get_dataset_inp_fn([\"example.tfrecords\"],\n                                epochs=epochs,\n                                batch_size=BATCH_SIZE)\n# Instantiate Estimator\nest = estimator.Estimator(model_fn=model_fn, params=model_params)\n\nprint(help(est))\n\n### Option 1 ###\nest.train(input_fn=inpfun, steps=5000)\n\n### Option 2 ###\nest.fit(input_fn=inpfun, steps=5000)\n</code></pre>\n</details>\n<h3>Describe the problem</h3>\n<p>In this manual it implies that <code>tf.Estimator</code> has a method <code>train()</code>:<br>\n<a href=\"https://www.tensorflow.org/extend/estimators\" rel=\"nofollow\">https://www.tensorflow.org/extend/estimators</a></p>\n<p>When I instantiate an estimator and run <code>est.train(input_fn=inpfun, steps=5000)</code> I am getting:</p>\n<pre><code> AttributeError: 'Estimator' object has no attribute 'train'\n</code></pre>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Used doc\n\n\nOS Platform and Distribution, versions etc:\n\n\n\n== cat /etc/issue ===============================================\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64\nMac OS X 10.12.6\n== are we in docker =============================================\nNo\n== compiler =====================================================\nApple LLVM version 8.1.0 (clang-802.0.42)\nTarget: x86_64-apple-darwin16.7.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\n== uname -a =====================================================\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64\n== check pips ===================================================\nnumpy (1.13.1)\nprotobuf (3.3.0)\ntensorflow (1.2.1)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.2.1\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\ntf_env_collect.sh: line 105: nvidia-smi: command not found\nNo GPU\n\n\nExact command to reproduce:\nI am modifying this script that works + documentation as referenced below. The resulting code is following:\n\n\n# coding: utf-8\nimport sys\nsys.path.append(\"/data/dlituiev/target2/\")\nfrom inception import get_model\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, InputLayer, Reshape, Input\nimport tensorflow as tf\nfrom tensorflow.python.framework.ops import _get_graph_from_inputs\nfrom tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\nimport numpy as np\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')\n\nBATCH_SIZE = 4\nn_classes=10\nfinal_activation='linear'\nlr=1e-4\nopt_name = \"Adadelta\"\nepochs = 20\nHEIGHT, WIDTH = 512, 512\n\ndef get_model():\n    model = Sequential()\n    model.add(InputLayer(input_shape=[512 , 512, 1], batch_size=BATCH_SIZE))\n    #     model.add(Reshape([512*512,]))\n    model.add(Flatten())\n    model.add(Dense(n_classes, activation='relu', ))\n    return model\n\n\ng = tf.Graph()\nwith g.as_default():\n    model = get_model()\n    model.build()\n    funcmodel = model.model\n\n    def model_fn(features, labels, params):\n        optimizer = params[\"optimizer\"]\n        opt_params= params.get(\"opt_params\", {})\n    #     x = tf.placeholder(tf.float32, shape=model.layers[0].input.shape)\n        print(\"features\", features.shape)\n        logyhat = funcmodel(features)\n\n        if (mode == tf.estimator.ModeKeys.TRAIN or\n            mode == tf.estimator.ModeKeys.EVAL):\n    #         loss = tf.contrib.keras.backend.categorical_crossentropy()\n            loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logyhat)\n        else:\n            loss = None\n        if mode == tf.estimator.ModeKeys.TRAIN:\n            optimizer = getattr(tf.train, optimizer)\n            train_op = optimizer(opt_params).minimize(loss)\n        else:\n            train_op = None\n        if mode == tf.estimator.ModeKeys.PREDICT:\n            predictions = tf.nn.softmax(logyhat)\n        else:\n            predictions = None\n\n        \"\"\"\n        return tf.estimator.EstimatorSpec(\n              mode=mode,\n              predictions=predictions,\n              loss=loss,\n              train_op=train_op)\n              \"\"\"\n\n        return model_fn_lib.ModelFnOps(\n              mode=mode,\n              predictions=predictions,\n              loss=loss,\n              train_op=train_op,\n              #eval_metric_ops=eval_metric_ops\n              )\n    ##############################################\n\n    def parser(record):\n        keys_to_features = {\n            'height': tf.FixedLenFeature([], tf.int64),\n            'width': tf.FixedLenFeature([], tf.int64),\n            'image_raw': tf.FixedLenFeature([], tf.string),\n            'label': tf.FixedLenFeature([], tf.int64)\n            }\n        features = tf.parse_single_example(\n          record,\n          features=keys_to_features)\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.float32)\n        #annotation = tf.decode_raw(features['mask_raw'], tf.uint8)\n\n        height = tf.cast(features['height'], tf.int32)\n        width = tf.cast(features['width'], tf.int32)\n\n#         image_shape = tf.stack([height, width, 1])\n        image_shape = tf.stack([HEIGHT, WIDTH,1])\n        #annotation_shape = tf.pack([height, width, 1])\n\n        image = tf.reshape(image, image_shape)\n        label = tf.cast(features[\"label\"], tf.int32)\n        return image, label\n\n    def get_dataset_inp_fn(filenames, epochs=20, batch_size=2,\n                           buffer_size=100):\n        def dataset_input_fn():\n            dataset = tf.contrib.data.TFRecordDataset(filenames)\n\n            # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n            # protocol buffer, and perform any additional per-record preprocessing.\n\n            # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n            # tensor for each example.\n            dataset = dataset.map(parser)\n            dataset = dataset.shuffle(buffer_size=buffer_size)\n            dataset = dataset.batch(batch_size)\n            dataset = dataset.repeat(epochs)\n            iterator = dataset.make_one_shot_iterator()\n\n            # `features` is a dictionary in which each value is a batch of values for\n            # that feature; `labels` is a batch of labels.\n            features, labels = iterator.get_next()\n            return features, labels\n        return dataset_input_fn\n\n##############################################\ndef get_optimizer(opt_name = \"Adadelta\", **kwargs):\n    #lr=kwargs.pop(\"lr\", 1e-4)\n    opt_name = opt_name if opt_name.endswith(\"Optimizer\") else opt_name.title()+\"Optimizer\"\n    optimizer = getattr(tf.train, opt_name)\n    return optimizer#(lr, **kwargs)\n##############################################\n\nfrom tensorflow.contrib.learn.python.learn.estimators import estimator\nLEARNING_RATE = 0.001\n# Set model params\nmodel_params = {\"opt_params\":{\"learning_rate\": LEARNING_RATE}, 'optimizer' : get_optimizer()}\n\ninpfun = get_dataset_inp_fn([\"example.tfrecords\"],\n                                epochs=epochs,\n                                batch_size=BATCH_SIZE)\n# Instantiate Estimator\nest = estimator.Estimator(model_fn=model_fn, params=model_params)\n\nprint(help(est))\n\n### Option 1 ###\nest.train(input_fn=inpfun, steps=5000)\n\n### Option 2 ###\nest.fit(input_fn=inpfun, steps=5000)\n\n\nDescribe the problem\nIn this manual it implies that tf.Estimator has a method train():\nhttps://www.tensorflow.org/extend/estimators\nWhen I instantiate an estimator and run est.train(input_fn=inpfun, steps=5000) I am getting:\n AttributeError: 'Estimator' object has no attribute 'train'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Used doc\r\n\r\n- **OS Platform and Distribution, versions etc**:\r\n<details>\r\n== cat /etc/issue ===============================================\r\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.6\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.1.0 (clang-802.0.42)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin PEDS-0MAHH2C-LT 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\nNo GPU\r\n</details>\r\n\r\n- **Exact command to reproduce**:\r\nI am modifying this [script that works](http://localhost:8888/notebooks/keras_tfest/keras-estimator/Integration%20of%20Keras%20with%20Tensorflow.ipynb) + documentation as referenced below. The resulting code is following:\r\n\r\n<details>\r\n\r\n    # coding: utf-8\r\n    import sys\r\n    sys.path.append(\"/data/dlituiev/target2/\")\r\n    from inception import get_model\r\n    from keras.models import Sequential, Model\r\n    from keras.layers import Dense, Dropout, Activation, Flatten, InputLayer, Reshape, Input\r\n    import tensorflow as tf\r\n    from tensorflow.python.framework.ops import _get_graph_from_inputs\r\n    from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\r\n    import numpy as np\r\n    from keras import backend as K\r\n    K.set_image_dim_ordering('tf')\r\n\r\n    BATCH_SIZE = 4\r\n    n_classes=10\r\n    final_activation='linear'\r\n    lr=1e-4\r\n    opt_name = \"Adadelta\"\r\n    epochs = 20\r\n    HEIGHT, WIDTH = 512, 512\r\n\r\n    def get_model():\r\n        model = Sequential()\r\n        model.add(InputLayer(input_shape=[512 , 512, 1], batch_size=BATCH_SIZE))\r\n        #     model.add(Reshape([512*512,]))\r\n        model.add(Flatten())\r\n        model.add(Dense(n_classes, activation='relu', ))\r\n        return model\r\n\r\n\r\n    g = tf.Graph()\r\n    with g.as_default():\r\n        model = get_model()\r\n        model.build()\r\n        funcmodel = model.model\r\n\r\n        def model_fn(features, labels, params):\r\n            optimizer = params[\"optimizer\"]\r\n            opt_params= params.get(\"opt_params\", {})\r\n        #     x = tf.placeholder(tf.float32, shape=model.layers[0].input.shape)\r\n            print(\"features\", features.shape)\r\n            logyhat = funcmodel(features)\r\n\r\n            if (mode == tf.estimator.ModeKeys.TRAIN or\r\n                mode == tf.estimator.ModeKeys.EVAL):\r\n        #         loss = tf.contrib.keras.backend.categorical_crossentropy()\r\n                loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logyhat)\r\n            else:\r\n                loss = None\r\n            if mode == tf.estimator.ModeKeys.TRAIN:\r\n                optimizer = getattr(tf.train, optimizer)\r\n                train_op = optimizer(opt_params).minimize(loss)\r\n            else:\r\n                train_op = None\r\n            if mode == tf.estimator.ModeKeys.PREDICT:\r\n                predictions = tf.nn.softmax(logyhat)\r\n            else:\r\n                predictions = None\r\n\r\n            \"\"\"\r\n            return tf.estimator.EstimatorSpec(\r\n                  mode=mode,\r\n                  predictions=predictions,\r\n                  loss=loss,\r\n                  train_op=train_op)\r\n                  \"\"\"\r\n\r\n            return model_fn_lib.ModelFnOps(\r\n                  mode=mode,\r\n                  predictions=predictions,\r\n                  loss=loss,\r\n                  train_op=train_op,\r\n                  #eval_metric_ops=eval_metric_ops\r\n                  )\r\n        ##############################################\r\n\r\n        def parser(record):\r\n            keys_to_features = {\r\n                'height': tf.FixedLenFeature([], tf.int64),\r\n                'width': tf.FixedLenFeature([], tf.int64),\r\n                'image_raw': tf.FixedLenFeature([], tf.string),\r\n                'label': tf.FixedLenFeature([], tf.int64)\r\n                }\r\n            features = tf.parse_single_example(\r\n              record,\r\n              features=keys_to_features)\r\n\r\n            # Convert from a scalar string tensor (whose single string has\r\n            # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\r\n            # [mnist.IMAGE_PIXELS].\r\n            image = tf.decode_raw(features['image_raw'], tf.float32)\r\n            #annotation = tf.decode_raw(features['mask_raw'], tf.uint8)\r\n\r\n            height = tf.cast(features['height'], tf.int32)\r\n            width = tf.cast(features['width'], tf.int32)\r\n\r\n    #         image_shape = tf.stack([height, width, 1])\r\n            image_shape = tf.stack([HEIGHT, WIDTH,1])\r\n            #annotation_shape = tf.pack([height, width, 1])\r\n\r\n            image = tf.reshape(image, image_shape)\r\n            label = tf.cast(features[\"label\"], tf.int32)\r\n            return image, label\r\n\r\n        def get_dataset_inp_fn(filenames, epochs=20, batch_size=2,\r\n                               buffer_size=100):\r\n            def dataset_input_fn():\r\n                dataset = tf.contrib.data.TFRecordDataset(filenames)\r\n\r\n                # Use `tf.parse_single_example()` to extract data from a `tf.Example`\r\n                # protocol buffer, and perform any additional per-record preprocessing.\r\n\r\n                # Use `Dataset.map()` to build a pair of a feature dictionary and a label\r\n                # tensor for each example.\r\n                dataset = dataset.map(parser)\r\n                dataset = dataset.shuffle(buffer_size=buffer_size)\r\n                dataset = dataset.batch(batch_size)\r\n                dataset = dataset.repeat(epochs)\r\n                iterator = dataset.make_one_shot_iterator()\r\n\r\n                # `features` is a dictionary in which each value is a batch of values for\r\n                # that feature; `labels` is a batch of labels.\r\n                features, labels = iterator.get_next()\r\n                return features, labels\r\n            return dataset_input_fn\r\n\r\n    ##############################################\r\n    def get_optimizer(opt_name = \"Adadelta\", **kwargs):\r\n        #lr=kwargs.pop(\"lr\", 1e-4)\r\n        opt_name = opt_name if opt_name.endswith(\"Optimizer\") else opt_name.title()+\"Optimizer\"\r\n        optimizer = getattr(tf.train, opt_name)\r\n        return optimizer#(lr, **kwargs)\r\n    ##############################################\r\n\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n    LEARNING_RATE = 0.001\r\n    # Set model params\r\n    model_params = {\"opt_params\":{\"learning_rate\": LEARNING_RATE}, 'optimizer' : get_optimizer()}\r\n\r\n    inpfun = get_dataset_inp_fn([\"example.tfrecords\"],\r\n                                    epochs=epochs,\r\n                                    batch_size=BATCH_SIZE)\r\n    # Instantiate Estimator\r\n    est = estimator.Estimator(model_fn=model_fn, params=model_params)\r\n\r\n    print(help(est))\r\n\r\n    ### Option 1 ###\r\n    est.train(input_fn=inpfun, steps=5000)\r\n\r\n    ### Option 2 ###\r\n    est.fit(input_fn=inpfun, steps=5000)\r\n\r\n\r\n</details>\r\n\r\n### Describe the problem\r\nIn this manual it implies that `tf.Estimator` has a method `train()`:\r\nhttps://www.tensorflow.org/extend/estimators\r\n\r\nWhen I instantiate an estimator and run `est.train(input_fn=inpfun, steps=5000)` I am getting:\r\n\r\n     AttributeError: 'Estimator' object has no attribute 'train'\r\n"}