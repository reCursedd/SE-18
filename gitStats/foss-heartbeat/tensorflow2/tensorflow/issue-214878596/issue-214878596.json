{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8483", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8483/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8483/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8483/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8483", "id": 214878596, "node_id": "MDU6SXNzdWUyMTQ4Nzg1OTY=", "number": 8483, "title": "Errors polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED", "user": {"login": "jw447", "id": 20617304, "node_id": "MDQ6VXNlcjIwNjE3MzA0", "avatar_url": "https://avatars3.githubusercontent.com/u/20617304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jw447", "html_url": "https://github.com/jw447", "followers_url": "https://api.github.com/users/jw447/followers", "following_url": "https://api.github.com/users/jw447/following{/other_user}", "gists_url": "https://api.github.com/users/jw447/gists{/gist_id}", "starred_url": "https://api.github.com/users/jw447/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jw447/subscriptions", "organizations_url": "https://api.github.com/users/jw447/orgs", "repos_url": "https://api.github.com/users/jw447/repos", "events_url": "https://api.github.com/users/jw447/events{/privacy}", "received_events_url": "https://api.github.com/users/jw447/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-17T00:44:09Z", "updated_at": "2017-03-21T16:45:59Z", "closed_at": "2017-03-21T16:45:59Z", "author_association": "NONE", "body_html": "<p>I am running Tensor-flow on Google compute engine instances and I met with this problem when the training period is finished (after step 9990).</p>\n<pre><code>2017-03-17 00:24:23.021298: step 9980, loss = 0.72 (242.4 examples/sec; 0.264 sec/batch)\n2017-03-17 00:24:34.693612: step 9990, loss = 0.79 (208.4 examples/sec; 0.307 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n</code></pre>\n<p>Can anyone identify this problem and let me know how to fix it?</p>", "body_text": "I am running Tensor-flow on Google compute engine instances and I met with this problem when the training period is finished (after step 9990).\n2017-03-17 00:24:23.021298: step 9980, loss = 0.72 (242.4 examples/sec; 0.264 sec/batch)\n2017-03-17 00:24:34.693612: step 9990, loss = 0.79 (208.4 examples/sec; 0.307 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n\nCan anyone identify this problem and let me know how to fix it?", "body": "I am running Tensor-flow on Google compute engine instances and I met with this problem when the training period is finished (after step 9990).\r\n```\r\n2017-03-17 00:24:23.021298: step 9980, loss = 0.72 (242.4 examples/sec; 0.264 sec/batch)\r\n2017-03-17 00:24:34.693612: step 9990, loss = 0.79 (208.4 examples/sec; 0.307 sec/batch)\r\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_DEINITIALIZED\r\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\r\nAborted (core dumped)\r\n```\r\nCan anyone identify this problem and let me know how to fix it?"}