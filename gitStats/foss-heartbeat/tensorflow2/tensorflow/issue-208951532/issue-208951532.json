{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7707", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7707/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7707/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7707/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7707", "id": 208951532, "node_id": "MDU6SXNzdWUyMDg5NTE1MzI=", "number": 7707, "title": "estimator with batch size and data feeding", "user": {"login": "agniszczotka", "id": 25079800, "node_id": "MDQ6VXNlcjI1MDc5ODAw", "avatar_url": "https://avatars0.githubusercontent.com/u/25079800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agniszczotka", "html_url": "https://github.com/agniszczotka", "followers_url": "https://api.github.com/users/agniszczotka/followers", "following_url": "https://api.github.com/users/agniszczotka/following{/other_user}", "gists_url": "https://api.github.com/users/agniszczotka/gists{/gist_id}", "starred_url": "https://api.github.com/users/agniszczotka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agniszczotka/subscriptions", "organizations_url": "https://api.github.com/users/agniszczotka/orgs", "repos_url": "https://api.github.com/users/agniszczotka/repos", "events_url": "https://api.github.com/users/agniszczotka/events{/privacy}", "received_events_url": "https://api.github.com/users/agniszczotka/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-20T18:12:52Z", "updated_at": "2017-02-21T19:50:07Z", "closed_at": "2017-02-21T19:49:59Z", "author_association": "NONE", "body_html": "<p>Could you provide an example of using the high-level API Estimators with placeholders and feeding batches  like for a basic use:<br>\nfor step in xrange(max_steps):<br>\nbatch_of_inputs,batch_of_targets= get_batch_from_disk(step) # e.g. batches are stored as list where step is and index of the list<br>\nfeed_dict = {x:batch_of_inputs,y:batch_of_targets}<br>\n_, loss_value = sess.run([train_op, loss],<br>\nfeed_dict=feed_dict)<br>\nHow to do the same with Estimator API?<br>\nEstimator takes batch_size, steps, input_fuc or feed_fun as an argument and but it is not clear for me how to implement a function which will load data of batch size  e.g. in every iteration from disk?</p>", "body_text": "Could you provide an example of using the high-level API Estimators with placeholders and feeding batches  like for a basic use:\nfor step in xrange(max_steps):\nbatch_of_inputs,batch_of_targets= get_batch_from_disk(step) # e.g. batches are stored as list where step is and index of the list\nfeed_dict = {x:batch_of_inputs,y:batch_of_targets}\n_, loss_value = sess.run([train_op, loss],\nfeed_dict=feed_dict)\nHow to do the same with Estimator API?\nEstimator takes batch_size, steps, input_fuc or feed_fun as an argument and but it is not clear for me how to implement a function which will load data of batch size  e.g. in every iteration from disk?", "body": "Could you provide an example of using the high-level API Estimators with placeholders and feeding batches  like for a basic use:\r\nfor step in xrange(max_steps):\r\n   batch_of_inputs,batch_of_targets= get_batch_from_disk(step) # e.g. batches are stored as list where step is and index of the list\r\n    feed_dict = {x:batch_of_inputs,y:batch_of_targets}\r\n    _, loss_value = sess.run([train_op, loss],\r\n                             feed_dict=feed_dict)\r\nHow to do the same with Estimator API?\r\nEstimator takes batch_size, steps, input_fuc or feed_fun as an argument and but it is not clear for me how to implement a function which will load data of batch size  e.g. in every iteration from disk?"}