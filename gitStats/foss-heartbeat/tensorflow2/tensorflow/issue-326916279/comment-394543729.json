{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/394543729", "html_url": "https://github.com/tensorflow/tensorflow/issues/19588#issuecomment-394543729", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19588", "id": 394543729, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDU0MzcyOQ==", "user": {"login": "huangynn", "id": 12636388, "node_id": "MDQ6VXNlcjEyNjM2Mzg4", "avatar_url": "https://avatars2.githubusercontent.com/u/12636388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huangynn", "html_url": "https://github.com/huangynn", "followers_url": "https://api.github.com/users/huangynn/followers", "following_url": "https://api.github.com/users/huangynn/following{/other_user}", "gists_url": "https://api.github.com/users/huangynn/gists{/gist_id}", "starred_url": "https://api.github.com/users/huangynn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huangynn/subscriptions", "organizations_url": "https://api.github.com/users/huangynn/orgs", "repos_url": "https://api.github.com/users/huangynn/repos", "events_url": "https://api.github.com/users/huangynn/events{/privacy}", "received_events_url": "https://api.github.com/users/huangynn/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-05T00:39:54Z", "updated_at": "2018-06-05T00:39:54Z", "author_association": "NONE", "body_html": "<p>def get_inputs(mode, csv_file, batch_size, label_list, preprocess):<br>\niterator_initializer_hook = IteratorInitializerHook()<br>\ndef inputs():<br>\nis_training = mode==estimator.ModeKeys.TRAIN<br>\nds = tf.data.TextLineDataset(csv_file).skip(1)</p>\n<pre><code>    def classification_parse_line(line):\n        columns = ['img','label']\n        img_name, label = tf.decode_csv(\n            line, \n            record_defaults = [[''],['']]) \n        # assume every pic is rgb\n        image_decoded = tf.image.decode_png(\n            tf.read_file(img_name),\n            channels=3)\n        image = preprocess(image_decoded)\n        \"\"\"image = image_preprocessing_fn(\n            image, \n            image_size,\n            image_size)\"\"\"\n        return image,label\n    \n    cpu_num = multiprocessing.cpu_count()\n    ds = ds.apply(\n        tf.contrib.data.map_and_batch(\n            classification_parse_line,\n            batch_size=batch_size,\n            num_parallel_batches=cpu_num))   \n    ds = ds.prefetch(None)\n    iterator = ds.make_initializable_iterator()\n\n    iterator_initializer_hook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer)\n    return ds\n\nreturn iterator_initializer_hook, inputs\n</code></pre>\n<p>distribution = tf.contrib.distribute.MirroredStrategy()<br>\nconfig = tf.estimator.RunConfig(<br>\nmodel_dir=args.model_dir,<br>\ntf_random_seed=912,<br>\nsave_summary_steps=args.save_summary_steps,<br>\nsave_checkpoints_steps=args.save_interval_steps,<br>\nkeep_checkpoint_max=5*get_num_replicas(),<br>\ntrain_distribute=distribution,<br>\nsession_config=session_config<br>\n)</p>\n<p>classifier = tf.estimator.Estimator(<br>\nmy_model,<br>\nconfig=config,<br>\nparams=params)<br>\nfor epoch in range(args.num_epochs):<br>\nlogger.info('Starting epoch %d / %d' % (<br>\nepoch + 1, args.num_epochs))<br>\nclassifier.train(<br>\ntrain_ds,<br>\nhooks=[train_ds_hook])<br>\nclassifier.evaluate(<br>\nval_ds,<br>\nhooks=[val_ds_hook])</p>", "body_text": "def get_inputs(mode, csv_file, batch_size, label_list, preprocess):\niterator_initializer_hook = IteratorInitializerHook()\ndef inputs():\nis_training = mode==estimator.ModeKeys.TRAIN\nds = tf.data.TextLineDataset(csv_file).skip(1)\n    def classification_parse_line(line):\n        columns = ['img','label']\n        img_name, label = tf.decode_csv(\n            line, \n            record_defaults = [[''],['']]) \n        # assume every pic is rgb\n        image_decoded = tf.image.decode_png(\n            tf.read_file(img_name),\n            channels=3)\n        image = preprocess(image_decoded)\n        \"\"\"image = image_preprocessing_fn(\n            image, \n            image_size,\n            image_size)\"\"\"\n        return image,label\n    \n    cpu_num = multiprocessing.cpu_count()\n    ds = ds.apply(\n        tf.contrib.data.map_and_batch(\n            classification_parse_line,\n            batch_size=batch_size,\n            num_parallel_batches=cpu_num))   \n    ds = ds.prefetch(None)\n    iterator = ds.make_initializable_iterator()\n\n    iterator_initializer_hook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer)\n    return ds\n\nreturn iterator_initializer_hook, inputs\n\ndistribution = tf.contrib.distribute.MirroredStrategy()\nconfig = tf.estimator.RunConfig(\nmodel_dir=args.model_dir,\ntf_random_seed=912,\nsave_summary_steps=args.save_summary_steps,\nsave_checkpoints_steps=args.save_interval_steps,\nkeep_checkpoint_max=5*get_num_replicas(),\ntrain_distribute=distribution,\nsession_config=session_config\n)\nclassifier = tf.estimator.Estimator(\nmy_model,\nconfig=config,\nparams=params)\nfor epoch in range(args.num_epochs):\nlogger.info('Starting epoch %d / %d' % (\nepoch + 1, args.num_epochs))\nclassifier.train(\ntrain_ds,\nhooks=[train_ds_hook])\nclassifier.evaluate(\nval_ds,\nhooks=[val_ds_hook])", "body": "def get_inputs(mode, csv_file, batch_size, label_list, preprocess):\r\n    iterator_initializer_hook = IteratorInitializerHook()\r\n    def inputs():\r\n        is_training = mode==estimator.ModeKeys.TRAIN\r\n        ds = tf.data.TextLineDataset(csv_file).skip(1)   \r\n                \r\n        def classification_parse_line(line):\r\n            columns = ['img','label']\r\n            img_name, label = tf.decode_csv(\r\n                line, \r\n                record_defaults = [[''],['']]) \r\n            # assume every pic is rgb\r\n            image_decoded = tf.image.decode_png(\r\n                tf.read_file(img_name),\r\n                channels=3)\r\n            image = preprocess(image_decoded)\r\n            \"\"\"image = image_preprocessing_fn(\r\n                image, \r\n                image_size,\r\n                image_size)\"\"\"\r\n            return image,label\r\n        \r\n        cpu_num = multiprocessing.cpu_count()\r\n        ds = ds.apply(\r\n            tf.contrib.data.map_and_batch(\r\n                classification_parse_line,\r\n                batch_size=batch_size,\r\n                num_parallel_batches=cpu_num))   \r\n        ds = ds.prefetch(None)\r\n        iterator = ds.make_initializable_iterator()\r\n   \r\n        iterator_initializer_hook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer)\r\n        return ds\r\n    \r\n    return iterator_initializer_hook, inputs\r\n\r\n distribution = tf.contrib.distribute.MirroredStrategy()\r\n config = tf.estimator.RunConfig(\r\n        model_dir=args.model_dir,\r\n        tf_random_seed=912,\r\n        save_summary_steps=args.save_summary_steps,\r\n        save_checkpoints_steps=args.save_interval_steps,\r\n        keep_checkpoint_max=5*get_num_replicas(),\r\n        train_distribute=distribution,\r\n        session_config=session_config\r\n    )\r\n\r\n classifier = tf.estimator.Estimator(\r\n        my_model,\r\n        config=config,\r\n        params=params)\r\n    for epoch in range(args.num_epochs):\r\n        logger.info('Starting epoch %d / %d' % (\r\n            epoch + 1, args.num_epochs))\r\n        classifier.train(\r\n            train_ds,\r\n            hooks=[train_ds_hook])\r\n        classifier.evaluate(\r\n             val_ds,\r\n            hooks=[val_ds_hook])"}