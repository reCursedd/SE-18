{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224439504", "html_url": "https://github.com/tensorflow/tensorflow/issues/2714#issuecomment-224439504", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2714", "id": 224439504, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDQzOTUwNA==", "user": {"login": "zhengwy888", "id": 1190730, "node_id": "MDQ6VXNlcjExOTA3MzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1190730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhengwy888", "html_url": "https://github.com/zhengwy888", "followers_url": "https://api.github.com/users/zhengwy888/followers", "following_url": "https://api.github.com/users/zhengwy888/following{/other_user}", "gists_url": "https://api.github.com/users/zhengwy888/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhengwy888/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhengwy888/subscriptions", "organizations_url": "https://api.github.com/users/zhengwy888/orgs", "repos_url": "https://api.github.com/users/zhengwy888/repos", "events_url": "https://api.github.com/users/zhengwy888/events{/privacy}", "received_events_url": "https://api.github.com/users/zhengwy888/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-07T22:58:04Z", "updated_at": "2016-06-07T22:58:21Z", "author_association": "NONE", "body_html": "<p>in the <code>__call__</code> function of LSTMCell</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>, <span class=\"pl-smi\">state</span>, <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Long short-term memory cell (LSTM).<span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-k\">with</span> vs.variable_scope(scope <span class=\"pl-k\">or</span> <span class=\"pl-c1\">self</span>.scope <span class=\"pl-k\">or</span> <span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__name__</span>):  <span class=\"pl-c\"><span class=\"pl-c\">#</span> \"BasicLSTMCell\"</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Parameters of gates are concatenated into one multiply for efficiency.</span>\n      c, h <span class=\"pl-k\">=</span> array_ops.split(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, state)\n      concat <span class=\"pl-k\">=</span> xnor_linear_tf([inputs, h], <span class=\"pl-c1\">4</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>._num_units, <span class=\"pl-c1\">True</span>,\n              <span class=\"pl-v\">biasBinarized</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>\n              )\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> i = input_gate, j = new_input, f = forget_gate, o = output_gate</span>\n      i, j, f, o <span class=\"pl-k\">=</span> array_ops.split(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, concat)\n\n      sig_activation <span class=\"pl-k\">=</span> sigmoid\n      new_c <span class=\"pl-k\">=</span> tanh(c <span class=\"pl-k\">*</span> sig_activation(f <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>._forget_bias) <span class=\"pl-k\">+</span> sig_activation(i) <span class=\"pl-k\">*</span> (j))\n      new_h <span class=\"pl-k\">=</span> (new_c) <span class=\"pl-k\">*</span> sig_activation(o)\n      <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>._is_training:\n          timestep <span class=\"pl-k\">=</span> get_timestep()\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>i/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), i)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>j/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), j)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>f/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), f)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>o/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), o)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>c/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), c)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>h/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), h)\n          tf.histogram_summary(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x/<span class=\"pl-c1\">%03d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (timestep), inputs)\n\n      <span class=\"pl-k\">return</span> new_h, array_ops.concat(<span class=\"pl-c1\">1</span>, [new_c, new_h])\n</pre></div>", "body_text": "in the __call__ function of LSTMCell\n  def __call__(self, inputs, state, scope=None):\n    \"\"\"Long short-term memory cell (LSTM).\"\"\"\n    with vs.variable_scope(scope or self.scope or type(self).__name__):  # \"BasicLSTMCell\"\n      # Parameters of gates are concatenated into one multiply for efficiency.\n      c, h = array_ops.split(1, 2, state)\n      concat = xnor_linear_tf([inputs, h], 4 * self._num_units, True,\n              biasBinarized=False\n              )\n\n      # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n      i, j, f, o = array_ops.split(1, 4, concat)\n\n      sig_activation = sigmoid\n      new_c = tanh(c * sig_activation(f + self._forget_bias) + sig_activation(i) * (j))\n      new_h = (new_c) * sig_activation(o)\n      if self._is_training:\n          timestep = get_timestep()\n          tf.histogram_summary(\"i/%03d\" % (timestep), i)\n          tf.histogram_summary(\"j/%03d\" % (timestep), j)\n          tf.histogram_summary(\"f/%03d\" % (timestep), f)\n          tf.histogram_summary(\"o/%03d\" % (timestep), o)\n          tf.histogram_summary(\"c/%03d\" % (timestep), c)\n          tf.histogram_summary(\"h/%03d\" % (timestep), h)\n          tf.histogram_summary(\"x/%03d\" % (timestep), inputs)\n\n      return new_h, array_ops.concat(1, [new_c, new_h])", "body": "in the `__call__` function of LSTMCell\n\n``` python\n  def __call__(self, inputs, state, scope=None):\n    \"\"\"Long short-term memory cell (LSTM).\"\"\"\n    with vs.variable_scope(scope or self.scope or type(self).__name__):  # \"BasicLSTMCell\"\n      # Parameters of gates are concatenated into one multiply for efficiency.\n      c, h = array_ops.split(1, 2, state)\n      concat = xnor_linear_tf([inputs, h], 4 * self._num_units, True,\n              biasBinarized=False\n              )\n\n      # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n      i, j, f, o = array_ops.split(1, 4, concat)\n\n      sig_activation = sigmoid\n      new_c = tanh(c * sig_activation(f + self._forget_bias) + sig_activation(i) * (j))\n      new_h = (new_c) * sig_activation(o)\n      if self._is_training:\n          timestep = get_timestep()\n          tf.histogram_summary(\"i/%03d\" % (timestep), i)\n          tf.histogram_summary(\"j/%03d\" % (timestep), j)\n          tf.histogram_summary(\"f/%03d\" % (timestep), f)\n          tf.histogram_summary(\"o/%03d\" % (timestep), o)\n          tf.histogram_summary(\"c/%03d\" % (timestep), c)\n          tf.histogram_summary(\"h/%03d\" % (timestep), h)\n          tf.histogram_summary(\"x/%03d\" % (timestep), inputs)\n\n      return new_h, array_ops.concat(1, [new_c, new_h])\n\n```\n"}