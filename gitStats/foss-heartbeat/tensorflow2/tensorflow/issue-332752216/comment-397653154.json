{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397653154", "html_url": "https://github.com/tensorflow/tensorflow/issues/20059#issuecomment-397653154", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20059", "id": 397653154, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzY1MzE1NA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-15T15:13:07Z", "updated_at": "2018-06-15T15:13:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Ah yes, that argument was only added in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/bf228e1435da0032d2529de93661b742ee8a7048/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/bf228e1435da0032d2529de93661b742ee8a7048\"><tt>bf228e1</tt></a>, so you'd need to upgrade to use it.</p>\n<p>As a proxy however, does it speed up your program if you cut <code>num_parallel_batches</code> down to 1?</p>\n<p>(Incidentlly, the reason we added <code>num_parallel_calls</code> was because on some platforms and with some batch sizes, kicking off <code>batch_size</code> computations would slow things down. The prototype automatic optimizer for <code>map().batch()</code> -&gt; <code>map_and_batch()</code> (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/bab05a2191383b3c66e9ea9ee192aef0aa36c218/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/bab05a2191383b3c66e9ea9ee192aef0aa36c218\"><tt>bab05a2</tt></a>) uses <code>num_parallel_calls</code> to keep the degree of parallelism the same before and after the rewrite.)</p>", "body_text": "Ah yes, that argument was only added in bf228e1, so you'd need to upgrade to use it.\nAs a proxy however, does it speed up your program if you cut num_parallel_batches down to 1?\n(Incidentlly, the reason we added num_parallel_calls was because on some platforms and with some batch sizes, kicking off batch_size computations would slow things down. The prototype automatic optimizer for map().batch() -> map_and_batch() (bab05a2) uses num_parallel_calls to keep the degree of parallelism the same before and after the rewrite.)", "body": "Ah yes, that argument was only added in bf228e1435da0032d2529de93661b742ee8a7048, so you'd need to upgrade to use it.\r\n\r\nAs a proxy however, does it speed up your program if you cut `num_parallel_batches` down to 1?\r\n\r\n(Incidentlly, the reason we added `num_parallel_calls` was because on some platforms and with some batch sizes, kicking off `batch_size` computations would slow things down. The prototype automatic optimizer for `map().batch()` -> `map_and_batch()` (bab05a2191383b3c66e9ea9ee192aef0aa36c218) uses `num_parallel_calls` to keep the degree of parallelism the same before and after the rewrite.)"}