{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/373569079", "html_url": "https://github.com/tensorflow/tensorflow/issues/8151#issuecomment-373569079", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8151", "id": 373569079, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzU2OTA3OQ==", "user": {"login": "simonkhan12ka4", "id": 36461948, "node_id": "MDQ6VXNlcjM2NDYxOTQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/36461948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonkhan12ka4", "html_url": "https://github.com/simonkhan12ka4", "followers_url": "https://api.github.com/users/simonkhan12ka4/followers", "following_url": "https://api.github.com/users/simonkhan12ka4/following{/other_user}", "gists_url": "https://api.github.com/users/simonkhan12ka4/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonkhan12ka4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonkhan12ka4/subscriptions", "organizations_url": "https://api.github.com/users/simonkhan12ka4/orgs", "repos_url": "https://api.github.com/users/simonkhan12ka4/repos", "events_url": "https://api.github.com/users/simonkhan12ka4/events{/privacy}", "received_events_url": "https://api.github.com/users/simonkhan12ka4/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-16T00:53:31Z", "updated_at": "2018-03-16T00:53:31Z", "author_association": "NONE", "body_html": "<p>i get this error for my code  can somebody help?<br>\nerror<br>\n[[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_Placeholder_0_0, weights/read)]]</p>\n<p>#from tensorflow.python.client import device_lib<br>\n#print(device_lib.list_local_devices())</p>\n<p>import os<br>\nimport time<br>\nimport math<br>\nimport numpy as np<br>\nimport tensorflow as tf<br>\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'</p>\n<h1>Load the CIFAR10 dataset</h1>\n<p>from keras.datasets import cifar10<br>\nbaseDir = os.path.dirname(os.path.abspath('<strong>file</strong>')) + '/'<br>\nclassesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']</p>\n<h1>Select device</h1>\n<p>deviceType = \"/cpu:0\"</p>\n<p>#def train():<br>\n(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()<br>\nxVal = xTrain[49000:, :].astype( np.float )<br>\nyVal = np.squeeze( yTrain[49000:, :] )<br>\nxTrain = xTrain[:49000, :].astype( np.float )<br>\nyTrain = np.squeeze( yTrain[:49000, :] )<br>\nyTest = np.squeeze( yTest )<br>\nxTest = xTest.astype( np.float )<br>\nprint( 'Train image shape:    {0}'.format( xTrain.shape ) )<br>\nprint( 'Train label shape:    {0}'.format( yTrain.shape ) )<br>\nprint( 'Validate image shape: {0}'.format( xVal.shape ) )<br>\nprint( 'Validate label shape: {0}'.format( yVal.shape ) )<br>\nprint( 'Test image shape:     {0}'.format( xTest.shape ) )<br>\nprint( 'Test label shape:     {0}'.format( yTest.shape ) )</p>\n<p>batch_size = 100<br>\nlearning_rate = 0.0000006<br>\nmax_steps = 1100</p>\n<p>meanImage = np.mean( xTrain, axis=0 )<br>\nxTrain -= meanImage<br>\nxVal -= meanImage<br>\nxTest -= meanImage<br>\ntf.reset_default_graph()<br>\nwith tf.device( deviceType ):<br>\nx = tf.placeholder( tf.float32, [None, 32,32,3] )<br>\ny= tf.placeholder( tf.int64, [None] )<br>\nfilter = tf.get_variable( 'weights', [7, 7, 3, 64],initializer=tf.truncated_normal_initializer( stddev=5e-2, dtype=tf.float32 ),<br>\ndtype=tf.float32 )</p>\n<pre><code>conv1 = tf.nn.conv2d(x, filter, strides=[1,1,1,1], padding=\"SAME\") # Stride [batch, height, width, channels]\nconv1=tf.nn.relu(conv1)\nconv1 = tf.layers.max_pooling2d( conv1, 2, 2 )\nfc1 = tf.contrib.layers.flatten( conv1 )\nfc1 = tf.layers.dense( fc1, 1024 )\nfc1 = tf.nn.relu( fc1 )\nyOut = tf.layers.dense( fc1, 10 )\n\n# Define Loss\ntotalLoss = tf.losses.hinge_loss( tf.one_hot( y, 10 ), logits=yOut )\nmeanLoss = tf.reduce_mean( totalLoss )\n\n# Define Optimizer\noptimizer = tf.train.AdamOptimizer( 5e-4 )\ntrainStep = optimizer.minimize( meanLoss )\n\n# Define correct Prediction and accuracy\ncorrectPrediction = tf.equal( tf.argmax( yOut, 1 ), y )\naccuracy = tf.reduce_mean( tf.cast( correctPrediction, tf.float32 ) )\nlossHistory=[]\n\nwith tf.Session()as sess:\n    sess.run( tf.global_variables_initializer() )\n    for i in range( max_steps):\n\n        s = np.arange( xTrain.shape[0] )\n        np.random.shuffle( s )\n        xTr = xTrain[s]\n        yTr = yTrain[s]\n        batch_xs = xTr[:100]\n        batch_ys = yTr[:100]\n        main_loss, _ = sess.run( [meanLoss, trainStep],\n                                 feed_dict=({x: batch_xs, y: batch_ys}) )\n        train_accuracy = sess.run( accuracy, feed_dict={x: xTrain, y: yTrain} )\n        test_accuracy = sess.run( accuracy, feed_dict={x: xTest, y: yTest} )\n\n        lossHistory.append( main_loss )\n        if i % 100 == 0 and len( lossHistory ) is not 0:\n            print( 'Loop {0} loss {1} '.format( i, lossHistory[i] ) )\n            print( 'Train_Accuracy {0} Test_Accuracy {1}'.format( train_accuracy, test_accuracy ) )\n</code></pre>\n<h1>Train Model</h1>\n<pre><code>            # def train():\n</code></pre>\n<h1>(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()</h1>\n<h1>xVal = xTrain[49000:, :].astype( np.float )</h1>\n<h1>yVal = np.squeeze( yTrain[49000:, :] )</h1>\n<h1>xTrain = xTrain[:49000, :].astype( np.float )</h1>\n<h1>yTrain = np.squeeze( yTrain[:49000, :] )</h1>\n<h1>yTest = np.squeeze( yTest )</h1>\n<h1>xTest = xTest.astype( np.float )</h1>\n<pre><code># batch_size = 10\n# learning_rate = 0.0000006\n# max_steps = 1100\n# print( 'Train image shape:    {0}'.format( xTrain.shape ) )\n# print( 'Train label shape:    {0}'.format( yTrain.shape ) )\n# print( 'Validate image shape: {0}'.format( xVal.shape ) )\n# print( 'Validate label shape: {0}'.format( yVal.shape ) )\n# print( 'Test image shape:     {0}'.format( xTest.shape ) )\n# print( 'Test label shape:     {0}'.format( yTest.shape ) )\n#\n# meanImage = np.mean( xTrain, axis=0 )\n# xTrain -= meanImage\n# xVal -= meanImage\n# xTest -= meanImage\n</code></pre>\n<h1># Reshape data from channel to rows</h1>\n<h1>xTrain = np.reshape( xTrain, (xTrain.shape[0], -1) )</h1>\n<h1>xVal = np.reshape( xVal, (xVal.shape[0], -1) )</h1>\n<h1>xTest = np.reshape( xTest, (xTest.shape[0], -1) )</h1>\n<h1></h1>\n<h1># Add bias dimension columns</h1>\n<h1></h1>\n<h1>print( 'Train image shape after add bias column:   {0}'.format( xTrain.shape ) )</h1>\n<h1>print( 'Val image shape after add bias column:     {0}'.format( xVal.shape ) )</h1>\n<h1>print( 'Test image shape after add bias column:    {0}'.format( xTest.shape ) )</h1>\n<h1></h1>\n<h1>image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )</h1>\n<h1></h1>\n<h1>#label_holder = tf.placeholder( tf.int64, shape=[None] )</h1>\n<h1>label_holder=tf.placeholder(tf.int64, [None])</h1>\n<h1></h1>\n<h1>weight = tf.Variable( tf.zeros( [3072, 10] ), name='weights' )</h1>\n<h1>bias = tf.Variable( tf.zeros( [10] ), name='bias' )</h1>\n<h1></h1>\n<h1># Define the classifier's result</h1>\n<h1>logits = tf.matmul( image_holder, weight ) + bias</h1>\n<h1></h1>\n<h1>loss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits,</h1>\n<h1>labels=label_holder ) )</h1>\n<h1></h1>\n<h1># Define the training operation</h1>\n<h1>train_step = tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )</h1>\n<h1></h1>\n<h1>lossHistory = []</h1>\n<h1>correct_prediction = tf.equal( tf.argmax( logits, 1 ), label_holder )</h1>\n<h1></h1>\n<h1># Operation calculating the accuracy of our predictions</h1>\n<h1>accuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )</h1>\n<pre><code>#saver = tf.train.Saver()\n\n\n    # cwd = os.getcwd()\n    # saver_route = saver.save( sess, cwd + \"/model/model.ckpt\" )\n    # print( \"Model saved in this directory: %s\" % saver_route )\n    #pass\n</code></pre>\n<h1>print ('Real label is:', np.argmax(yTest[num]))</h1>\n<h1>print ('Neural Network predicted', (classification[0]))</h1>\n<h1>import string</h1>\n<h1></h1>\n<h1></h1>\n<h1>def test(args):</h1>\n<h1>classnames = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']</h1>\n<h1></h1>\n<h1>image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )</h1>\n<h1>img = cv2.imread( args )</h1>\n<h1>print (img.shape)</h1>\n<h1></h1>\n<h1>img = img.reshape( (1, img.shape[0] * img.shape[1] * img.shape[2]) )</h1>\n<h1>#img = img.reshape (1,3072)</h1>\n<h1>print (img)</h1>\n<h1></h1>\n<h1>img = cv2.resize( img, (3072, 1) )</h1>\n<h1>#print (img.shape)</h1>\n<h1>img = img.astype( np.float32 )</h1>\n<h1>print (img)</h1>\n<h1>cwd = os.getcwd()</h1>\n<h1></h1>\n<h1>with tf.Session() as sess:</h1>\n<h1>model = tf.train.import_meta_graph( cwd + \"/model/model.ckpt.meta\", clear_devices=True )</h1>\n<h1>model.restore( sess, tf.train.latest_checkpoint( cwd + \"/model/\" ) )</h1>\n<h1>weight = sess.run( 'weights:0' )</h1>\n<h1></h1>\n<h1>bias = sess.run( 'bias:0' )</h1>\n<h1>logits = tf.matmul( image_holder, weight ) + bias</h1>\n<h1>prediction = tf.nn.softmax( logits )</h1>\n<h1></h1>\n<h1>answer= sess.run( prediction, feed_dict={image_holder: img} )</h1>\n<h1>print (answer.shape)</h1>\n<h1>print (answer)</h1>\n<h1></h1>\n<h1>answer = answer.reshape(-1)</h1>\n<h1>print (answer.shape)</h1>\n<h1>print(answer)</h1>\n<h1></h1>\n<h1>score= answer.argmax(axis=0)</h1>\n<h1>print(score)</h1>\n<h1></h1>\n<h1>print( classnames[score] )</h1>\n<h1>pass</h1>\n<h1></h1>\n<h1></h1>\n<h1>def main(argv):</h1>\n<h1>if str( argv[0] ) == 'train':</h1>\n<h1>train()</h1>\n<h1>return</h1>\n<h1></h1>\n<h1>if str( argv[0] ) == 'test':</h1>\n<h1>test( str( argv[1] ) )</h1>\n<h1></h1>\n<h1></h1>\n<h1></h1>\n<h1></h1>\n<h1></h1>\n<h1>if <strong>name</strong> == '<strong>main</strong>':</h1>\n<h1>main( sys.argv[1:] )</h1>\n<h1></h1>\n<h1></h1>", "body_text": "i get this error for my code  can somebody help?\nerror\n[[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_Placeholder_0_0, weights/read)]]\n#from tensorflow.python.client import device_lib\n#print(device_lib.list_local_devices())\nimport os\nimport time\nimport math\nimport numpy as np\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nLoad the CIFAR10 dataset\nfrom keras.datasets import cifar10\nbaseDir = os.path.dirname(os.path.abspath('file')) + '/'\nclassesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\nSelect device\ndeviceType = \"/cpu:0\"\n#def train():\n(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\nxVal = xTrain[49000:, :].astype( np.float )\nyVal = np.squeeze( yTrain[49000:, :] )\nxTrain = xTrain[:49000, :].astype( np.float )\nyTrain = np.squeeze( yTrain[:49000, :] )\nyTest = np.squeeze( yTest )\nxTest = xTest.astype( np.float )\nprint( 'Train image shape:    {0}'.format( xTrain.shape ) )\nprint( 'Train label shape:    {0}'.format( yTrain.shape ) )\nprint( 'Validate image shape: {0}'.format( xVal.shape ) )\nprint( 'Validate label shape: {0}'.format( yVal.shape ) )\nprint( 'Test image shape:     {0}'.format( xTest.shape ) )\nprint( 'Test label shape:     {0}'.format( yTest.shape ) )\nbatch_size = 100\nlearning_rate = 0.0000006\nmax_steps = 1100\nmeanImage = np.mean( xTrain, axis=0 )\nxTrain -= meanImage\nxVal -= meanImage\nxTest -= meanImage\ntf.reset_default_graph()\nwith tf.device( deviceType ):\nx = tf.placeholder( tf.float32, [None, 32,32,3] )\ny= tf.placeholder( tf.int64, [None] )\nfilter = tf.get_variable( 'weights', [7, 7, 3, 64],initializer=tf.truncated_normal_initializer( stddev=5e-2, dtype=tf.float32 ),\ndtype=tf.float32 )\nconv1 = tf.nn.conv2d(x, filter, strides=[1,1,1,1], padding=\"SAME\") # Stride [batch, height, width, channels]\nconv1=tf.nn.relu(conv1)\nconv1 = tf.layers.max_pooling2d( conv1, 2, 2 )\nfc1 = tf.contrib.layers.flatten( conv1 )\nfc1 = tf.layers.dense( fc1, 1024 )\nfc1 = tf.nn.relu( fc1 )\nyOut = tf.layers.dense( fc1, 10 )\n\n# Define Loss\ntotalLoss = tf.losses.hinge_loss( tf.one_hot( y, 10 ), logits=yOut )\nmeanLoss = tf.reduce_mean( totalLoss )\n\n# Define Optimizer\noptimizer = tf.train.AdamOptimizer( 5e-4 )\ntrainStep = optimizer.minimize( meanLoss )\n\n# Define correct Prediction and accuracy\ncorrectPrediction = tf.equal( tf.argmax( yOut, 1 ), y )\naccuracy = tf.reduce_mean( tf.cast( correctPrediction, tf.float32 ) )\nlossHistory=[]\n\nwith tf.Session()as sess:\n    sess.run( tf.global_variables_initializer() )\n    for i in range( max_steps):\n\n        s = np.arange( xTrain.shape[0] )\n        np.random.shuffle( s )\n        xTr = xTrain[s]\n        yTr = yTrain[s]\n        batch_xs = xTr[:100]\n        batch_ys = yTr[:100]\n        main_loss, _ = sess.run( [meanLoss, trainStep],\n                                 feed_dict=({x: batch_xs, y: batch_ys}) )\n        train_accuracy = sess.run( accuracy, feed_dict={x: xTrain, y: yTrain} )\n        test_accuracy = sess.run( accuracy, feed_dict={x: xTest, y: yTest} )\n\n        lossHistory.append( main_loss )\n        if i % 100 == 0 and len( lossHistory ) is not 0:\n            print( 'Loop {0} loss {1} '.format( i, lossHistory[i] ) )\n            print( 'Train_Accuracy {0} Test_Accuracy {1}'.format( train_accuracy, test_accuracy ) )\n\nTrain Model\n            # def train():\n\n(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\nxVal = xTrain[49000:, :].astype( np.float )\nyVal = np.squeeze( yTrain[49000:, :] )\nxTrain = xTrain[:49000, :].astype( np.float )\nyTrain = np.squeeze( yTrain[:49000, :] )\nyTest = np.squeeze( yTest )\nxTest = xTest.astype( np.float )\n# batch_size = 10\n# learning_rate = 0.0000006\n# max_steps = 1100\n# print( 'Train image shape:    {0}'.format( xTrain.shape ) )\n# print( 'Train label shape:    {0}'.format( yTrain.shape ) )\n# print( 'Validate image shape: {0}'.format( xVal.shape ) )\n# print( 'Validate label shape: {0}'.format( yVal.shape ) )\n# print( 'Test image shape:     {0}'.format( xTest.shape ) )\n# print( 'Test label shape:     {0}'.format( yTest.shape ) )\n#\n# meanImage = np.mean( xTrain, axis=0 )\n# xTrain -= meanImage\n# xVal -= meanImage\n# xTest -= meanImage\n\n# Reshape data from channel to rows\nxTrain = np.reshape( xTrain, (xTrain.shape[0], -1) )\nxVal = np.reshape( xVal, (xVal.shape[0], -1) )\nxTest = np.reshape( xTest, (xTest.shape[0], -1) )\n\n# Add bias dimension columns\n\nprint( 'Train image shape after add bias column:   {0}'.format( xTrain.shape ) )\nprint( 'Val image shape after add bias column:     {0}'.format( xVal.shape ) )\nprint( 'Test image shape after add bias column:    {0}'.format( xTest.shape ) )\n\nimage_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\n\n#label_holder = tf.placeholder( tf.int64, shape=[None] )\nlabel_holder=tf.placeholder(tf.int64, [None])\n\nweight = tf.Variable( tf.zeros( [3072, 10] ), name='weights' )\nbias = tf.Variable( tf.zeros( [10] ), name='bias' )\n\n# Define the classifier's result\nlogits = tf.matmul( image_holder, weight ) + bias\n\nloss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits,\nlabels=label_holder ) )\n\n# Define the training operation\ntrain_step = tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )\n\nlossHistory = []\ncorrect_prediction = tf.equal( tf.argmax( logits, 1 ), label_holder )\n\n# Operation calculating the accuracy of our predictions\naccuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\n#saver = tf.train.Saver()\n\n\n    # cwd = os.getcwd()\n    # saver_route = saver.save( sess, cwd + \"/model/model.ckpt\" )\n    # print( \"Model saved in this directory: %s\" % saver_route )\n    #pass\n\nprint ('Real label is:', np.argmax(yTest[num]))\nprint ('Neural Network predicted', (classification[0]))\nimport string\n\n\ndef test(args):\nclassnames = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\nimage_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\nimg = cv2.imread( args )\nprint (img.shape)\n\nimg = img.reshape( (1, img.shape[0] * img.shape[1] * img.shape[2]) )\n#img = img.reshape (1,3072)\nprint (img)\n\nimg = cv2.resize( img, (3072, 1) )\n#print (img.shape)\nimg = img.astype( np.float32 )\nprint (img)\ncwd = os.getcwd()\n\nwith tf.Session() as sess:\nmodel = tf.train.import_meta_graph( cwd + \"/model/model.ckpt.meta\", clear_devices=True )\nmodel.restore( sess, tf.train.latest_checkpoint( cwd + \"/model/\" ) )\nweight = sess.run( 'weights:0' )\n\nbias = sess.run( 'bias:0' )\nlogits = tf.matmul( image_holder, weight ) + bias\nprediction = tf.nn.softmax( logits )\n\nanswer= sess.run( prediction, feed_dict={image_holder: img} )\nprint (answer.shape)\nprint (answer)\n\nanswer = answer.reshape(-1)\nprint (answer.shape)\nprint(answer)\n\nscore= answer.argmax(axis=0)\nprint(score)\n\nprint( classnames[score] )\npass\n\n\ndef main(argv):\nif str( argv[0] ) == 'train':\ntrain()\nreturn\n\nif str( argv[0] ) == 'test':\ntest( str( argv[1] ) )\n\n\n\n\n\nif name == 'main':\nmain( sys.argv[1:] )", "body": "i get this error for my code  can somebody help?\r\nerror\r\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_Placeholder_0_0, weights/read)]]\r\n\r\n#from tensorflow.python.client import device_lib\r\n#print(device_lib.list_local_devices())\r\n\r\nimport os\r\nimport time\r\nimport math\r\nimport numpy as np\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n\r\n# Load the CIFAR10 dataset\r\nfrom keras.datasets import cifar10\r\nbaseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\r\nclassesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n\r\n\r\n# Select device\r\ndeviceType = \"/cpu:0\"\r\n\r\n\r\n#def train():\r\n(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\r\nxVal = xTrain[49000:, :].astype( np.float )\r\nyVal = np.squeeze( yTrain[49000:, :] )\r\nxTrain = xTrain[:49000, :].astype( np.float )\r\nyTrain = np.squeeze( yTrain[:49000, :] )\r\nyTest = np.squeeze( yTest )\r\nxTest = xTest.astype( np.float )\r\nprint( 'Train image shape:    {0}'.format( xTrain.shape ) )\r\nprint( 'Train label shape:    {0}'.format( yTrain.shape ) )\r\nprint( 'Validate image shape: {0}'.format( xVal.shape ) )\r\nprint( 'Validate label shape: {0}'.format( yVal.shape ) )\r\nprint( 'Test image shape:     {0}'.format( xTest.shape ) )\r\nprint( 'Test label shape:     {0}'.format( yTest.shape ) )\r\n\r\nbatch_size = 100\r\nlearning_rate = 0.0000006\r\nmax_steps = 1100\r\n\r\nmeanImage = np.mean( xTrain, axis=0 )\r\nxTrain -= meanImage\r\nxVal -= meanImage\r\nxTest -= meanImage\r\ntf.reset_default_graph()\r\nwith tf.device( deviceType ):\r\n    x = tf.placeholder( tf.float32, [None, 32,32,3] )\r\n    y= tf.placeholder( tf.int64, [None] )\r\n    filter = tf.get_variable( 'weights', [7, 7, 3, 64],initializer=tf.truncated_normal_initializer( stddev=5e-2, dtype=tf.float32 ),\r\n                              dtype=tf.float32 )\r\n\r\n    conv1 = tf.nn.conv2d(x, filter, strides=[1,1,1,1], padding=\"SAME\") # Stride [batch, height, width, channels]\r\n    conv1=tf.nn.relu(conv1)\r\n    conv1 = tf.layers.max_pooling2d( conv1, 2, 2 )\r\n    fc1 = tf.contrib.layers.flatten( conv1 )\r\n    fc1 = tf.layers.dense( fc1, 1024 )\r\n    fc1 = tf.nn.relu( fc1 )\r\n    yOut = tf.layers.dense( fc1, 10 )\r\n\r\n    # Define Loss\r\n    totalLoss = tf.losses.hinge_loss( tf.one_hot( y, 10 ), logits=yOut )\r\n    meanLoss = tf.reduce_mean( totalLoss )\r\n\r\n    # Define Optimizer\r\n    optimizer = tf.train.AdamOptimizer( 5e-4 )\r\n    trainStep = optimizer.minimize( meanLoss )\r\n\r\n    # Define correct Prediction and accuracy\r\n    correctPrediction = tf.equal( tf.argmax( yOut, 1 ), y )\r\n    accuracy = tf.reduce_mean( tf.cast( correctPrediction, tf.float32 ) )\r\n    lossHistory=[]\r\n\r\n    with tf.Session()as sess:\r\n        sess.run( tf.global_variables_initializer() )\r\n        for i in range( max_steps):\r\n\r\n            s = np.arange( xTrain.shape[0] )\r\n            np.random.shuffle( s )\r\n            xTr = xTrain[s]\r\n            yTr = yTrain[s]\r\n            batch_xs = xTr[:100]\r\n            batch_ys = yTr[:100]\r\n            main_loss, _ = sess.run( [meanLoss, trainStep],\r\n                                     feed_dict=({x: batch_xs, y: batch_ys}) )\r\n            train_accuracy = sess.run( accuracy, feed_dict={x: xTrain, y: yTrain} )\r\n            test_accuracy = sess.run( accuracy, feed_dict={x: xTest, y: yTest} )\r\n\r\n            lossHistory.append( main_loss )\r\n            if i % 100 == 0 and len( lossHistory ) is not 0:\r\n                print( 'Loop {0} loss {1} '.format( i, lossHistory[i] ) )\r\n                print( 'Train_Accuracy {0} Test_Accuracy {1}'.format( train_accuracy, test_accuracy ) )\r\n\r\n# Train Model\r\n\r\n                # def train():\r\n#     (xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\r\n#     xVal = xTrain[49000:, :].astype( np.float )\r\n#     yVal = np.squeeze( yTrain[49000:, :] )\r\n#     xTrain = xTrain[:49000, :].astype( np.float )\r\n#     yTrain = np.squeeze( yTrain[:49000, :] )\r\n#     yTest = np.squeeze( yTest )\r\n#     xTest = xTest.astype( np.float )\r\n\r\n    # batch_size = 10\r\n    # learning_rate = 0.0000006\r\n    # max_steps = 1100\r\n    # print( 'Train image shape:    {0}'.format( xTrain.shape ) )\r\n    # print( 'Train label shape:    {0}'.format( yTrain.shape ) )\r\n    # print( 'Validate image shape: {0}'.format( xVal.shape ) )\r\n    # print( 'Validate label shape: {0}'.format( yVal.shape ) )\r\n    # print( 'Test image shape:     {0}'.format( xTest.shape ) )\r\n    # print( 'Test label shape:     {0}'.format( yTest.shape ) )\r\n    #\r\n    # meanImage = np.mean( xTrain, axis=0 )\r\n    # xTrain -= meanImage\r\n    # xVal -= meanImage\r\n    # xTest -= meanImage\r\n\r\n#     # Reshape data from channel to rows\r\n#     xTrain = np.reshape( xTrain, (xTrain.shape[0], -1) )\r\n#     xVal = np.reshape( xVal, (xVal.shape[0], -1) )\r\n#     xTest = np.reshape( xTest, (xTest.shape[0], -1) )\r\n#\r\n#     # Add bias dimension columns\r\n#\r\n#     print( 'Train image shape after add bias column:   {0}'.format( xTrain.shape ) )\r\n#     print( 'Val image shape after add bias column:     {0}'.format( xVal.shape ) )\r\n#     print( 'Test image shape after add bias column:    {0}'.format( xTest.shape ) )\r\n#\r\n#     image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\r\n#\r\n#     #label_holder = tf.placeholder( tf.int64, shape=[None] )\r\n#     label_holder=tf.placeholder(tf.int64, [None])\r\n#\r\n#     weight = tf.Variable( tf.zeros( [3072, 10] ), name='weights' )\r\n#     bias = tf.Variable( tf.zeros( [10] ), name='bias' )\r\n#\r\n#     # Define the classifier's result\r\n#     logits = tf.matmul( image_holder, weight ) + bias\r\n#\r\n#     loss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits,\r\n#                                                                            labels=label_holder ) )\r\n#\r\n#     # Define the training operation\r\n#     train_step = tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )\r\n#\r\n#     lossHistory = []\r\n#     correct_prediction = tf.equal( tf.argmax( logits, 1 ), label_holder )\r\n#\r\n#     # Operation calculating the accuracy of our predictions\r\n#     accuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\r\n    #saver = tf.train.Saver()\r\n\r\n\r\n        # cwd = os.getcwd()\r\n        # saver_route = saver.save( sess, cwd + \"/model/model.ckpt\" )\r\n        # print( \"Model saved in this directory: %s\" % saver_route )\r\n        #pass\r\n\r\n\r\n# print ('Real label is:', np.argmax(yTest[num]))\r\n# print ('Neural Network predicted', (classification[0]))\r\n# import string\r\n#\r\n#\r\n# def test(args):\r\n#     classnames = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n#\r\n#     image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\r\n#     img = cv2.imread( args )\r\n#     print (img.shape)\r\n#\r\n#     img = img.reshape( (1, img.shape[0] * img.shape[1] * img.shape[2]) )\r\n#     #img = img.reshape (1,3072)\r\n#     print (img)\r\n#\r\n#     img = cv2.resize( img, (3072, 1) )\r\n#     #print (img.shape)\r\n#     img = img.astype( np.float32 )\r\n#     print (img)\r\n#     cwd = os.getcwd()\r\n#\r\n#     with tf.Session() as sess:\r\n#         model = tf.train.import_meta_graph( cwd + \"/model/model.ckpt.meta\", clear_devices=True )\r\n#         model.restore( sess, tf.train.latest_checkpoint( cwd + \"/model/\" ) )\r\n#         weight = sess.run( 'weights:0' )\r\n#\r\n#         bias = sess.run( 'bias:0' )\r\n#         logits = tf.matmul( image_holder, weight ) + bias\r\n#         prediction = tf.nn.softmax( logits )\r\n#\r\n#         answer= sess.run( prediction, feed_dict={image_holder: img} )\r\n#         print (answer.shape)\r\n#         print (answer)\r\n#\r\n#         answer = answer.reshape(-1)\r\n#         print (answer.shape)\r\n#         print(answer)\r\n#\r\n#         score= answer.argmax(axis=0)\r\n#         print(score)\r\n#\r\n#         print( classnames[score] )\r\n#         pass\r\n#\r\n#\r\n# def main(argv):\r\n#     if str( argv[0] ) == 'train':\r\n#         train()\r\n#         return\r\n#\r\n#     if str( argv[0] ) == 'test':\r\n#         test( str( argv[1] ) )\r\n#\r\n#\r\n#\r\n#\r\n#\r\n# if __name__ == '__main__':\r\n#     main( sys.argv[1:] )\r\n#\r\n#\r\n"}