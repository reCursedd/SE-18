{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/196224462", "html_url": "https://github.com/tensorflow/tensorflow/issues/813#issuecomment-196224462", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/813", "id": 196224462, "node_id": "MDEyOklzc3VlQ29tbWVudDE5NjIyNDQ2Mg==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-14T09:31:59Z", "updated_at": "2016-03-14T09:33:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've changed the shape to <code>(10000,)</code> to isolate the overhead from calling that many nodes a bit better.<br>\nResults:</p>\n<pre><code>[2]: %timeit s.run(y)\n10 loops, best of 3: 36.6 ms per loop\n [3]: %timeit np.cumsum(X, axis=0)\nThe slowest run took 8.94 times longer than the fastest. This could mean that an intermediate result is being cached.\n10000 loops, best of 3: 28.2 \u00b5s per loop\n</code></pre>\n<p>So it seems that although there's considerable overhead, it's smaller than the time required to add the length <code>1000</code> vectors above.</p>", "body_text": "I've changed the shape to (10000,) to isolate the overhead from calling that many nodes a bit better.\nResults:\n[2]: %timeit s.run(y)\n10 loops, best of 3: 36.6 ms per loop\n [3]: %timeit np.cumsum(X, axis=0)\nThe slowest run took 8.94 times longer than the fastest. This could mean that an intermediate result is being cached.\n10000 loops, best of 3: 28.2 \u00b5s per loop\n\nSo it seems that although there's considerable overhead, it's smaller than the time required to add the length 1000 vectors above.", "body": "I've changed the shape to `(10000,)` to isolate the overhead from calling that many nodes a bit better.\nResults:\n\n```\n[2]: %timeit s.run(y)\n10 loops, best of 3: 36.6 ms per loop\n [3]: %timeit np.cumsum(X, axis=0)\nThe slowest run took 8.94 times longer than the fastest. This could mean that an intermediate result is being cached.\n10000 loops, best of 3: 28.2 \u00b5s per loop\n```\n\nSo it seems that although there's considerable overhead, it's smaller than the time required to add the length `1000` vectors above.\n"}