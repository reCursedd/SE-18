{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/195835861", "html_url": "https://github.com/tensorflow/tensorflow/issues/813#issuecomment-195835861", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/813", "id": 195835861, "node_id": "MDEyOklzc3VlQ29tbWVudDE5NTgzNTg2MQ==", "user": {"login": "ibab", "id": 890531, "node_id": "MDQ6VXNlcjg5MDUzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/890531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibab", "html_url": "https://github.com/ibab", "followers_url": "https://api.github.com/users/ibab/followers", "following_url": "https://api.github.com/users/ibab/following{/other_user}", "gists_url": "https://api.github.com/users/ibab/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibab/subscriptions", "organizations_url": "https://api.github.com/users/ibab/orgs", "repos_url": "https://api.github.com/users/ibab/repos", "events_url": "https://api.github.com/users/ibab/events{/privacy}", "received_events_url": "https://api.github.com/users/ibab/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-12T23:45:03Z", "updated_at": "2016-03-12T23:45:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've needed <code>cumsum</code> and <code>cumprod</code> ops today and wrote the following based on <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1876772\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/leconteur\">@leconteur</a>'s code above:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">cumsum</span>(<span class=\"pl-smi\">xs</span>):\n    values <span class=\"pl-k\">=</span> tf.unpack(xs)\n    out <span class=\"pl-k\">=</span> []\n    prev <span class=\"pl-k\">=</span> tf.zeros_like(values[<span class=\"pl-c1\">0</span>])\n    <span class=\"pl-k\">for</span> val <span class=\"pl-k\">in</span> values:\n        s <span class=\"pl-k\">=</span> prev <span class=\"pl-k\">+</span> val\n        out.append(s)\n        prev <span class=\"pl-k\">=</span> s\n    result <span class=\"pl-k\">=</span> tf.pack(out)\n    <span class=\"pl-k\">return</span> result</pre></div>\n<p>This seems to give me relatively decent speed:</p>\n<div class=\"highlight highlight-source-python\"><pre>s <span class=\"pl-k\">=</span> tf.Session()\nX <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">10000</span>, <span class=\"pl-c1\">1000</span>))\nv <span class=\"pl-k\">=</span> tf.Variable(X)\ns.run(tf.initialize_all_variables())\ny <span class=\"pl-k\">=</span> cumsum(v)\n\n [<span class=\"pl-c1\">2</span>]: <span class=\"pl-k\">%</span>timeit s.run(y)\n<span class=\"pl-c1\">10</span> loops, best of <span class=\"pl-c1\">3</span>: <span class=\"pl-c1\">110</span> ms per loop\n [<span class=\"pl-c1\">3</span>]: <span class=\"pl-k\">%</span>timeit np.cumsum(X, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n<span class=\"pl-c1\">10</span> loops, best of <span class=\"pl-c1\">3</span>: <span class=\"pl-c1\">80.3</span> ms per loop</pre></div>\n<p>It would still be nice to have dedicated (and parallel?) ops for this, though.<br>\nMaybe <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6969686\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/benoitsteiner\">@benoitsteiner</a> can comment on whether adding an <code>accumulate</code> implementation to Eigen would make sense. I might have time to contribute that.</p>", "body_text": "I've needed cumsum and cumprod ops today and wrote the following based on @leconteur's code above:\nimport tensorflow as tf\n\ndef cumsum(xs):\n    values = tf.unpack(xs)\n    out = []\n    prev = tf.zeros_like(values[0])\n    for val in values:\n        s = prev + val\n        out.append(s)\n        prev = s\n    result = tf.pack(out)\n    return result\nThis seems to give me relatively decent speed:\ns = tf.Session()\nX = np.random.uniform(0, 1, size=(10000, 1000))\nv = tf.Variable(X)\ns.run(tf.initialize_all_variables())\ny = cumsum(v)\n\n [2]: %timeit s.run(y)\n10 loops, best of 3: 110 ms per loop\n [3]: %timeit np.cumsum(X, axis=0)\n10 loops, best of 3: 80.3 ms per loop\nIt would still be nice to have dedicated (and parallel?) ops for this, though.\nMaybe @benoitsteiner can comment on whether adding an accumulate implementation to Eigen would make sense. I might have time to contribute that.", "body": "I've needed `cumsum` and `cumprod` ops today and wrote the following based on @leconteur's code above:\n\n``` python\nimport tensorflow as tf\n\ndef cumsum(xs):\n    values = tf.unpack(xs)\n    out = []\n    prev = tf.zeros_like(values[0])\n    for val in values:\n        s = prev + val\n        out.append(s)\n        prev = s\n    result = tf.pack(out)\n    return result\n```\n\nThis seems to give me relatively decent speed:\n\n``` python\ns = tf.Session()\nX = np.random.uniform(0, 1, size=(10000, 1000))\nv = tf.Variable(X)\ns.run(tf.initialize_all_variables())\ny = cumsum(v)\n\n [2]: %timeit s.run(y)\n10 loops, best of 3: 110 ms per loop\n [3]: %timeit np.cumsum(X, axis=0)\n10 loops, best of 3: 80.3 ms per loop\n```\n\nIt would still be nice to have dedicated (and parallel?) ops for this, though.\nMaybe @benoitsteiner can comment on whether adding an `accumulate` implementation to Eigen would make sense. I might have time to contribute that.\n"}