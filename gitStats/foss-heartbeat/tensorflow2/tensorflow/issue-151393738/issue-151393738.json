{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2130", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2130/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2130/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2130/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2130", "id": 151393738, "node_id": "MDU6SXNzdWUxNTEzOTM3Mzg=", "number": 2130, "title": "coord.request_stop() doesn't stop the threads", "user": {"login": "ivankreso", "id": 2056432, "node_id": "MDQ6VXNlcjIwNTY0MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2056432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivankreso", "html_url": "https://github.com/ivankreso", "followers_url": "https://api.github.com/users/ivankreso/followers", "following_url": "https://api.github.com/users/ivankreso/following{/other_user}", "gists_url": "https://api.github.com/users/ivankreso/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivankreso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivankreso/subscriptions", "organizations_url": "https://api.github.com/users/ivankreso/orgs", "repos_url": "https://api.github.com/users/ivankreso/repos", "events_url": "https://api.github.com/users/ivankreso/events{/privacy}", "received_events_url": "https://api.github.com/users/ivankreso/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-04-27T14:02:15Z", "updated_at": "2017-09-23T03:15:59Z", "closed_at": "2016-04-28T02:49:19Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Arch Linux</p>\n<p>Installed version of CUDA and cuDNN: cuda 7.5 cuDNNv4</p>\n<p>If installed from sources, provide the commit hash:<br>\ncommit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/cf1659d1c233f8ddbee13fd298464d76e58bdccb/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/cf1659d1c233f8ddbee13fd298464d76e58bdccb\"><tt>cf1659d</tt></a></p>\n<h3>Steps to reproduce</h3>\n<pre><code>import tensorflow as tf\n\nqueue_size = 100\nwith tf.Graph().as_default():\n  sess = tf.Session()\n  queue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int32)\n  enqueue_placeholder = tf.placeholder(dtype=tf.int32)\n  enqueue_op = queue.enqueue(enqueue_placeholder)\n  dequeue_op = queue.dequeue()\n  for f in range(queue_size):\n    sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\n  queue.close()\n\n  dequeue_op = tf.reshape(dequeue_op, shape=[1])\n  queue_batch = tf.train.batch([dequeue_op], batch_size=1, num_threads=1, capacity=64)\n\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  for i in range(queue_size):\n    print(sess.run([queue_batch]))\n\n  coord.request_stop()\n  coord.join(threads, stop_grace_period_secs=5)\n  sess.close()\n</code></pre>\n<h3>What have you tried?</h3>\n<p><a href=\"https://www.tensorflow.org/versions/r0.8/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects\" rel=\"nofollow\">https://www.tensorflow.org/versions/r0.8/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects</a></p>\n<p>According to documentation coord.request_stop() should stop the threads but in this case<br>\nwe get a deadlock in coord.join().</p>\n<h3>Logs or other output that would be helpful</h3>\n<pre><code>...\n[array([[97]], dtype=int32)]\n[array([[98]], dtype=int32)]\n[array([[99]], dtype=int32)]\nTraceback (most recent call last):\n  File \"test_queue.py\", line 26, in &lt;module&gt;\n    sess.close()\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3213, in get_controller\n    yield default\n  File \"test_queue.py\", line 25, in &lt;module&gt;\n    coord.join(threads, stop_grace_period_secs=5)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 289, in join\n    \" \".join(stragglers))\nRuntimeError: ('Coordinator stopped with threads still running: %s', 'Thread-1')\n</code></pre>\n<p>If I put sess.close() before coord.join() the threads are killed but there is still a weird warning which should not exist because I called queue.close() before.</p>\n<pre><code>...\nW tensorflow/core/kernels/queue_base.cc:300] _0_fifo_queue: Skipping cancelled dequeue attempt with queue not closed\n</code></pre>", "body_text": "Environment info\nOperating System: Arch Linux\nInstalled version of CUDA and cuDNN: cuda 7.5 cuDNNv4\nIf installed from sources, provide the commit hash:\ncommit cf1659d\nSteps to reproduce\nimport tensorflow as tf\n\nqueue_size = 100\nwith tf.Graph().as_default():\n  sess = tf.Session()\n  queue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int32)\n  enqueue_placeholder = tf.placeholder(dtype=tf.int32)\n  enqueue_op = queue.enqueue(enqueue_placeholder)\n  dequeue_op = queue.dequeue()\n  for f in range(queue_size):\n    sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\n  queue.close()\n\n  dequeue_op = tf.reshape(dequeue_op, shape=[1])\n  queue_batch = tf.train.batch([dequeue_op], batch_size=1, num_threads=1, capacity=64)\n\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  for i in range(queue_size):\n    print(sess.run([queue_batch]))\n\n  coord.request_stop()\n  coord.join(threads, stop_grace_period_secs=5)\n  sess.close()\n\nWhat have you tried?\nhttps://www.tensorflow.org/versions/r0.8/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects\nAccording to documentation coord.request_stop() should stop the threads but in this case\nwe get a deadlock in coord.join().\nLogs or other output that would be helpful\n...\n[array([[97]], dtype=int32)]\n[array([[98]], dtype=int32)]\n[array([[99]], dtype=int32)]\nTraceback (most recent call last):\n  File \"test_queue.py\", line 26, in <module>\n    sess.close()\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3213, in get_controller\n    yield default\n  File \"test_queue.py\", line 25, in <module>\n    coord.join(threads, stop_grace_period_secs=5)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 289, in join\n    \" \".join(stragglers))\nRuntimeError: ('Coordinator stopped with threads still running: %s', 'Thread-1')\n\nIf I put sess.close() before coord.join() the threads are killed but there is still a weird warning which should not exist because I called queue.close() before.\n...\nW tensorflow/core/kernels/queue_base.cc:300] _0_fifo_queue: Skipping cancelled dequeue attempt with queue not closed", "body": "### Environment info\n\nOperating System: Arch Linux\n\nInstalled version of CUDA and cuDNN: cuda 7.5 cuDNNv4\n\nIf installed from sources, provide the commit hash:\ncommit cf1659d1c233f8ddbee13fd298464d76e58bdccb\n### Steps to reproduce\n\n```\nimport tensorflow as tf\n\nqueue_size = 100\nwith tf.Graph().as_default():\n  sess = tf.Session()\n  queue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int32)\n  enqueue_placeholder = tf.placeholder(dtype=tf.int32)\n  enqueue_op = queue.enqueue(enqueue_placeholder)\n  dequeue_op = queue.dequeue()\n  for f in range(queue_size):\n    sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\n  queue.close()\n\n  dequeue_op = tf.reshape(dequeue_op, shape=[1])\n  queue_batch = tf.train.batch([dequeue_op], batch_size=1, num_threads=1, capacity=64)\n\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  for i in range(queue_size):\n    print(sess.run([queue_batch]))\n\n  coord.request_stop()\n  coord.join(threads, stop_grace_period_secs=5)\n  sess.close()\n```\n### What have you tried?\n\nhttps://www.tensorflow.org/versions/r0.8/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects\n\nAccording to documentation coord.request_stop() should stop the threads but in this case\nwe get a deadlock in coord.join().\n### Logs or other output that would be helpful\n\n```\n...\n[array([[97]], dtype=int32)]\n[array([[98]], dtype=int32)]\n[array([[99]], dtype=int32)]\nTraceback (most recent call last):\n  File \"test_queue.py\", line 26, in <module>\n    sess.close()\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3213, in get_controller\n    yield default\n  File \"test_queue.py\", line 25, in <module>\n    coord.join(threads, stop_grace_period_secs=5)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 289, in join\n    \" \".join(stragglers))\nRuntimeError: ('Coordinator stopped with threads still running: %s', 'Thread-1')\n```\n\nIf I put sess.close() before coord.join() the threads are killed but there is still a weird warning which should not exist because I called queue.close() before.\n\n```\n...\nW tensorflow/core/kernels/queue_base.cc:300] _0_fifo_queue: Skipping cancelled dequeue attempt with queue not closed\n```\n"}