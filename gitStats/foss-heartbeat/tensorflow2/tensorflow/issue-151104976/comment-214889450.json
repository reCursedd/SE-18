{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/214889450", "html_url": "https://github.com/tensorflow/tensorflow/issues/2109#issuecomment-214889450", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2109", "id": 214889450, "node_id": "MDEyOklzc3VlQ29tbWVudDIxNDg4OTQ1MA==", "user": {"login": "akors", "id": 3023492, "node_id": "MDQ6VXNlcjMwMjM0OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3023492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akors", "html_url": "https://github.com/akors", "followers_url": "https://api.github.com/users/akors/followers", "following_url": "https://api.github.com/users/akors/following{/other_user}", "gists_url": "https://api.github.com/users/akors/gists{/gist_id}", "starred_url": "https://api.github.com/users/akors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akors/subscriptions", "organizations_url": "https://api.github.com/users/akors/orgs", "repos_url": "https://api.github.com/users/akors/repos", "events_url": "https://api.github.com/users/akors/events{/privacy}", "received_events_url": "https://api.github.com/users/akors/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-26T21:17:04Z", "updated_at": "2016-04-27T07:57:17Z", "author_association": "NONE", "body_html": "<p>Hi. This is my story of how I got TensorFlow to compile on my Fedora 23 machine. Maybe it will be useful for you:</p>\n<h1>How to compile TensorFlow from source on Fedora 23 with a custom compiler.</h1>\n<p>Compiling TensorFlow with GPU support is possible, but a bit tricky on Fedora 23 and up.<br>\nThe compilation requires a specific GCC version which is not available from Fedora repoisitories and specifying the compiler is more complicated than it should be.</p>\n<h2>Compiling GCC</h2>\n<p>For CUDA version 7.5, you need to obtain the source code for GCC version 4.9. You can obtain it from here.</p>\n<p>Next, you need to install GCC compile-time dependencies:</p>\n<pre><code>sudo dnf install mpfr-devel gmp-devel libmpc-devel isl-devel\n</code></pre>\n<p>Now you have to configure the GCC build. For details, check out the <a href=\"https://gcc.gnu.org/install/configure.html\" rel=\"nofollow\">GCC configuration page</a>. I suggest installing into a custom prefix, such as <code>/opt/gcc-4.9</code>. I suggest enabling only C and C++ and skipping the rest of the GCC languages to save time and disk space. The options --with-as, --with-ld and --with-nm are required, because otherwise TensorFlow build will fail, complaining that those binaries cannot be found.</p>\n<pre><code>/configure --prefix=/opt/gcc-4.9 --disable-nls --enable-languages=c,c++ --with-ld=/bin/ld --with-nm=/bin/nm --with-as=/usr/bin/as\n</code></pre>\n<p>When this step is done, you can compile GCC with the following command:</p>\n<pre><code>make -j4\n</code></pre>\n<p>This assumes you want to use 4 processing cores. You can use more or less, or omit the -j option entirely.</p>\n<p>Finally, run as root:</p>\n<pre><code>make install\n</code></pre>\n<h2>Compiling bazel</h2>\n<p>Obtain the bazel source code. You need the current master branch, NOT any of the recent releases.</p>\n<pre><code>git clone https://github.com/bazelbuild/bazel.git\n</code></pre>\n<p>To compile bazel, you need to specify</p>\n<pre><code>export CC=/opt/gcc-4.9/bin/gcc\n./compile\n</code></pre>\n<p>This will produce the bazel binary in <code>path/to/bazel/output/bazel</code></p>\n<h2>Compiling TensorFlow</h2>\n<p>Obtain the TensorFlow source code</p>\n<pre><code>git clone --recurse-submodules https://github.com/tensorflow/tensorflow\n</code></pre>\n<p>Modify the file <code>third_party/gpus/crosstool/CROSSTOOL</code>: Find the toolchain entry where the <code>toolchain_identifier</code>is set to <code>\"local_linux\"</code>. Only change entries here, the rest is irrelevant.</p>\n<p>Replace the following lines:</p>\n<p>cxx_builtin_include_directory: \"/usr/lib/gcc/\"<br>\ncxx_builtin_include_directory: \"/usr/local/include\"</p>\n<p>with the following lines:<br>\ncxx_builtin_include_directory: \"/opt/gcc-4.9/lib/gcc/\"<br>\ncxx_builtin_include_directory: \"/opt/gcc-4.9/local/include\"<br>\ncxx_builtin_include_directory: \"/opt/gcc-4.9/include\"</p>\n<p>Next, run the <code>./configure</code> and set your options. Specify your self-compiled GCC (for me <code>/opt/gcc-4.9/bin/gcc</code>) as the compiler to be used by nvcc.</p>\n<p>To compile the source, use the following command line:</p>\n<pre><code>path/to/bazel/output/bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer\n</code></pre>\n<p>Explanations:</p>\n<ul>\n<li>build: what bazel should do</li>\n<li>-c opt: Don't know, says so in the docu</li>\n<li>--config=cuda: Compile with CUDA support. Don't ask me why you have to specify that again, even though you did so in ./configure.</li>\n<li>--genrule_strategy=standalone: This compiles in \"standalone mode\". Don't ask me what that is, but it's required so that generated output files can find the <code>libcudart.so</code> that they are linked to (see issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"150176807\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2053\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2053/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2053\">#2053</a>).</li>\n<li>--local_resources 4096,4.0,1.0 -j 4: Use at most 4096M of memory, 4.0 CPU's, 1.0 of I/O and 4 threads. This is required so that the compilation doesn't crash due to out-of-memory (I have 8GB of physical memory and 4GB of swap). The 4096 is still a lie, because the compilation still used more - but at least it didn't crash.</li>\n<li>//tensorflow/cc:tutorials_example_trainer: What to build.</li>\n</ul>\n<p>I sincerely hope that this guide will be obsolete very soon, and you can just get cracking without all these workarounds. But for now, this will probably be useful.</p>", "body_text": "Hi. This is my story of how I got TensorFlow to compile on my Fedora 23 machine. Maybe it will be useful for you:\nHow to compile TensorFlow from source on Fedora 23 with a custom compiler.\nCompiling TensorFlow with GPU support is possible, but a bit tricky on Fedora 23 and up.\nThe compilation requires a specific GCC version which is not available from Fedora repoisitories and specifying the compiler is more complicated than it should be.\nCompiling GCC\nFor CUDA version 7.5, you need to obtain the source code for GCC version 4.9. You can obtain it from here.\nNext, you need to install GCC compile-time dependencies:\nsudo dnf install mpfr-devel gmp-devel libmpc-devel isl-devel\n\nNow you have to configure the GCC build. For details, check out the GCC configuration page. I suggest installing into a custom prefix, such as /opt/gcc-4.9. I suggest enabling only C and C++ and skipping the rest of the GCC languages to save time and disk space. The options --with-as, --with-ld and --with-nm are required, because otherwise TensorFlow build will fail, complaining that those binaries cannot be found.\n/configure --prefix=/opt/gcc-4.9 --disable-nls --enable-languages=c,c++ --with-ld=/bin/ld --with-nm=/bin/nm --with-as=/usr/bin/as\n\nWhen this step is done, you can compile GCC with the following command:\nmake -j4\n\nThis assumes you want to use 4 processing cores. You can use more or less, or omit the -j option entirely.\nFinally, run as root:\nmake install\n\nCompiling bazel\nObtain the bazel source code. You need the current master branch, NOT any of the recent releases.\ngit clone https://github.com/bazelbuild/bazel.git\n\nTo compile bazel, you need to specify\nexport CC=/opt/gcc-4.9/bin/gcc\n./compile\n\nThis will produce the bazel binary in path/to/bazel/output/bazel\nCompiling TensorFlow\nObtain the TensorFlow source code\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\n\nModify the file third_party/gpus/crosstool/CROSSTOOL: Find the toolchain entry where the toolchain_identifieris set to \"local_linux\". Only change entries here, the rest is irrelevant.\nReplace the following lines:\ncxx_builtin_include_directory: \"/usr/lib/gcc/\"\ncxx_builtin_include_directory: \"/usr/local/include\"\nwith the following lines:\ncxx_builtin_include_directory: \"/opt/gcc-4.9/lib/gcc/\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/local/include\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/include\"\nNext, run the ./configure and set your options. Specify your self-compiled GCC (for me /opt/gcc-4.9/bin/gcc) as the compiler to be used by nvcc.\nTo compile the source, use the following command line:\npath/to/bazel/output/bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer\n\nExplanations:\n\nbuild: what bazel should do\n-c opt: Don't know, says so in the docu\n--config=cuda: Compile with CUDA support. Don't ask me why you have to specify that again, even though you did so in ./configure.\n--genrule_strategy=standalone: This compiles in \"standalone mode\". Don't ask me what that is, but it's required so that generated output files can find the libcudart.so that they are linked to (see issue #2053).\n--local_resources 4096,4.0,1.0 -j 4: Use at most 4096M of memory, 4.0 CPU's, 1.0 of I/O and 4 threads. This is required so that the compilation doesn't crash due to out-of-memory (I have 8GB of physical memory and 4GB of swap). The 4096 is still a lie, because the compilation still used more - but at least it didn't crash.\n//tensorflow/cc:tutorials_example_trainer: What to build.\n\nI sincerely hope that this guide will be obsolete very soon, and you can just get cracking without all these workarounds. But for now, this will probably be useful.", "body": "Hi. This is my story of how I got TensorFlow to compile on my Fedora 23 machine. Maybe it will be useful for you:\n\n# How to compile TensorFlow from source on Fedora 23 with a custom compiler.\n\nCompiling TensorFlow with GPU support is possible, but a bit tricky on Fedora 23 and up.\nThe compilation requires a specific GCC version which is not available from Fedora repoisitories and specifying the compiler is more complicated than it should be.\n\n## Compiling GCC\n\nFor CUDA version 7.5, you need to obtain the source code for GCC version 4.9. You can obtain it from [here](ftp://ftp.gnu.org/gnu/gcc/gcc-4.9.2/).\n\nNext, you need to install GCC compile-time dependencies:\n\n```\nsudo dnf install mpfr-devel gmp-devel libmpc-devel isl-devel\n```\n\nNow you have to configure the GCC build. For details, check out the [GCC configuration page](https://gcc.gnu.org/install/configure.html). I suggest installing into a custom prefix, such as `/opt/gcc-4.9`. I suggest enabling only C and C++ and skipping the rest of the GCC languages to save time and disk space. The options --with-as, --with-ld and --with-nm are required, because otherwise TensorFlow build will fail, complaining that those binaries cannot be found.\n\n```\n/configure --prefix=/opt/gcc-4.9 --disable-nls --enable-languages=c,c++ --with-ld=/bin/ld --with-nm=/bin/nm --with-as=/usr/bin/as\n```\n\nWhen this step is done, you can compile GCC with the following command:\n\n```\nmake -j4\n```\n\nThis assumes you want to use 4 processing cores. You can use more or less, or omit the -j option entirely.\n\nFinally, run as root:\n\n```\nmake install\n```\n\n## Compiling bazel\n\nObtain the bazel source code. You need the current master branch, NOT any of the recent releases.\n\n```\ngit clone https://github.com/bazelbuild/bazel.git\n```\n\nTo compile bazel, you need to specify \n\n```\nexport CC=/opt/gcc-4.9/bin/gcc\n./compile\n```\n\nThis will produce the bazel binary in `path/to/bazel/output/bazel`\n\n## Compiling TensorFlow\n\nObtain the TensorFlow source code\n\n```\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\n```\n\nModify the file `third_party/gpus/crosstool/CROSSTOOL`: Find the toolchain entry where the `toolchain_identifier`is set to `\"local_linux\"`. Only change entries here, the rest is irrelevant.\n\nReplace the following lines:\n\ncxx_builtin_include_directory: \"/usr/lib/gcc/\"\ncxx_builtin_include_directory: \"/usr/local/include\"\n\nwith the following lines:\ncxx_builtin_include_directory: \"/opt/gcc-4.9/lib/gcc/\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/local/include\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/include\"\n\nNext, run the `./configure` and set your options. Specify your self-compiled GCC (for me `/opt/gcc-4.9/bin/gcc`) as the compiler to be used by nvcc.\n\nTo compile the source, use the following command line:\n\n```\npath/to/bazel/output/bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer\n```\n\nExplanations:\n- build: what bazel should do\n- -c opt: Don't know, says so in the docu\n- --config=cuda: Compile with CUDA support. Don't ask me why you have to specify that again, even though you did so in ./configure.\n- --genrule_strategy=standalone: This compiles in \"standalone mode\". Don't ask me what that is, but it's required so that generated output files can find the `libcudart.so` that they are linked to (see issue #2053).\n- --local_resources 4096,4.0,1.0 -j 4: Use at most 4096M of memory, 4.0 CPU's, 1.0 of I/O and 4 threads. This is required so that the compilation doesn't crash due to out-of-memory (I have 8GB of physical memory and 4GB of swap). The 4096 is still a lie, because the compilation still used more - but at least it didn't crash.\n- //tensorflow/cc:tutorials_example_trainer: What to build.\n\nI sincerely hope that this guide will be obsolete very soon, and you can just get cracking without all these workarounds. But for now, this will probably be useful.\n"}