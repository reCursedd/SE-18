{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285931111", "html_url": "https://github.com/tensorflow/tensorflow/issues/4742#issuecomment-285931111", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4742", "id": 285931111, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTkzMTExMQ==", "user": {"login": "ahundt", "id": 55744, "node_id": "MDQ6VXNlcjU1NzQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/55744?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahundt", "html_url": "https://github.com/ahundt", "followers_url": "https://api.github.com/users/ahundt/followers", "following_url": "https://api.github.com/users/ahundt/following{/other_user}", "gists_url": "https://api.github.com/users/ahundt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahundt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahundt/subscriptions", "organizations_url": "https://api.github.com/users/ahundt/orgs", "repos_url": "https://api.github.com/users/ahundt/repos", "events_url": "https://api.github.com/users/ahundt/events{/privacy}", "received_events_url": "https://api.github.com/users/ahundt/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-12T08:52:55Z", "updated_at": "2017-03-12T09:11:19Z", "author_association": "NONE", "body_html": "<p>I think this may also shrink the dimensions as well? I believe a source of confusion here may be due to varying definitions of atrous convolution depending on the paper being read. Basically, some papers defined atrous convolutions incorrectly when they really meant dilated convolutions. This is explained in <a href=\"https://arxiv.org/abs/1511.07122\" rel=\"nofollow\">Multi-Scale Context Aggregation by Dilated Convolutions</a> with the authors' implementation in <a href=\"https://github.com/fyu/dilation\">https://github.com/fyu/dilation</a>.</p>\n<p>Also see the related issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"167357968\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3492\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3492/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3492\">#3492</a>.</p>\n<p>I think what people are hoping for is a new function, or perhaps simply an additional parameter to the atrous function, is the ability to specify a constant scale of the output data so this can behave the same as these papers where the output dimensions are the same as the input, since this is particularly useful for semantic segmentation.</p>\n<p>I believe this is implemented in <code>tensorflow/models/slim/.../resnet_utils.py</code> in the function <a href=\"https://github.com/tensorflow/models/blob/master/slim/nets/resnet_utils.py#L77\">conv2d_same</a>. It may even be simple enough to migrate that option directly upstream. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2501383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/warmspringwinds\">@warmspringwinds</a> is also very familiar with this and may be able to verify that everything I've said here is correct, or perhaps contribute some additional information.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vrv\">@vrv</a> or <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5453737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatatodd\">@tatatodd</a> regarding the TensorFlow API design, if this version of dilated convolution with constant input/output dimensions is supported directly in <code>tf.nn</code> should it be applied via:</p>\n<ol>\n<li><code>atrous_conv2d</code> with the <code>SAME</code> padding flag</li>\n<li><code>atrous_conv2d</code> with a separate parameter</li>\n<li>a totally separate function</li>\n</ol>", "body_text": "I think this may also shrink the dimensions as well? I believe a source of confusion here may be due to varying definitions of atrous convolution depending on the paper being read. Basically, some papers defined atrous convolutions incorrectly when they really meant dilated convolutions. This is explained in Multi-Scale Context Aggregation by Dilated Convolutions with the authors' implementation in https://github.com/fyu/dilation.\nAlso see the related issue #3492.\nI think what people are hoping for is a new function, or perhaps simply an additional parameter to the atrous function, is the ability to specify a constant scale of the output data so this can behave the same as these papers where the output dimensions are the same as the input, since this is particularly useful for semantic segmentation.\nI believe this is implemented in tensorflow/models/slim/.../resnet_utils.py in the function conv2d_same. It may even be simple enough to migrate that option directly upstream. @warmspringwinds is also very familiar with this and may be able to verify that everything I've said here is correct, or perhaps contribute some additional information.\n@vrv or @tatatodd regarding the TensorFlow API design, if this version of dilated convolution with constant input/output dimensions is supported directly in tf.nn should it be applied via:\n\natrous_conv2d with the SAME padding flag\natrous_conv2d with a separate parameter\na totally separate function", "body": "I think this may also shrink the dimensions as well? I believe a source of confusion here may be due to varying definitions of atrous convolution depending on the paper being read. Basically, some papers defined atrous convolutions incorrectly when they really meant dilated convolutions. This is explained in [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122) with the authors' implementation in https://github.com/fyu/dilation.\r\n\r\nAlso see the related issue https://github.com/tensorflow/tensorflow/issues/3492.\r\n\r\nI think what people are hoping for is a new function, or perhaps simply an additional parameter to the atrous function, is the ability to specify a constant scale of the output data so this can behave the same as these papers where the output dimensions are the same as the input, since this is particularly useful for semantic segmentation.\r\n\r\nI believe this is implemented in `tensorflow/models/slim/.../resnet_utils.py` in the function [conv2d_same](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_utils.py#L77). It may even be simple enough to migrate that option directly upstream. @warmspringwinds is also very familiar with this and may be able to verify that everything I've said here is correct, or perhaps contribute some additional information.\r\n\r\n@vrv or @tatatodd regarding the TensorFlow API design, if this version of dilated convolution with constant input/output dimensions is supported directly in `tf.nn` should it be applied via:\r\n 1. `atrous_conv2d` with the `SAME` padding flag\r\n 2. `atrous_conv2d` with a separate parameter\r\n 3.  a totally separate function\r\n\r\n"}