{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13500", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13500/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13500/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13500/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13500", "id": 263012741, "node_id": "MDU6SXNzdWUyNjMwMTI3NDE=", "number": 13500, "title": "Tensorflow binary seems compiled to use SIMD instructions like AVX2 and FMA, but actually not?", "user": {"login": "MartinZZZ", "id": 12166108, "node_id": "MDQ6VXNlcjEyMTY2MTA4", "avatar_url": "https://avatars0.githubusercontent.com/u/12166108?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MartinZZZ", "html_url": "https://github.com/MartinZZZ", "followers_url": "https://api.github.com/users/MartinZZZ/followers", "following_url": "https://api.github.com/users/MartinZZZ/following{/other_user}", "gists_url": "https://api.github.com/users/MartinZZZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MartinZZZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MartinZZZ/subscriptions", "organizations_url": "https://api.github.com/users/MartinZZZ/orgs", "repos_url": "https://api.github.com/users/MartinZZZ/repos", "events_url": "https://api.github.com/users/MartinZZZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MartinZZZ/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-10-05T06:00:22Z", "updated_at": "2018-01-09T10:19:08Z", "closed_at": "2017-10-12T00:27:03Z", "author_association": "NONE", "body_html": "<p>I found similar issues mentioned as <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"211551389\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8037\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8037/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8037\">#8037</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"209460351\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/7778\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7778/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/7778\">#7778</a> etc, but the issue seems not solved: the warnings did disappear after building with the necessary optimization options, but they appeared again when I followed this tutorial (<a href=\"https://www.tensorflow.org/performance/xla/tfcompile\" rel=\"nofollow\">https://www.tensorflow.org/performance/xla/tfcompile</a>) to the last step. So, is the tensorflow binary compiled to use the SIMD instructions or not?</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>: No</li>\n<li><strong>OS Platform and Distribution</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from</strong>: source</li>\n<li><strong>TensorFlow version</strong>: v1.3.0-rc1-3000-g840dcae</li>\n<li><strong>Python version</strong>: Python3</li>\n<li><strong>Bazel version</strong>: 0.6.0</li>\n<li><strong>CPU</strong>: Intel Core i7-4770, Haswell architecture, supporting AVX2 and FMA</li>\n<li><strong>GPU</strong>: No</li>\n<li><strong>Compiler</strong>: gcc 5.4.0</li>\n</ul>\n<h3>Issue reproducing:</h3>\n<ol>\n<li>Building tensorflow from source:</li>\n</ol>\n<ul>\n<li>\n<p>Configure: only jemalloc and XLA JIT support are ticked. The default optimization flag is <code>-march=native</code>, therefore was not specified;</p>\n</li>\n<li>\n<p>Build pip package:</p>\n</li>\n</ul>\n<pre><code>bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\n</code></pre>\n<ul>\n<li>Install pip package:</li>\n</ul>\n<pre><code>sudo -H python3 -m pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl\n</code></pre>\n<ul>\n<li>The installation was validated using the \"Hello, TensorFlow!\" example, and no warnings are generated.</li>\n</ul>\n<ol start=\"2\">\n<li>Generating <code>tfcompile</code> binary:</li>\n</ol>\n<pre><code>bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot:tfcompile\n</code></pre>\n<ol start=\"3\">\n<li>Follow the tutorial here <a href=\"https://www.tensorflow.org/performance/xla/tfcompile\" rel=\"nofollow\">https://www.tensorflow.org/performance/xla/tfcompile</a>, in the directory <code>//tensorflow/compiler/aot/tests</code>:</li>\n</ol>\n<ul>\n<li>\n<p>Step 1: The config file already exists as <code>test_graph_tfmatmul.config.pbtxt</code>;</p>\n</li>\n<li>\n<p>Step 2.1: Generate the graph file <code>test_graph_tfmatmul.pb</code>:</p>\n</li>\n</ul>\n<pre><code>python3 ./make_test_graphs.py --out_dir=./\n</code></pre>\n<ul>\n<li>Step 2.2: Compile the graph using <code>tfcompile</code>:</li>\n</ul>\n<pre><code>~/tensorFlow_src/tensorflow/bazel-bin/tensorflow/compiler/aot/tfcompile --graph=\"./test_graph_tfmatmul.pb\" --config=\"./test_graph_tfmatmul.config.pbtxt\" --entry_point=\"test_graph_tfmatmul\" --cpp_class=\"foo::bar::MatMulComp\" --out_object=\"test_graph_tfmatmul.o\" --out_header=\"test_graph_tfmatmul.h\" --target_features=\"+avx2\"\n</code></pre>\n<ul>\n<li>Step 3: Creating a file named <code>my_code.cc</code>:</li>\n</ul>\n<pre><code>#define EIGEN_USE_THREADS\n#define EIGEN_USE_CUSTOM_THREAD_POOL\n\n#include &lt;iostream&gt;\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/compiler/aot/tests/test_graph_tfmatmul.h\" // generated\n\nint main(int argc, char** argv) {\n    Eigen::ThreadPool tp(2);  // Size the thread pool as appropriate.\n    Eigen::ThreadPoolDevice device(&amp;tp, tp.NumThreads());\n\n    foo::bar::MatMulComp matmul;\n    matmul.set_thread_pool(&amp;device);\n\n    // Set up args and run the computation.\n    const float args[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};\n    std::copy(args + 0, args + 6, matmul.arg0_data());\n    std::copy(args + 6, args + 12, matmul.arg1_data());\n    matmul.Run();\n\n    // Check result\n    if (matmul.result0(0, 0) == 58) {\n        std::cout &lt;&lt; \"Success\" &lt;&lt; std::endl;\n    } else {\n        std::cout &lt;&lt; \"Failed. Expected value 58 at 0,0. Got:\"\n                    &lt;&lt; matmul.result0(0, 0) &lt;&lt; std::endl;\n    }\n\n    return 0;\n}\n</code></pre>\n<ul>\n<li>Step 4.1: Create the <code>BUILD</code> file:</li>\n</ul>\n<pre><code># Example of linking your binary\n# Also see //third_party/tensorflow/compiler/aot/tests/BUILD\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\n\n# The same tf_library call from step 2 above.\ntf_library(\n    name = \"test_graph_tfmatmul\",\n    cpp_class = \"foo::bar::MatMulComp\",\n    graph = \"test_graph_tfmatmul.pb\",\n    config = \"test_graph_tfmatmul.config.pbtxt\",\n)\n\n# The executable code generated by tf_library can then be linked into your code.\ncc_binary(\n    name = \"my_binary\",\n    srcs = [\n        \"my_code.cc\",  # include test_graph_tfmatmul.h to access the generated header\n    ],\n    deps = [\n        \":test_graph_tfmatmul\",  # link in the generated object file\n        \"//third_party/eigen3\",\n    ],\n    linkopts = [\n        \"-lpthread\",\n    ]\n)\n</code></pre>\n<ul>\n<li>Step 4.2: Create the final binary:</li>\n</ul>\n<pre><code>bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot/tests:my_binary\n</code></pre>\n<p>Finally, it will print:<br>\n<code>INFO: From Executing genrule //tensorflow/compiler/aot/tests:gen_test_graph_tfmatmul: 2017-10-05 15:15:29.233159: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</code><br>\n(An error will also occur, but that is another issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"262658135\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13482\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/13482/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/13482\">#13482</a>).</p>\n<p>So, is the tensorflow binary compiled to use the SIMD instructions (SSE4.1 SSE4.2 AVX AVX2 FMA) or not? May I have your advice?</p>", "body_text": "I found similar issues mentioned as #8037, #7778 etc, but the issue seems not solved: the warnings did disappear after building with the necessary optimization options, but they appeared again when I followed this tutorial (https://www.tensorflow.org/performance/xla/tfcompile) to the last step. So, is the tensorflow binary compiled to use the SIMD instructions or not?\nSystem information\n\nHave I written custom code: No\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from: source\nTensorFlow version: v1.3.0-rc1-3000-g840dcae\nPython version: Python3\nBazel version: 0.6.0\nCPU: Intel Core i7-4770, Haswell architecture, supporting AVX2 and FMA\nGPU: No\nCompiler: gcc 5.4.0\n\nIssue reproducing:\n\nBuilding tensorflow from source:\n\n\n\nConfigure: only jemalloc and XLA JIT support are ticked. The default optimization flag is -march=native, therefore was not specified;\n\n\nBuild pip package:\n\n\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\n\n\nInstall pip package:\n\nsudo -H python3 -m pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl\n\n\nThe installation was validated using the \"Hello, TensorFlow!\" example, and no warnings are generated.\n\n\nGenerating tfcompile binary:\n\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot:tfcompile\n\n\nFollow the tutorial here https://www.tensorflow.org/performance/xla/tfcompile, in the directory //tensorflow/compiler/aot/tests:\n\n\n\nStep 1: The config file already exists as test_graph_tfmatmul.config.pbtxt;\n\n\nStep 2.1: Generate the graph file test_graph_tfmatmul.pb:\n\n\npython3 ./make_test_graphs.py --out_dir=./\n\n\nStep 2.2: Compile the graph using tfcompile:\n\n~/tensorFlow_src/tensorflow/bazel-bin/tensorflow/compiler/aot/tfcompile --graph=\"./test_graph_tfmatmul.pb\" --config=\"./test_graph_tfmatmul.config.pbtxt\" --entry_point=\"test_graph_tfmatmul\" --cpp_class=\"foo::bar::MatMulComp\" --out_object=\"test_graph_tfmatmul.o\" --out_header=\"test_graph_tfmatmul.h\" --target_features=\"+avx2\"\n\n\nStep 3: Creating a file named my_code.cc:\n\n#define EIGEN_USE_THREADS\n#define EIGEN_USE_CUSTOM_THREAD_POOL\n\n#include <iostream>\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/compiler/aot/tests/test_graph_tfmatmul.h\" // generated\n\nint main(int argc, char** argv) {\n    Eigen::ThreadPool tp(2);  // Size the thread pool as appropriate.\n    Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\n\n    foo::bar::MatMulComp matmul;\n    matmul.set_thread_pool(&device);\n\n    // Set up args and run the computation.\n    const float args[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};\n    std::copy(args + 0, args + 6, matmul.arg0_data());\n    std::copy(args + 6, args + 12, matmul.arg1_data());\n    matmul.Run();\n\n    // Check result\n    if (matmul.result0(0, 0) == 58) {\n        std::cout << \"Success\" << std::endl;\n    } else {\n        std::cout << \"Failed. Expected value 58 at 0,0. Got:\"\n                    << matmul.result0(0, 0) << std::endl;\n    }\n\n    return 0;\n}\n\n\nStep 4.1: Create the BUILD file:\n\n# Example of linking your binary\n# Also see //third_party/tensorflow/compiler/aot/tests/BUILD\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\n\n# The same tf_library call from step 2 above.\ntf_library(\n    name = \"test_graph_tfmatmul\",\n    cpp_class = \"foo::bar::MatMulComp\",\n    graph = \"test_graph_tfmatmul.pb\",\n    config = \"test_graph_tfmatmul.config.pbtxt\",\n)\n\n# The executable code generated by tf_library can then be linked into your code.\ncc_binary(\n    name = \"my_binary\",\n    srcs = [\n        \"my_code.cc\",  # include test_graph_tfmatmul.h to access the generated header\n    ],\n    deps = [\n        \":test_graph_tfmatmul\",  # link in the generated object file\n        \"//third_party/eigen3\",\n    ],\n    linkopts = [\n        \"-lpthread\",\n    ]\n)\n\n\nStep 4.2: Create the final binary:\n\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot/tests:my_binary\n\nFinally, it will print:\nINFO: From Executing genrule //tensorflow/compiler/aot/tests:gen_test_graph_tfmatmul: 2017-10-05 15:15:29.233159: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n(An error will also occur, but that is another issue #13482).\nSo, is the tensorflow binary compiled to use the SIMD instructions (SSE4.1 SSE4.2 AVX AVX2 FMA) or not? May I have your advice?", "body": "I found similar issues mentioned as #8037, #7778 etc, but the issue seems not solved: the warnings did disappear after building with the necessary optimization options, but they appeared again when I followed this tutorial (https://www.tensorflow.org/performance/xla/tfcompile) to the last step. So, is the tensorflow binary compiled to use the SIMD instructions or not?\r\n\r\n### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: v1.3.0-rc1-3000-g840dcae\r\n- **Python version**: Python3\r\n- **Bazel version**: 0.6.0\r\n- **CPU**: Intel Core i7-4770, Haswell architecture, supporting AVX2 and FMA\r\n- **GPU**: No\r\n- **Compiler**: gcc 5.4.0\r\n\r\n### Issue reproducing:\r\n1. Building tensorflow from source:\r\n\r\n- Configure: only jemalloc and XLA JIT support are ticked. The default optimization flag is `-march=native`, therefore was not specified;\r\n\r\n- Build pip package:\r\n```\r\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n``` \r\n- Install pip package:\r\n```\r\nsudo -H python3 -m pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl\r\n```\r\n- The installation was validated using the \"Hello, TensorFlow!\" example, and no warnings are generated.\r\n\r\n2. Generating `tfcompile` binary:\r\n```\r\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot:tfcompile\r\n```\r\n\r\n3. Follow the tutorial here https://www.tensorflow.org/performance/xla/tfcompile, in the directory `//tensorflow/compiler/aot/tests`:\r\n- Step 1: The config file already exists as `test_graph_tfmatmul.config.pbtxt`;\r\n\r\n- Step 2.1: Generate the graph file `test_graph_tfmatmul.pb`:\r\n```\r\npython3 ./make_test_graphs.py --out_dir=./\r\n```\r\n- Step 2.2: Compile the graph using `tfcompile`:\r\n```\r\n~/tensorFlow_src/tensorflow/bazel-bin/tensorflow/compiler/aot/tfcompile --graph=\"./test_graph_tfmatmul.pb\" --config=\"./test_graph_tfmatmul.config.pbtxt\" --entry_point=\"test_graph_tfmatmul\" --cpp_class=\"foo::bar::MatMulComp\" --out_object=\"test_graph_tfmatmul.o\" --out_header=\"test_graph_tfmatmul.h\" --target_features=\"+avx2\"\r\n```\r\n\r\n- Step 3: Creating a file named `my_code.cc`:\r\n```\r\n#define EIGEN_USE_THREADS\r\n#define EIGEN_USE_CUSTOM_THREAD_POOL\r\n\r\n#include <iostream>\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"tensorflow/compiler/aot/tests/test_graph_tfmatmul.h\" // generated\r\n\r\nint main(int argc, char** argv) {\r\n    Eigen::ThreadPool tp(2);  // Size the thread pool as appropriate.\r\n    Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\r\n\r\n    foo::bar::MatMulComp matmul;\r\n    matmul.set_thread_pool(&device);\r\n\r\n    // Set up args and run the computation.\r\n    const float args[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};\r\n    std::copy(args + 0, args + 6, matmul.arg0_data());\r\n    std::copy(args + 6, args + 12, matmul.arg1_data());\r\n    matmul.Run();\r\n\r\n    // Check result\r\n    if (matmul.result0(0, 0) == 58) {\r\n        std::cout << \"Success\" << std::endl;\r\n    } else {\r\n        std::cout << \"Failed. Expected value 58 at 0,0. Got:\"\r\n                    << matmul.result0(0, 0) << std::endl;\r\n    }\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n- Step 4.1: Create the `BUILD` file:\r\n```\r\n# Example of linking your binary\r\n# Also see //third_party/tensorflow/compiler/aot/tests/BUILD\r\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\r\n\r\n# The same tf_library call from step 2 above.\r\ntf_library(\r\n    name = \"test_graph_tfmatmul\",\r\n    cpp_class = \"foo::bar::MatMulComp\",\r\n    graph = \"test_graph_tfmatmul.pb\",\r\n    config = \"test_graph_tfmatmul.config.pbtxt\",\r\n)\r\n\r\n# The executable code generated by tf_library can then be linked into your code.\r\ncc_binary(\r\n    name = \"my_binary\",\r\n    srcs = [\r\n        \"my_code.cc\",  # include test_graph_tfmatmul.h to access the generated header\r\n    ],\r\n    deps = [\r\n        \":test_graph_tfmatmul\",  # link in the generated object file\r\n        \"//third_party/eigen3\",\r\n    ],\r\n    linkopts = [\r\n        \"-lpthread\",\r\n    ]\r\n)\r\n```\r\n\r\n- Step 4.2: Create the final binary:\r\n```\r\nbazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/compiler/aot/tests:my_binary\r\n```\r\n\r\nFinally, it will print:\r\n`INFO: From Executing genrule //tensorflow/compiler/aot/tests:gen_test_graph_tfmatmul:\r\n2017-10-05 15:15:29.233159: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA`\r\n(An error will also occur, but that is another issue #13482).\r\n\r\nSo, is the tensorflow binary compiled to use the SIMD instructions (SSE4.1 SSE4.2 AVX AVX2 FMA) or not? May I have your advice?\r\n"}