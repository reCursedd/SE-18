{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14214", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14214/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14214/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14214/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14214", "id": 270999686, "node_id": "MDU6SXNzdWUyNzA5OTk2ODY=", "number": 14214, "title": "do fine tuning with my own image size ", "user": {"login": "jamesben6688", "id": 11385453, "node_id": "MDQ6VXNlcjExMzg1NDUz", "avatar_url": "https://avatars0.githubusercontent.com/u/11385453?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesben6688", "html_url": "https://github.com/jamesben6688", "followers_url": "https://api.github.com/users/jamesben6688/followers", "following_url": "https://api.github.com/users/jamesben6688/following{/other_user}", "gists_url": "https://api.github.com/users/jamesben6688/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesben6688/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesben6688/subscriptions", "organizations_url": "https://api.github.com/users/jamesben6688/orgs", "repos_url": "https://api.github.com/users/jamesben6688/repos", "events_url": "https://api.github.com/users/jamesben6688/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesben6688/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-03T14:36:53Z", "updated_at": "2017-11-04T02:28:20Z", "closed_at": "2017-11-04T02:28:20Z", "author_association": "NONE", "body_html": "<p>I would like to do transfer learning and fine tuning with some pretrained model in tensorflow.contrib.slim. I searched some examples about this. However, almost all of these examples will resize images to the specified size that the model needs. For example, 224\u00d7224 is the size that vgg16 needed. Will it be possible to set my own image size? Like 512\u00d7512. In keras, I can do this like following:</p>\n<pre><code>`base_model= VGG16(include_top=False, input_shape=(512, 512, 3))` \n</code></pre>\n<p>Up till now, I have not found the solution, can this be down in tensorflow and slim?</p>", "body_text": "I would like to do transfer learning and fine tuning with some pretrained model in tensorflow.contrib.slim. I searched some examples about this. However, almost all of these examples will resize images to the specified size that the model needs. For example, 224\u00d7224 is the size that vgg16 needed. Will it be possible to set my own image size? Like 512\u00d7512. In keras, I can do this like following:\n`base_model= VGG16(include_top=False, input_shape=(512, 512, 3))` \n\nUp till now, I have not found the solution, can this be down in tensorflow and slim?", "body": "I would like to do transfer learning and fine tuning with some pretrained model in tensorflow.contrib.slim. I searched some examples about this. However, almost all of these examples will resize images to the specified size that the model needs. For example, 224\u00d7224 is the size that vgg16 needed. Will it be possible to set my own image size? Like 512\u00d7512. In keras, I can do this like following:\r\n\r\n    `base_model= VGG16(include_top=False, input_shape=(512, 512, 3))` \r\n\r\nUp till now, I have not found the solution, can this be down in tensorflow and slim?\r\n"}