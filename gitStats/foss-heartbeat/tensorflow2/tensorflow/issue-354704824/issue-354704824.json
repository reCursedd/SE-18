{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21921", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21921/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21921/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21921/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21921", "id": 354704824, "node_id": "MDU6SXNzdWUzNTQ3MDQ4MjQ=", "number": 21921, "title": " Tensorflow lite model gives very different accuracy value compared to python model", "user": {"login": "jimenisimo", "id": 19747012, "node_id": "MDQ6VXNlcjE5NzQ3MDEy", "avatar_url": "https://avatars3.githubusercontent.com/u/19747012?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jimenisimo", "html_url": "https://github.com/jimenisimo", "followers_url": "https://api.github.com/users/jimenisimo/followers", "following_url": "https://api.github.com/users/jimenisimo/following{/other_user}", "gists_url": "https://api.github.com/users/jimenisimo/gists{/gist_id}", "starred_url": "https://api.github.com/users/jimenisimo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jimenisimo/subscriptions", "organizations_url": "https://api.github.com/users/jimenisimo/orgs", "repos_url": "https://api.github.com/users/jimenisimo/repos", "events_url": "https://api.github.com/users/jimenisimo/events{/privacy}", "received_events_url": "https://api.github.com/users/jimenisimo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, {"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2018-08-28T12:17:40Z", "updated_at": "2018-10-15T17:08:34Z", "closed_at": "2018-10-15T17:08:34Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10</li>\n<li><strong>Python version</strong>:3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.16.0</li>\n<li><strong>CUDA/cuDNN version</strong>:N/A</li>\n<li><strong>GPU model and memory</strong>:N/A</li>\n<li><strong>Exact command to reproduce</strong>: See Source Code</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using tensorflow 1.10 Python 3.6</p>\n<p>My code is based in the premade iris classification model provided by TensorFlow. This means, I am using a Tensorflow DNN premade classifier, with the difference following difference:</p>\n<p>10 features instead 4.<br>\n5 classes instead 3.<br>\nThe test and training files can be downloaded from the following link: <a href=\"https://www.dropbox.com/sh/nmu8i2i8xe6hvfq/AADQEOIHH8e-kUHQf8zmmDMDa?dl=0\" rel=\"nofollow\">https://www.dropbox.com/sh/nmu8i2i8xe6hvfq/AADQEOIHH8e-kUHQf8zmmDMDa?dl=0</a></p>\n<p>I have made a code to export this classifier to a tflite format, however the accuracy in the python model is higher than 75% but when exported the accuracy decrease approximately to 45% this means approximately 30% Accuracy is lost (This is too much). I have tried the code with different set of data and in all of them the accuracy after exporting decrease a lot! This made me think that something is going wrong with the TocoConverter function or that maybe I am exporting to tflite incorrectly, missing a parameter or something like that.</p>\n<p>I share the code in which I calculate also the accuracy of the .tflite file.</p>\n<p>I hope some of you can identify the error, or give a possible solution</p>\n<h3>Source code / logs</h3>\n<pre><code>import argparse\nimport tensorflow as tf\n\nimport pandas as pd\nimport csv\n\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\nimport numpy as np\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\nparser.add_argument('--train_steps', default=1000, type=int,\n                    help='number of training steps')\n\nfeatures_global = None\nfeature_spec = None\n\nMODEL_NAME = 'myModel'\n\ndef load_data(train_path, test_path):\n    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n\n    with open(train_path, newline='') as f:\n        reader = csv.reader(f)\n        column_names = next(reader)\n\n    y_name = column_names[-1]\n\n    train = pd.read_csv(train_path, names=column_names, header=0)\n    train_x, train_y = train, train.pop(y_name)\n\n    test = pd.read_csv(test_path, names=column_names, header=0)\n    test_x, test_y = test, test.pop(y_name)\n\n    return (train_x, train_y), (test_x, test_y)\n\n\ndef train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\n\ndef eval_input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        # No labels, use only features.\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n\n    # Batch the examples\n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\n\ndef main(argv):\n    args = parser.parse_args(argv[1:])\n\n    train_path = \"trainData.csv\"\n    test_path = \"testData.csv\"\n\n    # Fetch the data\n    (train_x, train_y), (test_x, test_y) = load_data(train_path, test_path)\n\n    # Load labels\n    num_labels = 5\n\n    # Feature columns describe how to use the input.\n    my_feature_columns = []\n    for key in train_x.keys():\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n\n    # Build 2 hidden layer DNN\n    classifier = tf.estimator.DNNClassifier(\n        feature_columns=my_feature_columns,\n        # Two hidden layers of 10 nodes each.\n        hidden_units=[100, 500],\n        # The model must choose between 'num_labels' classes.\n        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),\n        n_classes=num_labels,\n        model_dir=\"myModel\")\n\n    # Train the Model\n    classifier.train(\n        input_fn=lambda:train_input_fn(train_x, train_y,\n                                                args.batch_size),\n        steps=args.train_steps)\n\n    # Evaluate the model.\n    eval_result = classifier.evaluate(\n        input_fn=lambda:eval_input_fn(test_x, test_y,\n                                                args.batch_size))\n\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n\n    # Export model\n    feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\n    serve_input_fun = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n    saved_model_path = classifier.export_savedmodel(\n            export_dir_base=\"out\",\n            serving_input_receiver_fn=serve_input_fun,\n            as_text=True,\n            checkpoint_path=classifier.latest_checkpoint(),\n        )\n    tf.reset_default_graph()\n    var = tf.Variable(0)\n    with tf.Session() as sess:\n        # First let's load meta graph and restore weights\n        sess.run(tf.global_variables_initializer())\n        latest_checkpoint_path = classifier.latest_checkpoint()\n        saver = tf.train.import_meta_graph(latest_checkpoint_path + '.meta')\n        saver.restore(sess, latest_checkpoint_path)\n\n        input_arrays = [\"dnn/input_from_feature_columns/input_layer/concat\"]\n        output_arrays = [\"dnn/logits/BiasAdd\"]\n\n        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph_def,\n            output_node_names=[\"dnn/logits/BiasAdd\"])\n\n        frozen_graph = \"out/frozen_graph.pb\"\n\n        with tf.gfile.FastGFile(frozen_graph, \"wb\") as f:\n                f.write(frozen_graph_def.SerializeToString())\n\n        # save original graphdef to text file\n        with open(\"estimator_graph.pbtxt\", \"w\") as fp:\n            fp.write(str(sess.graph_def))\n        # save frozen graph def to text file\n        with open(\"estimator_frozen_graph.pbtxt\", \"w\") as fp:\n            fp.write(str(frozen_graph_def))\n\n        input_node_names = input_arrays\n        output_node_name = output_arrays\n        output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n                frozen_graph_def, input_node_names, output_node_name,\n                tf.float32.as_datatype_enum)\n\n        final_model_path = 'out/opt_' + MODEL_NAME + '.pb'\n        with tf.gfile.FastGFile(final_model_path, \"wb\") as f:\n            f.write(output_graph_def.SerializeToString())\n\n        tflite_file = \"out/iris.tflite\"\n\n        converter = tf.contrib.lite.TocoConverter.from_frozen_graph(final_model_path, input_arrays, output_arrays, input_shapes={\"dnn/input_from_feature_columns/input_layer/concat\": [1, 10]})\n        tflite_model = converter.convert()\n        open(tflite_file, \"wb\").write(tflite_model)\n\n        interpreter = tf.contrib.lite.Interpreter(model_path=tflite_file)\n        interpreter.allocate_tensors()\n\n        # Get input and output tensors.\n        input_details = interpreter.get_input_details()\n        output_details = interpreter.get_output_details()\n\n        # Test model on random input data.\n        input_shape = input_details[0]['shape']\n        # change the following line to feed into your own data.\n        input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n        resultlist = list()\n        df = pd.read_csv(test_path)\n        expected = df.iloc[:, -1].values.tolist()\n        with open(test_path, newline='') as f:\n            reader = csv.reader(f)\n            column_names = next(reader)\n            for x in range(1, len(expected)):\n                linea = next(reader)\n                linea = linea[:len(linea) - 1]\n                input_data2 = np.array(linea, dtype=np.float32)\n                interpreter.set_tensor(input_details[0]['index'], [input_data2])\n                interpreter.invoke()\n                output_data = interpreter.get_tensor(output_details[0]['index'])\n                #print(output_data)\n                max = 0;\n                longitud = len(output_data[0])\n\n                for k in range(0, longitud):\n                    if (output_data[0][k] &gt; output_data[0][max]):\n                        max = k\n                resultlist.append(max)\n            print(resultlist)\n\n        coincidences = 0\n        for pred_dict, expec in zip(resultlist, expected):\n            if pred_dict == expec:\n                coincidences = coincidences + 1\n\n        print(\"tflite Accuracy: \" + str(coincidences / len(expected)))\n\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run(main)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.10\nPython version:3.6\nBazel version (if compiling from source): 0.16.0\nCUDA/cuDNN version:N/A\nGPU model and memory:N/A\nExact command to reproduce: See Source Code\n\nDescribe the problem\nI am using tensorflow 1.10 Python 3.6\nMy code is based in the premade iris classification model provided by TensorFlow. This means, I am using a Tensorflow DNN premade classifier, with the difference following difference:\n10 features instead 4.\n5 classes instead 3.\nThe test and training files can be downloaded from the following link: https://www.dropbox.com/sh/nmu8i2i8xe6hvfq/AADQEOIHH8e-kUHQf8zmmDMDa?dl=0\nI have made a code to export this classifier to a tflite format, however the accuracy in the python model is higher than 75% but when exported the accuracy decrease approximately to 45% this means approximately 30% Accuracy is lost (This is too much). I have tried the code with different set of data and in all of them the accuracy after exporting decrease a lot! This made me think that something is going wrong with the TocoConverter function or that maybe I am exporting to tflite incorrectly, missing a parameter or something like that.\nI share the code in which I calculate also the accuracy of the .tflite file.\nI hope some of you can identify the error, or give a possible solution\nSource code / logs\nimport argparse\nimport tensorflow as tf\n\nimport pandas as pd\nimport csv\n\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\nimport numpy as np\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\nparser.add_argument('--train_steps', default=1000, type=int,\n                    help='number of training steps')\n\nfeatures_global = None\nfeature_spec = None\n\nMODEL_NAME = 'myModel'\n\ndef load_data(train_path, test_path):\n    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n\n    with open(train_path, newline='') as f:\n        reader = csv.reader(f)\n        column_names = next(reader)\n\n    y_name = column_names[-1]\n\n    train = pd.read_csv(train_path, names=column_names, header=0)\n    train_x, train_y = train, train.pop(y_name)\n\n    test = pd.read_csv(test_path, names=column_names, header=0)\n    test_x, test_y = test, test.pop(y_name)\n\n    return (train_x, train_y), (test_x, test_y)\n\n\ndef train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\n\ndef eval_input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        # No labels, use only features.\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n\n    # Batch the examples\n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\n\ndef main(argv):\n    args = parser.parse_args(argv[1:])\n\n    train_path = \"trainData.csv\"\n    test_path = \"testData.csv\"\n\n    # Fetch the data\n    (train_x, train_y), (test_x, test_y) = load_data(train_path, test_path)\n\n    # Load labels\n    num_labels = 5\n\n    # Feature columns describe how to use the input.\n    my_feature_columns = []\n    for key in train_x.keys():\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n\n    # Build 2 hidden layer DNN\n    classifier = tf.estimator.DNNClassifier(\n        feature_columns=my_feature_columns,\n        # Two hidden layers of 10 nodes each.\n        hidden_units=[100, 500],\n        # The model must choose between 'num_labels' classes.\n        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),\n        n_classes=num_labels,\n        model_dir=\"myModel\")\n\n    # Train the Model\n    classifier.train(\n        input_fn=lambda:train_input_fn(train_x, train_y,\n                                                args.batch_size),\n        steps=args.train_steps)\n\n    # Evaluate the model.\n    eval_result = classifier.evaluate(\n        input_fn=lambda:eval_input_fn(test_x, test_y,\n                                                args.batch_size))\n\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n\n    # Export model\n    feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\n    serve_input_fun = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n    saved_model_path = classifier.export_savedmodel(\n            export_dir_base=\"out\",\n            serving_input_receiver_fn=serve_input_fun,\n            as_text=True,\n            checkpoint_path=classifier.latest_checkpoint(),\n        )\n    tf.reset_default_graph()\n    var = tf.Variable(0)\n    with tf.Session() as sess:\n        # First let's load meta graph and restore weights\n        sess.run(tf.global_variables_initializer())\n        latest_checkpoint_path = classifier.latest_checkpoint()\n        saver = tf.train.import_meta_graph(latest_checkpoint_path + '.meta')\n        saver.restore(sess, latest_checkpoint_path)\n\n        input_arrays = [\"dnn/input_from_feature_columns/input_layer/concat\"]\n        output_arrays = [\"dnn/logits/BiasAdd\"]\n\n        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph_def,\n            output_node_names=[\"dnn/logits/BiasAdd\"])\n\n        frozen_graph = \"out/frozen_graph.pb\"\n\n        with tf.gfile.FastGFile(frozen_graph, \"wb\") as f:\n                f.write(frozen_graph_def.SerializeToString())\n\n        # save original graphdef to text file\n        with open(\"estimator_graph.pbtxt\", \"w\") as fp:\n            fp.write(str(sess.graph_def))\n        # save frozen graph def to text file\n        with open(\"estimator_frozen_graph.pbtxt\", \"w\") as fp:\n            fp.write(str(frozen_graph_def))\n\n        input_node_names = input_arrays\n        output_node_name = output_arrays\n        output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n                frozen_graph_def, input_node_names, output_node_name,\n                tf.float32.as_datatype_enum)\n\n        final_model_path = 'out/opt_' + MODEL_NAME + '.pb'\n        with tf.gfile.FastGFile(final_model_path, \"wb\") as f:\n            f.write(output_graph_def.SerializeToString())\n\n        tflite_file = \"out/iris.tflite\"\n\n        converter = tf.contrib.lite.TocoConverter.from_frozen_graph(final_model_path, input_arrays, output_arrays, input_shapes={\"dnn/input_from_feature_columns/input_layer/concat\": [1, 10]})\n        tflite_model = converter.convert()\n        open(tflite_file, \"wb\").write(tflite_model)\n\n        interpreter = tf.contrib.lite.Interpreter(model_path=tflite_file)\n        interpreter.allocate_tensors()\n\n        # Get input and output tensors.\n        input_details = interpreter.get_input_details()\n        output_details = interpreter.get_output_details()\n\n        # Test model on random input data.\n        input_shape = input_details[0]['shape']\n        # change the following line to feed into your own data.\n        input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n        resultlist = list()\n        df = pd.read_csv(test_path)\n        expected = df.iloc[:, -1].values.tolist()\n        with open(test_path, newline='') as f:\n            reader = csv.reader(f)\n            column_names = next(reader)\n            for x in range(1, len(expected)):\n                linea = next(reader)\n                linea = linea[:len(linea) - 1]\n                input_data2 = np.array(linea, dtype=np.float32)\n                interpreter.set_tensor(input_details[0]['index'], [input_data2])\n                interpreter.invoke()\n                output_data = interpreter.get_tensor(output_details[0]['index'])\n                #print(output_data)\n                max = 0;\n                longitud = len(output_data[0])\n\n                for k in range(0, longitud):\n                    if (output_data[0][k] > output_data[0][max]):\n                        max = k\n                resultlist.append(max)\n            print(resultlist)\n\n        coincidences = 0\n        for pred_dict, expec in zip(resultlist, expected):\n            if pred_dict == expec:\n                coincidences = coincidences + 1\n\n        print(\"tflite Accuracy: \" + str(coincidences / len(expected)))\n\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run(main)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**: 0.16.0\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**: See Source Code\r\n\r\n### Describe the problem\r\nI am using tensorflow 1.10 Python 3.6\r\n\r\nMy code is based in the premade iris classification model provided by TensorFlow. This means, I am using a Tensorflow DNN premade classifier, with the difference following difference:\r\n\r\n10 features instead 4.\r\n5 classes instead 3.\r\nThe test and training files can be downloaded from the following link: https://www.dropbox.com/sh/nmu8i2i8xe6hvfq/AADQEOIHH8e-kUHQf8zmmDMDa?dl=0\r\n\r\nI have made a code to export this classifier to a tflite format, however the accuracy in the python model is higher than 75% but when exported the accuracy decrease approximately to 45% this means approximately 30% Accuracy is lost (This is too much). I have tried the code with different set of data and in all of them the accuracy after exporting decrease a lot! This made me think that something is going wrong with the TocoConverter function or that maybe I am exporting to tflite incorrectly, missing a parameter or something like that.\r\n\r\nI share the code in which I calculate also the accuracy of the .tflite file.\r\n\r\nI hope some of you can identify the error, or give a possible solution\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\nimport pandas as pd\r\nimport csv\r\n\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\nimport numpy as np\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\r\nparser.add_argument('--train_steps', default=1000, type=int,\r\n                    help='number of training steps')\r\n\r\nfeatures_global = None\r\nfeature_spec = None\r\n\r\nMODEL_NAME = 'myModel'\r\n\r\ndef load_data(train_path, test_path):\r\n    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\r\n\r\n    with open(train_path, newline='') as f:\r\n        reader = csv.reader(f)\r\n        column_names = next(reader)\r\n\r\n    y_name = column_names[-1]\r\n\r\n    train = pd.read_csv(train_path, names=column_names, header=0)\r\n    train_x, train_y = train, train.pop(y_name)\r\n\r\n    test = pd.read_csv(test_path, names=column_names, header=0)\r\n    test_x, test_y = test, test.pop(y_name)\r\n\r\n    return (train_x, train_y), (test_x, test_y)\r\n\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef eval_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for evaluation or prediction\"\"\"\r\n    features=dict(features)\r\n    if labels is None:\r\n        # No labels, use only features.\r\n        inputs = features\r\n    else:\r\n        inputs = (features, labels)\r\n\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\r\n\r\n    # Batch the examples\r\n    assert batch_size is not None, \"batch_size must not be None\"\r\n    dataset = dataset.batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef main(argv):\r\n    args = parser.parse_args(argv[1:])\r\n\r\n    train_path = \"trainData.csv\"\r\n    test_path = \"testData.csv\"\r\n\r\n    # Fetch the data\r\n    (train_x, train_y), (test_x, test_y) = load_data(train_path, test_path)\r\n\r\n    # Load labels\r\n    num_labels = 5\r\n\r\n    # Feature columns describe how to use the input.\r\n    my_feature_columns = []\r\n    for key in train_x.keys():\r\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n\r\n    # Build 2 hidden layer DNN\r\n    classifier = tf.estimator.DNNClassifier(\r\n        feature_columns=my_feature_columns,\r\n        # Two hidden layers of 10 nodes each.\r\n        hidden_units=[100, 500],\r\n        # The model must choose between 'num_labels' classes.\r\n        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),\r\n        n_classes=num_labels,\r\n        model_dir=\"myModel\")\r\n\r\n    # Train the Model\r\n    classifier.train(\r\n        input_fn=lambda:train_input_fn(train_x, train_y,\r\n                                                args.batch_size),\r\n        steps=args.train_steps)\r\n\r\n    # Evaluate the model.\r\n    eval_result = classifier.evaluate(\r\n        input_fn=lambda:eval_input_fn(test_x, test_y,\r\n                                                args.batch_size))\r\n\r\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\r\n\r\n    # Export model\r\n    feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\r\n    serve_input_fun = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n    saved_model_path = classifier.export_savedmodel(\r\n            export_dir_base=\"out\",\r\n            serving_input_receiver_fn=serve_input_fun,\r\n            as_text=True,\r\n            checkpoint_path=classifier.latest_checkpoint(),\r\n        )\r\n    tf.reset_default_graph()\r\n    var = tf.Variable(0)\r\n    with tf.Session() as sess:\r\n        # First let's load meta graph and restore weights\r\n        sess.run(tf.global_variables_initializer())\r\n        latest_checkpoint_path = classifier.latest_checkpoint()\r\n        saver = tf.train.import_meta_graph(latest_checkpoint_path + '.meta')\r\n        saver.restore(sess, latest_checkpoint_path)\r\n\r\n        input_arrays = [\"dnn/input_from_feature_columns/input_layer/concat\"]\r\n        output_arrays = [\"dnn/logits/BiasAdd\"]\r\n\r\n        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess, sess.graph_def,\r\n            output_node_names=[\"dnn/logits/BiasAdd\"])\r\n\r\n        frozen_graph = \"out/frozen_graph.pb\"\r\n\r\n        with tf.gfile.FastGFile(frozen_graph, \"wb\") as f:\r\n                f.write(frozen_graph_def.SerializeToString())\r\n\r\n        # save original graphdef to text file\r\n        with open(\"estimator_graph.pbtxt\", \"w\") as fp:\r\n            fp.write(str(sess.graph_def))\r\n        # save frozen graph def to text file\r\n        with open(\"estimator_frozen_graph.pbtxt\", \"w\") as fp:\r\n            fp.write(str(frozen_graph_def))\r\n\r\n        input_node_names = input_arrays\r\n        output_node_name = output_arrays\r\n        output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n                frozen_graph_def, input_node_names, output_node_name,\r\n                tf.float32.as_datatype_enum)\r\n\r\n        final_model_path = 'out/opt_' + MODEL_NAME + '.pb'\r\n        with tf.gfile.FastGFile(final_model_path, \"wb\") as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n\r\n        tflite_file = \"out/iris.tflite\"\r\n\r\n        converter = tf.contrib.lite.TocoConverter.from_frozen_graph(final_model_path, input_arrays, output_arrays, input_shapes={\"dnn/input_from_feature_columns/input_layer/concat\": [1, 10]})\r\n        tflite_model = converter.convert()\r\n        open(tflite_file, \"wb\").write(tflite_model)\r\n\r\n        interpreter = tf.contrib.lite.Interpreter(model_path=tflite_file)\r\n        interpreter.allocate_tensors()\r\n\r\n        # Get input and output tensors.\r\n        input_details = interpreter.get_input_details()\r\n        output_details = interpreter.get_output_details()\r\n\r\n        # Test model on random input data.\r\n        input_shape = input_details[0]['shape']\r\n        # change the following line to feed into your own data.\r\n        input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n        resultlist = list()\r\n        df = pd.read_csv(test_path)\r\n        expected = df.iloc[:, -1].values.tolist()\r\n        with open(test_path, newline='') as f:\r\n            reader = csv.reader(f)\r\n            column_names = next(reader)\r\n            for x in range(1, len(expected)):\r\n                linea = next(reader)\r\n                linea = linea[:len(linea) - 1]\r\n                input_data2 = np.array(linea, dtype=np.float32)\r\n                interpreter.set_tensor(input_details[0]['index'], [input_data2])\r\n                interpreter.invoke()\r\n                output_data = interpreter.get_tensor(output_details[0]['index'])\r\n                #print(output_data)\r\n                max = 0;\r\n                longitud = len(output_data[0])\r\n\r\n                for k in range(0, longitud):\r\n                    if (output_data[0][k] > output_data[0][max]):\r\n                        max = k\r\n                resultlist.append(max)\r\n            print(resultlist)\r\n\r\n        coincidences = 0\r\n        for pred_dict, expec in zip(resultlist, expected):\r\n            if pred_dict == expec:\r\n                coincidences = coincidences + 1\r\n\r\n        print(\"tflite Accuracy: \" + str(coincidences / len(expected)))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run(main)\r\n```"}