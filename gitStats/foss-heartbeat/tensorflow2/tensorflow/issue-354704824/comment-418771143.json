{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/418771143", "html_url": "https://github.com/tensorflow/tensorflow/issues/21921#issuecomment-418771143", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21921", "id": 418771143, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODc3MTE0Mw==", "user": {"login": "hequn", "id": 6846124, "node_id": "MDQ6VXNlcjY4NDYxMjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/6846124?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hequn", "html_url": "https://github.com/hequn", "followers_url": "https://api.github.com/users/hequn/followers", "following_url": "https://api.github.com/users/hequn/following{/other_user}", "gists_url": "https://api.github.com/users/hequn/gists{/gist_id}", "starred_url": "https://api.github.com/users/hequn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hequn/subscriptions", "organizations_url": "https://api.github.com/users/hequn/orgs", "repos_url": "https://api.github.com/users/hequn/repos", "events_url": "https://api.github.com/users/hequn/events{/privacy}", "received_events_url": "https://api.github.com/users/hequn/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-05T15:21:21Z", "updated_at": "2018-09-06T09:28:08Z", "author_association": "NONE", "body_html": "<h2>Hi, guys <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10109708\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/YijinLiu\">@YijinLiu</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19747012\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jimenisimo\">@jimenisimo</a> I solved my problem by adding the std and mean to the input data though I did not give the  \"--mean_values=128     --std_values=128\" when using bazel compile.<br>\nWhen inferring the image, 'input_data = np.expand_dims((input_data - args.input_mean) / args.input_std, axis=0)' should be given , and the input_mean is 128/ std is 128.</h2>\n<p>errrrrrr, finally I check the source code and find the comment first:<br>\n\"In floating point Mobilenet model, 'normalized_image_tensor' has values<br>\nbetween [-1,1). This typically means mapping each pixel (linearly)<br>\nto a value between [-1, 1]. Input image<br>\nvalues between 0 and 255 are scaled by (1/128.0) and then a value of<br>\n-1 is added to them to ensure the range is [-1,1).<br>\nIn quantized Mobilenet model, 'normalized_image_tensor' has values between [0,<br>\n255].\"<br>\nIn the<br>\n1\u3001\"export_tflite_graph.py-&gt;predicted_tensors = detection_model.predict(image, true_image_shapes=None)\"<br>\n2\u3001\"model_builder.py-&gt;'ssd_mobilenet_v2': SSDMobileNetV2FeatureExtractor,\"<br>\n3\u3001\"SSDMobileNetV2FeatureExtractor.py-&gt;def preprocess(self, resized_inputs):return (2.0 / 255.0) * resized_inputs - 1.0\"<br>\nWhere the normalization was done, but not for tflite, it is for \"export_inference_graph.py\". So careless I am, sorry guys.</p>", "body_text": "Hi, guys @YijinLiu @jimenisimo I solved my problem by adding the std and mean to the input data though I did not give the  \"--mean_values=128     --std_values=128\" when using bazel compile.\nWhen inferring the image, 'input_data = np.expand_dims((input_data - args.input_mean) / args.input_std, axis=0)' should be given , and the input_mean is 128/ std is 128.\nerrrrrrr, finally I check the source code and find the comment first:\n\"In floating point Mobilenet model, 'normalized_image_tensor' has values\nbetween [-1,1). This typically means mapping each pixel (linearly)\nto a value between [-1, 1]. Input image\nvalues between 0 and 255 are scaled by (1/128.0) and then a value of\n-1 is added to them to ensure the range is [-1,1).\nIn quantized Mobilenet model, 'normalized_image_tensor' has values between [0,\n255].\"\nIn the\n1\u3001\"export_tflite_graph.py->predicted_tensors = detection_model.predict(image, true_image_shapes=None)\"\n2\u3001\"model_builder.py->'ssd_mobilenet_v2': SSDMobileNetV2FeatureExtractor,\"\n3\u3001\"SSDMobileNetV2FeatureExtractor.py->def preprocess(self, resized_inputs):return (2.0 / 255.0) * resized_inputs - 1.0\"\nWhere the normalization was done, but not for tflite, it is for \"export_inference_graph.py\". So careless I am, sorry guys.", "body": "Hi, guys @YijinLiu @jimenisimo I solved my problem by adding the std and mean to the input data though I did not give the  \"--mean_values=128     --std_values=128\" when using bazel compile.\r\nWhen inferring the image, 'input_data = np.expand_dims((input_data - args.input_mean) / args.input_std, axis=0)' should be given , and the input_mean is 128/ std is 128.\r\n---------------------------------------------------------------------------------------------------------------\r\nerrrrrrr, finally I check the source code and find the comment first:\r\n\"In floating point Mobilenet model, 'normalized_image_tensor' has values\r\nbetween [-1,1). This typically means mapping each pixel (linearly)\r\nto a value between [-1, 1]. Input image\r\nvalues between 0 and 255 are scaled by (1/128.0) and then a value of\r\n-1 is added to them to ensure the range is [-1,1).\r\nIn quantized Mobilenet model, 'normalized_image_tensor' has values between [0,\r\n255].\"\r\nIn the \r\n1\u3001\"export_tflite_graph.py->predicted_tensors = detection_model.predict(image, true_image_shapes=None)\"\r\n2\u3001\"model_builder.py->'ssd_mobilenet_v2': SSDMobileNetV2FeatureExtractor,\"\r\n3\u3001\"SSDMobileNetV2FeatureExtractor.py->def preprocess(self, resized_inputs):return (2.0 / 255.0) * resized_inputs - 1.0\"\r\nWhere the normalization was done, but not for tflite, it is for \"export_inference_graph.py\". So careless I am, sorry guys."}