{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12512", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12512/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12512/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12512/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12512", "id": 252158733, "node_id": "MDU6SXNzdWUyNTIxNTg3MzM=", "number": 12512, "title": "NaNs during training with `tf.contrib.rnn.LayerNormBasicLSTMCell`", "user": {"login": "alanhdu", "id": 1914111, "node_id": "MDQ6VXNlcjE5MTQxMTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1914111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanhdu", "html_url": "https://github.com/alanhdu", "followers_url": "https://api.github.com/users/alanhdu/followers", "following_url": "https://api.github.com/users/alanhdu/following{/other_user}", "gists_url": "https://api.github.com/users/alanhdu/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanhdu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanhdu/subscriptions", "organizations_url": "https://api.github.com/users/alanhdu/orgs", "repos_url": "https://api.github.com/users/alanhdu/repos", "events_url": "https://api.github.com/users/alanhdu/events{/privacy}", "received_events_url": "https://api.github.com/users/alanhdu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-23T04:48:54Z", "updated_at": "2018-09-05T17:00:34Z", "closed_at": "2017-08-28T04:41:19Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3</li>\n<li><strong>Python version</strong>:  3.5</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 8.0 and CuDNN 6 (although I can replicate without a GPU)</li>\n<li><strong>GPU model and memory</strong>: Nvidia K80 (from Amazon P2 instance)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When training a model using <code>tf.contrib.rnn.LayerNormBasicLSTMCell</code>, sometimes my weights go to <code>nan</code>, even though the training data looks perfectly innocent.</p>\n<p><del>I have <strong>not</strong> seen this with Tensorflow 1.2.1, which leads me to suspect that there's been a regression somewhere, but I could've just been luckier (<g-emoji class=\"g-emoji\" alias=\"four_leaf_clover\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f340.png\">\ud83c\udf40</g-emoji>) with TF 1.2</del> (nevermind -- I have reproduced this with TF 1.2.1)</p>\n<h3>Source code / logs</h3>\n<p>I've created two examples of this in <a href=\"https://github.com/alanhdu/tensorflow-12512\">https://github.com/alanhdu/tensorflow-12512</a> (clone the repo, enter a folder, and run <code>test.py</code> or build and run the <code>Dockerfile</code>. The key line(s) there are:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">print</span>([np.isfinite(v).all() <span class=\"pl-k\">for</span> v <span class=\"pl-k\">in</span> sess.run(tf.trainable_variables())])\nsess.run(train_step, feed_dict)\n<span class=\"pl-c1\">print</span>([np.isfinite(v).all() <span class=\"pl-k\">for</span> v <span class=\"pl-k\">in</span> sess.run(tf.trainable_variables())])</pre></div>\n<p>The first print statement prints all <code>True</code>s, which is good -- but after the training step, suddenly some of the weights have <code>nan</code>s in them (and hence there's one <code>False</code> in the second print statement).</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.3\nPython version:  3.5\nCUDA/cuDNN version: CUDA 8.0 and CuDNN 6 (although I can replicate without a GPU)\nGPU model and memory: Nvidia K80 (from Amazon P2 instance)\nExact command to reproduce:\n\nDescribe the problem\nWhen training a model using tf.contrib.rnn.LayerNormBasicLSTMCell, sometimes my weights go to nan, even though the training data looks perfectly innocent.\nI have not seen this with Tensorflow 1.2.1, which leads me to suspect that there's been a regression somewhere, but I could've just been luckier (\ud83c\udf40) with TF 1.2 (nevermind -- I have reproduced this with TF 1.2.1)\nSource code / logs\nI've created two examples of this in https://github.com/alanhdu/tensorflow-12512 (clone the repo, enter a folder, and run test.py or build and run the Dockerfile. The key line(s) there are:\nprint([np.isfinite(v).all() for v in sess.run(tf.trainable_variables())])\nsess.run(train_step, feed_dict)\nprint([np.isfinite(v).all() for v in sess.run(tf.trainable_variables())])\nThe first print statement prints all Trues, which is good -- but after the training step, suddenly some of the weights have nans in them (and hence there's one False in the second print statement).", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**:  3.5\r\n- **CUDA/cuDNN version**: CUDA 8.0 and CuDNN 6 (although I can replicate without a GPU)\r\n- **GPU model and memory**: Nvidia K80 (from Amazon P2 instance)\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nWhen training a model using `tf.contrib.rnn.LayerNormBasicLSTMCell`, sometimes my weights go to `nan`, even though the training data looks perfectly innocent.\r\n\r\n~~I have **not** seen this with Tensorflow 1.2.1, which leads me to suspect that there's been a regression somewhere, but I could've just been luckier (\ud83c\udf40) with TF 1.2~~ (nevermind -- I have reproduced this with TF 1.2.1)\r\n\r\n### Source code / logs\r\n\r\nI've created two examples of this in https://github.com/alanhdu/tensorflow-12512 (clone the repo, enter a folder, and run `test.py` or build and run the `Dockerfile`. The key line(s) there are:\r\n\r\n```python\r\nprint([np.isfinite(v).all() for v in sess.run(tf.trainable_variables())])\r\nsess.run(train_step, feed_dict)\r\nprint([np.isfinite(v).all() for v in sess.run(tf.trainable_variables())])\r\n```\r\n\r\nThe first print statement prints all `True`s, which is good -- but after the training step, suddenly some of the weights have `nan`s in them (and hence there's one `False` in the second print statement)."}