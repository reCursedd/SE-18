{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/321606303", "html_url": "https://github.com/tensorflow/tensorflow/issues/12154#issuecomment-321606303", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12154", "id": 321606303, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTYwNjMwMw==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-10T16:38:32Z", "updated_at": "2017-08-10T16:38:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>As a heuristic, you could search for all instances of <code>ops.RegisterGradient</code>, that gives you which op has a gradient associated. You can then get source, and parse out <code>None</code>s out of <code>return</code> line, which gives you the inputs without gradients.</p>\n<p>Note that this works only for atomic ops. Something like <code>tf.norm</code> will support gradients, but there are no gradients for this op in particular because it's defined in terms of sqrt/reduce_sum/etc</p>", "body_text": "As a heuristic, you could search for all instances of ops.RegisterGradient, that gives you which op has a gradient associated. You can then get source, and parse out Nones out of return line, which gives you the inputs without gradients.\nNote that this works only for atomic ops. Something like tf.norm will support gradients, but there are no gradients for this op in particular because it's defined in terms of sqrt/reduce_sum/etc", "body": "As a heuristic, you could search for all instances of `ops.RegisterGradient`, that gives you which op has a gradient associated. You can then get source, and parse out `None`s out of `return` line, which gives you the inputs without gradients.\r\n\r\nNote that this works only for atomic ops. Something like `tf.norm` will support gradients, but there are no gradients for this op in particular because it's defined in terms of sqrt/reduce_sum/etc"}