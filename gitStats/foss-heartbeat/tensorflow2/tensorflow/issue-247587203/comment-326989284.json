{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326989284", "html_url": "https://github.com/tensorflow/tensorflow/issues/11988#issuecomment-326989284", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988", "id": 326989284, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjk4OTI4NA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-04T15:35:21Z", "updated_at": "2017-09-04T15:35:21Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">One could add a special case for scalar state that just passes it through.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sep 4, 2017 12:33 AM, \"Lee\" ***@***.***&gt; wrote:\n I have found similar error while I use AttentionWrapper at raw_rnn. It\n seems that the problem came from the function _copy_some_through when it\n try to copy next_state to state conditioned on elements_finished. I think\n it is the consequence of time attribute of AttentionWrapperState can not\n be copied through by the code tf.where(elements_finished, cur_i, cand_i)\n inside _copy_some_through, since time is just a scalar but\n elements_finished is a tensor shaped like [batch_size].\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"247587203\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11988\" href=\"https://github.com/tensorflow/tensorflow/issues/11988#issuecomment-326887212\">#11988 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim2TiNfp4R-5_vpD8j6cm8RI0jSa9ks5se6fOgaJpZM4Or7y3\">https://github.com/notifications/unsubscribe-auth/ABtim2TiNfp4R-5_vpD8j6cm8RI0jSa9ks5se6fOgaJpZM4Or7y3</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "One could add a special case for scalar state that just passes it through.\n\u2026\nOn Sep 4, 2017 12:33 AM, \"Lee\" ***@***.***> wrote:\n I have found similar error while I use AttentionWrapper at raw_rnn. It\n seems that the problem came from the function _copy_some_through when it\n try to copy next_state to state conditioned on elements_finished. I think\n it is the consequence of time attribute of AttentionWrapperState can not\n be copied through by the code tf.where(elements_finished, cur_i, cand_i)\n inside _copy_some_through, since time is just a scalar but\n elements_finished is a tensor shaped like [batch_size].\n\n \u2014\n You are receiving this because you were assigned.\n Reply to this email directly, view it on GitHub\n <#11988 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim2TiNfp4R-5_vpD8j6cm8RI0jSa9ks5se6fOgaJpZM4Or7y3>\n .", "body": "One could add a special case for scalar state that just passes it through.\n\nOn Sep 4, 2017 12:33 AM, \"Lee\" <notifications@github.com> wrote:\n\n> I have found similar error while I use AttentionWrapper at raw_rnn. It\n> seems that the problem came from the function _copy_some_through when it\n> try to copy next_state to state conditioned on elements_finished. I think\n> it is the consequence of time attribute of AttentionWrapperState can not\n> be copied through by the code tf.where(elements_finished, cur_i, cand_i)\n> inside _copy_some_through, since time is just a scalar but\n> elements_finished is a tensor shaped like [batch_size].\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11988#issuecomment-326887212>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim2TiNfp4R-5_vpD8j6cm8RI0jSa9ks5se6fOgaJpZM4Or7y3>\n> .\n>\n"}