{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11988", "id": 247587203, "node_id": "MDU6SXNzdWUyNDc1ODcyMDM=", "number": 11988, "title": "AttentionWrapper is not compatible with dynamic_rnn", "user": {"login": "jingxil", "id": 7728630, "node_id": "MDQ6VXNlcjc3Mjg2MzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/7728630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jingxil", "html_url": "https://github.com/jingxil", "followers_url": "https://api.github.com/users/jingxil/followers", "following_url": "https://api.github.com/users/jingxil/following{/other_user}", "gists_url": "https://api.github.com/users/jingxil/gists{/gist_id}", "starred_url": "https://api.github.com/users/jingxil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jingxil/subscriptions", "organizations_url": "https://api.github.com/users/jingxil/orgs", "repos_url": "https://api.github.com/users/jingxil/repos", "events_url": "https://api.github.com/users/jingxil/events{/privacy}", "received_events_url": "https://api.github.com/users/jingxil/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "lmthang", "id": 396613, "node_id": "MDQ6VXNlcjM5NjYxMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/396613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmthang", "html_url": "https://github.com/lmthang", "followers_url": "https://api.github.com/users/lmthang/followers", "following_url": "https://api.github.com/users/lmthang/following{/other_user}", "gists_url": "https://api.github.com/users/lmthang/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmthang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmthang/subscriptions", "organizations_url": "https://api.github.com/users/lmthang/orgs", "repos_url": "https://api.github.com/users/lmthang/repos", "events_url": "https://api.github.com/users/lmthang/events{/privacy}", "received_events_url": "https://api.github.com/users/lmthang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "lmthang", "id": 396613, "node_id": "MDQ6VXNlcjM5NjYxMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/396613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmthang", "html_url": "https://github.com/lmthang", "followers_url": "https://api.github.com/users/lmthang/followers", "following_url": "https://api.github.com/users/lmthang/following{/other_user}", "gists_url": "https://api.github.com/users/lmthang/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmthang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmthang/subscriptions", "organizations_url": "https://api.github.com/users/lmthang/orgs", "repos_url": "https://api.github.com/users/lmthang/repos", "events_url": "https://api.github.com/users/lmthang/events{/privacy}", "received_events_url": "https://api.github.com/users/lmthang/received_events", "type": "User", "site_admin": false}, {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-08-03T04:11:15Z", "updated_at": "2017-12-24T12:16:55Z", "closed_at": "2017-12-24T12:16:55Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>TensorFlow version (v1.2.0-rc2-21-g12f033d 1.2.0)</strong>:</li>\n<li><strong>Python 3</strong></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The return of <code>zero_state</code> function of  <code>tensorflow.contrib.seq2seq.AttentionWrapper</code> is not compatible with <code>tensorflow.nn.dynamic_rnn</code> function.  It seems that <code>if output.shape.ndims == 0:</code> in <code>_copy_one_through</code> function does not work. Once those scalar elements in return tuple are modified to have the shape like [batch_size, ...] the error disappears.</p>\n<h3>Code to reproduce the bug</h3>\n<pre><code>import tensorflow as tf\n\nbatch_size=2\nhidden_units = 3\nattention_size = 4\nmax_len = 5\n\ninputs = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\ncontext = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\ninput_lens = (2,4)\n\ncell = tf.contrib.rnn.LSTMCell(hidden_units)\nam = tf.contrib.seq2seq.BahdanauAttention(attention_size, context)\nwrapper = tf.contrib.seq2seq.AttentionWrapper(cell,am)\ntf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\n</code></pre>\n<h3>Log</h3>\n<pre><code>Traceback (most recent call last):\n  File \"test.py\", line 15, in &lt;module&gt;\n    tf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\n    skip_conditionals=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 210, in _rnn_step\n    final_output_and_state = _copy_some_through(new_output, new_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in _copy_some_through\n    for state, new_state in zip(flat_state, flat_new_state)]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in &lt;listcomp&gt;\n    for state, new_state in zip(flat_state, flat_new_state)]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 171, in _copy_one_through\n    return array_ops.where(copy_cond, output, new_output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [2], [], [].\n</code></pre>", "body_text": "System information\n\nTensorFlow version (v1.2.0-rc2-21-g12f033d 1.2.0):\nPython 3\n\nDescribe the problem\nThe return of zero_state function of  tensorflow.contrib.seq2seq.AttentionWrapper is not compatible with tensorflow.nn.dynamic_rnn function.  It seems that if output.shape.ndims == 0: in _copy_one_through function does not work. Once those scalar elements in return tuple are modified to have the shape like [batch_size, ...] the error disappears.\nCode to reproduce the bug\nimport tensorflow as tf\n\nbatch_size=2\nhidden_units = 3\nattention_size = 4\nmax_len = 5\n\ninputs = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\ncontext = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\ninput_lens = (2,4)\n\ncell = tf.contrib.rnn.LSTMCell(hidden_units)\nam = tf.contrib.seq2seq.BahdanauAttention(attention_size, context)\nwrapper = tf.contrib.seq2seq.AttentionWrapper(cell,am)\ntf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\n\nLog\nTraceback (most recent call last):\n  File \"test.py\", line 15, in <module>\n    tf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\n    skip_conditionals=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 210, in _rnn_step\n    final_output_and_state = _copy_some_through(new_output, new_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in _copy_some_through\n    for state, new_state in zip(flat_state, flat_new_state)]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in <listcomp>\n    for state, new_state in zip(flat_state, flat_new_state)]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 171, in _copy_one_through\n    return array_ops.where(copy_cond, output, new_output)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [2], [], [].", "body": "### System information\r\n- **TensorFlow version (v1.2.0-rc2-21-g12f033d 1.2.0)**:\r\n- **Python 3**\r\n\r\n### Describe the problem\r\n\r\nThe return of `zero_state` function of  `tensorflow.contrib.seq2seq.AttentionWrapper` is not compatible with `tensorflow.nn.dynamic_rnn` function.  It seems that `if output.shape.ndims == 0:` in `_copy_one_through` function does not work. Once those scalar elements in return tuple are modified to have the shape like [batch_size, ...] the error disappears.\r\n\r\n### Code to reproduce the bug\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nbatch_size=2\r\nhidden_units = 3\r\nattention_size = 4\r\nmax_len = 5\r\n\r\ninputs = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\r\ncontext = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\r\ninput_lens = (2,4)\r\n\r\ncell = tf.contrib.rnn.LSTMCell(hidden_units)\r\nam = tf.contrib.seq2seq.BahdanauAttention(attention_size, context)\r\nwrapper = tf.contrib.seq2seq.AttentionWrapper(cell,am)\r\ntf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\r\n```\r\n### Log\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 15, in <module>\r\n    tf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 210, in _rnn_step\r\n    final_output_and_state = _copy_some_through(new_output, new_state)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in _copy_some_through\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in <listcomp>\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 171, in _copy_one_through\r\n    return array_ops.where(copy_cond, output, new_output)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\r\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [2], [], [].\r\n```"}