{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326887212", "html_url": "https://github.com/tensorflow/tensorflow/issues/11988#issuecomment-326887212", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11988", "id": 326887212, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjg4NzIxMg==", "user": {"login": "lyy1994", "id": 7354097, "node_id": "MDQ6VXNlcjczNTQwOTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7354097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lyy1994", "html_url": "https://github.com/lyy1994", "followers_url": "https://api.github.com/users/lyy1994/followers", "following_url": "https://api.github.com/users/lyy1994/following{/other_user}", "gists_url": "https://api.github.com/users/lyy1994/gists{/gist_id}", "starred_url": "https://api.github.com/users/lyy1994/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lyy1994/subscriptions", "organizations_url": "https://api.github.com/users/lyy1994/orgs", "repos_url": "https://api.github.com/users/lyy1994/repos", "events_url": "https://api.github.com/users/lyy1994/events{/privacy}", "received_events_url": "https://api.github.com/users/lyy1994/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-04T07:32:44Z", "updated_at": "2017-09-04T07:33:36Z", "author_association": "NONE", "body_html": "<p>I have found similar error while I use <code>AttentionWrapper</code> at <code>raw_rnn</code>. It seems that the problem came from the function <code>_copy_some_through</code> when it try to copy <code>next_state</code> to <code>state</code> conditioned on <code>elements_finished</code>. I think it is the consequence of <code>time</code> attribute of <code>AttentionWrapperState</code> can not be copied through by the code <code>tf.where(elements_finished, cur_i, cand_i)</code> inside function <code>_copy_some_through</code> implementation, since <code>time</code> is just a scalar but <code>elements_finished</code> is a tensor shaped like <code>[batch_size]</code>.</p>", "body_text": "I have found similar error while I use AttentionWrapper at raw_rnn. It seems that the problem came from the function _copy_some_through when it try to copy next_state to state conditioned on elements_finished. I think it is the consequence of time attribute of AttentionWrapperState can not be copied through by the code tf.where(elements_finished, cur_i, cand_i) inside function _copy_some_through implementation, since time is just a scalar but elements_finished is a tensor shaped like [batch_size].", "body": "I have found similar error while I use `AttentionWrapper` at `raw_rnn`. It seems that the problem came from the function `_copy_some_through` when it try to copy `next_state` to `state` conditioned on `elements_finished`. I think it is the consequence of `time` attribute of `AttentionWrapperState` can not be copied through by the code `tf.where(elements_finished, cur_i, cand_i)` inside function `_copy_some_through` implementation, since `time` is just a scalar but `elements_finished` is a tensor shaped like `[batch_size]`."}