{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15782", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15782/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15782/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15782/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15782", "id": 285380491, "node_id": "MDU6SXNzdWUyODUzODA0OTE=", "number": 15782, "title": "[BUG REPORT] how to set TF_CONFIG,  bug ? ", "user": {"login": "automateljw", "id": 5774705, "node_id": "MDQ6VXNlcjU3NzQ3MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5774705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/automateljw", "html_url": "https://github.com/automateljw", "followers_url": "https://api.github.com/users/automateljw/followers", "following_url": "https://api.github.com/users/automateljw/following{/other_user}", "gists_url": "https://api.github.com/users/automateljw/gists{/gist_id}", "starred_url": "https://api.github.com/users/automateljw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/automateljw/subscriptions", "organizations_url": "https://api.github.com/users/automateljw/orgs", "repos_url": "https://api.github.com/users/automateljw/repos", "events_url": "https://api.github.com/users/automateljw/events{/privacy}", "received_events_url": "https://api.github.com/users/automateljw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-01-02T08:56:17Z", "updated_at": "2018-01-03T02:05:57Z", "closed_at": "2018-01-03T02:05:57Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\n('v1.4.0-19-ga52c8d9', '1.4.1')</p>\n<h3>Describe the problem</h3>\n<p>[NORMAL CODE]</p>\n<pre><code>  chief_host = ['localhost:20000']\n  worker_hosts = ['localhost:20002']\n  ps_hosts = ['localhost:20001']\n\n  cluster = {'chief': chief_host,\n             'worker': worker_hosts,\n             'ps': ps_hosts}\n  task_type = 'chief'\n  task_index = 0\n  os.environ['TF_CONFIG'] = json.dumps(\n      {'cluster': cluster,\n       'task': {'type': task_type, 'index': task_index}})\n</code></pre>\n<p>[ NORMAL OUTPUT]</p>\n<pre><code>INFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20001'], u'chief': [u'localhost:20000'], u'worker': [u'localhost:20002']}, u'task': {u'index': 0, u'type': u'chief'}}\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\n  key: \"GPU\"\n}\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x5e30bd0&gt;, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhost:20000', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\nINFO:tensorflow:Start Tensorflow server.\n2018-01-02 16:31:58.374169: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\nE0102 16:31:58.378815122   44355 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\n2018-01-02 16:31:58.384682: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -&gt; {0 -&gt; localhost:20000}\n2018-01-02 16:31:58.384723: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:20001}\n2018-01-02 16:31:58.384736: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:20002}\n2018-01-02 16:31:58.391874: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20000\nParsing data/adult.data\nINFO:tensorflow:Create CheckpointSaverHook.\n2018-01-02 16:32:10.407610: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:10.407652: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n2018-01-02 16:32:20.407746: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:20.407766: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n2018-01-02 16:32:30.407834: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:30.407850: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n</code></pre>\n<p>============</p>\n<p>[BUG CODE]</p>\n<pre><code>  print(type(chief_host), type(worker_hosts), type(ps_hosts))\n  print('chief=',chief_host, 'worker=',worker_hosts, 'ps=',ps_hosts)\n\n  chief_host = chief_host\n  worker_hosts = worker_hosts\n  ps_hosts = ps_hosts\n\n  cluster = {'chief': chief_host,\n             'worker': worker_hosts,\n             'ps': ps_hosts}\n  task_type = 'chief' \n  task_index = 0 \n  os.environ['TF_CONFIG'] = json.dumps(\n      {'cluster': cluster,\n       'task': {'type': task_type, 'index': task_index}})\n</code></pre>\n<p>[BUG OUTPUT]</p>\n<pre><code>&lt;type 'list'&gt; &lt;type 'list'&gt; &lt;type 'list'&gt;\nchief= ['localhosts:20001'] worker= ['localhost:20003'] ps= ['localhost:20000']\n\nINFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20000'], u'chief': [u'localhosts:20001'], u'worker': [u'localhost:20003']}, u'task': {u'index': 0, u'type': u'chief'}}\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\n  key: \"GPU\"\n}\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x6264e10&gt;, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhosts:20001', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\nINFO:tensorflow:Start Tensorflow server.\n2018-01-02 16:34:09.909573: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\nE0102 16:34:09.914156177   44635 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\n2018-01-02 16:34:09.920491: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -&gt; {0 -&gt; localhost:20001}\n2018-01-02 16:34:09.920540: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:20000}\n2018-01-02 16:34:09.920558: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:20003}\n2018-01-02 16:34:09.927272: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20001\nParsing data/adult.data\nINFO:tensorflow:Create CheckpointSaverHook.\n</code></pre>\n<p>Note: [ BUG OUTPUT ] don't print \" CreateSession still waiting for response from worker \" ,  i have wait long enough !!!</p>\n<p>===========<br>\nmy train and eval code</p>\n<pre><code>  train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(FLAGS.train_data,\n      None, True, FLAGS.batch_size), max_steps=30000)\n  eval_spec = tf.estimator.EvalSpec(input_fn=lambda: input_fn(FLAGS.test_data, 1, False,\n      FLAGS.batch_size), steps=5)\n  tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n</code></pre>\n<p>i can run my code on non-distribution and distribution as follows style:</p>\n<pre><code>TF_CONFIG='{\n    \"cluster\": {\n        \"chief\": [\"localhost:20000\"],\n        \"worker\": [\"localhost:20002\"],\n        \"ps\": [\"localhost:20001\"]\n    },\n    \"task\": {\"type\": \"worker\", \"index\": 0}\n}'\nTF_CONFIG=$TF_CONFIG python wide_deep_d.py \n\n......\n</code></pre>\n<p>but can't set TF_CONFIG by os.environ with json.dumps correctly</p>\n<p>Need your help, Thanks ,</p>", "body_text": "System information\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n('v1.4.0-19-ga52c8d9', '1.4.1')\nDescribe the problem\n[NORMAL CODE]\n  chief_host = ['localhost:20000']\n  worker_hosts = ['localhost:20002']\n  ps_hosts = ['localhost:20001']\n\n  cluster = {'chief': chief_host,\n             'worker': worker_hosts,\n             'ps': ps_hosts}\n  task_type = 'chief'\n  task_index = 0\n  os.environ['TF_CONFIG'] = json.dumps(\n      {'cluster': cluster,\n       'task': {'type': task_type, 'index': task_index}})\n\n[ NORMAL OUTPUT]\nINFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20001'], u'chief': [u'localhost:20000'], u'worker': [u'localhost:20002']}, u'task': {u'index': 0, u'type': u'chief'}}\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\n  key: \"GPU\"\n}\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x5e30bd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhost:20000', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\nINFO:tensorflow:Start Tensorflow server.\n2018-01-02 16:31:58.374169: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\nE0102 16:31:58.378815122   44355 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\n2018-01-02 16:31:58.384682: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20000}\n2018-01-02 16:31:58.384723: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20001}\n2018-01-02 16:31:58.384736: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20002}\n2018-01-02 16:31:58.391874: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20000\nParsing data/adult.data\nINFO:tensorflow:Create CheckpointSaverHook.\n2018-01-02 16:32:10.407610: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:10.407652: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n2018-01-02 16:32:20.407746: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:20.407766: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n2018-01-02 16:32:30.407834: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n2018-01-02 16:32:30.407850: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\n\n============\n[BUG CODE]\n  print(type(chief_host), type(worker_hosts), type(ps_hosts))\n  print('chief=',chief_host, 'worker=',worker_hosts, 'ps=',ps_hosts)\n\n  chief_host = chief_host\n  worker_hosts = worker_hosts\n  ps_hosts = ps_hosts\n\n  cluster = {'chief': chief_host,\n             'worker': worker_hosts,\n             'ps': ps_hosts}\n  task_type = 'chief' \n  task_index = 0 \n  os.environ['TF_CONFIG'] = json.dumps(\n      {'cluster': cluster,\n       'task': {'type': task_type, 'index': task_index}})\n\n[BUG OUTPUT]\n<type 'list'> <type 'list'> <type 'list'>\nchief= ['localhosts:20001'] worker= ['localhost:20003'] ps= ['localhost:20000']\n\nINFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20000'], u'chief': [u'localhosts:20001'], u'worker': [u'localhost:20003']}, u'task': {u'index': 0, u'type': u'chief'}}\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\n  key: \"GPU\"\n}\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x6264e10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhosts:20001', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\nINFO:tensorflow:Start Tensorflow server.\n2018-01-02 16:34:09.909573: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\nE0102 16:34:09.914156177   44635 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\n2018-01-02 16:34:09.920491: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20001}\n2018-01-02 16:34:09.920540: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20000}\n2018-01-02 16:34:09.920558: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20003}\n2018-01-02 16:34:09.927272: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20001\nParsing data/adult.data\nINFO:tensorflow:Create CheckpointSaverHook.\n\nNote: [ BUG OUTPUT ] don't print \" CreateSession still waiting for response from worker \" ,  i have wait long enough !!!\n===========\nmy train and eval code\n  train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(FLAGS.train_data,\n      None, True, FLAGS.batch_size), max_steps=30000)\n  eval_spec = tf.estimator.EvalSpec(input_fn=lambda: input_fn(FLAGS.test_data, 1, False,\n      FLAGS.batch_size), steps=5)\n  tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n\ni can run my code on non-distribution and distribution as follows style:\nTF_CONFIG='{\n    \"cluster\": {\n        \"chief\": [\"localhost:20000\"],\n        \"worker\": [\"localhost:20002\"],\n        \"ps\": [\"localhost:20001\"]\n    },\n    \"task\": {\"type\": \"worker\", \"index\": 0}\n}'\nTF_CONFIG=$TF_CONFIG python wide_deep_d.py \n\n......\n\nbut can't set TF_CONFIG by os.environ with json.dumps correctly\nNeed your help, Thanks ,", "body": "------------------------\r\n\r\n### System information\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.4.0-19-ga52c8d9', '1.4.1')\r\n\r\n\r\n### Describe the problem\r\n\r\n[NORMAL CODE]\r\n```\r\n  chief_host = ['localhost:20000']\r\n  worker_hosts = ['localhost:20002']\r\n  ps_hosts = ['localhost:20001']\r\n\r\n  cluster = {'chief': chief_host,\r\n             'worker': worker_hosts,\r\n             'ps': ps_hosts}\r\n  task_type = 'chief'\r\n  task_index = 0\r\n  os.environ['TF_CONFIG'] = json.dumps(\r\n      {'cluster': cluster,\r\n       'task': {'type': task_type, 'index': task_index}})\r\n```\r\n\r\n[ NORMAL OUTPUT]\r\n```\r\nINFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20001'], u'chief': [u'localhost:20000'], u'worker': [u'localhost:20002']}, u'task': {u'index': 0, u'type': u'chief'}}\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\r\n  key: \"GPU\"\r\n}\r\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x5e30bd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhost:20000', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\r\nINFO:tensorflow:Start Tensorflow server.\r\n2018-01-02 16:31:58.374169: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\nE0102 16:31:58.378815122   44355 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\r\n2018-01-02 16:31:58.384682: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20000}\r\n2018-01-02 16:31:58.384723: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20001}\r\n2018-01-02 16:31:58.384736: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20002}\r\n2018-01-02 16:31:58.391874: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20000\r\nParsing data/adult.data\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2018-01-02 16:32:10.407610: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2018-01-02 16:32:10.407652: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\r\n2018-01-02 16:32:20.407746: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2018-01-02 16:32:20.407766: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\r\n2018-01-02 16:32:30.407834: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\r\n2018-01-02 16:32:30.407850: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0\r\n```\r\n\r\n============\r\n\r\n[BUG CODE]\r\n```\r\n  print(type(chief_host), type(worker_hosts), type(ps_hosts))\r\n  print('chief=',chief_host, 'worker=',worker_hosts, 'ps=',ps_hosts)\r\n\r\n  chief_host = chief_host\r\n  worker_hosts = worker_hosts\r\n  ps_hosts = ps_hosts\r\n\r\n  cluster = {'chief': chief_host,\r\n             'worker': worker_hosts,\r\n             'ps': ps_hosts}\r\n  task_type = 'chief' \r\n  task_index = 0 \r\n  os.environ['TF_CONFIG'] = json.dumps(\r\n      {'cluster': cluster,\r\n       'task': {'type': task_type, 'index': task_index}})\r\n```\r\n\r\n[BUG OUTPUT]\r\n```\r\n<type 'list'> <type 'list'> <type 'list'>\r\nchief= ['localhosts:20001'] worker= ['localhost:20003'] ps= ['localhost:20000']\r\n\r\nINFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20000'], u'chief': [u'localhosts:20001'], u'worker': [u'localhost:20003']}, u'task': {u'index': 0, u'type': u'chief'}}\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {\r\n  key: \"GPU\"\r\n}\r\n, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x6264e10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhosts:20001', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}\r\nINFO:tensorflow:Start Tensorflow server.\r\n2018-01-02 16:34:09.909573: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\nE0102 16:34:09.914156177   44635 ev_epoll1_linux.c:1051]     grpc epoll fd: 3\r\n2018-01-02 16:34:09.920491: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20001}\r\n2018-01-02 16:34:09.920540: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20000}\r\n2018-01-02 16:34:09.920558: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20003}\r\n2018-01-02 16:34:09.927272: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20001\r\nParsing data/adult.data\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n```\r\n\r\nNote: [ BUG OUTPUT ] don't print \" CreateSession still waiting for response from worker \" ,  i have wait long enough !!!\r\n\r\n===========\r\nmy train and eval code\r\n```\r\n  train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(FLAGS.train_data,\r\n      None, True, FLAGS.batch_size), max_steps=30000)\r\n  eval_spec = tf.estimator.EvalSpec(input_fn=lambda: input_fn(FLAGS.test_data, 1, False,\r\n      FLAGS.batch_size), steps=5)\r\n  tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\r\n```\r\ni can run my code on non-distribution and distribution as follows style:\r\n```\r\nTF_CONFIG='{\r\n    \"cluster\": {\r\n        \"chief\": [\"localhost:20000\"],\r\n        \"worker\": [\"localhost:20002\"],\r\n        \"ps\": [\"localhost:20001\"]\r\n    },\r\n    \"task\": {\"type\": \"worker\", \"index\": 0}\r\n}'\r\nTF_CONFIG=$TF_CONFIG python wide_deep_d.py \r\n\r\n......\r\n```\r\nbut can't set TF_CONFIG by os.environ with json.dumps correctly\r\n\r\nNeed your help, Thanks , "}