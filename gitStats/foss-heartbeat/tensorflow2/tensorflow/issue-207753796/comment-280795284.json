{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280795284", "html_url": "https://github.com/tensorflow/tensorflow/issues/7521#issuecomment-280795284", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7521", "id": 280795284, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDc5NTI4NA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-17T23:31:16Z", "updated_at": "2017-02-17T23:31:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It's impossible to say for certain without the user program. One possibility is that you have many Python threads that could be doing a non-trivial amount of work (e.g. copying buffers for feeding/fetching) outside the GIL and hence in parallel. These threads would be created outside the <code>tf.Session</code> and so would not be limited by the configuration options. Some operations (e.g. <code>ReaderRead</code>) create their own threads internally as well, and these are not bound by the configuration options either.</p>\n<p>TL;DR: If you want to force TensorFlow to use a single core, the best plan right now would be to use OS-level enforcement mechanisms (e.g. cgroups) to limit the process to (and schedule all its threads on) a single core.</p>", "body_text": "It's impossible to say for certain without the user program. One possibility is that you have many Python threads that could be doing a non-trivial amount of work (e.g. copying buffers for feeding/fetching) outside the GIL and hence in parallel. These threads would be created outside the tf.Session and so would not be limited by the configuration options. Some operations (e.g. ReaderRead) create their own threads internally as well, and these are not bound by the configuration options either.\nTL;DR: If you want to force TensorFlow to use a single core, the best plan right now would be to use OS-level enforcement mechanisms (e.g. cgroups) to limit the process to (and schedule all its threads on) a single core.", "body": "It's impossible to say for certain without the user program. One possibility is that you have many Python threads that could be doing a non-trivial amount of work (e.g. copying buffers for feeding/fetching) outside the GIL and hence in parallel. These threads would be created outside the `tf.Session` and so would not be limited by the configuration options. Some operations (e.g. `ReaderRead`) create their own threads internally as well, and these are not bound by the configuration options either.\r\n\r\nTL;DR: If you want to force TensorFlow to use a single core, the best plan right now would be to use OS-level enforcement mechanisms (e.g. cgroups) to limit the process to (and schedule all its threads on) a single core."}