{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336490529", "html_url": "https://github.com/tensorflow/tensorflow/issues/13616#issuecomment-336490529", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13616", "id": 336490529, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjQ5MDUyOQ==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-13T15:45:27Z", "updated_at": "2017-10-13T15:45:27Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">No, the size of the graph is constant even if you call f(x) in each\niteration, because tensorflow's while loop is symbolic and only creates the\nbody graph once.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Oct 13, 2017 at 8:43 AM, Artem Artemev ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/alextp\">@alextp</a> &lt;<a href=\"https://github.com/alextp\">https://github.com/alextp</a>&gt;. oh, that's bad. Okay, I managed to\n pass f(x) as python function and at each iteration I construct new tensor y\n = f(x), does it mean that the size of the graph will grow linearly with\n number of iterations? Can an unwise usage of while_loop lead to the graph\n \"overflow\", taking into account that graph size is limited?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"264395867\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/13616\" href=\"https://github.com/tensorflow/tensorflow/issues/13616#issuecomment-336488570\">#13616 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxXr6HKksKduSmuWFS3-emCehda_tks5sr4UrgaJpZM4P0qPF\">https://github.com/notifications/unsubscribe-auth/AAATxXr6HKksKduSmuWFS3-emCehda_tks5sr4UrgaJpZM4P0qPF</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "No, the size of the graph is constant even if you call f(x) in each\niteration, because tensorflow's while loop is symbolic and only creates the\nbody graph once.\n\u2026\nOn Fri, Oct 13, 2017 at 8:43 AM, Artem Artemev ***@***.***> wrote:\n @alextp <https://github.com/alextp>. oh, that's bad. Okay, I managed to\n pass f(x) as python function and at each iteration I construct new tensor y\n = f(x), does it mean that the size of the graph will grow linearly with\n number of iterations? Can an unwise usage of while_loop lead to the graph\n \"overflow\", taking into account that graph size is limited?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#13616 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxXr6HKksKduSmuWFS3-emCehda_tks5sr4UrgaJpZM4P0qPF>\n .\n\n\n-- \n - Alex", "body": "No, the size of the graph is constant even if you call f(x) in each\niteration, because tensorflow's while loop is symbolic and only creates the\nbody graph once.\n\nOn Fri, Oct 13, 2017 at 8:43 AM, Artem Artemev <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp>. oh, that's bad. Okay, I managed to\n> pass f(x) as python function and at each iteration I construct new tensor y\n> = f(x), does it mean that the size of the graph will grow linearly with\n> number of iterations? Can an unwise usage of while_loop lead to the graph\n> \"overflow\", taking into account that graph size is limited?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13616#issuecomment-336488570>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxXr6HKksKduSmuWFS3-emCehda_tks5sr4UrgaJpZM4P0qPF>\n> .\n>\n\n\n\n-- \n - Alex\n"}