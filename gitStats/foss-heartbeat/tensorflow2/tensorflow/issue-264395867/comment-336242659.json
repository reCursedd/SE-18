{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/336242659", "html_url": "https://github.com/tensorflow/tensorflow/issues/13616#issuecomment-336242659", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13616", "id": 336242659, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI0MjY1OQ==", "user": {"login": "awav", "id": 24483645, "node_id": "MDQ6VXNlcjI0NDgzNjQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/24483645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awav", "html_url": "https://github.com/awav", "followers_url": "https://api.github.com/users/awav/followers", "following_url": "https://api.github.com/users/awav/following{/other_user}", "gists_url": "https://api.github.com/users/awav/gists{/gist_id}", "starred_url": "https://api.github.com/users/awav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awav/subscriptions", "organizations_url": "https://api.github.com/users/awav/orgs", "repos_url": "https://api.github.com/users/awav/repos", "events_url": "https://api.github.com/users/awav/events{/privacy}", "received_events_url": "https://api.github.com/users/awav/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-12T19:34:08Z", "updated_at": "2017-10-13T10:05:12Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> Hello, your snippet doesn't do what I need, I simplified it a bit below. Let me explain what it does.<br>\nThere is function f and variable x. At each iteration step I increment x and <strong>want</strong> to re-evaluate f and take negative of it. <strong>What's good:</strong> if I take assign tensorflow operation and pass it to the next iteration (even if I'm not using it), I can successfully increment external variable x. <strong>What's bad</strong> the function - <code>f</code> evaluated only once, but <em>must be evaluated  with freshly assigned x as many times as number of iterations</em>. Check example below:</p>\n<p>Here <code>f(x) = x^2</code>, and <code>f_neg=-f(x)</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">cond</span>(<span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">_x_prev</span>, <span class=\"pl-smi\">_f_prev</span>):\n  <span class=\"pl-k\">return</span> i <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">3</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">gen_body</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">f</span>):\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">i</span>, <span class=\"pl-smi\">_x_prev</span>, <span class=\"pl-smi\">_f_prev</span>):\n    x_assign <span class=\"pl-k\">=</span> x.assign(x <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> with tf.control_dependencies([x.assign(x + 1)]):</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>   x_assign = x._ref()</span>\n    <span class=\"pl-k\">with</span> tf.control_dependencies([x_assign]):\n      f_neg <span class=\"pl-k\">=</span> tf.negative(f)\n      i <span class=\"pl-k\">=</span> tf.add(i, <span class=\"pl-c1\">1</span>)\n      i <span class=\"pl-k\">=</span> tf.Print(i, [i], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>&gt;&gt;&gt; Iteration <span class=\"pl-pds\">'</span></span>)\n      i <span class=\"pl-k\">=</span> tf.Print(i, [x], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>x = <span class=\"pl-pds\">'</span></span>)\n      i <span class=\"pl-k\">=</span> tf.Print(i, [x_assign], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>x_assign = <span class=\"pl-pds\">'</span></span>)\n      i <span class=\"pl-k\">=</span> tf.Print(i, [f], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>f = <span class=\"pl-pds\">'</span></span>)\n      i <span class=\"pl-k\">=</span> tf.Print(i, [f_neg], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>f_neg = <span class=\"pl-pds\">'</span></span>)\n      <span class=\"pl-k\">return</span> i, x_assign, f_neg\n  <span class=\"pl-k\">return</span> body\n\ntf.reset_default_graph()\nsess <span class=\"pl-k\">=</span> tf.InteractiveSession()\ni <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>i<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\nv <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>v<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\nfunc_v <span class=\"pl-k\">=</span> tf.square(v)\nl <span class=\"pl-k\">=</span> tf.while_loop(cond, gen_body(v, func_v), (i, v, func_v))\nsess.run(tf.global_variables_initializer())\nsess.run((l, v))</pre></div>\n<p>Output. x incremented successfully from 0 to 3, but f remains non-updated! <strong>I need updated f</strong>.</p>\n<pre><code>... &gt;&gt;&gt; Iteration [1]\n... x = [1]\n... x_assign = [1]\n... f = [0]\n... f_neg = [0]\n\n... &gt;&gt;&gt; Iteration [2]\n... x = [2]\n... x_assign = [2]\n... f = [0]\n... f_neg = [0]\n\n... &gt;&gt;&gt; Iteration [3]\n... x = [3]\n... x_assign = [3]\n... f = [0]\n... f_neg = [0]\n</code></pre>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">259</span>]: tf.<span class=\"pl-c1\">__version__</span>\nOut[<span class=\"pl-c1\">259</span>]: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1.2.1<span class=\"pl-pds\">'</span></span></pre></div>\n<p>I propose to add a method to the tensor structure which will be equivalent to <code>read_value()</code> for standard variable. It will form operation which re-evalutes the tensor when it is required. In example above that tensor is <code>f</code>.</p>", "body_text": "@alextp, @ebrevdo Hello, your snippet doesn't do what I need, I simplified it a bit below. Let me explain what it does.\nThere is function f and variable x. At each iteration step I increment x and want to re-evaluate f and take negative of it. What's good: if I take assign tensorflow operation and pass it to the next iteration (even if I'm not using it), I can successfully increment external variable x. What's bad the function - f evaluated only once, but must be evaluated  with freshly assigned x as many times as number of iterations. Check example below:\nHere f(x) = x^2, and f_neg=-f(x):\ndef cond(i, _x_prev, _f_prev):\n  return i < 3\n\ndef gen_body(x, f):\n  def body(i, _x_prev, _f_prev):\n    x_assign = x.assign(x + 1)\n    # with tf.control_dependencies([x.assign(x + 1)]):\n    #   x_assign = x._ref()\n    with tf.control_dependencies([x_assign]):\n      f_neg = tf.negative(f)\n      i = tf.add(i, 1)\n      i = tf.Print(i, [i], message='>>> Iteration ')\n      i = tf.Print(i, [x], message='x = ')\n      i = tf.Print(i, [x_assign], message='x_assign = ')\n      i = tf.Print(i, [f], message='f = ')\n      i = tf.Print(i, [f_neg], message='f_neg = ')\n      return i, x_assign, f_neg\n  return body\n\ntf.reset_default_graph()\nsess = tf.InteractiveSession()\ni = tf.get_variable(\"i\", initializer=0)\nv = tf.get_variable(\"v\", initializer=0)\nfunc_v = tf.square(v)\nl = tf.while_loop(cond, gen_body(v, func_v), (i, v, func_v))\nsess.run(tf.global_variables_initializer())\nsess.run((l, v))\nOutput. x incremented successfully from 0 to 3, but f remains non-updated! I need updated f.\n... >>> Iteration [1]\n... x = [1]\n... x_assign = [1]\n... f = [0]\n... f_neg = [0]\n\n... >>> Iteration [2]\n... x = [2]\n... x_assign = [2]\n... f = [0]\n... f_neg = [0]\n\n... >>> Iteration [3]\n... x = [3]\n... x_assign = [3]\n... f = [0]\n... f_neg = [0]\n\nIn [259]: tf.__version__\nOut[259]: '1.2.1'\nI propose to add a method to the tensor structure which will be equivalent to read_value() for standard variable. It will form operation which re-evalutes the tensor when it is required. In example above that tensor is f.", "body": "@alextp, @ebrevdo Hello, your snippet doesn't do what I need, I simplified it a bit below. Let me explain what it does.\r\nThere is function f and variable x. At each iteration step I increment x and **want** to re-evaluate f and take negative of it. **What's good:** if I take assign tensorflow operation and pass it to the next iteration (even if I'm not using it), I can successfully increment external variable x. **What's bad** the function - `f` evaluated only once, but _must be evaluated  with freshly assigned x as many times as number of iterations_. Check example below:\r\n\r\nHere `f(x) = x^2`, and `f_neg=-f(x)`:\r\n\r\n```python\r\ndef cond(i, _x_prev, _f_prev):\r\n  return i < 3\r\n\r\ndef gen_body(x, f):\r\n  def body(i, _x_prev, _f_prev):\r\n    x_assign = x.assign(x + 1)\r\n    # with tf.control_dependencies([x.assign(x + 1)]):\r\n    #   x_assign = x._ref()\r\n    with tf.control_dependencies([x_assign]):\r\n      f_neg = tf.negative(f)\r\n      i = tf.add(i, 1)\r\n      i = tf.Print(i, [i], message='>>> Iteration ')\r\n      i = tf.Print(i, [x], message='x = ')\r\n      i = tf.Print(i, [x_assign], message='x_assign = ')\r\n      i = tf.Print(i, [f], message='f = ')\r\n      i = tf.Print(i, [f_neg], message='f_neg = ')\r\n      return i, x_assign, f_neg\r\n  return body\r\n\r\ntf.reset_default_graph()\r\nsess = tf.InteractiveSession()\r\ni = tf.get_variable(\"i\", initializer=0)\r\nv = tf.get_variable(\"v\", initializer=0)\r\nfunc_v = tf.square(v)\r\nl = tf.while_loop(cond, gen_body(v, func_v), (i, v, func_v))\r\nsess.run(tf.global_variables_initializer())\r\nsess.run((l, v))\r\n```\r\n\r\nOutput. x incremented successfully from 0 to 3, but f remains non-updated! **I need updated f**.\r\n\r\n```\r\n... >>> Iteration [1]\r\n... x = [1]\r\n... x_assign = [1]\r\n... f = [0]\r\n... f_neg = [0]\r\n\r\n... >>> Iteration [2]\r\n... x = [2]\r\n... x_assign = [2]\r\n... f = [0]\r\n... f_neg = [0]\r\n\r\n... >>> Iteration [3]\r\n... x = [3]\r\n... x_assign = [3]\r\n... f = [0]\r\n... f_neg = [0]\r\n```\r\n\r\n```python\r\nIn [259]: tf.__version__\r\nOut[259]: '1.2.1'\r\n```\r\n\r\nI propose to add a method to the tensor structure which will be equivalent to `read_value()` for standard variable. It will form operation which re-evalutes the tensor when it is required. In example above that tensor is `f`.\r\n"}