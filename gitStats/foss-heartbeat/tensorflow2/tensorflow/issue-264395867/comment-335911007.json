{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335911007", "html_url": "https://github.com/tensorflow/tensorflow/issues/13616#issuecomment-335911007", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13616", "id": 335911007, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTkxMTAwNw==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-11T18:51:24Z", "updated_at": "2017-10-11T18:51:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is an optimization that we turned on because you don't want a Variable sitting on a parameter server elsewhere in the datacenter to be accessed at each iteration of an RNN.  you want to access it only once and cache it.  in this case you have an assign inside the while_loop and converting a Variable to a Tensor doesn't look to see if an assign has been performed just prior to this, to know it must refresh the value.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> should we reset the caching identity tensor of a Variable after each assign?</p>", "body_text": "This is an optimization that we turned on because you don't want a Variable sitting on a parameter server elsewhere in the datacenter to be accessed at each iteration of an RNN.  you want to access it only once and cache it.  in this case you have an assign inside the while_loop and converting a Variable to a Tensor doesn't look to see if an assign has been performed just prior to this, to know it must refresh the value.  @mrry should we reset the caching identity tensor of a Variable after each assign?", "body": "This is an optimization that we turned on because you don't want a Variable sitting on a parameter server elsewhere in the datacenter to be accessed at each iteration of an RNN.  you want to access it only once and cache it.  in this case you have an assign inside the while_loop and converting a Variable to a Tensor doesn't look to see if an assign has been performed just prior to this, to know it must refresh the value.  @mrry should we reset the caching identity tensor of a Variable after each assign?"}