{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16851", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16851/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16851/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16851/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16851", "id": 295360380, "node_id": "MDU6SXNzdWUyOTUzNjAzODA=", "number": 16851, "title": "Output of Inceptionv3 slim 2016 tflite model is problematic", "user": {"login": "freedomtan", "id": 3395998, "node_id": "MDQ6VXNlcjMzOTU5OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3395998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/freedomtan", "html_url": "https://github.com/freedomtan", "followers_url": "https://api.github.com/users/freedomtan/followers", "following_url": "https://api.github.com/users/freedomtan/following{/other_user}", "gists_url": "https://api.github.com/users/freedomtan/gists{/gist_id}", "starred_url": "https://api.github.com/users/freedomtan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/freedomtan/subscriptions", "organizations_url": "https://api.github.com/users/freedomtan/orgs", "repos_url": "https://api.github.com/users/freedomtan/repos", "events_url": "https://api.github.com/users/freedomtan/events{/privacy}", "received_events_url": "https://api.github.com/users/freedomtan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 26, "created_at": "2018-02-08T02:07:48Z", "updated_at": "2018-09-14T16:56:58Z", "closed_at": "2018-04-27T20:39:42Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: N/A, this is a bug report of a tflite model released by Google</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Any one</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: both</li>\n<li><strong>TensorFlow version (use command below)</strong>: after TF Lite released</li>\n<li><strong>Python version</strong>: both</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: see descriptions below</li>\n</ul>\n<p>It seems the output of the <a href=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/inception_v3_slim_2016_android_2017_11_10.zip\" rel=\"nofollow\">inceptionv3 slim 2016 tflite model released by google</a> is problematic. If you run <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/label_image/label_image.md\">label_image for tflite</a>, you'll get</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">&gt;</span> ./label_image -m inceptionv3_slim_2016.tflite\nLoaded model inceptionv3_slim_2016.tflite\nresolved reporter\ninvoked \naverage time: 1009.48 ms \n8.06111: 653 military uniform\n6.19022: 668 mortarboard\n5.83456: 401 academic gown\n5.26993: 835 suit\n4.80701: 855 theater curtain</pre></div>\n<p>If you convert InceptionV3 yourself,</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">&gt;</span> curl http://download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz \\\n <span class=\"pl-k\">|</span> tar -C /tmp -xzf -\n<span class=\"pl-k\">&gt;</span> bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --  \\\n--input_file=/tmp/inception_v3_2016_08_28_frozen.pb  \\\n--output_file=/tmp/inceptionv3.tflite   --input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,299,299,3 \\\n--input_array=input   --output_array=InceptionV3/Predictions/Reshape_1</pre></div>\n<p>and push the /tmp/inceptionv3.tflite to your android devices, then you can see expected results like</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">&gt;</span> ./label_image -m inceptionv3.tflite             \nLoaded model inceptionv3.tflite\nresolved reporter\ninvoked \naverage time: 1020.93 ms \n0.496246: 653 military uniform\n0.0764156: 668 mortarboard\n0.0535454: 401 academic gown\n0.030444: 835 suit\n0.0191629: 855 theater curtain</pre></div>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A, this is a bug report of a tflite model released by Google\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Any one\nTensorFlow installed from (source or binary): both\nTensorFlow version (use command below): after TF Lite released\nPython version: both\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: see descriptions below\n\nIt seems the output of the inceptionv3 slim 2016 tflite model released by google is problematic. If you run label_image for tflite, you'll get\n> ./label_image -m inceptionv3_slim_2016.tflite\nLoaded model inceptionv3_slim_2016.tflite\nresolved reporter\ninvoked \naverage time: 1009.48 ms \n8.06111: 653 military uniform\n6.19022: 668 mortarboard\n5.83456: 401 academic gown\n5.26993: 835 suit\n4.80701: 855 theater curtain\nIf you convert InceptionV3 yourself,\n> curl http://download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz \\\n | tar -C /tmp -xzf -\n> bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --  \\\n--input_file=/tmp/inception_v3_2016_08_28_frozen.pb  \\\n--output_file=/tmp/inceptionv3.tflite   --input_format=TENSORFLOW_GRAPHDEF \\\n--output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,299,299,3 \\\n--input_array=input   --output_array=InceptionV3/Predictions/Reshape_1\nand push the /tmp/inceptionv3.tflite to your android devices, then you can see expected results like\n> ./label_image -m inceptionv3.tflite             \nLoaded model inceptionv3.tflite\nresolved reporter\ninvoked \naverage time: 1020.93 ms \n0.496246: 653 military uniform\n0.0764156: 668 mortarboard\n0.0535454: 401 academic gown\n0.030444: 835 suit\n0.0191629: 855 theater curtain", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A, this is a bug report of a tflite model released by Google\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any one\r\n- **TensorFlow installed from (source or binary)**: both\r\n- **TensorFlow version (use command below)**: after TF Lite released\r\n- **Python version**: both\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: see descriptions below\r\n\r\nIt seems the output of the [inceptionv3 slim 2016 tflite model released by google](https://storage.googleapis.com/download.tensorflow.org/models/tflite/inception_v3_slim_2016_android_2017_11_10.zip) is problematic. If you run [label_image for tflite](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/label_image/label_image.md), you'll get\r\n\r\n```bash\r\n> ./label_image -m inceptionv3_slim_2016.tflite\r\nLoaded model inceptionv3_slim_2016.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 1009.48 ms \r\n8.06111: 653 military uniform\r\n6.19022: 668 mortarboard\r\n5.83456: 401 academic gown\r\n5.26993: 835 suit\r\n4.80701: 855 theater curtain\r\n```\r\n\r\nIf you convert InceptionV3 yourself, \r\n```bash\r\n> curl http://download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz \\\r\n | tar -C /tmp -xzf -\r\n> bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --  \\\r\n--input_file=/tmp/inception_v3_2016_08_28_frozen.pb  \\\r\n--output_file=/tmp/inceptionv3.tflite   --input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,299,299,3 \\\r\n--input_array=input   --output_array=InceptionV3/Predictions/Reshape_1\r\n```\r\n\r\nand push the /tmp/inceptionv3.tflite to your android devices, then you can see expected results like\r\n\r\n```bash\r\n> ./label_image -m inceptionv3.tflite             \r\nLoaded model inceptionv3.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 1020.93 ms \r\n0.496246: 653 military uniform\r\n0.0764156: 668 mortarboard\r\n0.0535454: 401 academic gown\r\n0.030444: 835 suit\r\n0.0191629: 855 theater curtain\r\n```"}