{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11313", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11313/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11313/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11313/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11313", "id": 240826735, "node_id": "MDU6SXNzdWUyNDA4MjY3MzU=", "number": 11313, "title": "tf.nn.embedding_lookup_sparse behaves not as expected", "user": {"login": "chunyang-wen", "id": 2911134, "node_id": "MDQ6VXNlcjI5MTExMzQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/2911134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chunyang-wen", "html_url": "https://github.com/chunyang-wen", "followers_url": "https://api.github.com/users/chunyang-wen/followers", "following_url": "https://api.github.com/users/chunyang-wen/following{/other_user}", "gists_url": "https://api.github.com/users/chunyang-wen/gists{/gist_id}", "starred_url": "https://api.github.com/users/chunyang-wen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chunyang-wen/subscriptions", "organizations_url": "https://api.github.com/users/chunyang-wen/orgs", "repos_url": "https://api.github.com/users/chunyang-wen/repos", "events_url": "https://api.github.com/users/chunyang-wen/events{/privacy}", "received_events_url": "https://api.github.com/users/chunyang-wen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-07-06T02:23:48Z", "updated_at": "2017-07-06T05:07:02Z", "closed_at": "2017-07-06T05:07:02Z", "author_association": "NONE", "body_html": "<p>Simple repeated code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n\na <span class=\"pl-k\">=</span> tf.constant([[<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>], [<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">0</span>]])\nb <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>])\n\ns <span class=\"pl-k\">=</span> tf.SparseTensor(tf.cast(a, tf.int64), b, <span class=\"pl-v\">dense_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">5</span>))\n\nn <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">3</span>)\nnn <span class=\"pl-k\">=</span> tf.Variable(n, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>aha<span class=\"pl-pds\">'</span></span>)\n\nr <span class=\"pl-k\">=</span> tf.nn.embedding_lookup_sparse(nn, s, <span class=\"pl-c1\">None</span>,<span class=\"pl-v\">combiner</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sum<span class=\"pl-pds\">'</span></span>)\n\nsess <span class=\"pl-k\">=</span> tf.Session()\nsess.run(tf.global_variables_initializer())\n\n<span class=\"pl-c1\">print</span> sess.run(r)</pre></div>\n<p><strong>expected results</strong>: 2*3</p>\n<div class=\"highlight highlight-source-python\"><pre>[[ <span class=\"pl-c1\">0.45522392</span>  <span class=\"pl-c1\">0.67905994</span>  <span class=\"pl-c1\">0.79126569</span>]\n [ <span class=\"pl-c1\">0.62346977</span>  <span class=\"pl-c1\">0.42459864</span>  <span class=\"pl-c1\">0.03796264</span>]]</pre></div>\n<p>but <strong>actual results</strong>: 4*3</p>\n<div class=\"highlight highlight-source-python\"><pre>[[ <span class=\"pl-c1\">0</span>.          0.          0.        ]\n [ <span class=\"pl-c1\">0</span>.          0.          0.        ]\n [ <span class=\"pl-c1\">0.45522392</span>  <span class=\"pl-c1\">0.67905994</span>  <span class=\"pl-c1\">0.79126569</span>]\n [ <span class=\"pl-c1\">0.62346977</span>  <span class=\"pl-c1\">0.42459864</span>  <span class=\"pl-c1\">0.03796264</span>]]</pre></div>\n<p>I do not get it. Can anyone help to clarify the result?</p>\n<p>Tensorflow version: 1.2.1, installed with pip.<br>\nOS: mac os 10.12.5</p>\n<p><a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse\" rel=\"nofollow\">tf.nn.embedding_lookup_sparse</a></p>\n<p>Another problem: I am using a partitioned variable to lookup. Pseudo code:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> tf.getVariable(<span class=\"pl-c1\">...</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> it is a partitioned variable, pass partitioner to it</span>\nb <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(a)\n\nresult <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> b:\n    result.append( tf.nn.embedding_lookup_sparse(p, sparseTensor, <span class=\"pl-c1\">None</span>, <span class=\"pl-v\">combiner</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sum<span class=\"pl-pds\">'</span></span>))\n\nfinal_result <span class=\"pl-k\">=</span> tf.concat(result, <span class=\"pl-c1\">0</span>)\n\nsess.run(final_result)</pre></div>\n<p>if I remove the <code>tf.concat</code>, and replace it with:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">for</span> ff <span class=\"pl-k\">in</span> final_result:\n    sess.run(ff)</pre></div>\n<p>The part of code behaves as expected. But when I do concat, it crashes and the error message is:</p>\n<div class=\"highlight highlight-source-python\"><pre>InvalidArgumentError (see above <span class=\"pl-k\">for</span> traceback): segment ids are <span class=\"pl-k\">not</span> increasing\n\t [[Node: embedding_lookup_sparse = SparseSegmentSum[T=<span class=\"pl-c1\">DT_DOUBLE</span>, Tidx=<span class=\"pl-c1\">DT_INT32</span>, _device=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:localhost/replica:0/task:0/cpu:0<span class=\"pl-pds\">\"</span></span>](embedding_lookup_sparse<span class=\"pl-k\">/</span>embedding_lookup, embedding_lookup_sparse<span class=\"pl-k\">/</span>Unique:<span class=\"pl-c1\">1</span>, embedding_lookup_sparse<span class=\"pl-k\">/</span>Cast)]]</pre></div>\n<p>After a serious investigation, I understand <strong>segment ids are not increasing</strong>. It means that:</p>\n<div class=\"highlight highlight-source-python\"><pre>sparse_ids <span class=\"pl-k\">=</span> [[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">0</span>],[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>]] <span class=\"pl-c\"><span class=\"pl-c\">#</span> invalid</span>\nsparse_ids <span class=\"pl-k\">=</span> [[<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>],[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">0</span>]] <span class=\"pl-c\"><span class=\"pl-c\">#</span> valid</span></pre></div>\n<p>This is documented in the previous link I provided. But I have printed all the sparse indices and values using <code>tf.Print</code>. Everything seems fine.</p>\n<p>So my question is : does <code>tf.concat</code> apply any special rules\uff1f</p>", "body_text": "Simple repeated code:\nimport tensorflow as tf\nimport numpy as np\n\n\na = tf.constant([[2,3], [3,0]])\nb = tf.constant([0, 3])\n\ns = tf.SparseTensor(tf.cast(a, tf.int64), b, dense_shape=(4,5))\n\nn = np.random.rand(5,3)\nnn = tf.Variable(n, name='aha')\n\nr = tf.nn.embedding_lookup_sparse(nn, s, None,combiner='sum')\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nprint sess.run(r)\nexpected results: 2*3\n[[ 0.45522392  0.67905994  0.79126569]\n [ 0.62346977  0.42459864  0.03796264]]\nbut actual results: 4*3\n[[ 0.          0.          0.        ]\n [ 0.          0.          0.        ]\n [ 0.45522392  0.67905994  0.79126569]\n [ 0.62346977  0.42459864  0.03796264]]\nI do not get it. Can anyone help to clarify the result?\nTensorflow version: 1.2.1, installed with pip.\nOS: mac os 10.12.5\ntf.nn.embedding_lookup_sparse\nAnother problem: I am using a partitioned variable to lookup. Pseudo code:\na = tf.getVariable(...) # it is a partitioned variable, pass partitioner to it\nb = list(a)\n\nresult = []\nfor p in b:\n    result.append( tf.nn.embedding_lookup_sparse(p, sparseTensor, None, combiner='sum'))\n\nfinal_result = tf.concat(result, 0)\n\nsess.run(final_result)\nif I remove the tf.concat, and replace it with:\nfor ff in final_result:\n    sess.run(ff)\nThe part of code behaves as expected. But when I do concat, it crashes and the error message is:\nInvalidArgumentError (see above for traceback): segment ids are not increasing\n\t [[Node: embedding_lookup_sparse = SparseSegmentSum[T=DT_DOUBLE, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_lookup_sparse/embedding_lookup, embedding_lookup_sparse/Unique:1, embedding_lookup_sparse/Cast)]]\nAfter a serious investigation, I understand segment ids are not increasing. It means that:\nsparse_ids = [[1,0],[0,1]] # invalid\nsparse_ids = [[0,1],[1,0]] # valid\nThis is documented in the previous link I provided. But I have printed all the sparse indices and values using tf.Print. Everything seems fine.\nSo my question is : does tf.concat apply any special rules\uff1f", "body": "Simple repeated code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\na = tf.constant([[2,3], [3,0]])\r\nb = tf.constant([0, 3])\r\n\r\ns = tf.SparseTensor(tf.cast(a, tf.int64), b, dense_shape=(4,5))\r\n\r\nn = np.random.rand(5,3)\r\nnn = tf.Variable(n, name='aha')\r\n\r\nr = tf.nn.embedding_lookup_sparse(nn, s, None,combiner='sum')\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nprint sess.run(r)\r\n```\r\n\r\n**expected results**: 2*3\r\n\r\n```python\r\n[[ 0.45522392  0.67905994  0.79126569]\r\n [ 0.62346977  0.42459864  0.03796264]]\r\n```\r\n\r\nbut **actual results**: 4\\*3\r\n\r\n```python\r\n[[ 0.          0.          0.        ]\r\n [ 0.          0.          0.        ]\r\n [ 0.45522392  0.67905994  0.79126569]\r\n [ 0.62346977  0.42459864  0.03796264]]\r\n```\r\n\r\nI do not get it. Can anyone help to clarify the result?\r\n\r\nTensorflow version: 1.2.1, installed with pip.\r\nOS: mac os 10.12.5 \r\n\r\n[tf.nn.embedding_lookup_sparse](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)\r\n\r\nAnother problem: I am using a partitioned variable to lookup. Pseudo code:\r\n\r\n```python\r\na = tf.getVariable(...) # it is a partitioned variable, pass partitioner to it\r\nb = list(a)\r\n\r\nresult = []\r\nfor p in b:\r\n    result.append( tf.nn.embedding_lookup_sparse(p, sparseTensor, None, combiner='sum'))\r\n\r\nfinal_result = tf.concat(result, 0)\r\n\r\nsess.run(final_result)\r\n```\r\n\r\nif I remove the `tf.concat`, and replace it with:\r\n\r\n```python\r\nfor ff in final_result:\r\n    sess.run(ff)\r\n```\r\n\r\nThe part of code behaves as expected. But when I do concat, it crashes and the error message is:\r\n\r\n```python\r\nInvalidArgumentError (see above for traceback): segment ids are not increasing\r\n\t [[Node: embedding_lookup_sparse = SparseSegmentSum[T=DT_DOUBLE, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_lookup_sparse/embedding_lookup, embedding_lookup_sparse/Unique:1, embedding_lookup_sparse/Cast)]]\r\n```\r\n\r\nAfter a serious investigation, I understand **segment ids are not increasing**. It means that:\r\n\r\n```python\r\nsparse_ids = [[1,0],[0,1]] # invalid\r\nsparse_ids = [[0,1],[1,0]] # valid\r\n```\r\nThis is documented in the previous link I provided. But I have printed all the sparse indices and values using `tf.Print`. Everything seems fine. \r\n\r\nSo my question is : does `tf.concat` apply any special rules\uff1f\r\n\r\n"}