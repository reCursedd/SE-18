{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5985", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5985/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5985/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5985/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5985", "id": 192612459, "node_id": "MDU6SXNzdWUxOTI2MTI0NTk=", "number": 5985, "title": "None gradient from GRU", "user": {"login": "petrbel", "id": 461519, "node_id": "MDQ6VXNlcjQ2MTUxOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/461519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrbel", "html_url": "https://github.com/petrbel", "followers_url": "https://api.github.com/users/petrbel/followers", "following_url": "https://api.github.com/users/petrbel/following{/other_user}", "gists_url": "https://api.github.com/users/petrbel/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrbel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrbel/subscriptions", "organizations_url": "https://api.github.com/users/petrbel/orgs", "repos_url": "https://api.github.com/users/petrbel/repos", "events_url": "https://api.github.com/users/petrbel/events{/privacy}", "received_events_url": "https://api.github.com/users/petrbel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 31, "created_at": "2016-11-30T16:28:13Z", "updated_at": "2018-08-20T19:34:33Z", "closed_at": "2017-06-16T18:21:28Z", "author_association": "NONE", "body_html": "<p>Hello everybody,</p>\n<p><strong>Introduction:</strong><br>\nI am trying to reproduce the work of Szegedy et al: <a href=\"https://arxiv.org/abs/1312.6199\" rel=\"nofollow\">Intriguing properties of neural networks</a> and Dezfooli et al: <a href=\"https://arxiv.org/abs/1610.08401\" rel=\"nofollow\">Universal adversarial perturbations</a>. What they do, briefly, is that they take the gradient <code>g</code> of the network with respect to the input image <code>x</code>, then slightly modify the input image <code>x</code> \"against\" the obtained gradient, i.e. <code>x-0.001g</code>. The modified images are consequently considered as another network input, hence new gradients <code>g'</code> might be computed and obtained. The result gradients are manually set to the average of those two set obtains gradients, i.e. <code>g/2 + g'/2</code>. I hope I explained that clearly.</p>\n<p>I successfully implemented it for images in TF 0.10 (working on 0.12RC as well). Now I want to do something similar with recurrent networks (sentiment analysis task). So I have a input sequence of tokens (numbers), a variable <code>embeddings</code> which is used by <code>tf.nn.embedding_lookup</code>. After the lookup, the sequence of proper embeddings is traversed by GRU (dynamically). It's last state is considered as the representation of the sequence. Then a MLP with a single hidden layer and ReLU activation is applied, resulting in 2 neurons representing the positive and negative logits respectively. The loss is traditional categorical cross entropy.</p>\n<p><strong>Bug</strong><br>\nSimilarly to the papers mentioned above, I obtain gradients of the embedding, and modify the current embeddings slightly \"against\" the obtained gradient. Than I compute the new loss and <em>new gradients (here is the problem!)</em> and update the network by their mean.</p>\n<p>The problem is that the returned <em>new gradients</em> are all <code>None</code>s. I originally worked with TF 0.10, however, I got an error explaining that second order derivatives are impossible to obtain from scan. I upgraded to recently released TF 0.12RC which doesn't throw this error but returns <code>None</code>s instead.</p>\n<p><strong>Related Issues and SOs</strong><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"126842425\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/783\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/783/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/783\">#783</a> is somewhat similar, but not the same. <a href=\"http://stackoverflow.com/questions/36874522/tensorflow-gradients\" rel=\"nofollow\">This question</a> deals with very the same problem  but the solution isn't sufficient as replacing the <code>None</code> value with zero is really worthless in my case since I need to modify the variable against the gradient.</p>\n<p><strong>Minimal Not-Working Example</strong><br>\nI am sorry the code is so long. It is partially caused by the fact that the problem is non-trivial and requires few lines and partially by the amount of comments I tried to write in order to make the code more readable. All platform/version information is stored at beginning of the file.</p>\n<p>The <code>main()</code> function constructs two <code>SimpleSentiment</code>s as the models that are trained. Each one is trained for few epochs and batches. First instance is without the adversarial, hence we perform no trick regarding modifying the gradients (for a sanity check). The second uses the complicated <code>if</code> branch in the constructor and obtains <code>None</code>s as described above.</p>\n<p>I believe this is a bug and not my mistake, however, it can't be ruled out as I am not as experienced with TF as I'd like to be.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> #!/usr/bin/env python3</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> python 3.5 (anaconda)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> TF 0.12 RC from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> $ python -c \"import tensorflow; print(tensorflow.__version__)\"</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>  0.12.0-rc0</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> OS: RedHat 7.2</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> CPU version only, no GPU, no CUDA, no CUDNN</span>\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">from</span> tensorflow.python.ops.rnn_cell <span class=\"pl-k\">import</span> GRUCell\n\n\n<span class=\"pl-c1\">BATCH</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> batch size</span>\n<span class=\"pl-c1\">MAX_LEN</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> max length of the sequence</span>\n<span class=\"pl-c1\">MLP_HIDDEN_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> number of hidden neurons in the MLP</span>\n<span class=\"pl-c1\">EMBEDDING_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">300</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> embedding dimension</span>\n<span class=\"pl-c1\">VOCAB_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> vocabulary size</span>\n\n<span class=\"pl-c1\">THREADS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> number of threads to be used</span>\n<span class=\"pl-c1\">STD</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.001</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> standard deviation of ariable initializers</span>\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">SimpleSentiment</span>:\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">adversarial</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-smi\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/cpu:0<span class=\"pl-pds\">'</span></span>):\n\n        <span class=\"pl-c1\">self</span>.embeddings <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>word_embeddings<span class=\"pl-pds\">'</span></span>,\n                                          <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_uniform([<span class=\"pl-c1\">VOCAB_SIZE</span>, <span class=\"pl-c1\">EMBEDDING_DIM</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>))\n\n        <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>sentiment<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> scope:\n            <span class=\"pl-k\">with</span> tf.device(device):\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Inputs</span>\n                <span class=\"pl-c1\">self</span>.text <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">BATCH</span>, <span class=\"pl-c1\">MAX_LEN</span>])\n                <span class=\"pl-c1\">self</span>.text_len <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">BATCH</span>])\n                <span class=\"pl-c1\">self</span>.sentiment <span class=\"pl-k\">=</span> tf.placeholder(tf.int32, [<span class=\"pl-c1\">BATCH</span>])\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Normal loss</span>\n                loss_normal <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._loss(<span class=\"pl-c1\">self</span>.text, <span class=\"pl-c1\">self</span>.text_len, <span class=\"pl-c1\">self</span>.sentiment)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Define the optimizer</span>\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note: I've tried multiple of optimizers and none helped</span>\n                optimizer <span class=\"pl-k\">=</span> tf.train.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0005</span>)\n\n                <span class=\"pl-k\">if</span> adversarial:  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Define adversarial loss</span>\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Let's acces already defined variables</span>\n                    scope.reuse_variables()\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Gradients of all variable (according to normal loss)</span>\n                    gradients <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss_normal)\n                    <span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">len</span>(gradients), gradients)\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> gradients of the embeddings</span>\n                    emb_gradient <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss_normal, [<span class=\"pl-c1\">self</span>.embeddings])[<span class=\"pl-c1\">0</span>][<span class=\"pl-c1\">0</span>]\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> this how much we want to shift the embeddings, i.e. going \"against\" the gradient</span>\n                    delta <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.001</span><span class=\"pl-k\">*</span>tf.sign(emb_gradient)\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> let's compute the loss once again but this time we add the delta to the embeddings</span>\n                    loss_adversarial <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._loss(<span class=\"pl-c1\">self</span>.text, <span class=\"pl-c1\">self</span>.text_len, <span class=\"pl-c1\">self</span>.sentiment, delta)\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> new gradient of the whole computational graph</span>\n                    adversarial_gradients <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss_adversarial)\n                    <span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">len</span>(adversarial_gradients), adversarial_gradients)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> everything is None!</span>\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Now we compute an average of old and new gradients</span>\n                    new_gradients <span class=\"pl-k\">=</span> [((g <span class=\"pl-k\">+</span> ag)<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span>, vg) <span class=\"pl-k\">for</span> ((g, vg), (ag, avg)) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(gradients, adversarial_gradients)]\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> and apply them</span>\n                    <span class=\"pl-c1\">self</span>.training <span class=\"pl-k\">=</span> optimizer.apply_gradients(new_gradients)\n\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Btw this doesn't work either</span>\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> self.training = optimizer.apply_gradients(adversarial_gradients)</span>\n\n                    <span class=\"pl-c1\">self</span>.loss_final <span class=\"pl-k\">=</span> (loss_normal <span class=\"pl-k\">+</span> loss_adversarial) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">2</span>\n\n                <span class=\"pl-k\">else</span>:  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Normal loss</span>\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> simply minimize according to the gradients</span>\n                    <span class=\"pl-c1\">self</span>.loss_final <span class=\"pl-k\">=</span> loss_normal\n                    <span class=\"pl-c1\">self</span>.training <span class=\"pl-k\">=</span> optimizer.minimize(loss_normal)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create the session</span>\n                <span class=\"pl-c1\">self</span>.session <span class=\"pl-k\">=</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>tf.ConfigProto(<span class=\"pl-v\">inter_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">THREADS</span>,\n                                                                <span class=\"pl-v\">intra_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">THREADS</span>,\n                                                                <span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> init everything (still deprecated way)</span>\n                <span class=\"pl-c1\">self</span>.session.run(tf.initialize_all_variables())\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_loss</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">text</span>, <span class=\"pl-smi\">text_len</span>, <span class=\"pl-smi\">sentiment</span>, <span class=\"pl-smi\">emb_delta</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> use embedding</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> note that emb_delta is zero as long as adversarial=False</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> if adversarial=False then each embedding is shifted by appropriate emb_delta</span>\n        text <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(<span class=\"pl-c1\">self</span>.embeddings <span class=\"pl-k\">+</span> emb_delta, text)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> run gru</span>\n        gru_cell <span class=\"pl-k\">=</span> GRUCell(<span class=\"pl-c1\">MLP_HIDDEN_DIM</span>)\n        outputs, state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(<span class=\"pl-v\">cell</span><span class=\"pl-k\">=</span>gru_cell,\n                                           <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>text,\n                                           <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>text_len,\n                                           <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> define MLP</span>\n        W1 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>MLP_W1<span class=\"pl-pds\">'</span></span>,\n                             <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[state.get_shape()[<span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">MLP_HIDDEN_DIM</span>],\n                             <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">STD</span>))\n        W2 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>MLP_W2<span class=\"pl-pds\">'</span></span>,\n                             <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">MLP_HIDDEN_DIM</span>, <span class=\"pl-c1\">2</span>],\n                             <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">STD</span>))\n        h1 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>MLP_h1<span class=\"pl-pds\">'</span></span>,\n                             <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">MLP_HIDDEN_DIM</span>],\n                             <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">STD</span>))\n        h2 <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>MLP_h2<span class=\"pl-pds\">'</span></span>,\n                             <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>],\n                             <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.random_normal_initializer(<span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">STD</span>))\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> apply MLP of the last GRU state</span>\n        after_first_layer <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(state, W1) <span class=\"pl-k\">+</span> h1)\n        logits <span class=\"pl-k\">=</span> tf.matmul(after_first_layer, W2) <span class=\"pl-k\">+</span> h2\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> compute loss via categorial cross entropy</span>\n        loss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, sentiment))\n        <span class=\"pl-k\">return</span> loss\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    <span class=\"pl-k\">for</span> adversarial <span class=\"pl-k\">in</span> [<span class=\"pl-c1\">False</span>, <span class=\"pl-c1\">True</span>]:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span>=================================<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">if</span> adversarial:\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Using the adversarial loss<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Using the standard loss<span class=\"pl-pds\">'</span></span>)\n\n        net <span class=\"pl-k\">=</span> SimpleSentiment(<span class=\"pl-v\">adversarial</span><span class=\"pl-k\">=</span>adversarial)\n\n        <span class=\"pl-k\">for</span> epoch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>):\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Epoch <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(epoch))\n\n            <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>):\n                _, loss_final <span class=\"pl-k\">=</span> net.session.run([net.training, net.loss_final],\n                                                {net.text: np.array([[<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                                     [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                                     [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                                     [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>],\n                                                                     [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">7</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>),\n                                                 net.text_len: np.array([<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">10</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>),\n                                                 net.sentiment: np.array([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>int32<span class=\"pl-pds\">'</span></span>)})\n\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\t</span>Batch <span class=\"pl-c1\">{}</span>: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(batch, loss_final))\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>\n<p>Thanks for help<br>\nPetr</p>", "body_text": "Hello everybody,\nIntroduction:\nI am trying to reproduce the work of Szegedy et al: Intriguing properties of neural networks and Dezfooli et al: Universal adversarial perturbations. What they do, briefly, is that they take the gradient g of the network with respect to the input image x, then slightly modify the input image x \"against\" the obtained gradient, i.e. x-0.001g. The modified images are consequently considered as another network input, hence new gradients g' might be computed and obtained. The result gradients are manually set to the average of those two set obtains gradients, i.e. g/2 + g'/2. I hope I explained that clearly.\nI successfully implemented it for images in TF 0.10 (working on 0.12RC as well). Now I want to do something similar with recurrent networks (sentiment analysis task). So I have a input sequence of tokens (numbers), a variable embeddings which is used by tf.nn.embedding_lookup. After the lookup, the sequence of proper embeddings is traversed by GRU (dynamically). It's last state is considered as the representation of the sequence. Then a MLP with a single hidden layer and ReLU activation is applied, resulting in 2 neurons representing the positive and negative logits respectively. The loss is traditional categorical cross entropy.\nBug\nSimilarly to the papers mentioned above, I obtain gradients of the embedding, and modify the current embeddings slightly \"against\" the obtained gradient. Than I compute the new loss and new gradients (here is the problem!) and update the network by their mean.\nThe problem is that the returned new gradients are all Nones. I originally worked with TF 0.10, however, I got an error explaining that second order derivatives are impossible to obtain from scan. I upgraded to recently released TF 0.12RC which doesn't throw this error but returns Nones instead.\nRelated Issues and SOs\n#783 is somewhat similar, but not the same. This question deals with very the same problem  but the solution isn't sufficient as replacing the None value with zero is really worthless in my case since I need to modify the variable against the gradient.\nMinimal Not-Working Example\nI am sorry the code is so long. It is partially caused by the fact that the problem is non-trivial and requires few lines and partially by the amount of comments I tried to write in order to make the code more readable. All platform/version information is stored at beginning of the file.\nThe main() function constructs two SimpleSentiments as the models that are trained. Each one is trained for few epochs and batches. First instance is without the adversarial, hence we perform no trick regarding modifying the gradients (for a sanity check). The second uses the complicated if branch in the constructor and obtains Nones as described above.\nI believe this is a bug and not my mistake, however, it can't be ruled out as I am not as experienced with TF as I'd like to be.\n# #!/usr/bin/env python3\n\n# python 3.5 (anaconda)\n# TF 0.12 RC from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl\n# $ python -c \"import tensorflow; print(tensorflow.__version__)\"\n#  0.12.0-rc0\n\n# OS: RedHat 7.2\n# CPU version only, no GPU, no CUDA, no CUDNN\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import GRUCell\n\n\nBATCH = 5  # batch size\nMAX_LEN = 10  # max length of the sequence\nMLP_HIDDEN_DIM = 128  # number of hidden neurons in the MLP\nEMBEDDING_DIM = 300  # embedding dimension\nVOCAB_SIZE = 8  # vocabulary size\n\nTHREADS = 4  # number of threads to be used\nSTD=0.001  # standard deviation of ariable initializers\n\n\nclass SimpleSentiment:\n    def __init__(self, adversarial=False, device='/cpu:0'):\n\n        self.embeddings = tf.get_variable('word_embeddings',\n                                          initializer=tf.random_uniform([VOCAB_SIZE, EMBEDDING_DIM], -1.0, 1.0))\n\n        with tf.variable_scope('sentiment') as scope:\n            with tf.device(device):\n                # Inputs\n                self.text = tf.placeholder(tf.int32, [BATCH, MAX_LEN])\n                self.text_len = tf.placeholder(tf.int32, [BATCH])\n                self.sentiment = tf.placeholder(tf.int32, [BATCH])\n\n                # Normal loss\n                loss_normal = self._loss(self.text, self.text_len, self.sentiment)\n\n                # Define the optimizer\n                # Note: I've tried multiple of optimizers and none helped\n                optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n\n                if adversarial:  # Define adversarial loss\n                    # Let's acces already defined variables\n                    scope.reuse_variables()\n\n                    # Gradients of all variable (according to normal loss)\n                    gradients = optimizer.compute_gradients(loss_normal)\n                    print(len(gradients), gradients)\n\n                    # gradients of the embeddings\n                    emb_gradient = optimizer.compute_gradients(loss_normal, [self.embeddings])[0][0]\n\n                    # this how much we want to shift the embeddings, i.e. going \"against\" the gradient\n                    delta = 0.001*tf.sign(emb_gradient)\n\n                    # let's compute the loss once again but this time we add the delta to the embeddings\n                    loss_adversarial = self._loss(self.text, self.text_len, self.sentiment, delta)\n\n                    # new gradient of the whole computational graph\n                    adversarial_gradients = optimizer.compute_gradients(loss_adversarial)\n                    print(len(adversarial_gradients), adversarial_gradients)  # everything is None!\n\n                    # Now we compute an average of old and new gradients\n                    new_gradients = [((g + ag)/2, vg) for ((g, vg), (ag, avg)) in zip(gradients, adversarial_gradients)]\n\n                    # and apply them\n                    self.training = optimizer.apply_gradients(new_gradients)\n\n                    # Btw this doesn't work either\n                    # self.training = optimizer.apply_gradients(adversarial_gradients)\n\n                    self.loss_final = (loss_normal + loss_adversarial) / 2\n\n                else:  # Normal loss\n                    # simply minimize according to the gradients\n                    self.loss_final = loss_normal\n                    self.training = optimizer.minimize(loss_normal)\n\n                # Create the session\n                self.session = tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=THREADS,\n                                                                intra_op_parallelism_threads=THREADS,\n                                                                allow_soft_placement=True))\n\n                # init everything (still deprecated way)\n                self.session.run(tf.initialize_all_variables())\n\n    def _loss(self, text, text_len, sentiment, emb_delta=0):\n        # use embedding\n        # note that emb_delta is zero as long as adversarial=False\n        # if adversarial=False then each embedding is shifted by appropriate emb_delta\n        text = tf.nn.embedding_lookup(self.embeddings + emb_delta, text)\n\n        # run gru\n        gru_cell = GRUCell(MLP_HIDDEN_DIM)\n        outputs, state = tf.nn.dynamic_rnn(cell=gru_cell,\n                                           inputs=text,\n                                           sequence_length=text_len,\n                                           dtype=tf.float32)\n\n        # define MLP\n        W1 = tf.get_variable(name='MLP_W1',\n                             shape=[state.get_shape()[1], MLP_HIDDEN_DIM],\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\n        W2 = tf.get_variable(name='MLP_W2',\n                             shape=[MLP_HIDDEN_DIM, 2],\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\n        h1 = tf.get_variable(name='MLP_h1',\n                             shape=[MLP_HIDDEN_DIM],\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\n        h2 = tf.get_variable(name='MLP_h2',\n                             shape=[2],\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\n\n        # apply MLP of the last GRU state\n        after_first_layer = tf.nn.relu(tf.matmul(state, W1) + h1)\n        logits = tf.matmul(after_first_layer, W2) + h2\n\n        # compute loss via categorial cross entropy\n        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, sentiment))\n        return loss\n\n\ndef main():\n    for adversarial in [False, True]:\n        print('\\n=================================')\n        if adversarial:\n            print('Using the adversarial loss')\n        else:\n            print('Using the standard loss')\n\n        net = SimpleSentiment(adversarial=adversarial)\n\n        for epoch in range(5):\n            print('Epoch {}'.format(epoch))\n\n            for batch in range(3):\n                _, loss_final = net.session.run([net.training, net.loss_final],\n                                                {net.text: np.array([[3, 1, 1, 2, 1, 0, 0, 0, 0, 0],\n                                                                     [3, 4, 1, 2, 1, 4, 4, 0, 0, 0],\n                                                                     [1, 1, 1, 2, 0, 0, 0, 0, 0, 0],\n                                                                     [3, 3, 3, 2, 1, 7, 0, 0, 0, 0],\n                                                                     [7, 1, 5, 2, 4, 2, 2, 2, 1, 7]], dtype='int32'),\n                                                 net.text_len: np.array([5, 7, 4, 6, 10], dtype='int32'),\n                                                 net.sentiment: np.array([0, 0, 1, 1, 0], dtype='int32')})\n\n                print('\\tBatch {}: {}'.format(batch, loss_final))\n\nif __name__ == '__main__':\n    main()\nThanks for help\nPetr", "body": "Hello everybody,\r\n\r\n**Introduction:**\r\nI am trying to reproduce the work of Szegedy et al: [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199) and Dezfooli et al: [Universal adversarial perturbations](https://arxiv.org/abs/1610.08401). What they do, briefly, is that they take the gradient `g` of the network with respect to the input image `x`, then slightly modify the input image `x` \"against\" the obtained gradient, i.e. `x-0.001g`. The modified images are consequently considered as another network input, hence new gradients `g'` might be computed and obtained. The result gradients are manually set to the average of those two set obtains gradients, i.e. `g/2 + g'/2`. I hope I explained that clearly.\r\n\r\nI successfully implemented it for images in TF 0.10 (working on 0.12RC as well). Now I want to do something similar with recurrent networks (sentiment analysis task). So I have a input sequence of tokens (numbers), a variable `embeddings` which is used by `tf.nn.embedding_lookup`. After the lookup, the sequence of proper embeddings is traversed by GRU (dynamically). It's last state is considered as the representation of the sequence. Then a MLP with a single hidden layer and ReLU activation is applied, resulting in 2 neurons representing the positive and negative logits respectively. The loss is traditional categorical cross entropy.\r\n\r\n**Bug**\r\nSimilarly to the papers mentioned above, I obtain gradients of the embedding, and modify the current embeddings slightly \"against\" the obtained gradient. Than I compute the new loss and _new gradients (here is the problem!)_ and update the network by their mean.\r\n\r\nThe problem is that the returned _new gradients_ are all `None`s. I originally worked with TF 0.10, however, I got an error explaining that second order derivatives are impossible to obtain from scan. I upgraded to recently released TF 0.12RC which doesn't throw this error but returns `None`s instead.\r\n\r\n**Related Issues and SOs**\r\n#783 is somewhat similar, but not the same. [This question](http://stackoverflow.com/questions/36874522/tensorflow-gradients) deals with very the same problem  but the solution isn't sufficient as replacing the `None` value with zero is really worthless in my case since I need to modify the variable against the gradient.\r\n\r\n**Minimal Not-Working Example**\r\nI am sorry the code is so long. It is partially caused by the fact that the problem is non-trivial and requires few lines and partially by the amount of comments I tried to write in order to make the code more readable. All platform/version information is stored at beginning of the file.\r\n\r\nThe `main()` function constructs two `SimpleSentiment`s as the models that are trained. Each one is trained for few epochs and batches. First instance is without the adversarial, hence we perform no trick regarding modifying the gradients (for a sanity check). The second uses the complicated `if` branch in the constructor and obtains `None`s as described above.\r\n\r\nI believe this is a bug and not my mistake, however, it can't be ruled out as I am not as experienced with TF as I'd like to be.\r\n\r\n```python\r\n# #!/usr/bin/env python3\r\n\r\n# python 3.5 (anaconda)\r\n# TF 0.12 RC from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl\r\n# $ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n#  0.12.0-rc0\r\n\r\n# OS: RedHat 7.2\r\n# CPU version only, no GPU, no CUDA, no CUDNN\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.rnn_cell import GRUCell\r\n\r\n\r\nBATCH = 5  # batch size\r\nMAX_LEN = 10  # max length of the sequence\r\nMLP_HIDDEN_DIM = 128  # number of hidden neurons in the MLP\r\nEMBEDDING_DIM = 300  # embedding dimension\r\nVOCAB_SIZE = 8  # vocabulary size\r\n\r\nTHREADS = 4  # number of threads to be used\r\nSTD=0.001  # standard deviation of ariable initializers\r\n\r\n\r\nclass SimpleSentiment:\r\n    def __init__(self, adversarial=False, device='/cpu:0'):\r\n\r\n        self.embeddings = tf.get_variable('word_embeddings',\r\n                                          initializer=tf.random_uniform([VOCAB_SIZE, EMBEDDING_DIM], -1.0, 1.0))\r\n\r\n        with tf.variable_scope('sentiment') as scope:\r\n            with tf.device(device):\r\n                # Inputs\r\n                self.text = tf.placeholder(tf.int32, [BATCH, MAX_LEN])\r\n                self.text_len = tf.placeholder(tf.int32, [BATCH])\r\n                self.sentiment = tf.placeholder(tf.int32, [BATCH])\r\n\r\n                # Normal loss\r\n                loss_normal = self._loss(self.text, self.text_len, self.sentiment)\r\n\r\n                # Define the optimizer\r\n                # Note: I've tried multiple of optimizers and none helped\r\n                optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\r\n\r\n                if adversarial:  # Define adversarial loss\r\n                    # Let's acces already defined variables\r\n                    scope.reuse_variables()\r\n\r\n                    # Gradients of all variable (according to normal loss)\r\n                    gradients = optimizer.compute_gradients(loss_normal)\r\n                    print(len(gradients), gradients)\r\n\r\n                    # gradients of the embeddings\r\n                    emb_gradient = optimizer.compute_gradients(loss_normal, [self.embeddings])[0][0]\r\n\r\n                    # this how much we want to shift the embeddings, i.e. going \"against\" the gradient\r\n                    delta = 0.001*tf.sign(emb_gradient)\r\n\r\n                    # let's compute the loss once again but this time we add the delta to the embeddings\r\n                    loss_adversarial = self._loss(self.text, self.text_len, self.sentiment, delta)\r\n\r\n                    # new gradient of the whole computational graph\r\n                    adversarial_gradients = optimizer.compute_gradients(loss_adversarial)\r\n                    print(len(adversarial_gradients), adversarial_gradients)  # everything is None!\r\n\r\n                    # Now we compute an average of old and new gradients\r\n                    new_gradients = [((g + ag)/2, vg) for ((g, vg), (ag, avg)) in zip(gradients, adversarial_gradients)]\r\n\r\n                    # and apply them\r\n                    self.training = optimizer.apply_gradients(new_gradients)\r\n\r\n                    # Btw this doesn't work either\r\n                    # self.training = optimizer.apply_gradients(adversarial_gradients)\r\n\r\n                    self.loss_final = (loss_normal + loss_adversarial) / 2\r\n\r\n                else:  # Normal loss\r\n                    # simply minimize according to the gradients\r\n                    self.loss_final = loss_normal\r\n                    self.training = optimizer.minimize(loss_normal)\r\n\r\n                # Create the session\r\n                self.session = tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=THREADS,\r\n                                                                intra_op_parallelism_threads=THREADS,\r\n                                                                allow_soft_placement=True))\r\n\r\n                # init everything (still deprecated way)\r\n                self.session.run(tf.initialize_all_variables())\r\n\r\n    def _loss(self, text, text_len, sentiment, emb_delta=0):\r\n        # use embedding\r\n        # note that emb_delta is zero as long as adversarial=False\r\n        # if adversarial=False then each embedding is shifted by appropriate emb_delta\r\n        text = tf.nn.embedding_lookup(self.embeddings + emb_delta, text)\r\n\r\n        # run gru\r\n        gru_cell = GRUCell(MLP_HIDDEN_DIM)\r\n        outputs, state = tf.nn.dynamic_rnn(cell=gru_cell,\r\n                                           inputs=text,\r\n                                           sequence_length=text_len,\r\n                                           dtype=tf.float32)\r\n\r\n        # define MLP\r\n        W1 = tf.get_variable(name='MLP_W1',\r\n                             shape=[state.get_shape()[1], MLP_HIDDEN_DIM],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        W2 = tf.get_variable(name='MLP_W2',\r\n                             shape=[MLP_HIDDEN_DIM, 2],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        h1 = tf.get_variable(name='MLP_h1',\r\n                             shape=[MLP_HIDDEN_DIM],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        h2 = tf.get_variable(name='MLP_h2',\r\n                             shape=[2],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n\r\n        # apply MLP of the last GRU state\r\n        after_first_layer = tf.nn.relu(tf.matmul(state, W1) + h1)\r\n        logits = tf.matmul(after_first_layer, W2) + h2\r\n\r\n        # compute loss via categorial cross entropy\r\n        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, sentiment))\r\n        return loss\r\n\r\n\r\ndef main():\r\n    for adversarial in [False, True]:\r\n        print('\\n=================================')\r\n        if adversarial:\r\n            print('Using the adversarial loss')\r\n        else:\r\n            print('Using the standard loss')\r\n\r\n        net = SimpleSentiment(adversarial=adversarial)\r\n\r\n        for epoch in range(5):\r\n            print('Epoch {}'.format(epoch))\r\n\r\n            for batch in range(3):\r\n                _, loss_final = net.session.run([net.training, net.loss_final],\r\n                                                {net.text: np.array([[3, 1, 1, 2, 1, 0, 0, 0, 0, 0],\r\n                                                                     [3, 4, 1, 2, 1, 4, 4, 0, 0, 0],\r\n                                                                     [1, 1, 1, 2, 0, 0, 0, 0, 0, 0],\r\n                                                                     [3, 3, 3, 2, 1, 7, 0, 0, 0, 0],\r\n                                                                     [7, 1, 5, 2, 4, 2, 2, 2, 1, 7]], dtype='int32'),\r\n                                                 net.text_len: np.array([5, 7, 4, 6, 10], dtype='int32'),\r\n                                                 net.sentiment: np.array([0, 0, 1, 1, 0], dtype='int32')})\r\n\r\n                print('\\tBatch {}: {}'.format(batch, loss_final))\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nThanks for help\r\nPetr"}