{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1231", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1231/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1231/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1231/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1231", "id": 135304268, "node_id": "MDU6SXNzdWUxMzUzMDQyNjg=", "number": 1231, "title": "sampled softmax vs regular softmax", "user": {"login": "zcyang", "id": 5890073, "node_id": "MDQ6VXNlcjU4OTAwNzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/5890073?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zcyang", "html_url": "https://github.com/zcyang", "followers_url": "https://api.github.com/users/zcyang/followers", "following_url": "https://api.github.com/users/zcyang/following{/other_user}", "gists_url": "https://api.github.com/users/zcyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/zcyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zcyang/subscriptions", "organizations_url": "https://api.github.com/users/zcyang/orgs", "repos_url": "https://api.github.com/users/zcyang/repos", "events_url": "https://api.github.com/users/zcyang/events{/privacy}", "received_events_url": "https://api.github.com/users/zcyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-02-22T03:32:30Z", "updated_at": "2016-02-25T04:20:26Z", "closed_at": "2016-02-22T07:35:00Z", "author_association": "NONE", "body_html": "<p>For the seq2seq example, sampled softmax is 2-3 times slower than regular softmax, is it because sampled softmax is on CPU while regular softmax is on GPU? Then why do we need sampled softmax, it saves gpu memory?</p>\n<p>But the convergence speed of sampled softmax (in terms of iterations) is much faster then regular softmax? Any mathematical reasons?</p>\n<p>Many thanks!</p>", "body_text": "For the seq2seq example, sampled softmax is 2-3 times slower than regular softmax, is it because sampled softmax is on CPU while regular softmax is on GPU? Then why do we need sampled softmax, it saves gpu memory?\nBut the convergence speed of sampled softmax (in terms of iterations) is much faster then regular softmax? Any mathematical reasons?\nMany thanks!", "body": "For the seq2seq example, sampled softmax is 2-3 times slower than regular softmax, is it because sampled softmax is on CPU while regular softmax is on GPU? Then why do we need sampled softmax, it saves gpu memory?\n\nBut the convergence speed of sampled softmax (in terms of iterations) is much faster then regular softmax? Any mathematical reasons?\n\nMany thanks!\n"}