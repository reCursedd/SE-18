{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422599063", "html_url": "https://github.com/tensorflow/tensorflow/issues/22234#issuecomment-422599063", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22234", "id": 422599063, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjU5OTA2Mw==", "user": {"login": "omalleyt12", "id": 29100818, "node_id": "MDQ6VXNlcjI5MTAwODE4", "avatar_url": "https://avatars3.githubusercontent.com/u/29100818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/omalleyt12", "html_url": "https://github.com/omalleyt12", "followers_url": "https://api.github.com/users/omalleyt12/followers", "following_url": "https://api.github.com/users/omalleyt12/following{/other_user}", "gists_url": "https://api.github.com/users/omalleyt12/gists{/gist_id}", "starred_url": "https://api.github.com/users/omalleyt12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/omalleyt12/subscriptions", "organizations_url": "https://api.github.com/users/omalleyt12/orgs", "repos_url": "https://api.github.com/users/omalleyt12/repos", "events_url": "https://api.github.com/users/omalleyt12/events{/privacy}", "received_events_url": "https://api.github.com/users/omalleyt12/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T00:01:00Z", "updated_at": "2018-09-19T00:01:00Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16792948\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/OneMoreSecond\">@OneMoreSecond</a> Your <code>Lambda</code> should accept a list of inputs rather than referencing the global variable <code>inputs2</code>. I'm not sure <code>TimeDistributed</code> is the best way to go about this. Here's an example that I believe satisfies your use case</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow.keras <span class=\"pl-k\">as</span> k\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ninput1 <span class=\"pl-k\">=</span> k.layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">10</span>))\ninput2 <span class=\"pl-k\">=</span> k.layers.Input(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">10</span>,))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">expand_and_concat</span>(<span class=\"pl-smi\">x</span>):\n  x0, x1 <span class=\"pl-k\">=</span> x\n  x1  <span class=\"pl-k\">=</span> tf.expand_dims(x1, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n  x1  <span class=\"pl-k\">=</span> tf.tile(x1, [<span class=\"pl-c1\">1</span>, tf.shape(x0)[<span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">1</span>])\n  <span class=\"pl-k\">return</span> tf.concat([x0, x1], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\nresults <span class=\"pl-k\">=</span> k.layers.Lambda(expand_and_concat)([input1, input2])\nmodel <span class=\"pl-k\">=</span> k.models.Model([input1, input2], results)\n\ndata1 <span class=\"pl-k\">=</span> np.zeros((<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">7</span>,<span class=\"pl-c1\">10</span>))\ndata2 <span class=\"pl-k\">=</span> np.zeros((<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">10</span>))\n\nmodel.predict([data1,data2])</pre></div>", "body_text": "@OneMoreSecond Your Lambda should accept a list of inputs rather than referencing the global variable inputs2. I'm not sure TimeDistributed is the best way to go about this. Here's an example that I believe satisfies your use case\nimport tensorflow.keras as k\nimport numpy as np\n\ninput1 = k.layers.Input(shape=(None, 10))\ninput2 = k.layers.Input(shape=(10,))\n\ndef expand_and_concat(x):\n  x0, x1 = x\n  x1  = tf.expand_dims(x1, axis=1)\n  x1  = tf.tile(x1, [1, tf.shape(x0)[1], 1])\n  return tf.concat([x0, x1], axis=2)\n\nresults = k.layers.Lambda(expand_and_concat)([input1, input2])\nmodel = k.models.Model([input1, input2], results)\n\ndata1 = np.zeros((3,7,10))\ndata2 = np.zeros((3,10))\n\nmodel.predict([data1,data2])", "body": "@OneMoreSecond Your `Lambda` should accept a list of inputs rather than referencing the global variable `inputs2`. I'm not sure `TimeDistributed` is the best way to go about this. Here's an example that I believe satisfies your use case\r\n\r\n```python\r\nimport tensorflow.keras as k\r\nimport numpy as np\r\n\r\ninput1 = k.layers.Input(shape=(None, 10))\r\ninput2 = k.layers.Input(shape=(10,))\r\n\r\ndef expand_and_concat(x):\r\n  x0, x1 = x\r\n  x1  = tf.expand_dims(x1, axis=1)\r\n  x1  = tf.tile(x1, [1, tf.shape(x0)[1], 1])\r\n  return tf.concat([x0, x1], axis=2)\r\n\r\nresults = k.layers.Lambda(expand_and_concat)([input1, input2])\r\nmodel = k.models.Model([input1, input2], results)\r\n\r\ndata1 = np.zeros((3,7,10))\r\ndata2 = np.zeros((3,10))\r\n\r\nmodel.predict([data1,data2])\r\n```\r\n"}