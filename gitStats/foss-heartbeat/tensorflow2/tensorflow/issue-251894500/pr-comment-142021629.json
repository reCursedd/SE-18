{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/142021629", "pull_request_review_id": 66328763, "id": 142021629, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MjAyMTYyOQ==", "diff_hunk": "@@ -260,7 +260,8 @@ def _log_prob(self, counts):\n \n   def _log_unnormalized_prob(self, counts):\n     counts = self._maybe_assert_valid_sample(counts)\n-    return math_ops.reduce_sum(counts * math_ops.log(self.probs), -1)\n+    logsumexp = math_ops.reduce_logsumexp(self.logits, -1, keep_dims=True)", "path": "tensorflow/python/ops/distributions/multinomial.py", "position": 5, "original_position": 5, "commit_id": "f9ebb6e634d7d32fe95395c6b0b02498b8384774", "original_commit_id": "f9ebb6e634d7d32fe95395c6b0b02498b8384774", "user": {"login": "YiMX", "id": 24216379, "node_id": "MDQ6VXNlcjI0MjE2Mzc5", "avatar_url": "https://avatars0.githubusercontent.com/u/24216379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YiMX", "html_url": "https://github.com/YiMX", "followers_url": "https://api.github.com/users/YiMX/followers", "following_url": "https://api.github.com/users/YiMX/following{/other_user}", "gists_url": "https://api.github.com/users/YiMX/gists{/gist_id}", "starred_url": "https://api.github.com/users/YiMX/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YiMX/subscriptions", "organizations_url": "https://api.github.com/users/YiMX/orgs", "repos_url": "https://api.github.com/users/YiMX/repos", "events_url": "https://api.github.com/users/YiMX/events{/privacy}", "received_events_url": "https://api.github.com/users/YiMX/received_events", "type": "User", "site_admin": false}, "body": "![default](https://user-images.githubusercontent.com/24216379/31052265-5a7fb326-a6b2-11e7-9761-8cdb7e02fd2c.png)\r\n```\r\nfrom tensorflow.python.ops import math_ops\r\nimport tensorflow as tf\r\n\r\nwith tf.Session() as sess:\r\n    counts = [1., 2., 3.]\r\n    logits = [-1., 2., 3.]\r\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\r\n    \r\n    # The previous one\r\n    print('The previous one', sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\r\n    \r\n    # Minus cross entropy\r\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\r\n    \r\n    # The current one\r\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\r\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\r\n\r\n    \r\n    # Let some of probs be close to zero\r\n    counts = [1., 2., 3.]\r\n    logits = [-1000., 2000., 2000.]\r\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\r\n    \r\n    # The previous one\r\n    print('The previous one',sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\r\n    \r\n    # Minus cross entropy\r\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\r\n    \r\n    # The current one\r\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\r\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\r\n```\r\n**The above returns:**\r\n\r\n('The previous one', -7.9593754)\r\n('Minus Cross entropy', -7.9593763)\r\n('The current one', -7.9593763)\r\n('The previous one', nan)\r\n('Minus Cross entropy', -3004.1587)\r\n('The current one', -3004.1587)\r\n", "created_at": "2017-10-01T06:14:16Z", "updated_at": "2017-10-01T06:14:16Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/12485#discussion_r142021629", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12485", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/142021629"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/12485#discussion_r142021629"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12485"}}, "body_html": "<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/24216379/31052265-5a7fb326-a6b2-11e7-9761-8cdb7e02fd2c.png\"><img src=\"https://user-images.githubusercontent.com/24216379/31052265-5a7fb326-a6b2-11e7-9761-8cdb7e02fd2c.png\" alt=\"default\" style=\"max-width:100%;\"></a></p>\n<pre><code>from tensorflow.python.ops import math_ops\nimport tensorflow as tf\n\nwith tf.Session() as sess:\n    counts = [1., 2., 3.]\n    logits = [-1., 2., 3.]\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\n    \n    # The previous one\n    print('The previous one', sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\n    \n    # Minus cross entropy\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\n    \n    # The current one\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\n\n    \n    # Let some of probs be close to zero\n    counts = [1., 2., 3.]\n    logits = [-1000., 2000., 2000.]\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\n    \n    # The previous one\n    print('The previous one',sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\n    \n    # Minus cross entropy\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\n    \n    # The current one\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\n</code></pre>\n<p><strong>The above returns:</strong></p>\n<p>('The previous one', -7.9593754)<br>\n('Minus Cross entropy', -7.9593763)<br>\n('The current one', -7.9593763)<br>\n('The previous one', nan)<br>\n('Minus Cross entropy', -3004.1587)<br>\n('The current one', -3004.1587)</p>", "body_text": "from tensorflow.python.ops import math_ops\nimport tensorflow as tf\n\nwith tf.Session() as sess:\n    counts = [1., 2., 3.]\n    logits = [-1., 2., 3.]\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\n    \n    # The previous one\n    print('The previous one', sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\n    \n    # Minus cross entropy\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\n    \n    # The current one\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\n\n    \n    # Let some of probs be close to zero\n    counts = [1., 2., 3.]\n    logits = [-1000., 2000., 2000.]\n    probs = tf.exp(logits) / tf.reduce_sum(tf.exp(logits))\n    \n    # The previous one\n    print('The previous one',sess.run(math_ops.reduce_sum(counts * math_ops.log(probs), -1)))\n    \n    # Minus cross entropy\n    print('Minus Cross entropy', sess.run(-tf.nn.softmax_cross_entropy_with_logits(labels=counts, logits=logits)))\n    \n    # The current one\n    logsumexp = math_ops.reduce_logsumexp(logits, -1, keep_dims=True)\n    print('The current one',sess.run(math_ops.reduce_sum(counts * (logits - logsumexp), -1)))\n\nThe above returns:\n('The previous one', -7.9593754)\n('Minus Cross entropy', -7.9593763)\n('The current one', -7.9593763)\n('The previous one', nan)\n('Minus Cross entropy', -3004.1587)\n('The current one', -3004.1587)", "in_reply_to_id": 141989468}