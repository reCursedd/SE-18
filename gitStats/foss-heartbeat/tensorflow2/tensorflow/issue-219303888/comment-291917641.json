{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291917641", "html_url": "https://github.com/tensorflow/tensorflow/pull/8955#issuecomment-291917641", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8955", "id": 291917641, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTkxNzY0MQ==", "user": {"login": "vrv", "id": 463737, "node_id": "MDQ6VXNlcjQ2MzczNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/463737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrv", "html_url": "https://github.com/vrv", "followers_url": "https://api.github.com/users/vrv/followers", "following_url": "https://api.github.com/users/vrv/following{/other_user}", "gists_url": "https://api.github.com/users/vrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrv/subscriptions", "organizations_url": "https://api.github.com/users/vrv/orgs", "repos_url": "https://api.github.com/users/vrv/repos", "events_url": "https://api.github.com/users/vrv/events{/privacy}", "received_events_url": "https://api.github.com/users/vrv/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T16:27:43Z", "updated_at": "2017-04-05T16:27:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think the documentation is correct:</p>\n<ul>\n<li>\n<p>An op that produces multiple outputs may receive gradients from each of them.  Hence, in the gradient function for an op, 'grads' will be the gradients it receives for each output, and so 'grads' will contain as many Tensors as there are outputs.</p>\n</li>\n<li>\n<p>The gradient function must <em>produce</em> / return Tensors (or None) for each of its inputs, since the ops that produce the input would also expect to receive a Tensor as their gradients.</p>\n</li>\n</ul>\n<p>Is that clear?  Feel free to comment if you think further clarification is needed..</p>", "body_text": "I think the documentation is correct:\n\n\nAn op that produces multiple outputs may receive gradients from each of them.  Hence, in the gradient function for an op, 'grads' will be the gradients it receives for each output, and so 'grads' will contain as many Tensors as there are outputs.\n\n\nThe gradient function must produce / return Tensors (or None) for each of its inputs, since the ops that produce the input would also expect to receive a Tensor as their gradients.\n\n\nIs that clear?  Feel free to comment if you think further clarification is needed..", "body": "I think the documentation is correct:\r\n\r\n- An op that produces multiple outputs may receive gradients from each of them.  Hence, in the gradient function for an op, 'grads' will be the gradients it receives for each output, and so 'grads' will contain as many Tensors as there are outputs. \r\n\r\n- The gradient function must *produce* / return Tensors (or None) for each of its inputs, since the ops that produce the input would also expect to receive a Tensor as their gradients. \r\n\r\nIs that clear?  Feel free to comment if you think further clarification is needed.."}