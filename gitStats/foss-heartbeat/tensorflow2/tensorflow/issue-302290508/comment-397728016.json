{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397728016", "html_url": "https://github.com/tensorflow/tensorflow/pull/17438#issuecomment-397728016", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17438", "id": 397728016, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzcyODAxNg==", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-15T20:04:13Z", "updated_at": "2018-06-15T20:04:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=28400841\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pierremac\">@pierremac</a>: The weight decay parameter (let's call it <code>w</code> here) is the parameter that is multiplied with the variable before subtracting it, i.e., an update step looks roughly like this:<br>\n<code>var = var - grad - (w * var)</code><br>\nIt's not possible to compute the normalized weight decay within the optimizer as this depends on your specific dataset.<br>\nTo now create AdamWR as in the paper, you need to compute the decay manually by multiplying your initial decay (ideally the normalized version) with your learning rate schedule, e.g.,</p>\n<pre><code>LR = ... # set your learning rate here\nW_NORM = ...  # set your weight decay value here\nglobal_step = tf.train.get_or_create_global_step()\nschedule = tf.train.cosine_decay_restarts(1, global_step,\n                                          first_decay_steps=?, t_mul=2.0,\n                                          m_mul=1.0, alpha=0.0)\nlr = LR * schedule\nweight_decay = W_NORM * sqrt(batch_size / num_training_samples * num_epochs) * schedule\n\nloss = ...\noptimizer = tf.contrib.opt.AdamwOptimizer(weight_decay, lr)\ntrain_op = optimizer.minimize(loss)\n\n</code></pre>\n<p>Regarding values for LR and W_NORM, this really depends on your model. W_NORM usually should be smaller than LR as otherwise regularization is stronger than the update step. The nice thing about decoupled weight decay is that you can tune learning rate and weight decay independent. So I'd suggest to first set decay to 0, do hyperparameter optimization for the learning rate and once you have found the<br>\nbest performing learning rate you keep that fixed and start to optimize the decay parameter.</p>\n<p>Hope that helps a bit ;)</p>", "body_text": "@pierremac: The weight decay parameter (let's call it w here) is the parameter that is multiplied with the variable before subtracting it, i.e., an update step looks roughly like this:\nvar = var - grad - (w * var)\nIt's not possible to compute the normalized weight decay within the optimizer as this depends on your specific dataset.\nTo now create AdamWR as in the paper, you need to compute the decay manually by multiplying your initial decay (ideally the normalized version) with your learning rate schedule, e.g.,\nLR = ... # set your learning rate here\nW_NORM = ...  # set your weight decay value here\nglobal_step = tf.train.get_or_create_global_step()\nschedule = tf.train.cosine_decay_restarts(1, global_step,\n                                          first_decay_steps=?, t_mul=2.0,\n                                          m_mul=1.0, alpha=0.0)\nlr = LR * schedule\nweight_decay = W_NORM * sqrt(batch_size / num_training_samples * num_epochs) * schedule\n\nloss = ...\noptimizer = tf.contrib.opt.AdamwOptimizer(weight_decay, lr)\ntrain_op = optimizer.minimize(loss)\n\n\nRegarding values for LR and W_NORM, this really depends on your model. W_NORM usually should be smaller than LR as otherwise regularization is stronger than the update step. The nice thing about decoupled weight decay is that you can tune learning rate and weight decay independent. So I'd suggest to first set decay to 0, do hyperparameter optimization for the learning rate and once you have found the\nbest performing learning rate you keep that fixed and start to optimize the decay parameter.\nHope that helps a bit ;)", "body": "@pierremac: The weight decay parameter (let's call it `w` here) is the parameter that is multiplied with the variable before subtracting it, i.e., an update step looks roughly like this:\r\n`var = var - grad - (w * var)`\r\nIt's not possible to compute the normalized weight decay within the optimizer as this depends on your specific dataset. \r\nTo now create AdamWR as in the paper, you need to compute the decay manually by multiplying your initial decay (ideally the normalized version) with your learning rate schedule, e.g.,\r\n```\r\nLR = ... # set your learning rate here\r\nW_NORM = ...  # set your weight decay value here\r\nglobal_step = tf.train.get_or_create_global_step()\r\nschedule = tf.train.cosine_decay_restarts(1, global_step,\r\n                                          first_decay_steps=?, t_mul=2.0,\r\n                                          m_mul=1.0, alpha=0.0)\r\nlr = LR * schedule\r\nweight_decay = W_NORM * sqrt(batch_size / num_training_samples * num_epochs) * schedule\r\n\r\nloss = ...\r\noptimizer = tf.contrib.opt.AdamwOptimizer(weight_decay, lr)\r\ntrain_op = optimizer.minimize(loss)\r\n\r\n```\r\n\r\nRegarding values for LR and W_NORM, this really depends on your model. W_NORM usually should be smaller than LR as otherwise regularization is stronger than the update step. The nice thing about decoupled weight decay is that you can tune learning rate and weight decay independent. So I'd suggest to first set decay to 0, do hyperparameter optimization for the learning rate and once you have found the\r\nbest performing learning rate you keep that fixed and start to optimize the decay parameter.\r\n\r\nHope that helps a bit ;)"}