{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12598", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12598/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12598/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12598/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12598", "id": 252897236, "node_id": "MDU6SXNzdWUyNTI4OTcyMzY=", "number": 12598, "title": "data dependent variable initialization in tf 1.3.0", "user": {"login": "pesser", "id": 2175508, "node_id": "MDQ6VXNlcjIxNzU1MDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/2175508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pesser", "html_url": "https://github.com/pesser", "followers_url": "https://api.github.com/users/pesser/followers", "following_url": "https://api.github.com/users/pesser/following{/other_user}", "gists_url": "https://api.github.com/users/pesser/gists{/gist_id}", "starred_url": "https://api.github.com/users/pesser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pesser/subscriptions", "organizations_url": "https://api.github.com/users/pesser/orgs", "repos_url": "https://api.github.com/users/pesser/repos", "events_url": "https://api.github.com/users/pesser/events{/privacy}", "received_events_url": "https://api.github.com/users/pesser/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2017-08-25T13:14:52Z", "updated_at": "2018-04-17T08:05:11Z", "closed_at": "2018-04-17T08:05:11Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: ArchLinux</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: <code>pip install tensorflow-gpu</code></li>\n<li><strong>TensorFlow version (use command below)</strong>: <code>v1.3.0-rc2-20-g0787eee 1.3.0</code></li>\n<li><strong>Python version</strong>: <code>Python 3.6.2</code></li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: <code>cuda 8.0.61</code>/<code>cudnn6 6.0.21</code></li>\n<li><strong>GPU model and memory</strong>: GeForce GTX 980M 8GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>After updating to tf 1.3 my usual routines for data dependent initialization of variables are broken. They take massive amounts of time and memory. I have written a minimal example to reproduce the problem (see below). In fact, the example suggests that the time increases exponentially with the number of layers, i.e. it takes takes roughly 6, 12 and 24 seconds to initialize 10, 11 and 12 layers, respectively. On a different machine running on tf 1.2.1 the same code initializes 100 layers in less than a second yet it produces the same, correct values. Similiarly, the (host) memory usage explodes. I should also mention that the issue appears when defining the graph, i.e. before any session is opened, and not during execution of the initialization operation.</p>\n<p>I would be glad if someone can point out a better way of doing the kind of data dependent initialization shown in the example (using two passes is somewhat annoying) but the issue is that the update made this method completely unusable. <a href=\"https://github.com/tensorflow/tensorflow/files/1251882/traceback.txt\">Traceback from keyboard interrupt</a> suggest that the recently introduced <a href=\"https://github.com/tensorflow/tensorflow/blob/ebc421daf2c812fdfc3007294741c6c07f4957c3/tensorflow/python/ops/variables.py#L763\"><code>_build_initializer_expr</code></a> might be involved.</p>\n<h3>Source code / logs</h3>\n<pre><code>import time\nimport tensorflow as tf\n\ndef layer(x, name, init):\n    with tf.variable_scope(name, reuse = not init):\n        initializer = x\n        b = tf.get_variable('b', dtype=tf.float32, initializer = initializer)\n        # without next if we get error\n        # 'Attempting to use uninitialized variable.'\n        # for layer 1\n        if init:\n            return x + b.initialized_value()\n        else:\n            return x + b\n\n\nif __name__ == \"__main__\":\n    n_layers = 10\n\n    print(\"tensorflow {} {}\".format(tf.GIT_VERSION, tf.VERSION))\n    print(\"n_layers {}\".format(n_layers))\n\n    def _pass(x, init):\n        h = x\n        for i in range(n_layers):\n            h = layer(h, \"layer_{}\".format(i), init)\n        return h\n    \n    # first pass for initialization\n    x = tf.constant([1.0])\n    t = time.time()\n    h = _pass(x, True)\n    print(\"init pass {:.4}\".format(time.time() - t))\n\n    # second pass as usual\n    t = time.time()\n    h = _pass(x, False)\n    print(\"next pass {:.4}\".format(time.time() - t))\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        print(\"final value {}\".format(h.eval()))\n</code></pre>\n<p>This is basically the data dependent initialization method as described in <a href=\"https://github.com/openai/weightnorm\">OpenAI's weight norm code</a> stripped down to the bare minimum where the problem occurs. This weight normalization code as well as the <a href=\"https://github.com/openai/pixel-cnn\">PixelCNN++ code</a> are also affected by this.</p>\n<p>Output on 1.3.0:</p>\n<pre><code>tensorflow v1.3.0-rc2-20-g0787eee 1.3.0\nn_layers 10\ninit pass 5.934\nnext pass 0.003919\nfinal value [ 1024.]\n</code></pre>\n<p>Output on 1.2.1 (different machine):</p>\n<pre><code>tensorflow 1.2.1\nn_layers 10\ninit pass 0.1085\nnext pass 0.00644\nfinal value [ 1024.]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ArchLinux\nTensorFlow installed from (source or binary): pip install tensorflow-gpu\nTensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0\nPython version: Python 3.6.2\nBazel version (if compiling from source):\nCUDA/cuDNN version: cuda 8.0.61/cudnn6 6.0.21\nGPU model and memory: GeForce GTX 980M 8GB\nExact command to reproduce:\n\nDescribe the problem\nAfter updating to tf 1.3 my usual routines for data dependent initialization of variables are broken. They take massive amounts of time and memory. I have written a minimal example to reproduce the problem (see below). In fact, the example suggests that the time increases exponentially with the number of layers, i.e. it takes takes roughly 6, 12 and 24 seconds to initialize 10, 11 and 12 layers, respectively. On a different machine running on tf 1.2.1 the same code initializes 100 layers in less than a second yet it produces the same, correct values. Similiarly, the (host) memory usage explodes. I should also mention that the issue appears when defining the graph, i.e. before any session is opened, and not during execution of the initialization operation.\nI would be glad if someone can point out a better way of doing the kind of data dependent initialization shown in the example (using two passes is somewhat annoying) but the issue is that the update made this method completely unusable. Traceback from keyboard interrupt suggest that the recently introduced _build_initializer_expr might be involved.\nSource code / logs\nimport time\nimport tensorflow as tf\n\ndef layer(x, name, init):\n    with tf.variable_scope(name, reuse = not init):\n        initializer = x\n        b = tf.get_variable('b', dtype=tf.float32, initializer = initializer)\n        # without next if we get error\n        # 'Attempting to use uninitialized variable.'\n        # for layer 1\n        if init:\n            return x + b.initialized_value()\n        else:\n            return x + b\n\n\nif __name__ == \"__main__\":\n    n_layers = 10\n\n    print(\"tensorflow {} {}\".format(tf.GIT_VERSION, tf.VERSION))\n    print(\"n_layers {}\".format(n_layers))\n\n    def _pass(x, init):\n        h = x\n        for i in range(n_layers):\n            h = layer(h, \"layer_{}\".format(i), init)\n        return h\n    \n    # first pass for initialization\n    x = tf.constant([1.0])\n    t = time.time()\n    h = _pass(x, True)\n    print(\"init pass {:.4}\".format(time.time() - t))\n\n    # second pass as usual\n    t = time.time()\n    h = _pass(x, False)\n    print(\"next pass {:.4}\".format(time.time() - t))\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        print(\"final value {}\".format(h.eval()))\n\nThis is basically the data dependent initialization method as described in OpenAI's weight norm code stripped down to the bare minimum where the problem occurs. This weight normalization code as well as the PixelCNN++ code are also affected by this.\nOutput on 1.3.0:\ntensorflow v1.3.0-rc2-20-g0787eee 1.3.0\nn_layers 10\ninit pass 5.934\nnext pass 0.003919\nfinal value [ 1024.]\n\nOutput on 1.2.1 (different machine):\ntensorflow 1.2.1\nn_layers 10\ninit pass 0.1085\nnext pass 0.00644\nfinal value [ 1024.]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ArchLinux\r\n- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: `v1.3.0-rc2-20-g0787eee 1.3.0`\r\n- **Python version**: `Python 3.6.2`\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: `cuda 8.0.61`/`cudnn6 6.0.21`\r\n- **GPU model and memory**: GeForce GTX 980M 8GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nAfter updating to tf 1.3 my usual routines for data dependent initialization of variables are broken. They take massive amounts of time and memory. I have written a minimal example to reproduce the problem (see below). In fact, the example suggests that the time increases exponentially with the number of layers, i.e. it takes takes roughly 6, 12 and 24 seconds to initialize 10, 11 and 12 layers, respectively. On a different machine running on tf 1.2.1 the same code initializes 100 layers in less than a second yet it produces the same, correct values. Similiarly, the (host) memory usage explodes. I should also mention that the issue appears when defining the graph, i.e. before any session is opened, and not during execution of the initialization operation.\r\n\r\nI would be glad if someone can point out a better way of doing the kind of data dependent initialization shown in the example (using two passes is somewhat annoying) but the issue is that the update made this method completely unusable. [Traceback from keyboard interrupt](https://github.com/tensorflow/tensorflow/files/1251882/traceback.txt) suggest that the recently introduced [`_build_initializer_expr`](https://github.com/tensorflow/tensorflow/blob/ebc421daf2c812fdfc3007294741c6c07f4957c3/tensorflow/python/ops/variables.py#L763) might be involved.\r\n\r\n### Source code / logs\r\n\r\n    import time\r\n    import tensorflow as tf\r\n\r\n    def layer(x, name, init):\r\n        with tf.variable_scope(name, reuse = not init):\r\n            initializer = x\r\n            b = tf.get_variable('b', dtype=tf.float32, initializer = initializer)\r\n            # without next if we get error\r\n            # 'Attempting to use uninitialized variable.'\r\n            # for layer 1\r\n            if init:\r\n                return x + b.initialized_value()\r\n            else:\r\n                return x + b\r\n\r\n\r\n    if __name__ == \"__main__\":\r\n        n_layers = 10\r\n\r\n        print(\"tensorflow {} {}\".format(tf.GIT_VERSION, tf.VERSION))\r\n        print(\"n_layers {}\".format(n_layers))\r\n\r\n        def _pass(x, init):\r\n            h = x\r\n            for i in range(n_layers):\r\n                h = layer(h, \"layer_{}\".format(i), init)\r\n            return h\r\n        \r\n        # first pass for initialization\r\n        x = tf.constant([1.0])\r\n        t = time.time()\r\n        h = _pass(x, True)\r\n        print(\"init pass {:.4}\".format(time.time() - t))\r\n\r\n        # second pass as usual\r\n        t = time.time()\r\n        h = _pass(x, False)\r\n        print(\"next pass {:.4}\".format(time.time() - t))\r\n\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            print(\"final value {}\".format(h.eval()))\r\n\r\n\r\nThis is basically the data dependent initialization method as described in [OpenAI's weight norm code](https://github.com/openai/weightnorm) stripped down to the bare minimum where the problem occurs. This weight normalization code as well as the [PixelCNN++ code](https://github.com/openai/pixel-cnn) are also affected by this.\r\n\r\nOutput on 1.3.0:\r\n\r\n    tensorflow v1.3.0-rc2-20-g0787eee 1.3.0\r\n    n_layers 10\r\n    init pass 5.934\r\n    next pass 0.003919\r\n    final value [ 1024.]\r\n\r\nOutput on 1.2.1 (different machine):\r\n\r\n    tensorflow 1.2.1\r\n    n_layers 10\r\n    init pass 0.1085\r\n    next pass 0.00644\r\n    final value [ 1024.]\r\n\r\n\r\n\r\n\r\n"}