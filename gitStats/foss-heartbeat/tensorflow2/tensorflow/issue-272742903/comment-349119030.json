{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/349119030", "html_url": "https://github.com/tensorflow/tensorflow/issues/14423#issuecomment-349119030", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14423", "id": 349119030, "node_id": "MDEyOklzc3VlQ29tbWVudDM0OTExOTAzMA==", "user": {"login": "nluehr", "id": 1873655, "node_id": "MDQ6VXNlcjE4NzM2NTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1873655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nluehr", "html_url": "https://github.com/nluehr", "followers_url": "https://api.github.com/users/nluehr/followers", "following_url": "https://api.github.com/users/nluehr/following{/other_user}", "gists_url": "https://api.github.com/users/nluehr/gists{/gist_id}", "starred_url": "https://api.github.com/users/nluehr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nluehr/subscriptions", "organizations_url": "https://api.github.com/users/nluehr/orgs", "repos_url": "https://api.github.com/users/nluehr/repos", "events_url": "https://api.github.com/users/nluehr/events{/privacy}", "received_events_url": "https://api.github.com/users/nluehr/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-04T21:54:46Z", "updated_at": "2017-12-04T21:54:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have not been able to reproduce system hangs using the 387.12 driver on Ubuntu 16.04.</p>\n<p>The slow initialization is indeed likely the driver JIT compiling PTX for your GPU's specific architecture.  On my system, this takes between 90 and 105 seconds and results in a cache size of ~116MB. During the jit, Ctrl-C waits for the jit to complete before exiting, but killing the jitting process from another terminal terminates the jit immediately.</p>\n<p>After the first run caches the tensorflow binaries, subsequent runs of the 'global_variable_initializer' test provided above runs in ~1.9 seconds.</p>\n<p>Re-Jitting is required after the driver is reinstalled. Also, if the JIT cache is too small, the JIT will be repeated on every run. You can set the jit cache size to 1GB by setting <code>export CUDA_CACHE_MAXSIZE=$((1024*1024*1024))</code>.</p>\n<p>I wouldn't expect it to make a significant improvement for a single 950M, but putting the driver into persistence mode with <code>nvidia-smi -pm 1</code> can also reduce CUDA initialization time.</p>", "body_text": "I have not been able to reproduce system hangs using the 387.12 driver on Ubuntu 16.04.\nThe slow initialization is indeed likely the driver JIT compiling PTX for your GPU's specific architecture.  On my system, this takes between 90 and 105 seconds and results in a cache size of ~116MB. During the jit, Ctrl-C waits for the jit to complete before exiting, but killing the jitting process from another terminal terminates the jit immediately.\nAfter the first run caches the tensorflow binaries, subsequent runs of the 'global_variable_initializer' test provided above runs in ~1.9 seconds.\nRe-Jitting is required after the driver is reinstalled. Also, if the JIT cache is too small, the JIT will be repeated on every run. You can set the jit cache size to 1GB by setting export CUDA_CACHE_MAXSIZE=$((1024*1024*1024)).\nI wouldn't expect it to make a significant improvement for a single 950M, but putting the driver into persistence mode with nvidia-smi -pm 1 can also reduce CUDA initialization time.", "body": "I have not been able to reproduce system hangs using the 387.12 driver on Ubuntu 16.04.\r\n\r\nThe slow initialization is indeed likely the driver JIT compiling PTX for your GPU's specific architecture.  On my system, this takes between 90 and 105 seconds and results in a cache size of ~116MB. During the jit, Ctrl-C waits for the jit to complete before exiting, but killing the jitting process from another terminal terminates the jit immediately.\r\n\r\nAfter the first run caches the tensorflow binaries, subsequent runs of the 'global_variable_initializer' test provided above runs in ~1.9 seconds.\r\n\r\nRe-Jitting is required after the driver is reinstalled. Also, if the JIT cache is too small, the JIT will be repeated on every run. You can set the jit cache size to 1GB by setting `export CUDA_CACHE_MAXSIZE=$((1024*1024*1024))`.\r\n\r\nI wouldn't expect it to make a significant improvement for a single 950M, but putting the driver into persistence mode with `nvidia-smi -pm 1` can also reduce CUDA initialization time."}