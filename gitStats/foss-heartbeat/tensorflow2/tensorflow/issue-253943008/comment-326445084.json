{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326445084", "html_url": "https://github.com/tensorflow/tensorflow/issues/12704#issuecomment-326445084", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12704", "id": 326445084, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjQ0NTA4NA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-31T23:15:45Z", "updated_at": "2017-08-31T23:15:45Z", "author_association": "MEMBER", "body_html": "<p>As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1381301\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ppwwyyxx\">@ppwwyyxx</a> mentioned you are creating a bigger and bigger graph each time.</p>\n<p>Try to create the graph once and use it multiple times, for example</p>\n<pre><code>def build():\n        image_placeholder = tf.placeholder([], tf.string)\n        image = tf.image.decode_jpeg(image_placeholder, channels=3)\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n        processed_images  = tf.expand_dims(processed_image, 0)\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\n        probabilities = tf.nn.softmax(logits)\n        return image_placeholder, probabilities\n\ndef predict(url, sess, image_placeholder):\n        image_string = urllib.urlopen(url).read()\n        np_probabilities = sess.run(probabilities, {image_placeholder: image_string})\n        return np_probabilities.tolist()\n\ngraph = tf.Graph()\nwith graph.as_default():\n  build()\n  init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\n  with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\n    init_fn(sess)\n\n  url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n  for _ in range(20):\n      predict(url)\n</code></pre>", "body_text": "As @ppwwyyxx mentioned you are creating a bigger and bigger graph each time.\nTry to create the graph once and use it multiple times, for example\ndef build():\n        image_placeholder = tf.placeholder([], tf.string)\n        image = tf.image.decode_jpeg(image_placeholder, channels=3)\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n        processed_images  = tf.expand_dims(processed_image, 0)\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\n        probabilities = tf.nn.softmax(logits)\n        return image_placeholder, probabilities\n\ndef predict(url, sess, image_placeholder):\n        image_string = urllib.urlopen(url).read()\n        np_probabilities = sess.run(probabilities, {image_placeholder: image_string})\n        return np_probabilities.tolist()\n\ngraph = tf.Graph()\nwith graph.as_default():\n  build()\n  init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\n  with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\n    init_fn(sess)\n\n  url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n  for _ in range(20):\n      predict(url)", "body": "As @ppwwyyxx mentioned you are creating a bigger and bigger graph each time.\r\n\r\nTry to create the graph once and use it multiple times, for example\r\n\r\n```\r\ndef build():\r\n        image_placeholder = tf.placeholder([], tf.string)\r\n        image = tf.image.decode_jpeg(image_placeholder, channels=3)\r\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\r\n        processed_images  = tf.expand_dims(processed_image, 0)\r\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\r\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\r\n        probabilities = tf.nn.softmax(logits)\r\n        return image_placeholder, probabilities\r\n\r\ndef predict(url, sess, image_placeholder):\r\n        image_string = urllib.urlopen(url).read()\r\n        np_probabilities = sess.run(probabilities, {image_placeholder: image_string})\r\n        return np_probabilities.tolist()\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n  build()\r\n  init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\r\n  with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\r\n    init_fn(sess)\r\n\r\n  url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\r\n  for _ in range(20):\r\n      predict(url)\r\n```"}