{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12704", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12704/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12704/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12704/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12704", "id": 253943008, "node_id": "MDU6SXNzdWUyNTM5NDMwMDg=", "number": 12704, "title": "Memory leak when reusing variables with slim", "user": {"login": "koelscha", "id": 20746434, "node_id": "MDQ6VXNlcjIwNzQ2NDM0", "avatar_url": "https://avatars0.githubusercontent.com/u/20746434?v=4", "gravatar_id": "", "url": "https://api.github.com/users/koelscha", "html_url": "https://github.com/koelscha", "followers_url": "https://api.github.com/users/koelscha/followers", "following_url": "https://api.github.com/users/koelscha/following{/other_user}", "gists_url": "https://api.github.com/users/koelscha/gists{/gist_id}", "starred_url": "https://api.github.com/users/koelscha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/koelscha/subscriptions", "organizations_url": "https://api.github.com/users/koelscha/orgs", "repos_url": "https://api.github.com/users/koelscha/repos", "events_url": "https://api.github.com/users/koelscha/events{/privacy}", "received_events_url": "https://api.github.com/users/koelscha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-08-30T09:58:10Z", "updated_at": "2018-02-04T05:05:53Z", "closed_at": "2018-02-04T05:05:53Z", "author_association": "NONE", "body_html": "<h3>System information:</h3>\n<ul>\n<li>Windows 7 x64</li>\n<li>Python 3.5.2 |Anaconda 4.2.0 (64-bit)</li>\n<li>Tensorflow 1.3.0 installed via pip</li>\n</ul>\n<h3>Problem</h3>\n<p>I want to use TF-Slim models to classify images in a server. For this, I would like to load the network only once and reuse the variables. I adjusted the tutorial given here: <a href=\"https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb\">https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb</a></p>\n<h3>Code to reproduce</h3>\n<pre><code>import tensorflow as tf\nfrom tensorflow.contrib import slim\n\nimport urllib.request as urllib\nfrom nets import inception\nfrom preprocessing import inception_preprocessing\n\n\nimage_size = inception.inception_v1.default_image_size\n\ninitialized = False\ngraph = tf.Graph()\n\ninit_fn = None\n\ndef predict():\n    global initialized\n    global init_fn\n    with graph.as_default():\n        url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n        image_string = urllib.urlopen(url).read()\n        image = tf.image.decode_jpeg(image_string, channels=3)\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n        processed_images  = tf.expand_dims(processed_image, 0)\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\n        probabilities = tf.nn.softmax(logits)\n        if not initialized:\n            init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\n        with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\n            init_fn(sess)\n            np_probabilities = sess.run(probabilities)\n        initialized = True\n    return np_probabilities.tolist()\n\nfor _ in range(20):\n    predict()\n</code></pre>\n<h3>Memory Usage monitored with Process Explorer</h3>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/20746434/29866915-33ed6506-8d7a-11e7-8dd4-1fc3e1b2f1d7.png\"><img src=\"https://user-images.githubusercontent.com/20746434/29866915-33ed6506-8d7a-11e7-8dd4-1fc3e1b2f1d7.png\" alt=\"memory\" style=\"max-width:100%;\"></a><br>\nThis is the memory usage when calling the predict function 20 times. As you can see, it keeps increasing.</p>\n<p>Am I doing it wrong, or is it a bug?</p>", "body_text": "System information:\n\nWindows 7 x64\nPython 3.5.2 |Anaconda 4.2.0 (64-bit)\nTensorflow 1.3.0 installed via pip\n\nProblem\nI want to use TF-Slim models to classify images in a server. For this, I would like to load the network only once and reuse the variables. I adjusted the tutorial given here: https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb\nCode to reproduce\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\n\nimport urllib.request as urllib\nfrom nets import inception\nfrom preprocessing import inception_preprocessing\n\n\nimage_size = inception.inception_v1.default_image_size\n\ninitialized = False\ngraph = tf.Graph()\n\ninit_fn = None\n\ndef predict():\n    global initialized\n    global init_fn\n    with graph.as_default():\n        url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n        image_string = urllib.urlopen(url).read()\n        image = tf.image.decode_jpeg(image_string, channels=3)\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n        processed_images  = tf.expand_dims(processed_image, 0)\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\n        probabilities = tf.nn.softmax(logits)\n        if not initialized:\n            init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\n        with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\n            init_fn(sess)\n            np_probabilities = sess.run(probabilities)\n        initialized = True\n    return np_probabilities.tolist()\n\nfor _ in range(20):\n    predict()\n\nMemory Usage monitored with Process Explorer\n\nThis is the memory usage when calling the predict function 20 times. As you can see, it keeps increasing.\nAm I doing it wrong, or is it a bug?", "body": "### System information:\r\n- Windows 7 x64\r\n- Python 3.5.2 |Anaconda 4.2.0 (64-bit)\r\n- Tensorflow 1.3.0 installed via pip\r\n\r\n\r\n### Problem\r\nI want to use TF-Slim models to classify images in a server. For this, I would like to load the network only once and reuse the variables. I adjusted the tutorial given here: https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb\r\n\r\n### Code to reproduce\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import slim\r\n\r\nimport urllib.request as urllib\r\nfrom nets import inception\r\nfrom preprocessing import inception_preprocessing\r\n\r\n\r\nimage_size = inception.inception_v1.default_image_size\r\n\r\ninitialized = False\r\ngraph = tf.Graph()\r\n\r\ninit_fn = None\r\n\r\ndef predict():\r\n    global initialized\r\n    global init_fn\r\n    with graph.as_default():\r\n        url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\r\n        image_string = urllib.urlopen(url).read()\r\n        image = tf.image.decode_jpeg(image_string, channels=3)\r\n        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\r\n        processed_images  = tf.expand_dims(processed_image, 0)\r\n        with slim.arg_scope(inception.inception_v1_arg_scope()):\r\n            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)\r\n        probabilities = tf.nn.softmax(logits)\r\n        if not initialized:\r\n            init_fn = slim.assign_from_checkpoint_fn(\"tmp/checkpoints/inception_v1.ckpt\", slim.get_model_variables(\"InceptionV1\"))\r\n        with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:\r\n            init_fn(sess)\r\n            np_probabilities = sess.run(probabilities)\r\n        initialized = True\r\n    return np_probabilities.tolist()\r\n\r\nfor _ in range(20):\r\n    predict()\r\n```\r\n\r\n\r\n### Memory Usage monitored with Process Explorer\r\n![memory](https://user-images.githubusercontent.com/20746434/29866915-33ed6506-8d7a-11e7-8dd4-1fc3e1b2f1d7.png)\r\nThis is the memory usage when calling the predict function 20 times. As you can see, it keeps increasing.\r\n\r\n\r\nAm I doing it wrong, or is it a bug?"}