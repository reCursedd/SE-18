{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3853", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3853/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3853/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3853/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3853", "id": 171486800, "node_id": "MDU6SXNzdWUxNzE0ODY4MDA=", "number": 3853, "title": "Options for sparse gradients?", "user": {"login": "codefever", "id": 1624981, "node_id": "MDQ6VXNlcjE2MjQ5ODE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1624981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codefever", "html_url": "https://github.com/codefever", "followers_url": "https://api.github.com/users/codefever/followers", "following_url": "https://api.github.com/users/codefever/following{/other_user}", "gists_url": "https://api.github.com/users/codefever/gists{/gist_id}", "starred_url": "https://api.github.com/users/codefever/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codefever/subscriptions", "organizations_url": "https://api.github.com/users/codefever/orgs", "repos_url": "https://api.github.com/users/codefever/repos", "events_url": "https://api.github.com/users/codefever/events{/privacy}", "received_events_url": "https://api.github.com/users/codefever/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-08-16T18:36:13Z", "updated_at": "2017-06-29T10:34:14Z", "closed_at": "2016-09-01T05:16:54Z", "author_association": "NONE", "body_html": "<p>Does <code>compute_gradients()</code> support outputs in sparse form? I'm working on a large-scale linear model with sparse inputs. It's quite inefficient to use gradients as dense <code>Tensor</code>, especially in distributed training.</p>\n<p>It seems that <code>apply_gradients()</code> of some optimisers supports gradient inputs as <code>IndexedSlices</code> type. But currently I've not found a clear way to convert gradients into this form.</p>\n<p>I've try sth like below to get X indices from mini-batch inputs, and then feed into IndexedSlices with gradient slices. But it doesn't seem to be good because <code>tf.unique</code> does not make <code>x_indices</code> sorted.</p>\n<pre><code>new_grads_and_vars = []\nx_indices, _ = tf.unique(tf.reshape(tf.slice(X.indices, [0, 1], [-1, 1]), shape=[-1]))  # &lt;- not sorted\nfor grad, var in grads_and_vars:\n   grad_vals = tf.gather(grad, indices=x_indices)\n   grad_slice = tf.IndexedSlices(indices=x_indices, values=grad_vals)\n   new_grads_and_vars.append((grad_slice, var))\ngrads_and_vars = new_grads_and_vars\n</code></pre>\n<p>Any ideas? Thx.</p>", "body_text": "Does compute_gradients() support outputs in sparse form? I'm working on a large-scale linear model with sparse inputs. It's quite inefficient to use gradients as dense Tensor, especially in distributed training.\nIt seems that apply_gradients() of some optimisers supports gradient inputs as IndexedSlices type. But currently I've not found a clear way to convert gradients into this form.\nI've try sth like below to get X indices from mini-batch inputs, and then feed into IndexedSlices with gradient slices. But it doesn't seem to be good because tf.unique does not make x_indices sorted.\nnew_grads_and_vars = []\nx_indices, _ = tf.unique(tf.reshape(tf.slice(X.indices, [0, 1], [-1, 1]), shape=[-1]))  # <- not sorted\nfor grad, var in grads_and_vars:\n   grad_vals = tf.gather(grad, indices=x_indices)\n   grad_slice = tf.IndexedSlices(indices=x_indices, values=grad_vals)\n   new_grads_and_vars.append((grad_slice, var))\ngrads_and_vars = new_grads_and_vars\n\nAny ideas? Thx.", "body": "Does `compute_gradients()` support outputs in sparse form? I'm working on a large-scale linear model with sparse inputs. It's quite inefficient to use gradients as dense `Tensor`, especially in distributed training.\n\nIt seems that `apply_gradients()` of some optimisers supports gradient inputs as `IndexedSlices` type. But currently I've not found a clear way to convert gradients into this form. \n\nI've try sth like below to get X indices from mini-batch inputs, and then feed into IndexedSlices with gradient slices. But it doesn't seem to be good because `tf.unique` does not make `x_indices` sorted.\n\n```\nnew_grads_and_vars = []\nx_indices, _ = tf.unique(tf.reshape(tf.slice(X.indices, [0, 1], [-1, 1]), shape=[-1]))  # <- not sorted\nfor grad, var in grads_and_vars:\n   grad_vals = tf.gather(grad, indices=x_indices)\n   grad_slice = tf.IndexedSlices(indices=x_indices, values=grad_vals)\n   new_grads_and_vars.append((grad_slice, var))\ngrads_and_vars = new_grads_and_vars\n```\n\nAny ideas? Thx.\n"}