{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111070225", "pull_request_review_id": 32280177, "id": 111070225, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMTA3MDIyNQ==", "diff_hunk": "@@ -561,76 +727,273 @@ static void FillInputs(const Node* n,\n   }\n }\n \n+void MklLayoutRewritePass::GetNodesProducingTFTensorList(\n+    const gtl::InlinedVector<std::pair<Node*, int>, 4>& inputs,\n+    int* input_idx, int list_length,\n+    std::vector<NodeBuilder::NodeOut>* output_nodes) {\n+  CHECK_LT(*input_idx, inputs.size());\n+  CHECK_GT(list_length, 0);\n+  CHECK_NOTNULL(output_nodes);\n+  output_nodes->reserve(list_length);\n+\n+  while (list_length != 0) {\n+    CHECK_GT(list_length, 0);\n+    CHECK_LE(*input_idx, inputs.size());\n+    Node* n = inputs[*input_idx].first;\n+    int slot = inputs[*input_idx].second;\n+    const OpDef::ArgDef& arg = n->op_def().output_arg(slot);\n+    // If input node 'n' is producing a list/array output at output\n+    // slot 'slot' then we need to find out the length of that list/array.\n+    if (ArgIsList(arg)) {\n+      int N = GetTensorListLength(arg, n);\n+      CHECK_LE(N, list_length);\n+      for (int j = 0; j < N; j++) {\n+        output_nodes->push_back(NodeBuilder::NodeOut(n, slot));\n+      }\n+      (*input_idx)++;\n+      list_length -= N;\n+    } else {\n+      // But if input node 'n' is just producing a single tensor at\n+      // output slot 'slot' then we just add that single node.\n+      output_nodes->push_back(NodeBuilder::NodeOut(n, slot));\n+      (*input_idx)++;\n+      list_length--;\n+    }\n+  }\n+}\n+\n // TODO(nhasabni) We should move this to mkl_util.h.\n-void MklLayoutRewritePass::GetDummyMklTensorNode(std::unique_ptr<Graph>* g,\n-                                                 Node** out, Node* orign) {\n+void MklLayoutRewritePass::GetDummyMklTensorNode(\n+    std::unique_ptr<Graph>* g, Node** out, Node* orig_node) {\n   // We use a tensor of shape {8} and value 0,0,0,0,0,0,0,0 to represent\n   // dummy Mkl tensor. 8 = 2*size_t.\n   const DataType dt = DataTypeToEnum<uint8>::v();\n   TensorProto proto;\n   proto.set_dtype(dt);\n   uint8 zero[8] = {0, 0, 0, 0, 0, 0, 0, 0};\n-  proto.set_tensor_content(const_cast<const void*>(static_cast<void*>(&zero)),\n-                           8);\n+  proto.set_tensor_content(const_cast<const void*>(\n+      static_cast<void*>(&zero)), 8);\n   TensorShape dummy_shape({8});\n   dummy_shape.AsProto(proto.mutable_tensor_shape());\n-  TF_CHECK_OK(\n-      NodeBuilder((*g)->NewName(\"DMT\"), \"Const\")\n-          .Attr(\"value\", proto)\n-          .Attr(\"dtype\", dt)\n-          .Device(orign->def().device())  // We place this node on same\n-                                          // device as device of original\n-                                          // node.\n-          .Finalize(&**g, out));\n-  (*out)->set_assigned_device_name(orign->assigned_device_name());\n+  TF_CHECK_OK(NodeBuilder((*g)->NewName(\"DMT\"), \"Const\")\n+                 .Attr(\"value\", proto)\n+                 .Attr(\"dtype\", dt)\n+                 .Device(orig_node->def().device())  // We place this node on\n+                                             // same device as device of\n+                                             // original node.\n+                 .Finalize(&**g, out));\n+  (*out)->set_assigned_device_name(orig_node->assigned_device_name());\n }\n \n-Status MklLayoutRewritePass::SetUpInputs(\n+void MklLayoutRewritePass::GetNodesProducingMklTensorList(\n     std::unique_ptr<Graph>* g,\n-    const gtl::InlinedVector<std::pair<Node*, int>, 4>& inputs, NodeBuilder* nb,\n-    Node* orign) {\n-  std::vector<NodeBuilder::NodeOut> new_inputs;\n-\n-  // 1. Let's setup inputs for the new node.\n-  for (int i = 0; i < inputs.size(); i++) {\n-    Node* n = inputs[i].first;\n-    // First let's copy original TF tensor input as it is.\n-    new_inputs.push_back(NodeBuilder::NodeOut(n, inputs[i].second));\n-\n-    // Second, let's add edge to propagate Mkl tensors from input Mkl layers,\n-    // or generate a dummy Mkl tensor representing not-mkl-tensor case.\n-    if (IsRewrittenNode(n)) {\n-      // If we have visited this node and rewritten it, then it will generate\n-      // an edge that will receive Mkl tensor from a node.\n-      // First, let's assert that this op is Mkl layer.\n-      DataType T;\n-      TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &T));\n-      // If this op has been rewritten, then its name must have been same as\n-      // Mkl op.\n-      CHECK_EQ(mkl_layer_registry::IsMklLayer(n->type_string(), T), true);\n-      // src slot number for Mkl tensor would be the one next to TF tensor\n-      // slot number.\n-      new_inputs.push_back(NodeBuilder::NodeOut(n, inputs[i].second + 1));\n+    const gtl::InlinedVector<std::pair<Node*, int>, 4>& inputs,\n+    int* input_idx, int list_length,\n+    std::vector<NodeBuilder::NodeOut>* output_nodes) {\n+  CHECK_LT(*input_idx, inputs.size());\n+  CHECK_GT(list_length, 0);\n+  CHECK_NOTNULL(output_nodes);\n+  output_nodes->reserve(list_length);\n+\n+  while (list_length != 0) {\n+    CHECK_GT(list_length, 0);\n+    CHECK_LE(*input_idx, inputs.size());\n+    Node* n = inputs[*input_idx].first;\n+    int slot = inputs[*input_idx].second;\n+    const OpDef::ArgDef& arg = n->op_def().output_arg(slot);\n+    // We need to check first if the input edge is going to carry a\n+    // single tensor or a list of tensors. If it is a list of tensors,\n+    // then we need to create list of Mkl dummy nodes.\n+    if (ArgIsList(arg)) {\n+      // If input node 'n' is producing a list/array output at output\n+      // slot 'slot' then we need to find out the length of that list/array.\n+      int N = GetTensorListLength(arg, n);\n+      CHECK_LE(N, list_length);\n+      Node* mkl_node = nullptr;\n+      int mkl_node_output_slot = 0;\n+      // If it is a list, then create a list of Mkl dummy nodes.\n+      for (int j = 0; j < N; j++) {\n+        GetNodeProducingMklTensor(g, n, slot, &mkl_node, &mkl_node_output_slot);\n+        output_nodes->push_back(NodeBuilder::NodeOut(mkl_node,\n+                                                    mkl_node_output_slot));\n+      }\n+      (*input_idx)++;\n+      list_length -= N;\n     } else {\n-      // If we have not visited the node and rewritten it, then we need\n-      // to create a dummy node that will feed a non-Mkl tensor to this node.\n-      // DummyMklTensor node has no input and generates only 1 output\n-      // (dummy Mkl tensor) as output slot number 0.\n-      Node* dmt = nullptr;\n-      GetDummyMklTensorNode(g, &dmt, orign);\n-      CHECK_NOTNULL(dmt);\n-      new_inputs.push_back(NodeBuilder::NodeOut(dmt, 0));\n+      // If it is not a list, then create a single Mkl tensor node.\n+      Node* mkl_node = nullptr;\n+      int mkl_node_output_slot = 0;\n+      GetNodeProducingMklTensor(g, n, slot, &mkl_node, &mkl_node_output_slot);\n+      output_nodes->push_back(NodeBuilder::NodeOut(mkl_node,\n+                                                  mkl_node_output_slot));\n+      (*input_idx)++;\n+      list_length--;\n     }\n   }\n+}\n+\n+// Get an input node that will feed Mkl tensor to the new\n+// node that we are constructing. An input node could be (1) 'n'\n+// if it is Mkl layer, or (2) a dummy node producing dummy Mkl tensor\n+// if 'n' is not an Mkl layer.\n+void MklLayoutRewritePass::GetNodeProducingMklTensor(std::unique_ptr<Graph>* g,\n+    Node* n,\n+    int n_output_slot, Node** mkl_node, int* mkl_node_output_slot) {\n+  CHECK_NOTNULL(n);\n+  CHECK_NOTNULL(mkl_node);\n+  CHECK_NOTNULL(mkl_node_output_slot);\n+  if (IsRewrittenNode(n)) {\n+    // If we have visited this node and rewritten it, then it will generate\n+    // an edge that will receive Mkl tensor from a node.\n+    // First, let's assert that this op is Mkl layer.\n+    DataType T;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &T));\n+    // If this op has been rewritten, then its name must have been same as\n+    // Mkl op.\n+    CHECK_EQ(mkl_op_registry::IsMklOp(n->type_string(), T), true);\n+    // output slot number for Mkl tensor would be N+slot number of TensorFlow\n+    // tensor, where N is total number of TensorFlow tensors.\n+    *mkl_node = n;\n+    *mkl_node_output_slot = GetTensorMetaDataIndex(n_output_slot,\n+                                                  n->num_outputs());\n+  } else {\n+    // If we have not visited the node and rewritten it, then we need\n+    // to create a dummy node that will feed a dummy Mkl tensor to this node.\n+    // DummyMklTensor node has no input and generates only 1 output\n+    // (dummy Mkl tensor) as output slot number 0.\n+    GetDummyMklTensorNode(g, mkl_node, n);\n+    CHECK_NOTNULL(*mkl_node);\n+    *mkl_node_output_slot = 0;\n+  }\n+}\n \n-  // The total number of inputs to new node _must_ be 2 times the number\n-  // of inputs to the original node: N original Tensorflow tensors and\n-  // N for Mkl tensors corresponding to each Tensorflow tensors.\n-  CHECK_EQ(new_inputs.size(), inputs.size() * 2);\n+int MklLayoutRewritePass::SetUpContiguousInputs(std::unique_ptr<Graph>* g,\n+    const gtl::InlinedVector<std::pair<Node*, int>, 4>& old_node_inputs,\n+    NodeBuilder* nb, Node* old_node,\n+    std::vector<NodeBuilder::NodeOut>* workspace_tensors,\n+    bool are_workspace_tensors_available) {\n+  CHECK_NOTNULL(workspace_tensors);\n+  CHECK_EQ(kTensorOrdering, MklTfTensorOrdering::TENSORS_CONTIGUOUS);\n+\n+  // Number of input slots to original op\n+  // Input slots are represented by .Input() calls in REGISTER_OP.\n+  int old_node_input_slots = old_node->op_def().input_arg_size();\n+  // Actual number of inputs can be greater than or equal to number\n+  // of Input slots because inputs of type list could be unfolded.\n+  CHECK_GE(old_node_inputs.size(), old_node_input_slots);\n+  int nnsidx = 0;  // slot index for inputs of new node\n+\n+  // Let's copy all inputs (TF tensors) of original node to new node.\n+  int iidx = 0;", "path": "tensorflow/core/graph/mkl_layout_pass.cc", "position": null, "original_position": 819, "commit_id": "b5ef5bfcb39a0ba0cef4e1f7e9d766344f918ab2", "original_commit_id": "67f9925ef9ceed02892c200a3122092ab497943a", "user": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "body": "what does the first i mean here? iidx->i_idx?", "created_at": "2017-04-12T06:03:07Z", "updated_at": "2017-04-13T23:37:54Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r111070225", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111070225"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r111070225"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968"}}, "body_html": "<p>what does the first i mean here? iidx-&gt;i_idx?</p>", "body_text": "what does the first i mean here? iidx->i_idx?"}