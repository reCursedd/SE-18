{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111261027", "pull_request_review_id": 32494753, "id": 111261027, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMTI2MTAyNw==", "diff_hunk": "@@ -0,0 +1,688 @@\n+/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#ifdef INTEL_MKL\n+\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/register_types.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n+#include \"tensorflow/core/util/mkl_util.h\"\n+#include \"third_party/mkl/include/mkl_dnn.h\"\n+#include \"third_party/mkl/include/mkl_dnn_types.h\"\n+\n+namespace tensorflow {\n+using CPUDevice = Eigen::ThreadPoolDevice;\n+template <typename Device, typename T>\n+class MklFusedBatchNormOp : public OpKernel {\n+ public:\n+  explicit MklFusedBatchNormOp(OpKernelConstruction* context)\n+      : OpKernel(context) {\n+    float epsilon;\n+    OP_REQUIRES_OK(context, context->GetAttr(\"epsilon\", &epsilon));\n+    epsilon_ = T(epsilon);\n+    string tensor_format;\n+    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &tensor_format));\n+    OP_REQUIRES(context, FormatFromString(tensor_format, &tensor_format_),\n+                errors::InvalidArgument(\"Invalid data format\"));\n+    OP_REQUIRES_OK(context, context->GetAttr(\"is_training\", &is_training_));\n+  }\n+\n+  void Compute(OpKernelContext* context) override {\n+    MklFusedBatchNormOpContext mkl_context;\n+\n+    const Tensor& input = MklGetInput(context, 0);\n+    const Tensor& scale = MklGetInput(context, 1);\n+    const Tensor& shift = MklGetInput(context, 2);\n+    const Tensor& est_mean = MklGetInput(context, 3);\n+    const Tensor& est_variance = MklGetInput(context, 4);\n+\n+    GetMklShape(context, 0, &(mkl_context.mkl_shape_input_shape));\n+    bool input_in_mkl_format = mkl_context.mkl_shape_input_shape.IsMklTensor();\n+    if (!input_in_mkl_format) {\n+      OP_REQUIRES(context, input.dims() == 4,\n+                  errors::InvalidArgument(\"input must be 4-dimensional\",\n+                                          input.shape().DebugString()));\n+    }\n+    OP_REQUIRES(context, scale.dims() == 1,\n+                errors::InvalidArgument(\"scale must be 1-dimensional\",\n+                                        scale.shape().DebugString()));\n+    OP_REQUIRES(context, shift.dims() == 1,\n+                errors::InvalidArgument(\"offset must be 1-dimensional\",\n+                                        shift.shape().DebugString()));\n+    OP_REQUIRES(context, est_mean.dims() == 1,\n+                errors::InvalidArgument(\"estimated_mean must be 1-dimensional\",\n+                                        est_mean.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, est_variance.dims() == 1,\n+        errors::InvalidArgument(\"estimated_variance must be 1-dimensional\",\n+                                est_variance.shape().DebugString()));\n+    if (is_training_) {\n+      OP_REQUIRES(context, est_mean.dim_size(0) == 0,\n+                  errors::InvalidArgument(\"estimated_mean empty for training\",\n+                                          est_mean.shape().DebugString()));\n+      OP_REQUIRES(context, est_variance.dim_size(0) == 0,\n+                  errors::InvalidArgument(\n+                      \"estimated_variance must be empty for training\",\n+                      est_variance.shape().DebugString()));\n+    }\n+\n+    unsigned int flag_batch_norm =\n+        is_training_ ? dnnUseScaleShift\n+                     : (dnnUseInputMeanVariance | dnnUseScaleShift);\n+\n+    mkl_context.MklExtractParams(context, tensor_format_);\n+\n+    // Create layout only for input data as it is used in Op primitive.\n+    mkl_context.MklCreateInputLayout(context);\n+\n+    // Create Op primitive.\n+    CHECK_EQ(dnnBatchNormalizationCreateForward_v2_F32(\n+                 &(mkl_context.mkl_prim_batchnorm), nullptr,\n+                 mkl_context.mkl_lt_input, static_cast<float>(epsilon_),\n+                 flag_batch_norm),\n+             E_SUCCESS);\n+\n+    // Temporary tensors with buffers for the context inputs, if\n+    // conversion to MKL-Op specific layouts are required. It is assumed here\n+    // that TF's 1D tensors (scale, shift, est_mean, and est_variance) won't\n+    // require any conversion.\n+    // Since scale-shift is combined in MKL, a buffer is required.\n+    Tensor mkl_tmp_input_buf_tensor, mkl_tmp_scale_shift_buf_tensor;\n+    mkl_context.MklPrepareContextInputs(context, &mkl_tmp_input_buf_tensor,\n+                                        &mkl_tmp_scale_shift_buf_tensor);\n+\n+    // Output data in MKL layout\n+    Tensor* output = nullptr;\n+    TensorShape tf_shape_output;\n+    MklShape mkl_shape_output;\n+    mkl_shape_output.SetMklTensor(true);\n+    mkl_shape_output.SetMklLayout(mkl_context.mkl_prim_batchnorm,\n+                                  dnnResourceDst);\n+    mkl_shape_output.SetTfLayout(mkl_context.mkl_params.in_dim,\n+                                 mkl_context.mkl_params.in_sizes,\n+                                 mkl_context.mkl_params.in_strides);\n+    mkl_shape_output.SetTfDimOrder(mkl_context.mkl_params.in_dim,\n+                                   tensor_format_);\n+    tf_shape_output.AddDim(dnnLayoutGetMemorySize_F32(static_cast<dnnLayout_t>(\n+                               mkl_shape_output.GetMklLayout())) /\n+                           sizeof(T));\n+    AllocateOutputSetMklShape(context, 0, &output, tf_shape_output,\n+                              mkl_shape_output);\n+    mkl_context.mkl_res_batchnorm[dnnResourceDst] =\n+        static_cast<void*>(output->flat<T>().data());\n+\n+    // Batch mean in TF layout\n+    Tensor* batch_mean = nullptr;\n+    MklShape mkl_shape_batch_mean;\n+    mkl_shape_batch_mean.SetMklTensor(false);\n+    AllocateOutputSetMklShape(context, 1, &batch_mean, scale.shape(),\n+                              mkl_shape_batch_mean);\n+    // Batch variance in TF layout\n+    Tensor* batch_variance = nullptr;\n+    MklShape mkl_shape_batch_variance;\n+    mkl_shape_batch_variance.SetMklTensor(false);\n+    AllocateOutputSetMklShape(context, 2, &batch_variance, scale.shape(),\n+                              mkl_shape_batch_variance);\n+    // If training mode, set dnnResourceMean and dnnResourceVariance to\n+    // output tensors for batch mean and variance.\n+    // Otherwise, set dnnResourceMean and dnnResourceVariance to\n+    // estimated mean and variance.\n+    if (is_training_)\n+      mkl_context.MklSetMeanVariance(*batch_mean, *batch_variance);\n+    else\n+      mkl_context.MklSetMeanVariance(est_mean, est_variance);\n+\n+    // Now that all resources are set, it is ready for dnnExecute\n+    CHECK_EQ(dnnExecute_F32(mkl_context.mkl_prim_batchnorm,\n+                            mkl_context.mkl_res_batchnorm),\n+             E_SUCCESS);\n+\n+    // Mean and variance (without Bessel's correction) saved for backward\n+    // computation to serve as pre-computed mean and variance.\n+    Tensor* saved_mean = nullptr;\n+    MklShape mkl_shape_saved_mean;\n+    mkl_shape_saved_mean.SetMklTensor(false);\n+    AllocateOutputSetMklShape(context, 3, &saved_mean, scale.shape(),\n+                              mkl_shape_saved_mean);\n+    std::memcpy(\n+        reinterpret_cast<char*>(saved_mean->flat<float>().data()),\n+        reinterpret_cast<char*>(mkl_context.mkl_res_batchnorm[dnnResourceMean]),\n+        scale.NumElements() * sizeof(float));\n+    Tensor* saved_variance = nullptr;\n+    MklShape mkl_shape_saved_variance;\n+    mkl_shape_saved_variance.SetMklTensor(false);\n+    AllocateOutputSetMklShape(context, 4, &saved_variance, scale.shape(),\n+                              mkl_shape_saved_variance);\n+    std::memcpy(reinterpret_cast<char*>(saved_variance->flat<float>().data()),\n+                reinterpret_cast<char*>(\n+                    mkl_context.mkl_res_batchnorm[dnnResourceVariance]),\n+                scale.NumElements() * sizeof(float));\n+\n+    // Bessel's correction on variance, if training mode in on\n+    if (is_training_) {\n+      float* p_var = static_cast<float*>(batch_variance->flat<T>().data());\n+      auto depth = mkl_context.mkl_params.depth;\n+      size_t orig_size = mkl_context.mkl_params.in_sizes[0] *\n+                         mkl_context.mkl_params.in_sizes[1] *\n+                         mkl_context.mkl_params.in_sizes[3];\n+      size_t adjust_size = orig_size - 1;\n+      float adjust_factor = (static_cast<float>(orig_size)) / adjust_size;\n+      for (int i = 0; i < depth; i++) p_var[i] = adjust_factor * p_var[i];\n+    }\n+\n+    mkl_context.MklCleanup();\n+  }\n+\n+ private:\n+  T epsilon_;\n+  TensorFormat tensor_format_;\n+  bool is_training_;\n+\n+  // Structure containing all info for MklOp\n+  typedef struct {\n+    // Parameters used for input and output layouts\n+    struct MklBatchNormParams {\n+      // BatchNormOp src and\n+      size_t in_dim;\n+      size_t in_sizes[4];\n+      size_t in_strides[4];\n+      size_t depth;  // Batch normalization is done for per channel.\n+    } mkl_params;\n+\n+    MklShape mkl_shape_input_shape;\n+\n+    // MKL primitive and resources for BatchNormOp\n+    dnnPrimitive_t mkl_prim_batchnorm = nullptr;\n+    void* mkl_res_batchnorm[dnnResourceNumber];\n+\n+    // MKL layouts for inputs in the context\n+    dnnLayout_t mkl_lt_input = nullptr;\n+\n+    void MklCleanup() {\n+      bool input_in_mkl_format = mkl_shape_input_shape.IsMklTensor();\n+      if (!input_in_mkl_format) dnnLayoutDelete_F32(mkl_lt_input);\n+", "path": "tensorflow/core/kernels/mkl_fused_batch_norm_op.cc", "position": null, "original_position": 219, "commit_id": "b5ef5bfcb39a0ba0cef4e1f7e9d766344f918ab2", "original_commit_id": "67f9925ef9ceed02892c200a3122092ab497943a", "user": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "body": "Delete empty line?", "created_at": "2017-04-12T21:09:26Z", "updated_at": "2017-04-13T23:37:54Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r111261027", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/111261027"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r111261027"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968"}}, "body_html": "<p>Delete empty line?</p>", "body_text": "Delete empty line?"}