{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/110079409", "pull_request_review_id": 31222233, "id": 110079409, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMDA3OTQwOQ==", "diff_hunk": "@@ -267,29 +297,150 @@ class MklShape {\n   size_t dimension_ = 0;\n   size_t* sizes_ = nullptr;    // Required by MKL for conversions\n   size_t* strides_ = nullptr;  // Required by MKL for conversions\n-  // TF dimension corresponding to this MKL dimension\n-  size_t* tf_to_mkl_dim_map_ = nullptr;\n+  size_t* tf_to_mkl_dim_map_ =\n+      nullptr;  // TF dimension corresponding to this MKL dimension\n };\n \n-int inline GetTensorDataIndex(int n) {\n-  return 2 * n;  // index corresponding to nth input/output tensor\n+// List of MklShape objects. Used in Concat/Split layers.\n+typedef std::vector<MklShape> MklShapeList;\n+\n+// Check if all tensors specified by MklShapes are MKL tensors.\n+inline bool AreAllMklTensors(const MklShapeList& shapes) {\n+  for (auto& s : shapes) {\n+    if (!s.IsMklTensor()) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+template <typename T>\n+inline Tensor ConvertMklToTF(OpKernelContext *context,\n+                             const Tensor& mkl_tensor,\n+                             const MklShape& mkl_shape) {\n+  Tensor output_tensor;\n+  TensorShape output_shape;\n+\n+  for (size_t j = 0; j < mkl_shape.GetDimension(); j++) {\n+     // Outermost to innermost dimension\n+     output_shape.AddDim(mkl_shape.GetSizes()[mkl_shape.tf_dim_idx(j)]);\n+  }\n+\n+  // Allocate output tensor.\n+  context->allocate_temp(DataTypeToEnum<T>::v(),\n+                       output_shape, &output_tensor);\n+\n+  dnnLayout_t output_layout = static_cast<dnnLayout_t>(\n+                                mkl_shape.GetTfLayout());\n+  void *input_buffer = const_cast<T*>(mkl_tensor.flat<T>().data());\n+  void *output_buffer = const_cast<T*>(output_tensor.flat<T>().data());\n+\n+  if (mkl_tensor.NumElements() != 0) {\n+    mkl_shape.GetConvertedFlatData(output_layout, input_buffer, output_buffer);\n+  }\n+\n+  return output_tensor;\n }\n \n-int inline GetTensorMetaDataIndex(int n) {\n-  // index corresponding to meta data of nth input/output tensor\n-  return 2 * n + 1;\n+// Since our ops are going to produce and also consume N addition tensors\n+// (Mkl) for N Tensorflow tensors, we can have following different\n+// orderings among these 2N tensors.\n+//\n+// E.g., for Tensorflow tensors A, B, and C, our ops will produce and\n+// consume A_m, B_m, and C_m additionally.\n+//\n+// INTERLEAVED: in this case 2N tensors are interleaved. So for above\n+//              example, the ordering looks like: A, A_m, B, B_m, C, C_m.\n+//\n+// CONTIGUOUS: in thi case N Tensorflow tensors are contiguous followed\n+//             by N Mkl tensors. So for above example, the ordering looks\n+//             like: A, B, C, A_m, B_m, C_m\n+//\n+// Following APIs map index of original Tensorflow tensors to their appropriate\n+// position based on selected ordering. For contiguous ordering, we need to know\n+// the total number of tensors (parameter total).\n+//\n+typedef enum { TENSORS_INTERLEAVED, TENSORS_CONTIGUOUS } MklTfTensorOrdering;\n+// NOTE: Currently, we use contiguous ordering. If you change this, then you\n+// would need to change Mkl op definitions in nn_ops.cc.\n+static MklTfTensorOrdering kTensorOrdering = TENSORS_CONTIGUOUS;\n+\n+// Get index of MetaData tensor from index 'n' of Data tensor.\n+inline int DataIndexToMetaDataIndex(int n, int total_tensors) {\n+  if (kTensorOrdering == MklTfTensorOrdering::TENSORS_INTERLEAVED) {\n+    // For interleaved ordering, Mkl tensor follows immediately after\n+    // Tensorflow tensor.\n+    return n + 1;\n+  } else {\n+    CHECK_EQ(kTensorOrdering, MklTfTensorOrdering::TENSORS_CONTIGUOUS);\n+    // For contiguous ordering, Mkl tensor is n+total_tensors/2 away.\n+    return n + total_tensors/2;\n+  }\n }\n+\n+int inline GetTensorDataIndex(int n, int total_tensors) {\n+  if (kTensorOrdering == MklTfTensorOrdering::TENSORS_INTERLEAVED) {\n+    return 2 * n;  // index corresponding to nth input/output tensor\n+  } else {\n+    CHECK_EQ(kTensorOrdering, MklTfTensorOrdering::TENSORS_CONTIGUOUS);\n+    return n;\n+  }\n+}\n+\n+int inline GetTensorMetaDataIndex(int n, int total_tensors) {\n+  // Get index for TensorData first and then use mapping function\n+  // to get TensorMetaData index from TensorData index.\n+  int tidx = GetTensorDataIndex(n, total_tensors);\n+  return DataIndexToMetaDataIndex(tidx, total_tensors);\n+}\n+\n+\n // Get the MKL shape from the second string tensor\n inline void GetMklShape(OpKernelContext* ctext, int n, MklShape* mklshape) {\n   mklshape->DeSerializeMklShape(\n-      ctext->input(GetTensorMetaDataIndex(n)).flat<uint8>().data(),\n-      ctext->input(GetTensorMetaDataIndex(n)).flat<uint8>().size() *\n+      ctext->input(\n+        GetTensorMetaDataIndex(n, ctext->num_inputs())).flat<uint8>().data(),\n+      ctext->input(\n+        GetTensorMetaDataIndex(n, ctext->num_inputs())).flat<uint8>().size() *\n           sizeof(uint8));\n }\n \n // Gets the actual input", "path": "tensorflow/core/util/mkl_util.h", "position": 190, "original_position": 201, "commit_id": "b5ef5bfcb39a0ba0cef4e1f7e9d766344f918ab2", "original_commit_id": "562d1842de0a50cccfb44597c00c1a30e9483c35", "user": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "body": "\"Get\"", "created_at": "2017-04-06T05:00:49Z", "updated_at": "2017-04-13T23:37:54Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r110079409", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/110079409"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8968#discussion_r110079409"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8968"}}, "body_html": "<p>\"Get\"</p>", "body_text": "\"Get\""}