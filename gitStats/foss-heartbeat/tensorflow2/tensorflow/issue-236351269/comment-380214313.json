{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/380214313", "html_url": "https://github.com/tensorflow/tensorflow/issues/10749#issuecomment-380214313", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10749", "id": 380214313, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDIxNDMxMw==", "user": {"login": "rryan", "id": 26527, "node_id": "MDQ6VXNlcjI2NTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/26527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rryan", "html_url": "https://github.com/rryan", "followers_url": "https://api.github.com/users/rryan/followers", "following_url": "https://api.github.com/users/rryan/following{/other_user}", "gists_url": "https://api.github.com/users/rryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/rryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rryan/subscriptions", "organizations_url": "https://api.github.com/users/rryan/orgs", "repos_url": "https://api.github.com/users/rryan/repos", "events_url": "https://api.github.com/users/rryan/events{/privacy}", "received_events_url": "https://api.github.com/users/rryan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-10T19:09:22Z", "updated_at": "2018-04-10T19:09:54Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2855550\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Rassibassi\">@Rassibassi</a>, I'm working on adding complex128 support to the FFT ops, and I ran your code snippet on CPU with the new complex128 support. It looks like a good bit of the difference comes down to floating point precision, but there is still a difference in magnitude of error between our Eigen CPU kernels and NumPy's FFTPACK-based implementation:</p>\n<pre><code>('tf', '1.7.0-rc1')\n('scipy', '1.0.0')\n('numpy', '1.13.3')\n\nTF complex64 error:\nrelError():\n5.69994795505e-08\n2.28822314134e-05\n0.00236386710254\nerror():\n2.67673230982e-08\n1.07452364853e-05\n0.00111161453476\n\nTF complex128 error:\nrelError():\n2.03202621417e-25\n8.12885273597e-23\n8.1293612227e-21\nerror():\n8.45195242854e-26\n3.3806405275e-23\n3.38062769196e-21\n\nNP error:\nrelError():\n1.46110214039e-30\n2.56749381389e-28\n2.15249955484e-26\nerror():\n1.46110214039e-30\n2.56749381389e-28\n2.15249955484e-26\n\nTF complex64 error:\nrelError():\n2.80140031472e-06\n0.00114172830632\n0.137244893593\nerror():\n6.57350034283e-07\n0.000267167590172\n0.0312076844667\n\nTF complex128 error:\nrelError():\n5.34248829151e-24\n2.136542245e-21\n2.1367747769e-19\nerror():\n7.49076129451e-25\n2.9962948344e-22\n2.99628924207e-20\n\nNP error:\nrelError():\n1.32333991018e-29\n4.18679573526e-27\n3.71090920591e-25\nerror():\n1.32333991018e-29\n4.18679573526e-27\n3.71090920591e-25\n</code></pre>", "body_text": "@Rassibassi, I'm working on adding complex128 support to the FFT ops, and I ran your code snippet on CPU with the new complex128 support. It looks like a good bit of the difference comes down to floating point precision, but there is still a difference in magnitude of error between our Eigen CPU kernels and NumPy's FFTPACK-based implementation:\n('tf', '1.7.0-rc1')\n('scipy', '1.0.0')\n('numpy', '1.13.3')\n\nTF complex64 error:\nrelError():\n5.69994795505e-08\n2.28822314134e-05\n0.00236386710254\nerror():\n2.67673230982e-08\n1.07452364853e-05\n0.00111161453476\n\nTF complex128 error:\nrelError():\n2.03202621417e-25\n8.12885273597e-23\n8.1293612227e-21\nerror():\n8.45195242854e-26\n3.3806405275e-23\n3.38062769196e-21\n\nNP error:\nrelError():\n1.46110214039e-30\n2.56749381389e-28\n2.15249955484e-26\nerror():\n1.46110214039e-30\n2.56749381389e-28\n2.15249955484e-26\n\nTF complex64 error:\nrelError():\n2.80140031472e-06\n0.00114172830632\n0.137244893593\nerror():\n6.57350034283e-07\n0.000267167590172\n0.0312076844667\n\nTF complex128 error:\nrelError():\n5.34248829151e-24\n2.136542245e-21\n2.1367747769e-19\nerror():\n7.49076129451e-25\n2.9962948344e-22\n2.99628924207e-20\n\nNP error:\nrelError():\n1.32333991018e-29\n4.18679573526e-27\n3.71090920591e-25\nerror():\n1.32333991018e-29\n4.18679573526e-27\n3.71090920591e-25", "body": "@Rassibassi, I'm working on adding complex128 support to the FFT ops, and I ran your code snippet on CPU with the new complex128 support. It looks like a good bit of the difference comes down to floating point precision, but there is still a difference in magnitude of error between our Eigen CPU kernels and NumPy's FFTPACK-based implementation:\r\n\r\n```\r\n('tf', '1.7.0-rc1')\r\n('scipy', '1.0.0')\r\n('numpy', '1.13.3')\r\n\r\nTF complex64 error:\r\nrelError():\r\n5.69994795505e-08\r\n2.28822314134e-05\r\n0.00236386710254\r\nerror():\r\n2.67673230982e-08\r\n1.07452364853e-05\r\n0.00111161453476\r\n\r\nTF complex128 error:\r\nrelError():\r\n2.03202621417e-25\r\n8.12885273597e-23\r\n8.1293612227e-21\r\nerror():\r\n8.45195242854e-26\r\n3.3806405275e-23\r\n3.38062769196e-21\r\n\r\nNP error:\r\nrelError():\r\n1.46110214039e-30\r\n2.56749381389e-28\r\n2.15249955484e-26\r\nerror():\r\n1.46110214039e-30\r\n2.56749381389e-28\r\n2.15249955484e-26\r\n\r\nTF complex64 error:\r\nrelError():\r\n2.80140031472e-06\r\n0.00114172830632\r\n0.137244893593\r\nerror():\r\n6.57350034283e-07\r\n0.000267167590172\r\n0.0312076844667\r\n\r\nTF complex128 error:\r\nrelError():\r\n5.34248829151e-24\r\n2.136542245e-21\r\n2.1367747769e-19\r\nerror():\r\n7.49076129451e-25\r\n2.9962948344e-22\r\n2.99628924207e-20\r\n\r\nNP error:\r\nrelError():\r\n1.32333991018e-29\r\n4.18679573526e-27\r\n3.71090920591e-25\r\nerror():\r\n1.32333991018e-29\r\n4.18679573526e-27\r\n3.71090920591e-25\r\n```"}