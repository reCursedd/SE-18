{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17325", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17325/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17325/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17325/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17325", "id": 301034366, "node_id": "MDU6SXNzdWUzMDEwMzQzNjY=", "number": 17325, "title": "Resource exhausted: OOM when allocating tensor with shape, even when batch_size is 1.", "user": {"login": "AbhinavG7", "id": 36918209, "node_id": "MDQ6VXNlcjM2OTE4MjA5", "avatar_url": "https://avatars3.githubusercontent.com/u/36918209?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AbhinavG7", "html_url": "https://github.com/AbhinavG7", "followers_url": "https://api.github.com/users/AbhinavG7/followers", "following_url": "https://api.github.com/users/AbhinavG7/following{/other_user}", "gists_url": "https://api.github.com/users/AbhinavG7/gists{/gist_id}", "starred_url": "https://api.github.com/users/AbhinavG7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AbhinavG7/subscriptions", "organizations_url": "https://api.github.com/users/AbhinavG7/orgs", "repos_url": "https://api.github.com/users/AbhinavG7/repos", "events_url": "https://api.github.com/users/AbhinavG7/events{/privacy}", "received_events_url": "https://api.github.com/users/AbhinavG7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-02-28T14:00:59Z", "updated_at": "2018-02-28T15:02:50Z", "closed_at": "2018-02-28T15:02:50Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nI've registered a new problem for translating English to Swedish, the code is pretty similar to TranslateEndeWmtBpe32k, with Europarl data. I'm able to train with hidden_size: 128, anything over 128 and I get Resource exhausted error, even when batch size is 1. (I'm using hparams: transformer_big).</li>\n</ul>\n<p>I notice that previous posts on this issue were solved by reducing the batch size. I'm posting this because reducing batch size wasn't helpful and I'm hoping if someone encountered a similar issue.</p>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n</ul>\n<p>Linux deepnlp01 4.2.0-42-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115994238\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/49\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/49/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/49\">#49</a>~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux<br>\n4 VERSION=\"14.04.5 LTS, Trusty Tahr\"</p>\n<ul>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\ntf.VERSION = 1.4.1 (Installed from source)</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\n2.7.6</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:<br>\nBuild label: 0.5.2</p>\n</li>\n<li>\n<p><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nnvcc: NVIDIA (R) Cuda compiler driver<br>\nCuda compilation tools, release 8.0, V8.0.61</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nNVIDIA TITAN X (12GB)</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nUSR_DIR=/python2.7/site-packages/tensor2tensor/&lt;new_module&gt;</p>\n</li>\n</ul>\n<p>t2t-trainer <br>\n--data_dir=$DATA_DIR <br>\n--problems=$PROBLEM <br>\n--model=$MODEL <br>\n--hparams_set=$HPARAMS <br>\n--output_dir=$TRAIN_DIR <br>\n--t2t_usr_dir=$USR_DIR</p>\n<h3>Describe the problem</h3>\n<p>The data I'm using is parallel corpus English-Swedish, available on <a href=\"http://www.statmt.org/europarl/\" rel=\"nofollow\">http://www.statmt.org/europarl/</a> . I've created a dictionary myself of about 1,400,000 (1.4 million) words. [The problem persists even if I use a smaller vocab of about 10k words]</p>\n<p>I'm able to train with batch_size=1024 and hidden_size=128, if I increase the hidden size to 256, even with batch_size=1, it runs out of memory. I get the following error.</p>\n<h3>Source code / logs</h3>\n<p>This is the error I'm encountering:</p>\n<pre><code>2018-02-28 05:48:52.977027: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[90993,256]\n\nTraceback (most recent call last):\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in &lt;module&gt;\n    tf.app.run()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\n    t2t_trainer.main(argv)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\n    execute_schedule(exp)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\n    getattr(exp, FLAGS.schedule)()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\n    return func(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\n    hooks=self._train_monitors)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\n    hooks=hooks)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\n    raise six.reraise(*original_exc_info)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[90992,256]\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'training/gradients/AddN_96', defined at:\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in &lt;module&gt;\n    tf.app.run()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\n    t2t_trainer.main(argv)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\n    execute_schedule(exp)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\n    getattr(exp, FLAGS.schedule)()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\n    return func(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\n    hooks=self._train_monitors)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\n    hooks=hooks)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 711, in _train_model\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 694, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 829, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 923, in estimator_model_fn\n    loss, num_async_replicas=num_async_replicas)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 927, in estimator_spec_train\n    train_op = self.optimize(loss, num_async_replicas=num_async_replicas)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 351, in optimize\n    loss, lr, self.hparams, use_tpu=common_layers.is_on_tpu())\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 67, in optimize\n    colocate_gradients_with_ops=True)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 241, in optimize_loss\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 109, in compute_gradients\n    return self._opt.compute_gradients(loss, var_list, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 533, in gradients\n    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 872, in _AggregatedGrads\n    out_grads[i] = _MultiDeviceAddN(out_grad)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 767, in _MultiDeviceAddN\n    summands.append(math_ops.add_n(tensors))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2000, in add_n\n    return gen_math_ops._add_n(inputs, name=name)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 220, in _add_n\n    \"AddN\", inputs=inputs, name=name)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[90992,256]\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n</code></pre>\n<p>This is the code that I've modified:</p>\n<pre><code>def _get_europarl_ensv_dataset(directory, filename):\n    \"\"\"Extract the EuroParl en-sv corpus `filename` to directory unless it's there.\"\"\"\n\n    train_path = os.path.join(directory, filename)\n\n    return train_path\n\n\n@registry.register_problem\nclass TranslateEnsvEuroparl(translate.TranslateProblem):\n    \"\"\"Problem spec for EuroParl En-Sv translation, BPE version.\"\"\"\n\n    @property\n    def approx_vocab_size(self):\n        return 1455877\n\n    @property\n    def vocab_filename(self):\n        return \"vocab.europarl.ensv.txt\"\n\n    def get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):\n        vocab_filename = os.path.join(data_dir, self.vocab_filename)\n        if not tf.gfile.Exists(vocab_filename) and force_get:\n            raise ValueError(\"Vocab %s not found\" % vocab_filename)\n        return text_encoder.TokenTextEncoder(vocab_filename, replace_oov=\"UNK\")\n\n    def generate_samples(self, data_dir, tmp_dir, dataset_split):\n        \"\"\"Instance of token generator for the WMT en-&gt;de task, training set.\"\"\"\n        train = dataset_split == problem.DatasetSplit.TRAIN\n        dataset_path = (\"europarl-v7.train.sv-en\"\n                        if train else \"europarl-v7.test.sv-en\")\n        train_path = _get_europarl_ensv_dataset(tmp_dir, dataset_path)\n\n        # Vocab\n        token_path = os.path.join(data_dir, self.vocab_filename)\n        if not tf.gfile.Exists(token_path):\n            token_tmp_path = os.path.join(tmp_dir, self.vocab_filename)\n            tf.gfile.Copy(token_tmp_path, token_path)\n            with tf.gfile.GFile(token_path, mode=\"r\") as f:\n                vocab_data = \"&lt;pad&gt;\\n&lt;EOS&gt;\\n\" + f.read() + \"UNK\\n\"\n            with tf.gfile.GFile(token_path, mode=\"w\") as f:\n                f.write(vocab_data)\n\n        return text_problems.text2text_txt_iterator(train_path + \".en\",\n                                                    train_path + \".sv\")\n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nI've registered a new problem for translating English to Swedish, the code is pretty similar to TranslateEndeWmtBpe32k, with Europarl data. I'm able to train with hidden_size: 128, anything over 128 and I get Resource exhausted error, even when batch size is 1. (I'm using hparams: transformer_big).\n\nI notice that previous posts on this issue were solved by reducing the batch size. I'm posting this because reducing batch size wasn't helpful and I'm hoping if someone encountered a similar issue.\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n\nLinux deepnlp01 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n4 VERSION=\"14.04.5 LTS, Trusty Tahr\"\n\n\nTensorFlow installed from (source or binary):\ntf.VERSION = 1.4.1 (Installed from source)\n\n\nPython version:\n2.7.6\n\n\nBazel version (if compiling from source):\nBuild label: 0.5.2\n\n\nGCC/Compiler version (if compiling from source):\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n\n\nCUDA/cuDNN version:\nnvcc: NVIDIA (R) Cuda compiler driver\nCuda compilation tools, release 8.0, V8.0.61\n\n\nGPU model and memory:\nNVIDIA TITAN X (12GB)\n\n\nExact command to reproduce:\nUSR_DIR=/python2.7/site-packages/tensor2tensor/<new_module>\n\n\nt2t-trainer \n--data_dir=$DATA_DIR \n--problems=$PROBLEM \n--model=$MODEL \n--hparams_set=$HPARAMS \n--output_dir=$TRAIN_DIR \n--t2t_usr_dir=$USR_DIR\nDescribe the problem\nThe data I'm using is parallel corpus English-Swedish, available on http://www.statmt.org/europarl/ . I've created a dictionary myself of about 1,400,000 (1.4 million) words. [The problem persists even if I use a smaller vocab of about 10k words]\nI'm able to train with batch_size=1024 and hidden_size=128, if I increase the hidden size to 256, even with batch_size=1, it runs out of memory. I get the following error.\nSource code / logs\nThis is the error I'm encountering:\n2018-02-28 05:48:52.977027: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[90993,256]\n\nTraceback (most recent call last):\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\n    tf.app.run()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\n    t2t_trainer.main(argv)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\n    execute_schedule(exp)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\n    getattr(exp, FLAGS.schedule)()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\n    return func(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\n    hooks=self._train_monitors)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\n    hooks=hooks)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\n    raise six.reraise(*original_exc_info)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\n    run_metadata=run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\n    return self._sess.run(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[90992,256]\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'training/gradients/AddN_96', defined at:\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\n    tf.app.run()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\n    t2t_trainer.main(argv)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\n    execute_schedule(exp)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\n    getattr(exp, FLAGS.schedule)()\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\n    return func(*args, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\n    hooks=self._train_monitors)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\n    hooks=hooks)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 711, in _train_model\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 694, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 829, in wrapping_model_fn\n    use_tpu=use_tpu)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 923, in estimator_model_fn\n    loss, num_async_replicas=num_async_replicas)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 927, in estimator_spec_train\n    train_op = self.optimize(loss, num_async_replicas=num_async_replicas)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 351, in optimize\n    loss, lr, self.hparams, use_tpu=common_layers.is_on_tpu())\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 67, in optimize\n    colocate_gradients_with_ops=True)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 241, in optimize_loss\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 109, in compute_gradients\n    return self._opt.compute_gradients(loss, var_list, **kwargs)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 533, in gradients\n    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 872, in _AggregatedGrads\n    out_grads[i] = _MultiDeviceAddN(out_grad)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 767, in _MultiDeviceAddN\n    summands.append(math_ops.add_n(tensors))\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2000, in add_n\n    return gen_math_ops._add_n(inputs, name=name)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 220, in _add_n\n    \"AddN\", inputs=inputs, name=name)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[90992,256]\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n\nThis is the code that I've modified:\ndef _get_europarl_ensv_dataset(directory, filename):\n    \"\"\"Extract the EuroParl en-sv corpus `filename` to directory unless it's there.\"\"\"\n\n    train_path = os.path.join(directory, filename)\n\n    return train_path\n\n\n@registry.register_problem\nclass TranslateEnsvEuroparl(translate.TranslateProblem):\n    \"\"\"Problem spec for EuroParl En-Sv translation, BPE version.\"\"\"\n\n    @property\n    def approx_vocab_size(self):\n        return 1455877\n\n    @property\n    def vocab_filename(self):\n        return \"vocab.europarl.ensv.txt\"\n\n    def get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):\n        vocab_filename = os.path.join(data_dir, self.vocab_filename)\n        if not tf.gfile.Exists(vocab_filename) and force_get:\n            raise ValueError(\"Vocab %s not found\" % vocab_filename)\n        return text_encoder.TokenTextEncoder(vocab_filename, replace_oov=\"UNK\")\n\n    def generate_samples(self, data_dir, tmp_dir, dataset_split):\n        \"\"\"Instance of token generator for the WMT en->de task, training set.\"\"\"\n        train = dataset_split == problem.DatasetSplit.TRAIN\n        dataset_path = (\"europarl-v7.train.sv-en\"\n                        if train else \"europarl-v7.test.sv-en\")\n        train_path = _get_europarl_ensv_dataset(tmp_dir, dataset_path)\n\n        # Vocab\n        token_path = os.path.join(data_dir, self.vocab_filename)\n        if not tf.gfile.Exists(token_path):\n            token_tmp_path = os.path.join(tmp_dir, self.vocab_filename)\n            tf.gfile.Copy(token_tmp_path, token_path)\n            with tf.gfile.GFile(token_path, mode=\"r\") as f:\n                vocab_data = \"<pad>\\n<EOS>\\n\" + f.read() + \"UNK\\n\"\n            with tf.gfile.GFile(token_path, mode=\"w\") as f:\n                f.write(vocab_data)\n\n        return text_problems.text2text_txt_iterator(train_path + \".en\",\n                                                    train_path + \".sv\")", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI've registered a new problem for translating English to Swedish, the code is pretty similar to TranslateEndeWmtBpe32k, with Europarl data. I'm able to train with hidden_size: 128, anything over 128 and I get Resource exhausted error, even when batch size is 1. (I'm using hparams: transformer_big).\r\n\r\nI notice that previous posts on this issue were solved by reducing the batch size. I'm posting this because reducing batch size wasn't helpful and I'm hoping if someone encountered a similar issue.\r\n\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux deepnlp01 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n  4 VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\ntf.VERSION = 1.4.1 (Installed from source)\r\n\r\n- **Python version**: \r\n2.7.6\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.2\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n\r\n- **CUDA/cuDNN version**:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCuda compilation tools, release 8.0, V8.0.61\r\n\r\n- **GPU model and memory**:\r\nNVIDIA TITAN X (12GB)\r\n\r\n- **Exact command to reproduce**:\r\nUSR_DIR=<path>/python2.7/site-packages/tensor2tensor/<new_module>\r\n\r\nt2t-trainer \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problems=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n  --t2t_usr_dir=$USR_DIR\r\n\r\n### Describe the problem\r\n\r\nThe data I'm using is parallel corpus English-Swedish, available on http://www.statmt.org/europarl/ . I've created a dictionary myself of about 1,400,000 (1.4 million) words. [The problem persists even if I use a smaller vocab of about 10k words]\r\n\r\nI'm able to train with batch_size=1024 and hidden_size=128, if I increase the hidden size to 256, even with batch_size=1, it runs out of memory. I get the following error.\r\n\r\n### Source code / logs\r\nThis is the error I'm encountering:\r\n\r\n```\r\n2018-02-28 05:48:52.977027: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[90993,256]\r\n\r\nTraceback (most recent call last):\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\r\n    tf.app.run()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\r\n    execute_schedule(exp)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\r\n    hooks=self._train_monitors)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[90992,256]\r\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\r\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'training/gradients/AddN_96', defined at:\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 32, in <module>\r\n    tf.app.run()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 337, in main\r\n    execute_schedule(exp)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 287, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 717, in continuous_train_and_eval\r\n    hooks=self._train_monitors)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 711, in _train_model\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 694, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 829, in wrapping_model_fn\r\n    use_tpu=use_tpu)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 923, in estimator_model_fn\r\n    loss, num_async_replicas=num_async_replicas)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 927, in estimator_spec_train\r\n    train_op = self.optimize(loss, num_async_replicas=num_async_replicas)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 351, in optimize\r\n    loss, lr, self.hparams, use_tpu=common_layers.is_on_tpu())\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 67, in optimize\r\n    colocate_gradients_with_ops=True)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 241, in optimize_loss\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py\", line 109, in compute_gradients\r\n    return self._opt.compute_gradients(loss, var_list, **kwargs)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 533, in gradients\r\n    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 872, in _AggregatedGrads\r\n    out_grads[i] = _MultiDeviceAddN(out_grad)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 767, in _MultiDeviceAddN\r\n    summands.append(math_ops.add_n(tensors))\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2000, in add_n\r\n    return gen_math_ops._add_n(inputs, name=name)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 220, in _add_n\r\n    \"AddN\", inputs=inputs, name=name)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[90992,256]\r\n         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=[\"loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]\r\n         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24183_training/global_norm/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n```\r\nThis is the code that I've modified:\r\n\r\n```\r\ndef _get_europarl_ensv_dataset(directory, filename):\r\n    \"\"\"Extract the EuroParl en-sv corpus `filename` to directory unless it's there.\"\"\"\r\n\r\n    train_path = os.path.join(directory, filename)\r\n\r\n    return train_path\r\n\r\n\r\n@registry.register_problem\r\nclass TranslateEnsvEuroparl(translate.TranslateProblem):\r\n    \"\"\"Problem spec for EuroParl En-Sv translation, BPE version.\"\"\"\r\n\r\n    @property\r\n    def approx_vocab_size(self):\r\n        return 1455877\r\n\r\n    @property\r\n    def vocab_filename(self):\r\n        return \"vocab.europarl.ensv.txt\"\r\n\r\n    def get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):\r\n        vocab_filename = os.path.join(data_dir, self.vocab_filename)\r\n        if not tf.gfile.Exists(vocab_filename) and force_get:\r\n            raise ValueError(\"Vocab %s not found\" % vocab_filename)\r\n        return text_encoder.TokenTextEncoder(vocab_filename, replace_oov=\"UNK\")\r\n\r\n    def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n        \"\"\"Instance of token generator for the WMT en->de task, training set.\"\"\"\r\n        train = dataset_split == problem.DatasetSplit.TRAIN\r\n        dataset_path = (\"europarl-v7.train.sv-en\"\r\n                        if train else \"europarl-v7.test.sv-en\")\r\n        train_path = _get_europarl_ensv_dataset(tmp_dir, dataset_path)\r\n\r\n        # Vocab\r\n        token_path = os.path.join(data_dir, self.vocab_filename)\r\n        if not tf.gfile.Exists(token_path):\r\n            token_tmp_path = os.path.join(tmp_dir, self.vocab_filename)\r\n            tf.gfile.Copy(token_tmp_path, token_path)\r\n            with tf.gfile.GFile(token_path, mode=\"r\") as f:\r\n                vocab_data = \"<pad>\\n<EOS>\\n\" + f.read() + \"UNK\\n\"\r\n            with tf.gfile.GFile(token_path, mode=\"w\") as f:\r\n                f.write(vocab_data)\r\n\r\n        return text_problems.text2text_txt_iterator(train_path + \".en\",\r\n                                                    train_path + \".sv\")\r\n\r\n```"}