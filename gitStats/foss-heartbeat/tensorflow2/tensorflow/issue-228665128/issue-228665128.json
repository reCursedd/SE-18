{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9910", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9910/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9910/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9910/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9910", "id": 228665128, "node_id": "MDU6SXNzdWUyMjg2NjUxMjg=", "number": 9910, "title": "Issues with spark-tensorflow-connector", "user": {"login": "wj1066", "id": 18544010, "node_id": "MDQ6VXNlcjE4NTQ0MDEw", "avatar_url": "https://avatars1.githubusercontent.com/u/18544010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wj1066", "html_url": "https://github.com/wj1066", "followers_url": "https://api.github.com/users/wj1066/followers", "following_url": "https://api.github.com/users/wj1066/following{/other_user}", "gists_url": "https://api.github.com/users/wj1066/gists{/gist_id}", "starred_url": "https://api.github.com/users/wj1066/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wj1066/subscriptions", "organizations_url": "https://api.github.com/users/wj1066/orgs", "repos_url": "https://api.github.com/users/wj1066/repos", "events_url": "https://api.github.com/users/wj1066/events{/privacy}", "received_events_url": "https://api.github.com/users/wj1066/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-05-15T10:02:13Z", "updated_at": "2018-01-31T16:55:18Z", "closed_at": "2017-09-08T04:55:36Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.1.0 and 1.0.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>:NA</li>\n<li><strong>CUDA/cuDNN version</strong>:None</li>\n<li><strong>GPU model and memory</strong>:None</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When using <strong>spark-tensorflow-connector</strong>, I run the given example and get the the TFRecord test-output.tfr. Then I want to use it in tensorflow, but some errors occur.<br>\n<a href=\"https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector\">https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector</a></p>\n<h3>Source code / logs</h3>\n<p>scala code\uff1a</p>\n<div class=\"highlight highlight-source-scala\"><pre><span class=\"pl-k\">import</span> <span class=\"pl-en\">org</span>.<span class=\"pl-en\">apache</span>.<span class=\"pl-en\">commons</span>.<span class=\"pl-en\">io</span>.<span class=\"pl-en\">FileUtils</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-en\">org</span>.<span class=\"pl-en\">apache</span>.<span class=\"pl-en\">spark</span>.<span class=\"pl-en\">sql</span>.{ <span class=\"pl-en\">DataFrame</span>, <span class=\"pl-en\">Row</span> }\n<span class=\"pl-k\">import</span> <span class=\"pl-en\">org</span>.<span class=\"pl-en\">apache</span>.<span class=\"pl-en\">spark</span>.<span class=\"pl-en\">sql</span>.<span class=\"pl-en\">catalyst</span>.<span class=\"pl-en\">expressions</span>.<span class=\"pl-en\">GenericRow</span>\n<span class=\"pl-k\">import</span> <span class=\"pl-en\">org</span>.<span class=\"pl-en\">apache</span>.<span class=\"pl-en\">spark</span>.<span class=\"pl-en\">sql</span>.<span class=\"pl-en\">types</span>.<span class=\"pl-en\">_</span>\n\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">path</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test-output.tfr<span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">testRows</span><span class=\"pl-k\">:</span> <span class=\"pl-en\">Array</span>[<span class=\"pl-en\">Row</span>] <span class=\"pl-k\">=</span> <span class=\"pl-en\">Array</span>(\n<span class=\"pl-k\">new</span> <span class=\"pl-en\">GenericRow</span>(<span class=\"pl-en\">Array</span>[<span class=\"pl-en\">Any</span>](<span class=\"pl-c1\">11</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">23L</span>, <span class=\"pl-c1\">10.0F</span>, <span class=\"pl-c1\">14.0</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r1<span class=\"pl-pds\">\"</span></span>)),\n<span class=\"pl-k\">new</span> <span class=\"pl-en\">GenericRow</span>(<span class=\"pl-en\">Array</span>[<span class=\"pl-en\">Any</span>](<span class=\"pl-c1\">21</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">24L</span>, <span class=\"pl-c1\">12.0F</span>, <span class=\"pl-c1\">15.0</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>r2<span class=\"pl-pds\">\"</span></span>)))\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">schema</span> <span class=\"pl-k\">=</span> <span class=\"pl-en\">StructType</span>(<span class=\"pl-en\">List</span>(<span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>id<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">IntegerType</span>), \n                             <span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>IntegerTypelabel<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">IntegerType</span>), \n                             <span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>LongTypelabel<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">LongType</span>), \n                             <span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>FloatTypelabel<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">FloatType</span>), \n                             <span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>DoubleTypelabel<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">DoubleType</span>), \n                             <span class=\"pl-en\">StructField</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-en\">StringType</span>)))\n                             \n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">rdd</span> <span class=\"pl-k\">=</span> spark.sparkContext.parallelize(testRows)\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Save DataFrame as TFRecords</span>\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">df</span><span class=\"pl-k\">:</span> <span class=\"pl-en\">DataFrame</span> <span class=\"pl-k\">=</span> spark.createDataFrame(rdd, schema)\ndf.write.format(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tfrecords<span class=\"pl-pds\">\"</span></span>).save(path)\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Read TFRecords into DataFrame.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>The DataFrame schema is inferred from the TFRecords if no custom schema is provided.</span>\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">importedDf1</span><span class=\"pl-k\">:</span> <span class=\"pl-en\">DataFrame</span> <span class=\"pl-k\">=</span> spark.read.format(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tfrecords<span class=\"pl-pds\">\"</span></span>).load(path)\nimportedDf1.show()\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>Read TFRecords into DataFrame using custom schema</span>\n<span class=\"pl-k\">val</span> <span class=\"pl-smi\">importedDf2</span><span class=\"pl-k\">:</span> <span class=\"pl-en\">DataFrame</span> <span class=\"pl-k\">=</span> spark.read.format(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tfrecords<span class=\"pl-pds\">\"</span></span>).schema(schema).load(path)\nimportedDf2.show()</pre></div>\n<p>python code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-c1\">print</span>(tf.<span class=\"pl-c1\">__version__</span>)\nfileNameQue <span class=\"pl-k\">=</span> tf.train.string_input_producer([<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wj/test-output.tfr<span class=\"pl-pds\">\"</span></span>])\nreader <span class=\"pl-k\">=</span> tf.TFRecordReader()\nkey, value <span class=\"pl-k\">=</span> reader.read(fileNameQue)\nfeatures <span class=\"pl-k\">=</span> tf.parse_single_example(value, <span class=\"pl-v\">features</span><span class=\"pl-k\">=</span>{\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>id<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>IntegerTypelabel<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>LongTypelabel<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>FloatTypelabel<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.float32),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>DoubleTypelabel<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.float32),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.string),\n    })\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> with tf.Session() as sess:</span>\nsess <span class=\"pl-k\">=</span> tf.InteractiveSession()\n\ncoord<span class=\"pl-k\">=</span>tf.train.Coordinator()\nthreads<span class=\"pl-k\">=</span> tf.train.start_queue_runners(<span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>for i in range(2):</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])</span>\na <span class=\"pl-k\">=</span> sess.run(features)\ncoord.request_stop()\ncoord.join(threads)</pre></div>\n<p>logs:</p>\n<pre><code>---------------------------------------------------------------------------\nFailedPreconditionError                   Traceback (most recent call last)\n&lt;ipython-input-13-889826d0ffbd&gt; in &lt;module&gt;()\n      7 #for i in range(2):\n      8 # a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])\n----&gt; 9 a = sess.run(features)\n     10 \n     11 \n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    765     try:\n    766       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 767                          run_metadata_ptr)\n    768       if run_metadata:\n    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    963     if final_fetches or final_targets:\n    964       results = self._do_run(handle, final_targets, final_fetches,\n--&gt; 965                              feed_dict_string, options, run_metadata)\n    966     else:\n    967       results = []\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1013     if handle is None:\n   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-&gt; 1015                            target_list, options, run_metadata)\n   1016     else:\n   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1033         except KeyError:\n   1034           pass\n-&gt; 1035       raise type(e)(node_def, op, message)\n   1036 \n   1037   def _extend_graph(self):\n\nFailedPreconditionError: /home/wj/test-output.tfr\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\nCaused by op u'ReaderReadV2', defined at:\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-6-7fd6f1c21551&gt;\", line 1, in &lt;module&gt;\n    key, value = reader.read(fileNameQue)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 272, in read\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 410, in _reader_read_v2\n    queue_handle=queue_handle, name=name)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): /home/wj/test-output.tfr\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.1.0 and 1.0.0\nBazel version (if compiling from source):NA\nCUDA/cuDNN version:None\nGPU model and memory:None\nExact command to reproduce:\n\nDescribe the problem\nWhen using spark-tensorflow-connector, I run the given example and get the the TFRecord test-output.tfr. Then I want to use it in tensorflow, but some errors occur.\nhttps://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector\nSource code / logs\nscala code\uff1a\nimport org.apache.commons.io.FileUtils\nimport org.apache.spark.sql.{ DataFrame, Row }\nimport org.apache.spark.sql.catalyst.expressions.GenericRow\nimport org.apache.spark.sql.types._\n\nval path = \"test-output.tfr\"\nval testRows: Array[Row] = Array(\nnew GenericRow(Array[Any](11, 1, 23L, 10.0F, 14.0, \"r1\")),\nnew GenericRow(Array[Any](21, 2, 24L, 12.0F, 15.0, \"r2\")))\nval schema = StructType(List(StructField(\"id\", IntegerType), \n                             StructField(\"IntegerTypelabel\", IntegerType), \n                             StructField(\"LongTypelabel\", LongType), \n                             StructField(\"FloatTypelabel\", FloatType), \n                             StructField(\"DoubleTypelabel\", DoubleType), \n                             StructField(\"name\", StringType)))\n                             \nval rdd = spark.sparkContext.parallelize(testRows)\n\n//Save DataFrame as TFRecords\nval df: DataFrame = spark.createDataFrame(rdd, schema)\ndf.write.format(\"tfrecords\").save(path)\n\n//Read TFRecords into DataFrame.\n//The DataFrame schema is inferred from the TFRecords if no custom schema is provided.\nval importedDf1: DataFrame = spark.read.format(\"tfrecords\").load(path)\nimportedDf1.show()\n\n//Read TFRecords into DataFrame using custom schema\nval importedDf2: DataFrame = spark.read.format(\"tfrecords\").schema(schema).load(path)\nimportedDf2.show()\npython code:\nimport tensorflow as tf\nprint(tf.__version__)\nfileNameQue = tf.train.string_input_producer([\"/home/wj/test-output.tfr\"])\nreader = tf.TFRecordReader()\nkey, value = reader.read(fileNameQue)\nfeatures = tf.parse_single_example(value, features={\n        'id': tf.FixedLenFeature([], tf.int64),\n        'IntegerTypelabel': tf.FixedLenFeature([], tf.int64),\n        'LongTypelabel': tf.FixedLenFeature([], tf.int64),\n        'FloatTypelabel': tf.FixedLenFeature([], tf.float32),\n        'DoubleTypelabel': tf.FixedLenFeature([], tf.float32),\n        'name': tf.FixedLenFeature([], tf.string),\n    })\n# with tf.Session() as sess:\nsess = tf.InteractiveSession()\n\ncoord=tf.train.Coordinator()\nthreads= tf.train.start_queue_runners(coord=coord)\n#for i in range(2):\n# a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])\na = sess.run(features)\ncoord.request_stop()\ncoord.join(threads)\nlogs:\n---------------------------------------------------------------------------\nFailedPreconditionError                   Traceback (most recent call last)\n<ipython-input-13-889826d0ffbd> in <module>()\n      7 #for i in range(2):\n      8 # a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])\n----> 9 a = sess.run(features)\n     10 \n     11 \n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    765     try:\n    766       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 767                          run_metadata_ptr)\n    768       if run_metadata:\n    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    963     if final_fetches or final_targets:\n    964       results = self._do_run(handle, final_targets, final_fetches,\n--> 965                              feed_dict_string, options, run_metadata)\n    966     else:\n    967       results = []\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1013     if handle is None:\n   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-> 1015                            target_list, options, run_metadata)\n   1016     else:\n   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1033         except KeyError:\n   1034           pass\n-> 1035       raise type(e)(node_def, op, message)\n   1036 \n   1037   def _extend_graph(self):\n\nFailedPreconditionError: /home/wj/test-output.tfr\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\n\nCaused by op u'ReaderReadV2', defined at:\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-7fd6f1c21551>\", line 1, in <module>\n    key, value = reader.read(fileNameQue)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 272, in read\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 410, in _reader_read_v2\n    queue_handle=queue_handle, name=name)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): /home/wj/test-output.tfr\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.1.0 and 1.0.0\r\n- **Bazel version (if compiling from source)**:NA\r\n- **CUDA/cuDNN version**:None\r\n- **GPU model and memory**:None\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen using **spark-tensorflow-connector**, I run the given example and get the the TFRecord test-output.tfr. Then I want to use it in tensorflow, but some errors occur.\r\nhttps://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector\r\n\r\n### Source code / logs\r\n\r\nscala code\uff1a\r\n```scala\r\nimport org.apache.commons.io.FileUtils\r\nimport org.apache.spark.sql.{ DataFrame, Row }\r\nimport org.apache.spark.sql.catalyst.expressions.GenericRow\r\nimport org.apache.spark.sql.types._\r\n\r\nval path = \"test-output.tfr\"\r\nval testRows: Array[Row] = Array(\r\nnew GenericRow(Array[Any](11, 1, 23L, 10.0F, 14.0, \"r1\")),\r\nnew GenericRow(Array[Any](21, 2, 24L, 12.0F, 15.0, \"r2\")))\r\nval schema = StructType(List(StructField(\"id\", IntegerType), \r\n                             StructField(\"IntegerTypelabel\", IntegerType), \r\n                             StructField(\"LongTypelabel\", LongType), \r\n                             StructField(\"FloatTypelabel\", FloatType), \r\n                             StructField(\"DoubleTypelabel\", DoubleType), \r\n                             StructField(\"name\", StringType)))\r\n                             \r\nval rdd = spark.sparkContext.parallelize(testRows)\r\n\r\n//Save DataFrame as TFRecords\r\nval df: DataFrame = spark.createDataFrame(rdd, schema)\r\ndf.write.format(\"tfrecords\").save(path)\r\n\r\n//Read TFRecords into DataFrame.\r\n//The DataFrame schema is inferred from the TFRecords if no custom schema is provided.\r\nval importedDf1: DataFrame = spark.read.format(\"tfrecords\").load(path)\r\nimportedDf1.show()\r\n\r\n//Read TFRecords into DataFrame using custom schema\r\nval importedDf2: DataFrame = spark.read.format(\"tfrecords\").schema(schema).load(path)\r\nimportedDf2.show()\r\n```\r\n\r\npython code:\r\n```python\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nfileNameQue = tf.train.string_input_producer([\"/home/wj/test-output.tfr\"])\r\nreader = tf.TFRecordReader()\r\nkey, value = reader.read(fileNameQue)\r\nfeatures = tf.parse_single_example(value, features={\r\n        'id': tf.FixedLenFeature([], tf.int64),\r\n        'IntegerTypelabel': tf.FixedLenFeature([], tf.int64),\r\n        'LongTypelabel': tf.FixedLenFeature([], tf.int64),\r\n        'FloatTypelabel': tf.FixedLenFeature([], tf.float32),\r\n        'DoubleTypelabel': tf.FixedLenFeature([], tf.float32),\r\n        'name': tf.FixedLenFeature([], tf.string),\r\n    })\r\n# with tf.Session() as sess:\r\nsess = tf.InteractiveSession()\r\n\r\ncoord=tf.train.Coordinator()\r\nthreads= tf.train.start_queue_runners(coord=coord)\r\n#for i in range(2):\r\n# a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])\r\na = sess.run(features)\r\ncoord.request_stop()\r\ncoord.join(threads)\r\n```\r\nlogs:\r\n```\r\n---------------------------------------------------------------------------\r\nFailedPreconditionError                   Traceback (most recent call last)\r\n<ipython-input-13-889826d0ffbd> in <module>()\r\n      7 #for i in range(2):\r\n      8 # a,b,c,d,e,f = sess.run([id,IntegerTypelabel,LongTypelabel,FloatTypelabel,DoubleTypelabel,name])\r\n----> 9 a = sess.run(features)\r\n     10 \r\n     11 \r\n\r\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    765     try:\r\n    766       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 767                          run_metadata_ptr)\r\n    768       if run_metadata:\r\n    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    963     if final_fetches or final_targets:\r\n    964       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 965                              feed_dict_string, options, run_metadata)\r\n    966     else:\r\n    967       results = []\r\n\r\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1013     if handle is None:\r\n   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1015                            target_list, options, run_metadata)\r\n   1016     else:\r\n   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1033         except KeyError:\r\n   1034           pass\r\n-> 1035       raise type(e)(node_def, op, message)\r\n   1036 \r\n   1037   def _extend_graph(self):\r\n\r\nFailedPreconditionError: /home/wj/test-output.tfr\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\n\r\nCaused by op u'ReaderReadV2', defined at:\r\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/home/wj/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\r\n    app.start()\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-6-7fd6f1c21551>\", line 1, in <module>\r\n    key, value = reader.read(fileNameQue)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 272, in read\r\n    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 410, in _reader_read_v2\r\n    queue_handle=queue_handle, name=name)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/wj/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nFailedPreconditionError (see above for traceback): /home/wj/test-output.tfr\r\n\t [[Node: ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReaderV2, input_producer)]]\r\n```"}