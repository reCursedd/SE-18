{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12330", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12330/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12330/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12330/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12330", "id": 250638165, "node_id": "MDU6SXNzdWUyNTA2MzgxNjU=", "number": 12330, "title": "Request for computation of hessian wrt tensor of shape 1 x n", "user": {"login": "iramusa", "id": 4759395, "node_id": "MDQ6VXNlcjQ3NTkzOTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/4759395?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iramusa", "html_url": "https://github.com/iramusa", "followers_url": "https://api.github.com/users/iramusa/followers", "following_url": "https://api.github.com/users/iramusa/following{/other_user}", "gists_url": "https://api.github.com/users/iramusa/gists{/gist_id}", "starred_url": "https://api.github.com/users/iramusa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iramusa/subscriptions", "organizations_url": "https://api.github.com/users/iramusa/orgs", "repos_url": "https://api.github.com/users/iramusa/repos", "events_url": "https://api.github.com/users/iramusa/events{/privacy}", "received_events_url": "https://api.github.com/users/iramusa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-08-16T14:01:49Z", "updated_at": "2018-11-08T15:29:11Z", "closed_at": "2018-11-08T15:29:10Z", "author_association": "NONE", "body_html": "<p>There currently exists tf.hessians function which returns 2nd order <em>y</em> derivatives w.r.t. to a specified tensor <em>x</em>. Currently <em>x</em> has to be one dimensional.</p>\n<p>In my application, I need to differentiate with respect to a tensor that has dimensions batch_size x layer_width. (I am interested in second derivative of output from neural net with respect to a particular layer.) I can bring dimensionality down to 1 x layer_width, by setting batch_size to 1. Unfortunately, this still does not let me use tf.hessian.</p>\n<p>Would it be possible to add functionality where hessian w.r.t. <em>effectively</em> one-dimensional tensors can be computed? So that, for example tensors of shape 1 x n (or 1 x 1 x n) can be used. It feels like it shouldn't be a hard problem, but I'm completely lost when I look at tf.gradients code.</p>\n<p>Thanks</p>", "body_text": "There currently exists tf.hessians function which returns 2nd order y derivatives w.r.t. to a specified tensor x. Currently x has to be one dimensional.\nIn my application, I need to differentiate with respect to a tensor that has dimensions batch_size x layer_width. (I am interested in second derivative of output from neural net with respect to a particular layer.) I can bring dimensionality down to 1 x layer_width, by setting batch_size to 1. Unfortunately, this still does not let me use tf.hessian.\nWould it be possible to add functionality where hessian w.r.t. effectively one-dimensional tensors can be computed? So that, for example tensors of shape 1 x n (or 1 x 1 x n) can be used. It feels like it shouldn't be a hard problem, but I'm completely lost when I look at tf.gradients code.\nThanks", "body": "There currently exists tf.hessians function which returns 2nd order *y* derivatives w.r.t. to a specified tensor *x*. Currently *x* has to be one dimensional.\r\n\r\nIn my application, I need to differentiate with respect to a tensor that has dimensions batch_size x layer_width. (I am interested in second derivative of output from neural net with respect to a particular layer.) I can bring dimensionality down to 1 x layer_width, by setting batch_size to 1. Unfortunately, this still does not let me use tf.hessian.\r\n\r\nWould it be possible to add functionality where hessian w.r.t. *effectively* one-dimensional tensors can be computed? So that, for example tensors of shape 1 x n (or 1 x 1 x n) can be used. It feels like it shouldn't be a hard problem, but I'm completely lost when I look at tf.gradients code.\r\n\r\nThanks"}