{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323206812", "html_url": "https://github.com/tensorflow/tensorflow/issues/12330#issuecomment-323206812", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12330", "id": 323206812, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzIwNjgxMg==", "user": {"login": "tillahoffmann", "id": 966348, "node_id": "MDQ6VXNlcjk2NjM0OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/966348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tillahoffmann", "html_url": "https://github.com/tillahoffmann", "followers_url": "https://api.github.com/users/tillahoffmann/followers", "following_url": "https://api.github.com/users/tillahoffmann/following{/other_user}", "gists_url": "https://api.github.com/users/tillahoffmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/tillahoffmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tillahoffmann/subscriptions", "organizations_url": "https://api.github.com/users/tillahoffmann/orgs", "repos_url": "https://api.github.com/users/tillahoffmann/repos", "events_url": "https://api.github.com/users/tillahoffmann/events{/privacy}", "received_events_url": "https://api.github.com/users/tillahoffmann/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-17T22:03:06Z", "updated_at": "2017-08-17T22:09:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4759395\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/iramusa\">@iramusa</a>, you could approach the problem the other way round: Start with a 1D tensor which you reshape to the desired shape. Then you can compute the hessian of some function of your tensor with respect to the 1D tensor and reshape the hessian to match the desired shape. But examples are better than theory:</p>\n<div class=\"highlight highlight-source-python\"><pre>shape <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>)\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    x_flat <span class=\"pl-k\">=</span> tf.constant(np.random.normal(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, np.prod(shape)))\n    x <span class=\"pl-k\">=</span> tf.reshape(x_flat, shape)\n    y <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> x\n    hessian_flat, <span class=\"pl-k\">=</span> tf.hessians(y, x_flat)\n    hessian <span class=\"pl-k\">=</span> tf.reshape(hessian_flat, shape <span class=\"pl-k\">+</span> shape)</pre></div>\n<p>The problem with the squeezing is a result of the computation graph being a <a href=\"https://en.wikipedia.org/wiki/Directed_acyclic_graph\" rel=\"nofollow\">DAG</a>: suppose <code>y</code> is a function of your tensor <code>x</code> and <code>s</code> is the squeezed tensor. Then the graph looks something like this (excuse my terrible ASCII art).</p>\n<pre><code>     x\n    / \\\n   /   v\n  v   s = tf.squeeze(x)\ny = f(x)\n</code></pre>\n<p>In short, <code>tf.gradients(y, s)</code> will return <code>None</code> if <code>s</code> is not a child of <code>y</code> in the computation graph. One might argue that <code>s</code> and <code>x</code> <em>are</em> the same entity but unfortunately that is difficult to capture using the DAG.</p>", "body_text": "@iramusa, you could approach the problem the other way round: Start with a 1D tensor which you reshape to the desired shape. Then you can compute the hessian of some function of your tensor with respect to the 1D tensor and reshape the hessian to match the desired shape. But examples are better than theory:\nshape = (3, 5)\n\nwith tf.Graph().as_default():\n    x_flat = tf.constant(np.random.normal(0, 1, np.prod(shape)))\n    x = tf.reshape(x_flat, shape)\n    y = x * x\n    hessian_flat, = tf.hessians(y, x_flat)\n    hessian = tf.reshape(hessian_flat, shape + shape)\nThe problem with the squeezing is a result of the computation graph being a DAG: suppose y is a function of your tensor x and s is the squeezed tensor. Then the graph looks something like this (excuse my terrible ASCII art).\n     x\n    / \\\n   /   v\n  v   s = tf.squeeze(x)\ny = f(x)\n\nIn short, tf.gradients(y, s) will return None if s is not a child of y in the computation graph. One might argue that s and x are the same entity but unfortunately that is difficult to capture using the DAG.", "body": "@iramusa, you could approach the problem the other way round: Start with a 1D tensor which you reshape to the desired shape. Then you can compute the hessian of some function of your tensor with respect to the 1D tensor and reshape the hessian to match the desired shape. But examples are better than theory:\r\n\r\n```python\r\nshape = (3, 5)\r\n\r\nwith tf.Graph().as_default():\r\n    x_flat = tf.constant(np.random.normal(0, 1, np.prod(shape)))\r\n    x = tf.reshape(x_flat, shape)\r\n    y = x * x\r\n    hessian_flat, = tf.hessians(y, x_flat)\r\n    hessian = tf.reshape(hessian_flat, shape + shape)\r\n```\r\n\r\nThe problem with the squeezing is a result of the computation graph being a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph): suppose `y` is a function of your tensor `x` and `s` is the squeezed tensor. Then the graph looks something like this (excuse my terrible ASCII art).\r\n\r\n```\r\n     x\r\n    / \\\r\n   /   v\r\n  v   s = tf.squeeze(x)\r\ny = f(x)\r\n```\r\n\r\nIn short, `tf.gradients(y, s)` will return `None` if `s` is not a child of `y` in the computation graph. One might argue that `s` and `x` *are* the same entity but unfortunately that is difficult to capture using the DAG."}