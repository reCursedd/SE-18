{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12783", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12783/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12783/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12783/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12783", "id": 254895855, "node_id": "MDU6SXNzdWUyNTQ4OTU4NTU=", "number": 12783, "title": "Behavior of SVM in tensorflow.contrib.learn.python.learn.estimators inconsistent between dense and sparse inputs", "user": {"login": "knarf-hackatal2016", "id": 20258096, "node_id": "MDQ6VXNlcjIwMjU4MDk2", "avatar_url": "https://avatars0.githubusercontent.com/u/20258096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/knarf-hackatal2016", "html_url": "https://github.com/knarf-hackatal2016", "followers_url": "https://api.github.com/users/knarf-hackatal2016/followers", "following_url": "https://api.github.com/users/knarf-hackatal2016/following{/other_user}", "gists_url": "https://api.github.com/users/knarf-hackatal2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/knarf-hackatal2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/knarf-hackatal2016/subscriptions", "organizations_url": "https://api.github.com/users/knarf-hackatal2016/orgs", "repos_url": "https://api.github.com/users/knarf-hackatal2016/repos", "events_url": "https://api.github.com/users/knarf-hackatal2016/events{/privacy}", "received_events_url": "https://api.github.com/users/knarf-hackatal2016/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-03T19:38:01Z", "updated_at": "2017-09-04T00:01:18Z", "closed_at": "2017-09-04T00:01:18Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nArch Linux</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nBinary (community arch linux repo)</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.3.0-1</li>\n<li><strong>Python version</strong>:<br>\n3.6.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to use the SVM in tensorflow.contrib.learn with sparse input. The minimal test with real dense valued column works. However when I try to reproduce the exact same classification problem but wrapped in sparse feature columns with sparse_columns_with_integerized_features and weighted_sparse_columns, it fails. It might be a misuse of the sparse columns from me but I've spent a good amount of time reading the doc and the source code without understanding why.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<pre><code># TEST WITH REAL VALUED COLUMNS THAT WORKS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1': constant_op.constant([[0.0], [1.0], [3.0]]),\n      'feature2': constant_op.constant([[1.0], [-1.2], [1.0]]),\n  }, constant_op.constant([[1], [0], [1]])\n\nfeature1 = feature_column.real_valued_column('feature1')\nfeature2 = feature_column.real_valued_column('feature2')\nsvm_classifier = svm.SVM(feature_columns=[feature1, feature2],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss']  # 0 as expected\naccuracy = metrics['accuracy']  # 1 as expected\n\n# TEST WITH SAME VALUES BUT SPARSE COLUMNS, FAILS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\n                      dense_shape=[3,1],\n                      ),\n      'feature2_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\n                      dense_shape=[3,1],\n                      ),\n      'feature1_w': tf.SparseTensor(\n                      indices=[[0,0],[1,0],[2,0]],\n                      values=[0.0, 1.0, 3.0],\n                      dense_shape=[3,1]\n                      ),\n      'feature2_w': tf.SparseTensor(\n                      indices=[[0,0],[1,0],[2,0]],\n                      values=[1.0, -1.2, 1.0],\n                      dense_shape=[3,1]\n                      )\n      }, constant_op.constant([[1], [0], [1]])\n\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\n                                                                    bucket_size=2,)\nfeature2_id = feature_column.sparse_column_with_integerized_feature('feature2_id',\n                                                                    bucket_size=2,)\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\nfeature2_w = feature_column.weighted_sparse_column(feature2_id, 'feature2_w')\n\nsvm_classifier = svm.SVM(feature_columns=[feature1_w, feature2_w],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss'] # should be 0 but is 0.36363636\naccuracy = metrics['accuracy'] # should be 1 but is 0.666667\n\n# TEST WITH SPARSE COLUMNS IN ONE FEATURE COLUMN, SAME RESULTS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]], dtype=tf.int64),\n                      values=tf.constant([0, 1, 0, 1, 0, 1], dtype=tf.int64),\n                      dense_shape=[3,2],\n                      ),\n      'feature1_w': tf.SparseTensor(\n                      indices=[[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]],\n                      values=[0.0, 1.0, 1.0, -1.2, 3.0, 1.0],\n                      dense_shape=[3,2],\n                      )\n      }, constant_op.constant([[1], [0], [1]])\n\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\n                                                                    bucket_size=2,)\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\n\nsvm_classifier = svm.SVM(feature_columns=[feature1_w],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss']\naccuracy = metrics['accuracy']\n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nArch Linux\nTensorFlow installed from (source or binary):\nBinary (community arch linux repo)\nTensorFlow version (use command below):\n1.3.0-1\nPython version:\n3.6.2\nBazel version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI'm trying to use the SVM in tensorflow.contrib.learn with sparse input. The minimal test with real dense valued column works. However when I try to reproduce the exact same classification problem but wrapped in sparse feature columns with sparse_columns_with_integerized_features and weighted_sparse_columns, it fails. It might be a misuse of the sparse columns from me but I've spent a good amount of time reading the doc and the source code without understanding why.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\n# TEST WITH REAL VALUED COLUMNS THAT WORKS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1': constant_op.constant([[0.0], [1.0], [3.0]]),\n      'feature2': constant_op.constant([[1.0], [-1.2], [1.0]]),\n  }, constant_op.constant([[1], [0], [1]])\n\nfeature1 = feature_column.real_valued_column('feature1')\nfeature2 = feature_column.real_valued_column('feature2')\nsvm_classifier = svm.SVM(feature_columns=[feature1, feature2],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss']  # 0 as expected\naccuracy = metrics['accuracy']  # 1 as expected\n\n# TEST WITH SAME VALUES BUT SPARSE COLUMNS, FAILS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\n                      dense_shape=[3,1],\n                      ),\n      'feature2_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\n                      dense_shape=[3,1],\n                      ),\n      'feature1_w': tf.SparseTensor(\n                      indices=[[0,0],[1,0],[2,0]],\n                      values=[0.0, 1.0, 3.0],\n                      dense_shape=[3,1]\n                      ),\n      'feature2_w': tf.SparseTensor(\n                      indices=[[0,0],[1,0],[2,0]],\n                      values=[1.0, -1.2, 1.0],\n                      dense_shape=[3,1]\n                      )\n      }, constant_op.constant([[1], [0], [1]])\n\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\n                                                                    bucket_size=2,)\nfeature2_id = feature_column.sparse_column_with_integerized_feature('feature2_id',\n                                                                    bucket_size=2,)\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\nfeature2_w = feature_column.weighted_sparse_column(feature2_id, 'feature2_w')\n\nsvm_classifier = svm.SVM(feature_columns=[feature1_w, feature2_w],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss'] # should be 0 but is 0.36363636\naccuracy = metrics['accuracy'] # should be 1 but is 0.666667\n\n# TEST WITH SPARSE COLUMNS IN ONE FEATURE COLUMN, SAME RESULTS\ndef input_fn():\n  return {\n      'example_id': constant_op.constant(['1', '2', '3']),\n      'feature1_id': tf.SparseTensor(\n                      indices=tf.constant([[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]], dtype=tf.int64),\n                      values=tf.constant([0, 1, 0, 1, 0, 1], dtype=tf.int64),\n                      dense_shape=[3,2],\n                      ),\n      'feature1_w': tf.SparseTensor(\n                      indices=[[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]],\n                      values=[0.0, 1.0, 1.0, -1.2, 3.0, 1.0],\n                      dense_shape=[3,2],\n                      )\n      }, constant_op.constant([[1], [0], [1]])\n\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\n                                                                    bucket_size=2,)\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\n\nsvm_classifier = svm.SVM(feature_columns=[feature1_w],\n                         example_id_column='example_id',\n                         l1_regularization=0.0,\n                         l2_regularization=0.0)\nsvm_classifier.fit(input_fn=input_fn, steps=30)\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\nloss = metrics['loss']\naccuracy = metrics['accuracy']", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nArch Linux\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary (community arch linux repo)\r\n- **TensorFlow version (use command below)**:\r\n1.3.0-1\r\n- **Python version**: \r\n3.6.2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm trying to use the SVM in tensorflow.contrib.learn with sparse input. The minimal test with real dense valued column works. However when I try to reproduce the exact same classification problem but wrapped in sparse feature columns with sparse_columns_with_integerized_features and weighted_sparse_columns, it fails. It might be a misuse of the sparse columns from me but I've spent a good amount of time reading the doc and the source code without understanding why.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n# TEST WITH REAL VALUED COLUMNS THAT WORKS\r\ndef input_fn():\r\n  return {\r\n      'example_id': constant_op.constant(['1', '2', '3']),\r\n      'feature1': constant_op.constant([[0.0], [1.0], [3.0]]),\r\n      'feature2': constant_op.constant([[1.0], [-1.2], [1.0]]),\r\n  }, constant_op.constant([[1], [0], [1]])\r\n\r\nfeature1 = feature_column.real_valued_column('feature1')\r\nfeature2 = feature_column.real_valued_column('feature2')\r\nsvm_classifier = svm.SVM(feature_columns=[feature1, feature2],\r\n                         example_id_column='example_id',\r\n                         l1_regularization=0.0,\r\n                         l2_regularization=0.0)\r\nsvm_classifier.fit(input_fn=input_fn, steps=30)\r\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\r\nloss = metrics['loss']  # 0 as expected\r\naccuracy = metrics['accuracy']  # 1 as expected\r\n\r\n# TEST WITH SAME VALUES BUT SPARSE COLUMNS, FAILS\r\ndef input_fn():\r\n  return {\r\n      'example_id': constant_op.constant(['1', '2', '3']),\r\n      'feature1_id': tf.SparseTensor(\r\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\r\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\r\n                      dense_shape=[3,1],\r\n                      ),\r\n      'feature2_id': tf.SparseTensor(\r\n                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),\r\n                      values=tf.constant([0, 0, 0], dtype=tf.int64),\r\n                      dense_shape=[3,1],\r\n                      ),\r\n      'feature1_w': tf.SparseTensor(\r\n                      indices=[[0,0],[1,0],[2,0]],\r\n                      values=[0.0, 1.0, 3.0],\r\n                      dense_shape=[3,1]\r\n                      ),\r\n      'feature2_w': tf.SparseTensor(\r\n                      indices=[[0,0],[1,0],[2,0]],\r\n                      values=[1.0, -1.2, 1.0],\r\n                      dense_shape=[3,1]\r\n                      )\r\n      }, constant_op.constant([[1], [0], [1]])\r\n\r\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\r\n                                                                    bucket_size=2,)\r\nfeature2_id = feature_column.sparse_column_with_integerized_feature('feature2_id',\r\n                                                                    bucket_size=2,)\r\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\r\nfeature2_w = feature_column.weighted_sparse_column(feature2_id, 'feature2_w')\r\n\r\nsvm_classifier = svm.SVM(feature_columns=[feature1_w, feature2_w],\r\n                         example_id_column='example_id',\r\n                         l1_regularization=0.0,\r\n                         l2_regularization=0.0)\r\nsvm_classifier.fit(input_fn=input_fn, steps=30)\r\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\r\nloss = metrics['loss'] # should be 0 but is 0.36363636\r\naccuracy = metrics['accuracy'] # should be 1 but is 0.666667\r\n\r\n# TEST WITH SPARSE COLUMNS IN ONE FEATURE COLUMN, SAME RESULTS\r\ndef input_fn():\r\n  return {\r\n      'example_id': constant_op.constant(['1', '2', '3']),\r\n      'feature1_id': tf.SparseTensor(\r\n                      indices=tf.constant([[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]], dtype=tf.int64),\r\n                      values=tf.constant([0, 1, 0, 1, 0, 1], dtype=tf.int64),\r\n                      dense_shape=[3,2],\r\n                      ),\r\n      'feature1_w': tf.SparseTensor(\r\n                      indices=[[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]],\r\n                      values=[0.0, 1.0, 1.0, -1.2, 3.0, 1.0],\r\n                      dense_shape=[3,2],\r\n                      )\r\n      }, constant_op.constant([[1], [0], [1]])\r\n\r\nfeature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',\r\n                                                                    bucket_size=2,)\r\nfeature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')\r\n\r\nsvm_classifier = svm.SVM(feature_columns=[feature1_w],\r\n                         example_id_column='example_id',\r\n                         l1_regularization=0.0,\r\n                         l2_regularization=0.0)\r\nsvm_classifier.fit(input_fn=input_fn, steps=30)\r\nmetrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)\r\nloss = metrics['loss']\r\naccuracy = metrics['accuracy']\r\n\r\n```"}