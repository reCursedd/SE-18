{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/115997439", "pull_request_review_id": 37583982, "id": 115997439, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExNTk5NzQzOQ==", "diff_hunk": "@@ -0,0 +1,244 @@\n+# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import data_flow_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.platform import test\n+\n+\n+class MapStageTest(test.TestCase):\n+\n+  def testSimple(self):\n+    with self.test_session(use_gpu=True) as sess:\n+      with ops.device('/cpu:0'):\n+        x = array_ops.placeholder(dtypes.float32)\n+        pi = array_ops.placeholder(dtypes.int64)\n+        gi = array_ops.placeholder(dtypes.int64)\n+        v = 2. * (array_ops.zeros([128, 128]) + x)\n+      with ops.device('/gpu:0'):\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32])\n+        stage = stager.put(pi,[v])\n+        k, y = stager.get(gi)\n+        y = math_ops.reduce_max(math_ops.matmul(y, y))\n+      sess.run(stage, feed_dict={x: -1, pi: 0})\n+      for i in range(10):\n+        _, yval = sess.run([stage, y], feed_dict={x: i, pi: i+1, gi:i})\n+        self.assertAllClose(4 * (i - 1) * (i - 1) * 128, yval, rtol=1e-4)\n+\n+  def testMultiple(self):\n+    with self.test_session(use_gpu=True) as sess:\n+      with ops.device('/cpu:0'):\n+        x = array_ops.placeholder(dtypes.float32)\n+        pi = array_ops.placeholder(dtypes.int64)\n+        gi = array_ops.placeholder(dtypes.int64)\n+        v = 2. * (array_ops.zeros([128, 128]) + x)\n+      with ops.device('/gpu:0'):\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32, dtypes.float32])\n+        stage = stager.put(pi,[x, v])\n+        k, (z, y) = stager.get(gi)\n+        y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n+      sess.run(stage, feed_dict={x: -1, pi: 0})\n+      for i in range(10):\n+        _, yval = sess.run([stage, y], feed_dict={x: i, pi: i+1, gi:i})\n+        self.assertAllClose(\n+            4 * (i - 1) * (i - 1) * (i - 1) * 128, yval, rtol=1e-4)\n+\n+  def testDictionary(self):\n+    with self.test_session(use_gpu=True) as sess:\n+      with ops.device('/cpu:0'):\n+        x = array_ops.placeholder(dtypes.float32)\n+        pi = array_ops.placeholder(dtypes.int64)\n+        gi = array_ops.placeholder(dtypes.int64)\n+        v = 2. * (array_ops.zeros([128, 128]) + x)\n+      with ops.device(test.gpu_device_name()):\n+        stager = data_flow_ops.MapStagingArea(\n+            [dtypes.float32, dtypes.float32],\n+            shapes=[[], [128, 128]],\n+            names=['x', 'v'])\n+        stage = stager.put(pi,{'x': x, 'v': v})\n+        key, ret = stager.get(gi)\n+        z = ret['x']\n+        y = ret['v']\n+        y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n+      sess.run(stage, feed_dict={x: -1, pi: 0})\n+      for i in range(10):\n+        _, yval = sess.run([stage, y], feed_dict={x: i, pi: i+1, gi:i})\n+        self.assertAllClose(\n+            4 * (i - 1) * (i - 1) * (i - 1) * 128, yval, rtol=1e-4)\n+\n+  def testColocation1(self):\n+    with ops.device('/cpu:0'):\n+      x = array_ops.placeholder(dtypes.float32)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+    with ops.device('/gpu:0'):\n+      stager = data_flow_ops.MapStagingArea([dtypes.float32])\n+      y = stager.put(1,[v])\n+      self.assertEqual(y.device, '/device:GPU:0')\n+    with ops.device('/cpu:0'):\n+      _, x = stager.get(1)\n+      y = stager.peek(1)\n+      _, z = stager.get()\n+      self.assertEqual(x.device, '/device:CPU:0')\n+      self.assertEqual(y.device, '/device:CPU:0')\n+      self.assertEqual(z.device, '/device:CPU:0')\n+\n+  def testPeek(self):\n+    with ops.device('/cpu:0'):\n+      x = array_ops.placeholder(dtypes.int32, name='x')\n+      pi = array_ops.placeholder(dtypes.int64)\n+      gi = array_ops.placeholder(dtypes.int64)\n+      p = array_ops.placeholder(dtypes.int32, name='p')\n+    with ops.device(test.gpu_device_name()):\n+      stager = data_flow_ops.MapStagingArea([dtypes.int32, ], shapes=[[]])\n+      stage = stager.put(pi,[x])\n+      peek = stager.peek(gi)\n+      size = stager.size()\n+\n+    n = 10\n+\n+    with self.test_session(use_gpu=True) as sess:\n+      for i in range(n):\n+        sess.run(stage, feed_dict={x:i, pi:i})\n+\n+      for i in range(n):\n+        self.assertTrue(sess.run(peek, feed_dict={gi: i}) == i)\n+\n+      self.assertTrue(sess.run(size) == 10)\n+\n+  def testSizeAndClear(self):\n+    with ops.device('/cpu:0'):\n+      x = array_ops.placeholder(dtypes.float32, name='x')\n+      pi = array_ops.placeholder(dtypes.int64)\n+      gi = array_ops.placeholder(dtypes.int64)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+    with ops.device(test.gpu_device_name()):\n+      stager = data_flow_ops.MapStagingArea(\n+          [dtypes.float32, dtypes.float32],\n+          shapes=[[], [128, 128]],\n+          names=['x', 'v'])\n+      stage = stager.put(pi,{'x': x, 'v': v})\n+      size = stager.size()\n+      clear = stager.clear()\n+\n+    with self.test_session(use_gpu=True) as sess:\n+      sess.run(stage, feed_dict={x: -1, pi: 3})\n+      self.assertEqual(sess.run(size), 1)\n+      sess.run(stage, feed_dict={x: -1, pi: 1})\n+      self.assertEqual(sess.run(size), 2)\n+      sess.run(clear)\n+      self.assertEqual(sess.run(size), 0)\n+\n+\n+  def testCapacity(self):\n+    capacity = 3\n+\n+    with ops.device('/cpu:0'):\n+      x = array_ops.placeholder(dtypes.int32, name='x')\n+      pi = array_ops.placeholder(dtypes.int64, name='pi')\n+      gi = array_ops.placeholder(dtypes.int64, name='gi')\n+    with ops.device(test.gpu_device_name()):\n+      stager = data_flow_ops.MapStagingArea([dtypes.int32, ],\n+        capacity=capacity, shapes=[[]])\n+      stage = stager.put(pi,[x])\n+      get = stager.get()\n+      size = stager.size()\n+\n+    from six.moves import queue as Queue\n+    import threading\n+\n+    queue = Queue.Queue()\n+    n = 5\n+    missed = 0\n+\n+    with self.test_session(use_gpu=True) as sess:\n+      # Stage data in a separate thread which will block\n+      # when it hits the staging area's capacity and thus\n+      # not fill the queue with n tokens\n+      def thread_run():\n+        for i in range(n):\n+          sess.run(stage, feed_dict={x: i, pi: i})\n+          queue.put(0)\n+\n+      t = threading.Thread(target=thread_run)\n+      t.start()\n+\n+      # Get tokens from the queue, making notes of when we timeout\n+      for i in range(n):\n+        try:\n+          queue.get(timeout=0.05)\n+        except Queue.Empty:\n+          missed += 1\n+\n+      # We timed out n - capacity times waiting for queue puts\n+      self.assertTrue(missed == n - capacity)\n+\n+      # Clear the staging area out a bit\n+      for i in range(n - capacity):\n+        sess.run(get)\n+\n+      # This should now succeed\n+      t.join()\n+\n+      self.assertTrue(sess.run(size) == capacity)\n+\n+      # Clear out the staging area completely\n+      for i in range(capacity):\n+        sess.run(get)\n+\n+  def testOrdering(self):\n+    import six\n+    import random\n+\n+    with ops.device('/cpu:0'):\n+      x = array_ops.placeholder(dtypes.int32, name='x')\n+      pi = array_ops.placeholder(dtypes.int64, name='pi')\n+      gi = array_ops.placeholder(dtypes.int64, name='gi')\n+    with ops.device(test.gpu_device_name()):\n+      stager = data_flow_ops.MapStagingArea([dtypes.int32, ],\n+        shapes=[[]], ordered=True)\n+      stage = stager.put(pi,[x])\n+      get = stager.get()\n+      size = stager.size()\n+\n+    n = 10\n+\n+    with self.test_session(use_gpu=True) as sess:\n+      # Keys 0..n-1\n+      keys = list(six.moves.range(n))\n+\n+      # Shuffle them for random insert\n+      shuffle_keys = [i for i in keys]\n+      random.shuffle(shuffle_keys)", "path": "tensorflow/python/kernel_tests/map_stage_op_test.py", "position": null, "original_position": 229, "commit_id": "b292353578075c3a31ad438458a74a8538360ec6", "original_commit_id": "92d4d732cab8c6b8db83a38166298ed9a4e8961c", "user": {"login": "sjperkins", "id": 3530212, "node_id": "MDQ6VXNlcjM1MzAyMTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/3530212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sjperkins", "html_url": "https://github.com/sjperkins", "followers_url": "https://api.github.com/users/sjperkins/followers", "following_url": "https://api.github.com/users/sjperkins/following{/other_user}", "gists_url": "https://api.github.com/users/sjperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/sjperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sjperkins/subscriptions", "organizations_url": "https://api.github.com/users/sjperkins/orgs", "repos_url": "https://api.github.com/users/sjperkins/repos", "events_url": "https://api.github.com/users/sjperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/sjperkins/received_events", "type": "User", "site_admin": false}, "body": "https://github.com/tensorflow/tensorflow/pull/9686/commits/ff0c599ed31977df722808d36531548944e35fb6", "created_at": "2017-05-11T14:00:51Z", "updated_at": "2017-05-19T19:22:57Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/9686#discussion_r115997439", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9686", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/115997439"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/9686#discussion_r115997439"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/9686"}}, "body_html": "<p><a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/ff0c599ed31977df722808d36531548944e35fb6/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/ff0c599ed31977df722808d36531548944e35fb6\"><tt>ff0c599</tt></a></p>", "body_text": "ff0c599", "in_reply_to_id": 115594760}