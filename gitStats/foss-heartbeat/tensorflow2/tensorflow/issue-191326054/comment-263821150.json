{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263821150", "html_url": "https://github.com/tensorflow/tensorflow/pull/5813#issuecomment-263821150", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5813", "id": 263821150, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzgyMTE1MA==", "user": {"login": "Syndrome777", "id": 6788909, "node_id": "MDQ6VXNlcjY3ODg5MDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/6788909?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Syndrome777", "html_url": "https://github.com/Syndrome777", "followers_url": "https://api.github.com/users/Syndrome777/followers", "following_url": "https://api.github.com/users/Syndrome777/following{/other_user}", "gists_url": "https://api.github.com/users/Syndrome777/gists{/gist_id}", "starred_url": "https://api.github.com/users/Syndrome777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Syndrome777/subscriptions", "organizations_url": "https://api.github.com/users/Syndrome777/orgs", "repos_url": "https://api.github.com/users/Syndrome777/repos", "events_url": "https://api.github.com/users/Syndrome777/events{/privacy}", "received_events_url": "https://api.github.com/users/Syndrome777/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-30T09:11:03Z", "updated_at": "2016-11-30T16:53:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=684901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lukaszkaiser\">@lukaszkaiser</a>  No, the tests still have failures as last time.<br>\nI'm afraid that the change in this PR will clash with some implementation in tf.contrib. The clash may be in <code>Saver.save</code> of tf.contrib.<br>\nSee this for more detail.<br>\n<a href=\"https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/2766/\" rel=\"nofollow\">https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/2766/</a><br>\nFor example, I use tf.contrib to build a LR model with Adam. After <code>fit</code> action, the model will be saved as <code>ckpt.meta</code> and <code>ckpt</code>. Then restore this model, I get variable name from  <code>ckpt.meta</code>, and it's right for me. But I get different names in <code>ckpt</code>, and two variables have the same name, so the <code>Saver.restore</code> will fail.</p>\n<pre><code># Variable name in 'ckpt.meta'\nglobal_step:0 ()\nlinear//weight/part_0:0 (13, 1)\nlinear/bias_weight/part_0:0 (1,)\nbeta1_power:0 ()\nbeta2_power:0 ()\nlinear//weight/part_0/Adam:0 (13, 1)\nlinear//weight/part_0/Adam_1:0 (13, 1)\nlinear/bias_weight/part_0/Adam:0 (1,)\nlinear/bias_weight/part_0/Adam_1:0 (1,)\n\n# Variable name in 'ckpt' as master's implementation\nglobal_step:0 ()\nlinear//weight (13, 1)\nlinear/bias_weight (1,)\nbeta1_power ()\nbeta2_power ()\nlinear//weight/Adam (13, 1)\nlinear//weight/Adam_1 (13, 1)\nlinear/bias_weight/Adam (1,)\nlinear/bias_weight/Adam_1 (1,)\n\n# Variable name in 'ckpt' when this PR is merged\nglobal_step ()\nlinear//weight/ (13, 1)\nlinear/bias_weight/ (1,)\nbeta1_power ()\nbeta2_powe ()\nlinear//weight/ (13, 1)\nlinear//weight/ (13, 1)\nlinear/bias_weight/ (1,)\nlinear/bias_weight/ (1,)\n\n</code></pre>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">boston_input_fn</span>():\n  boston <span class=\"pl-k\">=</span> tf.contrib.learn.datasets.load_boston()\n  features <span class=\"pl-k\">=</span> tf.cast(tf.reshape(tf.constant(boston.data), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">13</span>]), tf.float32)\n  labels <span class=\"pl-k\">=</span> tf.cast(tf.reshape(tf.constant(boston.target), [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]), tf.float32)\n  <span class=\"pl-k\">return</span> features, labels\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">FeatureColumnTest</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">test</span>.<span class=\"pl-e\">TestCase</span>):\n\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">testTrain</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n    feature_columns <span class=\"pl-k\">=</span> tf.contrib.learn.infer_real_valued_columns_from_input_fn(\n        boston_input_fn)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>optimizer = tf.train.AdamOptimizer(1e-3) #fail!!</span>\n    optimizer <span class=\"pl-k\">=</span> MomentumOptimizer(<span class=\"pl-c1\">1e-3</span>, <span class=\"pl-c1\">0.9</span>)\n    est <span class=\"pl-k\">=</span> tf.contrib.learn.LinearRegressor(<span class=\"pl-v\">feature_columns</span><span class=\"pl-k\">=</span>feature_columns, <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span>optimizer)\n    est.fit(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>boston_input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">'</span>------------------------------------<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">print</span> (est.get_variable_names())\n    _ <span class=\"pl-k\">=</span> est.evaluate(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>boston_input_fn, <span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n  tf.test.main()</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">load_meta</span>(<span class=\"pl-smi\">meta_name</span>, <span class=\"pl-smi\">ckpt_name</span>):\n    sess <span class=\"pl-k\">=</span> tf.Session()\n    new_saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(meta_name)\n    <span class=\"pl-k\">for</span> v <span class=\"pl-k\">in</span> tf.global_variables():\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>for v in tf.all_variables():</span>\n        <span class=\"pl-c1\">print</span>(v.name)\n    <span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>+++++++++++<span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>new_saver.restore(sess, ckpt_name)</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>for v in tf.global_variables():</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>for v in tf.all_variables():</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>    print(v.name)</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">load_ckpt</span>(<span class=\"pl-smi\">ckpt_name</span>):\n    reader <span class=\"pl-k\">=</span> tf.train.NewCheckpointReader(ckpt_name)\n    variable <span class=\"pl-k\">=</span> reader.get_variable_to_shape_map()\n    <span class=\"pl-k\">for</span> k, v <span class=\"pl-k\">in</span> variable.iteritems():\n        <span class=\"pl-c1\">print</span> k, v</pre></div>", "body_text": "@lukaszkaiser  No, the tests still have failures as last time.\nI'm afraid that the change in this PR will clash with some implementation in tf.contrib. The clash may be in Saver.save of tf.contrib.\nSee this for more detail.\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/2766/\nFor example, I use tf.contrib to build a LR model with Adam. After fit action, the model will be saved as ckpt.meta and ckpt. Then restore this model, I get variable name from  ckpt.meta, and it's right for me. But I get different names in ckpt, and two variables have the same name, so the Saver.restore will fail.\n# Variable name in 'ckpt.meta'\nglobal_step:0 ()\nlinear//weight/part_0:0 (13, 1)\nlinear/bias_weight/part_0:0 (1,)\nbeta1_power:0 ()\nbeta2_power:0 ()\nlinear//weight/part_0/Adam:0 (13, 1)\nlinear//weight/part_0/Adam_1:0 (13, 1)\nlinear/bias_weight/part_0/Adam:0 (1,)\nlinear/bias_weight/part_0/Adam_1:0 (1,)\n\n# Variable name in 'ckpt' as master's implementation\nglobal_step:0 ()\nlinear//weight (13, 1)\nlinear/bias_weight (1,)\nbeta1_power ()\nbeta2_power ()\nlinear//weight/Adam (13, 1)\nlinear//weight/Adam_1 (13, 1)\nlinear/bias_weight/Adam (1,)\nlinear/bias_weight/Adam_1 (1,)\n\n# Variable name in 'ckpt' when this PR is merged\nglobal_step ()\nlinear//weight/ (13, 1)\nlinear/bias_weight/ (1,)\nbeta1_power ()\nbeta2_powe ()\nlinear//weight/ (13, 1)\nlinear//weight/ (13, 1)\nlinear/bias_weight/ (1,)\nlinear/bias_weight/ (1,)\n\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef boston_input_fn():\n  boston = tf.contrib.learn.datasets.load_boston()\n  features = tf.cast(tf.reshape(tf.constant(boston.data), [-1, 13]), tf.float32)\n  labels = tf.cast(tf.reshape(tf.constant(boston.target), [-1, 1]), tf.float32)\n  return features, labels\n\n\nclass FeatureColumnTest(tf.test.TestCase):\n\n  def testTrain(self):\n    feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input_fn(\n        boston_input_fn)\n    #optimizer = tf.train.AdamOptimizer(1e-3) #fail!!\n    optimizer = MomentumOptimizer(1e-3, 0.9)\n    est = tf.contrib.learn.LinearRegressor(feature_columns=feature_columns, optimizer=optimizer)\n    est.fit(input_fn=boston_input_fn, steps=1)\n    print ('------------------------------------')\n    print (est.get_variable_names())\n    _ = est.evaluate(input_fn=boston_input_fn, steps=1)\n\n\nif __name__ == '__main__':\n  tf.test.main()\ndef load_meta(meta_name, ckpt_name):\n    sess = tf.Session()\n    new_saver = tf.train.import_meta_graph(meta_name)\n    for v in tf.global_variables():\n    #for v in tf.all_variables():\n        print(v.name)\n    print \"+++++++++++\"\n    #new_saver.restore(sess, ckpt_name)\n    #for v in tf.global_variables():\n    #for v in tf.all_variables():\n    #    print(v.name)\n\ndef load_ckpt(ckpt_name):\n    reader = tf.train.NewCheckpointReader(ckpt_name)\n    variable = reader.get_variable_to_shape_map()\n    for k, v in variable.iteritems():\n        print k, v", "body": "@lukaszkaiser  No, the tests still have failures as last time.\r\nI'm afraid that the change in this PR will clash with some implementation in tf.contrib. The clash may be in `Saver.save` of tf.contrib.\r\nSee this for more detail.\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/2766/\r\nFor example, I use tf.contrib to build a LR model with Adam. After `fit` action, the model will be saved as `ckpt.meta` and `ckpt`. Then restore this model, I get variable name from  `ckpt.meta`, and it's right for me. But I get different names in `ckpt`, and two variables have the same name, so the `Saver.restore` will fail.\r\n```\r\n# Variable name in 'ckpt.meta'\r\nglobal_step:0 ()\r\nlinear//weight/part_0:0 (13, 1)\r\nlinear/bias_weight/part_0:0 (1,)\r\nbeta1_power:0 ()\r\nbeta2_power:0 ()\r\nlinear//weight/part_0/Adam:0 (13, 1)\r\nlinear//weight/part_0/Adam_1:0 (13, 1)\r\nlinear/bias_weight/part_0/Adam:0 (1,)\r\nlinear/bias_weight/part_0/Adam_1:0 (1,)\r\n\r\n# Variable name in 'ckpt' as master's implementation\r\nglobal_step:0 ()\r\nlinear//weight (13, 1)\r\nlinear/bias_weight (1,)\r\nbeta1_power ()\r\nbeta2_power ()\r\nlinear//weight/Adam (13, 1)\r\nlinear//weight/Adam_1 (13, 1)\r\nlinear/bias_weight/Adam (1,)\r\nlinear/bias_weight/Adam_1 (1,)\r\n\r\n# Variable name in 'ckpt' when this PR is merged\r\nglobal_step ()\r\nlinear//weight/ (13, 1)\r\nlinear/bias_weight/ (1,)\r\nbeta1_power ()\r\nbeta2_powe ()\r\nlinear//weight/ (13, 1)\r\nlinear//weight/ (13, 1)\r\nlinear/bias_weight/ (1,)\r\nlinear/bias_weight/ (1,)\r\n\r\n```\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef boston_input_fn():\r\n  boston = tf.contrib.learn.datasets.load_boston()\r\n  features = tf.cast(tf.reshape(tf.constant(boston.data), [-1, 13]), tf.float32)\r\n  labels = tf.cast(tf.reshape(tf.constant(boston.target), [-1, 1]), tf.float32)\r\n  return features, labels\r\n\r\n\r\nclass FeatureColumnTest(tf.test.TestCase):\r\n\r\n  def testTrain(self):\r\n    feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input_fn(\r\n        boston_input_fn)\r\n    #optimizer = tf.train.AdamOptimizer(1e-3) #fail!!\r\n    optimizer = MomentumOptimizer(1e-3, 0.9)\r\n    est = tf.contrib.learn.LinearRegressor(feature_columns=feature_columns, optimizer=optimizer)\r\n    est.fit(input_fn=boston_input_fn, steps=1)\r\n    print ('------------------------------------')\r\n    print (est.get_variable_names())\r\n    _ = est.evaluate(input_fn=boston_input_fn, steps=1)\r\n\r\n\r\nif __name__ == '__main__':\r\n  tf.test.main()\r\n```\r\n```python\r\ndef load_meta(meta_name, ckpt_name):\r\n    sess = tf.Session()\r\n    new_saver = tf.train.import_meta_graph(meta_name)\r\n    for v in tf.global_variables():\r\n    #for v in tf.all_variables():\r\n        print(v.name)\r\n    print \"+++++++++++\"\r\n    #new_saver.restore(sess, ckpt_name)\r\n    #for v in tf.global_variables():\r\n    #for v in tf.all_variables():\r\n    #    print(v.name)\r\n\r\ndef load_ckpt(ckpt_name):\r\n    reader = tf.train.NewCheckpointReader(ckpt_name)\r\n    variable = reader.get_variable_to_shape_map()\r\n    for k, v in variable.iteritems():\r\n        print k, v\r\n```\r\n"}