{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8566", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8566/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8566/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8566/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8566", "id": 215557799, "node_id": "MDU6SXNzdWUyMTU1NTc3OTk=", "number": 8566, "title": "avg_pool() is quietly returning garbage.", "user": {"login": "sullivak", "id": 3643255, "node_id": "MDQ6VXNlcjM2NDMyNTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/3643255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sullivak", "html_url": "https://github.com/sullivak", "followers_url": "https://api.github.com/users/sullivak/followers", "following_url": "https://api.github.com/users/sullivak/following{/other_user}", "gists_url": "https://api.github.com/users/sullivak/gists{/gist_id}", "starred_url": "https://api.github.com/users/sullivak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sullivak/subscriptions", "organizations_url": "https://api.github.com/users/sullivak/orgs", "repos_url": "https://api.github.com/users/sullivak/repos", "events_url": "https://api.github.com/users/sullivak/events{/privacy}", "received_events_url": "https://api.github.com/users/sullivak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-03-20T21:16:22Z", "updated_at": "2017-06-19T18:33:41Z", "closed_at": "2017-06-16T21:45:48Z", "author_association": "NONE", "body_html": "<p>I'm seeing an issue with various networks where, depending on image input size, it either works, crashes with a CUDA_ERROR_ILLEGAL_ADDRESS error, or, most worryingly, runs without issue but visually has strange artifacts (see attached). Does not happen if running on CPU.</p>\n<p>OS: Ubuntu 16.04. Running docker image based on tensorflow/tensorflow:1.0.1-gpu, with nvidia-docker 17.03.0-ce. GPUs: 2x Titan X (Pascal). Was also able to replicate running native on similar machine with same OS and hardware.</p>\n<p>Possibly related github issues:  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"197627477\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/6509\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/6509/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/6509\">#6509</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177594917\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4425\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4425/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4425\">#4425</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"166637669\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/3422\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3422/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/3422\">#3422</a> but these seem to be generally fixed by upgrading to same or earlier tensorflow or cudnn versions.</p>\n<p>ls -l /usr/local/nvidia/lib64/libcud*<br>\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so -&gt; libcuda.so.370.28<br>\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so.1 -&gt; libcuda.so.370.28<br>\n-rw-r--r-- 2 root root 8219624 Sep  2  2016 /usr/local/nvidia/lib64/libcuda.so.370.28</p>\n<p>This code can demonstrate the issues. Changing run_type changes the effect, hopefully each option is clear. Problem here starts after avg_pool, but I've seen with other outputs, e.g. activation functions.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> matplotlib.pyplot <span class=\"pl-k\">as</span> plt\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\nrun_type <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu_artifacts<span class=\"pl-pds\">\"</span></span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> \"gpu_works\" \"gpu_artifacts\" \"gpu_crashes\" \"cpu\"</span>\n<span class=\"pl-k\">if</span> run_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu_works<span class=\"pl-pds\">\"</span></span>:\n    num_gpus <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n    num_rows <span class=\"pl-k\">=</span> <span class=\"pl-c1\">900</span>\n<span class=\"pl-k\">elif</span> run_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu_crashes<span class=\"pl-pds\">\"</span></span>:\n    num_gpus <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n    num_rows <span class=\"pl-k\">=</span> <span class=\"pl-c1\">950</span>\n<span class=\"pl-k\">elif</span> run_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gpu_artifacts<span class=\"pl-pds\">\"</span></span>:\n    num_gpus <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n    num_rows <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\n<span class=\"pl-k\">elif</span> run_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>:\n    num_gpus <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    num_rows <span class=\"pl-k\">=</span> <span class=\"pl-c1\">950</span>\n\nnum_cols <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1900</span>\nxx, yy <span class=\"pl-k\">=</span> np.meshgrid(np.linspace(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span> <span class=\"pl-k\">*</span> np.pi, num_cols), np.linspace(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span> <span class=\"pl-k\">*</span> np.pi, num_rows))\nfaux_img <span class=\"pl-k\">=</span> np.zeros((num_rows, num_cols, <span class=\"pl-c1\">3</span>))\nfaux_img[:, :, <span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> np.sin(xx) <span class=\"pl-k\">+</span> np.cos(yy)\nfaux_img[:, :, <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> np.cos(xx) <span class=\"pl-k\">+</span> np.cos(yy)\nfaux_img[:, :, <span class=\"pl-c1\">2</span>] <span class=\"pl-k\">=</span> np.cos(xx) <span class=\"pl-k\">+</span> np.sin(yy)\n\nplt.figure()\nplt.imshow(faux_img)\nplt.title(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span>)\n\ninput_shape <span class=\"pl-k\">=</span> faux_img.shape\ninput_shape <span class=\"pl-k\">=</span> np.append([<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], input_shape)\ninputs <span class=\"pl-k\">=</span> np.array([faux_img.copy().ravel()])\n\nx_in_ravel <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, [<span class=\"pl-c1\">None</span>, np.prod(input_shape[<span class=\"pl-c1\">1</span>::])], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x_in_ravel<span class=\"pl-pds\">\"</span></span>)\nx_in <span class=\"pl-k\">=</span> tf.reshape(x_in_ravel, input_shape)\nfilt_vals <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">30</span>).astype(np.float32)\nW_0 <span class=\"pl-k\">=</span> tf.Variable(tf.constant(filt_vals))\nstrides <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>]\nconv_out <span class=\"pl-k\">=</span> tf.nn.conv2d(x_in, W_0, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>strides, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>VALID<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>conv1<span class=\"pl-pds\">\"</span></span>)\npool_out <span class=\"pl-k\">=</span> tf.nn.avg_pool(conv_out, <span class=\"pl-v\">ksize</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>strides, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>VALID<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>pool1<span class=\"pl-pds\">\"</span></span>)\n\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">device_count</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>GPU<span class=\"pl-pds\">'</span></span>: num_gpus})\nsess <span class=\"pl-k\">=</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\nsess.run(tf.global_variables_initializer())\nouts_conv, outs_pool <span class=\"pl-k\">=</span> sess.run([conv_out, pool_out], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x_in_ravel: inputs})\n\nfilt_out_fig, filt_out_ax <span class=\"pl-k\">=</span> plt.subplots()\npool_out_fig, pool_out_ax <span class=\"pl-k\">=</span> plt.subplots()\nfilt_out_ax.imshow(outs_conv[<span class=\"pl-c1\">0</span>, :, :, <span class=\"pl-c1\">15</span>])\nfilt_out_ax.set_title(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>conv2d output, looks normal<span class=\"pl-pds\">\"</span></span>)\npool_out_ax.imshow(outs_pool[<span class=\"pl-c1\">0</span>, :, :, <span class=\"pl-c1\">15</span>])\npool_out_ax.set_title(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>avg_pool output, striping artifacts<span class=\"pl-pds\">\"</span></span>)\n\nplt.show()</pre></div>\n<p>Output for run_type = \"gpu_crashes\":</p>\n<pre><code>I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:02:00.0\nTotal memory: 11.90GiB\nFree memory: 11.75GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x37cb5b0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 10.97GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n</code></pre>\n<p>Output plots for run_type = \"gpu_artifacts\":<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3643255/24121814/e47dd59c-0d76-11e7-9b35-4ee1327c0230.png\"><img src=\"https://cloud.githubusercontent.com/assets/3643255/24121814/e47dd59c-0d76-11e7-9b35-4ee1327c0230.png\" alt=\"input\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3643255/24121821/e806480c-0d76-11e7-839d-b94da94a3c75.png\"><img src=\"https://cloud.githubusercontent.com/assets/3643255/24121821/e806480c-0d76-11e7-839d-b94da94a3c75.png\" alt=\"conv_out\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/3643255/24121824/e9f23176-0d76-11e7-931f-62bb49bf2abd.png\"><img src=\"https://cloud.githubusercontent.com/assets/3643255/24121824/e9f23176-0d76-11e7-931f-62bb49bf2abd.png\" alt=\"pool_out\" style=\"max-width:100%;\"></a></p>", "body_text": "I'm seeing an issue with various networks where, depending on image input size, it either works, crashes with a CUDA_ERROR_ILLEGAL_ADDRESS error, or, most worryingly, runs without issue but visually has strange artifacts (see attached). Does not happen if running on CPU.\nOS: Ubuntu 16.04. Running docker image based on tensorflow/tensorflow:1.0.1-gpu, with nvidia-docker 17.03.0-ce. GPUs: 2x Titan X (Pascal). Was also able to replicate running native on similar machine with same OS and hardware.\nPossibly related github issues:  #6509, #4425, #3422 but these seem to be generally fixed by upgrading to same or earlier tensorflow or cudnn versions.\nls -l /usr/local/nvidia/lib64/libcud*\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so -> libcuda.so.370.28\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so.1 -> libcuda.so.370.28\n-rw-r--r-- 2 root root 8219624 Sep  2  2016 /usr/local/nvidia/lib64/libcuda.so.370.28\nThis code can demonstrate the issues. Changing run_type changes the effect, hopefully each option is clear. Problem here starts after avg_pool, but I've seen with other outputs, e.g. activation functions.\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\nrun_type = \"gpu_artifacts\"  # \"gpu_works\" \"gpu_artifacts\" \"gpu_crashes\" \"cpu\"\nif run_type == \"gpu_works\":\n    num_gpus = 1\n    num_rows = 900\nelif run_type == \"gpu_crashes\":\n    num_gpus = 1\n    num_rows = 950\nelif run_type == \"gpu_artifacts\":\n    num_gpus = 1\n    num_rows = 1000\nelif run_type == \"cpu\":\n    num_gpus = 0\n    num_rows = 950\n\nnum_cols = 1900\nxx, yy = np.meshgrid(np.linspace(0, 2 * np.pi, num_cols), np.linspace(0, 2 * np.pi, num_rows))\nfaux_img = np.zeros((num_rows, num_cols, 3))\nfaux_img[:, :, 0] = np.sin(xx) + np.cos(yy)\nfaux_img[:, :, 1] = np.cos(xx) + np.cos(yy)\nfaux_img[:, :, 2] = np.cos(xx) + np.sin(yy)\n\nplt.figure()\nplt.imshow(faux_img)\nplt.title(\"input\")\n\ninput_shape = faux_img.shape\ninput_shape = np.append([-1], input_shape)\ninputs = np.array([faux_img.copy().ravel()])\n\nx_in_ravel = tf.placeholder(tf.float32, [None, np.prod(input_shape[1::])], name=\"x_in_ravel\")\nx_in = tf.reshape(x_in_ravel, input_shape)\nfilt_vals = np.random.randn(5, 5, 3, 30).astype(np.float32)\nW_0 = tf.Variable(tf.constant(filt_vals))\nstrides = [1, 1, 1, 1]\nconv_out = tf.nn.conv2d(x_in, W_0, strides=strides, padding=\"VALID\", name=\"conv1\")\npool_out = tf.nn.avg_pool(conv_out, ksize=[1, 9, 9, 1], strides=strides, padding=\"VALID\", name=\"pool1\")\n\nconfig = tf.ConfigProto(device_count={'GPU': num_gpus})\nsess = tf.Session(config=config)\nsess.run(tf.global_variables_initializer())\nouts_conv, outs_pool = sess.run([conv_out, pool_out], feed_dict={x_in_ravel: inputs})\n\nfilt_out_fig, filt_out_ax = plt.subplots()\npool_out_fig, pool_out_ax = plt.subplots()\nfilt_out_ax.imshow(outs_conv[0, :, :, 15])\nfilt_out_ax.set_title(\"conv2d output, looks normal\")\npool_out_ax.imshow(outs_pool[0, :, :, 15])\npool_out_ax.set_title(\"avg_pool output, striping artifacts\")\n\nplt.show()\nOutput for run_type = \"gpu_crashes\":\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:02:00.0\nTotal memory: 11.90GiB\nFree memory: 11.75GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x37cb5b0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:01:00.0\nTotal memory: 11.90GiB\nFree memory: 10.97GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n\nOutput plots for run_type = \"gpu_artifacts\":", "body": "I'm seeing an issue with various networks where, depending on image input size, it either works, crashes with a CUDA_ERROR_ILLEGAL_ADDRESS error, or, most worryingly, runs without issue but visually has strange artifacts (see attached). Does not happen if running on CPU.\r\n\r\nOS: Ubuntu 16.04. Running docker image based on tensorflow/tensorflow:1.0.1-gpu, with nvidia-docker 17.03.0-ce. GPUs: 2x Titan X (Pascal). Was also able to replicate running native on similar machine with same OS and hardware.\r\n\r\nPossibly related github issues:  #6509, #4425, #3422 but these seem to be generally fixed by upgrading to same or earlier tensorflow or cudnn versions.\r\n\r\nls -l /usr/local/nvidia/lib64/libcud*\r\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so -> libcuda.so.370.28\r\nlrwxrwxrwx 1  999  999      17 Nov 21 20:42 /usr/local/nvidia/lib64/libcuda.so.1 -> libcuda.so.370.28\r\n-rw-r--r-- 2 root root 8219624 Sep  2  2016 /usr/local/nvidia/lib64/libcuda.so.370.28\r\n\r\nThis code can demonstrate the issues. Changing run_type changes the effect, hopefully each option is clear. Problem here starts after avg_pool, but I've seen with other outputs, e.g. activation functions.\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nrun_type = \"gpu_artifacts\"  # \"gpu_works\" \"gpu_artifacts\" \"gpu_crashes\" \"cpu\"\r\nif run_type == \"gpu_works\":\r\n    num_gpus = 1\r\n    num_rows = 900\r\nelif run_type == \"gpu_crashes\":\r\n    num_gpus = 1\r\n    num_rows = 950\r\nelif run_type == \"gpu_artifacts\":\r\n    num_gpus = 1\r\n    num_rows = 1000\r\nelif run_type == \"cpu\":\r\n    num_gpus = 0\r\n    num_rows = 950\r\n\r\nnum_cols = 1900\r\nxx, yy = np.meshgrid(np.linspace(0, 2 * np.pi, num_cols), np.linspace(0, 2 * np.pi, num_rows))\r\nfaux_img = np.zeros((num_rows, num_cols, 3))\r\nfaux_img[:, :, 0] = np.sin(xx) + np.cos(yy)\r\nfaux_img[:, :, 1] = np.cos(xx) + np.cos(yy)\r\nfaux_img[:, :, 2] = np.cos(xx) + np.sin(yy)\r\n\r\nplt.figure()\r\nplt.imshow(faux_img)\r\nplt.title(\"input\")\r\n\r\ninput_shape = faux_img.shape\r\ninput_shape = np.append([-1], input_shape)\r\ninputs = np.array([faux_img.copy().ravel()])\r\n\r\nx_in_ravel = tf.placeholder(tf.float32, [None, np.prod(input_shape[1::])], name=\"x_in_ravel\")\r\nx_in = tf.reshape(x_in_ravel, input_shape)\r\nfilt_vals = np.random.randn(5, 5, 3, 30).astype(np.float32)\r\nW_0 = tf.Variable(tf.constant(filt_vals))\r\nstrides = [1, 1, 1, 1]\r\nconv_out = tf.nn.conv2d(x_in, W_0, strides=strides, padding=\"VALID\", name=\"conv1\")\r\npool_out = tf.nn.avg_pool(conv_out, ksize=[1, 9, 9, 1], strides=strides, padding=\"VALID\", name=\"pool1\")\r\n\r\nconfig = tf.ConfigProto(device_count={'GPU': num_gpus})\r\nsess = tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\nouts_conv, outs_pool = sess.run([conv_out, pool_out], feed_dict={x_in_ravel: inputs})\r\n\r\nfilt_out_fig, filt_out_ax = plt.subplots()\r\npool_out_fig, pool_out_ax = plt.subplots()\r\nfilt_out_ax.imshow(outs_conv[0, :, :, 15])\r\nfilt_out_ax.set_title(\"conv2d output, looks normal\")\r\npool_out_ax.imshow(outs_pool[0, :, :, 15])\r\npool_out_ax.set_title(\"avg_pool output, striping artifacts\")\r\n\r\nplt.show()\r\n```\r\n\r\nOutput for run_type = \"gpu_crashes\":\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:02:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.75GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x37cb5b0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\r\n```\r\n\r\nOutput plots for run_type = \"gpu_artifacts\":\r\n![input](https://cloud.githubusercontent.com/assets/3643255/24121814/e47dd59c-0d76-11e7-9b35-4ee1327c0230.png)\r\n![conv_out](https://cloud.githubusercontent.com/assets/3643255/24121821/e806480c-0d76-11e7-839d-b94da94a3c75.png)\r\n![pool_out](https://cloud.githubusercontent.com/assets/3643255/24121824/e9f23176-0d76-11e7-931f-62bb49bf2abd.png)\r\n\r\n\r\n"}