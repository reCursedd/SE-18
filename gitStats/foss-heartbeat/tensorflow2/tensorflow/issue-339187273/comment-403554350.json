{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/403554350", "html_url": "https://github.com/tensorflow/tensorflow/issues/20619#issuecomment-403554350", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20619", "id": 403554350, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzU1NDM1MA==", "user": {"login": "tanzhenyu", "id": 15220929, "node_id": "MDQ6VXNlcjE1MjIwOTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15220929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanzhenyu", "html_url": "https://github.com/tanzhenyu", "followers_url": "https://api.github.com/users/tanzhenyu/followers", "following_url": "https://api.github.com/users/tanzhenyu/following{/other_user}", "gists_url": "https://api.github.com/users/tanzhenyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanzhenyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanzhenyu/subscriptions", "organizations_url": "https://api.github.com/users/tanzhenyu/orgs", "repos_url": "https://api.github.com/users/tanzhenyu/repos", "events_url": "https://api.github.com/users/tanzhenyu/events{/privacy}", "received_events_url": "https://api.github.com/users/tanzhenyu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-09T17:19:57Z", "updated_at": "2018-07-09T17:19:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I suspect the problem is coming from here:<br>\n<a href=\"https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1037\">https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1037</a><br>\nwhere it asked the optimizer for lr. On the other hand native AdamOptimizer uses _lr:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/adam.py#L94\">https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/adam.py#L94</a></p>\n<p>I wonder if we could make a check in the callback, if it's keras optimizer, adjust self.lr, if it's tf optimizer, adjust self._lr. else raise error.</p>", "body_text": "I suspect the problem is coming from here:\nhttps://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1037\nwhere it asked the optimizer for lr. On the other hand native AdamOptimizer uses _lr:\nhttps://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/adam.py#L94\nI wonder if we could make a check in the callback, if it's keras optimizer, adjust self.lr, if it's tf optimizer, adjust self._lr. else raise error.", "body": "I suspect the problem is coming from here:\r\nhttps://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1037\r\nwhere it asked the optimizer for lr. On the other hand native AdamOptimizer uses _lr:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/training/adam.py#L94\r\n\r\nI wonder if we could make a check in the callback, if it's keras optimizer, adjust self.lr, if it's tf optimizer, adjust self._lr. else raise error."}