{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/438892502", "html_url": "https://github.com/tensorflow/tensorflow/issues/20619#issuecomment-438892502", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20619", "id": 438892502, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODg5MjUwMg==", "user": {"login": "malikaltakrori", "id": 25109412, "node_id": "MDQ6VXNlcjI1MTA5NDEy", "avatar_url": "https://avatars2.githubusercontent.com/u/25109412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/malikaltakrori", "html_url": "https://github.com/malikaltakrori", "followers_url": "https://api.github.com/users/malikaltakrori/followers", "following_url": "https://api.github.com/users/malikaltakrori/following{/other_user}", "gists_url": "https://api.github.com/users/malikaltakrori/gists{/gist_id}", "starred_url": "https://api.github.com/users/malikaltakrori/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/malikaltakrori/subscriptions", "organizations_url": "https://api.github.com/users/malikaltakrori/orgs", "repos_url": "https://api.github.com/users/malikaltakrori/repos", "events_url": "https://api.github.com/users/malikaltakrori/events{/privacy}", "received_events_url": "https://api.github.com/users/malikaltakrori/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T02:23:15Z", "updated_at": "2018-11-15T02:49:31Z", "author_association": "NONE", "body_html": "<p>I faced a very similar problem, but while using SGD optimizer.<br>\nThe problem for me was in the file <strong>[condaEnv]\\Lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py</strong>, specifically, in function <strong>on_epoch_begin</strong>. I changed the code (I know it is bad) to this:</p>\n<pre><code>def on_epoch_begin(self, epoch, logs=None):\n    # if not hasattr(self.model.optimizer, 'lr'):   &lt;=== Original  self.model.optimizer.optimizer._learning_rate\n    if not hasattr(self.model.optimizer.optimizer, '_learning_rate'):\n      raise ValueError('Optimizer must have a \"lr\" attribute.')\n    try:  # new API\n      # lr = float(K.get_value(self.model.optimizer.lr))\n      lr = float(self.model.optimizer.optimizer._learning_rate)\n      lr = self.schedule(epoch, lr)\n    except TypeError:  # Support for old API for backward compatibility\n      lr = self.schedule(epoch)\n    if not isinstance(lr, (float, np.float32, np.float64)):\n      raise ValueError('The output of the \"schedule\" function '\n                       'should be float.')\n    # K.set_value(self.model.optimizer.lr, lr)\n    self.model.optimizer.optimizer._learning_rate = lr\n    if self.verbose &gt; 0:\n      print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n            'rate to %s.' % (epoch + 1, lr))\n</code></pre>\n<p>It works for me.</p>", "body_text": "I faced a very similar problem, but while using SGD optimizer.\nThe problem for me was in the file [condaEnv]\\Lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py, specifically, in function on_epoch_begin. I changed the code (I know it is bad) to this:\ndef on_epoch_begin(self, epoch, logs=None):\n    # if not hasattr(self.model.optimizer, 'lr'):   <=== Original  self.model.optimizer.optimizer._learning_rate\n    if not hasattr(self.model.optimizer.optimizer, '_learning_rate'):\n      raise ValueError('Optimizer must have a \"lr\" attribute.')\n    try:  # new API\n      # lr = float(K.get_value(self.model.optimizer.lr))\n      lr = float(self.model.optimizer.optimizer._learning_rate)\n      lr = self.schedule(epoch, lr)\n    except TypeError:  # Support for old API for backward compatibility\n      lr = self.schedule(epoch)\n    if not isinstance(lr, (float, np.float32, np.float64)):\n      raise ValueError('The output of the \"schedule\" function '\n                       'should be float.')\n    # K.set_value(self.model.optimizer.lr, lr)\n    self.model.optimizer.optimizer._learning_rate = lr\n    if self.verbose > 0:\n      print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n            'rate to %s.' % (epoch + 1, lr))\n\nIt works for me.", "body": "I faced a very similar problem, but while using SGD optimizer. \r\nThe problem for me was in the file **[condaEnv]\\Lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py**, specifically, in function **on_epoch_begin**. I changed the code (I know it is bad) to this: \r\n\r\n```\r\ndef on_epoch_begin(self, epoch, logs=None):\r\n    # if not hasattr(self.model.optimizer, 'lr'):   <=== Original  self.model.optimizer.optimizer._learning_rate\r\n    if not hasattr(self.model.optimizer.optimizer, '_learning_rate'):\r\n      raise ValueError('Optimizer must have a \"lr\" attribute.')\r\n    try:  # new API\r\n      # lr = float(K.get_value(self.model.optimizer.lr))\r\n      lr = float(self.model.optimizer.optimizer._learning_rate)\r\n      lr = self.schedule(epoch, lr)\r\n    except TypeError:  # Support for old API for backward compatibility\r\n      lr = self.schedule(epoch)\r\n    if not isinstance(lr, (float, np.float32, np.float64)):\r\n      raise ValueError('The output of the \"schedule\" function '\r\n                       'should be float.')\r\n    # K.set_value(self.model.optimizer.lr, lr)\r\n    self.model.optimizer.optimizer._learning_rate = lr\r\n    if self.verbose > 0:\r\n      print('\\nEpoch %05d: LearningRateScheduler reducing learning '\r\n            'rate to %s.' % (epoch + 1, lr))\r\n```\r\n\r\nIt works for me. "}