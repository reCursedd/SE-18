{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5543", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5543/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5543/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5543/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5543", "id": 188743911, "node_id": "MDU6SXNzdWUxODg3NDM5MTE=", "number": 5543, "title": "Constant folding doesn't remove control edges", "user": {"login": "DavidNorman", "id": 606831, "node_id": "MDQ6VXNlcjYwNjgzMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/606831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidNorman", "html_url": "https://github.com/DavidNorman", "followers_url": "https://api.github.com/users/DavidNorman/followers", "following_url": "https://api.github.com/users/DavidNorman/following{/other_user}", "gists_url": "https://api.github.com/users/DavidNorman/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidNorman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidNorman/subscriptions", "organizations_url": "https://api.github.com/users/DavidNorman/orgs", "repos_url": "https://api.github.com/users/DavidNorman/repos", "events_url": "https://api.github.com/users/DavidNorman/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidNorman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "keveman", "id": 229914, "node_id": "MDQ6VXNlcjIyOTkxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/229914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keveman", "html_url": "https://github.com/keveman", "followers_url": "https://api.github.com/users/keveman/followers", "following_url": "https://api.github.com/users/keveman/following{/other_user}", "gists_url": "https://api.github.com/users/keveman/gists{/gist_id}", "starred_url": "https://api.github.com/users/keveman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keveman/subscriptions", "organizations_url": "https://api.github.com/users/keveman/orgs", "repos_url": "https://api.github.com/users/keveman/repos", "events_url": "https://api.github.com/users/keveman/events{/privacy}", "received_events_url": "https://api.github.com/users/keveman/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "keveman", "id": 229914, "node_id": "MDQ6VXNlcjIyOTkxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/229914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keveman", "html_url": "https://github.com/keveman", "followers_url": "https://api.github.com/users/keveman/followers", "following_url": "https://api.github.com/users/keveman/following{/other_user}", "gists_url": "https://api.github.com/users/keveman/gists{/gist_id}", "starred_url": "https://api.github.com/users/keveman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keveman/subscriptions", "organizations_url": "https://api.github.com/users/keveman/orgs", "repos_url": "https://api.github.com/users/keveman/repos", "events_url": "https://api.github.com/users/keveman/events{/privacy}", "received_events_url": "https://api.github.com/users/keveman/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2016-11-11T11:50:59Z", "updated_at": "2017-02-15T10:55:39Z", "closed_at": "2017-02-15T10:55:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I believe that when constant folding takes place, and a section of a graph is replaced by a constant, that only the data output edge of the replaced node is removed.</p>\n<p>I believe that I can see that a graph of nodes ending up in a Div (part of the gradient generation bit) is replaced by a Const.  The output of the Div goes to a Mul, and this is changed to the new const correctly.</p>\n<p>However, there is a control output from the Div going to a Const (not sure why, but it is).  This is not changed to the Div replacement.  Consequently the dead node pruning doesn't remove the original Div.</p>\n<p>Here is some trace:</p>\n<p>During the constant folding:</p>\n<p>Graph Before #nodes 67 #edges 109<br>\nGraph Constant graph #nodes 32 #edges 42<br>\nConstant foldable 32 : 67</p>\n<p>Replacing {name:'gradients/Mean_grad/truediv' id:28 op device:{/job:localhost/replica:0/task:0/device:ipu:0} def:{gradients/Mean_grad/truediv = Div[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"](gradients/Mean_grad/Tile, gradients/Mean_grad/Cast)}} :: 0 with a constant<br>\nReplacing edge to gradients/Square_grad/mul_1:0</p>\n<p>During the post constant folding pruning:</p>\n<p>PruneForReverseReachability: gradients/Square_grad/mul_1 &lt;- gradients/Mean_grad/truediv/_0__cf__1<br>\nPruneForReverseReachability: gradients/Square_grad/mul/x &lt;- gradients/Mean_grad/truediv</p>\n<p>After the pruning:</p>\n<p>Graph ConstFolding #nodes 68 #edges 110</p>\n<p>When the graph is passed to the device, it contains:</p>\n<p>Node: gradients/Square_grad/mul/x = Const<a href=\"%5Egradients/Mean_grad/truediv\">dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [] values: 2&gt;, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"</a></p>", "body_text": "I believe that when constant folding takes place, and a section of a graph is replaced by a constant, that only the data output edge of the replaced node is removed.\nI believe that I can see that a graph of nodes ending up in a Div (part of the gradient generation bit) is replaced by a Const.  The output of the Div goes to a Mul, and this is changed to the new const correctly.\nHowever, there is a control output from the Div going to a Const (not sure why, but it is).  This is not changed to the Div replacement.  Consequently the dead node pruning doesn't remove the original Div.\nHere is some trace:\nDuring the constant folding:\nGraph Before #nodes 67 #edges 109\nGraph Constant graph #nodes 32 #edges 42\nConstant foldable 32 : 67\nReplacing {name:'gradients/Mean_grad/truediv' id:28 op device:{/job:localhost/replica:0/task:0/device:ipu:0} def:{gradients/Mean_grad/truediv = Div[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"](gradients/Mean_grad/Tile, gradients/Mean_grad/Cast)}} :: 0 with a constant\nReplacing edge to gradients/Square_grad/mul_1:0\nDuring the post constant folding pruning:\nPruneForReverseReachability: gradients/Square_grad/mul_1 <- gradients/Mean_grad/truediv/_0__cf__1\nPruneForReverseReachability: gradients/Square_grad/mul/x <- gradients/Mean_grad/truediv\nAfter the pruning:\nGraph ConstFolding #nodes 68 #edges 110\nWhen the graph is passed to the device, it contains:\nNode: gradients/Square_grad/mul/x = Constdtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"", "body": "I believe that when constant folding takes place, and a section of a graph is replaced by a constant, that only the data output edge of the replaced node is removed.  \r\n\r\nI believe that I can see that a graph of nodes ending up in a Div (part of the gradient generation bit) is replaced by a Const.  The output of the Div goes to a Mul, and this is changed to the new const correctly.\r\n\r\nHowever, there is a control output from the Div going to a Const (not sure why, but it is).  This is not changed to the Div replacement.  Consequently the dead node pruning doesn't remove the original Div.  \r\n\r\nHere is some trace:\r\n\r\nDuring the constant folding:\r\n\r\nGraph Before #nodes 67 #edges 109\r\nGraph Constant graph #nodes 32 #edges 42\r\nConstant foldable 32 : 67\r\n\r\nReplacing {name:'gradients/Mean_grad/truediv' id:28 op device:{/job:localhost/replica:0/task:0/device:ipu:0} def:{gradients/Mean_grad/truediv = Div[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"](gradients/Mean_grad/Tile, gradients/Mean_grad/Cast)}} :: 0 with a constant\r\nReplacing edge to gradients/Square_grad/mul_1:0\r\n\r\nDuring the post constant folding pruning:\r\n\r\nPruneForReverseReachability: gradients/Square_grad/mul_1 <- gradients/Mean_grad/truediv/_0__cf__1\r\nPruneForReverseReachability: gradients/Square_grad/mul/x <- gradients/Mean_grad/truediv\r\n\r\nAfter the pruning:\r\n\r\nGraph ConstFolding #nodes 68 #edges 110\r\n\r\n\r\nWhen the graph is passed to the device, it contains:\r\n\r\nNode: gradients/Square_grad/mul/x = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 2>, _device=\"/job:localhost/replica:0/task:0/device:ipu:0\"](^gradients/Mean_grad/truediv)\r\n\r\n"}