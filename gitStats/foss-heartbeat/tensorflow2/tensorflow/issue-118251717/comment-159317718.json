{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/159317718", "html_url": "https://github.com/tensorflow/tensorflow/issues/323#issuecomment-159317718", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/323", "id": 159317718, "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTMxNzcxOA==", "user": {"login": "jpiabrantes", "id": 2369107, "node_id": "MDQ6VXNlcjIzNjkxMDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2369107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpiabrantes", "html_url": "https://github.com/jpiabrantes", "followers_url": "https://api.github.com/users/jpiabrantes/followers", "following_url": "https://api.github.com/users/jpiabrantes/following{/other_user}", "gists_url": "https://api.github.com/users/jpiabrantes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpiabrantes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpiabrantes/subscriptions", "organizations_url": "https://api.github.com/users/jpiabrantes/orgs", "repos_url": "https://api.github.com/users/jpiabrantes/repos", "events_url": "https://api.github.com/users/jpiabrantes/events{/privacy}", "received_events_url": "https://api.github.com/users/jpiabrantes/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-24T16:12:12Z", "updated_at": "2015-11-24T16:15:57Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15737127\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vincentvanhoucke\">@vincentvanhoucke</a> Thank you for your help. I tried to debug it following your advices:</p>\n<p>I ran the algorithm with learning_rate = 0. Didn't raise any error.<br>\nI then tried to run the algorithm with different learning rates (lr) and obtained the following results:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/9f84472d22a5ce059aa9d8679c930256fa0ba47e/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f31353835333830352f6c6561726e696e675f72617465732e706e67\"><img src=\"https://camo.githubusercontent.com/9f84472d22a5ce059aa9d8679c930256fa0ba47e/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f31353835333830352f6c6561726e696e675f72617465732e706e67\" alt=\"lr_results\" data-canonical-src=\"https://dl.dropboxusercontent.com/u/15853805/learning_rates.png\" style=\"max-width:100%;\"></a></p>\n<p>All the learning rates, but the <code>lr = 1E-8</code>, made the program raise the error. The learning rate 1E-8 didn't learn anything.</p>\n<p>Basically I have a neural network with one hidden layer:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">model</span>(<span class=\"pl-smi\">data</span>, <span class=\"pl-smi\">train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    hidden <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(data, fc1_weights) <span class=\"pl-k\">+</span> fc1_biases)\n    <span class=\"pl-k\">return</span> tf.matmul(hidden, fc2_weights) <span class=\"pl-k\">+</span> fc2_biases</pre></div>\n<p>And a RMS loss function to optimize:</p>\n<div class=\"highlight highlight-source-python\"><pre>train_prediction <span class=\"pl-k\">=</span> model(train_data_node, <span class=\"pl-c1\">True</span>)\nloss <span class=\"pl-k\">=</span> tf.reduce_mean(tf.sqrt(tf.pow(((tf.sub(train_prediction,train_labels_node))),<span class=\"pl-c1\">2</span>)),<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>RMS<span class=\"pl-pds\">'</span></span>)\nbatch_index <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>)\nlearning_rate <span class=\"pl-k\">=</span> tf.train.exponential_decay(\n      <span class=\"pl-c1\">1E-8</span>,                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Base learning rate.</span>\n      batch_index <span class=\"pl-k\">*</span> <span class=\"pl-c1\">BATCH_SIZE</span>,  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Current index into the dataset.</span>\n      train_size,          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decay step.</span>\n      <span class=\"pl-c1\">0.95</span>,                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decay rate.</span>\n      <span class=\"pl-v\">staircase</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\noptimizer <span class=\"pl-k\">=</span> tf.train.MomentumOptimizer(learning_rate,<span class=\"pl-c1\">0.9</span>).minimize(loss, <span class=\"pl-v\">global_step</span><span class=\"pl-k\">=</span>batch_index) </pre></div>\n<p>My full code is here: <a href=\"https://gist.github.com/jpiabrantes/321aff988eaa00dfefcb\">gist</a> .<br>\nIf you want to run it you will also need the data that is [here](/home/joao/Dropbox/data analysis/rossman/results/results1/nn_train.dat<br>\n/home/joao/Dropbox/data analysis/rossman/results/results1/nn_val.dat) and <a href=\"https://dl.dropboxusercontent.com/u/15853805/nn_train.dat\" rel=\"nofollow\">here</a>.</p>", "body_text": "@vincentvanhoucke Thank you for your help. I tried to debug it following your advices:\nI ran the algorithm with learning_rate = 0. Didn't raise any error.\nI then tried to run the algorithm with different learning rates (lr) and obtained the following results:\n\nAll the learning rates, but the lr = 1E-8, made the program raise the error. The learning rate 1E-8 didn't learn anything.\nBasically I have a neural network with one hidden layer:\ndef model(data, train=False):\n    hidden = tf.nn.relu(tf.matmul(data, fc1_weights) + fc1_biases)\n    return tf.matmul(hidden, fc2_weights) + fc2_biases\nAnd a RMS loss function to optimize:\ntrain_prediction = model(train_data_node, True)\nloss = tf.reduce_mean(tf.sqrt(tf.pow(((tf.sub(train_prediction,train_labels_node))),2)),name='RMS')\nbatch_index = tf.Variable(0)\nlearning_rate = tf.train.exponential_decay(\n      1E-8,                # Base learning rate.\n      batch_index * BATCH_SIZE,  # Current index into the dataset.\n      train_size,          # Decay step.\n      0.95,                # Decay rate.\n      staircase=True)\noptimizer = tf.train.MomentumOptimizer(learning_rate,0.9).minimize(loss, global_step=batch_index) \nMy full code is here: gist .\nIf you want to run it you will also need the data that is [here](/home/joao/Dropbox/data analysis/rossman/results/results1/nn_train.dat\n/home/joao/Dropbox/data analysis/rossman/results/results1/nn_val.dat) and here.", "body": "@vincentvanhoucke Thank you for your help. I tried to debug it following your advices:\n\nI ran the algorithm with learning_rate = 0. Didn't raise any error.\nI then tried to run the algorithm with different learning rates (lr) and obtained the following results:\n\n![lr_results](https://dl.dropboxusercontent.com/u/15853805/learning_rates.png)\n\nAll the learning rates, but the `lr = 1E-8`, made the program raise the error. The learning rate 1E-8 didn't learn anything.\n\nBasically I have a neural network with one hidden layer:\n\n``` python\ndef model(data, train=False):\n    hidden = tf.nn.relu(tf.matmul(data, fc1_weights) + fc1_biases)\n    return tf.matmul(hidden, fc2_weights) + fc2_biases\n```\n\nAnd a RMS loss function to optimize:\n\n``` python\ntrain_prediction = model(train_data_node, True)\nloss = tf.reduce_mean(tf.sqrt(tf.pow(((tf.sub(train_prediction,train_labels_node))),2)),name='RMS')\nbatch_index = tf.Variable(0)\nlearning_rate = tf.train.exponential_decay(\n      1E-8,                # Base learning rate.\n      batch_index * BATCH_SIZE,  # Current index into the dataset.\n      train_size,          # Decay step.\n      0.95,                # Decay rate.\n      staircase=True)\noptimizer = tf.train.MomentumOptimizer(learning_rate,0.9).minimize(loss, global_step=batch_index) \n```\n\nMy full code is here: [gist](https://gist.github.com/jpiabrantes/321aff988eaa00dfefcb) .\nIf you want to run it you will also need the data that is [here](/home/joao/Dropbox/data analysis/rossman/results/results1/nn_train.dat\n/home/joao/Dropbox/data analysis/rossman/results/results1/nn_val.dat) and [here](https://dl.dropboxusercontent.com/u/15853805/nn_train.dat).\n"}