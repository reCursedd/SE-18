{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17050", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17050/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17050/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17050/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17050", "id": 297551524, "node_id": "MDU6SXNzdWUyOTc1NTE1MjQ=", "number": 17050, "title": "Distributed FIFOQueue with shared_name is not shared", "user": {"login": "illeatmyhat", "id": 5661986, "node_id": "MDQ6VXNlcjU2NjE5ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5661986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/illeatmyhat", "html_url": "https://github.com/illeatmyhat", "followers_url": "https://api.github.com/users/illeatmyhat/followers", "following_url": "https://api.github.com/users/illeatmyhat/following{/other_user}", "gists_url": "https://api.github.com/users/illeatmyhat/gists{/gist_id}", "starred_url": "https://api.github.com/users/illeatmyhat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/illeatmyhat/subscriptions", "organizations_url": "https://api.github.com/users/illeatmyhat/orgs", "repos_url": "https://api.github.com/users/illeatmyhat/repos", "events_url": "https://api.github.com/users/illeatmyhat/events{/privacy}", "received_events_url": "https://api.github.com/users/illeatmyhat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-15T18:34:45Z", "updated_at": "2018-02-20T21:48:03Z", "closed_at": "2018-02-20T21:48:03Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Environment</strong>:<br>\nShared Cluster</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nRHEL Server 7.2</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\npip install tensorflow-gpu</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\nv1.5.0-0-g37aa430d84 1.5.0</li>\n<li><strong>Python version</strong>:<br>\n3.6</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n9.0/7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nN/A -- GPU not allocated</li>\n</ul>\n<p>I am attempting to use a <code>FIFOQueue</code> to signal the parameter servers to shut down on a multi-machine shared cluster, based on <a href=\"https://stackoverflow.com/questions/39810356/shut-down-server-in-tensorflow/40186129#40186129\" rel=\"nofollow\">this</a> <a href=\"https://gist.github.com/yaroslavvb/ea1b1bae0a75c4aae593df7eca72d9ca\">example</a>. After some testing, I believe that <code>shared_name</code> simply doesn't seem to do anything--even after removing the <code>dequeue()</code> operations, the number of elements in the <code>FIFOQueue</code> don't correlate to the number of workers.</p>\n<p>Minimum Reproducible Code</p>\n<pre><code># for example\ncluster = tf.train.ClusterSpec({\n    'ps': ['192.168.1.1:36598'],\n    'worker': ['192.168.1.2:40596', '192.168.1.3:47324', '192.168.1.4:38923']\n})\n# ... #\nserver = tf.train.Server(cluster, job_name=job_name, task_index=task)\n\n# using server.join() causes cluster management headaches\n# use a FIFOQueue to tell the parameter server to shutdown\nif job_name == 'ps':\n    with tf.device('/job:ps/task:%d' % task):\n        queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\n    with tf.Session(server.target) as sess:\n        sess.run(queue.dequeue())\n        print('ps %d: quitting' % task)\n\n# MonitoredTrainingSession with FinalOpsHook not shown\nelif job_name == 'worker':\n    with tf.device('/job:worker/task:%d' % task):\n        with tf.name_scope('done_queue'):\n            queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\n    with tf.Session(server.target) as sess:\n        _, size = sess.run([queue.enqueue(1), queue.size()])\n        print('Worker:%d sending done to ps:%d [elements=%d]' % (task, 0, size))\n</code></pre>", "body_text": "System information\n\nEnvironment:\nShared Cluster\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nRHEL Server 7.2\nTensorFlow installed from (source or binary):\npip install tensorflow-gpu\nTensorFlow version (use command below):\nv1.5.0-0-g37aa430d84 1.5.0\nPython version:\n3.6\nCUDA/cuDNN version:\n9.0/7.0\nGPU model and memory:\nN/A -- GPU not allocated\n\nI am attempting to use a FIFOQueue to signal the parameter servers to shut down on a multi-machine shared cluster, based on this example. After some testing, I believe that shared_name simply doesn't seem to do anything--even after removing the dequeue() operations, the number of elements in the FIFOQueue don't correlate to the number of workers.\nMinimum Reproducible Code\n# for example\ncluster = tf.train.ClusterSpec({\n    'ps': ['192.168.1.1:36598'],\n    'worker': ['192.168.1.2:40596', '192.168.1.3:47324', '192.168.1.4:38923']\n})\n# ... #\nserver = tf.train.Server(cluster, job_name=job_name, task_index=task)\n\n# using server.join() causes cluster management headaches\n# use a FIFOQueue to tell the parameter server to shutdown\nif job_name == 'ps':\n    with tf.device('/job:ps/task:%d' % task):\n        queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\n    with tf.Session(server.target) as sess:\n        sess.run(queue.dequeue())\n        print('ps %d: quitting' % task)\n\n# MonitoredTrainingSession with FinalOpsHook not shown\nelif job_name == 'worker':\n    with tf.device('/job:worker/task:%d' % task):\n        with tf.name_scope('done_queue'):\n            queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\n    with tf.Session(server.target) as sess:\n        _, size = sess.run([queue.enqueue(1), queue.size()])\n        print('Worker:%d sending done to ps:%d [elements=%d]' % (task, 0, size))", "body": "### System information\r\n- **Environment**:\r\nShared Cluster\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nRHEL Server 7.2\r\n- **TensorFlow installed from (source or binary)**:\r\npip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**:\r\nv1.5.0-0-g37aa430d84 1.5.0\r\n- **Python version**:\r\n3.6\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0\r\n- **GPU model and memory**:\r\nN/A -- GPU not allocated\r\n\r\nI am attempting to use a `FIFOQueue` to signal the parameter servers to shut down on a multi-machine shared cluster, based on [this](https://stackoverflow.com/questions/39810356/shut-down-server-in-tensorflow/40186129#40186129) [example](https://gist.github.com/yaroslavvb/ea1b1bae0a75c4aae593df7eca72d9ca). After some testing, I believe that `shared_name` simply doesn't seem to do anything--even after removing the `dequeue()` operations, the number of elements in the `FIFOQueue` don't correlate to the number of workers.\r\n\r\nMinimum Reproducible Code\r\n```\r\n# for example\r\ncluster = tf.train.ClusterSpec({\r\n    'ps': ['192.168.1.1:36598'],\r\n    'worker': ['192.168.1.2:40596', '192.168.1.3:47324', '192.168.1.4:38923']\r\n})\r\n# ... #\r\nserver = tf.train.Server(cluster, job_name=job_name, task_index=task)\r\n\r\n# using server.join() causes cluster management headaches\r\n# use a FIFOQueue to tell the parameter server to shutdown\r\nif job_name == 'ps':\r\n    with tf.device('/job:ps/task:%d' % task):\r\n        queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\r\n    with tf.Session(server.target) as sess:\r\n        sess.run(queue.dequeue())\r\n        print('ps %d: quitting' % task)\r\n\r\n# MonitoredTrainingSession with FinalOpsHook not shown\r\nelif job_name == 'worker':\r\n    with tf.device('/job:worker/task:%d' % task):\r\n        with tf.name_scope('done_queue'):\r\n            queue = tf.FIFOQueue(cluster.num_tasks('worker'), tf.int32, shared_name='done_queue')\r\n    with tf.Session(server.target) as sess:\r\n        _, size = sess.run([queue.enqueue(1), queue.size()])\r\n        print('Worker:%d sending done to ps:%d [elements=%d]' % (task, 0, size))\r\n```"}