{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231394806", "pull_request_review_id": 172355443, "id": 231394806, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTM5NDgwNg==", "diff_hunk": "@@ -2391,6 +2638,161 @@ MklLayoutRewritePass::CheckForNodeRewrite(const Node* n) const {\n   return nullptr;\n }\n \n+//////////////////////////////////////////////////////////////////////////\n+//           Helper functions for node fusion\n+//////////////////////////////////////////////////////////////////////////\n+Status MklLayoutRewritePass::FuseTransposeMklOpTranspose(\n+    std::unique_ptr<Graph>* g, std::vector<Node*>& nodes,\n+    std::function<void(const Node*, NodeBuilder* nb, bool)> copy_attrs,\n+    string data_format) {\n+  Node* transpose_to_nhwc = nodes[0];\n+  Node* mklop = nodes[1];\n+  Node* transpose_to_nchw = nodes[2];\n+\n+  const int transpose_nhwc_num_inputs = transpose_to_nhwc->num_inputs();\n+  gtl::InlinedVector<Node*, 4> transpose_nhwc_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> transpose_nhwc_in(\n+      transpose_nhwc_num_inputs);\n+  FillInputs(transpose_to_nhwc, &transpose_nhwc_control_edges,\n+             &transpose_nhwc_in);\n+\n+  const int mklop_num_inputs = mklop->num_inputs();\n+  gtl::InlinedVector<Node*, 4> mklop_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> mklop_in(mklop_num_inputs);\n+  FillInputs(mklop, &mklop_control_edges, &mklop_in);\n+\n+  const int transpose_nchw_num_inputs = transpose_to_nchw->num_inputs();\n+  gtl::InlinedVector<Node*, 4> transpose_nchw_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> transpose_nchw_in(\n+      transpose_nchw_num_inputs);\n+  FillInputs(transpose_to_nchw, &transpose_nchw_control_edges,\n+             &transpose_nchw_in);\n+\n+  // We use same name as original node, but change the op\n+  // name.\n+  NodeBuilder nb(mklop->name(), mklop->type_string());\n+\n+  for (int i = 0; i < mklop_num_inputs; i++) {\n+    if (mklop_in[i].first == transpose_to_nhwc) {\n+      // Fill \"x\":\n+      nb.Input(transpose_nhwc_in[0].first, transpose_nhwc_in[0].second);\n+    } else {\n+      // Fill inputs other than \"x\":\n+      nb.Input(mklop_in[i].first, mklop_in[i].second);\n+    }\n+  }\n+\n+  copy_attrs(const_cast<const Node*>(mklop), &nb, true);\n+  nb.Attr(\"data_format\", data_format);\n+\n+  // Copy the device assigned to old node to new node.\n+  nb.Device(mklop->def().device());\n+\n+  // Create node.\n+  Node* new_node;\n+  TF_CHECK_OK(nb.Finalize(&**g, &new_node));\n+  CHECK_NOTNULL(new_node);\n+\n+  // Fill outputs.\n+  for (const Edge* e : transpose_to_nchw->out_edges()) {\n+    if (!e->IsControlEdge()) {\n+      const int kTransposeWithMklOpOutputSlot = 0;\n+      CHECK_NOTNULL((*g)->AddEdge(new_node, kTransposeWithMklOpOutputSlot, e->dst(),\n+                                  e->dst_input()));\n+    }\n+  }\n+\n+  // Copy device assigned to old node to new node.\n+  new_node->set_assigned_device_name(mklop->assigned_device_name());\n+\n+  // Copy requested_device and assigned_device_name_index\n+  new_node->set_requested_device(mklop->requested_device());\n+  new_node->set_assigned_device_name_index(mklop->assigned_device_name_index());\n+\n+  (*g)->RemoveNode(transpose_to_nhwc);\n+  (*g)->RemoveNode(mklop);\n+  (*g)->RemoveNode(transpose_to_nchw);\n+\n+  return Status::OK();\n+}\n+\n+Status MklLayoutRewritePass::FuseNode(\n+    std::unique_ptr<Graph>* g, std::vector<Node*>& nodes,\n+    const MklLayoutRewritePass::FusionInfo fi) {\n+  return fi.fuse_func(g, nodes, fi.copy_attrs);\n+}\n+\n+std::tuple<bool, std::vector<Node*>, const MklLayoutRewritePass::FusionInfo>\n+MklLayoutRewritePass::CheckForNodeFusion(Node* a) const {\n+  const FusionInfo* fi_ptr = nullptr;\n+\n+  for (auto fi = finfo_.begin(); fi != finfo_.end(); ++fi) {\n+    fi_ptr = &*fi;\n+    //\n+    // Make sure node \"a\" and its succeding nodes (b, c ...), match the pattern\n+    // defined in fusion info (ops[0], ops[1], ...),\n+    // aka. \"a->b->c\" matches \"op1->op2->op3\"\n+    //\n+\n+    std::stack<Node *, std::vector<Node *>> work_stack;\n+    std::unordered_set<Node *> visited_nodes;", "path": "tensorflow/core/graph/mkl_layout_pass.cc", "position": null, "original_position": 612, "commit_id": "88b2369fe7c4451c63ff0599f7477897dabff2e0", "original_commit_id": "13ed0286c40c81f23a73a9cd773da4d1dd27197a", "user": {"login": "wenxizhu", "id": 33611326, "node_id": "MDQ6VXNlcjMzNjExMzI2", "avatar_url": "https://avatars1.githubusercontent.com/u/33611326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenxizhu", "html_url": "https://github.com/wenxizhu", "followers_url": "https://api.github.com/users/wenxizhu/followers", "following_url": "https://api.github.com/users/wenxizhu/following{/other_user}", "gists_url": "https://api.github.com/users/wenxizhu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenxizhu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenxizhu/subscriptions", "organizations_url": "https://api.github.com/users/wenxizhu/orgs", "repos_url": "https://api.github.com/users/wenxizhu/repos", "events_url": "https://api.github.com/users/wenxizhu/events{/privacy}", "received_events_url": "https://api.github.com/users/wenxizhu/received_events", "type": "User", "site_admin": false}, "body": "You're right, that's a good counter-example. My algorithm has implications that subgraph is always a tree (whose root is \"A\"), that may not be true in real-world models. \r\n\r\nI modified the code, applied the idea you provide that \"remove the loop for out_edges()\" and \"record edge iterator instead of visited nodes\", but I probably not fully understand your idea:\r\n1. I don't think we can totally get rid of the `work_stack`, because overall this is a stack-based algorithm and we need a stack to help us roll back, that's what `work_stack` does.\r\n2. I prefer to to have `current_neighbor` as a `stack` rather than `vector`, then it will expand and shrink just as what `work_stack` does at the same time. This could avoid handling the `index` when rollback, it's more natural I think.\r\n", "created_at": "2018-11-07T06:43:33Z", "updated_at": "2018-11-14T06:34:27Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/23152#discussion_r231394806", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23152", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/231394806"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23152#discussion_r231394806"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23152"}}, "body_html": "<p>You're right, that's a good counter-example. My algorithm has implications that subgraph is always a tree (whose root is \"A\"), that may not be true in real-world models.</p>\n<p>I modified the code, applied the idea you provide that \"remove the loop for out_edges()\" and \"record edge iterator instead of visited nodes\", but I probably not fully understand your idea:</p>\n<ol>\n<li>I don't think we can totally get rid of the <code>work_stack</code>, because overall this is a stack-based algorithm and we need a stack to help us roll back, that's what <code>work_stack</code> does.</li>\n<li>I prefer to to have <code>current_neighbor</code> as a <code>stack</code> rather than <code>vector</code>, then it will expand and shrink just as what <code>work_stack</code> does at the same time. This could avoid handling the <code>index</code> when rollback, it's more natural I think.</li>\n</ol>", "body_text": "You're right, that's a good counter-example. My algorithm has implications that subgraph is always a tree (whose root is \"A\"), that may not be true in real-world models.\nI modified the code, applied the idea you provide that \"remove the loop for out_edges()\" and \"record edge iterator instead of visited nodes\", but I probably not fully understand your idea:\n\nI don't think we can totally get rid of the work_stack, because overall this is a stack-based algorithm and we need a stack to help us roll back, that's what work_stack does.\nI prefer to to have current_neighbor as a stack rather than vector, then it will expand and shrink just as what work_stack does at the same time. This could avoid handling the index when rollback, it's more natural I think.", "in_reply_to_id": 230461560}