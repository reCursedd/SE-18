{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439574707", "html_url": "https://github.com/tensorflow/tensorflow/issues/21522#issuecomment-439574707", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21522", "id": 439574707, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTU3NDcwNw==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-17T01:18:35Z", "updated_at": "2018-11-17T01:18:35Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8779942\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reger-men\">@reger-men</a> : Is it possible to get a shorter snippet that demonstrates the problem (ideally one that doesn't require downloading the dataset or figuring out how exactly to run the command in your repository). Could you elaborate on what you mean by \"memory is being allocated multiple times\"? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22289808\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/msabony1966\">@msabony1966</a> : Perhaps you have another, simpler, example demonstrating the problem?</p>\n<p>Note that TensorFlow doesn't return GPU memory to the system when it allocates it. So the memory usage you see in <code>nvidia-smi</code> will be the peak memory utilized on each GPU, which in-turn would need to account for both model parameters hosted on the device as well as the size of intermediate tensors computed along the way.</p>\n<p>Is it possible that even with model parallelism you're doing some operations that require parameters hosted on one GPU to be transferred to another GPU or something? Or that there are intermediate tensors computed on a single GPU that are larger than the memory footprint of that single GPU?</p>", "body_text": "@reger-men : Is it possible to get a shorter snippet that demonstrates the problem (ideally one that doesn't require downloading the dataset or figuring out how exactly to run the command in your repository). Could you elaborate on what you mean by \"memory is being allocated multiple times\"? @msabony1966 : Perhaps you have another, simpler, example demonstrating the problem?\nNote that TensorFlow doesn't return GPU memory to the system when it allocates it. So the memory usage you see in nvidia-smi will be the peak memory utilized on each GPU, which in-turn would need to account for both model parameters hosted on the device as well as the size of intermediate tensors computed along the way.\nIs it possible that even with model parallelism you're doing some operations that require parameters hosted on one GPU to be transferred to another GPU or something? Or that there are intermediate tensors computed on a single GPU that are larger than the memory footprint of that single GPU?", "body": "@reger-men : Is it possible to get a shorter snippet that demonstrates the problem (ideally one that doesn't require downloading the dataset or figuring out how exactly to run the command in your repository). Could you elaborate on what you mean by \"memory is being allocated multiple times\"? @msabony1966 : Perhaps you have another, simpler, example demonstrating the problem?\r\n\r\nNote that TensorFlow doesn't return GPU memory to the system when it allocates it. So the memory usage you see in `nvidia-smi` will be the peak memory utilized on each GPU, which in-turn would need to account for both model parameters hosted on the device as well as the size of intermediate tensors computed along the way.\r\n\r\nIs it possible that even with model parallelism you're doing some operations that require parameters hosted on one GPU to be transferred to another GPU or something? Or that there are intermediate tensors computed on a single GPU that are larger than the memory footprint of that single GPU?"}