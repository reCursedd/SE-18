{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15343", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15343/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15343/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15343/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15343", "id": 281846768, "node_id": "MDU6SXNzdWUyODE4NDY3Njg=", "number": 15343, "title": "Iterator on cached tf.data Dataset cannot be reinitialized ", "user": {"login": "agrinh", "id": 2157859, "node_id": "MDQ6VXNlcjIxNTc4NTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/2157859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agrinh", "html_url": "https://github.com/agrinh", "followers_url": "https://api.github.com/users/agrinh/followers", "following_url": "https://api.github.com/users/agrinh/following{/other_user}", "gists_url": "https://api.github.com/users/agrinh/gists{/gist_id}", "starred_url": "https://api.github.com/users/agrinh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agrinh/subscriptions", "organizations_url": "https://api.github.com/users/agrinh/orgs", "repos_url": "https://api.github.com/users/agrinh/repos", "events_url": "https://api.github.com/users/agrinh/events{/privacy}", "received_events_url": "https://api.github.com/users/agrinh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "saeta", "id": 1284535, "node_id": "MDQ6VXNlcjEyODQ1MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saeta", "html_url": "https://github.com/saeta", "followers_url": "https://api.github.com/users/saeta/followers", "following_url": "https://api.github.com/users/saeta/following{/other_user}", "gists_url": "https://api.github.com/users/saeta/gists{/gist_id}", "starred_url": "https://api.github.com/users/saeta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saeta/subscriptions", "organizations_url": "https://api.github.com/users/saeta/orgs", "repos_url": "https://api.github.com/users/saeta/repos", "events_url": "https://api.github.com/users/saeta/events{/privacy}", "received_events_url": "https://api.github.com/users/saeta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "saeta", "id": 1284535, "node_id": "MDQ6VXNlcjEyODQ1MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saeta", "html_url": "https://github.com/saeta", "followers_url": "https://api.github.com/users/saeta/followers", "following_url": "https://api.github.com/users/saeta/following{/other_user}", "gists_url": "https://api.github.com/users/saeta/gists{/gist_id}", "starred_url": "https://api.github.com/users/saeta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saeta/subscriptions", "organizations_url": "https://api.github.com/users/saeta/orgs", "repos_url": "https://api.github.com/users/saeta/repos", "events_url": "https://api.github.com/users/saeta/events{/privacy}", "received_events_url": "https://api.github.com/users/saeta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2017-12-13T18:15:07Z", "updated_at": "2018-04-05T16:02:39Z", "closed_at": "2017-12-14T19:52:24Z", "author_association": "NONE", "body_html": "<p>Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets, one for validation and one for training. The iterator can however only be initialized once per cached dataset. Seems to me like the iterator should remove the lock file when being reinitialized, it is not in my case and that is why I get this issue. Here's a minimal example with only one cached dataset.</p>\n<p>(basic system information below)</p>\n<h3>Example</h3>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\ndata <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>).astype(np.float32)\ndataset <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(data)\nbatches <span class=\"pl-k\">=</span> dataset.shuffle(<span class=\"pl-c1\">10</span>).repeat().batch(<span class=\"pl-c1\">5</span>)\n\nconfig <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">device_count</span> <span class=\"pl-k\">=</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>GPU<span class=\"pl-pds\">'</span></span>: <span class=\"pl-c1\">0</span>})\nsess <span class=\"pl-k\">=</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\n\ncache_dir <span class=\"pl-k\">=</span> os.path.join(os.getcwd(), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>cache_dir<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">try</span>:\n    os.makedirs(cache_dir)\n<span class=\"pl-k\">except</span> <span class=\"pl-c1\">OSError</span>:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Cache directory already exists<span class=\"pl-pds\">'</span></span>)\n\ncached <span class=\"pl-k\">=</span> batches.cache(os.path.join(cache_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>cache<span class=\"pl-pds\">'</span></span>))\niterator <span class=\"pl-k\">=</span> tf.data.Iterator.from_structure(<span class=\"pl-v\">output_types</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">output_shapes</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>))\nbatch <span class=\"pl-k\">=</span> iterator.get_next()\n\ninit1 <span class=\"pl-k\">=</span> iterator.make_initializer(cached)\ninit2 <span class=\"pl-k\">=</span> iterator.make_initializer(batches)\n\nsess.run(init1)\nsess.run(batch)</pre></div>\n<blockquote>\n<p>array([[ 0.11960778,  0.3081578 ,  0.96522039],<br>\n[ 0.90339011,  0.12458269,  0.30650312],<br>\n[ 0.58160347,  0.55877644,  0.50363588],<br>\n[ 0.2350398 ,  0.33509603,  0.4165386 ],<br>\n[ 0.76757395,  0.50134581,  0.93601096]], dtype=float32)</p>\n</blockquote>\n<div class=\"highlight highlight-source-python\"><pre>sess.run(init2)\nsess.run(batch)</pre></div>\n<blockquote>\n<p>array([[ 0.76757395,  0.50134581,  0.93601096],<br>\n[ 0.2350398 ,  0.33509603,  0.4165386 ],<br>\n[ 0.90339011,  0.12458269,  0.30650312],<br>\n[ 0.13266359,  0.82675195,  0.26691398],<br>\n[ 0.58160347,  0.55877644,  0.50363588]], dtype=float32)</p>\n</blockquote>\n<div class=\"highlight highlight-source-python\"><pre>sess.run(init1)\nsess.run(batch)</pre></div>\n<blockquote>\n<p>AlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/home/ubuntu/ai_notebooks/notebooks/projects/deep-purple/cache_dir/cache.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1513187725<br>\n[[Node: IteratorGetNext = IteratorGetNext<a href=\"Iterator\">output_shapes=[[5,3]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"</a>]]</p>\n</blockquote>\n<h3>Sytem information</h3>\n<p>Tensorflow version: v1.4.0-rc1-11-g130a514 1.4.0 (installed from pip)<br>\nPython version: 3.5.2<br>\nOS: Linux Ubuntu 16.04.3<br>\nCUDA: 8.0.61<br>\ncuDNN: 6</p>", "body_text": "Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets, one for validation and one for training. The iterator can however only be initialized once per cached dataset. Seems to me like the iterator should remove the lock file when being reinitialized, it is not in my case and that is why I get this issue. Here's a minimal example with only one cached dataset.\n(basic system information below)\nExample\nimport os\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndata = np.random.rand(10, 3).astype(np.float32)\ndataset = tf.data.Dataset.from_tensor_slices(data)\nbatches = dataset.shuffle(10).repeat().batch(5)\n\nconfig = tf.ConfigProto(device_count = {'GPU': 0})\nsess = tf.Session(config=config)\n\ncache_dir = os.path.join(os.getcwd(), 'cache_dir')\ntry:\n    os.makedirs(cache_dir)\nexcept OSError:\n    print('Cache directory already exists')\n\ncached = batches.cache(os.path.join(cache_dir, 'cache'))\niterator = tf.data.Iterator.from_structure(output_types=tf.float32, output_shapes=(5, 3))\nbatch = iterator.get_next()\n\ninit1 = iterator.make_initializer(cached)\ninit2 = iterator.make_initializer(batches)\n\nsess.run(init1)\nsess.run(batch)\n\narray([[ 0.11960778,  0.3081578 ,  0.96522039],\n[ 0.90339011,  0.12458269,  0.30650312],\n[ 0.58160347,  0.55877644,  0.50363588],\n[ 0.2350398 ,  0.33509603,  0.4165386 ],\n[ 0.76757395,  0.50134581,  0.93601096]], dtype=float32)\n\nsess.run(init2)\nsess.run(batch)\n\narray([[ 0.76757395,  0.50134581,  0.93601096],\n[ 0.2350398 ,  0.33509603,  0.4165386 ],\n[ 0.90339011,  0.12458269,  0.30650312],\n[ 0.13266359,  0.82675195,  0.26691398],\n[ 0.58160347,  0.55877644,  0.50363588]], dtype=float32)\n\nsess.run(init1)\nsess.run(batch)\n\nAlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/home/ubuntu/ai_notebooks/notebooks/projects/deep-purple/cache_dir/cache.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1513187725\n[[Node: IteratorGetNext = IteratorGetNextoutput_shapes=[[5,3]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\n\nSytem information\nTensorflow version: v1.4.0-rc1-11-g130a514 1.4.0 (installed from pip)\nPython version: 3.5.2\nOS: Linux Ubuntu 16.04.3\nCUDA: 8.0.61\ncuDNN: 6", "body": "Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets, one for validation and one for training. The iterator can however only be initialized once per cached dataset. Seems to me like the iterator should remove the lock file when being reinitialized, it is not in my case and that is why I get this issue. Here's a minimal example with only one cached dataset.\r\n\r\n(basic system information below)\r\n\r\n### Example\r\n```python\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndata = np.random.rand(10, 3).astype(np.float32)\r\ndataset = tf.data.Dataset.from_tensor_slices(data)\r\nbatches = dataset.shuffle(10).repeat().batch(5)\r\n\r\nconfig = tf.ConfigProto(device_count = {'GPU': 0})\r\nsess = tf.Session(config=config)\r\n\r\ncache_dir = os.path.join(os.getcwd(), 'cache_dir')\r\ntry:\r\n    os.makedirs(cache_dir)\r\nexcept OSError:\r\n    print('Cache directory already exists')\r\n\r\ncached = batches.cache(os.path.join(cache_dir, 'cache'))\r\niterator = tf.data.Iterator.from_structure(output_types=tf.float32, output_shapes=(5, 3))\r\nbatch = iterator.get_next()\r\n\r\ninit1 = iterator.make_initializer(cached)\r\ninit2 = iterator.make_initializer(batches)\r\n\r\nsess.run(init1)\r\nsess.run(batch)\r\n```\r\n> array([[ 0.11960778,  0.3081578 ,  0.96522039],\r\n       [ 0.90339011,  0.12458269,  0.30650312],\r\n       [ 0.58160347,  0.55877644,  0.50363588],\r\n       [ 0.2350398 ,  0.33509603,  0.4165386 ],\r\n       [ 0.76757395,  0.50134581,  0.93601096]], dtype=float32)\r\n\r\n```python\r\nsess.run(init2)\r\nsess.run(batch)\r\n```\r\n> array([[ 0.76757395,  0.50134581,  0.93601096],\r\n       [ 0.2350398 ,  0.33509603,  0.4165386 ],\r\n       [ 0.90339011,  0.12458269,  0.30650312],\r\n       [ 0.13266359,  0.82675195,  0.26691398],\r\n       [ 0.58160347,  0.55877644,  0.50363588]], dtype=float32)\r\n\r\n```python\r\nsess.run(init1)\r\nsess.run(batch)\r\n```\r\n> AlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/home/ubuntu/ai_notebooks/notebooks/projects/deep-purple/cache_dir/cache.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1513187725\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[5,3]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\n\r\n### Sytem information\r\nTensorflow version: v1.4.0-rc1-11-g130a514 1.4.0 (installed from pip)\r\nPython version: 3.5.2\r\nOS: Linux Ubuntu 16.04.3\r\nCUDA: 8.0.61\r\ncuDNN: 6"}