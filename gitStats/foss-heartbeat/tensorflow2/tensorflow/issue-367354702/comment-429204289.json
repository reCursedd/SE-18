{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/429204289", "html_url": "https://github.com/tensorflow/tensorflow/issues/22780#issuecomment-429204289", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22780", "id": 429204289, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTIwNDI4OQ==", "user": {"login": "facaiy", "id": 1112263, "node_id": "MDQ6VXNlcjExMTIyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1112263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/facaiy", "html_url": "https://github.com/facaiy", "followers_url": "https://api.github.com/users/facaiy/followers", "following_url": "https://api.github.com/users/facaiy/following{/other_user}", "gists_url": "https://api.github.com/users/facaiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/facaiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/facaiy/subscriptions", "organizations_url": "https://api.github.com/users/facaiy/orgs", "repos_url": "https://api.github.com/users/facaiy/repos", "events_url": "https://api.github.com/users/facaiy/events{/privacy}", "received_events_url": "https://api.github.com/users/facaiy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T04:57:07Z", "updated_at": "2018-10-12T07:46:36Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5126549\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lminer\">@lminer</a> Hi, can you use native optimizer (not TFOptimizer) directly? I think keras will take care of itself.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tensorflow.contrib.opt <span class=\"pl-k\">import</span> AdamWOptimizer\n<span class=\"pl-k\">from</span> tensorflow.python.keras.optimizers <span class=\"pl-k\">import</span> TFOptimizer\n<span class=\"pl-k\">from</span> tensorflow.python.keras.layers <span class=\"pl-k\">import</span> Dense\n<span class=\"pl-k\">from</span> tensorflow.python.keras.models <span class=\"pl-k\">import</span> Sequential\n\nmodel <span class=\"pl-k\">=</span> Sequential()\nmodel.add(Dense(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">activation</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tanh<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">input_shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,)))\n\ntfopt <span class=\"pl-k\">=</span> AdamWOptimizer(<span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">.004</span>)\n\nmodel.compile(<span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span>tfopt, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>mean_squared_error<span class=\"pl-pds\">'</span></span>)\nmodel.fit(np.random.random((<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>)),\n          np.random.random((<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">2</span>)),\n          <span class=\"pl-v\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>)</pre></div>", "body_text": "@lminer Hi, can you use native optimizer (not TFOptimizer) directly? I think keras will take care of itself.\nfrom tensorflow.contrib.opt import AdamWOptimizer\nfrom tensorflow.python.keras.optimizers import TFOptimizer\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(2, activation=\"tanh\", input_shape=(3,)))\n\ntfopt = AdamWOptimizer(weight_decay=0.1, learning_rate=.004)\n\nmodel.compile(optimizer=tfopt, loss='mean_squared_error')\nmodel.fit(np.random.random((5, 3)),\n          np.random.random((5, 2)),\n          epochs=5, batch_size=5)", "body": "@lminer Hi, can you use native optimizer (not TFOptimizer) directly? I think keras will take care of itself.\r\n\r\n```python\r\nfrom tensorflow.contrib.opt import AdamWOptimizer\r\nfrom tensorflow.python.keras.optimizers import TFOptimizer\r\nfrom tensorflow.python.keras.layers import Dense\r\nfrom tensorflow.python.keras.models import Sequential\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(2, activation=\"tanh\", input_shape=(3,)))\r\n\r\ntfopt = AdamWOptimizer(weight_decay=0.1, learning_rate=.004)\r\n\r\nmodel.compile(optimizer=tfopt, loss='mean_squared_error')\r\nmodel.fit(np.random.random((5, 3)),\r\n          np.random.random((5, 2)),\r\n          epochs=5, batch_size=5)\r\n```"}