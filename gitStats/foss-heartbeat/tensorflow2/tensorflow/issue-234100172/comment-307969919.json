{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/307969919", "html_url": "https://github.com/tensorflow/tensorflow/pull/10482#issuecomment-307969919", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10482", "id": 307969919, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzk2OTkxOQ==", "user": {"login": "bowang", "id": 425637, "node_id": "MDQ6VXNlcjQyNTYzNw==", "avatar_url": "https://avatars3.githubusercontent.com/u/425637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bowang", "html_url": "https://github.com/bowang", "followers_url": "https://api.github.com/users/bowang/followers", "following_url": "https://api.github.com/users/bowang/following{/other_user}", "gists_url": "https://api.github.com/users/bowang/gists{/gist_id}", "starred_url": "https://api.github.com/users/bowang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bowang/subscriptions", "organizations_url": "https://api.github.com/users/bowang/orgs", "repos_url": "https://api.github.com/users/bowang/repos", "events_url": "https://api.github.com/users/bowang/events{/privacy}", "received_events_url": "https://api.github.com/users/bowang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-13T00:13:30Z", "updated_at": "2017-06-13T00:13:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7370869\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sleepfin\">@sleepfin</a> Thanks for the performance measurement! My hypothesis on the GPU/CPU performance difference is caused by the change of per-op and total computation workload in group convolution.</p>\n<p>As in the current implementation that a single large convolution is decomposed into a number of small convolutions, the workload for a single small convolution may not be able to fully utilize a GPU to its limit. Thus, the GPU utilization decrease may lead to the slowdown.</p>\n<p>Meanwhile, when comparing the total amount of workload, that of the group convolution is smaller than that of a single convolution. Since CPU has much lower computation power, it is always saturated. Thus, the speedup on CPU was due to the reduction of total workload.</p>\n<p>This is just my hypothesis. Hope it may generate some ideas for further performance debugging.</p>", "body_text": "@sleepfin Thanks for the performance measurement! My hypothesis on the GPU/CPU performance difference is caused by the change of per-op and total computation workload in group convolution.\nAs in the current implementation that a single large convolution is decomposed into a number of small convolutions, the workload for a single small convolution may not be able to fully utilize a GPU to its limit. Thus, the GPU utilization decrease may lead to the slowdown.\nMeanwhile, when comparing the total amount of workload, that of the group convolution is smaller than that of a single convolution. Since CPU has much lower computation power, it is always saturated. Thus, the speedup on CPU was due to the reduction of total workload.\nThis is just my hypothesis. Hope it may generate some ideas for further performance debugging.", "body": "@sleepfin Thanks for the performance measurement! My hypothesis on the GPU/CPU performance difference is caused by the change of per-op and total computation workload in group convolution.\r\n\r\nAs in the current implementation that a single large convolution is decomposed into a number of small convolutions, the workload for a single small convolution may not be able to fully utilize a GPU to its limit. Thus, the GPU utilization decrease may lead to the slowdown.\r\n\r\nMeanwhile, when comparing the total amount of workload, that of the group convolution is smaller than that of a single convolution. Since CPU has much lower computation power, it is always saturated. Thus, the speedup on CPU was due to the reduction of total workload.\r\n\r\nThis is just my hypothesis. Hope it may generate some ideas for further performance debugging."}